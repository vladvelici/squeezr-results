start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050630427897), (30, 0.010039400542154908), (31, 0.01036160031799227), (34, 0.01331227587070316), (29, 0.013541154563426971), (35, 0.016018463298678398), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.0202324572019279), (46, 0.02104453998617828), (25, 0.021972602931782603), (23, 0.022379535948857665), (41, 0.022826647851616144), (44, 0.023395078955218196), (40, 0.024025025544688106), (45, 0.02429541014134884), (21, 0.02492459793575108), (22, 0.025168768130242825), (48, 0.02534125978127122), (24, 0.025899537140503526), (50, 0.02640997269190848), (42, 0.02667410089634359), (20, 0.02685900661163032), (49, 0.027037164196372032), (47, 0.029306469252333045), (39, 0.031570713268592954), (38, 0.03163787070661783), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.037960261572152376), (51, 0.04173417203128338), (9, 0.04340188158676028), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836634796112776), (2, 0.05454846704378724), (3, 0.05722427600994706), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734145730734), (52, 0.06862937565892935), (8, 0.07467832416296005), (10, 0.08034484647214413), (16, 0.08408282697200775), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.43757999688386917), (18, 0.5108212977647781), (53, 0.8211489245295525)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.01036160031799227), (34, 0.013133947271853685), (29, 0.013541154330596328), (26, 0.016037590568885207), (35, 0.0161692900583148), (28, 0.017728675389662385), (27, 0.019127049250528216), (43, 0.020072476705536246), (46, 0.020731385564431548), (25, 0.02197260269895196), (41, 0.02234709309414029), (23, 0.02237953571602702), (44, 0.023235687986016273), (40, 0.023841066751629114), (45, 0.02396554290316999), (48, 0.024917916161939502), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.02584081352688372), (24, 0.025899536442011595), (42, 0.026315323309972882), (49, 0.02665567514486611), (20, 0.026859007542952895), (47, 0.028728798497468233), (39, 0.03131764242425561), (38, 0.031380362808704376), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.038025842513889074), (51, 0.041223939042538404), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548467975109816), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.06745155155658722), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.43538710102438927), (18, 0.5108213126659393), (53, 0.8222573921084404)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600201576948), (34, 0.012765232706442475), (29, 0.013541154796257615), (35, 0.0159927518106997), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02007513167336583), (46, 0.02084140619263053), (25, 0.021972602466121316), (41, 0.022319766925647855), (23, 0.022379535483196378), (44, 0.023154049878939986), (40, 0.02388568432070315), (45, 0.024071689462289214), (48, 0.024877465097233653), (21, 0.024924597702920437), (22, 0.025168768363073468), (50, 0.025691177928820252), (24, 0.025899537606164813), (42, 0.026123747928068042), (49, 0.02647942234762013), (20, 0.026859007077291608), (47, 0.028693132335320115), (38, 0.031236795708537102), (39, 0.0312952920794487), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.032628596760332584), (37, 0.038376690819859505), (51, 0.041114033199846745), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.05892289988696575), (11, 0.05924912774935365), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734331995249), (52, 0.06700456142425537), (8, 0.07467832509428263), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387675493956), (36, 0.43640001118183136), (18, 0.5108213126659393), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.012387837166897953), (29, 0.013541154912672937), (35, 0.016008096048608422), (26, 0.01603759010322392), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.02008363325148821), (46, 0.020704444497823715), (25, 0.021972603164613247), (41, 0.022253196919336915), (23, 0.02237953571602702), (44, 0.023267761105671525), (40, 0.024013879243284464), (45, 0.0240929932333529), (48, 0.02466528001241386), (21, 0.0249245990999043), (22, 0.025168768595904112), (50, 0.02545973379164934), (42, 0.025655712466686964), (24, 0.025899537838995457), (49, 0.02628775662742555), (20, 0.026859007077291608), (47, 0.02836342342197895), (38, 0.031047647120431066), (39, 0.031380771892145276), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03897124622017145), (51, 0.040756203699857), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663293346763), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980923697352), (52, 0.06586315855383873), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4389924667775631), (18, 0.5108213126659393), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154796257615), (26, 0.016037590336054564), (35, 0.01605736301280558), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020049349404871464), (46, 0.0205529872328043), (25, 0.02197260269895196), (41, 0.022067483980208635), (23, 0.022379535250365734), (44, 0.022979133063927293), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.024386123288422823), (21, 0.02492459793575108), (50, 0.02504224143922329), (22, 0.025168768595904112), (42, 0.025414507603272796), (49, 0.025842698756605387), (24, 0.025899537606164813), (20, 0.02685900731012225), (47, 0.028050733963027596), (38, 0.031040059169754386), (39, 0.0315008033066988), (15, 0.03192339278757572), (7, 0.03228544723242521), (19, 0.032628596760332584), (37, 0.03911284962669015), (51, 0.04024627385661006), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722428020089865), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.0630098101682961), (52, 0.06486208736896515), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4381278418004513), (18, 0.5108213052153587), (53, 0.8458427637815475)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.017728674924001098), (27, 0.019127048319205642), (43, 0.02050345577299595), (46, 0.0207253226544708), (25, 0.021972603164613247), (23, 0.022379534784704447), (41, 0.02245262893848121), (44, 0.023364473832771182), (48, 0.024290355620905757), (45, 0.024438713677227497), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.02504217205569148), (22, 0.025168768363073468), (49, 0.02587597002275288), (24, 0.025899537838995457), (42, 0.026205407455563545), (20, 0.02685900731012225), (47, 0.028178583132103086), (15, 0.03192339139059186), (38, 0.032083500642329454), (7, 0.03228544583544135), (39, 0.03233744064345956), (19, 0.032628594897687435), (51, 0.039947258308529854), (37, 0.04073968203738332), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663526177406), (2, 0.05454846518114209), (3, 0.05722427600994706), (13, 0.05892290035262704), (11, 0.05924913100898266), (17, 0.06095684878528118), (0, 0.06300981063395739), (52, 0.06433630175888538), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4505343362689018), (18, 0.5108213052153587), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 1 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 2 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 3 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 4 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 5 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 6 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 7 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 8 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 9 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 10 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.0164706080686301), (28, 0.017728675389662385), (27, 0.019127048086374998), (43, 0.020046866731718183), (46, 0.020376994041725993), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.022379535250365734), (44, 0.023028337862342596), (48, 0.02377187693491578), (40, 0.023930813185870647), (45, 0.024178663035854697), (50, 0.02439029887318611), (21, 0.024924597470089793), (22, 0.0251687690615654), (42, 0.025188251165673137), (49, 0.02536152908578515), (24, 0.0258995380718261), (20, 0.02685900661163032), (47, 0.02736328006722033), (38, 0.031365619506686926), (15, 0.03192339092493057), (39, 0.03212768537923694), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03893592348322272), (37, 0.04020634340122342), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663526177406), (2, 0.05454846424981952), (3, 0.057224275544285774), (13, 0.058922899421304464), (11, 0.05924912774935365), (17, 0.06095684738829732), (52, 0.06232855003327131), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4444201961159706), (18, 0.5108212828636169), (53, 0.8537911921739578)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366262227297), (28, 0.017088500317186117), (27, 0.01888244692236185), (43, 0.019595165271312), (46, 0.02007358125410974), (41, 0.02096158522181213), (25, 0.021972602233290672), (23, 0.02237953501753509), (44, 0.022814956260845065), (48, 0.023128160974010825), (40, 0.02334519545547664), (50, 0.02375614712946117), (42, 0.023847302421927452), (45, 0.023873880272731185), (21, 0.02492459793575108), (49, 0.024960316019132733), (22, 0.025168769294396043), (24, 0.025899537140503526), (47, 0.02685554209165275), (20, 0.026859006844460964), (38, 0.030424013966694474), (39, 0.031514043686911464), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.037824880331754684), (37, 0.039368351455777884), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846378415823), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912868067622), (52, 0.06033282168209553), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4360685460269451), (18, 0.5108212977647781), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366262227297
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945483967662), (27, 0.018882447155192494), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.021467272425070405), (25, 0.02197260269895196), (44, 0.02202691719867289), (40, 0.02217966108582914), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.022379535483196378), (45, 0.022931481944397092), (49, 0.023708512308076024), (21, 0.024924598867073655), (22, 0.0251687690615654), (47, 0.025829139398410916), (24, 0.0258995380718261), (20, 0.026859006844460964), (38, 0.028956545516848564), (39, 0.029667829163372517), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.036009025759994984), (37, 0.036512387450784445), (9, 0.043401881121098995), (6, 0.046609032433480024), (4, 0.04749368270859122), (14, 0.04783663433045149), (2, 0.054548464715480804), (52, 0.05610728682950139), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734052598476), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4175764434039593), (18, 0.5108212977647781), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.01865610177628696), (41, 0.018849018029868603), (27, 0.018882446689531207), (48, 0.02090373425744474), (42, 0.02143200417049229), (40, 0.02183242072351277), (44, 0.021840530214831233), (50, 0.021869864081963897), (25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.022492847871035337), (49, 0.023123499006032944), (21, 0.024924597470089793), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.02685900661163032), (38, 0.02811406785622239), (39, 0.029206908773630857), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.035454337019473314), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846518114209), (52, 0.054696456994861364), (3, 0.05722428020089865), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049758136272), (5, 0.10667387023568153), (36, 0.4135979115962982), (18, 0.5108212903141975), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.01888244692236185), (46, 0.019302030326798558), (42, 0.02143200417049229), (48, 0.02154484298080206), (40, 0.021832421654835343), (50, 0.02194626908749342), (25, 0.021972602233290672), (23, 0.02237953501753509), (49, 0.02300687017850578), (44, 0.023108510533347726), (45, 0.02353560645133257), (21, 0.02492459723725915), (22, 0.02516876789741218), (47, 0.025820445735007524), (24, 0.02589953667484224), (20, 0.02685900661163032), (38, 0.028114068787544966), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.035091488156467676), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368643388152), (14, 0.047836634796112776), (52, 0.05332902818918228), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.06300981109961867), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.4135979190468788), (18, 0.5108213052153587), (53, 0.9678284078836441)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008932903409), (48, 0.020678168162703514), (50, 0.021344396751374006), (40, 0.021832420956343412), (25, 0.021972602466121316), (42, 0.02198693947866559), (23, 0.022379535483196378), (49, 0.022534748073667288), (45, 0.02392991748638451), (44, 0.024054003413766623), (21, 0.024924598401412368), (22, 0.025168767664581537), (24, 0.025899538537487388), (47, 0.02604393707588315), (20, 0.02685900661163032), (38, 0.028114069486036897), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.04340188158676028), (6, 0.046609030570834875), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.050476094242185354), (2, 0.05454846564680338), (3, 0.05722427600994706), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 1 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 2 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 3 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 4 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 8 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 10 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462957531214), (48, 0.01998970750719309), (50, 0.020775062264874578), (40, 0.021085952408611774), (42, 0.021369647467508912), (49, 0.021910030161961913), (25, 0.02197260269895196), (23, 0.022379535483196378), (44, 0.023239311994984746), (45, 0.023585307877510786), (21, 0.024924598168581724), (47, 0.025076948339119554), (22, 0.02516876789741218), (24, 0.025899537838995457), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.03281426173634827), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.048523630015552044), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462957531214
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.02083116164430976), (40, 0.021085953107103705), (42, 0.021369647467508912), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.0225369893014431), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.02589953737333417), (47, 0.026583048747852445), (20, 0.02685900661163032), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.03285081312060356), (37, 0.035420244093984365), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.04749368270859122), (14, 0.04783663433045149), (52, 0.048124798107892275), (2, 0.054548466578125954), (3, 0.05722427647560835), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095685064792633), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952408611774), (42, 0.021369647700339556), (25, 0.021972602466121316), (23, 0.022379535250365734), (50, 0.02247006236575544), (44, 0.02323931222781539), (45, 0.023585308576002717), (21, 0.024924597702920437), (22, 0.025168768828734756), (49, 0.02523410157300532), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.026859006145969033), (38, 0.027183361118659377), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.032969210762530565), (37, 0.035420244093984365), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.04783663572743535), (52, 0.05089045129716396), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108213126659393), (53, 1.266390934586525)]
computing accuracy for after removing block 40 . block score: 0.021085952408611774
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284766495227814), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.023098317440599203), (44, 0.024240857921540737), (49, 0.02450086921453476), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.026519698789343238), (20, 0.02685900731012225), (38, 0.02718335995450616), (39, 0.028580758720636368), (15, 0.031923392321914434), (51, 0.032220850232988596), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.03542024362832308), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.04885757155716419), (2, 0.0545484684407711), (3, 0.05722427973523736), (13, 0.05892290035262704), (11, 0.059249129611998796), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.3718615770339966)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658535912633), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.02492459793575108), (22, 0.025168767664581537), (24, 0.025899536907672882), (47, 0.026220475090667605), (20, 0.02685900661163032), (38, 0.027183360885828733), (39, 0.02858075895346701), (51, 0.031279068207368255), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340188018977642), (52, 0.046101709827780724), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722428020089865), (13, 0.058922900818288326), (11, 0.05924912681803107), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202658535912633
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.023761966032907367), (49, 0.02460233843885362), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.02589953620918095), (47, 0.026220474625006318), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.0285807594191283), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.0334430206567049), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.047493685968220234), (14, 0.0478366338647902), (52, 0.05265179416164756), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065233878791332), (18, 0.5108212977647781), (53, 1.6287680715322495)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 1 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 2 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 3 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 4 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 5 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 6 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 7 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.1]
training epoch 8 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.966 topk_dict {'top1': 0.966}
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.045497. All blocks and scores: [(45, 0.04549655597656965), (49, 0.04816038720309734), (44, 0.05002740863710642), (22, 0.0523562585003674), (23, 0.05238677281886339), (15, 0.05275117000564933), (47, 0.05296251643449068), (21, 0.05441956827417016), (38, 0.05749991722404957), (51, 0.058734054677188396), (20, 0.05960665922611952), (19, 0.06008868804201484), (7, 0.06240570452064276), (24, 0.0626213843934238), (39, 0.06503739580512047), (52, 0.06893812026828527), (37, 0.0691007450222969), (4, 0.07561847753822803), (14, 0.08505101501941681), (6, 0.08827430661767721), (9, 0.09146765433251858), (11, 0.09476434998214245), (2, 0.09582364093512297), (0, 0.10540985967963934), (3, 0.10647993721067905), (17, 0.10923292394727468), (8, 0.11532808654010296), (13, 0.11593469977378845), (1, 0.11673002876341343), (10, 0.14129839465022087), (12, 0.15103670582175255), (16, 0.15286844223737717), (5, 0.19707568362355232), (36, 0.6370783969759941), (18, 0.7120620161294937), (53, 0.9967640787363052)]
computing accuracy for after removing block 45 . block score: 0.04549655597656965
removed block 45 current accuracy 0.9586 loss from initial  0.04139999999999999
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.050027. All blocks and scores: [(44, 0.05002740817144513), (22, 0.05235625943168998), (23, 0.05238677281886339), (15, 0.052751169074326754), (49, 0.053193549159914255), (21, 0.05441956873983145), (38, 0.05749991862103343), (51, 0.058074348606169224), (20, 0.05960666015744209), (19, 0.06008868804201484), (47, 0.060926666017621756), (7, 0.06240570917725563), (24, 0.06262138253077865), (39, 0.0650373948737979), (37, 0.06910074409097433), (52, 0.07034987863153219), (4, 0.07561848126351833), (14, 0.08505101501941681), (6, 0.08827430848032236), (9, 0.09146765526384115), (11, 0.0947643518447876), (2, 0.09582364372909069), (0, 0.10540986154228449), (3, 0.10647993348538876), (17, 0.10923292580991983), (8, 0.11532808747142553), (13, 0.1159346979111433), (1, 0.11673002410680056), (10, 0.14129839651286602), (12, 0.15103670954704285), (16, 0.15286844223737717), (5, 0.19707567431032658), (36, 0.6370783746242523), (18, 0.7120620086789131), (53, 1.1319171637296677)]
computing accuracy for after removing block 44 . block score: 0.05002740817144513
removed block 44 current accuracy 0.9446 loss from initial  0.055400000000000005
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.052356. All blocks and scores: [(22, 0.05235625896602869), (23, 0.05238677188754082), (15, 0.052751169074326754), (49, 0.05426743719726801), (21, 0.05441956780850887), (51, 0.056072674691677094), (38, 0.057499917689710855), (20, 0.059606659691780806), (19, 0.06008868897333741), (7, 0.06240570778027177), (24, 0.06262138253077865), (47, 0.06471292581409216), (39, 0.06503739580512047), (52, 0.066870735026896), (37, 0.06910074409097433), (4, 0.07561847940087318), (14, 0.08505101781338453), (6, 0.08827430661767721), (9, 0.09146765619516373), (11, 0.0947643518447876), (2, 0.09582364186644554), (0, 0.10540985874831676), (3, 0.10647993441671133), (17, 0.10923292487859726), (8, 0.11532808281481266), (13, 0.11593470070511103), (1, 0.11673002876341343), (10, 0.14129839651286602), (12, 0.15103670582175255), (16, 0.15286844223737717), (5, 0.19707567803561687), (36, 0.6370783969759941), (18, 0.7120620161294937), (53, 1.2686492651700974)]
computing accuracy for after removing block 22 . block score: 0.05235625896602869
removed block 22 current accuracy 0.9396 loss from initial  0.06040000000000001
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.049225. All blocks and scores: [(23, 0.04922519717365503), (49, 0.05231830617412925), (15, 0.052751168608665466), (51, 0.05375125724822283), (21, 0.05441956780850887), (38, 0.055640953592956066), (24, 0.057236932683736086), (20, 0.05960665922611952), (19, 0.060088689904659986), (47, 0.06084380205720663), (52, 0.06185738183557987), (7, 0.06240571057423949), (39, 0.06359628587961197), (37, 0.06923098396509886), (4, 0.07561848033219576), (14, 0.08505101501941681), (6, 0.08827430754899979), (9, 0.0914676571264863), (11, 0.09476435091346502), (2, 0.09582364279776812), (0, 0.10540986061096191), (3, 0.10647993255406618), (17, 0.10923292487859726), (8, 0.11532808933407068), (13, 0.11593469604849815), (1, 0.11673003062605858), (10, 0.14129840023815632), (12, 0.1510367076843977), (16, 0.15286844037473202), (5, 0.19707567989826202), (36, 0.6169952005147934), (18, 0.7120620012283325), (53, 1.2823104709386826)]
computing accuracy for after removing block 23 . block score: 0.04922519717365503
removed block 23 current accuracy 0.927 loss from initial  0.07299999999999995
since last training loss: 0.038999999999999924 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.051437. All blocks and scores: [(49, 0.051436538342386484), (15, 0.052751169074326754), (51, 0.05312604829668999), (24, 0.05391083098948002), (21, 0.05441956873983145), (38, 0.05513166496530175), (47, 0.05927109019830823), (20, 0.05960666248574853), (52, 0.05994894169270992), (19, 0.0600886894389987), (7, 0.06240570871159434), (39, 0.06470475904643536), (37, 0.07417770009487867), (4, 0.07561848033219576), (14, 0.08505101501941681), (6, 0.08827430848032236), (9, 0.09146765526384115), (11, 0.09476434905081987), (2, 0.09582364559173584), (0, 0.10540986061096191), (3, 0.10647993441671133), (17, 0.10923292674124241), (8, 0.11532808747142553), (13, 0.11593469604849815), (1, 0.11673003062605858), (10, 0.14129839837551117), (12, 0.1510367076843977), (16, 0.15286844596266747), (5, 0.19707568921148777), (36, 0.6268216669559479), (18, 0.7120620161294937), (53, 1.2817481011152267)]
computing accuracy for after removing block 49 . block score: 0.051436538342386484
removed block 49 current accuracy 0.906 loss from initial  0.09399999999999997
since last training loss: 0.05999999999999994 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.052751. All blocks and scores: [(15, 0.052751170471310616), (24, 0.05391082959249616), (21, 0.05441956780850887), (38, 0.055131661240011454), (51, 0.05740966368466616), (47, 0.05927109159529209), (20, 0.05960666062310338), (19, 0.06008868757635355), (7, 0.062405708245933056), (39, 0.06470475904643536), (52, 0.06645002961158752), (37, 0.0741776991635561), (4, 0.07561847846955061), (14, 0.08505101408809423), (6, 0.08827430941164494), (9, 0.0914676571264863), (11, 0.0947643481194973), (2, 0.09582364372909069), (0, 0.10540986247360706), (3, 0.1064799390733242), (17, 0.10923292487859726), (8, 0.11532808933407068), (13, 0.115934694185853), (1, 0.11673003062605858), (10, 0.14129840023815632), (12, 0.1510367076843977), (16, 0.15286844410002232), (5, 0.19707568176090717), (36, 0.6268216818571091), (18, 0.7120620533823967), (53, 1.4872995913028717)]
computing accuracy for after removing block 15 . block score: 0.052751170471310616
removed block 15 current accuracy 0.9042 loss from initial  0.0958
since last training loss: 0.061799999999999966 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.050950. All blocks and scores: [(24, 0.0509495260193944), (21, 0.05120404623448849), (20, 0.05593685805797577), (38, 0.056157623417675495), (51, 0.057308638002723455), (47, 0.05912995571270585), (19, 0.06043632281944156), (7, 0.062405710108578205), (39, 0.06476305983960629), (52, 0.06585926655679941), (37, 0.07486911490559578), (4, 0.07561848312616348), (14, 0.08505101315677166), (6, 0.08827430661767721), (9, 0.09146765805780888), (11, 0.09476434998214245), (2, 0.09582364279776812), (0, 0.10540985781699419), (3, 0.10647993348538876), (17, 0.11024300754070282), (8, 0.11532809026539326), (13, 0.11593469604849815), (1, 0.11673003528267145), (10, 0.14129839465022087), (12, 0.151036711409688), (16, 0.17260551825165749), (5, 0.19707567617297173), (36, 0.6178599074482918), (18, 0.6913115233182907), (53, 1.5131610929965973)]
computing accuracy for after removing block 24 . block score: 0.0509495260193944
removed block 24 current accuracy 0.8698 loss from initial  0.13019999999999998
since last training loss: 0.09619999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 21, with score 0.051204. All blocks and scores: [(21, 0.051204048097133636), (51, 0.05279282573610544), (38, 0.0535423681139946), (47, 0.054914991836994886), (20, 0.05593685945495963), (52, 0.06024490902200341), (19, 0.06043632049113512), (39, 0.06097857281565666), (7, 0.06240570638328791), (37, 0.07093825098127127), (4, 0.07561848126351833), (14, 0.08505101501941681), (6, 0.08827430475503206), (9, 0.09146765433251858), (11, 0.09476434625685215), (2, 0.09582364186644554), (0, 0.10540986061096191), (3, 0.10647993627935648), (17, 0.1102430084720254), (8, 0.11532808560878038), (13, 0.1159346979111433), (1, 0.11673002690076828), (10, 0.14129840210080147), (12, 0.15103670582175255), (16, 0.1726055145263672), (5, 0.19707567617297173), (36, 0.6056888774037361), (18, 0.6913115307688713), (53, 1.516603261232376)]
computing accuracy for after removing block 21 . block score: 0.051204048097133636
removed block 21 current accuracy 0.8352 loss from initial  0.16479999999999995
since last training loss: 0.13079999999999992 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.051360. All blocks and scores: [(51, 0.05135970562696457), (38, 0.051586627028882504), (47, 0.05249046813696623), (20, 0.05593685759231448), (52, 0.056166942697018385), (39, 0.059570031240582466), (19, 0.06043632049113512), (7, 0.062405710108578205), (37, 0.07063677441328764), (4, 0.07561848126351833), (14, 0.08505101781338453), (6, 0.08827430568635464), (9, 0.0914676571264863), (11, 0.0947643518447876), (2, 0.09582364466041327), (0, 0.10540986154228449), (3, 0.10647993627935648), (17, 0.11024300288408995), (8, 0.11532808933407068), (13, 0.11593469697982073), (1, 0.11673003062605858), (10, 0.14129839465022087), (12, 0.15103670582175255), (16, 0.17260551825165749), (5, 0.19707568362355232), (36, 0.5914454609155655), (18, 0.6913115456700325), (53, 1.5513942241668701)]
computing accuracy for after removing block 51 . block score: 0.05135970562696457
removed block 51 current accuracy 0.7758 loss from initial  0.22419999999999995
training start
training epoch 0 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.1]
training epoch 1 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 2 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.1]
training epoch 3 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 6 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 7 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.1]
training epoch 8 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 9 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9488 topk_dict {'top1': 0.9488}
