start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050746843219), (30, 0.01003940065857023), (31, 0.010361599852330983), (34, 0.013312276219949126), (29, 0.01354115444701165), (35, 0.016018462600186467), (26, 0.01603759010322392), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020232456736266613), (46, 0.021044540219008923), (25, 0.021972602931782603), (23, 0.022379535483196378), (41, 0.022826647851616144), (44, 0.02339507848955691), (40, 0.024025026010349393), (45, 0.02429541014134884), (21, 0.024924598168581724), (22, 0.025168768130242825), (48, 0.02534125908277929), (24, 0.02589953737333417), (50, 0.02640997222624719), (42, 0.02667410159483552), (20, 0.026859007542952895), (49, 0.02703716396354139), (47, 0.029306468786671758), (39, 0.031570712802931666), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.03228544816374779), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.04173417342826724), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.05454846424981952), (3, 0.05722427600994706), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980737432837), (1, 0.06676734331995249), (52, 0.0686293737962842), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.43758000060915947), (18, 0.5108212977647781), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.013133948086760938), (29, 0.013541154214181006), (26, 0.016037589637562633), (35, 0.01616928935982287), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020072477171197534), (46, 0.020731384865939617), (25, 0.021972603164613247), (41, 0.022347092861309648), (23, 0.022379535948857665), (44, 0.023235687520354986), (40, 0.023841067450121045), (45, 0.02396554220467806), (48, 0.024917916161939502), (21, 0.024924598401412368), (22, 0.025168768130242825), (50, 0.02584081282839179), (24, 0.02589953667484224), (42, 0.026315323309972882), (49, 0.026655674446374178), (20, 0.026859007077291608), (47, 0.02872879756614566), (39, 0.03131764265708625), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.03802584344521165), (51, 0.04122393950819969), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.054548466578125954), (3, 0.05722427926957607), (13, 0.05892289895564318), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734331995249), (52, 0.06745155062526464), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.43538710474967957), (18, 0.5108213126659393), (53, 0.8222573921084404)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600201576948), (34, 0.012765232822857797), (29, 0.013541154563426971), (35, 0.01599275111220777), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020075131906196475), (46, 0.02084140619263053), (25, 0.021972602233290672), (41, 0.022319767391309142), (23, 0.022379535948857665), (44, 0.023154049878939986), (40, 0.023885683389380574), (45, 0.0240716899279505), (48, 0.024877465795725584), (21, 0.02492459863424301), (22, 0.025168768363073468), (50, 0.025691178860142827), (24, 0.025899537606164813), (42, 0.026123747928068042), (49, 0.026479422813281417), (20, 0.02685900661163032), (47, 0.028693132335320115), (38, 0.03123679617419839), (39, 0.03129529161378741), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.038376690819859505), (51, 0.04111403273418546), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663293346763), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734145730734), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.43640000745654106), (18, 0.5108213052153587), (53, 0.8289348855614662)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387837166897953), (29, 0.013541154330596328), (35, 0.01600809581577778), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020083633484318852), (46, 0.02070444473065436), (25, 0.021972602931782603), (41, 0.022253196919336915), (23, 0.022379535483196378), (44, 0.023267761105671525), (40, 0.024013880640268326), (45, 0.024092992767691612), (48, 0.024665279779583216), (21, 0.02492459863424301), (22, 0.0251687690615654), (50, 0.025459734024479985), (42, 0.025655713165178895), (24, 0.025899536442011595), (49, 0.02628775523044169), (20, 0.026859008008614182), (47, 0.028363423887640238), (38, 0.031047646887600422), (39, 0.03138077235780656), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663526177406), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912681803107), (17, 0.06095684738829732), (0, 0.06300980737432837), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4389924481511116), (18, 0.5108213052153587), (53, 0.8391561508178711)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154330596328), (26, 0.016037590568885207), (35, 0.01605736301280558), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020049349404871464), (46, 0.020552986999973655), (25, 0.02197260269895196), (41, 0.022067484445869923), (23, 0.022379535250365734), (44, 0.022979132598266006), (40, 0.023858347674831748), (45, 0.02412470243871212), (48, 0.024386123288422823), (21, 0.02492459653876722), (50, 0.025042240973562002), (22, 0.025168768595904112), (42, 0.025414507603272796), (49, 0.025842698523774743), (24, 0.02589953737333417), (20, 0.026859007542952895), (47, 0.028050735592842102), (38, 0.031040059169754386), (39, 0.0315008033066988), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.039112848695367575), (51, 0.0402462724596262), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663293346763), (2, 0.05454846378415823), (3, 0.05722427647560835), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300980877131224), (52, 0.06486208783462644), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049013078213), (5, 0.10667387396097183), (36, 0.4381278194487095), (18, 0.5108213126659393), (53, 0.8458427861332893)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.01603759080171585), (35, 0.016653420869261026), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.02050345577299595), (46, 0.0207253226544708), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.0224526294041425), (44, 0.023364474065601826), (48, 0.024290355388075113), (45, 0.024438712280243635), (40, 0.024470558622851968), (21, 0.024924598168581724), (50, 0.025042171822860837), (22, 0.02516876719892025), (49, 0.02587597048841417), (24, 0.025899537838995457), (42, 0.026205406757071614), (20, 0.026859007077291608), (47, 0.02817858220078051), (15, 0.03192339278757572), (38, 0.03208350110799074), (7, 0.032285446766763926), (39, 0.03233744017779827), (19, 0.032628594897687435), (51, 0.03994725737720728), (37, 0.04073968296870589), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846750944853), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.06095684692263603), (0, 0.06300981063395739), (52, 0.06433630362153053), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.45053430646657944), (18, 0.5108213126659393), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470607602968812), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.02004686719737947), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.021972602931782603), (23, 0.02237953501753509), (44, 0.023028337862342596), (48, 0.023771876469254494), (40, 0.023930812953040004), (45, 0.02417866257019341), (50, 0.02439029817469418), (21, 0.024924598401412368), (22, 0.025168768130242825), (42, 0.025188250932842493), (49, 0.02536152908578515), (24, 0.025899537606164813), (20, 0.02685900731012225), (47, 0.027363279834389687), (38, 0.03136561857536435), (15, 0.031923392321914434), (39, 0.03212768491357565), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03893592348322272), (37, 0.04020634386688471), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.047836634796112776), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.05892290407791734), (11, 0.05924912774935365), (17, 0.06095684785395861), (52, 0.062328551430255175), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4444201923906803), (18, 0.5108213126659393), (53, 0.8537911847233772)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500782847404), (27, 0.01888244692236185), (43, 0.019595165504142642), (46, 0.020073580788448453), (41, 0.020961584988981485), (25, 0.021972602466121316), (23, 0.022379535483196378), (44, 0.022814956260845065), (48, 0.023128160974010825), (40, 0.02334519592113793), (50, 0.023756146896630526), (42, 0.023847302654758096), (45, 0.02387388050556183), (21, 0.024924598168581724), (49, 0.02496031578630209), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026855540927499533), (20, 0.02685900661163032), (38, 0.030424014199525118), (39, 0.031514043686911464), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03782488126307726), (37, 0.03936835238710046), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.0589229017496109), (11, 0.059249130077660084), (52, 0.06033282075077295), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4360685534775257), (18, 0.5108212977647781), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555945018306375), (27, 0.01888244692236185), (46, 0.01916008465923369), (41, 0.01942429505288601), (48, 0.021467271726578474), (25, 0.02197260269895196), (44, 0.02202691650018096), (40, 0.022179661318659782), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.02237953618168831), (45, 0.022931481944397092), (49, 0.023708511842414737), (21, 0.02492459793575108), (22, 0.025168768363073468), (47, 0.025829139398410916), (24, 0.025899537606164813), (20, 0.02685900731012225), (38, 0.02895654598250985), (39, 0.029667829163372517), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.036009025294333696), (37, 0.03651238838210702), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846518114209), (52, 0.0561072863638401), (3, 0.05722428159788251), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095685111358762), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.41757646203041077), (18, 0.5108212977647781), (53, 0.91171445697546)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.018882447388023138), (48, 0.020903733791783452), (42, 0.021432004403322935), (40, 0.021832421887665987), (44, 0.021840530447661877), (50, 0.021869863383471966), (25, 0.021972602233290672), (23, 0.022379535250365734), (45, 0.022492847871035337), (49, 0.023123497609049082), (21, 0.024924597470089793), (47, 0.025067138951271772), (22, 0.0251687690615654), (24, 0.025899537140503526), (20, 0.02685900777578354), (38, 0.02811406971886754), (39, 0.029206908075138927), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03545433655381203), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493685968220234), (14, 0.047836633399128914), (2, 0.054548464715480804), (52, 0.054696458391845226), (3, 0.057224275544285774), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9246632382273674)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882446689531207), (46, 0.019302030093967915), (42, 0.021432004403322935), (48, 0.02154484367929399), (40, 0.021832421654835343), (50, 0.021946269320324063), (25, 0.021972602931782603), (23, 0.022379535483196378), (49, 0.02300687017850578), (44, 0.02310851006768644), (45, 0.0235356071498245), (21, 0.024924597702920437), (22, 0.025168768130242825), (47, 0.025820446899160743), (24, 0.025899537140503526), (20, 0.02685900777578354), (38, 0.028114068554714322), (39, 0.0292069090064615), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.035091488156467676), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05332903005182743), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290314659476), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 1 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 3 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.1]
training epoch 4 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 5 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 6 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 7 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 8 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.1]
training epoch 9 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 10 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.019070088863372803), (48, 0.02067816792987287), (50, 0.021344397449865937), (40, 0.021832421654835343), (25, 0.021972602931782603), (42, 0.02198694064281881), (23, 0.022379535483196378), (49, 0.022534747608006), (45, 0.023929917253553867), (44, 0.024054004112258554), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.02604393637739122), (20, 0.026859007077291608), (38, 0.028114069253206253), (39, 0.0292069090064615), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03379447944462299), (37, 0.03597764018923044), (9, 0.04340188065543771), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.04783663293346763), (52, 0.05047609331086278), (2, 0.05454846424981952), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4135979078710079), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.01866446272470057), (48, 0.01998970750719309), (50, 0.020775062032043934), (40, 0.021085953805595636), (42, 0.0213696479331702), (49, 0.021910030161961913), (25, 0.02197260269895196), (23, 0.022379535250365734), (44, 0.02323931222781539), (45, 0.023585307877510786), (21, 0.02492459793575108), (47, 0.025076948339119554), (22, 0.025168768595904112), (24, 0.025899536442011595), (20, 0.026859006378799677), (38, 0.027183360420167446), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.0328142608050257), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.048523630015552044), (2, 0.054548464715480804), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912774935365), (17, 0.060956851579248905), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.01866446272470057
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.020831161178648472), (40, 0.021085953107103705), (42, 0.021369647700339556), (25, 0.021972601767629385), (23, 0.022379535250365734), (49, 0.0225369893014431), (44, 0.023239312460646033), (45, 0.023585308576002717), (21, 0.024924597702920437), (22, 0.025168768363073468), (24, 0.025899537140503526), (47, 0.026583049912005663), (20, 0.026859008008614182), (38, 0.02718336135149002), (39, 0.02858075895346701), (15, 0.03192339185625315), (7, 0.03228544816374779), (19, 0.0326285962946713), (51, 0.03285081218928099), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368270859122), (14, 0.0478366338647902), (52, 0.04812479857355356), (2, 0.05454846518114209), (3, 0.057224280666559935), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953572764993), (42, 0.021369647700339556), (25, 0.021972602931782603), (23, 0.02237953571602702), (50, 0.022470062598586082), (44, 0.023239311994984746), (45, 0.02358530811034143), (21, 0.024924597702920437), (22, 0.025168768595904112), (49, 0.02523410110734403), (24, 0.025899537606164813), (47, 0.02658304967917502), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.032969210762530565), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.050890452694147825), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.05892289988696575), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065234139561653), (18, 0.5108213126659393), (53, 1.2663908898830414)]
computing accuracy for after removing block 40 . block score: 0.021085953572764993
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.02128476626239717), (25, 0.021972602466121316), (23, 0.022379535250365734), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.02450086921453476), (21, 0.024924596305936575), (22, 0.025168768595904112), (24, 0.0258995380718261), (47, 0.02651969902217388), (20, 0.026859006844460964), (38, 0.02718336065299809), (39, 0.028580758487805724), (15, 0.03192339185625315), (51, 0.03222084930166602), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.04885757341980934), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.3718616366386414)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.02120265830308199), (25, 0.021972602931782603), (23, 0.02237953501753509), (45, 0.023761966731399298), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924598401412368), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026220474392175674), (20, 0.02685900777578354), (38, 0.027183361118659377), (39, 0.028580759186297655), (51, 0.03127906774170697), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340188158676028), (52, 0.046101709827780724), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.02120265830308199
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.023761965800076723), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168767664581537), (24, 0.025899537606164813), (47, 0.026220474625006318), (20, 0.02685900731012225), (38, 0.02718336065299809), (39, 0.028580758487805724), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.033443022053688765), (37, 0.035420244093984365), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05265179416164756), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095684692263603), (0, 0.0630098101682961), (1, 0.06676734052598476), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.6287680864334106)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535250365734), (45, 0.0233820837456733), (49, 0.023860316025093198), (44, 0.023948067100718617), (21, 0.024924596771597862), (22, 0.025168768828734756), (47, 0.02536190371029079), (24, 0.02589953737333417), (38, 0.026533206226304173), (20, 0.026859007542952895), (39, 0.028472805861383677), (15, 0.031923392321914434), (7, 0.03228544630110264), (51, 0.03247324749827385), (19, 0.03262859536334872), (37, 0.034854767844080925), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.05042571108788252), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.3996613584458828), (18, 0.5108213126659393), (53, 1.631172239780426)]
computing accuracy for after removing block 23 . block score: 0.022379535250365734
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.02356328465975821), (45, 0.023582331370562315), (49, 0.02370715793222189), (24, 0.024551384150981903), (47, 0.02468883036635816), (21, 0.024924598168581724), (22, 0.025168768595904112), (38, 0.026409979909658432), (20, 0.026859007077291608), (39, 0.02843296923674643), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.032353680580854416), (19, 0.03262859582901001), (37, 0.03590833768248558), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.0488563678227365), (2, 0.05454846518114209), (3, 0.05722428020089865), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.40237870439887047), (18, 0.5108212828636169), (53, 1.617948278784752)]
computing accuracy for after removing block 44 . block score: 0.02356328465975821
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.02324675186537206), (49, 0.023541763424873352), (24, 0.02455138461664319), (21, 0.024924598168581724), (22, 0.025168768595904112), (47, 0.025985258864238858), (38, 0.026409979909658432), (20, 0.026859007542952895), (39, 0.028432969003915787), (15, 0.031923392321914434), (51, 0.0320491255261004), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.035908338613808155), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.048162917140871286), (2, 0.05454846750944853), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.05924913100898266), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.40237871557474136), (18, 0.5108212903141975), (53, 1.7482215464115143)]
computing accuracy for after removing block 45 . block score: 0.02324675186537206
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.0241570514626801), (24, 0.024551384150981903), (21, 0.024924597702920437), (22, 0.025168768130242825), (38, 0.026409980142489076), (20, 0.026859007077291608), (47, 0.02742941165342927), (39, 0.028432969003915787), (51, 0.03189300140365958), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03590833907946944), (9, 0.04340188065543771), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04907965241000056), (2, 0.054548466578125954), (3, 0.05722427926957607), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448399528861), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.40237870812416077), (18, 0.5108212977647781), (53, 1.8955670148134232)]
computing accuracy for after removing block 49 . block score: 0.0241570514626801
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8054 topk_dict {'top1': 0.8054} is_best True lr [0.1]
training epoch 1 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.1]
training epoch 2 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best True lr [0.1]
training epoch 3 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 4 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 5 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 6 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 7 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 8 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 9 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 10 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.955400)
finished training. finished 50 epochs. accuracy 0.9554 topk_dict {'top1': 0.9554}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.056460. All blocks and scores: [(15, 0.05645989254117012), (21, 0.06185281928628683), (19, 0.0629944414831698), (7, 0.06315270531922579), (20, 0.06528796907514334), (22, 0.06789495702832937), (51, 0.06856702640652657), (38, 0.06886184774339199), (52, 0.07191368471831083), (39, 0.07279932498931885), (37, 0.07318480126559734), (24, 0.07347569894045591), (47, 0.07351732067763805), (4, 0.08131341729313135), (6, 0.08288854826241732), (9, 0.08832289092242718), (11, 0.09788009244948626), (2, 0.09873860515654087), (14, 0.10534832626581192), (13, 0.10677395109087229), (17, 0.1083862790837884), (3, 0.1124686747789383), (0, 0.11390045285224915), (8, 0.11432314105331898), (1, 0.12215352710336447), (10, 0.14246115274727345), (12, 0.15018633008003235), (16, 0.15691730752587318), (5, 0.20945925824344158), (36, 0.5485706105828285), (18, 0.6723198816180229), (53, 1.0461939573287964)]
computing accuracy for after removing block 15 . block score: 0.05645989254117012
removed block 15 current accuracy 0.9536 loss from initial  0.0464
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.059257. All blocks and scores: [(21, 0.05925748450681567), (20, 0.062366316094994545), (7, 0.06315270252525806), (19, 0.06423048675060272), (22, 0.06426126509904861), (24, 0.06837927177548409), (38, 0.06859541684389114), (51, 0.06923058070242405), (37, 0.07201530691236258), (52, 0.0721476636826992), (39, 0.0735953925177455), (47, 0.07465038355439901), (4, 0.08131341729313135), (6, 0.08288854919373989), (9, 0.08832289278507233), (11, 0.0978800905868411), (2, 0.09873860329389572), (14, 0.10534832440316677), (13, 0.10677395109087229), (3, 0.11246867291629314), (0, 0.11390044912695885), (8, 0.11432314105331898), (17, 0.11557561997324228), (1, 0.12215352710336447), (10, 0.14246114529669285), (12, 0.1501863282173872), (16, 0.17593392170965672), (5, 0.20945925638079643), (36, 0.5351522341370583), (18, 0.6600660160183907), (53, 1.064841851592064)]
computing accuracy for after removing block 21 . block score: 0.05925748450681567
removed block 21 current accuracy 0.9486 loss from initial  0.0514
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.058359. All blocks and scores: [(22, 0.058358623180538416), (24, 0.058640916366130114), (20, 0.06236631562933326), (7, 0.06315270252525806), (19, 0.06423048675060272), (38, 0.06570467445999384), (52, 0.06689264066517353), (51, 0.06731152534484863), (47, 0.07114033587276936), (37, 0.07124363351613283), (39, 0.07325242459774017), (4, 0.08131341636180878), (6, 0.08288855198770761), (9, 0.0883228937163949), (11, 0.0978800905868411), (2, 0.09873860608786345), (14, 0.1053483234718442), (13, 0.10677395015954971), (3, 0.11246867571026087), (0, 0.1139004547148943), (8, 0.11432313919067383), (17, 0.11557561904191971), (1, 0.12215352617204189), (10, 0.14246115274727345), (12, 0.15018633008003235), (16, 0.17593391984701157), (5, 0.20945925824344158), (36, 0.5142537727952003), (18, 0.6600659936666489), (53, 1.0615763813257217)]
computing accuracy for after removing block 22 . block score: 0.058358623180538416
removed block 22 current accuracy 0.9322 loss from initial  0.06779999999999997
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.054109. All blocks and scores: [(24, 0.054109254851937294), (20, 0.06236631562933326), (7, 0.06315270345658064), (52, 0.06403317488729954), (19, 0.06423048581928015), (38, 0.06518545094877481), (51, 0.06535605806857347), (47, 0.06716480385512114), (39, 0.0735413059592247), (37, 0.07771563809365034), (4, 0.08131341636180878), (6, 0.08288854639977217), (9, 0.08832289185374975), (11, 0.09788008965551853), (2, 0.09873860236257315), (14, 0.10534832533448935), (13, 0.10677395574748516), (3, 0.1124686747789383), (0, 0.1139004472643137), (8, 0.1143231438472867), (17, 0.11557562183588743), (1, 0.12215352710336447), (10, 0.1424611508846283), (12, 0.1501863282173872), (16, 0.17593391984701157), (5, 0.20945925451815128), (36, 0.5284690037369728), (18, 0.6600660011172295), (53, 1.0439335405826569)]
computing accuracy for after removing block 24 . block score: 0.054109254851937294
removed block 24 current accuracy 0.914 loss from initial  0.08599999999999997
since last training loss: 0.04139999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.056957. All blocks and scores: [(52, 0.05695655941963196), (51, 0.06004899274557829), (47, 0.060486847534775734), (38, 0.06066783890128136), (20, 0.06236631469801068), (7, 0.06315270531922579), (19, 0.06423048675060272), (39, 0.06975164264440536), (37, 0.07305072247982025), (4, 0.08131341636180878), (6, 0.08288854919373989), (9, 0.08832289185374975), (11, 0.09788008965551853), (2, 0.09873860236257315), (14, 0.10534832626581192), (13, 0.10677395481616259), (3, 0.11246867850422859), (0, 0.11390044912695885), (8, 0.11432314105331898), (17, 0.11557561997324228), (1, 0.12215352617204189), (10, 0.14246114902198315), (12, 0.15018632635474205), (16, 0.17593392170965672), (5, 0.20945925638079643), (36, 0.5120010077953339), (18, 0.6600660011172295), (53, 1.0105951502919197)]
computing accuracy for after removing block 52 . block score: 0.05695655941963196
removed block 52 current accuracy 0.8874 loss from initial  0.11260000000000003
since last training loss: 0.06800000000000006 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.060049. All blocks and scores: [(51, 0.06004899460822344), (47, 0.060486845672130585), (38, 0.060667839366942644), (20, 0.06236631516367197), (7, 0.06315270531922579), (19, 0.06423048861324787), (39, 0.06975164357572794), (37, 0.07305072154849768), (4, 0.0813134154304862), (6, 0.08288854826241732), (9, 0.08832289185374975), (11, 0.09788009244948626), (2, 0.09873860236257315), (14, 0.10534832626581192), (13, 0.10677395667880774), (3, 0.11246867943555117), (0, 0.113900450989604), (8, 0.1143231438472867), (17, 0.11557562369853258), (1, 0.12215352896600962), (10, 0.1424611508846283), (12, 0.1501863282173872), (16, 0.175933925434947), (5, 0.20945925451815128), (36, 0.5120010003447533), (18, 0.6600660160183907), (53, 1.1172255873680115)]
computing accuracy for after removing block 51 . block score: 0.06004899460822344
removed block 51 current accuracy 0.8096 loss from initial  0.1904
since last training loss: 0.14580000000000004 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 47, with score 0.060487. All blocks and scores: [(47, 0.06048684613779187), (38, 0.06066783796995878), (20, 0.06236631562933326), (7, 0.06315270252525806), (19, 0.06423048675060272), (39, 0.06975164264440536), (37, 0.07305072154849768), (4, 0.08131341729313135), (6, 0.08288855198770761), (9, 0.08832289092242718), (11, 0.09788008965551853), (2, 0.09873860701918602), (14, 0.10534832440316677), (13, 0.10677395295351744), (3, 0.1124686747789383), (0, 0.11390045192092657), (8, 0.11432314105331898), (17, 0.11557561624795198), (1, 0.12215352337807417), (10, 0.14246115274727345), (12, 0.15018633008003235), (16, 0.17593391612172127), (5, 0.20945924893021584), (36, 0.5120010077953339), (18, 0.6600660085678101), (53, 1.1541427224874496)]
computing accuracy for after removing block 47 . block score: 0.06048684613779187
removed block 47 current accuracy 0.7346 loss from initial  0.26539999999999997
since last training loss: 0.2208 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.060668. All blocks and scores: [(38, 0.060667839366942644), (20, 0.06236631330102682), (7, 0.06315270345658064), (19, 0.06423048954457045), (39, 0.06975164357572794), (37, 0.0730507206171751), (4, 0.08131341636180878), (6, 0.08288855105638504), (9, 0.0883228937163949), (11, 0.09788008965551853), (2, 0.09873860515654087), (14, 0.10534832533448935), (13, 0.10677395854145288), (3, 0.11246867291629314), (0, 0.11390044819563627), (8, 0.11432314198464155), (17, 0.11557561997324228), (1, 0.12215352617204189), (10, 0.1424611508846283), (12, 0.1501863282173872), (16, 0.17593391984701157), (5, 0.20945925079286098), (36, 0.5120010152459145), (18, 0.6600660011172295), (53, 1.2333662509918213)]
computing accuracy for after removing block 38 . block score: 0.060667839366942644
removed block 38 current accuracy 0.6964 loss from initial  0.3036
since last training loss: 0.259 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 20, with score 0.062366. All blocks and scores: [(20, 0.062366314232349396), (7, 0.06315270531922579), (19, 0.0642304876819253), (37, 0.07305072341114283), (39, 0.07977037597447634), (4, 0.08131341449916363), (6, 0.08288855198770761), (9, 0.0883228899911046), (11, 0.09788008965551853), (2, 0.09873860143125057), (14, 0.10534832533448935), (13, 0.10677395295351744), (3, 0.11246867384761572), (0, 0.11390044912695885), (8, 0.11432314198464155), (17, 0.11557561997324228), (1, 0.12215352710336447), (10, 0.1424611508846283), (12, 0.15018633008003235), (16, 0.17593392170965672), (5, 0.20945925451815128), (36, 0.5120010077953339), (18, 0.6600660085678101), (53, 1.224345251917839)]
computing accuracy for after removing block 20 . block score: 0.062366314232349396
removed block 20 current accuracy 0.6622 loss from initial  0.3378
since last training loss: 0.2932 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.063153. All blocks and scores: [(7, 0.06315270252525806), (19, 0.06423048861324787), (37, 0.0783785404637456), (4, 0.08131341356784105), (39, 0.08165399357676506), (6, 0.08288855105638504), (9, 0.08832289092242718), (11, 0.0978800905868411), (2, 0.09873860236257315), (14, 0.1053483234718442), (13, 0.10677395295351744), (3, 0.11246867664158344), (0, 0.11390044819563627), (8, 0.11432313919067383), (17, 0.11557561811059713), (1, 0.12215352989733219), (10, 0.14246114902198315), (12, 0.1501863282173872), (16, 0.17593391984701157), (5, 0.20945925638079643), (36, 0.5284627974033356), (18, 0.6600659936666489), (53, 1.1703173071146011)]
computing accuracy for after removing block 7 . block score: 0.06315270252525806
removed block 7 current accuracy 0.6354 loss from initial  0.36460000000000004
since last training loss: 0.32000000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.062646. All blocks and scores: [(19, 0.06264630006626248), (37, 0.07300811819732189), (39, 0.08045395836234093), (4, 0.08131341449916363), (6, 0.08288855012506247), (9, 0.09016995038837194), (11, 0.09256385825574398), (13, 0.09545442461967468), (14, 0.09822962433099747), (17, 0.09826245438307524), (2, 0.09873860143125057), (3, 0.11246867943555117), (0, 0.11390045285224915), (8, 0.1164778359234333), (1, 0.12215353082865477), (12, 0.13677245192229748), (10, 0.1473955474793911), (16, 0.1591093074530363), (5, 0.20945925451815128), (36, 0.5050705596804619), (18, 0.6410103961825371), (53, 1.125456154346466)]
computing accuracy for after removing block 19 . block score: 0.06264630006626248
removed block 19 current accuracy 0.5916 loss from initial  0.4084
training start
training epoch 0 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best True lr [0.1]
training epoch 1 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best True lr [0.1]
training epoch 2 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.1]
training epoch 3 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best True lr [0.1]
training epoch 4 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 5 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 6 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 7 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 8 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.1]
training epoch 9 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 10 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.105676. All blocks and scores: [(37, 0.10567581653594971), (4, 0.10787835624068975), (0, 0.11755404062569141), (2, 0.11885326262563467), (39, 0.1280952114611864), (9, 0.12912515364587307), (6, 0.13173459097743034), (3, 0.14099851436913013), (11, 0.1466477196663618), (1, 0.15746896713972092), (14, 0.16023088619112968), (17, 0.16161900758743286), (13, 0.17016997747123241), (8, 0.17920814454555511), (10, 0.19752746634185314), (12, 0.21057864278554916), (5, 0.2523380480706692), (16, 0.2612832225859165), (36, 0.4717247933149338), (18, 0.6081122905015945), (53, 1.34146149456501)]
computing accuracy for after removing block 37 . block score: 0.10567581653594971
removed block 37 current accuracy 0.884 loss from initial  0.11599999999999999
since last training loss: 0.052000000000000046 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.107878. All blocks and scores: [(4, 0.10787835251539946), (0, 0.11755404248833656), (2, 0.11885326448827982), (9, 0.12912515178322792), (6, 0.1317345891147852), (3, 0.14099851623177528), (11, 0.14664772152900696), (1, 0.15746896341443062), (14, 0.16023088805377483), (17, 0.16161901503801346), (39, 0.16938094794750214), (13, 0.17016997747123241), (8, 0.1792081482708454), (10, 0.1975274682044983), (12, 0.21057865023612976), (5, 0.252338046208024), (16, 0.2612832151353359), (36, 0.4717247821390629), (18, 0.6081122756004333), (53, 1.3357345014810562)]
computing accuracy for after removing block 4 . block score: 0.10787835251539946
removed block 4 current accuracy 0.8844 loss from initial  0.11560000000000004
since last training loss: 0.05160000000000009 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 0, with score 0.117554. All blocks and scores: [(0, 0.11755403876304626), (2, 0.11885326448827982), (9, 0.13222466222941875), (11, 0.1361517272889614), (3, 0.14099851995706558), (17, 0.152810575440526), (14, 0.1539937611669302), (6, 0.15572495944797993), (1, 0.15746896527707577), (13, 0.16127807088196278), (39, 0.16730610467493534), (8, 0.17974457517266273), (10, 0.18925393745303154), (12, 0.2016618698835373), (16, 0.23450834676623344), (5, 0.28257647156715393), (36, 0.4662921838462353), (18, 0.6023555770516396), (53, 1.2935768812894821)]
computing accuracy for after removing block 0 . block score: 0.11755403876304626
removed block 0 current accuracy 0.8592 loss from initial  0.14080000000000004
since last training loss: 0.07680000000000009 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 9, with score 0.120478. All blocks and scores: [(9, 0.12047762051224709), (11, 0.12345542572438717), (3, 0.12385144550353289), (2, 0.127778647467494), (17, 0.14761675894260406), (14, 0.14968005567789078), (13, 0.15498710796236992), (6, 0.15759180672466755), (1, 0.15941421501338482), (39, 0.1619238741695881), (10, 0.17084337957203388), (8, 0.19329465180635452), (12, 0.20601823553442955), (16, 0.22262274287641048), (5, 0.2622280940413475), (36, 0.44883139058947563), (18, 0.5773046985268593), (53, 1.231098249554634)]
computing accuracy for after removing block 9 . block score: 0.12047762051224709
removed block 9 current accuracy 0.8302 loss from initial  0.16979999999999995
since last training loss: 0.1058 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.112880. All blocks and scores: [(11, 0.11288036778569221), (3, 0.12385144364088774), (2, 0.1277786437422037), (17, 0.1303129717707634), (14, 0.1341673769056797), (13, 0.14339571818709373), (39, 0.14846104010939598), (6, 0.15759181044995785), (10, 0.15873970836400986), (1, 0.15941421315073967), (12, 0.16465879417955875), (16, 0.18852517381310463), (8, 0.19329464435577393), (5, 0.2622280977666378), (36, 0.4115436524152756), (18, 0.5502094849944115), (53, 1.0657699704170227)]
computing accuracy for after removing block 11 . block score: 0.11288036778569221
removed block 11 current accuracy 0.7792 loss from initial  0.2208
since last training loss: 0.15680000000000005 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.122392. All blocks and scores: [(17, 0.12239199411123991), (3, 0.12385144550353289), (14, 0.12579964566975832), (2, 0.12777864933013916), (13, 0.13571317121386528), (39, 0.15487537905573845), (12, 0.15558742359280586), (6, 0.15759181044995785), (10, 0.158739710226655), (1, 0.15941421501338482), (16, 0.16952898167073727), (8, 0.19329464994370937), (5, 0.2622280903160572), (36, 0.41779040917754173), (18, 0.5538442060351372), (53, 1.0502652898430824)]
computing accuracy for after removing block 17 . block score: 0.12239199411123991
removed block 17 current accuracy 0.7512 loss from initial  0.24880000000000002
since last training loss: 0.18480000000000008 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 3, with score 0.123851. All blocks and scores: [(3, 0.12385144829750061), (14, 0.12579964194446802), (2, 0.127778647467494), (13, 0.13571317493915558), (39, 0.14378102868795395), (12, 0.15558742359280586), (6, 0.1575918085873127), (10, 0.15873970836400986), (1, 0.15941421501338482), (16, 0.16952898167073727), (8, 0.19329464621841908), (5, 0.2622280828654766), (36, 0.38559465482831), (18, 0.5267966315150261), (53, 0.9301805347204208)]
computing accuracy for after removing block 3 . block score: 0.12385144829750061
removed block 3 current accuracy 0.6376 loss from initial  0.36240000000000006
since last training loss: 0.2984000000000001 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 14, with score 0.118449. All blocks and scores: [(14, 0.11844862811267376), (2, 0.1277786437422037), (13, 0.1306113377213478), (39, 0.13425755128264427), (16, 0.14265013672411442), (12, 0.14387944899499416), (1, 0.15941421501338482), (10, 0.16344353184103966), (6, 0.1769592147320509), (8, 0.1988415066152811), (5, 0.3030531033873558), (36, 0.3624543957412243), (18, 0.49585172161459923), (53, 0.8102491348981857)]
computing accuracy for after removing block 14 . block score: 0.11844862811267376
removed block 14 current accuracy 0.5224 loss from initial  0.4776
since last training loss: 0.4136000000000001 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 2, with score 0.127779. All blocks and scores: [(2, 0.127778647467494), (13, 0.13061133585870266), (39, 0.13752276450395584), (12, 0.14387944713234901), (1, 0.15941421128809452), (16, 0.16130854561924934), (10, 0.16344352811574936), (6, 0.17695922031998634), (8, 0.1988415140658617), (5, 0.3030530922114849), (36, 0.3637588210403919), (18, 0.48105600476264954), (53, 0.8346782848238945)]
computing accuracy for after removing block 2 . block score: 0.127778647467494
removed block 2 current accuracy 0.3638 loss from initial  0.6362
since last training loss: 0.5722 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.113934. All blocks and scores: [(13, 0.11393400747328997), (12, 0.1249126298353076), (39, 0.13343912735581398), (16, 0.14078973606228828), (10, 0.15436017699539661), (1, 0.15941421687602997), (6, 0.16323805041611195), (8, 0.19530314020812511), (5, 0.3074609600007534), (36, 0.33813049644231796), (18, 0.43565790355205536), (53, 0.6436551883816719)]
computing accuracy for after removing block 13 . block score: 0.11393400747328997
removed block 13 current accuracy 0.2828 loss from initial  0.7172000000000001
since last training loss: 0.6532 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 12, with score 0.124913. All blocks and scores: [(12, 0.1249126335605979), (39, 0.13398989848792553), (16, 0.14971233531832695), (10, 0.15436017513275146), (1, 0.15941421873867512), (6, 0.16323804669082165), (8, 0.19530313462018967), (5, 0.3074609637260437), (36, 0.3265303894877434), (18, 0.4440701901912689), (53, 0.5783742591738701)]
computing accuracy for after removing block 12 . block score: 0.1249126335605979
removed block 12 current accuracy 0.1766 loss from initial  0.8234
since last training loss: 0.7594000000000001 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 39, with score 0.147706. All blocks and scores: [(39, 0.14770598523318768), (16, 0.15026233717799187), (10, 0.15436017513275146), (1, 0.15941421687602997), (6, 0.16323804669082165), (8, 0.19530314020812511), (5, 0.3074609600007534), (36, 0.3527001179754734), (18, 0.4595004729926586), (53, 0.7396983355283737)]
computing accuracy for after removing block 39 . block score: 0.14770598523318768
removed block 39 current accuracy 0.1364 loss from initial  0.8636
training start
training epoch 0 val accuracy 0.7984 topk_dict {'top1': 0.7984} is_best True lr [0.1]
training epoch 1 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.1]
training epoch 2 val accuracy 0.7924 topk_dict {'top1': 0.7924} is_best False lr [0.1]
training epoch 3 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.1]
training epoch 4 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.1]
training epoch 5 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 6 val accuracy 0.793 topk_dict {'top1': 0.793} is_best False lr [0.1]
training epoch 7 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best False lr [0.1]
training epoch 8 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 9 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.1]
training epoch 10 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.904400)
finished training. finished 50 epochs. accuracy 0.9044 topk_dict {'top1': 0.9044}
