start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996322590858), (32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.013312275987118483), (29, 0.013541154330596328), (35, 0.016018462600186467), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020232457434758544), (46, 0.021044540451839566), (25, 0.021972603164613247), (23, 0.02237953571602702), (41, 0.0228266476187855), (44, 0.023395078722387552), (40, 0.024025025311857462), (45, 0.02429541014134884), (21, 0.024924598168581724), (22, 0.025168768363073468), (48, 0.02534125908277929), (24, 0.025899537606164813), (50, 0.026409971993416548), (42, 0.026674099499359727), (20, 0.026859007077291608), (49, 0.027037165127694607), (47, 0.029306469950824976), (39, 0.03157071233727038), (38, 0.03163787163794041), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.037960262037813663), (51, 0.041734172496944666), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.060956846456974745), (0, 0.06300980737432837), (1, 0.06676734331995249), (52, 0.06862937659025192), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049665004015), (5, 0.10667387023568153), (36, 0.43757999688386917), (18, 0.5108212828636169), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996322590858
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013133947155438364), (29, 0.013541154679842293), (26, 0.016037590336054564), (35, 0.016169289825484157), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020072476705536246), (46, 0.020731385797262192), (25, 0.021972602931782603), (41, 0.022347092628479004), (23, 0.022379535483196378), (44, 0.0232356870546937), (40, 0.023841066751629114), (45, 0.023965542670339346), (48, 0.024917916161939502), (21, 0.02492459723725915), (22, 0.025168768595904112), (50, 0.025840813294053078), (24, 0.025899537606164813), (42, 0.02631532377563417), (49, 0.026655674213543534), (20, 0.02685900661163032), (47, 0.02872879756614566), (39, 0.031317642191424966), (38, 0.03138036374002695), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.03262859582901001), (37, 0.038025843910872936), (51, 0.04122393950819969), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.06745154969394207), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.43538711592555046), (18, 0.5108213126659393), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940124064684), (31, 0.010361600085161626), (34, 0.01276523305568844), (29, 0.013541154214181006), (35, 0.015992750646546483), (26, 0.016037590568885207), (28, 0.017728675855323672), (27, 0.019127048319205642), (43, 0.02007513213902712), (46, 0.020841405959799886), (25, 0.02197260339744389), (41, 0.02231976669281721), (23, 0.022379535483196378), (44, 0.023154050577431917), (40, 0.023885683389380574), (45, 0.02407168922945857), (48, 0.02487746556289494), (21, 0.024924597470089793), (22, 0.025168768130242825), (50, 0.02569117839448154), (24, 0.025899536907672882), (42, 0.02612374722957611), (49, 0.0264794216491282), (20, 0.026859007077291608), (47, 0.02869313140399754), (38, 0.03123679617419839), (39, 0.03129529161378741), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03837669128552079), (51, 0.04111403226852417), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.047836634796112776), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.0592491258867085), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734518259764), (52, 0.06700456235557795), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43640001490712166), (18, 0.5108213052153587), (53, 0.8289348781108856)]
computing accuracy for after removing block 30 . block score: 0.01003940124064684
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.012387837166897953), (29, 0.013541154679842293), (35, 0.016008096281439066), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.02008363325148821), (46, 0.02070444426499307), (25, 0.021972602233290672), (41, 0.022253196919336915), (23, 0.02237953501753509), (44, 0.023267761571332812), (40, 0.024013880407437682), (45, 0.024092992767691612), (48, 0.024665281176567078), (21, 0.024924598401412368), (22, 0.02516876789741218), (50, 0.025459734722971916), (42, 0.025655713165178895), (24, 0.025899537140503526), (49, 0.02628775709308684), (20, 0.026859007542952895), (47, 0.028363423887640238), (38, 0.031047646654769778), (39, 0.031380771892145276), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.054548466578125954), (3, 0.05722428020089865), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300981063395739), (52, 0.06586316134780645), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4389924630522728), (18, 0.5108213052153587), (53, 0.8391561582684517)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.01248961966484785), (29, 0.013541154214181006), (26, 0.016037590568885207), (35, 0.016057363245636225), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020049349637702107), (46, 0.020552987698465586), (25, 0.021972602466121316), (41, 0.022067485144361854), (23, 0.022379535250365734), (44, 0.02297913283109665), (40, 0.02385834790766239), (45, 0.024124702671542764), (48, 0.024386123288422823), (21, 0.024924598168581724), (50, 0.02504224143922329), (22, 0.025168768130242825), (42, 0.025414508301764727), (49, 0.02584269898943603), (24, 0.025899537838995457), (20, 0.026859007542952895), (47, 0.028050734428688884), (38, 0.031040058471262455), (39, 0.031500802375376225), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.03911284822970629), (51, 0.0402462724596262), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.05454846378415823), (3, 0.05722427926957607), (13, 0.058922900818288326), (11, 0.05924912681803107), (17, 0.060956848319619894), (0, 0.06300981156527996), (52, 0.06486208783462644), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4381278418004513), (18, 0.5108212903141975), (53, 0.8458428010344505)]
computing accuracy for after removing block 34 . block score: 0.01248961966484785
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154679842293), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.017728674924001098), (27, 0.019127047853544354), (43, 0.02050345577299595), (46, 0.02072532312013209), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.022452629171311855), (44, 0.02336447429843247), (48, 0.024290354922413826), (45, 0.024438712745904922), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.025042172288522124), (22, 0.025168767664581537), (49, 0.02587596932426095), (24, 0.025899537140503526), (42, 0.026205406989902258), (20, 0.026859006844460964), (47, 0.028178583132103086), (15, 0.031923392321914434), (38, 0.032083502039313316), (7, 0.032285446766763926), (39, 0.032337441109120846), (19, 0.032628594897687435), (51, 0.039947257842868567), (37, 0.04073968157172203), (9, 0.043401881121098995), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846704378724), (3, 0.05722427647560835), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300980970263481), (52, 0.06433630175888538), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.45053430274128914), (18, 0.5108212903141975), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154679842293
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037591034546494), (35, 0.016470608301460743), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02004686719737947), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.022379535948857665), (44, 0.023028337629511952), (48, 0.02377187623642385), (40, 0.023930812953040004), (45, 0.024178663035854697), (50, 0.024390297941863537), (21, 0.02492459793575108), (22, 0.025168768130242825), (42, 0.02518825070001185), (49, 0.02536152978427708), (24, 0.02589953667484224), (20, 0.02685900661163032), (47, 0.02736328006722033), (38, 0.031365619506686926), (15, 0.03192339139059186), (39, 0.03212768444791436), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.03893592394888401), (37, 0.040206342469900846), (9, 0.04340188065543771), (6, 0.046609030570834875), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684785395861), (52, 0.0623285504989326), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.1066738748922944), (36, 0.4444201998412609), (18, 0.5108213126659393), (53, 0.8537911921739578)]
computing accuracy for after removing block 26 . block score: 0.016037591034546494
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365563735366), (28, 0.017088500317186117), (27, 0.018882446456700563), (43, 0.019595165271312), (46, 0.020073581021279097), (41, 0.02096158475615084), (25, 0.02197260200046003), (23, 0.022379535948857665), (44, 0.02281495649367571), (48, 0.023128160974010825), (40, 0.023345195688307285), (50, 0.02375614712946117), (42, 0.023847303120419383), (45, 0.02387388003990054), (21, 0.02492459793575108), (49, 0.02496031578630209), (22, 0.02516876789741218), (24, 0.02589953667484224), (47, 0.026855542790144682), (20, 0.026859008008614182), (38, 0.030424013966694474), (39, 0.03151404415257275), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.058922899421304464), (11, 0.059249126352369785), (52, 0.06033282075077295), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4360685460269451), (18, 0.5108213052153587), (53, 0.8749377131462097)]
computing accuracy for after removing block 35 . block score: 0.015597365563735366
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945483967662), (27, 0.018882446456700563), (46, 0.019160084892064333), (41, 0.019424294820055366), (48, 0.021467271959409118), (25, 0.021972602466121316), (44, 0.02202691650018096), (40, 0.022179660387337208), (42, 0.02220643009059131), (50, 0.022256129421293736), (23, 0.022379535483196378), (45, 0.022931481478735805), (49, 0.02370851277373731), (21, 0.024924598168581724), (22, 0.025168768828734756), (47, 0.025829139398410916), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.028956546913832426), (39, 0.029667828232049942), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03600902622565627), (37, 0.03651238698512316), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.047836633399128914), (2, 0.054548464715480804), (52, 0.05610728682950139), (3, 0.0572242783382535), (13, 0.05892290361225605), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4175764434039593), (18, 0.5108213052153587), (53, 0.9117145091295242)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 1 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 2 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 3 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 6 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 7 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.1]
training epoch 8 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.1]
training epoch 9 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 10 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.01865610247477889), (41, 0.018849018728360534), (27, 0.018882447155192494), (48, 0.020903734024614096), (42, 0.021432003937661648), (40, 0.021832421654835343), (44, 0.021840530447661877), (50, 0.02186986431479454), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.02249284810386598), (49, 0.02312349807471037), (21, 0.02492459793575108), (47, 0.02506713941693306), (22, 0.0251687690615654), (24, 0.025899537838995457), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.03545433562248945), (37, 0.03597763925790787), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846564680338), (52, 0.05469645792618394), (3, 0.05722427647560835), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9246632605791092)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.01888244692236185), (46, 0.019302030559629202), (42, 0.021432004403322935), (48, 0.021544843912124634), (40, 0.021832421887665987), (50, 0.02194626908749342), (25, 0.021972602233290672), (23, 0.022379535483196378), (49, 0.02300687017850578), (44, 0.023108509834855795), (45, 0.023535607615485787), (21, 0.024924598401412368), (22, 0.025168767664581537), (47, 0.025820446200668812), (24, 0.025899537606164813), (20, 0.026859007077291608), (38, 0.02811406902037561), (39, 0.02920690760947764), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.035091488156467676), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.05332902865484357), (2, 0.05454846192151308), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.07467831950634718), (10, 0.08034484181553125), (16, 0.0840828325599432), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4135979078710079), (18, 0.5108212903141975), (53, 0.9678284004330635)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.019070088397711515), (48, 0.020678168162703514), (50, 0.02134439768269658), (40, 0.021832421189174056), (25, 0.021972602931782603), (42, 0.021986939711496234), (23, 0.02237953501753509), (49, 0.022534748073667288), (45, 0.023929917253553867), (44, 0.024054003413766623), (21, 0.024924598401412368), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026043936843052506), (20, 0.02685900731012225), (38, 0.028114070184528828), (39, 0.0292069090064615), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.04340187832713127), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05047609377652407), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387396097183), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.027817964553833)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462957531214), (48, 0.019989707740023732), (50, 0.02077506179921329), (40, 0.02108595333993435), (42, 0.021369647467508912), (49, 0.021910030161961913), (25, 0.02197260339744389), (23, 0.022379535483196378), (44, 0.02323931152932346), (45, 0.023585309740155935), (21, 0.024924598401412368), (47, 0.025076948339119554), (22, 0.025168769294396043), (24, 0.025899536907672882), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.028580758487805724), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.032814261270686984), (37, 0.03542024362832308), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.048523630015552044), (2, 0.054548467975109816), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4065233953297138), (18, 0.5108212903141975), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462957531214
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.020831161411479115), (40, 0.021085952641442418), (42, 0.0213696479331702), (25, 0.021972603164613247), (23, 0.022379535483196378), (49, 0.0225369893014431), (44, 0.023239311994984746), (45, 0.023585307877510786), (21, 0.024924597470089793), (22, 0.025168769294396043), (24, 0.025899537606164813), (47, 0.026583050144836307), (20, 0.026859006145969033), (38, 0.027183360187336802), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.03285081125795841), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (52, 0.04812479950487614), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387396097183), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.153771162033081)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952408611774), (42, 0.021369647700339556), (25, 0.02197260200046003), (23, 0.022379535948857665), (50, 0.022470062598586082), (44, 0.023239311762154102), (45, 0.023585307644680142), (21, 0.024924598401412368), (22, 0.025168768595904112), (49, 0.025234102038666606), (24, 0.02589953737333417), (47, 0.026583048282191157), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628594897687435), (51, 0.03296921122819185), (37, 0.035420244093984365), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.0478366338647902), (52, 0.05089045129716396), (2, 0.054548464715480804), (3, 0.057224280666559935), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467831950634718), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.2663908898830414)]
computing accuracy for after removing block 40 . block score: 0.021085952408611774
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.02128476626239717), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.023098317440599203), (44, 0.024240857688710093), (49, 0.024500868981704116), (21, 0.02492459793575108), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026519698556512594), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.03192339139059186), (51, 0.03222084976732731), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.035420244093984365), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.04885757248848677), (2, 0.05454846750944853), (3, 0.05722428020089865), (13, 0.058922900818288326), (11, 0.05924913054332137), (17, 0.06095684878528118), (0, 0.0630098064430058), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.0904204910621047), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.02492459793575108), (22, 0.0251687690615654), (24, 0.025899536907672882), (47, 0.026220474857836962), (20, 0.026859006844460964), (38, 0.02718336135149002), (39, 0.028580758487805724), (51, 0.03127906774170697), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.03542024455964565), (9, 0.04340187879279256), (52, 0.046101709362119436), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.4178234189748764)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.02237953501753509), (45, 0.02376196696422994), (49, 0.02460233890451491), (44, 0.024712180718779564), (21, 0.02492459723725915), (22, 0.025168768363073468), (24, 0.02589953620918095), (47, 0.02622047532349825), (20, 0.026859006844460964), (38, 0.02718336065299809), (39, 0.028580759651958942), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.0334430206567049), (37, 0.03542024316266179), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.05265179416164756), (2, 0.05454846424981952), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300980783998966), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049758136272), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.6287681460380554)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 1 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 2 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 3 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 4 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 5 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 6 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 7 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.1]
training epoch 8 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 9 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 10 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.967 topk_dict {'top1': 0.967} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.967 topk_dict {'top1': 0.967}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.046510. All blocks and scores: [(49, 0.046510177198797464), (45, 0.04821544699370861), (44, 0.04888447420671582), (21, 0.05177481146529317), (23, 0.054201983381062746), (47, 0.05544405337423086), (22, 0.056231942027807236), (19, 0.05638850573450327), (15, 0.05812498880550265), (20, 0.0588773125782609), (51, 0.059357963502407074), (7, 0.0608798461034894), (38, 0.06242327578365803), (39, 0.06281572533771396), (24, 0.06294725649058819), (37, 0.06861741654574871), (52, 0.07177005335688591), (4, 0.07794034760445356), (6, 0.08086562622338533), (9, 0.08487118221819401), (2, 0.09388354886323214), (17, 0.09746682178229094), (14, 0.09762292169034481), (3, 0.10693461261689663), (0, 0.10706616099923849), (1, 0.10740204434841871), (13, 0.11054544616490602), (11, 0.11183796543627977), (8, 0.12936958484351635), (10, 0.1413932554423809), (12, 0.14752557687461376), (16, 0.1535856444388628), (5, 0.2035806141793728), (36, 0.6167951822280884), (18, 0.696401447057724), (53, 0.9965309426188469)]
computing accuracy for after removing block 49 . block score: 0.046510177198797464
removed block 49 current accuracy 0.9608 loss from initial  0.03920000000000001
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.048215. All blocks and scores: [(45, 0.048215446062386036), (44, 0.048884475603699684), (21, 0.05177480960264802), (23, 0.05420198477804661), (47, 0.05544405244290829), (22, 0.056231943890452385), (19, 0.05638850433751941), (15, 0.05812498787418008), (20, 0.05887731118127704), (7, 0.0608798461034894), (38, 0.06242327485233545), (39, 0.06281572580337524), (24, 0.06294725509360433), (51, 0.06314312946051359), (37, 0.06861741654574871), (4, 0.07794034853577614), (52, 0.07951598707586527), (6, 0.08086562622338533), (9, 0.08487118408083916), (2, 0.09388355165719986), (17, 0.09746682178229094), (14, 0.09762292262166739), (3, 0.10693460609763861), (0, 0.10706615820527077), (1, 0.10740204527974129), (13, 0.11054544523358345), (11, 0.1118379682302475), (8, 0.12936958856880665), (10, 0.14139325357973576), (12, 0.14752557687461376), (16, 0.15358564630150795), (5, 0.20358061231672764), (36, 0.6167951822280884), (18, 0.6964014396071434), (53, 1.124605044722557)]
computing accuracy for after removing block 45 . block score: 0.048215446062386036
removed block 45 current accuracy 0.9498 loss from initial  0.05020000000000002
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.048884. All blocks and scores: [(44, 0.04888447606936097), (21, 0.05177480913698673), (23, 0.05420198244974017), (22, 0.05623194109648466), (19, 0.05638850526884198), (15, 0.05812498787418008), (20, 0.058877311646938324), (7, 0.060879846569150686), (38, 0.06242327578365803), (39, 0.06281572487205267), (24, 0.06294725555926561), (51, 0.06359317619353533), (47, 0.06376312393695116), (37, 0.06861741468310356), (4, 0.07794034946709871), (6, 0.08086562436074018), (9, 0.08487117849290371), (52, 0.08554612193256617), (2, 0.09388355165719986), (17, 0.09746681805700064), (14, 0.09762292169034481), (3, 0.1069346098229289), (0, 0.10706615541130304), (1, 0.10740204714238644), (13, 0.1105454508215189), (11, 0.11183796543627977), (8, 0.1293695904314518), (10, 0.1413932554423809), (12, 0.14752557128667831), (16, 0.1535856481641531), (5, 0.20358061604201794), (36, 0.616795189678669), (18, 0.6964014321565628), (53, 1.228426232933998)]
computing accuracy for after removing block 44 . block score: 0.04888447606936097
removed block 44 current accuracy 0.9354 loss from initial  0.06459999999999999
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.051775. All blocks and scores: [(21, 0.051774811930954456), (23, 0.05420198244974017), (22, 0.05623194109648466), (19, 0.05638850573450327), (15, 0.05812498787418008), (20, 0.058877309784293175), (7, 0.060879846569150686), (51, 0.062378971837460995), (38, 0.06242327485233545), (39, 0.06281572626903653), (24, 0.06294725509360433), (37, 0.06861741561442614), (47, 0.07000675424933434), (4, 0.07794034946709871), (6, 0.08086562715470791), (9, 0.08487117942422628), (52, 0.08561079390347004), (2, 0.09388355072587729), (17, 0.09746682178229094), (14, 0.09762292169034481), (3, 0.10693461261689663), (0, 0.10706615634262562), (1, 0.10740204714238644), (13, 0.11054544523358345), (11, 0.1118379682302475), (8, 0.1293695867061615), (10, 0.14139325357973576), (12, 0.14752557687461376), (16, 0.15358565002679825), (5, 0.20358061604201794), (36, 0.6167951822280884), (18, 0.6964014247059822), (53, 1.311884954571724)]
computing accuracy for after removing block 21 . block score: 0.051774811930954456
removed block 21 current accuracy 0.9304 loss from initial  0.0696
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.048112. All blocks and scores: [(23, 0.04811237193644047), (22, 0.05063283536583185), (24, 0.05548521364107728), (19, 0.05638850573450327), (15, 0.058124986942857504), (20, 0.05887731071561575), (38, 0.059232790023088455), (51, 0.05932242423295975), (39, 0.06023891316726804), (7, 0.0608798461034894), (47, 0.065268250182271), (37, 0.06774856895208359), (52, 0.0769437775015831), (4, 0.07794034760445356), (6, 0.08086562622338533), (9, 0.08487118128687143), (2, 0.09388355072587729), (17, 0.09746682085096836), (14, 0.09762292448431253), (3, 0.10693460889160633), (0, 0.10706615820527077), (1, 0.10740204248577356), (13, 0.11054544616490602), (11, 0.11183796357363462), (8, 0.1293695867061615), (10, 0.14139325730502605), (12, 0.1475255787372589), (16, 0.1535856481641531), (5, 0.20358062349259853), (36, 0.5896186232566833), (18, 0.6964014321565628), (53, 1.342123493552208)]
computing accuracy for after removing block 23 . block score: 0.04811237193644047
removed block 23 current accuracy 0.916 loss from initial  0.08399999999999996
since last training loss: 0.050999999999999934 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.050633. All blocks and scores: [(22, 0.05063283396884799), (24, 0.05379208503291011), (19, 0.05638850759714842), (15, 0.05812498927116394), (51, 0.05887387041002512), (20, 0.05887731071561575), (39, 0.0603426736779511), (38, 0.06039037788286805), (7, 0.06087984470650554), (47, 0.06316225090995431), (37, 0.07106500212103128), (52, 0.0755583830177784), (4, 0.07794034760445356), (6, 0.08086562529206276), (9, 0.08487118221819401), (2, 0.09388355258852243), (17, 0.09746682085096836), (14, 0.09762292169034481), (3, 0.10693460889160633), (0, 0.10706616099923849), (1, 0.10740204062312841), (13, 0.1105454470962286), (11, 0.11183796264231205), (8, 0.12936958484351635), (10, 0.1413932591676712), (12, 0.1475255750119686), (16, 0.15358565002679825), (5, 0.20358062162995338), (36, 0.604886993765831), (18, 0.6964014321565628), (53, 1.3384098261594772)]
computing accuracy for after removing block 22 . block score: 0.05063283396884799
removed block 22 current accuracy 0.89 loss from initial  0.10999999999999999
since last training loss: 0.07699999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.052025. All blocks and scores: [(24, 0.0520248687826097), (19, 0.056388506200164557), (51, 0.05677853710949421), (15, 0.05812498787418008), (20, 0.05887731211259961), (39, 0.05992716923356056), (47, 0.06004950078204274), (7, 0.060879847034811974), (38, 0.0612529874779284), (52, 0.07070037256926298), (37, 0.07466951478272676), (4, 0.07794034760445356), (6, 0.08086562436074018), (9, 0.08487118128687143), (2, 0.09388355258852243), (17, 0.09746682085096836), (14, 0.09762292262166739), (3, 0.1069346098229289), (0, 0.10706616099923849), (1, 0.10740204248577356), (13, 0.1105454470962286), (11, 0.1118379645049572), (8, 0.12936958856880665), (10, 0.14139325730502605), (12, 0.1475255787372589), (16, 0.1535856518894434), (5, 0.20358061790466309), (36, 0.6109864562749863), (18, 0.6964014545083046), (53, 1.3378390669822693)]
computing accuracy for after removing block 24 . block score: 0.0520248687826097
removed block 24 current accuracy 0.8646 loss from initial  0.13539999999999996
since last training loss: 0.10239999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.053023. All blocks and scores: [(51, 0.053022796753793955), (47, 0.0557607039809227), (19, 0.05638850526884198), (39, 0.05684561748057604), (15, 0.05812498647719622), (20, 0.0588773088529706), (38, 0.06053829472512007), (7, 0.060879846569150686), (52, 0.06564244441688061), (37, 0.0743997236713767), (4, 0.07794034760445356), (6, 0.08086562622338533), (9, 0.08487117849290371), (2, 0.09388355258852243), (17, 0.09746682085096836), (14, 0.09762292075902224), (3, 0.10693460702896118), (0, 0.10706615727394819), (1, 0.10740204341709614), (13, 0.11054544989019632), (11, 0.1118379645049572), (8, 0.1293695904314518), (10, 0.14139325730502605), (12, 0.1475255787372589), (16, 0.1535856407135725), (5, 0.20358061604201794), (36, 0.6068617179989815), (18, 0.6964014247059822), (53, 1.3330071717500687)]
computing accuracy for after removing block 51 . block score: 0.053022796753793955
removed block 51 current accuracy 0.8272 loss from initial  0.17279999999999995
since last training loss: 0.13979999999999992 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.055761. All blocks and scores: [(47, 0.05576070351526141), (19, 0.056388506665825844), (39, 0.056845614686608315), (15, 0.0581249906681478), (20, 0.05887731024995446), (38, 0.060538295190781355), (7, 0.060879846569150686), (52, 0.0719290105625987), (37, 0.0743997236713767), (4, 0.07794034946709871), (6, 0.08086562622338533), (9, 0.08487117663025856), (2, 0.09388355072587729), (17, 0.09746682085096836), (14, 0.09762292169034481), (3, 0.10693460796028376), (0, 0.10706616099923849), (1, 0.10740204714238644), (13, 0.11054544989019632), (11, 0.1118379645049572), (8, 0.12936958856880665), (10, 0.1413932554423809), (12, 0.1475255750119686), (16, 0.15358564630150795), (5, 0.20358061604201794), (36, 0.6068617329001427), (18, 0.6964014396071434), (53, 1.5043741166591644)]
computing accuracy for after removing block 47 . block score: 0.05576070351526141
removed block 47 current accuracy 0.7472 loss from initial  0.2528
training start
training epoch 0 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best True lr [0.1]
training epoch 1 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 2 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 3 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 4 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 5 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 6 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 7 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 8 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 9 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.075142. All blocks and scores: [(15, 0.075142209418118), (7, 0.08245002757757902), (38, 0.0865149237215519), (37, 0.08722847606986761), (19, 0.09531587269157171), (4, 0.09626265056431293), (20, 0.09751917608082294), (6, 0.09908571094274521), (39, 0.10045355185866356), (52, 0.10744695737957954), (9, 0.11352090630680323), (2, 0.11901730392128229), (3, 0.11966675333678722), (0, 0.1216077683493495), (14, 0.12499336712062359), (1, 0.1294542234390974), (11, 0.13125164434313774), (17, 0.13302286714315414), (13, 0.13649760000407696), (8, 0.15530086494982243), (12, 0.16318285465240479), (10, 0.17509440146386623), (16, 0.19443663395941257), (5, 0.21273652277886868), (36, 0.532654844224453), (18, 0.6353782713413239), (53, 1.156460464000702)]
computing accuracy for after removing block 15 . block score: 0.075142209418118
removed block 15 current accuracy 0.9386 loss from initial  0.06140000000000001
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 7, with score 0.082450. All blocks and scores: [(7, 0.08245002664625645), (38, 0.08507860638201237), (37, 0.08656917978078127), (20, 0.08975457213819027), (19, 0.09231816325336695), (4, 0.09626265242695808), (6, 0.09908571094274521), (39, 0.10139426589012146), (52, 0.10703207738697529), (9, 0.11352090630680323), (2, 0.11901729833334684), (3, 0.11966675519943237), (0, 0.12160776928067207), (14, 0.12499336991459131), (1, 0.12945422157645226), (11, 0.13125164434313774), (13, 0.13649759627878666), (17, 0.1409595012664795), (8, 0.15530086122453213), (12, 0.16318285837769508), (10, 0.17509440146386623), (16, 0.20010723359882832), (5, 0.21273652464151382), (36, 0.5155264809727669), (18, 0.6097735241055489), (53, 1.1595157235860825)]
computing accuracy for after removing block 7 . block score: 0.08245002664625645
removed block 7 current accuracy 0.9302 loss from initial  0.06979999999999997
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 37, with score 0.078466. All blocks and scores: [(37, 0.07846609223634005), (19, 0.08540494460612535), (20, 0.08651386573910713), (38, 0.08661697618663311), (4, 0.09626265522092581), (39, 0.09866625163704157), (6, 0.09908570908010006), (52, 0.10244608949869871), (9, 0.11193787213414907), (14, 0.11747065745294094), (17, 0.11767068598419428), (2, 0.11901729833334684), (3, 0.11966675519943237), (0, 0.12160776928067207), (13, 0.12254202738404274), (11, 0.1263821953907609), (1, 0.1294542271643877), (8, 0.15444488264620304), (12, 0.16021538712084293), (10, 0.1806283686310053), (16, 0.18162056058645248), (5, 0.21273652650415897), (36, 0.49469631537795067), (18, 0.5883306562900543), (53, 1.146156683564186)]
computing accuracy for after removing block 37 . block score: 0.07846609223634005
removed block 37 current accuracy 0.9088 loss from initial  0.09119999999999995
since last training loss: 0.03799999999999992 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 19, with score 0.085405. All blocks and scores: [(19, 0.08540494833141565), (20, 0.08651386853307486), (52, 0.0894902078434825), (39, 0.09537311177700758), (4, 0.09626265428960323), (38, 0.09822637494653463), (6, 0.09908571094274521), (9, 0.11193787399679422), (14, 0.11747066024690866), (17, 0.11767068598419428), (2, 0.11901730392128229), (3, 0.11966675613075495), (0, 0.12160776741802692), (13, 0.12254202552139759), (11, 0.1263821953907609), (1, 0.1294542271643877), (8, 0.1544448807835579), (12, 0.16021539084613323), (10, 0.18062836676836014), (16, 0.18162055872380733), (5, 0.21273651905357838), (36, 0.49469630792737007), (18, 0.5883306413888931), (53, 1.1157820373773575)]
computing accuracy for after removing block 19 . block score: 0.08540494833141565
removed block 19 current accuracy 0.8778 loss from initial  0.12219999999999998
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.078912. All blocks and scores: [(20, 0.07891223672777414), (52, 0.08421617839485407), (4, 0.09626265149563551), (39, 0.09753996971994638), (38, 0.09899888839572668), (6, 0.09908571094274521), (9, 0.11193787399679422), (14, 0.11747065838426352), (17, 0.11767068784683943), (2, 0.11901730578392744), (3, 0.11966675706207752), (0, 0.12160776928067207), (13, 0.12254203110933304), (11, 0.1263821953907609), (1, 0.12945422530174255), (8, 0.1544448845088482), (12, 0.16021539270877838), (10, 0.18062836676836014), (16, 0.18162055686116219), (5, 0.21273652277886868), (36, 0.4974950887262821), (18, 0.5883306562900543), (53, 1.1141183227300644)]
computing accuracy for after removing block 20 . block score: 0.07891223672777414
removed block 20 current accuracy 0.8102 loss from initial  0.18979999999999997
since last training loss: 0.13659999999999994 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 52, with score 0.080025. All blocks and scores: [(52, 0.08002476207911968), (4, 0.09626265242695808), (6, 0.09908570628613234), (39, 0.09984116163104773), (38, 0.1118790926411748), (9, 0.11193787585943937), (14, 0.11747066024690866), (17, 0.11767068412154913), (2, 0.11901730112731457), (3, 0.11966675613075495), (0, 0.12160776928067207), (13, 0.12254202645272017), (11, 0.12638219445943832), (1, 0.1294542234390974), (8, 0.1544448845088482), (12, 0.16021538898348808), (10, 0.18062837049365044), (16, 0.18162055872380733), (5, 0.21273651905357838), (36, 0.53521379083395), (18, 0.5883306711912155), (53, 1.1242267787456512)]
computing accuracy for after removing block 52 . block score: 0.08002476207911968
removed block 52 current accuracy 0.678 loss from initial  0.32199999999999995
since last training loss: 0.26879999999999993 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.096263. All blocks and scores: [(4, 0.09626265242695808), (6, 0.09908571001142263), (39, 0.09984116163104773), (38, 0.11187909450381994), (9, 0.1119378749281168), (14, 0.11747065931558609), (17, 0.11767068319022655), (2, 0.11901730205863714), (3, 0.1196667505428195), (0, 0.1216077683493495), (13, 0.12254202365875244), (11, 0.1263821953907609), (1, 0.12945422157645226), (8, 0.1544448807835579), (12, 0.16021538898348808), (10, 0.18062835931777954), (16, 0.18162055686116219), (5, 0.21273652091622353), (36, 0.5352137833833694), (18, 0.5883306562900543), (53, 1.2801152169704437)]
computing accuracy for after removing block 4 . block score: 0.09626265242695808
removed block 4 current accuracy 0.6732 loss from initial  0.3268
since last training loss: 0.27359999999999995 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.098691. All blocks and scores: [(39, 0.09869066718965769), (9, 0.10901714395731688), (6, 0.11001570988446474), (38, 0.11056679394096136), (17, 0.11531831603497267), (14, 0.11602024920284748), (11, 0.11839168053120375), (2, 0.11901730205863714), (3, 0.11966675613075495), (0, 0.1216077683493495), (13, 0.12287017237395048), (1, 0.1294542271643877), (8, 0.15475713089108467), (12, 0.1568498183041811), (16, 0.16263164207339287), (10, 0.180872505530715), (5, 0.23310106992721558), (36, 0.5349785909056664), (18, 0.5938827618956566), (53, 1.2447139918804169)]
computing accuracy for after removing block 39 . block score: 0.09869066718965769
removed block 39 current accuracy 0.5566 loss from initial  0.4434
since last training loss: 0.3902 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 9, with score 0.109017. All blocks and scores: [(9, 0.109017139300704), (6, 0.11001571174710989), (38, 0.11056679487228394), (17, 0.1153183151036501), (14, 0.11602025013417006), (11, 0.11839167680591345), (2, 0.11901730485260487), (3, 0.11966675333678722), (0, 0.12160777114331722), (13, 0.12287017609924078), (1, 0.12945422530174255), (8, 0.15475712902843952), (12, 0.1568498145788908), (16, 0.16263164393603802), (10, 0.18087250366806984), (5, 0.23310107365250587), (36, 0.5349786132574081), (18, 0.5938827767968178), (53, 1.4479369819164276)]
computing accuracy for after removing block 9 . block score: 0.109017139300704
removed block 9 current accuracy 0.4916 loss from initial  0.5084
since last training loss: 0.4552 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 38, with score 0.096529. All blocks and scores: [(38, 0.09652914479374886), (17, 0.10359056293964386), (11, 0.10669595189392567), (14, 0.1075101001188159), (6, 0.11001571360975504), (13, 0.11601482797414064), (2, 0.11901730019599199), (3, 0.1196667542681098), (0, 0.1216077683493495), (12, 0.12738994508981705), (1, 0.12945421785116196), (16, 0.13255762495100498), (8, 0.15475713275372982), (10, 0.1730790939182043), (5, 0.23310106992721558), (36, 0.476201418787241), (18, 0.5583741739392281), (53, 1.2131048440933228)]
computing accuracy for after removing block 38 . block score: 0.09652914479374886
removed block 38 current accuracy 0.4246 loss from initial  0.5754
since last training loss: 0.5222 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 17, with score 0.103591. All blocks and scores: [(17, 0.10359056480228901), (11, 0.10669595282524824), (14, 0.1075101001188159), (6, 0.11001571174710989), (13, 0.11601483076810837), (2, 0.11901730112731457), (3, 0.11966675519943237), (0, 0.12160776648670435), (12, 0.1273899469524622), (1, 0.12945422157645226), (16, 0.13255762867629528), (8, 0.15475713275372982), (10, 0.17307908833026886), (5, 0.23310107551515102), (36, 0.4762014262378216), (18, 0.5583741664886475), (53, 1.437858134508133)]
computing accuracy for after removing block 17 . block score: 0.10359056480228901
removed block 17 current accuracy 0.3858 loss from initial  0.6142000000000001
since last training loss: 0.5609999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.106696. All blocks and scores: [(11, 0.10669595096260309), (14, 0.10751010198146105), (6, 0.11001571360975504), (13, 0.1160148298367858), (2, 0.11901729926466942), (3, 0.11966675706207752), (0, 0.1216077683493495), (12, 0.12738994508981705), (1, 0.1294542234390974), (16, 0.13255762867629528), (8, 0.15475712902843952), (10, 0.1730790864676237), (5, 0.23310107365250587), (36, 0.43760571628808975), (18, 0.5341184139251709), (53, 1.366140678524971)]
computing accuracy for after removing block 11 . block score: 0.10669595096260309
removed block 11 current accuracy 0.3566 loss from initial  0.6434
training start
training epoch 0 val accuracy 0.7316 topk_dict {'top1': 0.7316} is_best True lr [0.1]
training epoch 1 val accuracy 0.7902 topk_dict {'top1': 0.7902} is_best True lr [0.1]
training epoch 2 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.1]
training epoch 3 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best True lr [0.1]
training epoch 4 val accuracy 0.838 topk_dict {'top1': 0.838} is_best False lr [0.1]
training epoch 5 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best False lr [0.1]
training epoch 6 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best True lr [0.1]
training epoch 7 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best False lr [0.1]
training epoch 8 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.1]
training epoch 9 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best True lr [0.1]
training epoch 10 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.915600)
finished training. finished 50 epochs. accuracy 0.9156 topk_dict {'top1': 0.9156}
