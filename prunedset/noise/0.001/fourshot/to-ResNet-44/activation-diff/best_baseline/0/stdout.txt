start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996380798519), (32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.010361599852330983), (34, 0.013312276103533804), (29, 0.013541154679842293), (35, 0.016018461668863893), (26, 0.01603759010322392), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020232456270605326), (46, 0.021044540451839566), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.02282664878293872), (44, 0.023395078722387552), (40, 0.024025024846196175), (45, 0.024295411072671413), (21, 0.024924597004428506), (22, 0.02516876789741218), (48, 0.025341259548440576), (24, 0.02589953737333417), (50, 0.02640997152775526), (42, 0.026674100663512945), (20, 0.02685900777578354), (49, 0.027037165593355894), (47, 0.029306468553841114), (39, 0.031570713268592954), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.037960262037813663), (51, 0.04173417296260595), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836634796112776), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734145730734), (52, 0.0686293737962842), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.43758001178503036), (18, 0.5108213052153587), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996380798519
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.010361600201576948), (34, 0.013133947737514973), (29, 0.013541154912672937), (26, 0.01603759080171585), (35, 0.016169289126992226), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.02007247693836689), (46, 0.020731384633108974), (25, 0.021972602466121316), (41, 0.02234709309414029), (23, 0.02237953571602702), (44, 0.023235687520354986), (40, 0.023841066984459758), (45, 0.023965542437508702), (48, 0.024917915929108858), (21, 0.02492459793575108), (22, 0.02516876789741218), (50, 0.02584081282839179), (24, 0.025899537606164813), (42, 0.02631532377563417), (49, 0.026655674446374178), (20, 0.026859007077291608), (47, 0.02872879710048437), (39, 0.03131764312274754), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (37, 0.038025844376534224), (51, 0.04122393950819969), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734331995249), (52, 0.06745155155658722), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.43538710474967957), (18, 0.5108212977647781), (53, 0.8222573548555374)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.010361600085161626), (34, 0.012765232473611832), (29, 0.013541154097765684), (35, 0.015992750879377127), (26, 0.016037590568885207), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020075131906196475), (46, 0.020841405959799886), (25, 0.02197260269895196), (41, 0.02231976785697043), (23, 0.022379535483196378), (44, 0.023154050577431917), (40, 0.02388568385504186), (45, 0.0240716899279505), (48, 0.02487746556289494), (21, 0.024924598401412368), (22, 0.0251687690615654), (50, 0.02569117839448154), (24, 0.025899536907672882), (42, 0.026123747462406754), (49, 0.026479421881958842), (20, 0.026859006844460964), (47, 0.028693132335320115), (38, 0.031236795475706458), (39, 0.031295292312279344), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859722599387), (37, 0.038376690819859505), (51, 0.04111403413116932), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.0670045642182231), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.43640000373125076), (18, 0.5108213126659393), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.012387837166897953), (29, 0.013541154563426971), (35, 0.016008096048608422), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.02070444426499307), (25, 0.02197260269895196), (41, 0.02225319668650627), (23, 0.02237953501753509), (44, 0.023267761571332812), (40, 0.02401387970894575), (45, 0.024092992767691612), (48, 0.024665280245244503), (21, 0.024924598168581724), (22, 0.025168768363073468), (50, 0.02545973495580256), (42, 0.025655712699517608), (24, 0.02589953737333417), (49, 0.026287756394594908), (20, 0.02685900731012225), (47, 0.02836342412047088), (38, 0.03104764735326171), (39, 0.03138077212497592), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.038971245754510164), (51, 0.04075620323419571), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095684692263603), (0, 0.0630098064430058), (52, 0.06586315855383873), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4389924630522728), (18, 0.5108213126659393), (53, 0.8391561582684517)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619432017207), (29, 0.013541154679842293), (26, 0.016037590336054564), (35, 0.01605736347846687), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020049350103363395), (46, 0.020552987465634942), (25, 0.021972602466121316), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132598266006), (40, 0.02385834790766239), (45, 0.024124702671542764), (48, 0.024386122589930892), (21, 0.024924598168581724), (50, 0.02504224143922329), (22, 0.025168768595904112), (42, 0.02541450783610344), (49, 0.025842699222266674), (24, 0.025899537140503526), (20, 0.026859006844460964), (47, 0.028050734428688884), (38, 0.0310400587040931), (39, 0.0315008033066988), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.039112848695367575), (51, 0.04024627385661006), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.054548464715480804), (3, 0.057224275544285774), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980830565095), (52, 0.0648620892316103), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4381278455257416), (18, 0.5108213052153587), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489619432017207
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.016037591267377138), (35, 0.016653420170769095), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020503456005826592), (46, 0.0207253226544708), (25, 0.021972603630274534), (23, 0.022379535483196378), (41, 0.022452628472819924), (44, 0.02336447429843247), (48, 0.02429035515524447), (45, 0.024438712978735566), (40, 0.024470558390021324), (21, 0.024924598401412368), (50, 0.02504217205569148), (22, 0.025168768130242825), (49, 0.025875970954075456), (24, 0.025899536907672882), (42, 0.026205406757071614), (20, 0.02685900731012225), (47, 0.028178582899272442), (15, 0.03192339139059186), (38, 0.032083500642329454), (7, 0.03228544723242521), (39, 0.03233744064345956), (19, 0.03262859536334872), (51, 0.03994725923985243), (37, 0.04073968343436718), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.05892290361225605), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.0630098101682961), (52, 0.06433630036190152), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049013078213), (5, 0.10667387116700411), (36, 0.45053431391716003), (18, 0.5108212903141975), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.016470608301460743), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02004686719737947), (46, 0.020376993576064706), (41, 0.021723242942243814), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.02302833623252809), (48, 0.023771876003593206), (40, 0.023930813185870647), (45, 0.024178662803024054), (50, 0.024390298407524824), (21, 0.02492459793575108), (22, 0.025168767664581537), (42, 0.025188250932842493), (49, 0.025361529551446438), (24, 0.0258995380718261), (20, 0.026859008008614182), (47, 0.02736328006722033), (38, 0.03136561927385628), (15, 0.03192339185625315), (39, 0.03212768444791436), (7, 0.032285445369780064), (19, 0.032628596760332584), (51, 0.0389359244145453), (37, 0.040206344332545996), (9, 0.04340188205242157), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892289988696575), (11, 0.05924912728369236), (17, 0.06095684925094247), (52, 0.062328549567610025), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4444201961159706), (18, 0.5108213052153587), (53, 0.853791169822216)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365447320044), (28, 0.017088501015678048), (27, 0.01888244762085378), (43, 0.019595165736973286), (46, 0.02007358125410974), (41, 0.020961585454642773), (25, 0.021972602931782603), (23, 0.02237953571602702), (44, 0.022814955795183778), (48, 0.023128160974010825), (40, 0.023345195688307285), (50, 0.023756146198138595), (42, 0.023847303353250027), (45, 0.02387388003990054), (21, 0.024924598401412368), (49, 0.02496031578630209), (22, 0.025168768130242825), (24, 0.025899537838995457), (47, 0.026855542324483395), (20, 0.026859007542952895), (38, 0.030424013966694474), (39, 0.03151404415257275), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722427600994706), (13, 0.05892290221527219), (11, 0.05924912728369236), (52, 0.06033282168209553), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734052598476), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4360685534775257), (18, 0.5108213052153587), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597365447320044
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 1 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 2 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 3 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 4 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 5 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 6 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 7 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 8 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.1]
training epoch 9 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 10 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945483967662), (27, 0.01888244692236185), (46, 0.019160084892064333), (41, 0.019424294587224722), (48, 0.021467272425070405), (25, 0.021972602233290672), (44, 0.02202691650018096), (40, 0.022179661318659782), (42, 0.022206429624930024), (50, 0.022256128955632448), (23, 0.022379535250365734), (45, 0.022931481711566448), (49, 0.02370851207524538), (21, 0.024924597702920437), (22, 0.025168768595904112), (47, 0.02582913893274963), (24, 0.025899537140503526), (20, 0.02685900777578354), (38, 0.028956546913832426), (39, 0.029667829163372517), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.03600902622565627), (37, 0.03651238791644573), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836634796112776), (2, 0.05454846564680338), (52, 0.05610728682950139), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.41757645830512047), (18, 0.5108213052153587), (53, 0.9117144718766212)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102241948247), (41, 0.01884901849552989), (27, 0.018882446689531207), (48, 0.020903734490275383), (42, 0.02143200417049229), (40, 0.021832421189174056), (44, 0.021840530447661877), (50, 0.02186986431479454), (25, 0.021972603164613247), (23, 0.022379535250365734), (45, 0.022492847871035337), (49, 0.023123498307541013), (21, 0.02492459793575108), (47, 0.025067138485610485), (22, 0.025168768363073468), (24, 0.0258995380718261), (20, 0.026859006844460964), (38, 0.028114070184528828), (39, 0.029206909239292145), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.035454337019473314), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548464715480804), (52, 0.054696458857506514), (3, 0.0572242783382535), (13, 0.058922899421304464), (11, 0.05924912868067622), (17, 0.06095685111358762), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4135979227721691), (18, 0.5108212977647781), (53, 0.924663245677948)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882447155192494), (46, 0.019302030559629202), (42, 0.02143200463615358), (48, 0.021544843213632703), (40, 0.0218324214220047), (50, 0.021946269320324063), (25, 0.02197260200046003), (23, 0.022379535483196378), (49, 0.023006869480013847), (44, 0.023108510300517082), (45, 0.023535606916993856), (21, 0.024924597470089793), (22, 0.025168768130242825), (47, 0.025820447131991386), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.028114070184528828), (39, 0.02920690830796957), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.035091488622128963), (37, 0.03597763879224658), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663433045149), (52, 0.053329030983150005), (2, 0.05454846564680338), (3, 0.05722427600994706), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4135979190468788), (18, 0.5108213052153587), (53, 0.9678284302353859)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.01907008863054216), (48, 0.020678168395534158), (50, 0.02134439698420465), (40, 0.021832421189174056), (25, 0.021972602931782603), (42, 0.021986940409988165), (23, 0.022379535483196378), (49, 0.02253474877215922), (45, 0.023929917020723224), (44, 0.02405400387942791), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537838995457), (47, 0.02604393707588315), (20, 0.02685900777578354), (38, 0.02811406971886754), (39, 0.029206907842308283), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.03379448037594557), (37, 0.03597763925790787), (9, 0.043401881121098995), (6, 0.046609030570834875), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.0504760961048305), (2, 0.05454846331849694), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049013078213), (5, 0.10667387209832668), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.01998970750719309), (50, 0.020775061566382647), (40, 0.02108595333993435), (42, 0.021369647700339556), (49, 0.02191002992913127), (25, 0.021972602466121316), (23, 0.02237953571602702), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.02492459863424301), (47, 0.025076947640627623), (22, 0.025168768130242825), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.027183360885828733), (39, 0.028580759186297655), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.032814261270686984), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836634796112776), (52, 0.04852363187819719), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560370787978), (50, 0.020831161877140403), (40, 0.021085952641442418), (42, 0.021369647467508912), (25, 0.021972602931782603), (23, 0.022379535483196378), (49, 0.022536989767104387), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.024924597702920437), (22, 0.02516876789741218), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.02685900661163032), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03285081218928099), (37, 0.03542024316266179), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.047836633399128914), (52, 0.048124798107892275), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212828636169), (53, 1.153771162033081)]
computing accuracy for after removing block 48 . block score: 0.020327560370787978
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.02108595403842628), (42, 0.021369648166000843), (25, 0.02197260269895196), (23, 0.02237953501753509), (50, 0.022470062831416726), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.02492459723725915), (22, 0.025168768595904112), (49, 0.02523410157300532), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03296921169385314), (37, 0.03542024362832308), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.050890450831502676), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049665004015), (5, 0.10667387023568153), (36, 0.4065234065055847), (18, 0.5108212977647781), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.02108595403842628
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968682132661343), (50, 0.021284765796735883), (25, 0.02197260200046003), (23, 0.022379535250365734), (45, 0.023098317440599203), (44, 0.024240857921540737), (49, 0.024500868748873472), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.026519698556512594), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580758720636368), (15, 0.03192339139059186), (51, 0.03222084976732731), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.04885757248848677), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.3718615621328354)]
computing accuracy for after removing block 42 . block score: 0.020968682132661343
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.1]
training epoch 1 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 2 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 3 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 4 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 5 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 6 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 7 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 8 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 9 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 10 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.967600)
finished training. finished 50 epochs. accuracy 0.9676 topk_dict {'top1': 0.9676}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.042137. All blocks and scores: [(50, 0.04213705379515886), (49, 0.04236755194142461), (45, 0.04590732278302312), (23, 0.04821803001686931), (47, 0.050401021260768175), (44, 0.05057933460921049), (25, 0.05069872969761491), (21, 0.05174804013222456), (20, 0.0524597242474556), (51, 0.05305177113041282), (15, 0.0546020045876503), (22, 0.055287439841777086), (24, 0.05641981074586511), (19, 0.05824394291266799), (38, 0.05842797737568617), (7, 0.06010470585897565), (39, 0.06186310527846217), (52, 0.06552681792527437), (4, 0.06793793942779303), (37, 0.06901617161929607), (9, 0.08550692163407803), (11, 0.09134388249367476), (0, 0.09673066064715385), (6, 0.09824629593640566), (14, 0.10083951894193888), (1, 0.10191960912197828), (2, 0.10215792804956436), (3, 0.10518093407154083), (17, 0.10752632934600115), (13, 0.11432295851409435), (8, 0.12240940146148205), (10, 0.156685721129179), (16, 0.15969872288405895), (12, 0.16195150837302208), (5, 0.1994761787354946), (36, 0.6600949540734291), (18, 0.7272839099168777), (53, 0.9737900272011757)]
computing accuracy for after removing block 50 . block score: 0.04213705379515886
removed block 50 current accuracy 0.9546 loss from initial  0.045399999999999996
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.042368. All blocks and scores: [(49, 0.042367552407085896), (45, 0.04590732464566827), (23, 0.04821803141385317), (47, 0.050401021260768175), (44, 0.05057933693751693), (25, 0.05069872923195362), (21, 0.051748039200901985), (20, 0.05245972704142332), (15, 0.05460200272500515), (22, 0.055287439841777086), (24, 0.05641980981454253), (51, 0.05680610053241253), (19, 0.05824394337832928), (38, 0.058427974581718445), (7, 0.06010470585897565), (39, 0.0618631043471396), (4, 0.06793793942779303), (37, 0.06901617255061865), (52, 0.07365300692617893), (9, 0.08550692070275545), (11, 0.0913438806310296), (0, 0.09673066437244415), (6, 0.09824629779905081), (14, 0.10083951987326145), (1, 0.10191960632801056), (2, 0.10215792711824179), (3, 0.10518093127757311), (17, 0.10752633307129145), (13, 0.11432296223938465), (8, 0.12240939494222403), (10, 0.1566857174038887), (16, 0.15969872660934925), (12, 0.16195151023566723), (5, 0.19947618059813976), (36, 0.6600949466228485), (18, 0.7272839099168777), (53, 1.1166163831949234)]
computing accuracy for after removing block 49 . block score: 0.042367552407085896
removed block 49 current accuracy 0.947 loss from initial  0.05300000000000005
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.045907. All blocks and scores: [(45, 0.04590732464566827), (23, 0.04821803094819188), (47, 0.05040102219209075), (44, 0.05057933647185564), (25, 0.050698730163276196), (21, 0.05174803966656327), (20, 0.0524597242474556), (15, 0.05460200412198901), (22, 0.055287440307438374), (24, 0.05641981307417154), (19, 0.0582439424470067), (38, 0.058427977841347456), (7, 0.06010470539331436), (51, 0.061445631086826324), (39, 0.061863102950155735), (4, 0.06793793849647045), (37, 0.06901617534458637), (52, 0.07998932432383299), (9, 0.0855069188401103), (11, 0.09134388249367476), (0, 0.09673066530376673), (6, 0.09824629407376051), (14, 0.10083952080458403), (1, 0.10191961098462343), (2, 0.10215792804956436), (3, 0.10518093500286341), (17, 0.10752633213996887), (13, 0.1143229603767395), (8, 0.12240939680486917), (10, 0.15668572299182415), (16, 0.15969872288405895), (12, 0.16195150837302208), (5, 0.19947618059813976), (36, 0.6600949540734291), (18, 0.7272838950157166), (53, 1.179323136806488)]
computing accuracy for after removing block 45 . block score: 0.04590732464566827
removed block 45 current accuracy 0.9346 loss from initial  0.06540000000000001
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.048218. All blocks and scores: [(23, 0.048218031879514456), (44, 0.050579335540533066), (25, 0.05069872923195362), (21, 0.05174804013222456), (20, 0.05245972657576203), (15, 0.05460200319066644), (22, 0.055287438444793224), (47, 0.05608209827914834), (24, 0.05641980841755867), (19, 0.0582439424470067), (38, 0.05842797551304102), (51, 0.059648707043379545), (7, 0.06010470539331436), (39, 0.061863106209784746), (4, 0.06793793849647045), (37, 0.0690161744132638), (52, 0.08147641085088253), (9, 0.08550692070275545), (11, 0.09134388249367476), (0, 0.096730662509799), (6, 0.09824629779905081), (14, 0.1008395217359066), (1, 0.10191960819065571), (2, 0.10215793084353209), (3, 0.10518093686550856), (17, 0.1075263312086463), (13, 0.1143229603767395), (8, 0.12240940053015947), (10, 0.156685721129179), (16, 0.15969872288405895), (12, 0.16195151209831238), (5, 0.19947618432343006), (36, 0.6600949540734291), (18, 0.7272839173674583), (53, 1.2472842782735825)]
computing accuracy for after removing block 23 . block score: 0.048218031879514456
removed block 23 current accuracy 0.928 loss from initial  0.07199999999999995
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 25, with score 0.049898. All blocks and scores: [(25, 0.04989807028323412), (44, 0.04998473823070526), (21, 0.05174804013222456), (20, 0.05245972704142332), (24, 0.05284382542595267), (15, 0.05460200319066644), (47, 0.055276192259043455), (22, 0.0552874393761158), (38, 0.05789752257987857), (19, 0.05824394151568413), (51, 0.05984366312623024), (7, 0.060104706324636936), (39, 0.0633823573589325), (4, 0.06793793849647045), (37, 0.07288075983524323), (52, 0.08177989069372416), (9, 0.08550691977143288), (11, 0.09134387876838446), (0, 0.09673066344112158), (6, 0.09824629593640566), (14, 0.1008395180106163), (1, 0.10191960912197828), (2, 0.10215792898088694), (3, 0.10518093220889568), (17, 0.1075263312086463), (13, 0.11432296223938465), (8, 0.12240939680486917), (10, 0.156685721129179), (16, 0.15969872660934925), (12, 0.16195151023566723), (5, 0.1994761824607849), (36, 0.6658714339137077), (18, 0.7272839024662971), (53, 1.253930702805519)]
computing accuracy for after removing block 25 . block score: 0.04989807028323412
removed block 25 current accuracy 0.9186 loss from initial  0.08140000000000003
since last training loss: 0.049000000000000044 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.049442. All blocks and scores: [(44, 0.04944228986278176), (21, 0.05174804059788585), (47, 0.05231911316514015), (20, 0.052459726110100746), (24, 0.05284382589161396), (15, 0.05460200319066644), (22, 0.05528743891045451), (38, 0.05633539520204067), (51, 0.05777472676709294), (19, 0.05824394337832928), (7, 0.06010470446199179), (39, 0.0655227703973651), (4, 0.0679379403591156), (37, 0.07763794809579849), (52, 0.08010472729802132), (9, 0.08550692349672318), (11, 0.0913438806310296), (0, 0.09673066064715385), (6, 0.09824629779905081), (14, 0.10083951894193888), (1, 0.10191960632801056), (2, 0.10215792804956436), (3, 0.10518093593418598), (17, 0.1075263312086463), (13, 0.11432295758277178), (8, 0.12240939773619175), (10, 0.1566857174038887), (16, 0.15969872660934925), (12, 0.16195150651037693), (5, 0.19947618432343006), (36, 0.6855211406946182), (18, 0.7272838950157166), (53, 1.2438114285469055)]
computing accuracy for after removing block 44 . block score: 0.04944228986278176
removed block 44 current accuracy 0.8922 loss from initial  0.1078
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.051748. All blocks and scores: [(21, 0.05174803826957941), (20, 0.05245972657576203), (24, 0.052843826822936535), (15, 0.0546020045876503), (22, 0.055287438444793224), (38, 0.05633539520204067), (47, 0.0566671178676188), (51, 0.0578413987532258), (19, 0.05824394291266799), (7, 0.0601047039963305), (39, 0.06552276946604252), (4, 0.0679379403591156), (37, 0.07763794623315334), (52, 0.08228578139096498), (9, 0.08550692163407803), (11, 0.09134388342499733), (0, 0.09673066064715385), (6, 0.09824629500508308), (14, 0.1008395180106163), (1, 0.10191960912197828), (2, 0.10215792898088694), (3, 0.10518093314021826), (17, 0.1075263312086463), (13, 0.11432295944541693), (8, 0.12240939866751432), (10, 0.15668572671711445), (16, 0.1596987284719944), (12, 0.16195151209831238), (5, 0.19947617687284946), (36, 0.6855211555957794), (18, 0.7272839024662971), (53, 1.2812605202198029)]
computing accuracy for after removing block 21 . block score: 0.05174803826957941
removed block 21 current accuracy 0.885 loss from initial  0.11499999999999999
since last training loss: 0.0826 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.046002. All blocks and scores: [(24, 0.046002302784472704), (22, 0.05117009999230504), (20, 0.05245972564443946), (47, 0.053475940600037575), (38, 0.054208116605877876), (15, 0.054602003656327724), (51, 0.055825541727244854), (19, 0.0582439424470067), (7, 0.0601047039963305), (39, 0.06386184599250555), (4, 0.0679379403591156), (37, 0.07341360859572887), (52, 0.07371505629271269), (9, 0.08550692349672318), (11, 0.0913438806310296), (0, 0.09673066437244415), (6, 0.09824629686772823), (14, 0.10083951894193888), (1, 0.10191960725933313), (2, 0.10215793084353209), (3, 0.10518093220889568), (17, 0.10752633027732372), (13, 0.11432295572012663), (8, 0.12240939773619175), (10, 0.156685721129179), (16, 0.15969872660934925), (12, 0.16195150651037693), (5, 0.19947619177401066), (36, 0.6464375853538513), (18, 0.7272838801145554), (53, 1.3309870064258575)]
computing accuracy for after removing block 24 . block score: 0.046002302784472704
removed block 24 current accuracy 0.8644 loss from initial  0.13560000000000005
training start
training epoch 0 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.1]
training epoch 1 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.1]
training epoch 2 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best True lr [0.1]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 4 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 5 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 6 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 7 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 8 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 9 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.953200)
finished training. finished 50 epochs. accuracy 0.9532 topk_dict {'top1': 0.9532}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.058622. All blocks and scores: [(7, 0.05862157745286822), (15, 0.0695979529991746), (38, 0.07281821966171265), (51, 0.07494090776890516), (20, 0.0753157353028655), (19, 0.0754757234826684), (4, 0.07597644813358784), (37, 0.07826637011021376), (47, 0.07927247602492571), (52, 0.08340881392359734), (39, 0.08378804847598076), (9, 0.08875047415494919), (14, 0.10096423234790564), (22, 0.10170255973935127), (6, 0.109199327416718), (2, 0.11432712525129318), (17, 0.11725947633385658), (1, 0.11882829014211893), (11, 0.1201032605022192), (3, 0.12026041001081467), (0, 0.12132329121232033), (13, 0.1281554400920868), (8, 0.1360872983932495), (12, 0.17377941124141216), (16, 0.1788840014487505), (10, 0.17907843366265297), (5, 0.21896063350141048), (36, 0.6036659702658653), (18, 0.6717604249715805), (53, 1.0112831071019173)]
computing accuracy for after removing block 7 . block score: 0.05862157745286822
removed block 7 current accuracy 0.9494 loss from initial  0.05059999999999998
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.067303. All blocks and scores: [(15, 0.06730277836322784), (20, 0.07166617177426815), (19, 0.07177439983934164), (51, 0.07218624465167522), (38, 0.07268693763762712), (37, 0.07347795832902193), (4, 0.07597644813358784), (47, 0.07704083621501923), (52, 0.07974903471767902), (39, 0.08159352838993073), (9, 0.09157574456185102), (22, 0.09651871118694544), (14, 0.09700042195618153), (17, 0.09744417294859886), (6, 0.10919932089745998), (11, 0.11257849168032408), (13, 0.11379587557166815), (2, 0.11432712711393833), (1, 0.11882828455418348), (3, 0.12026040907949209), (0, 0.12132328748703003), (8, 0.1323065534234047), (16, 0.16217881254851818), (12, 0.16267304122447968), (10, 0.1784461047500372), (5, 0.21896063722670078), (36, 0.5816217139363289), (18, 0.6500382274389267), (53, 1.0119911581277847)]
computing accuracy for after removing block 15 . block score: 0.06730277836322784
removed block 15 current accuracy 0.9426 loss from initial  0.05740000000000001
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.067102. All blocks and scores: [(20, 0.06710190046578646), (37, 0.07112986035645008), (38, 0.0712380250915885), (19, 0.0721228588372469), (51, 0.07237113174051046), (4, 0.07597644906491041), (47, 0.07785379607230425), (52, 0.07937662489712238), (39, 0.08061447739601135), (22, 0.08958714734762907), (9, 0.09157574828714132), (14, 0.09700041823089123), (17, 0.10393983963876963), (6, 0.10919932369142771), (11, 0.1125784907490015), (13, 0.11379587091505527), (2, 0.11432712711393833), (1, 0.11882828641682863), (3, 0.12026041466742754), (0, 0.12132328655570745), (8, 0.1323065496981144), (12, 0.16267304122447968), (10, 0.17844609543681145), (16, 0.18366174213588238), (5, 0.21896063722670078), (36, 0.558351069688797), (18, 0.6304626986384392), (53, 1.0067058131098747)]
computing accuracy for after removing block 20 . block score: 0.06710190046578646
removed block 20 current accuracy 0.9328 loss from initial  0.06720000000000004
since last training loss: 0.020400000000000085 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.068651. All blocks and scores: [(51, 0.06865103635936975), (38, 0.07046188786625862), (19, 0.07212285604327917), (52, 0.07218471448868513), (47, 0.07250223588198423), (4, 0.07597644999623299), (37, 0.07659388985484838), (39, 0.07964661996811628), (22, 0.08478732034564018), (9, 0.09157574642449617), (14, 0.09700042009353638), (17, 0.1039398368448019), (6, 0.10919932276010513), (11, 0.11257849354296923), (13, 0.11379587464034557), (2, 0.11432712525129318), (1, 0.11882828921079636), (3, 0.12026041094213724), (0, 0.1213232958689332), (8, 0.13230655156075954), (12, 0.16267304494976997), (10, 0.1784461047500372), (16, 0.18366173841059208), (5, 0.21896063536405563), (36, 0.5613919049501419), (18, 0.6304626986384392), (53, 0.9944656565785408)]
computing accuracy for after removing block 51 . block score: 0.06865103635936975
removed block 51 current accuracy 0.8956 loss from initial  0.10440000000000005
since last training loss: 0.057600000000000096 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 38, with score 0.070462. All blocks and scores: [(38, 0.0704618887975812), (19, 0.07212285697460175), (47, 0.07250223495066166), (4, 0.07597645092755556), (37, 0.07659388892352581), (52, 0.07925611175596714), (39, 0.07964662089943886), (22, 0.08478731755167246), (9, 0.09157574735581875), (14, 0.09700042009353638), (17, 0.10393983777612448), (6, 0.10919932555407286), (11, 0.11257849168032408), (13, 0.11379587464034557), (2, 0.11432712525129318), (1, 0.11882828641682863), (3, 0.12026041187345982), (0, 0.12132329493761063), (8, 0.13230654783546925), (12, 0.16267303749918938), (10, 0.17844610288739204), (16, 0.18366173841059208), (5, 0.21896063722670078), (36, 0.5613919198513031), (18, 0.630462683737278), (53, 1.1493593454360962)]
computing accuracy for after removing block 38 . block score: 0.0704618887975812
removed block 38 current accuracy 0.8636 loss from initial  0.13639999999999997
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 19, with score 0.072123. All blocks and scores: [(19, 0.07212285697460175), (47, 0.0726512810215354), (4, 0.07597644813358784), (37, 0.07659389078617096), (52, 0.07721121981739998), (22, 0.08478731848299503), (9, 0.0915757417678833), (39, 0.09399218577891588), (14, 0.09700042102485895), (17, 0.10393983405083418), (6, 0.10919932462275028), (11, 0.11257849540561438), (13, 0.113795873709023), (2, 0.11432712525129318), (1, 0.11882828269153833), (3, 0.12026041373610497), (0, 0.12132329307496548), (8, 0.13230654783546925), (12, 0.16267304122447968), (10, 0.1784461010247469), (16, 0.18366173841059208), (5, 0.21896064281463623), (36, 0.5613919198513031), (18, 0.6304627060890198), (53, 1.1765791922807693)]
computing accuracy for after removing block 19 . block score: 0.07212285697460175
removed block 19 current accuracy 0.8254 loss from initial  0.17459999999999998
since last training loss: 0.12780000000000002 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.070293. All blocks and scores: [(47, 0.07029327284544706), (52, 0.07258640322834253), (4, 0.07597644533962011), (37, 0.0820271410048008), (22, 0.08280191663652658), (9, 0.09157574642449617), (39, 0.09475765191018581), (14, 0.09700042195618153), (17, 0.1039398368448019), (6, 0.10919931996613741), (11, 0.1125784944742918), (13, 0.1137958774343133), (2, 0.11432712338864803), (1, 0.11882828734815121), (3, 0.12026041094213724), (0, 0.12132329400628805), (8, 0.1323065459728241), (12, 0.16267303749918938), (10, 0.17844609916210175), (16, 0.18366173654794693), (5, 0.21896063163876534), (36, 0.5613774210214615), (18, 0.6304626911878586), (53, 1.1613657176494598)]
computing accuracy for after removing block 47 . block score: 0.07029327284544706
removed block 47 current accuracy 0.7382 loss from initial  0.26180000000000003
since last training loss: 0.21500000000000008 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 4, with score 0.075976. All blocks and scores: [(4, 0.07597645092755556), (37, 0.0820271410048008), (22, 0.08280191570520401), (52, 0.08378005400300026), (9, 0.09157574456185102), (39, 0.09475765377283096), (14, 0.0970004228875041), (17, 0.10393983498215675), (6, 0.10919932182878256), (11, 0.11257849354296923), (13, 0.11379587464034557), (2, 0.11432712525129318), (1, 0.11882828827947378), (3, 0.12026041280478239), (0, 0.12132329400628805), (8, 0.1323065496981144), (12, 0.16267304122447968), (10, 0.1784461010247469), (16, 0.18366173841059208), (5, 0.21896063536405563), (36, 0.5613774284720421), (18, 0.6304626911878586), (53, 1.172084555029869)]
computing accuracy for after removing block 4 . block score: 0.07597645092755556
removed block 4 current accuracy 0.715 loss from initial  0.28500000000000003
since last training loss: 0.23820000000000008 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 22, with score 0.082292. All blocks and scores: [(22, 0.08229183219373226), (37, 0.0834019873291254), (52, 0.08556701056659222), (9, 0.09345350321382284), (39, 0.09643756691366434), (14, 0.09764984250068665), (17, 0.10198577400296926), (11, 0.10819152276962996), (13, 0.11327927373349667), (2, 0.11432712711393833), (1, 0.11882828548550606), (3, 0.12026041001081467), (0, 0.12132329121232033), (6, 0.1264891941100359), (8, 0.1364597138017416), (12, 0.15733054652810097), (16, 0.1659163348376751), (10, 0.1772022508084774), (5, 0.23546656034886837), (36, 0.5721691101789474), (18, 0.6418788284063339), (53, 1.12632155418396)]
computing accuracy for after removing block 22 . block score: 0.08229183219373226
removed block 22 current accuracy 0.5972 loss from initial  0.40280000000000005
training start
training epoch 0 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best True lr [0.1]
training epoch 1 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 2 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best True lr [0.1]
training epoch 3 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 4 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.1]
training epoch 5 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 6 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 7 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 8 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 9 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 10 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.935000)
finished training. finished 50 epochs. accuracy 0.935 topk_dict {'top1': 0.935}
