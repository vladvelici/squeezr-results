start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050630427897), (30, 0.010039400542154908), (31, 0.010361600201576948), (34, 0.01331227645277977), (29, 0.013541154330596328), (35, 0.01601846283301711), (26, 0.01603759080171585), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020232456969097257), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.02237953501753509), (41, 0.0228266476187855), (44, 0.023395079420879483), (40, 0.02402502507902682), (45, 0.024295410374179482), (21, 0.024924597702920437), (22, 0.025168768130242825), (48, 0.02534125908277929), (24, 0.025899536907672882), (50, 0.026409973157569766), (42, 0.026674100663512945), (20, 0.026859006844460964), (49, 0.027037164196372032), (47, 0.029306468088179827), (39, 0.031570712802931666), (38, 0.03163787117227912), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.04173417296260595), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.0686293737962842), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.10667387209832668), (36, 0.43757999688386917), (18, 0.5108213052153587), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.010361600085161626), (34, 0.013133947271853685), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169288894161582), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020072476472705603), (46, 0.02073138509877026), (25, 0.021972602931782603), (41, 0.02234709309414029), (23, 0.022379535483196378), (44, 0.023235687520354986), (40, 0.0238410672172904), (45, 0.02396554220467806), (48, 0.02491791662760079), (21, 0.024924597470089793), (22, 0.025168768595904112), (50, 0.02584081282839179), (24, 0.025899537838995457), (42, 0.026315323309972882), (49, 0.02665567514486611), (20, 0.026859007077291608), (47, 0.028728797333315015), (39, 0.0313176428899169), (38, 0.031380362808704376), (15, 0.03192339185625315), (7, 0.032285444904118776), (19, 0.03262859582901001), (37, 0.038025843910872936), (51, 0.041223939042538404), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722427926957607), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734145730734), (52, 0.06745155062526464), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387582361698), (36, 0.43538710474967957), (18, 0.5108212977647781), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.01276523305568844), (29, 0.013541154330596328), (35, 0.015992751345038414), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020075131906196475), (46, 0.02084140619263053), (25, 0.02197260269895196), (41, 0.02231976669281721), (23, 0.022379535483196378), (44, 0.023154049646109343), (40, 0.023885683389380574), (45, 0.024071689695119858), (48, 0.02487746486440301), (21, 0.024924598168581724), (22, 0.025168768595904112), (50, 0.025691177928820252), (24, 0.0258995380718261), (42, 0.026123747928068042), (49, 0.026479421881958842), (20, 0.02685900731012225), (47, 0.028693132800981402), (38, 0.031236796407029033), (39, 0.03129529161378741), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628594897687435), (37, 0.038376690819859505), (51, 0.04111403413116932), (9, 0.043401877861469984), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.060956849716603756), (0, 0.06300980783998966), (1, 0.06676734238862991), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.43640001118183136), (18, 0.5108212977647781), (53, 0.8289348855614662)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372017733753), (34, 0.012387837283313274), (29, 0.013541154912672937), (35, 0.01600809581577778), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.020704444497823715), (25, 0.02197260269895196), (41, 0.022253197617828846), (23, 0.022379535483196378), (44, 0.02326776133850217), (40, 0.024013880640268326), (45, 0.024092993000522256), (48, 0.024665281176567078), (21, 0.024924597702920437), (22, 0.025168768363073468), (50, 0.02545973425731063), (42, 0.02565571293234825), (24, 0.02589953667484224), (49, 0.026287755696102977), (20, 0.026859006378799677), (47, 0.028363423887640238), (38, 0.031047646887600422), (39, 0.03138077165931463), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340187832713127), (6, 0.046609030570834875), (4, 0.04749368270859122), (14, 0.047836633399128914), (2, 0.05454846937209368), (3, 0.05722428020089865), (13, 0.05892290407791734), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.0630098101682961), (52, 0.0658631594851613), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667386744171381), (36, 0.4389924630522728), (18, 0.5108213052153587), (53, 0.8391561359167099)]
computing accuracy for after removing block 31 . block score: 0.010375372017733753
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489620014093816), (29, 0.013541154330596328), (26, 0.016037590568885207), (35, 0.01605736301280558), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020049349637702107), (46, 0.020552987465634942), (25, 0.021972603164613247), (41, 0.022067483281716704), (23, 0.02237953571602702), (44, 0.02297913283109665), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.02438612305559218), (21, 0.02492459723725915), (50, 0.02504224143922329), (22, 0.02516876789741218), (42, 0.025414507603272796), (49, 0.025842698058113456), (24, 0.025899537140503526), (20, 0.026859007077291608), (47, 0.02805073536001146), (38, 0.03104006010107696), (39, 0.0315008033066988), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.039112847764045), (51, 0.04024627385661006), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980970263481), (52, 0.06486208969727159), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.438127838075161), (18, 0.5108213052153587), (53, 0.8458427935838699)]
computing accuracy for after removing block 34 . block score: 0.012489620014093816
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.016037590336054564), (35, 0.016653419937938452), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020503456238657236), (46, 0.020725322188809514), (25, 0.021972602931782603), (23, 0.022379535250365734), (41, 0.022452629171311855), (44, 0.02336447359994054), (48, 0.0242903558537364), (45, 0.02443871251307428), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.02504217275418341), (22, 0.025168768130242825), (49, 0.025875971419736743), (24, 0.025899537838995457), (42, 0.026205406989902258), (20, 0.026859007542952895), (47, 0.028178582666441798), (15, 0.03192339092493057), (38, 0.03208350110799074), (7, 0.032285446766763926), (39, 0.03233744157478213), (19, 0.032628596760332584), (51, 0.03994725877419114), (37, 0.04073968390002847), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.057224278803914785), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300980551168323), (52, 0.0643363050185144), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.45053430274128914), (18, 0.5108212977647781), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 1 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 2 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best False lr [0.1]
training epoch 3 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.1]
training epoch 4 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 7 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 9 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 10 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470607602968812), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020046866731718183), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.02302833693102002), (48, 0.023771876469254494), (40, 0.023930813651531935), (45, 0.024178662803024054), (50, 0.024390298640355468), (21, 0.024924597702920437), (22, 0.025168768595904112), (42, 0.02518825070001185), (49, 0.025361529318615794), (24, 0.025899536907672882), (20, 0.026859007077291608), (47, 0.02736327867023647), (38, 0.031365618808194995), (15, 0.03192339139059186), (39, 0.03212768537923694), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03893592348322272), (37, 0.040206344332545996), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.060956848319619894), (52, 0.06232855236157775), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.07467832043766975), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4444201961159706), (18, 0.5108212977647781), (53, 0.8537912294268608)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366378642619), (28, 0.01708850055001676), (27, 0.01888244692236185), (43, 0.019595166202634573), (46, 0.020073581486940384), (41, 0.020961584988981485), (25, 0.02197260339744389), (23, 0.02237953571602702), (44, 0.022814956726506352), (48, 0.023128160275518894), (40, 0.023345195688307285), (50, 0.023756146663799882), (42, 0.023847303120419383), (45, 0.023873880272731185), (21, 0.024924597702920437), (49, 0.024960316251963377), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.026855542324483395), (20, 0.02685900661163032), (38, 0.030424014665186405), (39, 0.03151404415257275), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.037824880331754684), (37, 0.03936835238710046), (9, 0.04340188158676028), (6, 0.046609032433480024), (4, 0.047493682242929935), (14, 0.047836633399128914), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249129611998796), (52, 0.06033281935378909), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4360685460269451), (18, 0.5108213126659393), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366378642619
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945251137018), (27, 0.01888244692236185), (46, 0.01916008535772562), (41, 0.019424294820055366), (48, 0.021467272425070405), (25, 0.021972603164613247), (44, 0.022026916034519672), (40, 0.022179660387337208), (42, 0.0222064305562526), (50, 0.022256129421293736), (23, 0.022379535250365734), (45, 0.022931481478735805), (49, 0.02370851207524538), (21, 0.02492459793575108), (22, 0.02516876789741218), (47, 0.025829139398410916), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.028956546681001782), (39, 0.029667828232049942), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.03600902669131756), (37, 0.03651238698512316), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846564680338), (52, 0.0561072863638401), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.0592491258867085), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4175764434039593), (18, 0.5108212903141975), (53, 0.9117144420742989)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.018882447388023138), (48, 0.020903733791783452), (42, 0.02143200417049229), (40, 0.02183242072351277), (44, 0.021840531146153808), (50, 0.021869863849133253), (25, 0.02197260269895196), (23, 0.02237953501753509), (45, 0.02249284856952727), (49, 0.02312349807471037), (21, 0.024924598867073655), (47, 0.02506713941693306), (22, 0.025168767431750894), (24, 0.025899535976350307), (20, 0.026859007077291608), (38, 0.028114068787544966), (39, 0.029206908773630857), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03545433608815074), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.05454846424981952), (52, 0.054696456994861364), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979078710079), (18, 0.5108212903141975), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.01888244622386992), (46, 0.019302030559629202), (42, 0.02143200347200036), (48, 0.02154484367929399), (40, 0.021832421654835343), (50, 0.021946268621832132), (25, 0.021972602931782603), (23, 0.022379535250365734), (49, 0.023006869945675135), (44, 0.023108510533347726), (45, 0.023535606684163213), (21, 0.024924597470089793), (22, 0.02516876789741218), (47, 0.0258204466663301), (24, 0.025899537140503526), (20, 0.02685900661163032), (38, 0.028114069486036897), (39, 0.029206909239292145), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.035091488622128963), (37, 0.03597764018923044), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05332903005182743), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.060956846456974745), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 0.9678283929824829)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.019070088863372803), (48, 0.020678168162703514), (50, 0.021344397449865937), (40, 0.021832421189174056), (25, 0.02197260339744389), (42, 0.021986940409988165), (23, 0.022379535483196378), (49, 0.02253474877215922), (45, 0.023929917253553867), (44, 0.02405400318093598), (21, 0.024924598401412368), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.02604393707588315), (20, 0.026859007077291608), (38, 0.028114069486036897), (39, 0.02920690830796957), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.03379447991028428), (37, 0.03597763832658529), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.05047609517350793), (2, 0.05454846424981952), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300981156527996), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 1 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 2 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 3 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 4 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 5 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 6 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 7 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 8 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.1]
training epoch 9 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 10 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.01998970750719309), (50, 0.020775061566382647), (40, 0.021085952874273062), (42, 0.021369647700339556), (49, 0.021910030161961913), (25, 0.021972603164613247), (23, 0.02237953571602702), (44, 0.023239312693476677), (45, 0.023585308576002717), (21, 0.024924598401412368), (47, 0.02507694880478084), (22, 0.025168768130242825), (24, 0.025899537140503526), (20, 0.026859006378799677), (38, 0.027183361118659377), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.0328142608050257), (37, 0.03542024502530694), (9, 0.04340187879279256), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.04852363187819719), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233878791332), (18, 0.5108212903141975), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560370787978), (50, 0.02083116164430976), (40, 0.02108595333993435), (42, 0.021369647001847625), (25, 0.021972602233290672), (23, 0.022379535948857665), (49, 0.0225369893014431), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.02492459653876722), (22, 0.025168768595904112), (24, 0.02589953737333417), (47, 0.026583049213513732), (20, 0.02685900731012225), (38, 0.02718336065299809), (39, 0.02858075825497508), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.03285081218928099), (37, 0.035420242697000504), (9, 0.043401879258453846), (6, 0.04660903010517359), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.04812479764223099), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560370787978
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647700339556), (25, 0.02197260269895196), (23, 0.022379535250365734), (50, 0.022470062831416726), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924597702920437), (22, 0.025168768595904112), (49, 0.025234101805835962), (24, 0.025899537606164813), (47, 0.02658304967917502), (20, 0.026859007542952895), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.03296921215951443), (37, 0.035420244093984365), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.05089045129716396), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.0904204910621047), (5, 0.10667387302964926), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.266390934586525)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868073567748), (50, 0.021284765796735883), (25, 0.021972602466121316), (23, 0.022379535948857665), (45, 0.02309831720776856), (44, 0.024240857688710093), (49, 0.02450086921453476), (21, 0.02492459863424301), (22, 0.025168768828734756), (24, 0.025899537838995457), (47, 0.026519698556512594), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.028580759186297655), (15, 0.03192339139059186), (51, 0.03222084790468216), (7, 0.0322854476980865), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.048857572954148054), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828325599432), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.4065233841538429), (18, 0.5108212903141975), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.02096868073567748
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658535912633), (25, 0.021972603164613247), (23, 0.02237953571602702), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.02471218234859407), (21, 0.02492459723725915), (22, 0.025168768828734756), (24, 0.025899537140503526), (47, 0.026220475556328893), (20, 0.02685900661163032), (38, 0.027183361118659377), (39, 0.02858075895346701), (51, 0.03127906727604568), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340187972411513), (52, 0.046101709362119436), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846331849694), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.4065233916044235), (18, 0.5108212903141975), (53, 1.417823389172554)]
computing accuracy for after removing block 50 . block score: 0.021202658535912633
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602233290672), (23, 0.02237953571602702), (45, 0.023761966032907367), (49, 0.02460233843885362), (44, 0.02471218165010214), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537140503526), (47, 0.026220474625006318), (20, 0.026859008008614182), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.03344302112236619), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.05265179416164756), (2, 0.054548466112464666), (3, 0.05722427926957607), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108212903141975), (53, 1.6287681460380554)]
computing accuracy for after removing block 25 . block score: 0.021972602233290672
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 1 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 2 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 3 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 4 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 7 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 8 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 9 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 10 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.966000)
finished training. finished 50 epochs. accuracy 0.966 topk_dict {'top1': 0.966}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.044149. All blocks and scores: [(49, 0.044148636516183615), (45, 0.05090450122952461), (44, 0.051135056652128696), (21, 0.051400866359472275), (20, 0.05538939358666539), (23, 0.05545015260577202), (15, 0.05545034632086754), (22, 0.05551149370148778), (19, 0.056543771643191576), (47, 0.05674353754147887), (38, 0.05869278637692332), (51, 0.059996760450303555), (7, 0.06015980523079634), (24, 0.06058013252913952), (39, 0.0633233105763793), (37, 0.0653805136680603), (52, 0.06924530677497387), (4, 0.0767863355576992), (6, 0.08403167687356472), (9, 0.08640736527740955), (14, 0.09139309450984001), (2, 0.09600836876779795), (0, 0.10306585300713778), (13, 0.10620404407382011), (11, 0.10939652193337679), (17, 0.11091583967208862), (3, 0.11217526532709599), (1, 0.11833239533007145), (8, 0.11942598596215248), (12, 0.14134107902646065), (10, 0.14825128018856049), (16, 0.15816724300384521), (5, 0.18382298573851585), (36, 0.6302609816193581), (18, 0.6963853538036346), (53, 1.0093233212828636)]
computing accuracy for after removing block 49 . block score: 0.044148636516183615
removed block 49 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.050905. All blocks and scores: [(45, 0.05090450122952461), (44, 0.05113505758345127), (21, 0.05140086496248841), (20, 0.05538939451798797), (23, 0.055450151674449444), (15, 0.05545034306123853), (22, 0.05551149370148778), (19, 0.05654377304017544), (47, 0.05674353847280145), (38, 0.05869278870522976), (7, 0.06015980336815119), (24, 0.060580134857445955), (51, 0.0622858009301126), (39, 0.0633233105763793), (37, 0.06538051459938288), (52, 0.07584385946393013), (4, 0.07678633369505405), (6, 0.08403167687356472), (9, 0.08640736807137728), (14, 0.09139309544116259), (2, 0.09600837156176567), (0, 0.1030658520758152), (13, 0.10620404686778784), (11, 0.10939652658998966), (17, 0.11091584246605635), (3, 0.11217526998370886), (1, 0.11833239626139402), (8, 0.11942598968744278), (12, 0.14134108275175095), (10, 0.14825127460062504), (16, 0.15816724486649036), (5, 0.18382299318909645), (36, 0.6302609816193581), (18, 0.6963853240013123), (53, 1.1158586293458939)]
computing accuracy for after removing block 45 . block score: 0.05090450122952461
removed block 45 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.051135. All blocks and scores: [(44, 0.051135056652128696), (21, 0.051400866359472275), (20, 0.05538939079269767), (23, 0.05545015214011073), (15, 0.0554503439925611), (22, 0.05551149323582649), (19, 0.056543771643191576), (38, 0.05869278637692332), (51, 0.06015319237485528), (7, 0.060159807093441486), (24, 0.06058013346046209), (47, 0.06291053770110011), (39, 0.0633233105763793), (37, 0.06538051646202803), (4, 0.07678633369505405), (52, 0.07808268163353205), (6, 0.08403167873620987), (9, 0.0864073671400547), (14, 0.09139309450984001), (2, 0.09600836876779795), (0, 0.10306585300713778), (13, 0.10620404500514269), (11, 0.10939652100205421), (17, 0.11091583874076605), (3, 0.11217526998370886), (1, 0.11833239626139402), (8, 0.11942598782479763), (12, 0.14134108275175095), (10, 0.14825128018856049), (16, 0.15816724114120007), (5, 0.18382299691438675), (36, 0.6302609816193581), (18, 0.6963853389024734), (53, 1.2340031266212463)]
computing accuracy for after removing block 44 . block score: 0.051135056652128696
removed block 44 current accuracy 0.9292 loss from initial  0.07079999999999997
since last training loss: 0.036799999999999944 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.051401. All blocks and scores: [(21, 0.0514008654281497), (20, 0.055389393121004105), (23, 0.055450151208788157), (15, 0.05545034445822239), (22, 0.05551149323582649), (19, 0.05654377397149801), (38, 0.05869278684258461), (51, 0.05881074443459511), (7, 0.060159807093441486), (24, 0.060580136720091105), (39, 0.06332331150770187), (37, 0.06538051459938288), (47, 0.06909222062677145), (4, 0.0767863318324089), (52, 0.07806663867086172), (6, 0.08403167594224215), (9, 0.08640736900269985), (14, 0.09139309450984001), (2, 0.09600836876779795), (0, 0.10306585114449263), (13, 0.10620404127985239), (11, 0.10939652007073164), (17, 0.1109158368781209), (3, 0.11217526998370886), (1, 0.11833239533007145), (8, 0.11942598316818476), (12, 0.14134108275175095), (10, 0.14825127832591534), (16, 0.15816723741590977), (5, 0.1838229913264513), (36, 0.6302609890699387), (18, 0.6963853612542152), (53, 1.313331738114357)]
computing accuracy for after removing block 21 . block score: 0.0514008654281497
removed block 21 current accuracy 0.922 loss from initial  0.07799999999999996
since last training loss: 0.04399999999999993 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.049496. All blocks and scores: [(22, 0.0494956998154521), (23, 0.049525439739227295), (24, 0.05368276173248887), (20, 0.055389393121004105), (15, 0.055450345389544964), (51, 0.05605222703889012), (38, 0.05626235483214259), (19, 0.056543773505836725), (7, 0.060159807093441486), (39, 0.06148509727790952), (37, 0.06302803847938776), (47, 0.06450673006474972), (52, 0.071415850892663), (4, 0.07678633462637663), (6, 0.08403167966753244), (9, 0.08640736807137728), (14, 0.09139309450984001), (2, 0.09600837156176567), (0, 0.1030658558011055), (13, 0.10620404593646526), (11, 0.10939652007073164), (17, 0.1109158368781209), (3, 0.11217526812106371), (1, 0.1183323971927166), (8, 0.11942598596215248), (12, 0.14134108275175095), (10, 0.14825127832591534), (16, 0.15816724486649036), (5, 0.18382298201322556), (36, 0.5968771204352379), (18, 0.6963853165507317), (53, 1.3316324651241302)]
computing accuracy for after removing block 22 . block score: 0.0494956998154521
removed block 22 current accuracy 0.9032 loss from initial  0.0968
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.046746. All blocks and scores: [(23, 0.04674578132107854), (24, 0.05026116408407688), (51, 0.0542085194028914), (20, 0.05538939218968153), (15, 0.055450344923883677), (19, 0.05654377210885286), (38, 0.05655819131061435), (7, 0.060159807559102774), (39, 0.06063412968069315), (47, 0.060942477080971), (37, 0.06757824681699276), (52, 0.06833826005458832), (4, 0.07678633462637663), (6, 0.08403168246150017), (9, 0.08640737179666758), (14, 0.09139309357851744), (2, 0.0960083706304431), (0, 0.1030658558011055), (13, 0.10620404593646526), (11, 0.10939652100205421), (17, 0.11091583780944347), (3, 0.11217526625841856), (1, 0.11833239626139402), (8, 0.11942598968744278), (12, 0.1413410808891058), (10, 0.14825127460062504), (16, 0.15816724114120007), (5, 0.18382299318909645), (36, 0.6059630364179611), (18, 0.6963853314518929), (53, 1.324240118265152)]
computing accuracy for after removing block 23 . block score: 0.04674578132107854
removed block 23 current accuracy 0.8742 loss from initial  0.12580000000000002
since last training loss: 0.09179999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.050160. All blocks and scores: [(24, 0.05016009509563446), (51, 0.05353139666840434), (20, 0.055389394983649254), (15, 0.05545034585520625), (19, 0.05654377257451415), (38, 0.058807745575904846), (7, 0.06015980802476406), (47, 0.060890733264386654), (39, 0.06229815864935517), (52, 0.07043539639562368), (37, 0.07572756242007017), (4, 0.07678633462637663), (6, 0.08403167687356472), (9, 0.08640736993402243), (14, 0.09139309544116259), (2, 0.09600836783647537), (0, 0.10306585486978292), (13, 0.10620404127985239), (11, 0.10939652286469936), (17, 0.11091583780944347), (3, 0.11217527277767658), (1, 0.11833239533007145), (8, 0.11942598689347506), (12, 0.1413410771638155), (10, 0.14825127460062504), (16, 0.15816724114120007), (5, 0.18382298946380615), (36, 0.640264630317688), (18, 0.6963853389024734), (53, 1.3104182481765747)]
computing accuracy for after removing block 24 . block score: 0.05016009509563446
removed block 24 current accuracy 0.832 loss from initial  0.16800000000000004
since last training loss: 0.134 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.050461. All blocks and scores: [(51, 0.05046123173087835), (20, 0.055389393121004105), (15, 0.055450343526899815), (47, 0.05593818565830588), (19, 0.05654377210885286), (38, 0.057546986266970634), (39, 0.05927485087886453), (7, 0.060159807093441486), (52, 0.06587864924222231), (4, 0.07678633369505405), (37, 0.07728678826242685), (6, 0.0840316778048873), (9, 0.08640736807137728), (14, 0.09139309544116259), (2, 0.09600836876779795), (0, 0.10306585486978292), (13, 0.10620404686778784), (11, 0.10939652472734451), (17, 0.11091583874076605), (3, 0.11217526718974113), (1, 0.11833239905536175), (8, 0.1194259887561202), (12, 0.1413410808891058), (10, 0.14825128018856049), (16, 0.15816724300384521), (5, 0.1838229950517416), (36, 0.6390040293335915), (18, 0.6963853538036346), (53, 1.296279326081276)]
computing accuracy for after removing block 51 . block score: 0.05046123173087835
removed block 51 current accuracy 0.7568 loss from initial  0.24319999999999997
since last training loss: 0.20919999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.055389. All blocks and scores: [(20, 0.05538939591497183), (15, 0.055450345389544964), (47, 0.05593818658962846), (19, 0.05654377304017544), (38, 0.057546986266970634), (39, 0.05927485041320324), (7, 0.060159805696457624), (52, 0.07111689541488886), (4, 0.0767863355576992), (37, 0.07728678733110428), (6, 0.0840316778048873), (9, 0.08640736807137728), (14, 0.09139309544116259), (2, 0.0960083706304431), (0, 0.1030658520758152), (13, 0.10620404873043299), (11, 0.10939652007073164), (17, 0.11091583594679832), (3, 0.11217526905238628), (1, 0.11833239812403917), (8, 0.11942598782479763), (12, 0.1413410846143961), (10, 0.1482512764632702), (16, 0.15816724300384521), (5, 0.18382298946380615), (36, 0.6390040293335915), (18, 0.6963853538036346), (53, 1.3753157407045364)]
computing accuracy for after removing block 20 . block score: 0.05538939591497183
removed block 20 current accuracy 0.7452 loss from initial  0.2548
training start
training epoch 0 val accuracy 0.847 topk_dict {'top1': 0.847} is_best True lr [0.1]
training epoch 1 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.1]
training epoch 2 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.1]
training epoch 3 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 5 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 6 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 7 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 8 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.1]
training epoch 9 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.949600)
finished training. finished 50 epochs. accuracy 0.9496 topk_dict {'top1': 0.9496}
