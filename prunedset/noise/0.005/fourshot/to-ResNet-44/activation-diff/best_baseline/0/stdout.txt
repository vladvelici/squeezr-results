start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996322590858), (32, 0.009233050630427897), (30, 0.010039400309324265), (31, 0.01036160031799227), (34, 0.01331227587070316), (29, 0.013541154563426971), (35, 0.016018463065847754), (26, 0.016037590336054564), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.0202324572019279), (46, 0.021044540917500854), (25, 0.021972602466121316), (23, 0.02237953571602702), (41, 0.022826647851616144), (44, 0.02339507918804884), (40, 0.024025025544688106), (45, 0.02429541083984077), (21, 0.024924598168581724), (22, 0.025168768595904112), (48, 0.025341259548440576), (24, 0.025899537140503526), (50, 0.026409971760585904), (42, 0.02667409973219037), (20, 0.02685900777578354), (49, 0.02703716536052525), (47, 0.02930646948516369), (39, 0.031570713268592954), (38, 0.03163787163794041), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03796026110649109), (51, 0.041734172496944666), (9, 0.04340187972411513), (6, 0.04660903289914131), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734145730734), (52, 0.06862937565892935), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43757999688386917), (18, 0.5108213052153587), (53, 0.8211488947272301)]
computing accuracy for after removing block 33 . block score: 0.007061996322590858
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400425739586), (31, 0.010361600085161626), (34, 0.013133947039023042), (29, 0.013541155029088259), (26, 0.01603759080171585), (35, 0.016169289592653513), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020072477171197534), (46, 0.020731385797262192), (25, 0.021972602466121316), (41, 0.022347092628479004), (23, 0.02237953571602702), (44, 0.023235687986016273), (40, 0.023841067450121045), (45, 0.023965542437508702), (48, 0.024917915929108858), (21, 0.024924598867073655), (22, 0.025168769527226686), (50, 0.025840813759714365), (24, 0.02589953667484224), (42, 0.026315323309972882), (49, 0.026655674213543534), (20, 0.02685900661163032), (47, 0.02872879756614566), (39, 0.031317641492933035), (38, 0.03138036374002695), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.038025844376534224), (51, 0.04122393950819969), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846704378724), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980783998966), (1, 0.06676734238862991), (52, 0.06745155155658722), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.0904204910621047), (5, 0.10667386837303638), (36, 0.43538710474967957), (18, 0.5108212977647781), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.01036159973591566), (34, 0.012765232473611832), (29, 0.013541154563426971), (35, 0.015992751345038414), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.019127049250528216), (43, 0.02007513213902712), (46, 0.020841406425461173), (25, 0.021972602931782603), (41, 0.022319767624139786), (23, 0.022379534784704447), (44, 0.023154050344601274), (40, 0.02388568432070315), (45, 0.024071689695119858), (48, 0.02487746556289494), (21, 0.02492459793575108), (22, 0.025168767431750894), (50, 0.025691178161650896), (24, 0.02589953737333417), (42, 0.026123747928068042), (49, 0.026479422813281417), (20, 0.026859008241444826), (47, 0.02869313210248947), (38, 0.03123679617419839), (39, 0.031295291846618056), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.032628594897687435), (37, 0.038376690819859505), (51, 0.04111403273418546), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922902680933475), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734238862991), (52, 0.06700456328690052), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.43640001118183136), (18, 0.5108212977647781), (53, 0.8289348855614662)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372250564396), (34, 0.01238783705048263), (29, 0.013541154563426971), (35, 0.016008096048608422), (26, 0.016037591034546494), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.020083633717149496), (46, 0.020704444497823715), (25, 0.021972602466121316), (41, 0.022253196919336915), (23, 0.022379535250365734), (44, 0.02326776133850217), (40, 0.024013880640268326), (45, 0.024092993466183543), (48, 0.02466528001241386), (21, 0.024924597702920437), (22, 0.02516876719892025), (50, 0.025459734722971916), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.026287756161764264), (20, 0.02685900731012225), (47, 0.028363423654809594), (38, 0.031047646887600422), (39, 0.031380771892145276), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.038971245754510164), (51, 0.040756203699857), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548466578125954), (3, 0.05722427600994706), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980970263481), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4389924593269825), (18, 0.5108212977647781), (53, 0.8391561359167099)]
computing accuracy for after removing block 31 . block score: 0.010375372250564396
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154796257615), (26, 0.016037591034546494), (35, 0.01605736301280558), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020049350103363395), (46, 0.0205529872328043), (25, 0.021972602233290672), (41, 0.02206748374737799), (23, 0.02237953571602702), (44, 0.02297913283109665), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.02438612305559218), (21, 0.024924597470089793), (50, 0.02504224143922329), (22, 0.025168767664581537), (42, 0.025414508068934083), (49, 0.025842699222266674), (24, 0.025899536907672882), (20, 0.026859007542952895), (47, 0.028050734428688884), (38, 0.03104005940258503), (39, 0.031500803073868155), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.039112848695367575), (51, 0.04024627339094877), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980783998966), (52, 0.06486208830028772), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.438127838075161), (18, 0.5108212977647781), (53, 0.845842756330967)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.016037590568885207), (35, 0.016653420869261026), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020503456238657236), (46, 0.02072532312013209), (25, 0.021972602931782603), (23, 0.02237953571602702), (41, 0.02245262893848121), (44, 0.023364474531263113), (48, 0.024290355388075113), (45, 0.024438713444396853), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.02504217205569148), (22, 0.025168768363073468), (49, 0.025875971419736743), (24, 0.02589953737333417), (42, 0.02620540652424097), (20, 0.02685900777578354), (47, 0.028178582666441798), (15, 0.03192339092493057), (38, 0.032083500642329454), (7, 0.03228544723242521), (39, 0.03233744157478213), (19, 0.03262859536334872), (51, 0.03994725877419114), (37, 0.04073968390002847), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980923697352), (52, 0.06433630269020796), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.45053430274128914), (18, 0.5108212977647781), (53, 0.84432003647089)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470607835799456), (28, 0.01772867515683174), (27, 0.019127049017697573), (43, 0.02004686719737947), (46, 0.020376994041725993), (41, 0.021723243175074458), (25, 0.021972602233290672), (23, 0.022379535483196378), (44, 0.023028336698189378), (48, 0.02377187623642385), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.024390297709032893), (21, 0.024924597470089793), (22, 0.025168768130242825), (42, 0.025188251631334424), (49, 0.02536152978427708), (24, 0.025899536442011595), (20, 0.02685900731012225), (47, 0.02736328006722033), (38, 0.03136561904102564), (15, 0.03192339185625315), (39, 0.03212768444791436), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.03893592348322272), (37, 0.04020634340122342), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924913100898266), (17, 0.06095685018226504), (52, 0.0623285504989326), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4444201961159706), (18, 0.5108212977647781), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500782847404), (27, 0.01888244692236185), (43, 0.019595165504142642), (46, 0.02007358125410974), (41, 0.020961584988981485), (25, 0.021972602233290672), (23, 0.022379535250365734), (44, 0.02281495649367571), (48, 0.023128160508349538), (40, 0.023345195688307285), (50, 0.023756146896630526), (42, 0.02384730288758874), (45, 0.023873880272731185), (21, 0.024924598401412368), (49, 0.024960316251963377), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.02685554255731404), (20, 0.026859007542952895), (38, 0.030424013268202543), (39, 0.03151404415257275), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03782488126307726), (37, 0.03936835192143917), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.05892289895564318), (11, 0.05924912774935365), (52, 0.06033282168209553), (17, 0.06095684785395861), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049665004015), (5, 0.10667387302964926), (36, 0.4360685497522354), (18, 0.5108212977647781), (53, 0.8749377429485321)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 1 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 2 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 3 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 4 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 5 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 6 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.1]
training epoch 9 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 10 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555945483967662), (27, 0.018882446689531207), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.02146727265790105), (25, 0.021972602931782603), (44, 0.022026916733011603), (40, 0.022179660154506564), (42, 0.022206429857760668), (50, 0.022256129421293736), (23, 0.022379535250365734), (45, 0.022931482177227736), (49, 0.023708512308076024), (21, 0.024924597470089793), (22, 0.02516876789741218), (47, 0.025829139165580273), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.02895654598250985), (39, 0.029667827766388655), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.036009027156978846), (37, 0.03651238791644573), (9, 0.04340187972411513), (6, 0.0466090296395123), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.0545484684407711), (52, 0.056107287760823965), (3, 0.05722428020089865), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.41757645085453987), (18, 0.5108213052153587), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.018882447155192494), (48, 0.020903734490275383), (42, 0.021432004868984222), (40, 0.021832420956343412), (44, 0.021840530447661877), (50, 0.02186986431479454), (25, 0.021972602931782603), (23, 0.022379535948857665), (45, 0.022492848336696625), (49, 0.023123498540371656), (21, 0.02492459793575108), (47, 0.025067139184102416), (22, 0.025168768595904112), (24, 0.02589953737333417), (20, 0.026859006844460964), (38, 0.028114070184528828), (39, 0.029206908540800214), (15, 0.03192339278757572), (7, 0.03228544583544135), (19, 0.032628594897687435), (51, 0.03545433608815074), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903010517359), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846518114209), (52, 0.054696458857506514), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882446689531207), (46, 0.019302030093967915), (42, 0.021432003937661648), (48, 0.021544843213632703), (40, 0.021832421654835343), (50, 0.021946269553154707), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.02300687017850578), (44, 0.02310851076617837), (45, 0.02353560645133257), (21, 0.024924598401412368), (22, 0.025168767664581537), (47, 0.025820446433499455), (24, 0.025899538304656744), (20, 0.026859007542952895), (38, 0.028114069486036897), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03509148769080639), (37, 0.03597763925790787), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.05332903005182743), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667387396097183), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 0.9678283855319023)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008863054216), (48, 0.0206781686283648), (50, 0.021344397449865937), (40, 0.0218324214220047), (25, 0.021972602931782603), (42, 0.021986939711496234), (23, 0.022379535250365734), (49, 0.022534748539328575), (45, 0.02392991678789258), (44, 0.02405400318093598), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.02604393777437508), (20, 0.026859007077291608), (38, 0.028114069253206253), (39, 0.029206908075138927), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03379448037594557), (37, 0.03597763832658529), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05047609377652407), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249130077660084), (17, 0.060956848319619894), (0, 0.06300981109961867), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4135979190468788), (18, 0.5108213052153587), (53, 1.027817964553833)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.01998970820568502), (50, 0.020775062264874578), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.021910030161961913), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.024924598867073655), (47, 0.025076947640627623), (22, 0.025168768595904112), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.027183361118659377), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.0328142608050257), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.04852363048121333), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.05892289895564318), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234065055847), (18, 0.5108213201165199), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.02083116234280169), (40, 0.02108595333993435), (42, 0.021369648166000843), (25, 0.021972602931782603), (23, 0.022379536414518952), (49, 0.0225369893014431), (44, 0.023239311994984746), (45, 0.023585309041664004), (21, 0.024924598168581724), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.02658304967917502), (20, 0.02685900777578354), (38, 0.02718335995450616), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.032850812654942274), (37, 0.03542024362832308), (9, 0.043401877861469984), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.0481247971765697), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.058922899421304464), (11, 0.0592491258867085), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.09042049571871758), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213126659393), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647001847625), (25, 0.02197260269895196), (23, 0.022379535250365734), (50, 0.022470062132924795), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924598401412368), (22, 0.025168768130242825), (49, 0.025234101805835962), (24, 0.025899537606164813), (47, 0.026583049213513732), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.028580758487805724), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03296921169385314), (37, 0.03542024502530694), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663293346763), (52, 0.050890449434518814), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.2663909196853638)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.021284766029566526), (25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.024500868748873472), (21, 0.024924597702920437), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.026519698090851307), (20, 0.026859007077291608), (38, 0.02718335995450616), (39, 0.028580758487805724), (15, 0.031923392321914434), (51, 0.032220848836004734), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.04885757248848677), (2, 0.054548466112464666), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249130077660084), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4065233878791332), (18, 0.5108213126659393), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.1]
training epoch 1 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 2 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 3 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 4 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 5 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 6 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 7 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 8 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 9 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 10 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.966400)
finished training. finished 50 epochs. accuracy 0.9664 topk_dict {'top1': 0.9664}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.041549. All blocks and scores: [(50, 0.04154868610203266), (49, 0.04585581738501787), (45, 0.046467823907732964), (44, 0.047546240501105785), (21, 0.047980389557778835), (23, 0.049765437841415405), (19, 0.05137588130310178), (51, 0.052338728215545416), (47, 0.05236788420006633), (20, 0.05476900935173035), (15, 0.05546042462810874), (7, 0.05557774659246206), (38, 0.055690499022603035), (22, 0.05589721258729696), (25, 0.05729651637375355), (24, 0.06052799476310611), (39, 0.06304351706057787), (52, 0.0668718870729208), (37, 0.07135519664734602), (4, 0.07597033958882093), (9, 0.08264504186809063), (6, 0.08767955284565687), (2, 0.09509088844060898), (14, 0.09545938763767481), (13, 0.1025079246610403), (11, 0.10932612605392933), (3, 0.11076490674167871), (1, 0.11121292877942324), (17, 0.1181370709091425), (0, 0.1194847971200943), (8, 0.12619933299720287), (10, 0.14178635738790035), (12, 0.16410482488572598), (16, 0.1665936354547739), (5, 0.18768894858658314), (36, 0.6644324064254761), (18, 0.7336741834878922), (53, 0.9477431923151016)]
computing accuracy for after removing block 50 . block score: 0.04154868610203266
removed block 50 current accuracy 0.9578 loss from initial  0.042200000000000015
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.045856. All blocks and scores: [(49, 0.04585581738501787), (45, 0.04646782297641039), (44, 0.04754624096676707), (21, 0.047980387695133686), (23, 0.049765437841415405), (19, 0.05137588270008564), (47, 0.05236788559705019), (20, 0.05476901168003678), (15, 0.05546042276546359), (7, 0.05557774705812335), (38, 0.055690499022603035), (22, 0.055897210724651814), (51, 0.05648479284718633), (25, 0.057296514976769686), (24, 0.06052799662575126), (39, 0.06304351706057787), (37, 0.0713551975786686), (4, 0.07597033772617579), (52, 0.07779412064701319), (9, 0.08264504093676805), (6, 0.08767955470830202), (2, 0.0950908875092864), (14, 0.09545938763767481), (13, 0.10250792652368546), (11, 0.10932612884789705), (3, 0.11076490860432386), (1, 0.11121292877942324), (17, 0.11813707184046507), (0, 0.11948479991406202), (8, 0.12619933299720287), (10, 0.1417863592505455), (12, 0.16410482302308083), (16, 0.16659364104270935), (5, 0.18768895603716373), (36, 0.6644323840737343), (18, 0.7336741909384727), (53, 1.0618312507867813)]
computing accuracy for after removing block 49 . block score: 0.04585581738501787
removed block 49 current accuracy 0.9506 loss from initial  0.0494
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.046468. All blocks and scores: [(45, 0.04646782437339425), (44, 0.04754623956978321), (21, 0.04798038816079497), (23, 0.049765437841415405), (19, 0.05137588083744049), (47, 0.0523678851313889), (20, 0.05476901168003678), (15, 0.05546042416244745), (7, 0.055577746126800776), (38, 0.05569050181657076), (22, 0.055897212121635675), (51, 0.05722071276977658), (25, 0.0572965145111084), (24, 0.06052799616008997), (39, 0.06304351473227143), (37, 0.07135519850999117), (4, 0.07597034052014351), (52, 0.08156570512801409), (9, 0.08264504000544548), (6, 0.08767955284565687), (2, 0.09509088657796383), (14, 0.09545938763767481), (13, 0.1025079283863306), (11, 0.1093261269852519), (3, 0.11076490301638842), (1, 0.11121292971074581), (17, 0.11813706811517477), (0, 0.1194848045706749), (8, 0.12619933113455772), (10, 0.14178635738790035), (12, 0.16410482861101627), (16, 0.1665936354547739), (5, 0.18768895231187344), (36, 0.6644323915243149), (18, 0.7336741462349892), (53, 1.0910373777151108)]
computing accuracy for after removing block 45 . block score: 0.04646782437339425
removed block 45 current accuracy 0.9394 loss from initial  0.06059999999999999
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.047546. All blocks and scores: [(44, 0.04754623956978321), (21, 0.04798038862645626), (23, 0.04976543551310897), (19, 0.05137588316574693), (20, 0.054769009817391634), (51, 0.05509240832179785), (15, 0.05546042416244745), (7, 0.055577746126800776), (38, 0.05569050181657076), (22, 0.05589721258729696), (25, 0.05729651730507612), (47, 0.057552363723516464), (24, 0.06052799616008997), (39, 0.0630435161292553), (37, 0.0713551975786686), (4, 0.07597033958882093), (52, 0.08250197302550077), (9, 0.08264504186809063), (6, 0.08767955284565687), (2, 0.0950908875092864), (14, 0.09545938484370708), (13, 0.10250792652368546), (11, 0.1093261232599616), (3, 0.11076490115374327), (1, 0.11121292971074581), (17, 0.11813706625252962), (0, 0.11948480270802975), (8, 0.12619932927191257), (10, 0.1417863555252552), (12, 0.16410482488572598), (16, 0.16659363731741905), (5, 0.1876889504492283), (36, 0.6644323989748955), (18, 0.7336741536855698), (53, 1.142629712820053)]
computing accuracy for after removing block 44 . block score: 0.04754623956978321
removed block 44 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.05260000000000009 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.047980. All blocks and scores: [(21, 0.04798038862645626), (23, 0.04976543877273798), (19, 0.05137588270008564), (51, 0.053555584978312254), (20, 0.054769011214375496), (15, 0.055460425559431314), (7, 0.05557774705812335), (38, 0.055690499022603035), (22, 0.05589721305295825), (25, 0.057296516839414835), (24, 0.06052799569442868), (47, 0.06072063185274601), (39, 0.0630435161292553), (37, 0.07135519571602345), (4, 0.07597033958882093), (52, 0.08128041680902243), (9, 0.08264504186809063), (6, 0.0876795519143343), (2, 0.09509088564664125), (14, 0.09545938856899738), (13, 0.10250792372971773), (11, 0.1093261269852519), (3, 0.11076490301638842), (1, 0.11121292971074581), (17, 0.11813706997781992), (0, 0.11948480363935232), (8, 0.12619932927191257), (10, 0.14178635738790035), (12, 0.16410482116043568), (16, 0.1665936317294836), (5, 0.187688946723938), (36, 0.6644323840737343), (18, 0.7336741909384727), (53, 1.2060792744159698)]
computing accuracy for after removing block 21 . block score: 0.04798038862645626
removed block 21 current accuracy 0.9088 loss from initial  0.09119999999999995
since last training loss: 0.057599999999999985 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.043478. All blocks and scores: [(23, 0.04347765678539872), (22, 0.050458989571779966), (19, 0.05137588270008564), (51, 0.051409557461738586), (25, 0.052181882318109274), (24, 0.05222724750638008), (38, 0.052554982248693705), (20, 0.054769011214375496), (15, 0.05546042509377003), (7, 0.05557774566113949), (47, 0.05684791412204504), (39, 0.060004694387316704), (37, 0.06721462961286306), (52, 0.07249352242797613), (4, 0.07597033865749836), (9, 0.08264504466205835), (6, 0.0876795519143343), (2, 0.09509088844060898), (14, 0.09545938950031996), (13, 0.10250792652368546), (11, 0.10932612791657448), (3, 0.11076490674167871), (1, 0.11121293064206839), (17, 0.11813706532120705), (0, 0.11948480177670717), (8, 0.12619933113455772), (10, 0.1417863592505455), (12, 0.16410481929779053), (16, 0.16659363731741905), (5, 0.187688946723938), (36, 0.6241277232766151), (18, 0.7336741536855698), (53, 1.2638648748397827)]
computing accuracy for after removing block 23 . block score: 0.04347765678539872
removed block 23 current accuracy 0.8966 loss from initial  0.10340000000000005
since last training loss: 0.06980000000000008 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.049451. All blocks and scores: [(24, 0.049451202154159546), (22, 0.050458990037441254), (51, 0.051152232103049755), (19, 0.05137588316574693), (25, 0.05222396459430456), (38, 0.052474717143923044), (20, 0.05476901028305292), (47, 0.05500849615782499), (15, 0.05546042462810874), (7, 0.055577747989445925), (39, 0.06007836852222681), (37, 0.0709068812429905), (52, 0.072256775572896), (4, 0.07597033772617579), (9, 0.08264504093676805), (6, 0.08767955377697945), (2, 0.09509088844060898), (14, 0.09545938950031996), (13, 0.10250792931765318), (11, 0.10932612512260675), (3, 0.11076490394771099), (1, 0.11121293064206839), (17, 0.1181370634585619), (0, 0.11948480363935232), (8, 0.12619933113455772), (10, 0.1417863517999649), (12, 0.16410482116043568), (16, 0.16659363731741905), (5, 0.1876889504492283), (36, 0.6319222152233124), (18, 0.7336741760373116), (53, 1.2406391352415085)]
computing accuracy for after removing block 24 . block score: 0.049451202154159546
removed block 24 current accuracy 0.88 loss from initial  0.12
since last training loss: 0.08640000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 51, with score 0.048097. All blocks and scores: [(51, 0.04809676669538021), (38, 0.05032184440642595), (22, 0.050458991434425116), (19, 0.05137588316574693), (47, 0.05158590991050005), (25, 0.05167582165449858), (20, 0.05476901074871421), (15, 0.05546042416244745), (7, 0.05557774845510721), (39, 0.058397816959768534), (37, 0.06634343229234219), (52, 0.06745165679603815), (4, 0.07597033958882093), (9, 0.08264504093676805), (6, 0.0876795519143343), (2, 0.09509088471531868), (14, 0.09545938950031996), (13, 0.10250792559236288), (11, 0.1093261269852519), (3, 0.11076490581035614), (1, 0.11121292784810066), (17, 0.1181370709091425), (0, 0.11948480550199747), (8, 0.12619933113455772), (10, 0.14178636111319065), (12, 0.16410482302308083), (16, 0.16659363359212875), (5, 0.18768895231187344), (36, 0.6050851866602898), (18, 0.7336741760373116), (53, 1.2555855214595795)]
computing accuracy for after removing block 51 . block score: 0.04809676669538021
removed block 51 current accuracy 0.8188 loss from initial  0.18120000000000003
training start
training epoch 0 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.1]
training epoch 1 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.1]
training epoch 2 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 3 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.1]
training epoch 4 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 5 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 6 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 7 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 8 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 9 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.954600)
finished training. finished 50 epochs. accuracy 0.9546 topk_dict {'top1': 0.9546}
start iteration 24
[activation diff]: block to remove picked: 19, with score 0.070785. All blocks and scores: [(19, 0.07078487239778042), (7, 0.07267570309340954), (38, 0.0726822791621089), (15, 0.0741028618067503), (20, 0.07989127188920975), (37, 0.0800635814666748), (39, 0.0847796443849802), (22, 0.08635665196925402), (47, 0.08697320055216551), (9, 0.09329881239682436), (52, 0.0944138690829277), (25, 0.0958584351465106), (4, 0.09712498169392347), (6, 0.09734294191002846), (14, 0.10480359848588705), (13, 0.1064434265717864), (2, 0.11091356817632914), (11, 0.11159178521484137), (17, 0.12110387440770864), (3, 0.12154339905828238), (1, 0.12260050605982542), (0, 0.1258696485310793), (8, 0.14532597549259663), (12, 0.16129045002162457), (10, 0.16789068281650543), (16, 0.20797453820705414), (5, 0.2292931918054819), (36, 0.5740334615111351), (18, 0.7131920531392097), (53, 1.0565505474805832)]
computing accuracy for after removing block 19 . block score: 0.07078487239778042
removed block 19 current accuracy 0.9466 loss from initial  0.0534
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.071203. All blocks and scores: [(38, 0.07120331097394228), (7, 0.07267570402473211), (20, 0.0737310303375125), (15, 0.07410286366939545), (37, 0.08350246958434582), (39, 0.08363029826432467), (47, 0.0839289678260684), (22, 0.08432701043784618), (52, 0.08855040837079287), (25, 0.08924515824764967), (9, 0.09329881053417921), (4, 0.09712498169392347), (6, 0.0973429437726736), (14, 0.10480359569191933), (13, 0.10644342750310898), (2, 0.11091356538236141), (11, 0.11159178614616394), (17, 0.12110387533903122), (3, 0.12154340092092752), (1, 0.12260050792247057), (0, 0.12586964946240187), (8, 0.14532597176730633), (12, 0.16129044815897942), (10, 0.16789067722856998), (16, 0.207974536344409), (5, 0.22929318994283676), (36, 0.5601722076535225), (18, 0.7131920531392097), (53, 1.0318235233426094)]
computing accuracy for after removing block 38 . block score: 0.07120331097394228
removed block 38 current accuracy 0.9326 loss from initial  0.06740000000000002
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.072676. All blocks and scores: [(7, 0.07267570309340954), (20, 0.0737310266122222), (15, 0.0741028618067503), (37, 0.08350246585905552), (22, 0.08432701043784618), (52, 0.08634782023727894), (47, 0.08709169737994671), (25, 0.08924515545368195), (9, 0.09329881146550179), (4, 0.0971249807626009), (6, 0.09734294191002846), (39, 0.10005471296608448), (14, 0.10480359941720963), (13, 0.10644343122839928), (2, 0.11091356538236141), (11, 0.11159178242087364), (17, 0.12110387347638607), (3, 0.12154340278357267), (1, 0.12260050512850285), (0, 0.12586964946240187), (8, 0.14532597362995148), (12, 0.16129044629633427), (10, 0.16789067722856998), (16, 0.2079745326191187), (5, 0.22929319366812706), (36, 0.5601722002029419), (18, 0.7131920456886292), (53, 1.0798737853765488)]
computing accuracy for after removing block 7 . block score: 0.07267570309340954
removed block 7 current accuracy 0.9246 loss from initial  0.07540000000000002
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.070378. All blocks and scores: [(15, 0.07037804555147886), (20, 0.07111970242112875), (37, 0.07395429071038961), (22, 0.07909751497209072), (52, 0.08283659163862467), (47, 0.08389985747635365), (25, 0.08522896375507116), (9, 0.08867505844682455), (13, 0.09271753765642643), (14, 0.09507470205426216), (4, 0.09712498169392347), (6, 0.0973429437726736), (39, 0.09868753794580698), (17, 0.09950701333582401), (11, 0.10270364303141832), (2, 0.11091356724500656), (3, 0.12154339998960495), (1, 0.12260050512850285), (0, 0.12586964666843414), (12, 0.14438365399837494), (8, 0.1459361184388399), (10, 0.16669254004955292), (16, 0.1898669619113207), (5, 0.22929319739341736), (36, 0.5332940816879272), (18, 0.6873407661914825), (53, 1.0834079682826996)]
computing accuracy for after removing block 15 . block score: 0.07037804555147886
removed block 15 current accuracy 0.9118 loss from initial  0.08819999999999995
since last training loss: 0.04279999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 20, with score 0.065539. All blocks and scores: [(20, 0.06553898006677628), (37, 0.07051352318376303), (22, 0.07389882951974869), (52, 0.08052658848464489), (25, 0.08114515151828527), (47, 0.08441050630062819), (9, 0.08867506124079227), (13, 0.09271753579378128), (14, 0.09507469926029444), (39, 0.09614714235067368), (4, 0.0971249807626009), (6, 0.0973429437726736), (17, 0.10188626032322645), (11, 0.10270364582538605), (2, 0.11091356351971626), (3, 0.1215434018522501), (1, 0.12260050885379314), (0, 0.12586964946240187), (12, 0.14438365399837494), (8, 0.14593611285090446), (10, 0.16669254004955292), (16, 0.20279516838490963), (5, 0.2292931918054819), (36, 0.5111398920416832), (18, 0.6622740551829338), (53, 1.0732906609773636)]
computing accuracy for after removing block 20 . block score: 0.06553898006677628
removed block 20 current accuracy 0.8832 loss from initial  0.11680000000000001
since last training loss: 0.07140000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 22, with score 0.074613. All blocks and scores: [(22, 0.07461330387741327), (37, 0.07694641035050154), (52, 0.07714135199785233), (25, 0.08039872162044048), (47, 0.08240764681249857), (9, 0.08867506217211485), (13, 0.092717538587749), (14, 0.09507469553500414), (4, 0.09712497983127832), (6, 0.0973429437726736), (39, 0.09910212364047766), (17, 0.10188626311719418), (11, 0.10270364489406347), (2, 0.11091356910765171), (3, 0.1215433981269598), (1, 0.12260050419718027), (0, 0.12586964573711157), (12, 0.14438365772366524), (8, 0.14593611471354961), (10, 0.16669254004955292), (16, 0.20279517024755478), (5, 0.2292931918054819), (36, 0.5290144607424736), (18, 0.6622740551829338), (53, 1.0487834066152573)]
computing accuracy for after removing block 22 . block score: 0.07461330387741327
removed block 22 current accuracy 0.8272 loss from initial  0.17279999999999995
since last training loss: 0.12739999999999996 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.072353. All blocks and scores: [(52, 0.07235323078930378), (47, 0.07741076312959194), (25, 0.07951006479561329), (37, 0.08057060930877924), (9, 0.08867505751550198), (13, 0.09271753672510386), (14, 0.09507470019161701), (4, 0.0971249807626009), (6, 0.09734294470399618), (39, 0.1001574732363224), (17, 0.1018862621858716), (11, 0.10270364582538605), (2, 0.11091356817632914), (3, 0.12154339905828238), (1, 0.122600506991148), (0, 0.125869644805789), (12, 0.14438365399837494), (8, 0.14593611471354961), (10, 0.16669253632426262), (16, 0.20279516652226448), (5, 0.2292931955307722), (36, 0.5426668152213097), (18, 0.662274070084095), (53, 1.0380701422691345)]
computing accuracy for after removing block 52 . block score: 0.07235323078930378
removed block 52 current accuracy 0.772 loss from initial  0.22799999999999998
since last training loss: 0.18259999999999998 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 47, with score 0.077411. All blocks and scores: [(47, 0.07741076219826937), (25, 0.07951006758958101), (37, 0.08057061024010181), (9, 0.08867505844682455), (13, 0.09271753672510386), (14, 0.09507470205426216), (4, 0.09712497983127832), (6, 0.09734294097870588), (39, 0.1001574769616127), (17, 0.10188626125454903), (11, 0.10270364210009575), (2, 0.11091356724500656), (3, 0.1215434018522501), (1, 0.122600506991148), (0, 0.1258696485310793), (12, 0.1443836595863104), (8, 0.1459361184388399), (10, 0.16669253818690777), (16, 0.20279516093432903), (5, 0.2292931918054819), (36, 0.5426668226718903), (18, 0.6622740551829338), (53, 1.074034258723259)]
computing accuracy for after removing block 47 . block score: 0.07741076219826937
removed block 47 current accuracy 0.6696 loss from initial  0.3304
since last training loss: 0.28500000000000003 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 25, with score 0.079510. All blocks and scores: [(25, 0.07951006665825844), (37, 0.08057061024010181), (9, 0.08867505844682455), (13, 0.09271753672510386), (14, 0.09507469926029444), (4, 0.0971249807626009), (6, 0.09734294284135103), (39, 0.10015747603029013), (17, 0.10188626404851675), (11, 0.1027036439627409), (2, 0.11091356258839369), (3, 0.12154339998960495), (1, 0.12260050792247057), (0, 0.12586965132504702), (12, 0.1443836595863104), (8, 0.14593611471354961), (10, 0.16669253259897232), (16, 0.20279516838490963), (5, 0.2292931918054819), (36, 0.5426668301224709), (18, 0.6622740477323532), (53, 1.262489676475525)]
computing accuracy for after removing block 25 . block score: 0.07951006665825844
removed block 25 current accuracy 0.6112 loss from initial  0.38880000000000003
training start
training epoch 0 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best True lr [0.1]
training epoch 1 val accuracy 0.836 topk_dict {'top1': 0.836} is_best True lr [0.1]
training epoch 2 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best True lr [0.1]
training epoch 3 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best True lr [0.1]
training epoch 4 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.1]
training epoch 5 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 6 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 7 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 8 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 9 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.1]
training epoch 10 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
