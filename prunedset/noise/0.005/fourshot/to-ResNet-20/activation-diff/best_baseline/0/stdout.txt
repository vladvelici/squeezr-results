start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050979673862), (30, 0.010039400309324265), (31, 0.010361600201576948), (34, 0.013312275987118483), (29, 0.013541154330596328), (35, 0.01601846283301711), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02023245580494404), (46, 0.021044540917500854), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.022826647153124213), (44, 0.023395078722387552), (40, 0.024025025311857462), (45, 0.02429541014134884), (21, 0.024924597470089793), (22, 0.0251687690615654), (48, 0.025341259315609932), (24, 0.02589953667484224), (50, 0.026409971993416548), (42, 0.026674100197851658), (20, 0.026859007077291608), (49, 0.027037164429202676), (47, 0.0293064690195024), (39, 0.03157071233727038), (38, 0.031637872103601694), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.037960261572152376), (51, 0.041734172496944666), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734425127506), (52, 0.06862937565892935), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.43757999688386917), (18, 0.5108212977647781), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.01003940065857023), (31, 0.010361600201576948), (34, 0.013133947737514973), (29, 0.013541155378334224), (26, 0.01603759010322392), (35, 0.016169289126992226), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02007247693836689), (46, 0.020731385331600904), (25, 0.02197260269895196), (41, 0.02234709239564836), (23, 0.02237953501753509), (44, 0.02323568775318563), (40, 0.0238410672172904), (45, 0.023965541971847415), (48, 0.024917916394770145), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.02584081352688372), (24, 0.025899537838995457), (42, 0.02631532377563417), (49, 0.026655674446374178), (20, 0.026859006844460964), (47, 0.028728797798976302), (39, 0.03131764172576368), (38, 0.03138036374002695), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.03262859722599387), (37, 0.03802584297955036), (51, 0.04122393997386098), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734331995249), (52, 0.06745154969394207), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43538710102438927), (18, 0.5108213126659393), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.01276523235719651), (29, 0.013541154330596328), (35, 0.015992751577869058), (26, 0.01603759010322392), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020075131906196475), (46, 0.02084140619263053), (25, 0.021972602233290672), (41, 0.022319767391309142), (23, 0.022379535250365734), (44, 0.02315405081026256), (40, 0.023885684553533792), (45, 0.024071689462289214), (48, 0.02487746556289494), (21, 0.02492459863424301), (22, 0.025168768363073468), (50, 0.02569117839448154), (24, 0.025899536907672882), (42, 0.026123747928068042), (49, 0.0264794216491282), (20, 0.026859007077291608), (47, 0.028693133732303977), (38, 0.031236796639859676), (39, 0.031295291846618056), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03837669035419822), (51, 0.04111403366550803), (9, 0.04340187972411513), (6, 0.04660903289914131), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300980737432837), (1, 0.06676734331995249), (52, 0.06700456328690052), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.43640000745654106), (18, 0.5108212977647781), (53, 0.8289348855614662)]
computing accuracy for after removing block 30 . block score: 0.010039400774985552
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.01238783705048263), (29, 0.013541154330596328), (35, 0.016008096048608422), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.02008363325148821), (46, 0.02070444426499307), (25, 0.02197260200046003), (41, 0.022253197384998202), (23, 0.022379535250365734), (44, 0.0232677620369941), (40, 0.02401388087309897), (45, 0.02409299253486097), (48, 0.024665280943736434), (21, 0.024924597470089793), (22, 0.025168768130242825), (50, 0.025459735188633204), (42, 0.025655713863670826), (24, 0.025899536907672882), (49, 0.02628775779157877), (20, 0.02685900731012225), (47, 0.02836342412047088), (38, 0.031047646887600422), (39, 0.031380771892145276), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859722599387), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340188018977642), (6, 0.04660903010517359), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300980970263481), (52, 0.0658631594851613), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4389924556016922), (18, 0.5108213052153587), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.01248961966484785), (29, 0.01354115444701165), (26, 0.016037591034546494), (35, 0.01605736347846687), (28, 0.017728674924001098), (27, 0.01912704878486693), (43, 0.020049349637702107), (46, 0.0205529872328043), (25, 0.021972602466121316), (41, 0.022067483980208635), (23, 0.022379535250365734), (44, 0.022979132132604718), (40, 0.023858347442001104), (45, 0.02412470243871212), (48, 0.024386122822761536), (21, 0.024924597470089793), (50, 0.025042241206392646), (22, 0.025168768130242825), (42, 0.025414507370442152), (49, 0.025842699222266674), (24, 0.025899537606164813), (20, 0.026859007077291608), (47, 0.028050733963027596), (38, 0.031040059635415673), (39, 0.0315008033066988), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.039112846832722425), (51, 0.040246272925287485), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846424981952), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.0630098101682961), (52, 0.06486208783462644), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.43812786042690277), (18, 0.5108213052153587), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.01248961966484785
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.016037590568885207), (35, 0.016653420636430383), (28, 0.017728675389662385), (27, 0.019127048086374998), (43, 0.020503456005826592), (46, 0.0207253226544708), (25, 0.02197260269895196), (23, 0.02237953571602702), (41, 0.02245262893848121), (44, 0.02336447359994054), (48, 0.024290355620905757), (45, 0.024438712745904922), (40, 0.024470558390021324), (21, 0.024924597004428506), (50, 0.02504217205569148), (22, 0.025168767664581537), (49, 0.025875970255583525), (24, 0.025899536442011595), (42, 0.026205406757071614), (20, 0.026859006378799677), (47, 0.028178582666441798), (15, 0.03192339139059186), (38, 0.03208350157365203), (7, 0.03228544583544135), (39, 0.03233744157478213), (19, 0.03262859582901001), (51, 0.039947259705513716), (37, 0.040739680640399456), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.0630098101682961), (52, 0.06433630362153053), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.45053431019186974), (18, 0.5108213126659393), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470607835799456), (28, 0.017728675855323672), (27, 0.019127048319205642), (43, 0.020046866964548826), (46, 0.020376994041725993), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.022379535483196378), (44, 0.023028338328003883), (48, 0.023771876003593206), (40, 0.023930813185870647), (45, 0.02417866257019341), (50, 0.024390298407524824), (21, 0.024924598401412368), (22, 0.0251687690615654), (42, 0.02518825139850378), (49, 0.025361529318615794), (24, 0.02589953737333417), (20, 0.02685900731012225), (47, 0.02736327867023647), (38, 0.03136561973951757), (15, 0.03192339139059186), (39, 0.03212768444791436), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.03893592394888401), (37, 0.040206342935562134), (9, 0.04340188158676028), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.04783663246780634), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684925094247), (52, 0.062328551430255175), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.44442018866539), (18, 0.5108212977647781), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366145811975), (28, 0.017088500084355474), (27, 0.01888244692236185), (43, 0.019595165736973286), (46, 0.020073580788448453), (41, 0.020961584988981485), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.02281495649367571), (48, 0.023128160974010825), (40, 0.02334519592113793), (50, 0.02375614712946117), (42, 0.02384730288758874), (45, 0.023873880272731185), (21, 0.024924598168581724), (49, 0.02496031578630209), (22, 0.02516876789741218), (24, 0.02589953737333417), (47, 0.026855542324483395), (20, 0.02685900731012225), (38, 0.0304240130353719), (39, 0.031514044385403395), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.037824881728738546), (37, 0.039368351455777884), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.04783663526177406), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924913054332137), (52, 0.06033282075077295), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049013078213), (5, 0.10667386837303638), (36, 0.436068557202816), (18, 0.5108213052153587), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366145811975
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945716798306), (27, 0.018882446689531207), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.02146727219223976), (25, 0.021972602466121316), (44, 0.022026916965842247), (40, 0.022179660852998495), (42, 0.02220643009059131), (50, 0.022256129188463092), (23, 0.02237953571602702), (45, 0.02293148124590516), (49, 0.02370851277373731), (21, 0.024924598168581724), (22, 0.0251687690615654), (47, 0.025829139398410916), (24, 0.02589953667484224), (20, 0.026859006844460964), (38, 0.028956546681001782), (39, 0.029667828232049942), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.036009025294333696), (37, 0.036512387450784445), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846424981952), (52, 0.056107287760823965), (3, 0.0572242820635438), (13, 0.058922902680933475), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4175764434039593), (18, 0.5108212977647781), (53, 0.9117144867777824)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102241948247), (41, 0.01884901849552989), (27, 0.018882446456700563), (48, 0.020903734024614096), (42, 0.02143200417049229), (40, 0.02183242212049663), (44, 0.021840530214831233), (50, 0.021869863849133253), (25, 0.021972602931782603), (23, 0.02237953618168831), (45, 0.022492847871035337), (49, 0.023123498540371656), (21, 0.024924598168581724), (47, 0.025067138951271772), (22, 0.0251687690615654), (24, 0.0258995380718261), (20, 0.026859006844460964), (38, 0.02811406971886754), (39, 0.0292069090064615), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03545433655381203), (37, 0.035977639723569155), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (52, 0.054696456994861364), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4135979041457176), (18, 0.5108213126659393), (53, 0.9246632605791092)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882446689531207), (46, 0.019302030559629202), (42, 0.021432003937661648), (48, 0.021544844144955277), (40, 0.021832421654835343), (50, 0.021946269320324063), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.02300687017850578), (44, 0.02310850960202515), (45, 0.0235356071498245), (21, 0.02492459793575108), (22, 0.025168767664581537), (47, 0.0258204466663301), (24, 0.025899537140503526), (20, 0.02685900661163032), (38, 0.028114069486036897), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.035091488156467676), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.05332903005182743), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924913100898266), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4135979153215885), (18, 0.5108213126659393), (53, 0.9678283929824829)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 1 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 2 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 3 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 4 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 5 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 6 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.1]
training epoch 7 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 8 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 9 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 10 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.01907008863054216), (48, 0.02067816792987287), (50, 0.02134439768269658), (40, 0.021832421654835343), (25, 0.021972602931782603), (42, 0.021986939711496234), (23, 0.022379535483196378), (49, 0.022534747840836644), (45, 0.023929917719215155), (44, 0.024054003646597266), (21, 0.02492459723725915), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.026043936843052506), (20, 0.026859006145969033), (38, 0.028114069486036897), (39, 0.029206908540800214), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.03379447991028428), (37, 0.03597763925790787), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.050476094242185354), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.01866446272470057), (48, 0.01998970750719309), (50, 0.020775062264874578), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.02191002992913127), (25, 0.021972602233290672), (23, 0.022379534784704447), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.024924597702920437), (47, 0.025076948339119554), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.02718335995450616), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03281426033936441), (37, 0.03542024316266179), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663526177406), (52, 0.04852363094687462), (2, 0.05454846424981952), (3, 0.05722427973523736), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095685064792633), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667386837303638), (36, 0.4065233990550041), (18, 0.5108213201165199), (53, 1.0384204685688019)]
computing accuracy for after removing block 46 . block score: 0.01866446272470057
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831161411479115), (40, 0.021085953107103705), (42, 0.0213696479331702), (25, 0.02197260200046003), (23, 0.022379535483196378), (49, 0.022536988835781813), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924597470089793), (22, 0.0251687690615654), (24, 0.025899537606164813), (47, 0.026583047583699226), (20, 0.026859006844460964), (38, 0.027183360187336802), (39, 0.028580758487805724), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03285081125795841), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.04783663572743535), (52, 0.048124799970537424), (2, 0.054548466112464666), (3, 0.05722427600994706), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647467508912), (25, 0.021972602466121316), (23, 0.022379535250365734), (50, 0.022470062831416726), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.02492459723725915), (22, 0.025168768130242825), (49, 0.02523410227149725), (24, 0.025899537140503526), (47, 0.026583049213513732), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.032969210762530565), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05089045222848654), (2, 0.05454846564680338), (3, 0.057224280666559935), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.0746783260256052), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049571871758), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.2663908898830414)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681667000055), (50, 0.021284765796735883), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.023098317440599203), (44, 0.024240857921540737), (49, 0.02450086921453476), (21, 0.024924597004428506), (22, 0.025168768828734756), (24, 0.025899537140503526), (47, 0.026519699255004525), (20, 0.02685900731012225), (38, 0.027183361118659377), (39, 0.028580757789313793), (15, 0.031923392321914434), (51, 0.03222084976732731), (7, 0.032285445369780064), (19, 0.03262859536334872), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04885757248848677), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980690866709), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065234065055847), (18, 0.5108213052153587), (53, 1.3718615770339966)]
computing accuracy for after removing block 42 . block score: 0.020968681667000055
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.023761966498568654), (49, 0.024602338671684265), (44, 0.024712180718779564), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.02589953737333417), (47, 0.026220475090667605), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075825497508), (51, 0.031279068207368255), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.043401879258453846), (52, 0.04610170889645815), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.05454846704378724), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249130077660084), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.4178234189748764)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.023761966032907367), (49, 0.024602338671684265), (44, 0.024712181417271495), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.02622047415934503), (20, 0.026859008008614182), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03344302158802748), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663293346763), (52, 0.05265179416164756), (2, 0.054548466112464666), (3, 0.057224280666559935), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.06095685018226504), (0, 0.06300980783998966), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387396097183), (36, 0.4065233916044235), (18, 0.5108212903141975), (53, 1.628768116235733)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535483196378), (45, 0.023382084676995873), (49, 0.02386031672358513), (44, 0.023948066402226686), (21, 0.024924598168581724), (22, 0.0251687690615654), (47, 0.02536190301179886), (24, 0.025899537140503526), (38, 0.026533204596489668), (20, 0.026859006145969033), (39, 0.02847280609421432), (15, 0.031923392321914434), (7, 0.03228544723242521), (51, 0.032473248429596424), (19, 0.032628596760332584), (37, 0.03485476830974221), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.050425713416188955), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.3996613621711731), (18, 0.5108213126659393), (53, 1.6311722099781036)]
computing accuracy for after removing block 23 . block score: 0.022379535483196378
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.023563285125419497), (45, 0.02358233113773167), (49, 0.023707157699391246), (24, 0.02455138461664319), (47, 0.024688830599188805), (21, 0.02492459723725915), (22, 0.025168768363073468), (38, 0.02640997967682779), (20, 0.02685900731012225), (39, 0.028432968072593212), (15, 0.03192339185625315), (7, 0.03228544723242521), (51, 0.03235368151217699), (19, 0.03262859536334872), (37, 0.035908338613808155), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663293346763), (52, 0.04885636828839779), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095684692263603), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408283162862062), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.40237870067358017), (18, 0.5108212977647781), (53, 1.617948293685913)]
computing accuracy for after removing block 44 . block score: 0.023563285125419497
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246752563863993), (49, 0.023541763424873352), (24, 0.02455138461664319), (21, 0.024924598168581724), (22, 0.025168768595904112), (47, 0.025985258864238858), (38, 0.026409979909658432), (20, 0.02685900591313839), (39, 0.028432969003915787), (15, 0.031923392321914434), (51, 0.0320491255261004), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03590833721682429), (9, 0.04340187832713127), (6, 0.046609030570834875), (4, 0.04749368270859122), (14, 0.0478366338647902), (52, 0.048162917140871286), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924913054332137), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.40237869694828987), (18, 0.5108212903141975), (53, 1.748221516609192)]
computing accuracy for after removing block 45 . block score: 0.023246752563863993
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157051229849458), (24, 0.02455138391815126), (21, 0.024924598168581724), (22, 0.025168768595904112), (38, 0.02640997967682779), (20, 0.02685900661163032), (47, 0.027429410722106695), (39, 0.02843296923674643), (51, 0.03189300233498216), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (37, 0.03590833768248558), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.047836633399128914), (52, 0.04907965287566185), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.40237870067358017), (18, 0.5108213052153587), (53, 1.8955669701099396)]
computing accuracy for after removing block 49 . block score: 0.024157051229849458
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.1]
training epoch 1 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.1]
training epoch 2 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 3 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 4 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 5 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 6 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 7 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 8 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 9 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 10 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.959800)
finished training. finished 50 epochs. accuracy 0.9598 topk_dict {'top1': 0.9598}
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.060177. All blocks and scores: [(21, 0.06017677206546068), (38, 0.062077118549495935), (20, 0.0633007981814444), (15, 0.06427352409809828), (19, 0.06476227007806301), (7, 0.06642598379403353), (22, 0.06911559496074915), (39, 0.07051633670926094), (4, 0.0719256792217493), (37, 0.07222461421042681), (51, 0.07225485239177942), (47, 0.07366001419723034), (24, 0.07891219761222601), (52, 0.07973804883658886), (6, 0.08774703834205866), (2, 0.09292824752628803), (14, 0.09583823103457689), (9, 0.09624175261706114), (17, 0.09857640601694584), (0, 0.101036979816854), (3, 0.10143448319286108), (11, 0.10338731948286295), (1, 0.10840934701263905), (13, 0.11332995258271694), (8, 0.13386700861155987), (16, 0.15636958926916122), (12, 0.15983388759195805), (10, 0.164973771199584), (5, 0.18964898772537708), (36, 0.5544730573892593), (18, 0.6615679785609245), (53, 1.018111526966095)]
computing accuracy for after removing block 21 . block score: 0.06017677206546068
removed block 21 current accuracy 0.951 loss from initial  0.049000000000000044
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.057531. All blocks and scores: [(38, 0.05753079429268837), (22, 0.06148569053038955), (20, 0.06330079538747668), (15, 0.06427352409809828), (19, 0.06476227287203074), (24, 0.0654066177085042), (7, 0.0664259810000658), (37, 0.06667330022901297), (39, 0.06779100466519594), (51, 0.06843051128089428), (47, 0.06912021245807409), (52, 0.07170955929905176), (4, 0.07192567829042673), (6, 0.08774704113602638), (2, 0.09292824566364288), (14, 0.09583822917193174), (9, 0.09624175168573856), (17, 0.09857640415430069), (0, 0.101036979816854), (3, 0.10143448505550623), (11, 0.10338731948286295), (1, 0.1084093488752842), (13, 0.11332995537668467), (8, 0.13386700861155987), (16, 0.15636958926916122), (12, 0.1598338931798935), (10, 0.16497377306222916), (5, 0.18964899145066738), (36, 0.5176777616143227), (18, 0.6615679934620857), (53, 1.0298874601721764)]
computing accuracy for after removing block 38 . block score: 0.05753079429268837
removed block 38 current accuracy 0.939 loss from initial  0.061000000000000054
since last training loss: 0.02080000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.061486. All blocks and scores: [(22, 0.06148569006472826), (20, 0.06330079725012183), (15, 0.06427352409809828), (19, 0.06476227007806301), (52, 0.06506255455315113), (51, 0.06506417784839869), (24, 0.0654066177085042), (7, 0.06642598193138838), (37, 0.06667330116033554), (47, 0.06743495166301727), (4, 0.07192568108439445), (39, 0.07700827531516552), (6, 0.08774704206734896), (2, 0.09292824473232031), (14, 0.09583822917193174), (9, 0.09624175354838371), (17, 0.09857640508562326), (0, 0.10103698167949915), (3, 0.10143448412418365), (11, 0.10338731948286295), (1, 0.10840934980660677), (13, 0.11332995165139437), (8, 0.13386700861155987), (16, 0.15636958926916122), (12, 0.15983388759195805), (10, 0.164973771199584), (5, 0.18964898958802223), (36, 0.5176777616143227), (18, 0.6615679934620857), (53, 1.0908741503953934)]
computing accuracy for after removing block 22 . block score: 0.06148569006472826
removed block 22 current accuracy 0.918 loss from initial  0.08199999999999996
since last training loss: 0.04179999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.059725. All blocks and scores: [(24, 0.059724701568484306), (52, 0.06206243857741356), (51, 0.062401062808930874), (47, 0.06274257833138108), (20, 0.06330079538747668), (15, 0.06427352502942085), (19, 0.06476227007806301), (7, 0.06642598286271095), (37, 0.07092611398547888), (4, 0.07192567829042673), (39, 0.07634222228080034), (6, 0.08774704206734896), (2, 0.09292824286967516), (14, 0.09583823010325432), (9, 0.09624175168573856), (17, 0.09857640508562326), (0, 0.101036979816854), (3, 0.1014344859868288), (11, 0.10338731948286295), (1, 0.1084093451499939), (13, 0.11332995444536209), (8, 0.13386700861155987), (16, 0.15636959299445152), (12, 0.1598338931798935), (10, 0.1649737674742937), (5, 0.18964898772537708), (36, 0.5261223986744881), (18, 0.6615679860115051), (53, 1.0660579949617386)]
computing accuracy for after removing block 24 . block score: 0.059724701568484306
removed block 24 current accuracy 0.8874 loss from initial  0.11260000000000003
since last training loss: 0.07240000000000002 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.055639. All blocks and scores: [(52, 0.05563883436843753), (47, 0.05776824150234461), (51, 0.05787872802466154), (20, 0.06330079538747668), (15, 0.06427352409809828), (19, 0.06476227007806301), (7, 0.0664259810000658), (37, 0.07019347418099642), (4, 0.07192568015307188), (39, 0.07398577872663736), (6, 0.08774704020470381), (2, 0.09292824566364288), (14, 0.09583822917193174), (9, 0.09624175634235144), (17, 0.09857640415430069), (0, 0.10103698167949915), (3, 0.10143448319286108), (11, 0.1033873213455081), (1, 0.10840934980660677), (13, 0.11332995072007179), (8, 0.13386700674891472), (16, 0.15636958926916122), (12, 0.15983389131724834), (10, 0.164973771199584), (5, 0.18964899331331253), (36, 0.5212854668498039), (18, 0.6615679785609245), (53, 1.0487672239542007)]
computing accuracy for after removing block 52 . block score: 0.05563883436843753
removed block 52 current accuracy 0.8556 loss from initial  0.14439999999999997
since last training loss: 0.10419999999999996 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 47, with score 0.057768. All blocks and scores: [(47, 0.05776824150234461), (51, 0.05787872616201639), (20, 0.06330079631879926), (15, 0.06427352596074343), (19, 0.06476227007806301), (7, 0.06642598379403353), (37, 0.07019347324967384), (4, 0.07192568201571703), (39, 0.07398577686399221), (6, 0.08774704020470381), (2, 0.09292824659496546), (14, 0.09583822824060917), (9, 0.09624175354838371), (17, 0.09857640415430069), (0, 0.101036979816854), (3, 0.10143448319286108), (11, 0.1033873213455081), (1, 0.10840934701263905), (13, 0.11332995351403952), (8, 0.13386700674891472), (16, 0.15636958926916122), (12, 0.15983388759195805), (10, 0.1649737749248743), (5, 0.18964898958802223), (36, 0.5212854668498039), (18, 0.6615680083632469), (53, 1.0254530757665634)]
computing accuracy for after removing block 47 . block score: 0.05776824150234461
removed block 47 current accuracy 0.8076 loss from initial  0.19240000000000002
since last training loss: 0.1522 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.062837. All blocks and scores: [(51, 0.06283687055110931), (20, 0.06330079725012183), (15, 0.0642735231667757), (19, 0.06476227194070816), (7, 0.06642598006874323), (37, 0.07019347324967384), (4, 0.0719256792217493), (39, 0.07398577872663736), (6, 0.08774704113602638), (2, 0.09292824286967516), (14, 0.09583822917193174), (9, 0.09624175168573856), (17, 0.09857640508562326), (0, 0.10103697795420885), (3, 0.10143448505550623), (11, 0.10338731948286295), (1, 0.10840934608131647), (13, 0.11332994978874922), (8, 0.13386700674891472), (16, 0.15636959485709667), (12, 0.15983389504253864), (10, 0.164973771199584), (5, 0.18964898958802223), (36, 0.5212854519486427), (18, 0.6615679711103439), (53, 1.2295193523168564)]
computing accuracy for after removing block 51 . block score: 0.06283687055110931
removed block 51 current accuracy 0.7032 loss from initial  0.29679999999999995
since last training loss: 0.25659999999999994 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 20, with score 0.063301. All blocks and scores: [(20, 0.06330079631879926), (15, 0.06427352502942085), (19, 0.06476227100938559), (7, 0.06642598006874323), (37, 0.07019347324967384), (4, 0.0719256792217493), (39, 0.07398577872663736), (6, 0.08774704206734896), (2, 0.09292824380099773), (14, 0.09583823010325432), (9, 0.09624175168573856), (17, 0.09857640508562326), (0, 0.101036979816854), (3, 0.1014344822615385), (11, 0.1033873176202178), (1, 0.10840934701263905), (13, 0.11332995351403952), (8, 0.13386700674891472), (16, 0.15636959113180637), (12, 0.15983389131724834), (10, 0.164973771199584), (5, 0.18964898772537708), (36, 0.5212854668498039), (18, 0.6615680158138275), (53, 1.2348887026309967)]
computing accuracy for after removing block 20 . block score: 0.06330079631879926
removed block 20 current accuracy 0.7 loss from initial  0.30000000000000004
since last training loss: 0.25980000000000003 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 15, with score 0.064274. All blocks and scores: [(15, 0.0642735231667757), (19, 0.06476227100938559), (7, 0.06642597820609808), (4, 0.07192567829042673), (39, 0.07494200952351093), (37, 0.07773309666663408), (6, 0.08774704299867153), (2, 0.09292824752628803), (14, 0.0958382273092866), (9, 0.09624175168573856), (17, 0.09857640601694584), (0, 0.10103697888553143), (3, 0.10143448412418365), (11, 0.10338731948286295), (1, 0.10840934608131647), (13, 0.11332994978874922), (8, 0.13386700488626957), (16, 0.15636959113180637), (12, 0.15983389131724834), (10, 0.16497377306222916), (5, 0.18964898772537708), (36, 0.5365929305553436), (18, 0.6615679860115051), (53, 1.1282153874635696)]
computing accuracy for after removing block 15 . block score: 0.0642735231667757
removed block 15 current accuracy 0.671 loss from initial  0.32899999999999996
since last training loss: 0.28879999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.066426. All blocks and scores: [(7, 0.06642598286271095), (19, 0.06687031034380198), (4, 0.0719256792217493), (37, 0.07347701396793127), (39, 0.07441313099116087), (6, 0.08774704020470381), (2, 0.09292824752628803), (14, 0.09583822637796402), (9, 0.09624175168573856), (0, 0.101036979816854), (3, 0.10143448505550623), (11, 0.10338731948286295), (17, 0.10755839571356773), (1, 0.10840934980660677), (13, 0.11332995258271694), (8, 0.13386701233685017), (12, 0.15983389131724834), (10, 0.16497376933693886), (16, 0.1742311604321003), (5, 0.18964898772537708), (36, 0.5191015675663948), (18, 0.6455791667103767), (53, 1.147579476237297)]
computing accuracy for after removing block 7 . block score: 0.06642598286271095
removed block 7 current accuracy 0.6354 loss from initial  0.36460000000000004
since last training loss: 0.3244 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.063911. All blocks and scores: [(19, 0.06391080468893051), (37, 0.06665593385696411), (4, 0.07192568015307188), (39, 0.07471098564565182), (6, 0.08774703927338123), (14, 0.08989831060171127), (2, 0.09292824659496546), (9, 0.09336227364838123), (17, 0.09359294082969427), (11, 0.09755409136414528), (0, 0.10103697702288628), (3, 0.10143448412418365), (13, 0.10197905451059341), (1, 0.1084093451499939), (8, 0.1308198869228363), (12, 0.1456456370651722), (16, 0.1520092561841011), (10, 0.16664551571011543), (5, 0.18964899145066738), (36, 0.5062852427363396), (18, 0.6226180046796799), (53, 1.111720323562622)]
computing accuracy for after removing block 19 . block score: 0.06391080468893051
removed block 19 current accuracy 0.5768 loss from initial  0.4232
training start
training epoch 0 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best True lr [0.1]
training epoch 1 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.1]
training epoch 2 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 3 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 4 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best False lr [0.1]
training epoch 5 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 6 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 8 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 9 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 10 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.932400)
finished training. finished 50 epochs. accuracy 0.9324 topk_dict {'top1': 0.9324}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.087676. All blocks and scores: [(4, 0.08767636585980654), (37, 0.10911205783486366), (9, 0.11953198071569204), (6, 0.1203078618273139), (39, 0.12714992929250002), (2, 0.13029899261891842), (0, 0.13126022927463055), (1, 0.13504404574632645), (3, 0.1368306614458561), (11, 0.14676645398139954), (14, 0.15606091916561127), (13, 0.16459757462143898), (8, 0.17674682848155499), (17, 0.20005378127098083), (10, 0.21034925058484077), (12, 0.219252472743392), (16, 0.24615423567593098), (5, 0.260730754584074), (36, 0.46805156394839287), (18, 0.601889431476593), (53, 1.3233552724123)]
computing accuracy for after removing block 4 . block score: 0.08767636585980654
removed block 4 current accuracy 0.9312 loss from initial  0.06879999999999997
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.110471. All blocks and scores: [(37, 0.11047124210745096), (9, 0.12132774200290442), (39, 0.1263732211664319), (2, 0.13029899820685387), (0, 0.1312602311372757), (1, 0.13504404947161674), (6, 0.13505428284406662), (3, 0.1368306651711464), (11, 0.14204496517777443), (14, 0.150345204398036), (13, 0.16233488731086254), (8, 0.17054075561463833), (17, 0.18877128511667252), (10, 0.20433544553816319), (12, 0.2144861426204443), (16, 0.23413293808698654), (5, 0.28543203324079514), (36, 0.4691437818109989), (18, 0.6009054705500603), (53, 1.3048294484615326)]
computing accuracy for after removing block 37 . block score: 0.11047124210745096
removed block 37 current accuracy 0.8838 loss from initial  0.11619999999999997
since last training loss: 0.04859999999999998 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 9, with score 0.121328. All blocks and scores: [(9, 0.12132774479687214), (2, 0.13029899820685387), (0, 0.1312602311372757), (1, 0.13504404574632645), (6, 0.13505428843200207), (3, 0.13683066330850124), (11, 0.14204496331512928), (14, 0.1503452006727457), (13, 0.16233489103615284), (39, 0.16731975972652435), (8, 0.17054075002670288), (17, 0.18877128697931767), (10, 0.20433544926345348), (12, 0.21448614448308945), (16, 0.23413293808698654), (5, 0.28543202951550484), (36, 0.4691437967121601), (18, 0.6009054705500603), (53, 1.4046811759471893)]
computing accuracy for after removing block 9 . block score: 0.12132774479687214
removed block 9 current accuracy 0.8738 loss from initial  0.12619999999999998
since last training loss: 0.058599999999999985 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 11, with score 0.129646. All blocks and scores: [(11, 0.12964563816785812), (2, 0.13029899261891842), (0, 0.1312602311372757), (14, 0.13456079177558422), (1, 0.13504404202103615), (6, 0.13505428843200207), (3, 0.13683066330850124), (39, 0.1486864872276783), (13, 0.15455209650099277), (17, 0.16718945652246475), (8, 0.17054075188934803), (12, 0.1894567608833313), (10, 0.19070280902087688), (16, 0.19609862193465233), (5, 0.28543202206492424), (36, 0.42779070883989334), (18, 0.5669952630996704), (53, 1.2209543883800507)]
computing accuracy for after removing block 11 . block score: 0.12964563816785812
removed block 11 current accuracy 0.8492 loss from initial  0.15080000000000005
since last training loss: 0.08320000000000005 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 14, with score 0.129826. All blocks and scores: [(14, 0.1298264842480421), (2, 0.13029899820685387), (0, 0.1312602311372757), (1, 0.13504404202103615), (6, 0.13505428656935692), (3, 0.1368306614458561), (13, 0.14699344523251057), (39, 0.15229337476193905), (17, 0.15855791978538036), (16, 0.16992643848061562), (8, 0.17054075561463833), (10, 0.19070281088352203), (12, 0.19362586550414562), (5, 0.28543203324079514), (36, 0.43570830300450325), (18, 0.5763663277029991), (53, 1.2212726473808289)]
computing accuracy for after removing block 14 . block score: 0.1298264842480421
removed block 14 current accuracy 0.802 loss from initial  0.19799999999999995
since last training loss: 0.13039999999999996 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 2, with score 0.130299. All blocks and scores: [(2, 0.13029899261891842), (0, 0.1312602274119854), (1, 0.1350440438836813), (6, 0.13505428843200207), (3, 0.13683066330850124), (13, 0.14699343964457512), (39, 0.15120995789766312), (17, 0.15341829136013985), (8, 0.17054075747728348), (10, 0.19070281833410263), (12, 0.19362586922943592), (16, 0.20301548391580582), (5, 0.28543202206492424), (36, 0.4295627251267433), (18, 0.5676120817661285), (53, 1.1946511268615723)]
computing accuracy for after removing block 2 . block score: 0.13029899261891842
removed block 2 current accuracy 0.7348 loss from initial  0.2652
since last training loss: 0.1976 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 6, with score 0.121473. All blocks and scores: [(6, 0.12147322855889797), (17, 0.12857643701136112), (0, 0.13126022927463055), (13, 0.13138773292303085), (3, 0.13474956713616848), (1, 0.13504404574632645), (39, 0.1372884400188923), (8, 0.1504913941025734), (10, 0.1782637368887663), (16, 0.18232466094195843), (12, 0.182390121743083), (5, 0.28715914487838745), (36, 0.39250916987657547), (18, 0.5248281434178352), (53, 1.0236733183264732)]
computing accuracy for after removing block 6 . block score: 0.12147322855889797
removed block 6 current accuracy 0.643 loss from initial  0.357
since last training loss: 0.2894 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.118429. All blocks and scores: [(17, 0.11842858418822289), (13, 0.12835929915308952), (39, 0.12971192970871925), (0, 0.13126022927463055), (3, 0.13474956713616848), (1, 0.1350440438836813), (16, 0.15114685334265232), (8, 0.15196532383561134), (12, 0.16984901949763298), (10, 0.18820343166589737), (5, 0.28715914487838745), (36, 0.37757743895053864), (18, 0.5122148096561432), (53, 0.876150332391262)]
computing accuracy for after removing block 17 . block score: 0.11842858418822289
removed block 17 current accuracy 0.5638 loss from initial  0.43620000000000003
since last training loss: 0.36860000000000004 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 39, with score 0.121862. All blocks and scores: [(39, 0.12186240591108799), (13, 0.12835929729044437), (0, 0.1312602311372757), (3, 0.13474956899881363), (1, 0.13504404202103615), (16, 0.15114685148000717), (8, 0.1519653219729662), (12, 0.16984902136027813), (10, 0.18820342794060707), (5, 0.28715914487838745), (36, 0.35234442725777626), (18, 0.4837462939321995), (53, 0.7656801864504814)]
computing accuracy for after removing block 39 . block score: 0.12186240591108799
removed block 39 current accuracy 0.3238 loss from initial  0.6762
since last training loss: 0.6086 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.128359. All blocks and scores: [(13, 0.12835929729044437), (0, 0.13126022927463055), (3, 0.13474956899881363), (1, 0.1350440438836813), (16, 0.15114684961736202), (8, 0.15196532383561134), (12, 0.16984902881085873), (10, 0.18820342235267162), (5, 0.28715915232896805), (36, 0.35234443470835686), (18, 0.4837463013827801), (53, 1.1199753731489182)]
computing accuracy for after removing block 13 . block score: 0.12835929729044437
removed block 13 current accuracy 0.2538 loss from initial  0.7462
since last training loss: 0.6786 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 0, with score 0.131260. All blocks and scores: [(0, 0.1312602311372757), (3, 0.13474956899881363), (1, 0.1350440476089716), (8, 0.15196532383561134), (16, 0.16561591997742653), (12, 0.16984902322292328), (10, 0.18820342607796192), (5, 0.28715914487838745), (36, 0.35577063262462616), (18, 0.5015780255198479), (53, 1.301655039191246)]
computing accuracy for after removing block 0 . block score: 0.1312602311372757
removed block 0 current accuracy 0.2144 loss from initial  0.7856
since last training loss: 0.718 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 3, with score 0.130992. All blocks and scores: [(3, 0.13099214248359203), (8, 0.14025315642356873), (16, 0.14759995602071285), (1, 0.1498596966266632), (10, 0.1662881337106228), (12, 0.22609824314713478), (5, 0.2874496541917324), (36, 0.35379135981202126), (18, 0.5178593471646309), (53, 1.2612260282039642)]
computing accuracy for after removing block 3 . block score: 0.13099214248359203
removed block 3 current accuracy 0.1758 loss from initial  0.8242
training start
training epoch 0 val accuracy 0.792 topk_dict {'top1': 0.792} is_best True lr [0.1]
training epoch 1 val accuracy 0.8242 topk_dict {'top1': 0.8242} is_best True lr [0.1]
training epoch 2 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.1]
training epoch 3 val accuracy 0.7792 topk_dict {'top1': 0.7792} is_best False lr [0.1]
training epoch 4 val accuracy 0.8162 topk_dict {'top1': 0.8162} is_best False lr [0.1]
training epoch 5 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.1]
training epoch 6 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.1]
training epoch 7 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.1]
training epoch 8 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 9 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 10 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.910600)
finished training. finished 50 epochs. accuracy 0.9106 topk_dict {'top1': 0.9106}
