start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050630427897), (30, 0.01003940065857023), (31, 0.010361600201576948), (34, 0.013312276219949126), (29, 0.013541154330596328), (35, 0.016018463065847754), (26, 0.016037591034546494), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020232456969097257), (46, 0.02104454068467021), (25, 0.02197260339744389), (23, 0.022379535483196378), (41, 0.0228266476187855), (44, 0.02339507848955691), (40, 0.02402502577751875), (45, 0.02429541083984077), (21, 0.02492459793575108), (22, 0.025168767664581537), (48, 0.025341259548440576), (24, 0.0258995380718261), (50, 0.02640997222624719), (42, 0.026674099965021014), (20, 0.026859007542952895), (49, 0.02703716396354139), (47, 0.0293064690195024), (39, 0.031570713268592954), (38, 0.03163787070661783), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03796025924384594), (51, 0.041734172496944666), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06862937472760677), (8, 0.07467832416296005), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4375799931585789), (18, 0.5108213126659393), (53, 0.8211488872766495)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.010039400425739586), (31, 0.010361600085161626), (34, 0.013133947155438364), (29, 0.013541154912672937), (26, 0.01603759080171585), (35, 0.016169289126992226), (28, 0.017728675855323672), (27, 0.01912704878486693), (43, 0.02007247693836689), (46, 0.020731384633108974), (25, 0.021972602466121316), (41, 0.022347092861309648), (23, 0.022379535250365734), (44, 0.023235688218846917), (40, 0.023841066285967827), (45, 0.023965542670339346), (48, 0.024917916394770145), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.02584081282839179), (24, 0.025899536907672882), (42, 0.02631532377563417), (49, 0.026655675377696753), (20, 0.026859006844460964), (47, 0.02872879826463759), (39, 0.03131764195859432), (38, 0.031380362808704376), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03802584344521165), (51, 0.041223939042538404), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249126352369785), (17, 0.060956851579248905), (0, 0.06300980970263481), (1, 0.06676734331995249), (52, 0.06745155062526464), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.43538709729909897), (18, 0.5108213052153587), (53, 0.822257399559021)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.012765232939273119), (29, 0.013541154214181006), (35, 0.015992751577869058), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02007513167336583), (46, 0.020841406425461173), (25, 0.021972602931782603), (41, 0.022319766925647855), (23, 0.022379535250365734), (44, 0.023154051043093204), (40, 0.023885684087872505), (45, 0.024071690160781145), (48, 0.024877465330064297), (21, 0.024924598168581724), (22, 0.02516876789741218), (50, 0.025691178161650896), (24, 0.02589953737333417), (42, 0.02612374839372933), (49, 0.026479422580450773), (20, 0.02685900777578354), (47, 0.02869313210248947), (38, 0.031236795475706458), (39, 0.031295291148126125), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03837668988853693), (51, 0.04111403413116932), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548466578125954), (3, 0.05722427973523736), (13, 0.05892290361225605), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.0670045642182231), (8, 0.07467832416296005), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.43640001118183136), (18, 0.5108213052153587), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.01238783763255924), (29, 0.013541154563426971), (35, 0.016008096281439066), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020083633484318852), (46, 0.02070444426499307), (25, 0.021972603164613247), (41, 0.022253197384998202), (23, 0.022379535483196378), (44, 0.02326776087284088), (40, 0.02401388087309897), (45, 0.024092993000522256), (48, 0.024665280943736434), (21, 0.024924597702920437), (22, 0.025168768130242825), (50, 0.025459734024479985), (42, 0.02565571339800954), (24, 0.025899536442011595), (49, 0.026287756860256195), (20, 0.026859008008614182), (47, 0.028363423887640238), (38, 0.031047647120431066), (39, 0.031380771892145276), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.038971245754510164), (51, 0.04075620323419571), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980923697352), (52, 0.06586316134780645), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4389924593269825), (18, 0.5108212977647781), (53, 0.8391561806201935)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154097765684), (26, 0.016037591034546494), (35, 0.016057362779974937), (28, 0.017728676088154316), (27, 0.019127048552036285), (43, 0.02004934917204082), (46, 0.020552987465634942), (25, 0.021972602466121316), (41, 0.022067484445869923), (23, 0.02237953571602702), (44, 0.022979132365435362), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.024386122822761536), (21, 0.024924596771597862), (50, 0.025042241206392646), (22, 0.0251687690615654), (42, 0.02541450853459537), (49, 0.025842699455097318), (24, 0.025899536907672882), (20, 0.02685900731012225), (47, 0.028050734428688884), (38, 0.031040059635415673), (39, 0.031500803073868155), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03911284822970629), (51, 0.04024627339094877), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300981063395739), (52, 0.06486208830028772), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4381278343498707), (18, 0.5108212977647781), (53, 0.8458427488803864)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.01603759080171585), (35, 0.01665342110209167), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02050345577299595), (46, 0.020725323585793376), (25, 0.021972602466121316), (23, 0.022379535948857665), (41, 0.022452629171311855), (44, 0.023364474531263113), (48, 0.024290354922413826), (45, 0.02443871251307428), (40, 0.02447055815719068), (21, 0.024924597470089793), (50, 0.025042171822860837), (22, 0.025168768595904112), (49, 0.025875969789922237), (24, 0.02589953737333417), (42, 0.026205406989902258), (20, 0.026859007542952895), (47, 0.028178582433611155), (15, 0.03192339185625315), (38, 0.03208350110799074), (7, 0.032285446766763926), (39, 0.032337441109120846), (19, 0.03262859582901001), (51, 0.039947258308529854), (37, 0.04073968296870589), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663246780634), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095685064792633), (0, 0.0630098101682961), (52, 0.06433630315586925), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.45053431019186974), (18, 0.5108213052153587), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470607835799456), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020046867663040757), (46, 0.02037699380889535), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.02237953501753509), (44, 0.023028336698189378), (48, 0.02377187623642385), (40, 0.023930812953040004), (45, 0.024178662337362766), (50, 0.024390299106016755), (21, 0.024924597470089793), (22, 0.025168767431750894), (42, 0.025188250932842493), (49, 0.025361528852954507), (24, 0.025899537140503526), (20, 0.02685900731012225), (47, 0.02736327867023647), (38, 0.03136561764404178), (15, 0.03192339139059186), (39, 0.03212768491357565), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03893592394888401), (37, 0.040206342935562134), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.060956849716603756), (52, 0.062328551430255175), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4444201923906803), (18, 0.5108213052153587), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365563735366), (28, 0.017088500084355474), (27, 0.01888244692236185), (43, 0.01959516596980393), (46, 0.020073580788448453), (41, 0.020961584988981485), (25, 0.02197260339744389), (23, 0.022379535948857665), (44, 0.02281495649367571), (48, 0.02312816074118018), (40, 0.02334519545547664), (50, 0.023756146896630526), (42, 0.023847302654758096), (45, 0.023873879807069898), (21, 0.02492459793575108), (49, 0.024960316019132733), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026855543022975326), (20, 0.02685900661163032), (38, 0.0304240130353719), (39, 0.03151404391974211), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.037824880331754684), (37, 0.03936835238710046), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.059249129611998796), (52, 0.06033282075077295), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4360685385763645), (18, 0.5108212977647781), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597365563735366
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945716798306), (27, 0.01888244692236185), (46, 0.01916008535772562), (41, 0.019424294820055366), (48, 0.02146727219223976), (25, 0.021972602466121316), (44, 0.022026916965842247), (40, 0.022179660852998495), (42, 0.022206430323421955), (50, 0.022256129188463092), (23, 0.022379535948857665), (45, 0.022931481478735805), (49, 0.023708513006567955), (21, 0.02492459793575108), (22, 0.025168768130242825), (47, 0.02582913963124156), (24, 0.025899537606164813), (20, 0.026859007077291608), (38, 0.02895654644817114), (39, 0.02966782869771123), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03600902669131756), (37, 0.03651238838210702), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846424981952), (52, 0.0561072863638401), (3, 0.057224278803914785), (13, 0.05892290314659476), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.41757645085453987), (18, 0.5108212977647781), (53, 0.9117145165801048)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.841 topk_dict {'top1': 0.841} is_best False lr [0.1]
training epoch 1 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best False lr [0.1]
training epoch 2 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 3 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 4 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 5 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 6 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 7 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 8 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 9 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.1]
training epoch 10 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140303436666727), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.01888244692236185), (48, 0.02090373425744474), (42, 0.021432004403322935), (40, 0.021832420956343412), (44, 0.021840531611815095), (50, 0.021869863849133253), (25, 0.021972602931782603), (23, 0.022379535948857665), (45, 0.02249284810386598), (49, 0.02312349807471037), (21, 0.024924597702920437), (47, 0.025067138951271772), (22, 0.02516876789741218), (24, 0.025899537606164813), (20, 0.026859007077291608), (38, 0.028114068554714322), (39, 0.029206908540800214), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859443202615), (51, 0.03545433655381203), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548466112464666), (52, 0.054696458857506514), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484460949898), (16, 0.08408283162862062), (12, 0.09042049571871758), (5, 0.10667386930435896), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.018140303436666727
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882446689531207), (46, 0.019302030326798558), (42, 0.021432004403322935), (48, 0.021544843213632703), (40, 0.021832421654835343), (50, 0.021946269553154707), (25, 0.021972602466121316), (23, 0.022379535483196378), (49, 0.023006869945675135), (44, 0.02310851006768644), (45, 0.023535606916993856), (21, 0.024924598168581724), (22, 0.02516876789741218), (47, 0.0258204466663301), (24, 0.025899536442011595), (20, 0.026859006844460964), (38, 0.02811406902037561), (39, 0.02920690830796957), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.035091488622128963), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.05332902865484357), (2, 0.05454846424981952), (3, 0.05722427600994706), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108212903141975), (53, 0.9678284004330635)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008863054216), (48, 0.020678168162703514), (50, 0.021344397915527225), (40, 0.021832421189174056), (25, 0.02197260269895196), (42, 0.021986940409988165), (23, 0.02237953571602702), (49, 0.022534748539328575), (45, 0.023929917253553867), (44, 0.024054003646597266), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537838995457), (47, 0.026043936610221863), (20, 0.02685900731012225), (38, 0.02811406902037561), (39, 0.02920690830796957), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03379447991028428), (37, 0.03597763832658529), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368270859122), (14, 0.04783663293346763), (52, 0.05047609377652407), (2, 0.05454846750944853), (3, 0.0572242783382535), (13, 0.05892289848998189), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.1066738748922944), (36, 0.4135979190468788), (18, 0.5108213126659393), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.0199897070415318), (50, 0.020775062032043934), (40, 0.021085952641442418), (42, 0.02136964723467827), (49, 0.021910030161961913), (25, 0.021972603164613247), (23, 0.022379535948857665), (44, 0.023239311994984746), (45, 0.023585307877510786), (21, 0.024924597702920437), (47, 0.025076947873458266), (22, 0.025168768130242825), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.032285445369780064), (19, 0.0326285962946713), (51, 0.032814261270686984), (37, 0.03542024455964565), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493682242929935), (14, 0.047836634796112776), (52, 0.048523631412535906), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831162575632334), (40, 0.02108595333993435), (42, 0.021369648166000843), (25, 0.021972602466121316), (23, 0.02237953571602702), (49, 0.022536989534273744), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899537606164813), (47, 0.026583048747852445), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.0328508117236197), (37, 0.03542024362832308), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.04783663293346763), (52, 0.048124796245247126), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980783998966), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952874273062), (42, 0.021369647700339556), (25, 0.021972602931782603), (23, 0.02237953571602702), (50, 0.022470062831416726), (44, 0.023239312693476677), (45, 0.023585309041664004), (21, 0.024924598168581724), (22, 0.025168768130242825), (49, 0.025234100874513388), (24, 0.02589953737333417), (47, 0.026583048747852445), (20, 0.026859006844460964), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.032969210762530565), (37, 0.035420244093984365), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.0508904499001801), (2, 0.054548464715480804), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233841538429), (18, 0.5108212903141975), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952874273062
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.021284765331074595), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.023098317440599203), (44, 0.024240857688710093), (49, 0.02450086921453476), (21, 0.024924597702920437), (22, 0.025168768130242825), (24, 0.025899536442011595), (47, 0.026519698556512594), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.02858075825497508), (15, 0.03192339139059186), (51, 0.032220848836004734), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663526177406), (52, 0.04885757155716419), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095685111358762), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.371861606836319)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.023761966731399298), (49, 0.024602339370176196), (44, 0.02471218118444085), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.02622047415934503), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758487805724), (51, 0.03127906727604568), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03542024316266179), (9, 0.04340188065543771), (52, 0.04610171029344201), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290361225605), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260339744389), (23, 0.022379535483196378), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537838995457), (47, 0.026220474392175674), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.028580758022144437), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.033443022053688765), (37, 0.03542024362832308), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.05265179416164756), (2, 0.05454846378415823), (3, 0.05722427926957607), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.628768116235733)]
computing accuracy for after removing block 25 . block score: 0.02197260339744389
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 1 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 2 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 5 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 6 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 7 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 8 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 9 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 10 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.966800)
finished training. finished 50 epochs. accuracy 0.9668 topk_dict {'top1': 0.9668}
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.048371. All blocks and scores: [(44, 0.048370860517024994), (49, 0.04871308896690607), (23, 0.049000458791852), (45, 0.05282785231247544), (47, 0.053568326868116856), (21, 0.05628248676657677), (22, 0.058122715912759304), (7, 0.058217029087245464), (38, 0.05852733692154288), (20, 0.05876078503206372), (51, 0.05936892330646515), (19, 0.06089031510055065), (24, 0.06189524382352829), (15, 0.06302175344899297), (39, 0.06312304176390171), (52, 0.06544935517013073), (37, 0.06832733564078808), (4, 0.07936693821102381), (6, 0.08499940857291222), (9, 0.08723007887601852), (2, 0.09526213258504868), (14, 0.09894520603120327), (3, 0.10105594992637634), (1, 0.10400402825325727), (13, 0.10745118744671345), (0, 0.10857369564473629), (17, 0.10864306427538395), (11, 0.111328667961061), (8, 0.13040229305624962), (16, 0.15345518104732037), (12, 0.15540000051259995), (10, 0.15965775027871132), (5, 0.1832097265869379), (36, 0.6382295489311218), (18, 0.7042868584394455), (53, 1.0031306594610214)]
computing accuracy for after removing block 44 . block score: 0.048370860517024994
removed block 44 current accuracy 0.9602 loss from initial  0.03979999999999995
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.048415. All blocks and scores: [(49, 0.04841463174670935), (23, 0.04900045972317457), (45, 0.055855931248515844), (21, 0.05628248257562518), (51, 0.05728306155651808), (47, 0.058050880674272776), (22, 0.058122715912759304), (7, 0.058217025361955166), (38, 0.058527336455881596), (20, 0.05876078503206372), (19, 0.06089031370356679), (24, 0.06189524149522185), (15, 0.06302175438031554), (39, 0.06312304176390171), (52, 0.06411078292876482), (37, 0.06832733657211065), (4, 0.07936693634837866), (6, 0.08499941043555737), (9, 0.0872300798073411), (2, 0.09526212979108095), (14, 0.09894520789384842), (3, 0.10105595272034407), (1, 0.10400402825325727), (13, 0.10745118651539087), (0, 0.10857369471341372), (17, 0.10864306334406137), (11, 0.11132867075502872), (8, 0.13040229678153992), (16, 0.15345518477261066), (12, 0.15539999678730965), (10, 0.15965775400400162), (5, 0.1832097228616476), (36, 0.63822952657938), (18, 0.7042868807911873), (53, 1.110426813364029)]
computing accuracy for after removing block 49 . block score: 0.04841463174670935
removed block 49 current accuracy 0.9488 loss from initial  0.05120000000000002
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.049000. All blocks and scores: [(23, 0.04900046065449715), (45, 0.055855931248515844), (21, 0.05628248443827033), (47, 0.05805088113993406), (22, 0.05812271451577544), (7, 0.05821702675893903), (38, 0.05852733599022031), (20, 0.05876078503206372), (19, 0.06089031556621194), (24, 0.061895243357867), (15, 0.06302175624296069), (39, 0.06312304269522429), (51, 0.06479816418141127), (37, 0.06832733564078808), (52, 0.07115933485329151), (4, 0.07936693727970123), (6, 0.08499940857291222), (9, 0.0872300798073411), (2, 0.09526212885975838), (14, 0.098945208825171), (3, 0.10105594992637634), (1, 0.1040040273219347), (13, 0.10745118744671345), (0, 0.10857369471341372), (17, 0.10864306055009365), (11, 0.111328667961061), (8, 0.13040229305624962), (16, 0.15345518477261066), (12, 0.1553999986499548), (10, 0.15965775214135647), (5, 0.18320972472429276), (36, 0.6382295414805412), (18, 0.7042868658900261), (53, 1.2825424373149872)]
computing accuracy for after removing block 23 . block score: 0.04900046065449715
removed block 23 current accuracy 0.9414 loss from initial  0.058599999999999985
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 47, with score 0.055485. All blocks and scores: [(47, 0.055485321674495935), (45, 0.0558721162378788), (21, 0.056282483506947756), (38, 0.058037522714585066), (22, 0.058122715912759304), (7, 0.05821702582761645), (20, 0.05876078503206372), (24, 0.058761488646268845), (19, 0.06089031370356679), (15, 0.06302175391465425), (39, 0.06332956813275814), (51, 0.06451328750699759), (52, 0.06942652631551027), (37, 0.07119859289377928), (4, 0.07936693727970123), (6, 0.08499940857291222), (9, 0.08723007794469595), (2, 0.09526212979108095), (14, 0.09894520603120327), (3, 0.10105594992637634), (1, 0.1040040235966444), (13, 0.10745118744671345), (0, 0.10857369285076857), (17, 0.1086430624127388), (11, 0.11132867075502872), (8, 0.13040229305624962), (16, 0.15345518290996552), (12, 0.15539999678730965), (10, 0.15965775027871132), (5, 0.1832097265869379), (36, 0.6479395627975464), (18, 0.7042868733406067), (53, 1.278409257531166)]
computing accuracy for after removing block 47 . block score: 0.055485321674495935
removed block 47 current accuracy 0.9106 loss from initial  0.08940000000000003
since last training loss: 0.05620000000000003 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.055872. All blocks and scores: [(45, 0.05587211810052395), (21, 0.05628248117864132), (38, 0.058037521317601204), (22, 0.05812271684408188), (7, 0.0582170276902616), (20, 0.05876078549772501), (24, 0.058761484920978546), (19, 0.06089031416922808), (15, 0.06302175391465425), (39, 0.06332956813275814), (51, 0.06583492644131184), (37, 0.0711985919624567), (52, 0.07156881503760815), (4, 0.07936694007366896), (6, 0.08499941043555737), (9, 0.0872300798073411), (2, 0.0952621353790164), (14, 0.098945208825171), (3, 0.10105594992637634), (1, 0.1040040273219347), (13, 0.1074511893093586), (0, 0.10857369378209114), (17, 0.10864306055009365), (11, 0.11132867075502872), (8, 0.13040229305624962), (16, 0.15345517918467522), (12, 0.15539999678730965), (10, 0.15965775586664677), (5, 0.18320972844958305), (36, 0.6479395851492882), (18, 0.7042868733406067), (53, 1.3972737789154053)]
computing accuracy for after removing block 45 . block score: 0.05587211810052395
removed block 45 current accuracy 0.874 loss from initial  0.126
since last training loss: 0.0928 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.056282. All blocks and scores: [(21, 0.05628248443827033), (38, 0.05803752178326249), (22, 0.05812271498143673), (7, 0.05821703001856804), (20, 0.05876078549772501), (24, 0.05876148724928498), (19, 0.060890316031873226), (15, 0.06302175531163812), (39, 0.06332956720143557), (51, 0.0654527461156249), (37, 0.0711985919624567), (52, 0.07771460060030222), (4, 0.07936693634837866), (6, 0.08499941043555737), (9, 0.08723007887601852), (2, 0.09526213444769382), (14, 0.0989452050998807), (3, 0.10105595085769892), (1, 0.1040040273219347), (13, 0.10745118465274572), (0, 0.10857369471341372), (17, 0.10864306520670652), (11, 0.111328667961061), (8, 0.13040229305624962), (16, 0.15345518104732037), (12, 0.15540000051259995), (10, 0.15965775400400162), (5, 0.18320972472429276), (36, 0.6479395478963852), (18, 0.7042868733406067), (53, 1.5213665813207626)]
computing accuracy for after removing block 21 . block score: 0.05628248443827033
removed block 21 current accuracy 0.8524 loss from initial  0.14759999999999995
since last training loss: 0.11439999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.051241. All blocks and scores: [(22, 0.05124085769057274), (24, 0.052268208004534245), (38, 0.05502884415909648), (7, 0.05821702582761645), (20, 0.05876078363507986), (19, 0.06089031370356679), (39, 0.061119509395211935), (15, 0.06302175531163812), (51, 0.0631108209490776), (37, 0.06755404267460108), (52, 0.07045848853886127), (4, 0.07936693634837866), (6, 0.08499940764158964), (9, 0.08723007887601852), (2, 0.0952621316537261), (14, 0.09894520696252584), (3, 0.10105594992637634), (1, 0.10400402918457985), (13, 0.10745118744671345), (0, 0.10857369750738144), (17, 0.1086430624127388), (11, 0.111328667961061), (8, 0.13040229491889477), (16, 0.15345518104732037), (12, 0.15539999678730965), (10, 0.15965775586664677), (5, 0.1832097265869379), (36, 0.6166170910000801), (18, 0.7042868733406067), (53, 1.5432511121034622)]
computing accuracy for after removing block 22 . block score: 0.05124085769057274
removed block 22 current accuracy 0.8148 loss from initial  0.18520000000000003
since last training loss: 0.15200000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.048099. All blocks and scores: [(24, 0.048098734114319086), (38, 0.05512944748625159), (7, 0.05821702862158418), (20, 0.058760782703757286), (19, 0.06089031510055065), (51, 0.061411770060658455), (39, 0.06148065626621246), (15, 0.06302175391465425), (52, 0.06880021840333939), (37, 0.07209265511482954), (4, 0.07936694007366896), (6, 0.08499940857291222), (9, 0.08723007887601852), (2, 0.09526213444769382), (14, 0.098945208825171), (3, 0.1010559480637312), (1, 0.104004031047225), (13, 0.10745118651539087), (0, 0.10857369285076857), (17, 0.10864306334406137), (11, 0.111328667961061), (8, 0.13040229864418507), (16, 0.15345517918467522), (12, 0.1553999949246645), (10, 0.15965775586664677), (5, 0.18320972472429276), (36, 0.6251004636287689), (18, 0.7042868658900261), (53, 1.5258284509181976)]
computing accuracy for after removing block 24 . block score: 0.048098734114319086
removed block 24 current accuracy 0.7768 loss from initial  0.22319999999999995
since last training loss: 0.18999999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.053912. All blocks and scores: [(38, 0.053912058006972075), (51, 0.05816150503233075), (7, 0.05821702862158418), (39, 0.05846458626911044), (20, 0.05876078363507986), (19, 0.060890314634889364), (15, 0.06302175438031554), (52, 0.06539301853626966), (37, 0.06843397207558155), (4, 0.07936693727970123), (6, 0.08499941043555737), (9, 0.08723007794469595), (2, 0.09526212979108095), (14, 0.09894520603120327), (3, 0.10105595365166664), (1, 0.10400402918457985), (13, 0.10745118744671345), (0, 0.10857369285076857), (17, 0.10864306706935167), (11, 0.11132866702973843), (8, 0.13040229305624962), (16, 0.15345518104732037), (12, 0.1553999986499548), (10, 0.15965775772929192), (5, 0.18320972844958305), (36, 0.6043444126844406), (18, 0.7042868733406067), (53, 1.5072494447231293)]
computing accuracy for after removing block 38 . block score: 0.053912058006972075
removed block 38 current accuracy 0.748 loss from initial  0.252
training start
training epoch 0 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best True lr [0.1]
training epoch 1 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.1]
training epoch 2 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 3 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 4 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 5 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 6 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 7 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 8 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 9 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.066750. All blocks and scores: [(7, 0.06674990709871054), (15, 0.08381746150553226), (52, 0.08735920954495668), (51, 0.09074796922504902), (19, 0.09137487784028053), (37, 0.09779865574091673), (4, 0.09861703868955374), (6, 0.09865215979516506), (20, 0.10299699660390615), (9, 0.10631393361836672), (39, 0.10831953678280115), (2, 0.10868529882282019), (0, 0.11121638119220734), (11, 0.11668132618069649), (13, 0.11816578079015017), (14, 0.12032556906342506), (17, 0.1273658089339733), (3, 0.12802131101489067), (1, 0.12835165113210678), (8, 0.15588321909308434), (10, 0.1772117018699646), (12, 0.18137847632169724), (16, 0.19509389251470566), (5, 0.21364608593285084), (36, 0.5532919019460678), (18, 0.6343948021531105), (53, 1.1295045465230942)]
computing accuracy for after removing block 7 . block score: 0.06674990709871054
removed block 7 current accuracy 0.9394 loss from initial  0.06059999999999999
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.080783. All blocks and scores: [(15, 0.08078348822891712), (52, 0.08271083980798721), (19, 0.08460056129842997), (51, 0.08827590104192495), (37, 0.0907392967492342), (20, 0.0977415693923831), (4, 0.09861703868955374), (6, 0.09865215700119734), (13, 0.10426978953182697), (9, 0.10438222531229258), (39, 0.10559420567005873), (17, 0.10766134690493345), (2, 0.10868530161678791), (11, 0.10946246236562729), (0, 0.11121637653559446), (14, 0.11504129972308874), (3, 0.12802131287753582), (1, 0.12835165299475193), (8, 0.14490055106580257), (12, 0.16186783462762833), (16, 0.17266832292079926), (10, 0.17626567743718624), (5, 0.21364607848227024), (36, 0.5276883915066719), (18, 0.6026063114404678), (53, 1.1283288449048996)]
computing accuracy for after removing block 15 . block score: 0.08078348822891712
removed block 15 current accuracy 0.9312 loss from initial  0.06879999999999997
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 52, with score 0.081602. All blocks and scores: [(52, 0.08160179574042559), (19, 0.08221750799566507), (37, 0.08828873466700315), (51, 0.08903019409626722), (20, 0.09174394141882658), (4, 0.09861704148352146), (6, 0.09865215793251991), (13, 0.10426979046314955), (9, 0.10438222344964743), (39, 0.1049819365143776), (2, 0.10868530068546534), (17, 0.1091804588213563), (11, 0.10946246236562729), (0, 0.11121638026088476), (14, 0.11504130158573389), (3, 0.12802131474018097), (1, 0.12835165113210678), (8, 0.14490054920315742), (12, 0.16186784207820892), (10, 0.1762656755745411), (16, 0.19876968301832676), (5, 0.2136460840702057), (36, 0.5079677700996399), (18, 0.5809889510273933), (53, 1.1448993235826492)]
computing accuracy for after removing block 52 . block score: 0.08160179574042559
removed block 52 current accuracy 0.889 loss from initial  0.11099999999999999
since last training loss: 0.05479999999999996 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 19, with score 0.082218. All blocks and scores: [(19, 0.0822175070643425), (37, 0.0882887365296483), (51, 0.08903019689023495), (20, 0.09174394141882658), (4, 0.09861703962087631), (6, 0.09865216165781021), (13, 0.10426979046314955), (9, 0.10438222344964743), (39, 0.10498193837702274), (2, 0.10868530347943306), (17, 0.109180455096066), (11, 0.10946246422827244), (0, 0.11121638212352991), (14, 0.11504130158573389), (3, 0.12802131474018097), (1, 0.12835165113210678), (8, 0.14490054920315742), (12, 0.16186784021556377), (10, 0.1762656755745411), (16, 0.1987696811556816), (5, 0.2136460840702057), (36, 0.5079677700996399), (18, 0.5809889510273933), (53, 1.261941984295845)]
computing accuracy for after removing block 19 . block score: 0.0822175070643425
removed block 19 current accuracy 0.8552 loss from initial  0.14480000000000004
since last training loss: 0.08860000000000001 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.086266. All blocks and scores: [(20, 0.08626590017229319), (51, 0.08849694207310677), (4, 0.09861703868955374), (6, 0.09865216072648764), (37, 0.10219599213451147), (13, 0.1042697886005044), (9, 0.10438222624361515), (39, 0.10770922340452671), (2, 0.10868529602885246), (17, 0.1091804588213563), (11, 0.10946245957165956), (0, 0.11121637932956219), (14, 0.11504129692912102), (3, 0.12802131101489067), (1, 0.12835164740681648), (8, 0.14490055292844772), (12, 0.16186783835291862), (10, 0.1762656755745411), (16, 0.1987696848809719), (5, 0.2136460803449154), (36, 0.5236765816807747), (18, 0.5809889286756516), (53, 1.2332326620817184)]
computing accuracy for after removing block 20 . block score: 0.08626590017229319
removed block 20 current accuracy 0.789 loss from initial  0.21099999999999997
since last training loss: 0.15479999999999994 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.080144. All blocks and scores: [(51, 0.0801437720656395), (4, 0.09861704055219889), (6, 0.09865215700119734), (13, 0.10426978953182697), (9, 0.1043822206556797), (39, 0.10457481909543276), (2, 0.10868530068546534), (17, 0.10918045416474342), (11, 0.10946245957165956), (0, 0.11121637839823961), (37, 0.11289600282907486), (14, 0.11504129972308874), (3, 0.12802131567150354), (1, 0.12835164740681648), (8, 0.14490055106580257), (12, 0.16186783649027348), (10, 0.17626567743718624), (16, 0.1987696848809719), (5, 0.21364608220756054), (36, 0.5382440388202667), (18, 0.5809889361262321), (53, 1.0900808423757553)]
computing accuracy for after removing block 51 . block score: 0.0801437720656395
removed block 51 current accuracy 0.6872 loss from initial  0.31279999999999997
since last training loss: 0.25659999999999994 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.098617. All blocks and scores: [(4, 0.09861703868955374), (6, 0.09865215700119734), (13, 0.10426978953182697), (9, 0.10438222438097), (39, 0.10457481816411018), (2, 0.10868529882282019), (17, 0.10918045323342085), (11, 0.10946246329694986), (0, 0.11121638305485249), (37, 0.11289600376039743), (14, 0.11504130251705647), (3, 0.12802131474018097), (1, 0.12835165113210678), (8, 0.14490054734051228), (12, 0.16186783649027348), (10, 0.17626567743718624), (16, 0.19876968301832676), (5, 0.21364607475697994), (36, 0.5382440537214279), (18, 0.5809889361262321), (53, 1.2656806707382202)]
computing accuracy for after removing block 4 . block score: 0.09861703868955374
removed block 4 current accuracy 0.6588 loss from initial  0.34119999999999995
since last training loss: 0.2849999999999999 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.103990. All blocks and scores: [(39, 0.10399035643786192), (13, 0.10429952759295702), (11, 0.10490291938185692), (17, 0.10550796799361706), (9, 0.10653978493064642), (2, 0.10868529789149761), (0, 0.11121637467294931), (14, 0.11378855258226395), (37, 0.11823642812669277), (6, 0.11862560920417309), (3, 0.12802131194621325), (1, 0.12835164740681648), (8, 0.14696165546774864), (12, 0.1531106997281313), (10, 0.1704738661646843), (16, 0.17974977754056454), (5, 0.23469849303364754), (36, 0.5465362295508385), (18, 0.5823644623160362), (53, 1.237553671002388)]
computing accuracy for after removing block 39 . block score: 0.10399035643786192
removed block 39 current accuracy 0.5308 loss from initial  0.46919999999999995
since last training loss: 0.4129999999999999 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 13, with score 0.104300. All blocks and scores: [(13, 0.10429952945560217), (11, 0.10490291845053434), (17, 0.10550796892493963), (9, 0.10653978306800127), (2, 0.10868529975414276), (0, 0.11121638398617506), (14, 0.11378854885697365), (37, 0.1182364271953702), (6, 0.11862560827285051), (3, 0.12802130915224552), (1, 0.12835164926946163), (8, 0.14696165546774864), (12, 0.15311069786548615), (10, 0.17047386430203915), (16, 0.1797497794032097), (5, 0.2346984948962927), (36, 0.5465362444519997), (18, 0.5823644623160362), (53, 1.3475056141614914)]
computing accuracy for after removing block 13 . block score: 0.10429952945560217
removed block 13 current accuracy 0.4386 loss from initial  0.5614
since last training loss: 0.5052 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 11, with score 0.104903. All blocks and scores: [(11, 0.10490291845053434), (9, 0.10653978772461414), (2, 0.10868530068546534), (0, 0.11121637932956219), (17, 0.11188498977571726), (6, 0.11862560734152794), (37, 0.1209266846999526), (14, 0.12728490866720676), (3, 0.12802130728960037), (1, 0.12835164926946163), (8, 0.1469616573303938), (12, 0.1531106997281313), (10, 0.170473862439394), (16, 0.1975800935178995), (5, 0.2346984948962927), (36, 0.5411006286740303), (18, 0.5766995474696159), (53, 1.443428486585617)]
computing accuracy for after removing block 11 . block score: 0.10490291845053434
removed block 11 current accuracy 0.3804 loss from initial  0.6195999999999999
since last training loss: 0.5633999999999999 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 17, with score 0.103056. All blocks and scores: [(17, 0.1030558031052351), (9, 0.10653978306800127), (2, 0.10868530254811049), (0, 0.11121637839823961), (6, 0.11862561013549566), (37, 0.12456707004457712), (14, 0.12463216576725245), (3, 0.12802131194621325), (1, 0.12835165299475193), (12, 0.1392965205013752), (8, 0.1469616573303938), (16, 0.14805562421679497), (10, 0.17047386057674885), (5, 0.23469849675893784), (36, 0.5438095852732658), (18, 0.5878777503967285), (53, 1.4065249562263489)]
computing accuracy for after removing block 17 . block score: 0.1030558031052351
removed block 17 current accuracy 0.352 loss from initial  0.648
since last training loss: 0.5918 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 9, with score 0.106540. All blocks and scores: [(9, 0.10653978399932384), (2, 0.10868529975414276), (0, 0.11121638119220734), (37, 0.11631461698561907), (6, 0.11862560827285051), (14, 0.12463216204196215), (3, 0.1280213175341487), (1, 0.12835165113210678), (12, 0.1392965167760849), (8, 0.14696165919303894), (16, 0.14805562607944012), (10, 0.1704738661646843), (5, 0.23469848930835724), (36, 0.5123439207673073), (18, 0.5559138581156731), (53, 1.4174696803092957)]
computing accuracy for after removing block 9 . block score: 0.10653978399932384
removed block 9 current accuracy 0.329 loss from initial  0.671
training start
training epoch 0 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best True lr [0.1]
training epoch 1 val accuracy 0.7498 topk_dict {'top1': 0.7498} is_best False lr [0.1]
training epoch 2 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.1]
training epoch 3 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.1]
training epoch 4 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 5 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best True lr [0.1]
training epoch 6 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 7 val accuracy 0.7988 topk_dict {'top1': 0.7988} is_best False lr [0.1]
training epoch 8 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 9 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 10 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.927400)
finished training. finished 50 epochs. accuracy 0.9274 topk_dict {'top1': 0.9274}
