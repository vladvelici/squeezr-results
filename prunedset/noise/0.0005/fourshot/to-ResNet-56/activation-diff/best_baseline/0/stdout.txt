start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996206175536), (32, 0.009233050630427897), (30, 0.01003940065857023), (31, 0.010361599968746305), (34, 0.013312276103533804), (29, 0.013541154796257615), (35, 0.01601846283301711), (26, 0.01603759080171585), (28, 0.017728676088154316), (27, 0.01912704878486693), (43, 0.02023245650343597), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.022379535250365734), (41, 0.022826648084446788), (44, 0.023395078955218196), (40, 0.02402502507902682), (45, 0.024295411072671413), (21, 0.02492459793575108), (22, 0.025168768130242825), (48, 0.025341259548440576), (24, 0.025899537140503526), (50, 0.026409973157569766), (42, 0.026674100663512945), (20, 0.026859007077291608), (49, 0.027037164196372032), (47, 0.029306469717994332), (39, 0.031570713268592954), (38, 0.031637870240956545), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03796026250347495), (51, 0.04173417203128338), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924912681803107), (17, 0.06095684925094247), (0, 0.06300981063395739), (1, 0.06676734145730734), (52, 0.06862937565892935), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.43758000805974007), (18, 0.5108212977647781), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996206175536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.01003940065857023), (31, 0.010361600085161626), (34, 0.013133947271853685), (29, 0.013541154563426971), (26, 0.01603759010322392), (35, 0.01616928935982287), (28, 0.017728676088154316), (27, 0.019127049250528216), (43, 0.020072476705536246), (46, 0.020731384633108974), (25, 0.02197260200046003), (41, 0.022347092861309648), (23, 0.022379535483196378), (44, 0.023235687287524343), (40, 0.023841066984459758), (45, 0.02396554173901677), (48, 0.02491791662760079), (21, 0.024924598168581724), (22, 0.025168768130242825), (50, 0.025840813061222434), (24, 0.025899537606164813), (42, 0.026315324008464813), (49, 0.02665567467920482), (20, 0.026859007077291608), (47, 0.028728798031806946), (39, 0.03131764172576368), (38, 0.03138036374002695), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03802584344521165), (51, 0.041223940439522266), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (52, 0.0674515487626195), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.43538709729909897), (18, 0.5108212977647781), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400774985552), (31, 0.010361600085161626), (34, 0.012765232590027153), (29, 0.013541154214181006), (35, 0.01599275111220777), (26, 0.01603759010322392), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02007513213902712), (46, 0.020841406425461173), (25, 0.021972602466121316), (41, 0.022319766925647855), (23, 0.022379535483196378), (44, 0.02315405081026256), (40, 0.02388568432070315), (45, 0.024071689695119858), (48, 0.024877465097233653), (21, 0.024924598168581724), (22, 0.025168768828734756), (50, 0.025691177928820252), (24, 0.02589953737333417), (42, 0.026123747695237398), (49, 0.026479422114789486), (20, 0.026859006378799677), (47, 0.028693132335320115), (38, 0.031236795941367745), (39, 0.03129529254510999), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.038376690819859505), (51, 0.04111403366550803), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300981063395739), (1, 0.06676734238862991), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.43640000745654106), (18, 0.5108212977647781), (53, 0.828934907913208)]
computing accuracy for after removing block 30 . block score: 0.010039400774985552
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387837399728596), (29, 0.013541154214181006), (35, 0.016008096281439066), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02008363325148821), (46, 0.02070444426499307), (25, 0.021972602931782603), (41, 0.02225319715216756), (23, 0.022379535483196378), (44, 0.02326776133850217), (40, 0.024013880407437682), (45, 0.024092992767691612), (48, 0.02466528001241386), (21, 0.024924598168581724), (22, 0.025168767664581537), (50, 0.025459734024479985), (42, 0.02565571339800954), (24, 0.0258995380718261), (49, 0.026287756161764264), (20, 0.02685900661163032), (47, 0.02836342342197895), (38, 0.03104764735326171), (39, 0.03138077282346785), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.0326285962946713), (37, 0.03897124482318759), (51, 0.04075620276853442), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.05892289895564318), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980970263481), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4389924518764019), (18, 0.5108212977647781), (53, 0.8391561806201935)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154330596328), (26, 0.016037590336054564), (35, 0.01605736301280558), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020049349404871464), (46, 0.020552987465634942), (25, 0.021972602466121316), (41, 0.022067484445869923), (23, 0.022379534784704447), (44, 0.022979133296757936), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.024386122589930892), (21, 0.024924598168581724), (50, 0.02504224074073136), (22, 0.025168767664581537), (42, 0.02541450783610344), (49, 0.025842698756605387), (24, 0.02589953737333417), (20, 0.026859008008614182), (47, 0.028050734661519527), (38, 0.0310400587040931), (39, 0.03150080353952944), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.03262859536334872), (37, 0.039112846832722425), (51, 0.04024627432227135), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663526177406), (2, 0.05454846518114209), (3, 0.05722428113222122), (13, 0.058922899421304464), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980830565095), (52, 0.06486208876594901), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4381278455257416), (18, 0.5108212977647781), (53, 0.8458427861332893)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154330596328), (26, 0.016037590336054564), (35, 0.016653420170769095), (28, 0.01772867515683174), (27, 0.019127049250528216), (43, 0.020503455540165305), (46, 0.020725322421640158), (25, 0.021972602931782603), (23, 0.02237953501753509), (41, 0.022452628472819924), (44, 0.0233644749969244), (48, 0.024290354689583182), (45, 0.024438712978735566), (40, 0.024470558622851968), (21, 0.02492459723725915), (50, 0.025042171590030193), (22, 0.025168768363073468), (49, 0.02587597002275288), (24, 0.025899536907672882), (42, 0.02620540652424097), (20, 0.026859007077291608), (47, 0.028178582433611155), (15, 0.03192339139059186), (38, 0.032083500642329454), (7, 0.03228544630110264), (39, 0.032337441109120846), (19, 0.03262859536334872), (51, 0.03994725923985243), (37, 0.04073968343436718), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846424981952), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.0630098101682961), (52, 0.06433630269020796), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.45053432136774063), (18, 0.5108213126659393), (53, 0.8443200513720512)]
computing accuracy for after removing block 29 . block score: 0.013541154330596328
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 1 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 2 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.1]
training epoch 7 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.1]
training epoch 8 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 9 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.1]
training epoch 10 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.0164706080686301), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02004686719737947), (46, 0.02037699311040342), (41, 0.021723242942243814), (25, 0.021972602233290672), (23, 0.02237953501753509), (44, 0.023028336465358734), (48, 0.023771876469254494), (40, 0.023930813185870647), (45, 0.024178662337362766), (50, 0.024390298640355468), (21, 0.024924598168581724), (22, 0.0251687690615654), (42, 0.025188250932842493), (49, 0.025361528852954507), (24, 0.025899537140503526), (20, 0.026859007077291608), (47, 0.027363279601559043), (38, 0.031365619506686926), (15, 0.03192339139059186), (39, 0.03212768537923694), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03893592348322272), (37, 0.040206342935562134), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.05892289988696575), (11, 0.05924912774935365), (17, 0.06095684785395861), (52, 0.06232854910194874), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4444201998412609), (18, 0.5108212903141975), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365330904722), (28, 0.01708849985152483), (27, 0.018882447155192494), (43, 0.019595165271312), (46, 0.020073581021279097), (41, 0.020961585454642773), (25, 0.021972602931782603), (23, 0.02237953618168831), (44, 0.022814956260845065), (48, 0.02312816074118018), (40, 0.02334519545547664), (50, 0.023756147595122457), (42, 0.023847301956266165), (45, 0.02387388050556183), (21, 0.024924598168581724), (49, 0.02496031578630209), (22, 0.02516876789741218), (24, 0.02589953737333417), (47, 0.02685554255731404), (20, 0.026859007542952895), (38, 0.030424013268202543), (39, 0.031514043686911464), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03782488079741597), (37, 0.03936835192143917), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663293346763), (2, 0.05454846518114209), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912914633751), (52, 0.06033282075077295), (17, 0.06095685064792633), (0, 0.06300980783998966), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.4360685497522354), (18, 0.5108212977647781), (53, 0.8749377354979515)]
computing accuracy for after removing block 35 . block score: 0.015597365330904722
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945716798306), (27, 0.01888244692236185), (46, 0.01916008535772562), (41, 0.01942429505288601), (48, 0.021467271726578474), (25, 0.021972602233290672), (44, 0.022026916965842247), (40, 0.02217966062016785), (42, 0.02220643009059131), (50, 0.022256129421293736), (23, 0.022379535948857665), (45, 0.022931481711566448), (49, 0.02370851277373731), (21, 0.024924597702920437), (22, 0.025168767664581537), (47, 0.025829140096902847), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.02895654598250985), (39, 0.0296678279992193), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03600902669131756), (37, 0.036512387450784445), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493685968220234), (14, 0.04783663433045149), (2, 0.05454846378415823), (52, 0.0561072863638401), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980783998966), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.41757645085453987), (18, 0.5108213052153587), (53, 0.9117144867777824)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102241948247), (41, 0.018849018262699246), (27, 0.018882447388023138), (48, 0.02090373425744474), (42, 0.02143200463615358), (40, 0.0218324214220047), (44, 0.021840530913323164), (50, 0.021869863383471966), (25, 0.02197260200046003), (23, 0.022379535483196378), (45, 0.02249284810386598), (49, 0.023123498307541013), (21, 0.024924597702920437), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.029206908773630857), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.032628596760332584), (51, 0.035454337019473314), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846518114209), (52, 0.05469645792618394), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095685064792633), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4135979153215885), (18, 0.5108212903141975), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882446689531207), (46, 0.019302030093967915), (42, 0.02143200463615358), (48, 0.02154484367929399), (40, 0.021832421887665987), (50, 0.021946269320324063), (25, 0.02197260339744389), (23, 0.02237953501753509), (49, 0.02300686971284449), (44, 0.02310851006768644), (45, 0.023535606916993856), (21, 0.024924598168581724), (22, 0.025168768130242825), (47, 0.025820446200668812), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.02811406902037561), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.035091488156467676), (37, 0.035977639723569155), (9, 0.04340187879279256), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.04783663526177406), (52, 0.053329029120504856), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290407791734), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4135979041457176), (18, 0.5108212977647781), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.019070088397711515), (48, 0.020678168395534158), (50, 0.021344397449865937), (40, 0.0218324214220047), (25, 0.021972602233290672), (42, 0.021986940409988165), (23, 0.022379535483196378), (49, 0.022534748073667288), (45, 0.023929916555061936), (44, 0.02405400271527469), (21, 0.024924598168581724), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026043937308713794), (20, 0.02685900777578354), (38, 0.028114068554714322), (39, 0.029206908773630857), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.033794480841606855), (37, 0.03597763925790787), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836634796112776), (52, 0.05047609377652407), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.058922899421304464), (11, 0.05924912728369236), (17, 0.06095684692263603), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 1.0278180092573166)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 1 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 2 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 3 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.1]
training epoch 4 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 7 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.1]
training epoch 8 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 9 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.1]
training epoch 10 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.019989707740023732), (50, 0.020775062032043934), (40, 0.021085952874273062), (42, 0.0213696479331702), (49, 0.021910030161961913), (25, 0.02197260339744389), (23, 0.02237953501753509), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.024924597702920437), (47, 0.025076947873458266), (22, 0.025168769294396043), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.02718336135149002), (39, 0.028580759186297655), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.0328142608050257), (37, 0.035420244093984365), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.048523630015552044), (2, 0.05454846331849694), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831161877140403), (40, 0.021085952874273062), (42, 0.021369647700339556), (25, 0.021972602466121316), (23, 0.02237953571602702), (49, 0.02253698999993503), (44, 0.023239311994984746), (45, 0.023585309041664004), (21, 0.024924597004428506), (22, 0.025168767431750894), (24, 0.025899537606164813), (47, 0.02658304967917502), (20, 0.026859007077291608), (38, 0.02718335995450616), (39, 0.028580758487805724), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03285081312060356), (37, 0.03542024362832308), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663200214505), (52, 0.0481247971765697), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.05892290221527219), (11, 0.05924913054332137), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4065234027802944), (18, 0.5108213126659393), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647467508912), (25, 0.021972602466121316), (23, 0.022379535483196378), (50, 0.02247006190009415), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.024924598401412368), (22, 0.025168768363073468), (49, 0.025234101340174675), (24, 0.025899537140503526), (47, 0.0265830485150218), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.028580759186297655), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03296921169385314), (37, 0.035420244093984365), (9, 0.043401881121098995), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.050890452694147825), (2, 0.05454846424981952), (3, 0.05722427973523736), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832509428263), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.2663909196853638)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.021284766029566526), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.023098317440599203), (44, 0.024240857921540737), (49, 0.024500868748873472), (21, 0.024924597702920437), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026519698789343238), (20, 0.026859008241444826), (38, 0.027183361118659377), (39, 0.028580758487805724), (15, 0.03192339278757572), (51, 0.03222084930166602), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.03542024502530694), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.0478366338647902), (52, 0.04885757155716419), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049665004015), (5, 0.1066738748922944), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.3718616217374802)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658070251346), (25, 0.021972602931782603), (23, 0.02237953501753509), (45, 0.02376196556724608), (49, 0.024602338206022978), (44, 0.02471218118444085), (21, 0.024924597702920437), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026220474392175674), (20, 0.026859006378799677), (38, 0.027183360420167446), (39, 0.028580758022144437), (51, 0.031279068207368255), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.035420244093984365), (9, 0.043401879258453846), (52, 0.046101709827780724), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846937209368), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667387582361698), (36, 0.4065233990550041), (18, 0.5108213201165199), (53, 1.4178234338760376)]
computing accuracy for after removing block 50 . block score: 0.021202658070251346
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.024712180718779564), (21, 0.02492459793575108), (22, 0.025168768595904112), (24, 0.025899537140503526), (47, 0.026220474625006318), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03344302158802748), (37, 0.03542024362832308), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836633399128914), (52, 0.05265179369598627), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.060956846456974745), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 1 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 2 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 3 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 4 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 9 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 10 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.969400)
finished training. finished 50 epochs. accuracy 0.9694 topk_dict {'top1': 0.9694}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.046912. All blocks and scores: [(49, 0.046912329737097025), (44, 0.05029802909120917), (45, 0.0518635711632669), (22, 0.053882315289229155), (21, 0.053953069262206554), (19, 0.05433875881135464), (47, 0.055321740452200174), (7, 0.05566878616809845), (15, 0.05899245897307992), (20, 0.05918652843683958), (23, 0.059216133784502745), (51, 0.05977538553997874), (38, 0.060610664542764425), (24, 0.06525112502276897), (39, 0.06707869935780764), (37, 0.06907626055181026), (52, 0.0691169397905469), (9, 0.08285300992429256), (4, 0.08417576551437378), (6, 0.08650580886751413), (14, 0.09107155818492174), (0, 0.09192068967968225), (2, 0.09352327417582273), (17, 0.09610845986753702), (11, 0.09739911835640669), (13, 0.10148037318140268), (3, 0.10201234370470047), (1, 0.10998694971203804), (8, 0.12189531233161688), (10, 0.13772856444120407), (12, 0.14957465417683125), (16, 0.1640481185168028), (5, 0.19186345674097538), (36, 0.6212798729538918), (18, 0.6735120266675949), (53, 0.9916035085916519)]
computing accuracy for after removing block 49 . block score: 0.046912329737097025
removed block 49 current accuracy 0.9582 loss from initial  0.04179999999999995
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.050298. All blocks and scores: [(44, 0.05029803002253175), (45, 0.05186357069760561), (22, 0.053882315289229155), (21, 0.05395306972786784), (19, 0.05433875881135464), (47, 0.05532174138352275), (7, 0.05566878663375974), (15, 0.05899245943874121), (20, 0.05918652843683958), (23, 0.059216135647147894), (38, 0.06061066314578056), (51, 0.06266020843759179), (24, 0.06525112502276897), (39, 0.06707869935780764), (37, 0.06907626055181026), (52, 0.07328623253852129), (9, 0.08285301085561514), (4, 0.0841757645830512), (6, 0.08650580979883671), (14, 0.09107155539095402), (0, 0.09192068967968225), (2, 0.09352327417582273), (17, 0.09610845614224672), (11, 0.09739912208169699), (13, 0.10148037411272526), (3, 0.10201234370470047), (1, 0.10998695157468319), (8, 0.121895307675004), (10, 0.13772856444120407), (12, 0.14957465417683125), (16, 0.16404811665415764), (5, 0.19186345674097538), (36, 0.6212798655033112), (18, 0.6735120490193367), (53, 1.0790662169456482)]
computing accuracy for after removing block 44 . block score: 0.05029803002253175
removed block 44 current accuracy 0.9482 loss from initial  0.05179999999999996
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.053882. All blocks and scores: [(22, 0.05388231296092272), (21, 0.053953071124851704), (19, 0.054338759277015924), (7, 0.0556687880307436), (45, 0.05593203753232956), (15, 0.05899245943874121), (20, 0.059186529368162155), (23, 0.05921613425016403), (38, 0.060610665474087), (47, 0.06105801835656166), (51, 0.061376307625323534), (24, 0.06525112316012383), (39, 0.06707869749516249), (37, 0.06907625962048769), (52, 0.0739657822996378), (9, 0.08285301178693771), (4, 0.08417576551437378), (6, 0.08650581073015928), (14, 0.09107155445963144), (0, 0.09192068967968225), (2, 0.09352327324450016), (17, 0.09610845986753702), (11, 0.09739911556243896), (13, 0.10148037504404783), (3, 0.10201234370470047), (1, 0.10998695064336061), (8, 0.12189530953764915), (10, 0.13772856257855892), (12, 0.1495746523141861), (16, 0.1640481185168028), (5, 0.19186346046626568), (36, 0.6212798580527306), (18, 0.6735120415687561), (53, 1.1647499054670334)]
computing accuracy for after removing block 22 . block score: 0.05388231296092272
removed block 22 current accuracy 0.9426 loss from initial  0.05740000000000001
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.053850. All blocks and scores: [(45, 0.05385034205392003), (21, 0.05395307019352913), (19, 0.05433875834569335), (7, 0.05566878616809845), (23, 0.05587393557652831), (47, 0.05658304551616311), (51, 0.05882622580975294), (15, 0.058992459904402494), (38, 0.0591502389870584), (20, 0.05918652983382344), (24, 0.05932024447247386), (39, 0.06600259896367788), (52, 0.06824491638690233), (37, 0.06987851019948721), (9, 0.08285301178693771), (4, 0.08417576923966408), (6, 0.08650580979883671), (14, 0.09107155352830887), (0, 0.09192068967968225), (2, 0.09352327324450016), (17, 0.09610845521092415), (11, 0.09739911649376154), (13, 0.10148037504404783), (3, 0.10201234556734562), (1, 0.10998695064336061), (8, 0.12189531046897173), (10, 0.13772856630384922), (12, 0.14957465417683125), (16, 0.16404811665415764), (5, 0.19186346046626568), (36, 0.6147318705916405), (18, 0.6735120192170143), (53, 1.167636588215828)]
computing accuracy for after removing block 45 . block score: 0.05385034205392003
removed block 45 current accuracy 0.92 loss from initial  0.07999999999999996
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.053953. All blocks and scores: [(21, 0.05395306972786784), (19, 0.054338759277015924), (7, 0.05566878756508231), (23, 0.05587393417954445), (51, 0.05879575107246637), (15, 0.05899245897307992), (38, 0.059150236658751965), (20, 0.05918652983382344), (24, 0.05932024260982871), (39, 0.06600259989500046), (47, 0.06612548604607582), (37, 0.06987851113080978), (52, 0.07239473890513182), (9, 0.08285301178693771), (4, 0.0841757683083415), (6, 0.08650580793619156), (14, 0.09107155632227659), (0, 0.09192069247364998), (2, 0.09352327417582273), (17, 0.09610845521092415), (11, 0.09739911928772926), (13, 0.10148037318140268), (3, 0.10201234463602304), (1, 0.10998695250600576), (8, 0.12189531046897173), (10, 0.13772856444120407), (12, 0.1495746523141861), (16, 0.1640481185168028), (5, 0.19186346232891083), (36, 0.6147318780422211), (18, 0.6735120415687561), (53, 1.25870680809021)]
computing accuracy for after removing block 21 . block score: 0.05395306972786784
removed block 21 current accuracy 0.902 loss from initial  0.09799999999999998
since last training loss: 0.06740000000000002 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.049748. All blocks and scores: [(23, 0.04974802676588297), (19, 0.05433875881135464), (24, 0.05456135421991348), (7, 0.05566878756508231), (38, 0.056415670551359653), (51, 0.05684815440326929), (15, 0.05899245897307992), (20, 0.059186527505517006), (47, 0.0631949296221137), (39, 0.06527439504861832), (52, 0.06579989194869995), (37, 0.06843406800180674), (9, 0.08285301085561514), (4, 0.08417576551437378), (6, 0.08650580886751413), (14, 0.09107155539095402), (0, 0.09192069061100483), (2, 0.09352327324450016), (17, 0.096108453348279), (11, 0.09739912021905184), (13, 0.10148037318140268), (3, 0.1020123427733779), (1, 0.10998694878071547), (8, 0.12189531046897173), (10, 0.13772856257855892), (12, 0.14957465790212154), (16, 0.16404812037944794), (5, 0.19186345674097538), (36, 0.5953062549233437), (18, 0.6735120341181755), (53, 1.3170804679393768)]
computing accuracy for after removing block 23 . block score: 0.04974802676588297
removed block 23 current accuracy 0.8872 loss from initial  0.11280000000000001
since last training loss: 0.08220000000000005 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.051456. All blocks and scores: [(24, 0.05145550239831209), (19, 0.05433875788003206), (7, 0.05566878756508231), (38, 0.056499678175896406), (51, 0.0565245863981545), (15, 0.05899245711043477), (20, 0.059186529368162155), (47, 0.062019632663577795), (52, 0.06545741856098175), (39, 0.06549099925905466), (37, 0.0740072438493371), (9, 0.08285301178693771), (4, 0.08417576737701893), (6, 0.08650580886751413), (14, 0.09107155818492174), (0, 0.09192068967968225), (2, 0.09352327417582273), (17, 0.09610845521092415), (11, 0.09739911928772926), (13, 0.10148037318140268), (3, 0.1020123464986682), (1, 0.10998695064336061), (8, 0.12189530860632658), (10, 0.13772856816649437), (12, 0.14957465790212154), (16, 0.16404811665415764), (5, 0.19186345115303993), (36, 0.623803935945034), (18, 0.6735120192170143), (53, 1.3524506986141205)]
computing accuracy for after removing block 24 . block score: 0.05145550239831209
removed block 24 current accuracy 0.8488 loss from initial  0.1512
since last training loss: 0.12060000000000004 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.053383. All blocks and scores: [(38, 0.05338319204747677), (51, 0.05353097151964903), (19, 0.0543387602083385), (7, 0.05566878756508231), (47, 0.05832174513489008), (15, 0.05899245943874121), (20, 0.05918652797117829), (52, 0.05976559594273567), (39, 0.06331984233111143), (37, 0.07223738729953766), (9, 0.08285300992429256), (4, 0.08417576737701893), (6, 0.08650580700486898), (14, 0.09107155725359917), (0, 0.0919206915423274), (2, 0.09352327603846788), (17, 0.09610845521092415), (11, 0.09739911835640669), (13, 0.10148037131875753), (3, 0.1020123427733779), (1, 0.10998695064336061), (8, 0.1218953114002943), (10, 0.13772856444120407), (12, 0.1495746523141861), (16, 0.1640481147915125), (5, 0.19186346046626568), (36, 0.611509844660759), (18, 0.6735120192170143), (53, 1.3567684143781662)]
computing accuracy for after removing block 38 . block score: 0.05338319204747677
removed block 38 current accuracy 0.8052 loss from initial  0.19479999999999997
since last training loss: 0.1642 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.053248. All blocks and scores: [(51, 0.05324838496744633), (19, 0.054338759277015924), (7, 0.055668787099421024), (52, 0.056140949949622154), (47, 0.0573886763304472), (15, 0.05899245850741863), (20, 0.05918652843683958), (39, 0.06753627024590969), (37, 0.07223738823086023), (9, 0.08285301178693771), (4, 0.0841757645830512), (6, 0.08650580979883671), (14, 0.09107155445963144), (0, 0.0919206915423274), (2, 0.09352327603846788), (17, 0.09610845800489187), (11, 0.09739911835640669), (13, 0.10148037225008011), (3, 0.10201234556734562), (1, 0.10998695064336061), (8, 0.12189531233161688), (10, 0.13772856444120407), (12, 0.1495746560394764), (16, 0.1640481185168028), (5, 0.19186346232891083), (36, 0.6115098297595978), (18, 0.6735120415687561), (53, 1.495630830526352)]
computing accuracy for after removing block 51 . block score: 0.05324838496744633
removed block 51 current accuracy 0.7418 loss from initial  0.2582
training start
training epoch 0 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.1]
training epoch 1 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 3 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.1]
training epoch 4 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 5 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 6 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 7 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.1]
training epoch 8 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 9 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
