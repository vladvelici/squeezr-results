start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.010361599968746305), (34, 0.013312275637872517), (29, 0.013541154679842293), (35, 0.01601846283301711), (26, 0.016037590336054564), (28, 0.017728674924001098), (27, 0.019127048319205642), (43, 0.020232456270605326), (46, 0.02104453998617828), (25, 0.021972602233290672), (23, 0.02237953571602702), (41, 0.022826648084446788), (44, 0.02339507918804884), (40, 0.024025025311857462), (45, 0.02429541083984077), (21, 0.024924597470089793), (22, 0.025168768828734756), (48, 0.025341259315609932), (24, 0.025899537140503526), (50, 0.026409971993416548), (42, 0.026674100663512945), (20, 0.026859007542952895), (49, 0.02703716396354139), (47, 0.02930646762251854), (39, 0.031570712802931666), (38, 0.03163787070661783), (15, 0.03192339139059186), (7, 0.03228544816374779), (19, 0.032628594897687435), (37, 0.037960261572152376), (51, 0.04173417296260595), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663246780634), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734331995249), (52, 0.0686293737962842), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4375799857079983), (18, 0.5108212903141975), (53, 0.8211489245295525)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050979673862), (30, 0.010039400891400874), (31, 0.010361600201576948), (34, 0.013133947271853685), (29, 0.013541154796257615), (26, 0.01603759080171585), (35, 0.016169289592653513), (28, 0.017728676088154316), (27, 0.019127048552036285), (43, 0.020072476705536246), (46, 0.020731384865939617), (25, 0.021972602931782603), (41, 0.022347092628479004), (23, 0.02237953618168831), (44, 0.023235688218846917), (40, 0.023841066751629114), (45, 0.023965542670339346), (48, 0.024917916161939502), (21, 0.02492459793575108), (22, 0.025168768363073468), (50, 0.02584081282839179), (24, 0.02589953737333417), (42, 0.02631532377563417), (49, 0.026655674912035465), (20, 0.026859006844460964), (47, 0.028728798497468233), (39, 0.03131764126010239), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.03802584344521165), (51, 0.04122393950819969), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734331995249), (52, 0.06745155155658722), (8, 0.07467832416296005), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.43538710474967957), (18, 0.5108213126659393), (53, 0.822257399559021)]
computing accuracy for after removing block 32 . block score: 0.009233050979673862
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.01036159973591566), (34, 0.012765232706442475), (29, 0.01354115444701165), (35, 0.015992750879377127), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020075131906196475), (46, 0.02084140619263053), (25, 0.021972602466121316), (41, 0.022319766459986567), (23, 0.022379535250365734), (44, 0.023154050344601274), (40, 0.02388568385504186), (45, 0.024071688996627927), (48, 0.024877465097233653), (21, 0.02492459793575108), (22, 0.025168767664581537), (50, 0.02569117839448154), (24, 0.02589953667484224), (42, 0.026123747928068042), (49, 0.02647942234762013), (20, 0.026859006378799677), (47, 0.028693133033812046), (38, 0.031236795941367745), (39, 0.031295291846618056), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03837669175118208), (51, 0.04111403413116932), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.05892290314659476), (11, 0.059249129611998796), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.06700456235557795), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.43640000745654106), (18, 0.5108212903141975), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372250564396), (34, 0.01238783705048263), (29, 0.01354115444701165), (35, 0.016008096048608422), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.020704444032162428), (25, 0.021972602233290672), (41, 0.022253196919336915), (23, 0.022379535250365734), (44, 0.023267760407179594), (40, 0.024013879476115108), (45, 0.024092992767691612), (48, 0.024665280943736434), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.025459734722971916), (42, 0.025655712699517608), (24, 0.025899537606164813), (49, 0.02628775662742555), (20, 0.026859007077291608), (47, 0.02836342342197895), (38, 0.03104764735326171), (39, 0.03138077165931463), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03897124528884888), (51, 0.04075620463117957), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.06300980923697352), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4389924630522728), (18, 0.5108212977647781), (53, 0.8391561582684517)]
computing accuracy for after removing block 31 . block score: 0.010375372250564396
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154563426971), (26, 0.01603759080171585), (35, 0.016057362547144294), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020049349404871464), (46, 0.020552987698465586), (25, 0.021972603164613247), (41, 0.022067484678700566), (23, 0.022379535948857665), (44, 0.022979132132604718), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.024386122822761536), (21, 0.024924598401412368), (50, 0.02504224143922329), (22, 0.025168768130242825), (42, 0.025414507603272796), (49, 0.025842699222266674), (24, 0.025899536907672882), (20, 0.02685900661163032), (47, 0.028050734661519527), (38, 0.03104005940258503), (39, 0.03150080353952944), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.032628594897687435), (37, 0.039112847764045), (51, 0.040246272925287485), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548466578125954), (3, 0.057224278803914785), (13, 0.05892290314659476), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980877131224), (52, 0.06486208876594901), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4381278455257416), (18, 0.5108212977647781), (53, 0.845842756330967)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016653420170769095), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020503456005826592), (46, 0.020725322421640158), (25, 0.02197260269895196), (23, 0.022379535250365734), (41, 0.02245262893848121), (44, 0.023364474531263113), (48, 0.024290355388075113), (45, 0.024438712978735566), (40, 0.024470558390021324), (21, 0.024924597702920437), (50, 0.025042172521352768), (22, 0.025168768363073468), (49, 0.025875969789922237), (24, 0.025899538537487388), (42, 0.026205406291410327), (20, 0.026859007077291608), (47, 0.028178583597764373), (15, 0.03192339139059186), (38, 0.032083502039313316), (7, 0.03228544723242521), (39, 0.03233744157478213), (19, 0.0326285962946713), (51, 0.039947259705513716), (37, 0.04073968390002847), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663526177406), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980923697352), (52, 0.06433630175888538), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.45053431391716003), (18, 0.5108213052153587), (53, 0.8443200811743736)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470607835799456), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02004686719737947), (46, 0.020376993343234062), (41, 0.02172324270941317), (25, 0.021972602233290672), (23, 0.02237953501753509), (44, 0.023028336698189378), (48, 0.023771876469254494), (40, 0.023930813185870647), (45, 0.02417866326868534), (50, 0.024390297941863537), (21, 0.02492459793575108), (22, 0.0251687690615654), (42, 0.02518825139850378), (49, 0.025361527921631932), (24, 0.025899537140503526), (20, 0.026859006844460964), (47, 0.027363278437405825), (38, 0.03136561904102564), (15, 0.03192339139059186), (39, 0.03212768491357565), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.038935923017561436), (37, 0.040206344332545996), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.047493685968220234), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922899421304464), (11, 0.05924912681803107), (17, 0.06095684925094247), (52, 0.062328549567610025), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4444201923906803), (18, 0.5108213052153587), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500782847404), (27, 0.018882447155192494), (43, 0.019595165038481355), (46, 0.020073580788448453), (41, 0.020961584523320198), (25, 0.02197260269895196), (23, 0.02237953571602702), (44, 0.022814956260845065), (48, 0.023128160974010825), (40, 0.023345196153968573), (50, 0.023756147362291813), (42, 0.023847302654758096), (45, 0.02387388003990054), (21, 0.024924598168581724), (49, 0.024960315320640802), (22, 0.025168767664581537), (24, 0.025899537140503526), (47, 0.02685554255731404), (20, 0.02685900731012225), (38, 0.030424013501033187), (39, 0.031514044385403395), (15, 0.03192339185625315), (7, 0.032285445369780064), (19, 0.0326285962946713), (51, 0.03782488126307726), (37, 0.03936835331842303), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368643388152), (14, 0.04783663293346763), (2, 0.05454846518114209), (3, 0.05722427647560835), (13, 0.05892290314659476), (11, 0.059249130077660084), (52, 0.06033281981945038), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4360685460269451), (18, 0.5108212903141975), (53, 0.8749377354979515)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945716798306), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.01942429505288601), (48, 0.021467271726578474), (25, 0.021972602931782603), (44, 0.022026916965842247), (40, 0.022179660852998495), (42, 0.022206429857760668), (50, 0.022256129188463092), (23, 0.022379535948857665), (45, 0.022931481478735805), (49, 0.02370851277373731), (21, 0.024924597702920437), (22, 0.025168768130242825), (47, 0.02582913963124156), (24, 0.02589953737333417), (20, 0.026859007077291608), (38, 0.028956546215340495), (39, 0.029667828930541873), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.03600902669131756), (37, 0.03651238651946187), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.04783663526177406), (2, 0.05454846564680338), (52, 0.056107285898178816), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.41757645830512047), (18, 0.5108212977647781), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 1 val accuracy 0.8158 topk_dict {'top1': 0.8158} is_best False lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 7 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.1]
training epoch 8 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 9 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 10 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102707609534), (41, 0.018849018262699246), (27, 0.018882446689531207), (48, 0.02090373425744474), (42, 0.021432004868984222), (40, 0.021832421189174056), (44, 0.021840531146153808), (50, 0.02186986361630261), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.022492848336696625), (49, 0.023123498307541013), (21, 0.024924597470089793), (47, 0.025067138951271772), (22, 0.025168768130242825), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.02811406902037561), (39, 0.029206908773630857), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03545433655381203), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846704378724), (52, 0.054696458857506514), (3, 0.05722427787259221), (13, 0.05892289988696575), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 0.9246632531285286)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882447155192494), (46, 0.019302030326798558), (42, 0.02143200463615358), (48, 0.021544843446463346), (40, 0.021832421654835343), (50, 0.021946269553154707), (25, 0.021972602931782603), (23, 0.02237953571602702), (49, 0.02300686971284449), (44, 0.023108510533347726), (45, 0.023535607382655144), (21, 0.024924598401412368), (22, 0.025168768828734756), (47, 0.025820446200668812), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.028114069951698184), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.035091488622128963), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05332903051748872), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.058922899421304464), (11, 0.05924912681803107), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.0803448474034667), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 0.9678284302353859)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.01907008863054216), (48, 0.02067816792987287), (50, 0.02134439768269658), (40, 0.021832421654835343), (25, 0.02197260200046003), (42, 0.02198694017715752), (23, 0.022379535250365734), (49, 0.02253474877215922), (45, 0.023929917719215155), (44, 0.024054003413766623), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.02604393637739122), (20, 0.026859006844460964), (38, 0.028114069486036897), (39, 0.029206909704953432), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.050476094242185354), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912681803107), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.01866446272470057), (48, 0.01998970750719309), (50, 0.020775061566382647), (40, 0.021085953107103705), (42, 0.0213696479331702), (49, 0.021910029696300626), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.023239311762154102), (45, 0.023585309041664004), (21, 0.024924598401412368), (47, 0.025076948339119554), (22, 0.025168768595904112), (24, 0.025899537606164813), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03281426033936441), (37, 0.03542024316266179), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04852363094687462), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.06095684692263603), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.01866446272470057
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831162109971046), (40, 0.021085953107103705), (42, 0.021369647001847625), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.022536989534273744), (44, 0.023239311994984746), (45, 0.02358530811034143), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.026583049446344376), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580758720636368), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.032628596760332584), (51, 0.03285081218928099), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663293346763), (52, 0.04812479764223099), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049665004015), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213201165199), (53, 1.1537711918354034)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369648398831487), (25, 0.02197260269895196), (23, 0.02237953501753509), (50, 0.02247006306424737), (44, 0.023239311994984746), (45, 0.02358530811034143), (21, 0.02492459793575108), (22, 0.025168768130242825), (49, 0.025234101340174675), (24, 0.02589953737333417), (47, 0.02658304898068309), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.028580759651958942), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03296921169385314), (37, 0.035420242697000504), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05089045129716396), (2, 0.054548466112464666), (3, 0.05722427973523736), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.02128476626239717), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.023098317673429847), (44, 0.02424085815437138), (49, 0.024500868981704116), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026519699953496456), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339139059186), (51, 0.03222084976732731), (7, 0.032285445369780064), (19, 0.032628596760332584), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.04749368270859122), (14, 0.047836634796112776), (52, 0.04885757248848677), (2, 0.05454846518114209), (3, 0.057224275544285774), (13, 0.058922900818288326), (11, 0.05924912681803107), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387116700411), (36, 0.4065233990550041), (18, 0.5108213126659393), (53, 1.3718615621328354)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202659234404564), (25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.02376196626573801), (49, 0.02460233843885362), (44, 0.024712181417271495), (21, 0.024924598401412368), (22, 0.0251687690615654), (24, 0.025899537140503526), (47, 0.026220475090667605), (20, 0.026859006378799677), (38, 0.027183360187336802), (39, 0.028580758022144437), (51, 0.03127906681038439), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628594897687435), (37, 0.03542024502530694), (9, 0.04340187879279256), (52, 0.046101709827780724), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828251093626), (12, 0.09042049385607243), (5, 0.10667387582361698), (36, 0.4065234027802944), (18, 0.5108212903141975), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202659234404564
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.02376196556724608), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.026220475090667605), (20, 0.026859007542952895), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.0334430206567049), (37, 0.03542024316266179), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.052651794627308846), (2, 0.05454846750944853), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212903141975), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best False lr [0.1]
training epoch 1 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 4 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 5 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 6 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 7 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 8 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 9 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.1]
training epoch 10 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.970000)
finished training. finished 50 epochs. accuracy 0.97 topk_dict {'top1': 0.97}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.044051. All blocks and scores: [(49, 0.04405149118974805), (44, 0.04845286766067147), (45, 0.05115407332777977), (21, 0.053008975461125374), (47, 0.054489773232489824), (20, 0.055394371971488), (23, 0.05625118035823107), (19, 0.05709549132734537), (22, 0.05755754839628935), (15, 0.057698026299476624), (38, 0.05833123065531254), (51, 0.059395404532551765), (39, 0.06403368711471558), (7, 0.06500218994915485), (24, 0.06784802302718163), (4, 0.06919210683554411), (37, 0.07008536532521248), (52, 0.07048972230404615), (6, 0.07638116460293531), (9, 0.08217997010797262), (14, 0.08740196283906698), (2, 0.08952626585960388), (3, 0.10180980805307627), (13, 0.10256947297602892), (1, 0.1082903016358614), (11, 0.10876412596553564), (17, 0.11139792297035456), (0, 0.1135559706017375), (8, 0.12283806875348091), (10, 0.15743200667202473), (16, 0.16329975612461567), (12, 0.16463760286569595), (5, 0.2050568386912346), (36, 0.6260709315538406), (18, 0.6837557181715965), (53, 0.9824656248092651)]
computing accuracy for after removing block 49 . block score: 0.04405149118974805
removed block 49 current accuracy 0.9596 loss from initial  0.04039999999999999
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.048453. All blocks and scores: [(44, 0.04845286952331662), (45, 0.05115407286211848), (21, 0.053008973598480225), (47, 0.05448977369815111), (20, 0.0553943682461977), (23, 0.05625117989256978), (19, 0.0570954903960228), (22, 0.05755755165591836), (15, 0.05769802676513791), (38, 0.0583312320522964), (51, 0.06388620333746076), (39, 0.06403368804603815), (7, 0.06500218994915485), (24, 0.06784802488982677), (4, 0.06919210683554411), (37, 0.07008536625653505), (52, 0.07558574341237545), (6, 0.07638116553425789), (9, 0.08217997010797262), (14, 0.08740196190774441), (2, 0.08952626399695873), (3, 0.10180980898439884), (13, 0.10256947297602892), (1, 0.10829030256718397), (11, 0.10876412317156792), (17, 0.11139792017638683), (0, 0.11355596967041492), (8, 0.12283806968480349), (10, 0.15743200853466988), (16, 0.16329975239932537), (12, 0.1646376010030508), (5, 0.2050568349659443), (36, 0.6260709390044212), (18, 0.6837557032704353), (53, 1.0917295664548874)]
computing accuracy for after removing block 44 . block score: 0.04845286952331662
removed block 44 current accuracy 0.9462 loss from initial  0.05379999999999996
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.053009. All blocks and scores: [(21, 0.05300897220149636), (45, 0.054705207236111164), (20, 0.055394371040165424), (23, 0.05625118128955364), (19, 0.057095490861684084), (22, 0.057557548861950636), (15, 0.05769802676513791), (38, 0.05833123158663511), (47, 0.060345064383000135), (51, 0.06281328853219748), (39, 0.06403368897736073), (7, 0.06500218901783228), (24, 0.06784802302718163), (4, 0.06919210497289896), (37, 0.07008536346256733), (52, 0.0744937127456069), (6, 0.07638116553425789), (9, 0.08217997010797262), (14, 0.08740196377038956), (2, 0.08952626306563616), (3, 0.10180980991572142), (13, 0.10256947111338377), (1, 0.10829030070453882), (11, 0.10876412317156792), (17, 0.1113979248329997), (0, 0.1135559706017375), (8, 0.12283806968480349), (10, 0.15743200480937958), (16, 0.16329974867403507), (12, 0.1646376010030508), (5, 0.20505683682858944), (36, 0.6260709464550018), (18, 0.6837557032704353), (53, 1.1750784367322922)]
computing accuracy for after removing block 21 . block score: 0.05300897220149636
removed block 21 current accuracy 0.9382 loss from initial  0.061799999999999966
since last training loss: 0.03179999999999994 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.049825. All blocks and scores: [(23, 0.04982488974928856), (45, 0.05234379321336746), (22, 0.052868010476231575), (20, 0.05539437010884285), (38, 0.056318522430956364), (47, 0.056818485260009766), (19, 0.057095488999038935), (15, 0.05769802536815405), (24, 0.05840020952746272), (51, 0.06021303916350007), (39, 0.06181762274354696), (7, 0.06500218901783228), (52, 0.06792252883315086), (4, 0.06919210776686668), (37, 0.06922152452170849), (6, 0.07638116646558046), (9, 0.08217997010797262), (14, 0.0874019656330347), (2, 0.08952626585960388), (3, 0.10180980805307627), (13, 0.10256946925073862), (1, 0.10829029884189367), (11, 0.10876412224024534), (17, 0.11139792297035456), (0, 0.11355596967041492), (8, 0.12283806782215834), (10, 0.15743201039731503), (16, 0.16329975053668022), (12, 0.1646376010030508), (5, 0.20505682937800884), (36, 0.6024346351623535), (18, 0.6837557107210159), (53, 1.213399887084961)]
computing accuracy for after removing block 23 . block score: 0.04982488974928856
removed block 23 current accuracy 0.9288 loss from initial  0.07120000000000004
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.052292. All blocks and scores: [(45, 0.052291670348495245), (22, 0.05286800675094128), (47, 0.0547216753475368), (20, 0.05539436964318156), (38, 0.05627067852765322), (19, 0.05709548853337765), (24, 0.05715159559622407), (15, 0.05769802816212177), (51, 0.06055115116760135), (39, 0.06349412631243467), (7, 0.06500218994915485), (52, 0.06659219507128), (4, 0.06919210683554411), (37, 0.07351171225309372), (6, 0.07638116646558046), (9, 0.08217996824532747), (14, 0.08740196190774441), (2, 0.08952626399695873), (3, 0.10180981084704399), (13, 0.10256947111338377), (1, 0.1082903016358614), (11, 0.10876412130892277), (17, 0.11139792576432228), (0, 0.11355596780776978), (8, 0.12283807061612606), (10, 0.15743200480937958), (16, 0.16329975053668022), (12, 0.16463760286569595), (5, 0.20505683310329914), (36, 0.6172120049595833), (18, 0.6837557107210159), (53, 1.2100484371185303)]
computing accuracy for after removing block 45 . block score: 0.052291670348495245
removed block 45 current accuracy 0.9032 loss from initial  0.0968
since last training loss: 0.06679999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.052868. All blocks and scores: [(22, 0.05286800907924771), (20, 0.055394369177520275), (38, 0.05627067806199193), (19, 0.05709549272432923), (24, 0.05715159699320793), (15, 0.05769802536815405), (51, 0.060969516169279814), (39, 0.0634941253811121), (47, 0.06384532060474157), (7, 0.06500218901783228), (4, 0.06919210776686668), (52, 0.06941019929945469), (37, 0.07351171225309372), (6, 0.07638116646558046), (9, 0.08217996917665005), (14, 0.08740196190774441), (2, 0.08952626213431358), (3, 0.10180981177836657), (13, 0.10256947483867407), (1, 0.10829029884189367), (11, 0.10876412503421307), (17, 0.11139792203903198), (0, 0.11355596780776978), (8, 0.12283807154744864), (10, 0.15743200667202473), (16, 0.16329975239932537), (12, 0.1646376010030508), (5, 0.20505683310329914), (36, 0.6172119975090027), (18, 0.6837557181715965), (53, 1.3448426723480225)]
computing accuracy for after removing block 22 . block score: 0.05286800907924771
removed block 22 current accuracy 0.8794 loss from initial  0.12060000000000004
since last training loss: 0.09060000000000001 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.051900. All blocks and scores: [(24, 0.05189993465319276), (38, 0.054898076225072145), (20, 0.055394369177520275), (19, 0.057095490861684084), (15, 0.057698026299476624), (51, 0.05858111195266247), (47, 0.059528108686208725), (39, 0.06315096467733383), (7, 0.0650021880865097), (52, 0.06554510537534952), (4, 0.06919210590422153), (6, 0.07638116553425789), (37, 0.07693672645837069), (9, 0.08217997197061777), (14, 0.08740196377038956), (2, 0.08952626306563616), (3, 0.10180980619043112), (13, 0.10256946925073862), (1, 0.10829030256718397), (11, 0.10876412224024534), (17, 0.11139792576432228), (0, 0.1135559706017375), (8, 0.12283806968480349), (10, 0.15743200667202473), (16, 0.16329974681138992), (12, 0.1646376010030508), (5, 0.2050568349659443), (36, 0.6189080625772476), (18, 0.6837557032704353), (53, 1.3386079967021942)]
computing accuracy for after removing block 24 . block score: 0.05189993465319276
removed block 24 current accuracy 0.8432 loss from initial  0.15680000000000005
since last training loss: 0.12680000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.052204. All blocks and scores: [(38, 0.05220351507887244), (51, 0.05426140455529094), (20, 0.055394369177520275), (47, 0.05549062602221966), (19, 0.057095490861684084), (15, 0.057698026299476624), (52, 0.060424383264034986), (39, 0.0618921360000968), (7, 0.06500218994915485), (4, 0.06919210590422153), (6, 0.07638116646558046), (37, 0.07691028621047735), (9, 0.08217996917665005), (14, 0.08740196377038956), (2, 0.08952626306563616), (3, 0.10180980991572142), (13, 0.10256947483867407), (1, 0.10829030442982912), (11, 0.10876412224024534), (17, 0.11139792669564486), (0, 0.11355597339570522), (8, 0.12283806595951319), (10, 0.15743200667202473), (16, 0.16329975239932537), (12, 0.16463760286569595), (5, 0.20505683310329914), (36, 0.6250142902135849), (18, 0.6837556958198547), (53, 1.34554922580719)]
computing accuracy for after removing block 38 . block score: 0.05220351507887244
removed block 38 current accuracy 0.8182 loss from initial  0.18179999999999996
since last training loss: 0.15179999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.052163. All blocks and scores: [(51, 0.05216300580650568), (47, 0.05513442913070321), (20, 0.055394371971488), (52, 0.05650360230356455), (19, 0.0570954903960228), (15, 0.0576980272307992), (39, 0.06435414310544729), (7, 0.06500218994915485), (4, 0.06919210590422153), (6, 0.07638116553425789), (37, 0.07691028900444508), (9, 0.0821799710392952), (14, 0.08740196377038956), (2, 0.08952626306563616), (3, 0.10180980991572142), (13, 0.10256947483867407), (1, 0.10829030256718397), (11, 0.10876412317156792), (17, 0.11139792297035456), (0, 0.11355597153306007), (8, 0.12283806782215834), (10, 0.15743201039731503), (16, 0.16329975239932537), (12, 0.1646375972777605), (5, 0.2050568349659443), (36, 0.6250142827630043), (18, 0.6837557181715965), (53, 1.4112658947706223)]
computing accuracy for after removing block 51 . block score: 0.05216300580650568
removed block 51 current accuracy 0.7474 loss from initial  0.25260000000000005
training start
training epoch 0 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.1]
training epoch 1 val accuracy 0.862 topk_dict {'top1': 0.862} is_best True lr [0.1]
training epoch 2 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 3 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.1]
training epoch 4 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 6 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 7 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 8 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 9 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.951600)
finished training. finished 50 epochs. accuracy 0.9516 topk_dict {'top1': 0.9516}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.075006. All blocks and scores: [(7, 0.07500553969293833), (15, 0.08366381656378508), (9, 0.08827200625091791), (52, 0.08956077136099339), (19, 0.08979565650224686), (47, 0.09374115336686373), (37, 0.09626978728920221), (6, 0.09885945450514555), (4, 0.09912995435297489), (20, 0.09989105258136988), (39, 0.10186422150582075), (2, 0.10735805239528418), (3, 0.11362323258072138), (0, 0.11833636462688446), (14, 0.12049154937267303), (1, 0.12505042925477028), (11, 0.12760593090206385), (13, 0.13394149206578732), (17, 0.1406701970845461), (8, 0.14127379097044468), (10, 0.16122262552380562), (16, 0.19604777731001377), (12, 0.19731628336012363), (5, 0.21465798281133175), (36, 0.5447136834263802), (18, 0.6259390115737915), (53, 1.1353062242269516)]
computing accuracy for after removing block 7 . block score: 0.07500553969293833
removed block 7 current accuracy 0.9468 loss from initial  0.053200000000000025
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.079276. All blocks and scores: [(15, 0.07927559036761522), (19, 0.08379788044840097), (52, 0.08456411305814981), (9, 0.08870387822389603), (37, 0.08963143546134233), (47, 0.09156689327210188), (20, 0.09567576181143522), (6, 0.09885945729911327), (4, 0.09912994876503944), (39, 0.10010968521237373), (2, 0.1073580514639616), (14, 0.11322925053536892), (3, 0.11362323723733425), (13, 0.11522026173770428), (11, 0.11675284989178181), (0, 0.11833635810762644), (17, 0.12165870983153582), (1, 0.12505042925477028), (8, 0.13430128805339336), (10, 0.16108940914273262), (16, 0.17617246694862843), (12, 0.18223308585584164), (5, 0.2146579846739769), (36, 0.5243545919656754), (18, 0.5969661325216293), (53, 1.1142930686473846)]
computing accuracy for after removing block 15 . block score: 0.07927559036761522
removed block 15 current accuracy 0.9424 loss from initial  0.057599999999999985
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 19, with score 0.082750. All blocks and scores: [(19, 0.08275044616311789), (52, 0.08406089246273041), (37, 0.08623488619923592), (20, 0.0882908022031188), (9, 0.08870387636125088), (47, 0.09235765598714352), (39, 0.09834185987710953), (6, 0.0988594563677907), (4, 0.09912995249032974), (2, 0.10735805239528418), (14, 0.11322925705462694), (3, 0.11362323258072138), (13, 0.11522026546299458), (11, 0.11675284709781408), (0, 0.11833636555820704), (17, 0.12390114739537239), (1, 0.125050432048738), (8, 0.13430128619074821), (10, 0.16108941100537777), (12, 0.18223308213055134), (16, 0.1980956494808197), (5, 0.21465798653662205), (36, 0.4976082295179367), (18, 0.5696976035833359), (53, 1.1143332868814468)]
computing accuracy for after removing block 19 . block score: 0.08275044616311789
removed block 19 current accuracy 0.9218 loss from initial  0.07820000000000005
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.080050. All blocks and scores: [(52, 0.08004987239837646), (20, 0.08166613150388002), (9, 0.0887038754299283), (47, 0.08890207577496767), (37, 0.09677450731396675), (39, 0.09742954093962908), (6, 0.09885945543646812), (4, 0.09912995621562004), (2, 0.10735804587602615), (14, 0.1132292514666915), (3, 0.11362323258072138), (13, 0.11522026173770428), (11, 0.11675284616649151), (0, 0.11833636462688446), (17, 0.12390115018934011), (1, 0.12505043391138315), (8, 0.13430128619074821), (10, 0.16108940541744232), (12, 0.1822330839931965), (16, 0.1980956494808197), (5, 0.2146579809486866), (36, 0.5035062953829765), (18, 0.5696975886821747), (53, 1.0855183750391006)]
computing accuracy for after removing block 52 . block score: 0.08004987239837646
removed block 52 current accuracy 0.8584 loss from initial  0.14159999999999995
since last training loss: 0.09319999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.081666. All blocks and scores: [(20, 0.08166613057255745), (9, 0.08870387636125088), (47, 0.08890207577496767), (37, 0.09677450638264418), (39, 0.09742953907698393), (6, 0.09885945543646812), (4, 0.09912995342165232), (2, 0.10735805239528418), (14, 0.11322925053536892), (3, 0.1136232353746891), (13, 0.11522026173770428), (11, 0.11675284896045923), (0, 0.11833636369556189), (17, 0.12390114646404982), (1, 0.12505043391138315), (8, 0.13430128619074821), (10, 0.16108941659331322), (12, 0.18223308585584164), (16, 0.1980956457555294), (5, 0.2146579846739769), (36, 0.5035063177347183), (18, 0.5696975886821747), (53, 1.191875010728836)]
computing accuracy for after removing block 20 . block score: 0.08166613057255745
removed block 20 current accuracy 0.7988 loss from initial  0.20120000000000005
since last training loss: 0.15280000000000005 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 47, with score 0.082702. All blocks and scores: [(47, 0.08270186744630337), (9, 0.08870387822389603), (39, 0.09842620603740215), (6, 0.09885945450514555), (4, 0.09912995528429747), (2, 0.10735805332660675), (37, 0.11023740470409393), (14, 0.11322925332933664), (3, 0.11362323723733425), (13, 0.1152202608063817), (11, 0.11675284430384636), (0, 0.11833636369556189), (17, 0.12390115018934011), (1, 0.12505043111741543), (8, 0.13430128619074821), (10, 0.16108940914273262), (12, 0.18223308213055134), (16, 0.19809563271701336), (5, 0.21465798281133175), (36, 0.5423222333192825), (18, 0.5696975886821747), (53, 1.1213908344507217)]
computing accuracy for after removing block 47 . block score: 0.08270186744630337
removed block 47 current accuracy 0.6952 loss from initial  0.30479999999999996
since last training loss: 0.25639999999999996 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 9, with score 0.088704. All blocks and scores: [(9, 0.08870387822389603), (39, 0.09842620696872473), (6, 0.0988594563677907), (4, 0.09912994969636202), (2, 0.10735804960131645), (37, 0.11023740656673908), (14, 0.11322925519198179), (3, 0.11362323444336653), (13, 0.11522025801241398), (11, 0.11675284802913666), (0, 0.11833636462688446), (17, 0.12390114832669497), (1, 0.12505043111741543), (8, 0.13430128619074821), (10, 0.16108941100537777), (12, 0.18223308771848679), (16, 0.19809564389288425), (5, 0.2146579846739769), (36, 0.5423222258687019), (18, 0.5696976110339165), (53, 1.274032399058342)]
computing accuracy for after removing block 9 . block score: 0.08870387822389603
removed block 9 current accuracy 0.643 loss from initial  0.357
since last training loss: 0.3086 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.089633. All blocks and scores: [(37, 0.08963338006287813), (39, 0.09255731757730246), (6, 0.0988594563677907), (4, 0.09912995155900717), (11, 0.10283579491078854), (14, 0.10344981029629707), (2, 0.10735804866999388), (13, 0.11170223169028759), (3, 0.11362323723733425), (17, 0.11461283825337887), (0, 0.11833636369556189), (1, 0.12505043111741543), (8, 0.13430128619074821), (12, 0.1483760941773653), (10, 0.15104583464562893), (16, 0.16244294308125973), (5, 0.21465798281133175), (36, 0.49363191798329353), (18, 0.5286222919821739), (53, 1.1890011727809906)]
computing accuracy for after removing block 37 . block score: 0.08963338006287813
removed block 37 current accuracy 0.6082 loss from initial  0.39180000000000004
since last training loss: 0.34340000000000004 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 6, with score 0.098859. All blocks and scores: [(6, 0.09885945543646812), (4, 0.09912995621562004), (11, 0.10283579770475626), (14, 0.1034498130902648), (2, 0.10735805239528418), (39, 0.111023741774261), (13, 0.11170222889631987), (3, 0.11362324096262455), (17, 0.11461283545941114), (0, 0.11833635997027159), (1, 0.12505043670535088), (8, 0.1343012899160385), (12, 0.14837609231472015), (10, 0.15104583650827408), (16, 0.16244295239448547), (5, 0.2146579883992672), (36, 0.49363189935684204), (18, 0.5286222919821739), (53, 1.2757143378257751)]
computing accuracy for after removing block 6 . block score: 0.09885945543646812
removed block 6 current accuracy 0.5278 loss from initial  0.47219999999999995
since last training loss: 0.42379999999999995 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 14, with score 0.091318. All blocks and scores: [(14, 0.09131757263094187), (11, 0.09262474346905947), (4, 0.09912995714694262), (2, 0.1073580514639616), (39, 0.10905421432107687), (13, 0.11021004058420658), (17, 0.11144722998142242), (3, 0.11362323723733425), (0, 0.11833636462688446), (1, 0.12505043018609285), (8, 0.12798059917986393), (16, 0.1340755894780159), (12, 0.138368533924222), (10, 0.15981322340667248), (5, 0.2146579846739769), (36, 0.4966960847377777), (18, 0.5147393122315407), (53, 1.3173234313726425)]
computing accuracy for after removing block 14 . block score: 0.09131757263094187
removed block 14 current accuracy 0.4552 loss from initial  0.5448
since last training loss: 0.4964 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.092625. All blocks and scores: [(11, 0.09262474440038204), (4, 0.09912995249032974), (2, 0.10735805053263903), (13, 0.11021003779023886), (17, 0.11238210648298264), (3, 0.1136232353746891), (39, 0.11441023834049702), (0, 0.11833636462688446), (1, 0.125050432048738), (8, 0.12798059917986393), (12, 0.13836853206157684), (10, 0.15981322713196278), (16, 0.16023324616253376), (5, 0.21465798281133175), (18, 0.5146992057561874), (36, 0.5151325091719627), (53, 1.4326049089431763)]
computing accuracy for after removing block 11 . block score: 0.09262474440038204
removed block 11 current accuracy 0.4234 loss from initial  0.5766
since last training loss: 0.5282 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 4, with score 0.099130. All blocks and scores: [(4, 0.09912995714694262), (2, 0.10735805053263903), (13, 0.1090520964935422), (17, 0.11073218658566475), (3, 0.11362323351204395), (39, 0.11751607526093721), (0, 0.11833636183291674), (16, 0.12444640230387449), (1, 0.1250504283234477), (8, 0.12798060104250908), (12, 0.13442515395581722), (10, 0.15981322340667248), (5, 0.2146579772233963), (36, 0.5220981165766716), (18, 0.5240469574928284), (53, 1.4381576925516129)]
computing accuracy for after removing block 4 . block score: 0.09912995714694262
removed block 4 current accuracy 0.3702 loss from initial  0.6298
training start
training epoch 0 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.1]
training epoch 1 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best True lr [0.1]
training epoch 2 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 3 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.1]
training epoch 4 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best False lr [0.1]
training epoch 5 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.1]
training epoch 6 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 7 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 8 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 9 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 10 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.929000)
finished training. finished 50 epochs. accuracy 0.929 topk_dict {'top1': 0.929}
