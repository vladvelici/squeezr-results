start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050630427897), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013312276219949126), (29, 0.013541154214181006), (35, 0.01601846283301711), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02023245650343597), (46, 0.021044539753347635), (25, 0.02197260269895196), (23, 0.022379535948857665), (41, 0.022826647851616144), (44, 0.023395078955218196), (40, 0.024025025544688106), (45, 0.02429541014134884), (21, 0.02492459793575108), (22, 0.025168768595904112), (48, 0.025341259315609932), (24, 0.025899537606164813), (50, 0.026409971993416548), (42, 0.026674099965021014), (20, 0.02685900661163032), (49, 0.027037164429202676), (47, 0.029306469717994332), (39, 0.03157071233727038), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.037960261572152376), (51, 0.041734172496944666), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427600994706), (13, 0.05892290361225605), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.06862937472760677), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4375799894332886), (18, 0.5108212903141975), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400542154908), (31, 0.010361599852330983), (34, 0.01313394762109965), (29, 0.013541154796257615), (26, 0.016037590336054564), (35, 0.01616928935982287), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020072476472705603), (46, 0.020731385564431548), (25, 0.021972602233290672), (41, 0.022347092628479004), (23, 0.022379535483196378), (44, 0.023235688218846917), (40, 0.02384106651879847), (45, 0.02396554290316999), (48, 0.024917915696278214), (21, 0.024924598168581724), (22, 0.025168768828734756), (50, 0.025840813061222434), (24, 0.02589953667484224), (42, 0.02631532377563417), (49, 0.02665567467920482), (20, 0.026859006844460964), (47, 0.028728797333315015), (39, 0.031317642191424966), (38, 0.031380362808704376), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03802584297955036), (51, 0.04122393950819969), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734331995249), (52, 0.06745155155658722), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4353870861232281), (18, 0.5108213052153587), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400425739586), (31, 0.010361599968746305), (34, 0.012765232590027153), (29, 0.013541154563426971), (35, 0.01599275111220777), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020075131440535188), (46, 0.020841405959799886), (25, 0.021972602931782603), (41, 0.022319766925647855), (23, 0.022379534784704447), (44, 0.023154049646109343), (40, 0.023885683389380574), (45, 0.02407168922945857), (48, 0.02487746556289494), (21, 0.024924597702920437), (22, 0.025168768363073468), (50, 0.025691177928820252), (24, 0.025899537838995457), (42, 0.026123747928068042), (49, 0.026479422114789486), (20, 0.026859006844460964), (47, 0.02869313210248947), (38, 0.031236796407029033), (39, 0.031295291846618056), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.032628596760332584), (37, 0.038376690819859505), (51, 0.04111403366550803), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734145730734), (52, 0.06700456328690052), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.43640001863241196), (18, 0.5108212903141975), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039400425739586
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371552072465), (34, 0.012387836934067309), (29, 0.013541154330596328), (35, 0.016008096048608422), (26, 0.01603759010322392), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020083633484318852), (46, 0.020704444497823715), (25, 0.021972602466121316), (41, 0.022253196919336915), (23, 0.022379535483196378), (44, 0.023267760640010238), (40, 0.024013880407437682), (45, 0.024092992302030325), (48, 0.024665279779583216), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.025459734024479985), (42, 0.025655712466686964), (24, 0.025899537140503526), (49, 0.02628775592893362), (20, 0.026859007077291608), (47, 0.028363424353301525), (38, 0.031047647120431066), (39, 0.03138077352195978), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.03262859582901001), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846378415823), (3, 0.05722427740693092), (13, 0.058922899421304464), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980830565095), (52, 0.06586316041648388), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4389924556016922), (18, 0.5108212977647781), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375371552072465
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154563426971), (26, 0.016037591034546494), (35, 0.016057362779974937), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020049349637702107), (46, 0.02055298676714301), (25, 0.021972602233290672), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132132604718), (40, 0.023858347674831748), (45, 0.02412470243871212), (48, 0.024386122124269605), (21, 0.02492459863424301), (50, 0.02504224143922329), (22, 0.025168768130242825), (42, 0.025414507603272796), (49, 0.0258426982909441), (24, 0.025899537140503526), (20, 0.026859006145969033), (47, 0.028050734428688884), (38, 0.031040059868246317), (39, 0.0315008033066988), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.039112848695367575), (51, 0.040246272925287485), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.05454846750944853), (3, 0.057224280666559935), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.06095685018226504), (0, 0.06300980783998966), (52, 0.0648620892316103), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828251093626), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.438127838075161), (18, 0.5108213052153587), (53, 0.8458427935838699)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541153981350362), (26, 0.016037591034546494), (35, 0.01665342040359974), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020503456238657236), (46, 0.02072532312013209), (25, 0.021972602466121316), (23, 0.022379535483196378), (41, 0.0224526294041425), (44, 0.023364474065601826), (48, 0.02429035515524447), (45, 0.024438712978735566), (40, 0.024470558622851968), (21, 0.024924597702920437), (50, 0.025042172288522124), (22, 0.025168768595904112), (49, 0.02587597002275288), (24, 0.025899536442011595), (42, 0.026205406757071614), (20, 0.026859007077291608), (47, 0.028178582666441798), (15, 0.03192339185625315), (38, 0.032083502039313316), (7, 0.03228544583544135), (39, 0.03233744017779827), (19, 0.03262859582901001), (51, 0.039947260171175), (37, 0.040739682503044605), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.05892290314659476), (11, 0.05924912774935365), (17, 0.06095684692263603), (0, 0.06300980923697352), (52, 0.06433630222454667), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.45053431764245033), (18, 0.5108213052153587), (53, 0.8443200513720512)]
computing accuracy for after removing block 29 . block score: 0.013541153981350362
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037591034546494), (35, 0.016470608301460743), (28, 0.017728675855323672), (27, 0.019127049017697573), (43, 0.020046866964548826), (46, 0.020376993576064706), (41, 0.021723242942243814), (25, 0.021972601767629385), (23, 0.02237953571602702), (44, 0.023028337163850665), (48, 0.023771876469254494), (40, 0.023930813185870647), (45, 0.024178663035854697), (50, 0.024390298640355468), (21, 0.024924597702920437), (22, 0.025168768595904112), (42, 0.02518825139850378), (49, 0.025361528852954507), (24, 0.025899536442011595), (20, 0.026859006844460964), (47, 0.0273632793687284), (38, 0.03136561904102564), (15, 0.03192339185625315), (39, 0.032127685844898224), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.03893592348322272), (37, 0.040206342469900846), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663526177406), (2, 0.054548466112464666), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095684738829732), (52, 0.06232855096459389), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.09042049665004015), (5, 0.10667387116700411), (36, 0.4444201998412609), (18, 0.5108212977647781), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037591034546494
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.01559736579656601), (28, 0.017088500782847404), (27, 0.01888244692236185), (43, 0.01959516596980393), (46, 0.020073581021279097), (41, 0.020961584290489554), (25, 0.021972602466121316), (23, 0.022379535483196378), (44, 0.02281495602801442), (48, 0.023128160508349538), (40, 0.02334519545547664), (50, 0.023756146896630526), (42, 0.02384730288758874), (45, 0.02387388050556183), (21, 0.02492459793575108), (49, 0.024960315553471446), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.02685554255731404), (20, 0.026859007542952895), (38, 0.03042401443235576), (39, 0.03151404415257275), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.037824882194399834), (37, 0.039368352852761745), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.057224275544285774), (13, 0.05892290221527219), (11, 0.0592491258867085), (52, 0.06033281935378909), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4360685385763645), (18, 0.5108213126659393), (53, 0.8749377429485321)]
computing accuracy for after removing block 35 . block score: 0.01559736579656601
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088501015678048), (43, 0.018555945483967662), (27, 0.018882446689531207), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.02146727219223976), (25, 0.021972602466121316), (44, 0.022026916965842247), (40, 0.02217965992167592), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.02237953501753509), (45, 0.022931482177227736), (49, 0.02370851277373731), (21, 0.024924598867073655), (22, 0.02516876789741218), (47, 0.025829139864072204), (24, 0.02589953737333417), (20, 0.026859006145969033), (38, 0.028956545749679208), (39, 0.0296678279992193), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628596760332584), (51, 0.036009025759994984), (37, 0.036512387450784445), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846704378724), (52, 0.05610728822648525), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387396097183), (36, 0.41757646203041077), (18, 0.5108212977647781), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.017088501015678048
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102009117603), (41, 0.01884901849552989), (27, 0.018882447155192494), (48, 0.020903734024614096), (42, 0.02143200417049229), (40, 0.021832421189174056), (44, 0.021840530913323164), (50, 0.021869863383471966), (25, 0.021972602233290672), (23, 0.022379535483196378), (45, 0.022492847638204694), (49, 0.023123497841879725), (21, 0.024924597470089793), (47, 0.025067138485610485), (22, 0.02516876789741218), (24, 0.02589953737333417), (20, 0.02685900777578354), (38, 0.02811406832188368), (39, 0.029206908075138927), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03545433608815074), (37, 0.03597763925790787), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663433045149), (2, 0.05454846518114209), (52, 0.05469645746052265), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 0.9246632531285286)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882447388023138), (46, 0.019302030326798558), (42, 0.021432004403322935), (48, 0.021544843912124634), (40, 0.021832421189174056), (50, 0.021946269320324063), (25, 0.021972603164613247), (23, 0.022379535483196378), (49, 0.023006869945675135), (44, 0.023108509834855795), (45, 0.023535606916993856), (21, 0.02492459723725915), (22, 0.02516876789741218), (47, 0.025820446433499455), (24, 0.025899537838995457), (20, 0.026859007542952895), (38, 0.028114070184528828), (39, 0.02920690947212279), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.035091488622128963), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.053329030983150005), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484554082155), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9678284078836441)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 1 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 2 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 3 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 4 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 5 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 6 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 7 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 8 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 9 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 10 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447388023138), (46, 0.019070088164880872), (48, 0.020678168395534158), (50, 0.021344397217035294), (40, 0.021832421189174056), (25, 0.021972602931782603), (42, 0.02198694017715752), (23, 0.022379535948857665), (49, 0.022534748539328575), (45, 0.023929917253553867), (44, 0.02405400318093598), (21, 0.024924598401412368), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026043936843052506), (20, 0.02685900777578354), (38, 0.028114068554714322), (39, 0.02920690830796957), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03379448037594557), (37, 0.03597763879224658), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.050476094242185354), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.05892289988696575), (11, 0.05924913054332137), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882447388023138
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462957531214), (48, 0.01998970750719309), (50, 0.020775061566382647), (40, 0.021085953572764993), (42, 0.02136964723467827), (49, 0.02191002992913127), (25, 0.021972602931782603), (23, 0.02237953571602702), (44, 0.023239311994984746), (45, 0.02358530811034143), (21, 0.024924598168581724), (47, 0.025076948339119554), (22, 0.025168768363073468), (24, 0.02589953667484224), (20, 0.02685900661163032), (38, 0.027183361118659377), (39, 0.028580759186297655), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03281426033936441), (37, 0.03542024316266179), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.048523631412535906), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108212903141975), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462957531214
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.02083116164430976), (40, 0.02108595333993435), (42, 0.021369647700339556), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.022536989534273744), (44, 0.02323931222781539), (45, 0.023585309041664004), (21, 0.02492459863424301), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183361584320664), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.03285081218928099), (37, 0.03542024362832308), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.04812479903921485), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108213052153587), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.02136964863166213), (25, 0.021972602466121316), (23, 0.02237953571602702), (50, 0.022470063297078013), (44, 0.023239312460646033), (45, 0.023585308576002717), (21, 0.024924598401412368), (22, 0.02516876789741218), (49, 0.02523410110734403), (24, 0.025899537140503526), (47, 0.026583049912005663), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580758487805724), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03296921122819185), (37, 0.03542024455964565), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.05089045129716396), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.2663909196853638)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.021284766029566526), (25, 0.021972602466121316), (23, 0.022379535250365734), (45, 0.023098318139091134), (44, 0.024240857921540737), (49, 0.024500869447365403), (21, 0.024924597702920437), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026519698789343238), (20, 0.026859007542952895), (38, 0.027183361118659377), (39, 0.028580757789313793), (15, 0.03192339092493057), (51, 0.032220850232988596), (7, 0.03228544630110264), (19, 0.032628594897687435), (37, 0.03542024502530694), (9, 0.0434018773958087), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.04885757248848677), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4065233878791332), (18, 0.5108213052153587), (53, 1.3718616217374802)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658535912633), (25, 0.021972602233290672), (23, 0.02237953571602702), (45, 0.02376196626573801), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.025899538537487388), (47, 0.026220474857836962), (20, 0.026859008008614182), (38, 0.02718336065299809), (39, 0.028580758022144437), (51, 0.03127906774170697), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.035420242697000504), (9, 0.04340187972411513), (52, 0.046101711224764585), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4065233841538429), (18, 0.5108213275671005), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202658535912633
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.02376196626573801), (49, 0.02460233890451491), (44, 0.024712181882932782), (21, 0.024924597702920437), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026220474625006318), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.028580757789313793), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03344302112236619), (37, 0.03542024502530694), (9, 0.043401879258453846), (6, 0.046609030570834875), (4, 0.04749368177726865), (14, 0.0478366338647902), (52, 0.05265179555863142), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924912681803107), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108213052153587), (53, 1.6287681013345718)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.02237953571602702), (45, 0.0233820837456733), (49, 0.023860316490754485), (44, 0.02394806663505733), (21, 0.024924598168581724), (22, 0.025168769294396043), (47, 0.02536190371029079), (24, 0.025899537140503526), (38, 0.02653320599347353), (20, 0.026859007542952895), (39, 0.02847280679270625), (15, 0.03192339092493057), (7, 0.03228544583544135), (51, 0.03247324749827385), (19, 0.0326285962946713), (37, 0.03485476737841964), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05042571295052767), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.3996613547205925), (18, 0.5108212977647781), (53, 1.631172239780426)]
computing accuracy for after removing block 23 . block score: 0.02237953571602702
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.02356328465975821), (45, 0.023582331836223602), (49, 0.023707158863544464), (24, 0.024551384150981903), (47, 0.024688829435035586), (21, 0.024924598401412368), (22, 0.025168768363073468), (38, 0.0264099792111665), (20, 0.026859007542952895), (39, 0.0284329685382545), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.03235368151217699), (19, 0.0326285962946713), (37, 0.03590833814814687), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.0488563678227365), (2, 0.05454846704378724), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.0592491258867085), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.40237870812416077), (18, 0.5108212903141975), (53, 1.6179482191801071)]
computing accuracy for after removing block 44 . block score: 0.02356328465975821
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246752563863993), (49, 0.023541763424873352), (24, 0.02455138391815126), (21, 0.024924597004428506), (22, 0.025168768595904112), (47, 0.025985258864238858), (38, 0.026409979443997145), (20, 0.026859006844460964), (39, 0.028432969469577074), (15, 0.03192339278757572), (51, 0.03204912459477782), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03590833768248558), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.048162917606532574), (2, 0.05454846378415823), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.40237870067358017), (18, 0.5108213052153587), (53, 1.748221531510353)]
computing accuracy for after removing block 45 . block score: 0.023246752563863993
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.02415705192834139), (24, 0.024551385082304478), (21, 0.024924598168581724), (22, 0.025168768363073468), (38, 0.026409980142489076), (20, 0.026859007542952895), (47, 0.027429412119090557), (39, 0.02843296923674643), (51, 0.031893002800643444), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03590833814814687), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.04907965287566185), (2, 0.05454846704378724), (3, 0.057224276941269636), (13, 0.05892290361225605), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.40237870067358017), (18, 0.5108212977647781), (53, 1.895566999912262)]
computing accuracy for after removing block 49 . block score: 0.02415705192834139
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best True lr [0.1]
training epoch 1 val accuracy 0.8124 topk_dict {'top1': 0.8124} is_best False lr [0.1]
training epoch 2 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best True lr [0.1]
training epoch 3 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.1]
training epoch 5 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 6 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 10 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.956 topk_dict {'top1': 0.956} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.957 topk_dict {'top1': 0.957} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9576 topk_dict {'top1': 0.9576}
start iteration 22
[activation diff]: block to remove picked: 19, with score 0.059957. All blocks and scores: [(19, 0.05995685514062643), (20, 0.06262682424858212), (15, 0.06293958844617009), (7, 0.06448522489517927), (38, 0.0645478805527091), (21, 0.06491156108677387), (22, 0.06597365997731686), (51, 0.06953496113419533), (39, 0.07280892971903086), (47, 0.07334259804338217), (52, 0.07422334514558315), (37, 0.07497043814510107), (24, 0.07527664955705404), (4, 0.08492120634764433), (9, 0.08688531629741192), (6, 0.08809553179889917), (14, 0.08948310278356075), (3, 0.10199255403131247), (2, 0.10260913614183664), (11, 0.10411033686250448), (17, 0.10958728473633528), (13, 0.11298895720392466), (0, 0.11681536305695772), (1, 0.12961574085056782), (8, 0.13417935743927956), (10, 0.15408522635698318), (12, 0.16135912016034126), (16, 0.1670359317213297), (5, 0.208628686144948), (36, 0.5468779504299164), (18, 0.6526394560933113), (53, 1.0475213825702667)]
computing accuracy for after removing block 19 . block score: 0.05995685514062643
removed block 19 current accuracy 0.949 loss from initial  0.051000000000000045
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.059643. All blocks and scores: [(20, 0.0596428457647562), (22, 0.06275983899831772), (15, 0.06293958658352494), (38, 0.06407847348600626), (21, 0.06423452962189913), (7, 0.0644852239638567), (24, 0.06883450597524643), (51, 0.06944125983864069), (47, 0.07087210286408663), (52, 0.07248929794877768), (39, 0.07462206203490496), (37, 0.07921366672962904), (4, 0.08492120448499918), (9, 0.08688531536608934), (6, 0.08809553366154432), (14, 0.08948310650885105), (3, 0.10199255123734474), (2, 0.10260913800448179), (11, 0.10411033313721418), (17, 0.109587287530303), (13, 0.11298895254731178), (0, 0.11681535746902227), (1, 0.12961573898792267), (8, 0.13417935743927956), (10, 0.15408522635698318), (12, 0.16135911643505096), (16, 0.16703592985868454), (5, 0.208628686144948), (36, 0.5446818321943283), (18, 0.6526394337415695), (53, 1.034442961215973)]
computing accuracy for after removing block 20 . block score: 0.0596428457647562
removed block 20 current accuracy 0.9348 loss from initial  0.06520000000000004
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.060719. All blocks and scores: [(22, 0.0607191645540297), (15, 0.06293958658352494), (38, 0.06306887324899435), (7, 0.06448522675782442), (24, 0.06485923752188683), (21, 0.06724454835057259), (51, 0.06748231314122677), (47, 0.06796535104513168), (52, 0.06868140399456024), (39, 0.07473346870392561), (4, 0.08492120541632175), (37, 0.08514269161969423), (9, 0.08688531443476677), (6, 0.08809552993625402), (14, 0.08948310278356075), (3, 0.10199255309998989), (2, 0.10260913707315922), (11, 0.10411033779382706), (17, 0.10958729218691587), (13, 0.11298895720392466), (0, 0.11681535933166742), (1, 0.12961573898792267), (8, 0.13417936116456985), (10, 0.15408522449433804), (12, 0.16135911643505096), (16, 0.1670359242707491), (5, 0.20862868055701256), (36, 0.5535525605082512), (18, 0.6526394337415695), (53, 1.0153782367706299)]
computing accuracy for after removing block 22 . block score: 0.0607191645540297
removed block 22 current accuracy 0.9212 loss from initial  0.07879999999999998
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.060428. All blocks and scores: [(24, 0.0604281728155911), (38, 0.06217122729867697), (15, 0.06293958611786366), (47, 0.06304084463045001), (51, 0.06304891547188163), (52, 0.0637667765840888), (7, 0.06448522489517927), (21, 0.06724454928189516), (39, 0.07554950658231974), (4, 0.08492120821028948), (9, 0.08688531536608934), (6, 0.08809552993625402), (14, 0.08948310557752848), (37, 0.09279768168926239), (3, 0.10199255496263504), (2, 0.10260913986712694), (11, 0.10411033406853676), (17, 0.10958728473633528), (13, 0.11298895440995693), (0, 0.11681536212563515), (1, 0.12961573898792267), (8, 0.13417936116456985), (10, 0.15408522821962833), (12, 0.16135911643505096), (16, 0.1670359317213297), (5, 0.2086286824196577), (36, 0.566570833325386), (18, 0.6526394486427307), (53, 0.996985025703907)]
computing accuracy for after removing block 24 . block score: 0.0604281728155911
removed block 24 current accuracy 0.904 loss from initial  0.09599999999999997
since last training loss: 0.05359999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.057903. All blocks and scores: [(52, 0.05790282739326358), (51, 0.05827606562525034), (47, 0.05963100120425224), (38, 0.06001914897933602), (15, 0.06293958611786366), (7, 0.0644852239638567), (21, 0.06724455021321774), (39, 0.07349614426493645), (4, 0.08492120541632175), (9, 0.08688531536608934), (6, 0.08809553273022175), (37, 0.08861904963850975), (14, 0.08948310278356075), (3, 0.10199255309998989), (2, 0.10260914359241724), (11, 0.10411033313721418), (17, 0.10958728473633528), (13, 0.11298895720392466), (0, 0.1168153639882803), (1, 0.12961573526263237), (8, 0.13417936116456985), (10, 0.15408522449433804), (12, 0.16135911457240582), (16, 0.1670359317213297), (5, 0.2086286824196577), (36, 0.5592255145311356), (18, 0.6526394411921501), (53, 0.9988519176840782)]
computing accuracy for after removing block 52 . block score: 0.05790282739326358
removed block 52 current accuracy 0.8672 loss from initial  0.13280000000000003
since last training loss: 0.09040000000000004 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.058276. All blocks and scores: [(51, 0.05827606515958905), (47, 0.05963100027292967), (38, 0.06001915130764246), (15, 0.06293958565220237), (7, 0.06448522582650185), (21, 0.06724454928189516), (39, 0.0734961461275816), (4, 0.0849212072789669), (9, 0.08688531536608934), (6, 0.0880955308675766), (37, 0.08861904963850975), (14, 0.08948310371488333), (3, 0.10199255123734474), (2, 0.10260913893580437), (11, 0.10411033779382706), (17, 0.10958728846162558), (13, 0.11298895161598921), (0, 0.11681535467505455), (1, 0.12961573898792267), (8, 0.13417935743927956), (10, 0.15408522449433804), (12, 0.1613591182976961), (16, 0.1670359317213297), (5, 0.2086286824196577), (36, 0.5592254996299744), (18, 0.6526394635438919), (53, 0.9571946337819099)]
computing accuracy for after removing block 51 . block score: 0.05827606515958905
removed block 51 current accuracy 0.8076 loss from initial  0.19240000000000002
since last training loss: 0.15000000000000002 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 47, with score 0.059631. All blocks and scores: [(47, 0.05963099980726838), (38, 0.06001915177330375), (15, 0.06293958704918623), (7, 0.0644852239638567), (21, 0.06724454741925001), (39, 0.07349614519625902), (4, 0.0849212072789669), (9, 0.0868853135034442), (6, 0.08809553273022175), (37, 0.0886190477758646), (14, 0.0894831046462059), (3, 0.10199255216866732), (2, 0.10260913986712694), (11, 0.10411033220589161), (17, 0.1095872838050127), (13, 0.11298895627260208), (0, 0.11681536212563515), (1, 0.12961573526263237), (8, 0.13417936116456985), (10, 0.15408522821962833), (12, 0.16135910898447037), (16, 0.16703593358397484), (5, 0.2086286824196577), (36, 0.559225507080555), (18, 0.6526394337415695), (53, 1.0497234016656876)]
computing accuracy for after removing block 47 . block score: 0.05963099980726838
removed block 47 current accuracy 0.7478 loss from initial  0.2522
since last training loss: 0.2098 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.060019. All blocks and scores: [(38, 0.060019150376319885), (15, 0.06293958611786366), (7, 0.06448522489517927), (21, 0.06724454835057259), (39, 0.0734961461275816), (4, 0.0849212072789669), (9, 0.08688531629741192), (6, 0.0880955345928669), (37, 0.08861905056983232), (14, 0.08948310185223818), (3, 0.10199255123734474), (2, 0.10260914359241724), (11, 0.10411033686250448), (17, 0.10958728473633528), (13, 0.11298895440995693), (0, 0.11681536212563515), (1, 0.12961573712527752), (8, 0.1341793593019247), (10, 0.15408522449433804), (12, 0.1613591182976961), (16, 0.16703592985868454), (5, 0.2086286786943674), (36, 0.5592255219817162), (18, 0.6526394411921501), (53, 1.1386865675449371)]
computing accuracy for after removing block 38 . block score: 0.060019150376319885
removed block 38 current accuracy 0.6924 loss from initial  0.3076
since last training loss: 0.2652 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 15, with score 0.062940. All blocks and scores: [(15, 0.06293958611786366), (7, 0.06448522489517927), (21, 0.06724454741925001), (39, 0.08468135446310043), (4, 0.08492120448499918), (9, 0.0868853135034442), (6, 0.08809553366154432), (37, 0.0886190477758646), (14, 0.0894831046462059), (3, 0.10199255403131247), (2, 0.10260914172977209), (11, 0.10411033499985933), (17, 0.10958728659898043), (13, 0.11298895347863436), (0, 0.11681536026299), (1, 0.12961574085056782), (8, 0.13417936116456985), (10, 0.15408522449433804), (12, 0.16135911643505096), (16, 0.16703593544662), (5, 0.208628686144948), (36, 0.5592255145311356), (18, 0.6526394486427307), (53, 1.170578971505165)]
computing accuracy for after removing block 15 . block score: 0.06293958611786366
removed block 15 current accuracy 0.6816 loss from initial  0.3184
since last training loss: 0.276 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 21, with score 0.062975. All blocks and scores: [(21, 0.06297457870095968), (7, 0.06448522489517927), (39, 0.08339053764939308), (37, 0.08479183726012707), (4, 0.08492120448499918), (9, 0.08688531536608934), (6, 0.08809552900493145), (14, 0.08948310650885105), (3, 0.10199255682528019), (2, 0.10260914079844952), (11, 0.10411033593118191), (13, 0.11298895347863436), (0, 0.11681535840034485), (17, 0.1198460916057229), (1, 0.12961574085056782), (8, 0.1341793593019247), (10, 0.15408522449433804), (12, 0.1613591182976961), (16, 0.18298273719847202), (5, 0.208628686144948), (36, 0.5440116599202156), (18, 0.6245901808142662), (53, 1.1849206686019897)]
computing accuracy for after removing block 21 . block score: 0.06297457870095968
removed block 21 current accuracy 0.6238 loss from initial  0.3762
since last training loss: 0.3338 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 7, with score 0.064485. All blocks and scores: [(7, 0.0644852239638567), (39, 0.08284929301589727), (4, 0.08492120634764433), (9, 0.08688531536608934), (6, 0.0880955308675766), (37, 0.08886831905692816), (14, 0.08948310371488333), (3, 0.10199255496263504), (2, 0.10260913800448179), (11, 0.10411033220589161), (13, 0.11298895347863436), (0, 0.11681536026299), (17, 0.1198460916057229), (1, 0.12961573898792267), (8, 0.1341793593019247), (10, 0.15408522635698318), (12, 0.16135911643505096), (16, 0.18298272788524628), (5, 0.20862868055701256), (36, 0.5383500531315804), (18, 0.6245901882648468), (53, 1.1018654108047485)]
computing accuracy for after removing block 7 . block score: 0.0644852239638567
removed block 7 current accuracy 0.5958 loss from initial  0.4042
training start
training epoch 0 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best True lr [0.1]
training epoch 1 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best True lr [0.1]
training epoch 2 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.1]
training epoch 3 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.1]
training epoch 4 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best True lr [0.1]
training epoch 5 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 6 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 7 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best True lr [0.1]
training epoch 8 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 9 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 10 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.931800)
finished training. finished 50 epochs. accuracy 0.9318 topk_dict {'top1': 0.9318}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.106382. All blocks and scores: [(4, 0.10638186987489462), (37, 0.1119800228625536), (2, 0.11299490183591843), (0, 0.12376873567700386), (3, 0.12574927136301994), (6, 0.12597254570573568), (39, 0.12800781056284904), (9, 0.13726767525076866), (14, 0.14016366936266422), (11, 0.14556315541267395), (1, 0.15691420994699), (13, 0.16952182352542877), (8, 0.1716688871383667), (17, 0.18011904507875443), (10, 0.18585814349353313), (12, 0.22504541464149952), (16, 0.23552395589649677), (5, 0.2706299312412739), (36, 0.4712034799158573), (18, 0.587915301322937), (53, 1.33512844145298)]
computing accuracy for after removing block 4 . block score: 0.10638186987489462
removed block 4 current accuracy 0.9242 loss from initial  0.07579999999999998
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.112995. All blocks and scores: [(2, 0.11299490462988615), (37, 0.11409547366201878), (0, 0.12376873474568129), (3, 0.12574926763772964), (39, 0.12826907634735107), (9, 0.1364331655204296), (14, 0.1374844778329134), (11, 0.1420337948948145), (6, 0.15305444784462452), (1, 0.15691420994699), (13, 0.16407092474400997), (17, 0.1753534972667694), (8, 0.17624957859516144), (10, 0.18649041093885899), (12, 0.21111581847071648), (16, 0.218648137524724), (5, 0.2959466949105263), (36, 0.47602810338139534), (18, 0.5885253325104713), (53, 1.3079851269721985)]
computing accuracy for after removing block 2 . block score: 0.11299490462988615
removed block 2 current accuracy 0.915 loss from initial  0.08499999999999996
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 37, with score 0.102371. All blocks and scores: [(37, 0.10237096156924963), (3, 0.10722983349114656), (0, 0.12376873381435871), (39, 0.12384743802249432), (14, 0.1244520852342248), (9, 0.1305963099002838), (11, 0.13322043046355247), (6, 0.13696048595011234), (17, 0.13977152667939663), (13, 0.14159909635782242), (1, 0.15691420622169971), (8, 0.17359231039881706), (10, 0.1779039353132248), (12, 0.197118129581213), (16, 0.1999906413257122), (5, 0.29189418628811836), (36, 0.43461743369698524), (18, 0.5283937081694603), (53, 1.2500178813934326)]
computing accuracy for after removing block 37 . block score: 0.10237096156924963
removed block 37 current accuracy 0.869 loss from initial  0.131
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.107230. All blocks and scores: [(3, 0.10722983814775944), (0, 0.12376873660832644), (14, 0.1244520815089345), (9, 0.13059631548821926), (11, 0.13322043232619762), (6, 0.1369604803621769), (17, 0.13977152854204178), (13, 0.14159909449517727), (1, 0.15691420622169971), (39, 0.15703264251351357), (8, 0.1735923159867525), (10, 0.1779039390385151), (12, 0.197118129581213), (16, 0.19999063946306705), (5, 0.29189417511224747), (36, 0.43461744859814644), (18, 0.5283937007188797), (53, 1.2143560349941254)]
computing accuracy for after removing block 3 . block score: 0.10722983814775944
removed block 3 current accuracy 0.8242 loss from initial  0.17579999999999996
since last training loss: 0.10759999999999992 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 14, with score 0.116929. All blocks and scores: [(14, 0.11692912876605988), (0, 0.12376873940229416), (11, 0.12746045924723148), (17, 0.12787463329732418), (9, 0.13235195726156235), (13, 0.13373957946896553), (39, 0.14820753410458565), (1, 0.15691420808434486), (6, 0.1575128436088562), (16, 0.16253449954092503), (8, 0.16820897161960602), (10, 0.18350636400282383), (12, 0.18586133420467377), (5, 0.3163192570209503), (36, 0.41223637014627457), (18, 0.48730484768748283), (53, 1.156945288181305)]
computing accuracy for after removing block 14 . block score: 0.11692912876605988
removed block 14 current accuracy 0.7542 loss from initial  0.24580000000000002
since last training loss: 0.17759999999999998 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 0, with score 0.123769. All blocks and scores: [(0, 0.12376873474568129), (11, 0.12746046110987663), (17, 0.12935104221105576), (9, 0.13235195726156235), (13, 0.13373958133161068), (39, 0.1500120386481285), (1, 0.15691420435905457), (6, 0.1575128398835659), (8, 0.16820897161960602), (10, 0.18350636586546898), (12, 0.18586133234202862), (16, 0.1929989792406559), (5, 0.31631925329566), (36, 0.4165189824998379), (18, 0.4819185137748718), (53, 1.2286086529493332)]
computing accuracy for after removing block 0 . block score: 0.12376873474568129
removed block 0 current accuracy 0.6492 loss from initial  0.3508
since last training loss: 0.28259999999999996 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 17, with score 0.123833. All blocks and scores: [(17, 0.12383301928639412), (13, 0.12446198333054781), (9, 0.12877332232892513), (11, 0.1293295081704855), (39, 0.14901989698410034), (1, 0.15812893211841583), (16, 0.16765723749995232), (6, 0.17124024778604507), (8, 0.1749305408447981), (10, 0.17662438936531544), (12, 0.20806082524359226), (5, 0.32712311670184135), (36, 0.4092397503554821), (18, 0.48387838900089264), (53, 1.1942521929740906)]
computing accuracy for after removing block 17 . block score: 0.12383301928639412
removed block 17 current accuracy 0.571 loss from initial  0.42900000000000005
since last training loss: 0.3608 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 13, with score 0.124462. All blocks and scores: [(13, 0.12446198146790266), (9, 0.12877332046627998), (11, 0.1293295081704855), (39, 0.1367994137108326), (1, 0.15812892839312553), (16, 0.16765723749995232), (6, 0.17124024406075478), (8, 0.17493053525686264), (10, 0.1766243912279606), (12, 0.20806082896888256), (5, 0.32712312042713165), (36, 0.3829776830971241), (18, 0.45383916050195694), (53, 1.04401133954525)]
computing accuracy for after removing block 13 . block score: 0.12446198146790266
removed block 13 current accuracy 0.433 loss from initial  0.567
since last training loss: 0.49879999999999997 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 9, with score 0.128773. All blocks and scores: [(9, 0.12877331674098969), (11, 0.1293295081704855), (39, 0.14016704820096493), (1, 0.15812893211841583), (16, 0.17013920657336712), (6, 0.17124024592339993), (8, 0.1749305371195078), (10, 0.17662438936531544), (12, 0.20806082151830196), (5, 0.32712311670184135), (36, 0.4034160301089287), (18, 0.4815645180642605), (53, 1.1397947371006012)]
computing accuracy for after removing block 9 . block score: 0.12877331674098969
removed block 9 current accuracy 0.3918 loss from initial  0.6082000000000001
since last training loss: 0.54 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 39, with score 0.128807. All blocks and scores: [(39, 0.12880737148225307), (16, 0.13887954130768776), (11, 0.1442610863596201), (10, 0.15363634191453457), (12, 0.1576805431395769), (1, 0.15812893025577068), (6, 0.17124024964869022), (8, 0.1749305371195078), (5, 0.32712313160300255), (36, 0.3657348155975342), (18, 0.48603053018450737), (53, 0.7361721992492676)]
computing accuracy for after removing block 39 . block score: 0.12880737148225307
removed block 39 current accuracy 0.2148 loss from initial  0.7852
since last training loss: 0.717 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 16, with score 0.138880. All blocks and scores: [(16, 0.13887954503297806), (11, 0.14426108449697495), (10, 0.15363634750247002), (12, 0.15768054127693176), (1, 0.15812892653048038), (6, 0.17124024406075478), (8, 0.17493053525686264), (5, 0.32712311670184135), (36, 0.3657348118722439), (18, 0.48603054881095886), (53, 1.4167441427707672)]
computing accuracy for after removing block 16 . block score: 0.13887954503297806
removed block 16 current accuracy 0.1568 loss from initial  0.8432
since last training loss: 0.7749999999999999 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 11, with score 0.144261. All blocks and scores: [(11, 0.14426108449697495), (10, 0.15363634750247002), (12, 0.15768054500222206), (1, 0.15812893025577068), (6, 0.17124024592339993), (8, 0.1749305408447981), (5, 0.32712312415242195), (36, 0.3959686681628227), (18, 0.5804114043712616), (53, 1.629697397351265)]
computing accuracy for after removing block 11 . block score: 0.14426108449697495
removed block 11 current accuracy 0.1438 loss from initial  0.8562
training start
training epoch 0 val accuracy 0.7744 topk_dict {'top1': 0.7744} is_best True lr [0.1]
training epoch 1 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best True lr [0.1]
training epoch 2 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best False lr [0.1]
training epoch 3 val accuracy 0.819 topk_dict {'top1': 0.819} is_best False lr [0.1]
training epoch 4 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best True lr [0.1]
training epoch 5 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 6 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 7 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best False lr [0.1]
training epoch 8 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.1]
training epoch 9 val accuracy 0.857 topk_dict {'top1': 0.857} is_best True lr [0.1]
training epoch 10 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.911000)
finished training. finished 50 epochs. accuracy 0.911 topk_dict {'top1': 0.911}
