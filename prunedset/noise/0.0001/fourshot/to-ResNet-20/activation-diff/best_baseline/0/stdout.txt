start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050281181931), (30, 0.010039401007816195), (31, 0.010361600201576948), (34, 0.013312276219949126), (29, 0.01354115444701165), (35, 0.016018462600186467), (26, 0.016037591034546494), (28, 0.017728674691170454), (27, 0.019127049250528216), (43, 0.02023245650343597), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.022379535948857665), (41, 0.022826647385954857), (44, 0.023395078722387552), (40, 0.024025025544688106), (45, 0.024295411305502057), (21, 0.024924598401412368), (22, 0.025168768130242825), (48, 0.025341259315609932), (24, 0.025899537606164813), (50, 0.026409972459077835), (42, 0.026674099965021014), (20, 0.026859007077291608), (49, 0.027037164894863963), (47, 0.02930646832101047), (39, 0.031570713268592954), (38, 0.031637870240956545), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859443202615), (37, 0.037960262037813663), (51, 0.04173417203128338), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368270859122), (14, 0.047836634796112776), (2, 0.05454846378415823), (3, 0.05722427926957607), (13, 0.058922900818288326), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.06862937659025192), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43758000060915947), (18, 0.5108213126659393), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.010039400542154908), (31, 0.010361599619500339), (34, 0.013133947504684329), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169289825484157), (28, 0.01772867515683174), (27, 0.019127049017697573), (43, 0.020072476705536246), (46, 0.020731385331600904), (25, 0.02197260269895196), (41, 0.022347092861309648), (23, 0.02237953571602702), (44, 0.02323568775318563), (40, 0.02384106651879847), (45, 0.02396554220467806), (48, 0.024917916394770145), (21, 0.024924598401412368), (22, 0.025168768595904112), (50, 0.02584081282839179), (24, 0.025899537140503526), (42, 0.026315322844311595), (49, 0.026655674912035465), (20, 0.026859007077291608), (47, 0.028728798497468233), (39, 0.0313176428899169), (38, 0.03138036374002695), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03802584344521165), (51, 0.04122393997386098), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493685968220234), (14, 0.047836634796112776), (2, 0.054548466578125954), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912681803107), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06745154969394207), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386744171381), (36, 0.4353870861232281), (18, 0.5108212977647781), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039401007816195), (31, 0.010361600201576948), (34, 0.012765232822857797), (29, 0.013541154563426971), (35, 0.015992751577869058), (26, 0.016037590568885207), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02007513213902712), (46, 0.02084140619263053), (25, 0.021972602931782603), (41, 0.02231976669281721), (23, 0.022379535250365734), (44, 0.023154049646109343), (40, 0.02388568501919508), (45, 0.02407168922945857), (48, 0.02487746556289494), (21, 0.024924598168581724), (22, 0.0251687690615654), (50, 0.02569117769598961), (24, 0.025899537838995457), (42, 0.026123747462406754), (49, 0.026479422114789486), (20, 0.02685900731012225), (47, 0.028693131636828184), (38, 0.031236795475706458), (39, 0.03129529068246484), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.038376690819859505), (51, 0.04111403366550803), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427600994706), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (52, 0.06700456328690052), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.43640002608299255), (18, 0.5108213052153587), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039401007816195
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372017733753), (34, 0.012387836934067309), (29, 0.013541154214181006), (35, 0.016008096048608422), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.020083633484318852), (46, 0.020704444032162428), (25, 0.02197260269895196), (41, 0.02225319715216756), (23, 0.02237953618168831), (44, 0.02326776133850217), (40, 0.02401388017460704), (45, 0.0240929932333529), (48, 0.02466528071090579), (21, 0.024924597702920437), (22, 0.025168767664581537), (50, 0.025459734722971916), (42, 0.025655713165178895), (24, 0.025899536442011595), (49, 0.02628775709308684), (20, 0.02685900661163032), (47, 0.028363423654809594), (38, 0.031047647120431066), (39, 0.03138077212497592), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.038971245754510164), (51, 0.04075620323419571), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.059249126352369785), (17, 0.06095684738829732), (0, 0.06300980830565095), (52, 0.06586316134780645), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4389924518764019), (18, 0.5108212977647781), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375372017733753
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489620130509138), (29, 0.013541154563426971), (26, 0.016037590336054564), (35, 0.016057362547144294), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020049349637702107), (46, 0.020552987465634942), (25, 0.02197260269895196), (41, 0.022067483980208635), (23, 0.022379535948857665), (44, 0.022979132365435362), (40, 0.023858347442001104), (45, 0.024124701973050833), (48, 0.02438612305559218), (21, 0.024924598168581724), (50, 0.025042241672053933), (22, 0.025168768130242825), (42, 0.025414508068934083), (49, 0.02584269898943603), (24, 0.025899536442011595), (20, 0.02685900661163032), (47, 0.02805073419585824), (38, 0.031040059635415673), (39, 0.03150080284103751), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.03911284916102886), (51, 0.04024627385661006), (9, 0.04340188158676028), (6, 0.046609032433480024), (4, 0.04749368550255895), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980970263481), (52, 0.06486208736896515), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4381278455257416), (18, 0.5108212977647781), (53, 0.8458427637815475)]
computing accuracy for after removing block 34 . block score: 0.012489620130509138
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.01603759080171585), (35, 0.016653420170769095), (28, 0.017728675389662385), (27, 0.019127048086374998), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.022452629171311855), (44, 0.02336447359994054), (48, 0.024290354922413826), (45, 0.024438712978735566), (40, 0.024470558390021324), (21, 0.02492459863424301), (50, 0.025042172987014055), (22, 0.025168768595904112), (49, 0.025875969789922237), (24, 0.025899537140503526), (42, 0.026205406291410327), (20, 0.02685900661163032), (47, 0.028178582666441798), (15, 0.03192339139059186), (38, 0.03208350157365203), (7, 0.03228544723242521), (39, 0.03233744157478213), (19, 0.03262859582901001), (51, 0.03994725877419114), (37, 0.04073968343436718), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722427600994706), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980830565095), (52, 0.06433630175888538), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.45053431019186974), (18, 0.5108212903141975), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470608301460743), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.02004686719737947), (46, 0.020376993576064706), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.02302833739668131), (48, 0.023771877167746425), (40, 0.023930813651531935), (45, 0.024178662803024054), (50, 0.024390298640355468), (21, 0.02492459793575108), (22, 0.025168768130242825), (42, 0.025188251165673137), (49, 0.025361529318615794), (24, 0.025899537140503526), (20, 0.026859007542952895), (47, 0.027363278437405825), (38, 0.03136561857536435), (15, 0.03192339185625315), (39, 0.03212768444791436), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03893592394888401), (37, 0.040206342935562134), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.05924912681803107), (17, 0.060956849716603756), (52, 0.0623285504989326), (0, 0.06300980551168323), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.4444201923906803), (18, 0.5108213126659393), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365330904722), (28, 0.01708850055001676), (27, 0.018882447155192494), (43, 0.019595165271312), (46, 0.020073581486940384), (41, 0.020961584523320198), (25, 0.021972603164613247), (23, 0.022379535250365734), (44, 0.02281495602801442), (48, 0.023128160275518894), (40, 0.023345196153968573), (50, 0.023756146896630526), (42, 0.02384730288758874), (45, 0.02387388050556183), (21, 0.024924598401412368), (49, 0.024960316019132733), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026855542324483395), (20, 0.02685900731012225), (38, 0.030424013966694474), (39, 0.031514045083895326), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03782488079741597), (37, 0.039368351455777884), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249128215014935), (52, 0.06033282168209553), (17, 0.060956851579248905), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4360685423016548), (18, 0.5108212977647781), (53, 0.8749377131462097)]
computing accuracy for after removing block 35 . block score: 0.015597365330904722
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088501248508692), (43, 0.018555945251137018), (27, 0.018882447388023138), (46, 0.019160084892064333), (41, 0.019424295285716653), (48, 0.021467271959409118), (25, 0.021972602466121316), (44, 0.022026916733011603), (40, 0.02217966062016785), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.022379535483196378), (45, 0.022931481944397092), (49, 0.023708511609584093), (21, 0.024924598401412368), (22, 0.025168767431750894), (47, 0.025829139165580273), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.028956545516848564), (39, 0.029667828464880586), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03600902669131756), (37, 0.036512387450784445), (9, 0.04340187879279256), (6, 0.046609030570834875), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548464715480804), (52, 0.05610728543251753), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300981156527996), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4175764434039593), (18, 0.5108212903141975), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.017088501248508692
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.01865610247477889), (41, 0.018849018029868603), (27, 0.018882446689531207), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.021832421654835343), (44, 0.021840530447661877), (50, 0.021869864081963897), (25, 0.021972603164613247), (23, 0.02237953501753509), (45, 0.022492847638204694), (49, 0.02312349807471037), (21, 0.02492459793575108), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.026859006378799677), (38, 0.028114069486036897), (39, 0.02920690830796957), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628594897687435), (51, 0.03545433655381203), (37, 0.03597763925790787), (9, 0.043401877861469984), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846564680338), (52, 0.0546964593231678), (3, 0.05722427787259221), (13, 0.05892290314659476), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.0630098064430058), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 0.924663245677948)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.01888244692236185), (46, 0.019302030093967915), (42, 0.021432003704831004), (48, 0.02154484367929399), (40, 0.021832421189174056), (50, 0.02194626978598535), (25, 0.021972602466121316), (23, 0.022379535483196378), (49, 0.023006869247183204), (44, 0.023108510300517082), (45, 0.02353560645133257), (21, 0.02492459793575108), (22, 0.025168768595904112), (47, 0.025820446200668812), (24, 0.025899537606164813), (20, 0.026859006378799677), (38, 0.02811406971886754), (39, 0.029206908540800214), (15, 0.03192339278757572), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.0350914872251451), (37, 0.03597763925790787), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.05332902818918228), (2, 0.05454846378415823), (3, 0.05722427600994706), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4135979078710079), (18, 0.5108213052153587), (53, 0.9678283929824829)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 1 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 2 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 3 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 4 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 5 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 6 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 7 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.1]
training epoch 8 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 9 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 10 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.019070088164880872), (48, 0.020678168162703514), (50, 0.021344397915527225), (40, 0.02183242212049663), (25, 0.02197260269895196), (42, 0.021986940409988165), (23, 0.022379535483196378), (49, 0.022534748073667288), (45, 0.023929917719215155), (44, 0.024054003646597266), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026043936843052506), (20, 0.026859006844460964), (38, 0.02811407041735947), (39, 0.0292069090064615), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03379448037594557), (37, 0.03597763879224658), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368643388152), (14, 0.0478366338647902), (52, 0.050476092379540205), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4135979041457176), (18, 0.5108213052153587), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.01998970750719309), (50, 0.02077506179921329), (40, 0.02108595333993435), (42, 0.0213696479331702), (49, 0.021910030161961913), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.02323931152932346), (45, 0.023585308576002717), (21, 0.02492459793575108), (47, 0.02507694810628891), (22, 0.025168768130242825), (24, 0.02589953737333417), (20, 0.02685900777578354), (38, 0.02718335995450616), (39, 0.028580758487805724), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.032814261270686984), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.048523630015552044), (2, 0.054548464715480804), (3, 0.05722427600994706), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685111358762), (0, 0.06300980877131224), (1, 0.06676734052598476), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233953297138), (18, 0.5108213126659393), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560370787978), (50, 0.020831162109971046), (40, 0.02108595333993435), (42, 0.0213696479331702), (25, 0.021972602931782603), (23, 0.022379535483196378), (49, 0.0225369893014431), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.02492459793575108), (22, 0.0251687690615654), (24, 0.025899537838995457), (47, 0.026583050144836307), (20, 0.026859007542952895), (38, 0.02718335995450616), (39, 0.028580758487805724), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.03285081218928099), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.04812479764223099), (2, 0.054548466112464666), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560370787978
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952874273062), (42, 0.021369647700339556), (25, 0.021972602466121316), (23, 0.022379535483196378), (50, 0.022470063297078013), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.024924597470089793), (22, 0.02516876789741218), (49, 0.02523410227149725), (24, 0.02589953737333417), (47, 0.026583048747852445), (20, 0.026859007077291608), (38, 0.027183361584320664), (39, 0.028580758487805724), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03296921215951443), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.050890450831502676), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912681803107), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952874273062
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.021284766029566526), (25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.02309831720776856), (44, 0.02424085745587945), (49, 0.024500868981704116), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.02651969948783517), (20, 0.02685900731012225), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339278757572), (51, 0.032220848836004734), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.04885757248848677), (2, 0.054548462852835655), (3, 0.05722428159788251), (13, 0.058922899421304464), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.40652337670326233), (18, 0.5108213052153587), (53, 1.371861606836319)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658070251346), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.023761966032907367), (49, 0.024602338671684265), (44, 0.02471218165010214), (21, 0.02492459793575108), (22, 0.025168767431750894), (24, 0.025899537838995457), (47, 0.026220475090667605), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580759186297655), (51, 0.03127906774170697), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.035420244093984365), (9, 0.043401881121098995), (52, 0.04610171215608716), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.4178234189748764)]
computing accuracy for after removing block 50 . block score: 0.021202658070251346
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972603164613247), (23, 0.022379535250365734), (45, 0.02376196556724608), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899537838995457), (47, 0.026220474625006318), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03344302112236619), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663293346763), (52, 0.05265179416164756), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912681803107), (17, 0.06095685111358762), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.4065234027802944), (18, 0.5108213201165199), (53, 1.628768116235733)]
computing accuracy for after removing block 25 . block score: 0.021972603164613247
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535250365734), (45, 0.023382084211334586), (49, 0.02386031672358513), (44, 0.02394806663505733), (21, 0.024924598401412368), (22, 0.02516876789741218), (47, 0.025361904175952077), (24, 0.025899537140503526), (38, 0.02653320482932031), (20, 0.02685900777578354), (39, 0.028472806327044964), (15, 0.03192339185625315), (7, 0.03228544583544135), (51, 0.03247324749827385), (19, 0.03262859582901001), (37, 0.03485476737841964), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05042571201920509), (2, 0.054548469837754965), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.3996613621711731), (18, 0.5108213126659393), (53, 1.6311722695827484)]
computing accuracy for after removing block 23 . block score: 0.022379535250365734
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.02356328465975821), (45, 0.02358233113773167), (49, 0.023707158397883177), (24, 0.02455138461664319), (47, 0.02468883083201945), (21, 0.024924598168581724), (22, 0.025168768828734756), (38, 0.026409979909658432), (20, 0.02685900661163032), (39, 0.0284329685382545), (15, 0.03192339139059186), (7, 0.03228544630110264), (51, 0.03235368197783828), (19, 0.032628594897687435), (37, 0.03590833814814687), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.04885636828839779), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.0746783260256052), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.40237869694828987), (18, 0.5108212903141975), (53, 1.6179482638835907)]
computing accuracy for after removing block 44 . block score: 0.02356328465975821
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.02324675233103335), (49, 0.023541762260720134), (24, 0.024551382986828685), (21, 0.024924598168581724), (22, 0.025168768130242825), (47, 0.02598525839857757), (38, 0.026409979909658432), (20, 0.02685900731012225), (39, 0.028432970168069005), (15, 0.03192339092493057), (51, 0.03204912506043911), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03590833768248558), (9, 0.043401877861469984), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04816291853785515), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980690866709), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.40237871184945107), (18, 0.5108212977647781), (53, 1.748221516609192)]
computing accuracy for after removing block 45 . block score: 0.02324675233103335
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157052161172032), (24, 0.024551384383812547), (21, 0.02492459863424301), (22, 0.025168768363073468), (38, 0.026409980142489076), (20, 0.02685900661163032), (47, 0.027429411187767982), (39, 0.0284329685382545), (51, 0.03189300186932087), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628596760332584), (37, 0.03590833768248558), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.04907965334132314), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.40237870067358017), (18, 0.5108213052153587), (53, 1.8955669850111008)]
computing accuracy for after removing block 49 . block score: 0.024157052161172032
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.814 topk_dict {'top1': 0.814} is_best True lr [0.1]
training epoch 1 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 2 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 3 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 4 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 5 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 6 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best True lr [0.1]
training epoch 7 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 8 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 9 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 10 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.961000)
finished training. finished 50 epochs. accuracy 0.961 topk_dict {'top1': 0.961}
start iteration 22
[activation diff]: block to remove picked: 19, with score 0.056570. All blocks and scores: [(19, 0.05657029943540692), (15, 0.05711182905361056), (21, 0.06303302943706512), (7, 0.06478257663547993), (20, 0.06583038344979286), (22, 0.06696373876184225), (38, 0.06731032580137253), (51, 0.06933277752250433), (39, 0.06984776258468628), (37, 0.07072791550308466), (47, 0.07122519239783287), (52, 0.07412336766719818), (24, 0.07548065017908812), (4, 0.07857684418559074), (6, 0.087480952963233), (11, 0.09325626119971275), (9, 0.09797513205558062), (2, 0.10269976314157248), (3, 0.10380179900676012), (1, 0.10385931935161352), (17, 0.10600358992815018), (14, 0.10907638911157846), (0, 0.11108732596039772), (13, 0.11674177646636963), (8, 0.1195466723293066), (10, 0.15148498117923737), (16, 0.152995266020298), (12, 0.153950747102499), (5, 0.1876443289220333), (36, 0.5387773364782333), (18, 0.665039174258709), (53, 1.0376775115728378)]
computing accuracy for after removing block 19 . block score: 0.05657029943540692
removed block 19 current accuracy 0.951 loss from initial  0.049000000000000044
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.057112. All blocks and scores: [(15, 0.05711182812228799), (20, 0.061532019171863794), (21, 0.06196006666868925), (22, 0.06384639348834753), (7, 0.06478257477283478), (38, 0.06738464068621397), (47, 0.06986536737531424), (39, 0.06988049950450659), (51, 0.07027493137866259), (52, 0.07167392689734697), (24, 0.07217527739703655), (37, 0.07463501580059528), (4, 0.07857684511691332), (6, 0.08748095203191042), (11, 0.09325626119971275), (9, 0.09797513484954834), (2, 0.10269976500421762), (3, 0.1038017999380827), (1, 0.10385932307690382), (17, 0.10600359085947275), (14, 0.10907639004290104), (0, 0.11108732875436544), (13, 0.11674177553504705), (8, 0.1195466686040163), (10, 0.15148497931659222), (16, 0.15299526043236256), (12, 0.15395074151456356), (5, 0.1876443400979042), (36, 0.5295998528599739), (18, 0.6650391668081284), (53, 1.0114513486623764)]
computing accuracy for after removing block 15 . block score: 0.05711182812228799
removed block 15 current accuracy 0.9462 loss from initial  0.05379999999999996
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.058122. All blocks and scores: [(20, 0.05812200391665101), (21, 0.05889349617063999), (22, 0.06056131236255169), (7, 0.06478257663547993), (38, 0.06631026417016983), (24, 0.06877557095140219), (39, 0.06908054649829865), (51, 0.0698470026254654), (52, 0.06996992696076632), (47, 0.07039167452603579), (37, 0.07164149452000856), (4, 0.07857684325426817), (6, 0.087480952963233), (11, 0.09325626119971275), (9, 0.09797513298690319), (2, 0.10269976407289505), (3, 0.10380179900676012), (1, 0.1038593165576458), (14, 0.10907638818025589), (17, 0.11013779044151306), (0, 0.1110873268917203), (13, 0.1167417736724019), (8, 0.1195466686040163), (10, 0.15148498117923737), (12, 0.15395074896514416), (16, 0.17074470035731792), (5, 0.1876443400979042), (36, 0.5109249129891396), (18, 0.6492681577801704), (53, 1.0277043133974075)]
computing accuracy for after removing block 20 . block score: 0.05812200391665101
removed block 20 current accuracy 0.9276 loss from initial  0.07240000000000002
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.061291. All blocks and scores: [(22, 0.0612908098846674), (21, 0.062126144766807556), (7, 0.0647825738415122), (52, 0.06678244844079018), (38, 0.06740308832377195), (51, 0.06909638457000256), (39, 0.06929385848343372), (47, 0.06929935608059168), (24, 0.07015594467520714), (4, 0.0785768423229456), (37, 0.07899184897542), (6, 0.087480952963233), (11, 0.09325626119971275), (9, 0.09797513484954834), (2, 0.10269976314157248), (3, 0.1038017999380827), (1, 0.10385932121425867), (14, 0.10907638911157846), (17, 0.11013778764754534), (0, 0.11108732316643), (13, 0.11674177553504705), (8, 0.11954667139798403), (10, 0.15148497745394707), (12, 0.15395075269043446), (16, 0.17074469476938248), (5, 0.1876443438231945), (36, 0.520880438387394), (18, 0.6492681801319122), (53, 1.013768658041954)]
computing accuracy for after removing block 22 . block score: 0.0612908098846674
removed block 22 current accuracy 0.912 loss from initial  0.08799999999999997
since last training loss: 0.04899999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.062027. All blocks and scores: [(52, 0.06202711910009384), (21, 0.06212614104151726), (7, 0.0647825738415122), (51, 0.06493549514561892), (47, 0.0654080854728818), (24, 0.06679274886846542), (39, 0.06809799838811159), (38, 0.06892135366797447), (4, 0.0785768423229456), (37, 0.08418622706085443), (6, 0.08748095016926527), (11, 0.09325625840574503), (9, 0.09797513578087091), (2, 0.10269976500421762), (3, 0.10380180180072784), (1, 0.1038593202829361), (14, 0.10907638911157846), (17, 0.11013778951019049), (0, 0.11108732596039772), (13, 0.11674177646636963), (8, 0.11954667046666145), (10, 0.15148498117923737), (12, 0.15395075269043446), (16, 0.17074469663202763), (5, 0.18764434568583965), (36, 0.5279103219509125), (18, 0.649268165230751), (53, 0.9987654238939285)]
computing accuracy for after removing block 52 . block score: 0.06202711910009384
removed block 52 current accuracy 0.865 loss from initial  0.135
since last training loss: 0.09599999999999997 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 21, with score 0.062126. All blocks and scores: [(21, 0.06212614290416241), (7, 0.0647825738415122), (51, 0.06493549700826406), (47, 0.06540808640420437), (24, 0.06679274886846542), (39, 0.06809799838811159), (38, 0.06892135459929705), (4, 0.07857684325426817), (37, 0.08418622612953186), (6, 0.087480952963233), (11, 0.09325626119971275), (9, 0.09797513298690319), (2, 0.10269976500421762), (3, 0.10380179807543755), (1, 0.10385932307690382), (14, 0.10907639097422361), (17, 0.11013779044151306), (0, 0.11108732596039772), (13, 0.11674177646636963), (8, 0.1195466723293066), (10, 0.15148498117923737), (12, 0.15395074896514416), (16, 0.17074469663202763), (5, 0.18764433823525906), (36, 0.5279103219509125), (18, 0.6492681801319122), (53, 1.0659673660993576)]
computing accuracy for after removing block 21 . block score: 0.06212614290416241
removed block 21 current accuracy 0.8326 loss from initial  0.1674
since last training loss: 0.12839999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 24, with score 0.060996. All blocks and scores: [(24, 0.06099611334502697), (51, 0.06229387270286679), (47, 0.06293827528133988), (7, 0.06478257570415735), (39, 0.0668321019038558), (38, 0.06700578611344099), (4, 0.0785768423229456), (37, 0.08087288402020931), (6, 0.08748095110058784), (11, 0.09325626119971275), (9, 0.09797513484954834), (2, 0.10269976407289505), (3, 0.1038017999380827), (1, 0.10385932307690382), (14, 0.10907639004290104), (17, 0.11013778764754534), (0, 0.1110873306170106), (13, 0.1167417736724019), (8, 0.1195466686040163), (10, 0.15148498117923737), (12, 0.1539507508277893), (16, 0.17074469849467278), (5, 0.18764433450996876), (36, 0.5005221031606197), (18, 0.649268165230751), (53, 0.9963240399956703)]
computing accuracy for after removing block 24 . block score: 0.06099611334502697
removed block 24 current accuracy 0.8048 loss from initial  0.19520000000000004
since last training loss: 0.1562 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.058612. All blocks and scores: [(51, 0.05861237086355686), (47, 0.05882648378610611), (7, 0.06478257291018963), (39, 0.06598248891532421), (38, 0.06704909261316061), (4, 0.07857684418559074), (37, 0.08518016990274191), (6, 0.08748095110058784), (11, 0.09325625840574503), (9, 0.09797513484954834), (2, 0.10269976407289505), (3, 0.10380180086940527), (1, 0.10385932307690382), (14, 0.10907639004290104), (17, 0.11013778764754534), (0, 0.11108732502907515), (13, 0.1167417773976922), (8, 0.1195466686040163), (10, 0.15148498117923737), (12, 0.153950747102499), (16, 0.17074469849467278), (5, 0.1876443363726139), (36, 0.5151864364743233), (18, 0.6492681875824928), (53, 0.9340757876634598)]
computing accuracy for after removing block 51 . block score: 0.05861237086355686
removed block 51 current accuracy 0.725 loss from initial  0.275
since last training loss: 0.236 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.058826. All blocks and scores: [(47, 0.0588264842517674), (7, 0.0647825738415122), (39, 0.06598249170929193), (38, 0.06704909261316061), (4, 0.07857684325426817), (37, 0.08518016897141933), (6, 0.087480952963233), (11, 0.09325626213103533), (9, 0.09797513298690319), (2, 0.10269976500421762), (3, 0.10380179714411497), (1, 0.10385932121425867), (14, 0.10907639190554619), (17, 0.11013779137283564), (0, 0.11108732502907515), (13, 0.11674177553504705), (8, 0.11954667046666145), (10, 0.15148498117923737), (12, 0.1539507508277893), (16, 0.17074469849467278), (5, 0.1876443363726139), (36, 0.5151864364743233), (18, 0.6492681503295898), (53, 1.0154834687709808)]
computing accuracy for after removing block 47 . block score: 0.0588264842517674
removed block 47 current accuracy 0.6638 loss from initial  0.33620000000000005
since last training loss: 0.2972 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.064783. All blocks and scores: [(7, 0.06478257570415735), (39, 0.06598249170929193), (38, 0.06704909354448318), (4, 0.07857684511691332), (37, 0.08518016990274191), (6, 0.08748095203191042), (11, 0.09325626119971275), (9, 0.09797513578087091), (2, 0.10269976314157248), (3, 0.10380179714411497), (1, 0.10385932214558125), (14, 0.10907638631761074), (17, 0.11013779137283564), (0, 0.11108732409775257), (13, 0.1167417811229825), (8, 0.1195466723293066), (10, 0.15148498117923737), (12, 0.153950747102499), (16, 0.17074469663202763), (5, 0.18764433823525906), (36, 0.5151864439249039), (18, 0.649268165230751), (53, 1.1576012074947357)]
computing accuracy for after removing block 7 . block score: 0.06478257570415735
removed block 7 current accuracy 0.6204 loss from initial  0.37960000000000005
since last training loss: 0.3406 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 39, with score 0.065150. All blocks and scores: [(39, 0.06514964811503887), (38, 0.06817543134093285), (4, 0.07857684325426817), (37, 0.0796681921929121), (6, 0.087480952963233), (11, 0.08866598922759295), (17, 0.096779715269804), (14, 0.10029162652790546), (13, 0.10120781790465117), (2, 0.10269976314157248), (9, 0.10289005190134048), (3, 0.10380180086940527), (1, 0.10385932307690382), (0, 0.11108732596039772), (8, 0.11850544344633818), (12, 0.14273439347743988), (10, 0.15665786527097225), (16, 0.15971827879548073), (5, 0.18764433450996876), (36, 0.5016390793025494), (18, 0.6324588060379028), (53, 1.0976087152957916)]
computing accuracy for after removing block 39 . block score: 0.06514964811503887
removed block 39 current accuracy 0.5328 loss from initial  0.46719999999999995
training start
training epoch 0 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best True lr [0.1]
training epoch 1 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best True lr [0.1]
training epoch 2 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best True lr [0.1]
training epoch 3 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 4 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.1]
training epoch 5 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 6 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 7 val accuracy 0.8164 topk_dict {'top1': 0.8164} is_best False lr [0.1]
training epoch 8 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.1]
training epoch 9 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 10 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.928800)
finished training. finished 50 epochs. accuracy 0.9288 topk_dict {'top1': 0.9288}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.089364. All blocks and scores: [(4, 0.08936394192278385), (37, 0.10814729891717434), (38, 0.11471796594560146), (9, 0.11860355641692877), (2, 0.12517948634922504), (6, 0.1259326646104455), (0, 0.12721126899123192), (3, 0.1288025975227356), (1, 0.13881839625537395), (11, 0.1428056675940752), (8, 0.15690171718597412), (13, 0.15941110625863075), (14, 0.16940153390169144), (17, 0.18592798709869385), (10, 0.19731740280985832), (12, 0.21654848009347916), (16, 0.23703313618898392), (5, 0.24833179637789726), (36, 0.4632834792137146), (18, 0.5957819893956184), (53, 1.2896966636180878)]
computing accuracy for after removing block 4 . block score: 0.08936394192278385
removed block 4 current accuracy 0.9212 loss from initial  0.07879999999999998
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.108263. All blocks and scores: [(37, 0.10826339107006788), (38, 0.11432323791086674), (9, 0.1225050138309598), (2, 0.12517948541790247), (0, 0.12721126899123192), (3, 0.12880260311067104), (11, 0.13439312390983105), (1, 0.13881839253008366), (6, 0.15239114500582218), (8, 0.15633325278759003), (13, 0.15751743502914906), (14, 0.16815718822181225), (17, 0.18001060746610165), (10, 0.19002188928425312), (12, 0.21477535739541054), (16, 0.21496380865573883), (5, 0.26382580399513245), (36, 0.45814837515354156), (18, 0.5887086167931557), (53, 1.2582292705774307)]
computing accuracy for after removing block 37 . block score: 0.10826339107006788
removed block 37 current accuracy 0.8806 loss from initial  0.11939999999999995
since last training loss: 0.04819999999999991 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 9, with score 0.122505. All blocks and scores: [(9, 0.12250501941889524), (2, 0.12517948541790247), (0, 0.12721127085387707), (3, 0.1288025975227356), (11, 0.13439312018454075), (1, 0.13881839625537395), (6, 0.15239114314317703), (8, 0.15633324906229973), (13, 0.1575174331665039), (38, 0.1638019774109125), (14, 0.1681571900844574), (17, 0.1800106056034565), (10, 0.19002188555896282), (12, 0.21477536298334599), (16, 0.21496380865573883), (5, 0.26382581144571304), (36, 0.45814839005470276), (18, 0.5887086167931557), (53, 1.2323386371135712)]
computing accuracy for after removing block 9 . block score: 0.12250501941889524
removed block 9 current accuracy 0.8688 loss from initial  0.13119999999999998
since last training loss: 0.05999999999999994 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 2, with score 0.125179. All blocks and scores: [(2, 0.12517948541790247), (11, 0.12584049254655838), (0, 0.1272112661972642), (3, 0.1288025975227356), (1, 0.13881839625537395), (38, 0.1486410703510046), (6, 0.15239114873111248), (13, 0.15258602052927017), (14, 0.15368390083312988), (8, 0.15633324719965458), (17, 0.1584414839744568), (16, 0.1793190184980631), (10, 0.17935207672417164), (12, 0.1814496796578169), (5, 0.26382581517100334), (36, 0.421813540160656), (18, 0.5594528391957283), (53, 1.1124670803546906)]
computing accuracy for after removing block 2 . block score: 0.12517948541790247
removed block 2 current accuracy 0.8346 loss from initial  0.1654
since last training loss: 0.09419999999999995 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.118186. All blocks and scores: [(11, 0.1181860389187932), (3, 0.12302618566900492), (0, 0.12721126526594162), (38, 0.13397514447569847), (1, 0.1388183906674385), (14, 0.13941004127264023), (13, 0.13994456082582474), (17, 0.14065317809581757), (8, 0.14570323005318642), (6, 0.15552682243287563), (16, 0.15867295488715172), (12, 0.16535267792642117), (10, 0.17709065042436123), (5, 0.2741796411573887), (36, 0.3850633092224598), (18, 0.5067699328064919), (53, 0.9997761249542236)]
computing accuracy for after removing block 11 . block score: 0.1181860389187932
removed block 11 current accuracy 0.8104 loss from initial  0.1896
since last training loss: 0.11839999999999995 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 3, with score 0.123026. All blocks and scores: [(3, 0.12302618753165007), (14, 0.12646546121686697), (0, 0.12721126340329647), (13, 0.13039049319922924), (38, 0.1353861652314663), (17, 0.1387129556387663), (1, 0.13881838880479336), (8, 0.14570323191583157), (16, 0.146596884354949), (12, 0.1537403929978609), (6, 0.15552682615816593), (10, 0.17709065414965153), (5, 0.2741796374320984), (36, 0.38537732511758804), (18, 0.5128324031829834), (53, 0.97662653028965)]
computing accuracy for after removing block 3 . block score: 0.12302618753165007
removed block 3 current accuracy 0.742 loss from initial  0.258
since last training loss: 0.18679999999999997 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 14, with score 0.119473. All blocks and scores: [(14, 0.119472561404109), (38, 0.12496256548911333), (16, 0.12546884268522263), (0, 0.12721126899123192), (13, 0.12752545066177845), (17, 0.13233708404004574), (1, 0.1388183981180191), (8, 0.13980497606098652), (12, 0.15143661387264729), (6, 0.16061526723206043), (10, 0.1812779325991869), (5, 0.29829559102654457), (36, 0.35651857033371925), (18, 0.47103868424892426), (53, 0.8518135771155357)]
computing accuracy for after removing block 14 . block score: 0.119472561404109
removed block 14 current accuracy 0.6594 loss from initial  0.3406
since last training loss: 0.2694 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.126084. All blocks and scores: [(17, 0.12608398869633675), (38, 0.1262836456298828), (0, 0.12721126805990934), (13, 0.12752544321119785), (1, 0.1388183943927288), (8, 0.13980497792363167), (16, 0.14744297228753567), (12, 0.15143661759793758), (6, 0.16061526536941528), (10, 0.18127792701125145), (5, 0.2982955873012543), (36, 0.35592566803097725), (18, 0.4733002558350563), (53, 0.852542445063591)]
computing accuracy for after removing block 17 . block score: 0.12608398869633675
removed block 17 current accuracy 0.5562 loss from initial  0.4438
since last training loss: 0.37259999999999993 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 38, with score 0.116437. All blocks and scores: [(38, 0.1164372842758894), (0, 0.12721126526594162), (13, 0.12752544321119785), (1, 0.1388183943927288), (8, 0.13980497792363167), (16, 0.14744297042489052), (12, 0.15143662132322788), (6, 0.16061526909470558), (10, 0.1812779288738966), (5, 0.29829559102654457), (36, 0.3238227479159832), (18, 0.44605927914381027), (53, 0.7458532750606537)]
computing accuracy for after removing block 38 . block score: 0.1164372842758894
removed block 38 current accuracy 0.3114 loss from initial  0.6886
since last training loss: 0.6174 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 0, with score 0.127211. All blocks and scores: [(0, 0.12721126712858677), (13, 0.12752544321119785), (1, 0.1388183906674385), (8, 0.13980497419834137), (16, 0.14744297042489052), (12, 0.15143661573529243), (6, 0.16061526350677013), (10, 0.1812779325991869), (5, 0.298295583575964), (36, 0.3238227516412735), (18, 0.44605928659439087), (53, 1.2789736092090607)]
computing accuracy for after removing block 0 . block score: 0.12721126712858677
removed block 0 current accuracy 0.2734 loss from initial  0.7266
since last training loss: 0.6554 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 13, with score 0.126719. All blocks and scores: [(13, 0.12671903241425753), (16, 0.1356393452733755), (8, 0.13785768300294876), (1, 0.14705943129956722), (10, 0.17277387343347073), (6, 0.1767237652093172), (12, 0.18092340975999832), (5, 0.2965538911521435), (36, 0.3137827701866627), (18, 0.4489035867154598), (53, 1.1338187456130981)]
computing accuracy for after removing block 13 . block score: 0.12671903241425753
removed block 13 current accuracy 0.1752 loss from initial  0.8248
since last training loss: 0.7535999999999999 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 16, with score 0.137710. All blocks and scores: [(16, 0.13771047070622444), (8, 0.1378576811403036), (1, 0.14705943129956722), (10, 0.17277387529611588), (6, 0.17672376707196236), (12, 0.18092341348528862), (5, 0.2965539023280144), (36, 0.3323782980442047), (18, 0.4673658236861229), (53, 1.3511861264705658)]
computing accuracy for after removing block 16 . block score: 0.13771047070622444
removed block 16 current accuracy 0.134 loss from initial  0.866
training start
training epoch 0 val accuracy 0.808 topk_dict {'top1': 0.808} is_best True lr [0.1]
training epoch 1 val accuracy 0.7664 topk_dict {'top1': 0.7664} is_best False lr [0.1]
training epoch 2 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best True lr [0.1]
training epoch 3 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best False lr [0.1]
training epoch 4 val accuracy 0.839 topk_dict {'top1': 0.839} is_best True lr [0.1]
training epoch 5 val accuracy 0.7674 topk_dict {'top1': 0.7674} is_best False lr [0.1]
training epoch 6 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best True lr [0.1]
training epoch 7 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best True lr [0.1]
training epoch 8 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 9 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best False lr [0.1]
training epoch 10 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
loading model_best from epoch 13 (acc 0.906800)
finished training. finished 50 epochs. accuracy 0.9068 topk_dict {'top1': 0.9068}
