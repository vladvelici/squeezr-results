start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050514012575), (30, 0.010039400891400874), (31, 0.01036160031799227), (34, 0.01331227587070316), (29, 0.013541154563426971), (35, 0.01601846283301711), (26, 0.01603759010322392), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020232456270605326), (46, 0.021044540451839566), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.022826647851616144), (44, 0.023395078955218196), (40, 0.024025025311857462), (45, 0.02429541083984077), (21, 0.024924598168581724), (22, 0.025168768130242825), (48, 0.02534125908277929), (24, 0.025899536907672882), (50, 0.02640997269190848), (42, 0.02667409973219037), (20, 0.026859006844460964), (49, 0.02703716466203332), (47, 0.029306468786671758), (39, 0.03157071419991553), (38, 0.031637870240956545), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859722599387), (37, 0.03796026110649109), (51, 0.04173417342826724), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.054548466112464666), (3, 0.057224275544285774), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095684738829732), (0, 0.06300980877131224), (1, 0.06676734145730734), (52, 0.0686293737962842), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4375799931585789), (18, 0.5108212828636169), (53, 0.8211488798260689)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050397597253), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013133947155438364), (29, 0.013541153981350362), (26, 0.016037591500207782), (35, 0.016169289825484157), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020072477171197534), (46, 0.020731385564431548), (25, 0.021972602931782603), (41, 0.022347092861309648), (23, 0.022379535483196378), (44, 0.0232356870546937), (40, 0.0238410672172904), (45, 0.023965542437508702), (48, 0.024917916394770145), (21, 0.024924598168581724), (22, 0.025168768363073468), (50, 0.02584081282839179), (24, 0.025899537140503526), (42, 0.026315324008464813), (49, 0.02665567467920482), (20, 0.026859007077291608), (47, 0.028728798497468233), (39, 0.03131764242425561), (38, 0.03138036350719631), (15, 0.03192339278757572), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.03802584484219551), (51, 0.04122393950819969), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.054548466578125954), (3, 0.05722427507862449), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734238862991), (52, 0.06745155062526464), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.1066738748922944), (36, 0.43538709729909897), (18, 0.5108213126659393), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050397597253
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400774985552), (31, 0.01036159973591566), (34, 0.012765232473611832), (29, 0.013541154679842293), (35, 0.015992751345038414), (26, 0.01603759080171585), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020075131207704544), (46, 0.020841406425461173), (25, 0.02197260269895196), (41, 0.022319766925647855), (23, 0.022379535483196378), (44, 0.02315405011177063), (40, 0.02388568385504186), (45, 0.0240716899279505), (48, 0.024877465097233653), (21, 0.024924597702920437), (22, 0.025168768130242825), (50, 0.02569117909297347), (24, 0.025899536442011595), (42, 0.026123747695237398), (49, 0.02647942234762013), (20, 0.026859006844460964), (47, 0.02869313210248947), (38, 0.031236795708537102), (39, 0.0312952920794487), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.03837669175118208), (51, 0.041114033199846745), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.04783663246780634), (2, 0.05454846750944853), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980830565095), (1, 0.06676734145730734), (52, 0.06700456328690052), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.43639999255537987), (18, 0.5108212903141975), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400774985552
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372017733753), (34, 0.012387837283313274), (29, 0.01354115444701165), (35, 0.016008096048608422), (26, 0.016037590568885207), (28, 0.01772867562249303), (27, 0.019127048086374998), (43, 0.020083633484318852), (46, 0.020704444032162428), (25, 0.02197260269895196), (41, 0.02225319715216756), (23, 0.02237953571602702), (44, 0.023267761571332812), (40, 0.024013879243284464), (45, 0.02409299253486097), (48, 0.02466528001241386), (21, 0.02492459723725915), (22, 0.02516876789741218), (50, 0.02545973495580256), (42, 0.02565571293234825), (24, 0.025899536907672882), (49, 0.026287756161764264), (20, 0.02685900661163032), (47, 0.02836342342197895), (38, 0.031047646887600422), (39, 0.03138077259063721), (15, 0.03192339278757572), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892289988696575), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.0630098101682961), (52, 0.06586316227912903), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484647214413), (16, 0.08408282604068518), (12, 0.090420494787395), (5, 0.10667387582361698), (36, 0.4389924556016922), (18, 0.5108213052153587), (53, 0.8391561359167099)]
computing accuracy for after removing block 31 . block score: 0.010375372017733753
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154679842293), (26, 0.016037590568885207), (35, 0.016057363245636225), (28, 0.017728674924001098), (27, 0.019127048086374998), (43, 0.02004934987053275), (46, 0.0205529872328043), (25, 0.021972602233290672), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132132604718), (40, 0.023858347674831748), (45, 0.024124701973050833), (48, 0.02438612305559218), (21, 0.024924598168581724), (50, 0.025042240973562002), (22, 0.025168767664581537), (42, 0.025414508301764727), (49, 0.025842698756605387), (24, 0.02589953667484224), (20, 0.02685900661163032), (47, 0.028050735592842102), (38, 0.03104005940258503), (39, 0.03150080284103751), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.032628596760332584), (37, 0.03911284916102886), (51, 0.04024627432227135), (9, 0.04340187832713127), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.0630098101682961), (52, 0.06486208690330386), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484647214413), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4381278418004513), (18, 0.5108212977647781), (53, 0.845842756330967)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.01603759080171585), (35, 0.01665342040359974), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020503456937149167), (46, 0.020725322188809514), (25, 0.02197260200046003), (23, 0.022379535948857665), (41, 0.0224526294041425), (44, 0.0233644749969244), (48, 0.024290354922413826), (45, 0.02443871251307428), (40, 0.024470558390021324), (21, 0.024924598401412368), (50, 0.025042172521352768), (22, 0.025168768130242825), (49, 0.02587597002275288), (24, 0.025899535976350307), (42, 0.026205406757071614), (20, 0.026859007542952895), (47, 0.028178582433611155), (15, 0.03192339139059186), (38, 0.03208350157365203), (7, 0.03228544630110264), (39, 0.03233744157478213), (19, 0.03262859536334872), (51, 0.039947257842868567), (37, 0.04073968157172203), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980970263481), (52, 0.06433630269020796), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.45053431019186974), (18, 0.5108213126659393), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037591500207782), (35, 0.0164706080686301), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.020046867430210114), (46, 0.020376994041725993), (41, 0.021723243175074458), (25, 0.021972602931782603), (23, 0.022379535483196378), (44, 0.023028337862342596), (48, 0.023771876469254494), (40, 0.02393081272020936), (45, 0.024178663035854697), (50, 0.024390298640355468), (21, 0.02492459863424301), (22, 0.025168768595904112), (42, 0.025188251165673137), (49, 0.025361529551446438), (24, 0.02589953737333417), (20, 0.026859007542952895), (47, 0.027363279601559043), (38, 0.03136561927385628), (15, 0.03192339185625315), (39, 0.03212768537923694), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03893592348322272), (37, 0.040206346195191145), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.05892289988696575), (11, 0.05924912728369236), (17, 0.06095684785395861), (52, 0.06232854910194874), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4444202035665512), (18, 0.5108212977647781), (53, 0.8537912145256996)]
computing accuracy for after removing block 26 . block score: 0.016037591500207782
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366262227297), (28, 0.01708850055001676), (27, 0.01888244692236185), (43, 0.01959516480565071), (46, 0.020073580788448453), (41, 0.020961584988981485), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.02281495602801442), (48, 0.023128160275518894), (40, 0.023345195688307285), (50, 0.023756146896630526), (42, 0.02384730218909681), (45, 0.02387388050556183), (21, 0.024924598168581724), (49, 0.024960316251963377), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.026855542790144682), (20, 0.026859006145969033), (38, 0.03042401373386383), (39, 0.031514044385403395), (15, 0.03192339139059186), (7, 0.03228544816374779), (19, 0.032628594897687435), (51, 0.037824880331754684), (37, 0.03936835331842303), (9, 0.04340187832713127), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290035262704), (11, 0.05924912774935365), (52, 0.06033282168209553), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4360685534775257), (18, 0.5108212903141975), (53, 0.8749377503991127)]
computing accuracy for after removing block 35 . block score: 0.015597366262227297
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 2 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 3 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 4 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 5 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 7 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 8 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 9 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.1]
training epoch 10 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500084355474), (43, 0.01855594594962895), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.019424295518547297), (48, 0.021467272425070405), (25, 0.02197260200046003), (44, 0.02202691650018096), (40, 0.02217966062016785), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.022379535483196378), (45, 0.02293148124590516), (49, 0.02370851207524538), (21, 0.02492459653876722), (22, 0.025168768130242825), (47, 0.025829139165580273), (24, 0.025899537838995457), (20, 0.026859007542952895), (38, 0.028956545749679208), (39, 0.029667828232049942), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.036009025759994984), (37, 0.036512387450784445), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.04783663433045149), (2, 0.05454846564680338), (52, 0.05610728822648525), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.41757646575570107), (18, 0.5108213126659393), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.017088500084355474
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102009117603), (41, 0.01884901849552989), (27, 0.018882447388023138), (48, 0.02090373425744474), (42, 0.021432004403322935), (40, 0.0218324214220047), (44, 0.021840531146153808), (50, 0.021869863383471966), (25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.022492847638204694), (49, 0.023123498307541013), (21, 0.024924598168581724), (47, 0.02506713871844113), (22, 0.025168768363073468), (24, 0.025899537140503526), (20, 0.02685900731012225), (38, 0.028114069253206253), (39, 0.029206909239292145), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.03545433655381203), (37, 0.035977639723569155), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548464715480804), (52, 0.054696458391845226), (3, 0.05722427600994706), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882446689531207), (46, 0.019302030326798558), (42, 0.021432003937661648), (48, 0.021544844144955277), (40, 0.021832420956343412), (50, 0.021946269553154707), (25, 0.021972602466121316), (23, 0.022379535250365734), (49, 0.023006869247183204), (44, 0.023108510533347726), (45, 0.023535606684163213), (21, 0.024924598168581724), (22, 0.025168768595904112), (47, 0.025820446433499455), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.028114068787544966), (39, 0.0292069090064615), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03509148908779025), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493682242929935), (14, 0.0478366338647902), (52, 0.05332902865484357), (2, 0.05454846750944853), (3, 0.0572242783382535), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049013078213), (5, 0.10667387023568153), (36, 0.4135979115962982), (18, 0.5108213275671005), (53, 0.9678284004330635)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.01907008863054216), (48, 0.020678168162703514), (50, 0.021344397915527225), (40, 0.021832421189174056), (25, 0.021972602466121316), (42, 0.02198694017715752), (23, 0.022379535483196378), (49, 0.022534748539328575), (45, 0.023929917253553867), (44, 0.024054003646597266), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.02589953737333417), (47, 0.02604393707588315), (20, 0.026859007542952895), (38, 0.028114069253206253), (39, 0.029206908540800214), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03379448037594557), (37, 0.035977639723569155), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.05047609517350793), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4135979041457176), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707972854376), (50, 0.020775061566382647), (40, 0.021085953572764993), (42, 0.021369647001847625), (49, 0.02191002992913127), (25, 0.021972603164613247), (23, 0.02237953571602702), (44, 0.023239312460646033), (45, 0.02358530880883336), (21, 0.02492459793575108), (47, 0.025076948339119554), (22, 0.02516876789741218), (24, 0.02589953667484224), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.028580759651958942), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.0328142608050257), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.04783663526177406), (52, 0.04852363234385848), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095685064792633), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234139561653), (18, 0.5108212977647781), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.02083116164430976), (40, 0.02108595333993435), (42, 0.021369646536186337), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.022536989068612456), (44, 0.02323931222781539), (45, 0.023585309041664004), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.026859008008614182), (38, 0.027183361118659377), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.032850812654942274), (37, 0.03542024455964565), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.0478366338647902), (52, 0.04812479857355356), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922904543578625), (11, 0.059249126352369785), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.0904204910621047), (5, 0.1066738748922944), (36, 0.406523410230875), (18, 0.5108212903141975), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953572764993), (42, 0.021369647700339556), (25, 0.021972602233290672), (23, 0.022379535483196378), (50, 0.02247006236575544), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.02492459863424301), (22, 0.0251687690615654), (49, 0.025234102737158537), (24, 0.02589953667484224), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183361118659377), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03296921215951443), (37, 0.03542024362832308), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.0478366338647902), (52, 0.05089045176282525), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085953572764993
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868073567748), (50, 0.02128476626239717), (25, 0.021972603164613247), (23, 0.02237953571602702), (45, 0.023098317440599203), (44, 0.024240857688710093), (49, 0.02450086921453476), (21, 0.024924598401412368), (22, 0.025168769294396043), (24, 0.02589953737333417), (47, 0.026519698789343238), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339092493057), (51, 0.03222085069864988), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.035420244093984365), (9, 0.04340188158676028), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.04885757155716419), (2, 0.05454846564680338), (3, 0.05722427926957607), (13, 0.05892290035262704), (11, 0.05924912681803107), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282604068518), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.02096868073567748
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.813 topk_dict {'top1': 0.813} is_best False lr [0.1]
training epoch 1 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 2 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 3 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 4 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 5 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 6 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 7 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 8 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 9 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 10 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.966600)
finished training. finished 50 epochs. accuracy 0.9666 topk_dict {'top1': 0.9666}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.041521. All blocks and scores: [(50, 0.04152121813967824), (49, 0.04212792031466961), (44, 0.047635622788220644), (21, 0.04876839788630605), (45, 0.049487711396068335), (22, 0.04984565498307347), (20, 0.051074575167149305), (23, 0.0533554065041244), (19, 0.053821809589862823), (24, 0.05410108622163534), (51, 0.05414553778246045), (47, 0.055273308884352446), (25, 0.05586447427049279), (38, 0.057633956894278526), (15, 0.05810387199744582), (7, 0.06093259761109948), (52, 0.06290635047480464), (39, 0.06564059108495712), (37, 0.07129037287086248), (4, 0.07877990137785673), (9, 0.07946893014013767), (6, 0.08662655670195818), (17, 0.09550672862678766), (14, 0.09606574382632971), (0, 0.10004096385091543), (11, 0.1005078935995698), (3, 0.1006995178759098), (2, 0.10284796077758074), (13, 0.1098955674096942), (1, 0.1205771341919899), (8, 0.12910858541727066), (10, 0.1414061337709427), (12, 0.15325778350234032), (16, 0.15403518453240395), (5, 0.19340872205793858), (36, 0.6576269790530205), (18, 0.7319333851337433), (53, 0.9912434592843056)]
computing accuracy for after removing block 50 . block score: 0.04152121813967824
removed block 50 current accuracy 0.956 loss from initial  0.04400000000000004
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.042128. All blocks and scores: [(49, 0.04212791891768575), (44, 0.04763562325388193), (21, 0.04876839928328991), (45, 0.04948771232739091), (22, 0.04984565591439605), (20, 0.05107457470148802), (23, 0.05335540743544698), (19, 0.05382181145250797), (24, 0.05410108622163534), (47, 0.05527330981567502), (25, 0.05586447473615408), (38, 0.05763395596295595), (15, 0.05810387013480067), (51, 0.058350078761577606), (7, 0.06093259993940592), (39, 0.06564059481024742), (52, 0.06970957387238741), (37, 0.07129037193953991), (4, 0.07877989858388901), (9, 0.0794689292088151), (6, 0.08662655390799046), (17, 0.09550673514604568), (14, 0.09606574103236198), (0, 0.100040964782238), (11, 0.1005078935995698), (3, 0.10069951880723238), (2, 0.10284796357154846), (13, 0.10989556089043617), (1, 0.12057713605463505), (8, 0.12910858541727066), (10, 0.141406137496233), (12, 0.15325778536498547), (16, 0.1540351863950491), (5, 0.19340872019529343), (36, 0.6576269939541817), (18, 0.7319333776831627), (53, 1.1295098811388016)]
computing accuracy for after removing block 49 . block score: 0.04212791891768575
removed block 49 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.047636. All blocks and scores: [(44, 0.047635620925575495), (21, 0.048768398351967335), (45, 0.04948771046474576), (22, 0.049845656380057335), (20, 0.05107457377016544), (23, 0.05335540743544698), (19, 0.05382181005552411), (24, 0.054101087618619204), (47, 0.055273308884352446), (25, 0.055864473804831505), (38, 0.057633957359939814), (15, 0.05810387106612325), (7, 0.060932598542422056), (51, 0.06191025488078594), (39, 0.06564059387892485), (37, 0.07129037287086248), (52, 0.07313751056790352), (4, 0.07877989951521158), (9, 0.07946893014013767), (6, 0.0866265557706356), (17, 0.09550673142075539), (14, 0.09606574196368456), (0, 0.10004096198827028), (11, 0.1005078935995698), (3, 0.10069952066987753), (2, 0.10284795984625816), (13, 0.10989556275308132), (1, 0.12057713512331247), (8, 0.12910858541727066), (10, 0.1414061337709427), (12, 0.15325778722763062), (16, 0.15403518080711365), (5, 0.19340872392058372), (36, 0.6576269939541817), (18, 0.7319333851337433), (53, 1.2201801091432571)]
computing accuracy for after removing block 44 . block score: 0.047635620925575495
removed block 44 current accuracy 0.928 loss from initial  0.07199999999999995
since last training loss: 0.03859999999999997 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.048768. All blocks and scores: [(21, 0.04876839788630605), (22, 0.04984565684571862), (20, 0.05107457423582673), (45, 0.05189051805064082), (23, 0.05335540836676955), (19, 0.0538218105211854), (24, 0.05410108622163534), (25, 0.05586447659879923), (38, 0.057633958756923676), (47, 0.057792363688349724), (15, 0.05810387060046196), (51, 0.059190526604652405), (7, 0.06093259807676077), (39, 0.0656405920162797), (37, 0.07129037380218506), (52, 0.07172375917434692), (4, 0.07877989951521158), (9, 0.07946892827749252), (6, 0.08662655390799046), (17, 0.09550673328340054), (14, 0.09606574010103941), (0, 0.10004096291959286), (11, 0.1005078935995698), (3, 0.10069951601326466), (2, 0.10284796077758074), (13, 0.10989556647837162), (1, 0.1205771379172802), (8, 0.12910858541727066), (10, 0.1414061337709427), (12, 0.15325778350234032), (16, 0.15403518080711365), (5, 0.19340872764587402), (36, 0.6576269865036011), (18, 0.7319333851337433), (53, 1.280166506767273)]
computing accuracy for after removing block 21 . block score: 0.04876839788630605
removed block 21 current accuracy 0.9226 loss from initial  0.07740000000000002
since last training loss: 0.04400000000000004 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.045764. All blocks and scores: [(22, 0.04576354939490557), (24, 0.04746959125623107), (23, 0.048046767711639404), (45, 0.050382889341562986), (20, 0.05107457563281059), (25, 0.051417659036815166), (19, 0.05382181145250797), (38, 0.05400906503200531), (47, 0.054278030060231686), (51, 0.05651389854028821), (15, 0.05810387060046196), (7, 0.06093259621411562), (39, 0.06379216443747282), (52, 0.0665700500831008), (37, 0.06941689737141132), (4, 0.07877990044653416), (9, 0.0794689292088151), (6, 0.08662655111402273), (17, 0.09550673328340054), (14, 0.09606573823839426), (0, 0.10004096105694771), (11, 0.1005078898742795), (3, 0.10069951880723238), (2, 0.10284796170890331), (13, 0.1098955636844039), (1, 0.12057713326066732), (8, 0.1291085910052061), (10, 0.141406137496233), (12, 0.15325778350234032), (16, 0.1540351826697588), (5, 0.19340872392058372), (36, 0.621411420404911), (18, 0.7319333627820015), (53, 1.2818098217248917)]
computing accuracy for after removing block 22 . block score: 0.04576354939490557
removed block 22 current accuracy 0.9116 loss from initial  0.08840000000000003
since last training loss: 0.05500000000000005 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.044689. All blocks and scores: [(24, 0.04468911187723279), (23, 0.04505914682522416), (45, 0.048691308591514826), (25, 0.04987456416711211), (47, 0.0507487365975976), (20, 0.051074575167149305), (38, 0.05327399028465152), (19, 0.05382181005552411), (51, 0.05441991565749049), (15, 0.05810387060046196), (7, 0.060932600405067205), (39, 0.06290934840217233), (52, 0.06355868885293603), (37, 0.07320911344140768), (4, 0.07877989951521158), (9, 0.0794689292088151), (6, 0.08662655390799046), (17, 0.09550673142075539), (14, 0.09606574103236198), (0, 0.10004096291959286), (11, 0.1005078898742795), (3, 0.10069952066987753), (2, 0.10284795984625816), (13, 0.10989555902779102), (1, 0.12057713326066732), (8, 0.12910858914256096), (10, 0.1414061337709427), (12, 0.15325778163969517), (16, 0.1540351826697588), (5, 0.19340872019529343), (36, 0.6174122467637062), (18, 0.7319333776831627), (53, 1.2588113248348236)]
computing accuracy for after removing block 24 . block score: 0.04468911187723279
removed block 24 current accuracy 0.8984 loss from initial  0.10160000000000002
since last training loss: 0.06820000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.044901. All blocks and scores: [(45, 0.04490062687546015), (23, 0.04505914682522416), (47, 0.046633530408144), (25, 0.050146440509706736), (51, 0.05027461750432849), (38, 0.05028752749785781), (20, 0.05107457470148802), (19, 0.0538218105211854), (15, 0.05810387199744582), (52, 0.05845107277855277), (39, 0.05901286657899618), (7, 0.06093259807676077), (37, 0.06830736063420773), (4, 0.07877989765256643), (9, 0.07946892734616995), (6, 0.08662655018270016), (17, 0.09550673142075539), (14, 0.09606573916971684), (0, 0.10004096198827028), (11, 0.10050788801163435), (3, 0.10069951880723238), (2, 0.10284795891493559), (13, 0.10989556182175875), (1, 0.12057713605463505), (8, 0.12910858541727066), (10, 0.14140613563358784), (12, 0.15325778350234032), (16, 0.15403518453240395), (5, 0.19340871833264828), (36, 0.5920176729559898), (18, 0.7319333851337433), (53, 1.2289609611034393)]
computing accuracy for after removing block 45 . block score: 0.04490062687546015
removed block 45 current accuracy 0.8776 loss from initial  0.12239999999999995
since last training loss: 0.08899999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.045059. All blocks and scores: [(23, 0.04505914822220802), (51, 0.04964985465630889), (25, 0.050146439112722874), (38, 0.05028752703219652), (47, 0.05055875796824694), (20, 0.05107457563281059), (19, 0.053821810986846685), (15, 0.05810387060046196), (39, 0.05901286518201232), (52, 0.059110759757459164), (7, 0.06093259947374463), (37, 0.06830736063420773), (4, 0.07877989951521158), (9, 0.07946893014013767), (6, 0.0866265520453453), (17, 0.09550673142075539), (14, 0.09606574010103941), (0, 0.100040964782238), (11, 0.10050788894295692), (3, 0.10069951973855495), (2, 0.10284795984625816), (13, 0.10989556275308132), (1, 0.1205771341919899), (8, 0.12910858914256096), (10, 0.1414061337709427), (12, 0.15325778163969517), (16, 0.1540351826697588), (5, 0.19340872019529343), (36, 0.5920176804065704), (18, 0.7319333776831627), (53, 1.3168352395296097)]
computing accuracy for after removing block 23 . block score: 0.04505914822220802
removed block 23 current accuracy 0.8574 loss from initial  0.14259999999999995
training start
training epoch 0 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 1 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 2 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.1]
training epoch 3 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 4 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 5 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 6 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 7 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 8 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 9 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.952600)
finished training. finished 50 epochs. accuracy 0.9526 topk_dict {'top1': 0.9526}
start iteration 24
[activation diff]: block to remove picked: 51, with score 0.073800. All blocks and scores: [(51, 0.07380047254264355), (7, 0.07422847114503384), (15, 0.07450146228075027), (38, 0.0767976064234972), (19, 0.07719452772289515), (52, 0.08195575792342424), (37, 0.08272013161331415), (20, 0.08304463513195515), (47, 0.08368012961000204), (39, 0.08421040698885918), (4, 0.09209269098937511), (6, 0.0954345865175128), (9, 0.09574829414486885), (25, 0.09920695330947638), (2, 0.112002975307405), (1, 0.11528346128761768), (14, 0.11798928305506706), (0, 0.12051502708345652), (3, 0.1211025258526206), (17, 0.12158896028995514), (11, 0.12216249853372574), (13, 0.13616539351642132), (8, 0.15026462264358997), (10, 0.16480238549411297), (12, 0.17288196831941605), (16, 0.1794247403740883), (5, 0.22199778072535992), (36, 0.6103839874267578), (18, 0.6881439238786697), (53, 1.0855861753225327)]
computing accuracy for after removing block 51 . block score: 0.07380047254264355
removed block 51 current accuracy 0.918 loss from initial  0.08199999999999996
since last training loss: 0.034599999999999964 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.074228. All blocks and scores: [(7, 0.07422847021371126), (15, 0.0745014613494277), (38, 0.07679760456085205), (19, 0.07719452772289515), (37, 0.08272013254463673), (20, 0.08304463326931), (47, 0.08368013054132462), (39, 0.0842104060575366), (52, 0.09135210886597633), (4, 0.09209268819540739), (6, 0.09543458372354507), (9, 0.0957482922822237), (25, 0.09920695424079895), (2, 0.11200297251343727), (1, 0.11528345756232738), (14, 0.11798928212374449), (0, 0.12051502708345652), (3, 0.12110252305865288), (17, 0.12158895656466484), (11, 0.12216249387711287), (13, 0.13616538979113102), (8, 0.15026462450623512), (10, 0.16480238363146782), (12, 0.1728819627314806), (16, 0.1794247403740883), (5, 0.2219977881759405), (36, 0.6103839948773384), (18, 0.6881438866257668), (53, 1.299998164176941)]
computing accuracy for after removing block 7 . block score: 0.07422847021371126
removed block 7 current accuracy 0.9108 loss from initial  0.08919999999999995
since last training loss: 0.04179999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.073245. All blocks and scores: [(19, 0.07324479147791862), (15, 0.07370556145906448), (38, 0.07684503588825464), (37, 0.07739496231079102), (20, 0.07912119757384062), (47, 0.08153186179697514), (39, 0.0826291823759675), (52, 0.08871690835803747), (4, 0.09209269098937511), (9, 0.09478697925806046), (25, 0.09491744637489319), (6, 0.0954345865175128), (17, 0.10393494740128517), (14, 0.10917442757636309), (2, 0.112002975307405), (11, 0.11439726408571005), (13, 0.11508383508771658), (1, 0.11528346687555313), (0, 0.12051502801477909), (3, 0.12110252305865288), (8, 0.151892377063632), (12, 0.16007070243358612), (10, 0.16468485072255135), (16, 0.1672578863799572), (5, 0.22199777886271477), (36, 0.5898905321955681), (18, 0.6587714105844498), (53, 1.305777296423912)]
computing accuracy for after removing block 19 . block score: 0.07324479147791862
removed block 19 current accuracy 0.9056 loss from initial  0.09440000000000004
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.073706. All blocks and scores: [(15, 0.07370555959641933), (38, 0.07561459578573704), (20, 0.07562969531863928), (47, 0.0787939028814435), (39, 0.0842431653290987), (52, 0.08506382908672094), (25, 0.08558299764990807), (37, 0.08601366728544235), (4, 0.09209269098937511), (9, 0.09478697646409273), (6, 0.09543458558619022), (17, 0.1039349464699626), (14, 0.10917442291975021), (2, 0.1120029715821147), (11, 0.11439726408571005), (13, 0.11508383601903915), (1, 0.11528346315026283), (0, 0.12051502615213394), (3, 0.12110252305865288), (8, 0.1518923733383417), (12, 0.16007069498300552), (10, 0.1646848600357771), (16, 0.16725788451731205), (5, 0.2219977919012308), (36, 0.5903736501932144), (18, 0.6587714329361916), (53, 1.2830105423927307)]
computing accuracy for after removing block 15 . block score: 0.07370555959641933
removed block 15 current accuracy 0.888 loss from initial  0.11199999999999999
since last training loss: 0.06459999999999999 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 20, with score 0.068273. All blocks and scores: [(20, 0.06827319785952568), (38, 0.07401985768228769), (47, 0.07987044379115105), (25, 0.08058850560337305), (39, 0.08280402328819036), (52, 0.08543266914784908), (37, 0.08564373012632132), (4, 0.09209269285202026), (9, 0.0947869811207056), (6, 0.09543458465486765), (17, 0.10418978054076433), (14, 0.10917442757636309), (2, 0.11200297437608242), (11, 0.1143972622230649), (13, 0.115083834156394), (1, 0.11528345942497253), (0, 0.12051502615213394), (3, 0.12110252305865288), (8, 0.1518923733383417), (12, 0.16007069684565067), (10, 0.1646848637610674), (16, 0.18071867525577545), (5, 0.22199778445065022), (36, 0.5664949640631676), (18, 0.6309974789619446), (53, 1.2943861484527588)]
computing accuracy for after removing block 20 . block score: 0.06827319785952568
removed block 20 current accuracy 0.8674 loss from initial  0.13260000000000005
since last training loss: 0.08520000000000005 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.070433. All blocks and scores: [(38, 0.07043348718434572), (47, 0.07327963598072529), (52, 0.07687791995704174), (25, 0.07720602676272392), (39, 0.0802190974354744), (37, 0.08854183834046125), (4, 0.09209268912672997), (9, 0.09478697925806046), (6, 0.0954345865175128), (17, 0.10418978426605463), (14, 0.10917442664504051), (2, 0.1120029715821147), (11, 0.11439726408571005), (13, 0.11508383601903915), (1, 0.11528345849364996), (0, 0.12051502615213394), (3, 0.12110252678394318), (8, 0.151892377063632), (12, 0.16007070057094097), (10, 0.1646848600357771), (16, 0.18071866966784), (5, 0.22199778258800507), (36, 0.5601807460188866), (18, 0.630997471511364), (53, 1.2631798684597015)]
computing accuracy for after removing block 38 . block score: 0.07043348718434572
removed block 38 current accuracy 0.8422 loss from initial  0.15780000000000005
since last training loss: 0.11040000000000005 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.073646. All blocks and scores: [(47, 0.07364596519619226), (52, 0.07390517089515924), (25, 0.07720602583140135), (37, 0.0885418364778161), (4, 0.09209269192069769), (9, 0.0947869811207056), (39, 0.09533477574586868), (6, 0.09543458372354507), (17, 0.10418978054076433), (14, 0.10917442757636309), (2, 0.11200297437608242), (11, 0.1143972659483552), (13, 0.11508383136242628), (1, 0.11528346594423056), (0, 0.12051502335816622), (3, 0.12110252864658833), (8, 0.15189237892627716), (12, 0.16007070243358612), (10, 0.16468485817313194), (16, 0.1807186771184206), (5, 0.22199777886271477), (36, 0.5601807460188866), (18, 0.630997471511364), (53, 1.3179723024368286)]
computing accuracy for after removing block 47 . block score: 0.07364596519619226
removed block 47 current accuracy 0.766 loss from initial  0.23399999999999999
since last training loss: 0.1866 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 25, with score 0.077206. All blocks and scores: [(25, 0.0772060276940465), (52, 0.08535733446478844), (37, 0.08854183740913868), (4, 0.09209268726408482), (9, 0.09478697925806046), (39, 0.09533477574586868), (6, 0.09543458465486765), (17, 0.1041897814720869), (14, 0.10917442850768566), (2, 0.11200297344475985), (11, 0.1143972622230649), (13, 0.11508383601903915), (1, 0.11528346128761768), (0, 0.12051502894610167), (3, 0.12110252771526575), (8, 0.151892377063632), (12, 0.16007070243358612), (10, 0.16468485444784164), (16, 0.18071866966784), (5, 0.22199778258800507), (36, 0.560180738568306), (18, 0.6309974938631058), (53, 1.5412851423025131)]
computing accuracy for after removing block 25 . block score: 0.0772060276940465
removed block 25 current accuracy 0.7016 loss from initial  0.2984
since last training loss: 0.251 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 52, with score 0.081052. All blocks and scores: [(52, 0.08105176966637373), (4, 0.09209268819540739), (9, 0.09478698205202818), (6, 0.0954345865175128), (39, 0.10038801562041044), (17, 0.1041897814720869), (37, 0.10597217362374067), (14, 0.10917442291975021), (2, 0.11200297065079212), (11, 0.1143972622230649), (13, 0.11508383136242628), (1, 0.11528346128761768), (0, 0.12051502428948879), (3, 0.12110252678394318), (8, 0.1518923807889223), (12, 0.16007070615887642), (10, 0.16468485444784164), (16, 0.1807186771184206), (5, 0.22199778631329536), (36, 0.6239956915378571), (18, 0.6309974789619446), (53, 1.5710658580064774)]
computing accuracy for after removing block 52 . block score: 0.08105176966637373
removed block 52 current accuracy 0.6262 loss from initial  0.3738
training start
training epoch 0 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best True lr [0.1]
training epoch 1 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.1]
training epoch 2 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 4 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 5 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 7 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 8 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 9 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 10 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.931800)
finished training. finished 50 epochs. accuracy 0.9318 topk_dict {'top1': 0.9318}
