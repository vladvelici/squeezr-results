start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050630427897), (30, 0.01003940065857023), (31, 0.010361600434407592), (34, 0.013312276219949126), (29, 0.01354115444701165), (35, 0.01601846283301711), (26, 0.01603759080171585), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020232456736266613), (46, 0.02104453998617828), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.02282664831727743), (44, 0.023395078955218196), (40, 0.02402502461336553), (45, 0.024295410374179482), (21, 0.024924597702920437), (22, 0.025168768595904112), (48, 0.025341259315609932), (24, 0.025899536442011595), (50, 0.02640997152775526), (42, 0.026674099965021014), (20, 0.026859006145969033), (49, 0.027037164894863963), (47, 0.029306468786671758), (39, 0.031570713268592954), (38, 0.03163787070661783), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859443202615), (37, 0.03796026110649109), (51, 0.04173417296260595), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.047493685968220234), (14, 0.04783663293346763), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980783998966), (1, 0.06676734145730734), (52, 0.06862937659025192), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.43758000433444977), (18, 0.5108212977647781), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400891400874), (31, 0.010361600201576948), (34, 0.013133947271853685), (29, 0.013541154679842293), (26, 0.016037590568885207), (35, 0.016169289592653513), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020072476472705603), (46, 0.020731385797262192), (25, 0.02197260339744389), (41, 0.022347092628479004), (23, 0.02237953571602702), (44, 0.02323568775318563), (40, 0.0238410672172904), (45, 0.02396554220467806), (48, 0.024917915696278214), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.025840813294053078), (24, 0.025899536907672882), (42, 0.02631532261148095), (49, 0.02665567467920482), (20, 0.026859007077291608), (47, 0.028728798497468233), (39, 0.03131764242425561), (38, 0.031380363274365664), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.038025843910872936), (51, 0.04122393950819969), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427647560835), (13, 0.05892290221527219), (11, 0.059249130077660084), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06745155062526464), (8, 0.07467831950634718), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.43538710474967957), (18, 0.5108213126659393), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.012765232590027153), (29, 0.013541154214181006), (35, 0.015992751345038414), (26, 0.016037591034546494), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.02007513167336583), (46, 0.020841405959799886), (25, 0.02197260339744389), (41, 0.0223197671584785), (23, 0.022379535483196378), (44, 0.02315405011177063), (40, 0.02388568385504186), (45, 0.02407168922945857), (48, 0.024877465097233653), (21, 0.024924597702920437), (22, 0.025168768595904112), (50, 0.025691178161650896), (24, 0.0258995380718261), (42, 0.026123747928068042), (49, 0.026479422114789486), (20, 0.026859006844460964), (47, 0.02869313256815076), (38, 0.03123679501004517), (39, 0.03129529161378741), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.038376690819859505), (51, 0.04111403273418546), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (2, 0.05454846704378724), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.059249131474643946), (17, 0.06095684738829732), (0, 0.06300980783998966), (1, 0.06676734052598476), (52, 0.0670045642182231), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.43640001118183136), (18, 0.5108213126659393), (53, 0.828934907913208)]
computing accuracy for after removing block 30 . block score: 0.010039400425739586
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.012387837166897953), (29, 0.013541155029088259), (35, 0.01600809651426971), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.020083633484318852), (46, 0.02070444426499307), (25, 0.02197260200046003), (41, 0.02225319715216756), (23, 0.02237953501753509), (44, 0.023267761571332812), (40, 0.024013879243284464), (45, 0.024092993699014187), (48, 0.024665279779583216), (21, 0.024924597702920437), (22, 0.02516876789741218), (50, 0.025459734722971916), (42, 0.02565571293234825), (24, 0.025899536907672882), (49, 0.026287756394594908), (20, 0.026859008008614182), (47, 0.028363423887640238), (38, 0.031047646654769778), (39, 0.03138077282346785), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4389924593269825), (18, 0.5108213126659393), (53, 0.8391561731696129)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619897678494), (29, 0.013541154796257615), (26, 0.016037590336054564), (35, 0.016057363245636225), (28, 0.017728675855323672), (27, 0.01912704878486693), (43, 0.02004934917204082), (46, 0.020552987465634942), (25, 0.02197260269895196), (41, 0.02206748421303928), (23, 0.022379535250365734), (44, 0.02297913283109665), (40, 0.023858346976339817), (45, 0.024124702671542764), (48, 0.024386122822761536), (21, 0.024924597702920437), (50, 0.025042241672053933), (22, 0.0251687690615654), (42, 0.025414508068934083), (49, 0.02584269898943603), (24, 0.025899536907672882), (20, 0.026859006844460964), (47, 0.02805073489435017), (38, 0.031040059169754386), (39, 0.03150080284103751), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03911284962669015), (51, 0.04024627339094877), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980877131224), (52, 0.06486208876594901), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4381278343498707), (18, 0.5108212977647781), (53, 0.8458427935838699)]
computing accuracy for after removing block 34 . block score: 0.012489619897678494
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154214181006), (26, 0.016037591034546494), (35, 0.01665342040359974), (28, 0.017728675389662385), (27, 0.019127048086374998), (43, 0.020503456238657236), (46, 0.020725322421640158), (25, 0.02197260269895196), (23, 0.02237953571602702), (41, 0.02245262893848121), (44, 0.02336447429843247), (48, 0.024290355620905757), (45, 0.024438712978735566), (40, 0.02447055885568261), (21, 0.02492459863424301), (50, 0.025042172521352768), (22, 0.025168768828734756), (49, 0.025875970721244812), (24, 0.025899537606164813), (42, 0.02620540652424097), (20, 0.026859007542952895), (47, 0.028178582433611155), (15, 0.03192339092493057), (38, 0.032083500642329454), (7, 0.03228544723242521), (39, 0.03233744064345956), (19, 0.03262859536334872), (51, 0.039947257842868567), (37, 0.04073968203738332), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300980877131224), (52, 0.06433630315586925), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.45053430646657944), (18, 0.5108212828636169), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154214181006
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 1 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 2 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 3 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 4 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.1]
training epoch 5 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 7 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.1]
training epoch 8 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.1]
training epoch 9 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 10 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037589870393276), (35, 0.016470608301460743), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020046867430210114), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.02197260269895196), (23, 0.022379535483196378), (44, 0.023028336698189378), (48, 0.023771876469254494), (40, 0.02393081341870129), (45, 0.024178663035854697), (50, 0.024390298640355468), (21, 0.024924597470089793), (22, 0.025168767664581537), (42, 0.025188251631334424), (49, 0.02536152978427708), (24, 0.02589953667484224), (20, 0.026859007542952895), (47, 0.02736328006722033), (38, 0.03136562020517886), (15, 0.031923390459269285), (39, 0.03212768491357565), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03893592348322272), (37, 0.040206344332545996), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663572743535), (2, 0.054548467975109816), (3, 0.05722427926957607), (13, 0.058922897558659315), (11, 0.059249128215014935), (17, 0.06095685064792633), (52, 0.06232855096459389), (0, 0.0630098101682961), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4444201923906803), (18, 0.5108212977647781), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.016037589870393276
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088501015678048), (27, 0.018882446456700563), (43, 0.019595165736973286), (46, 0.020073581021279097), (41, 0.02096158522181213), (25, 0.02197260269895196), (23, 0.02237953571602702), (44, 0.02281495602801442), (48, 0.023128160974010825), (40, 0.02334519545547664), (50, 0.023756146896630526), (42, 0.02384730288758874), (45, 0.02387388003990054), (21, 0.024924597702920437), (49, 0.024960315553471446), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.026855541858822107), (20, 0.026859006844460964), (38, 0.030424013268202543), (39, 0.03151404415257275), (15, 0.03192339278757572), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.037824880331754684), (37, 0.03936835238710046), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846424981952), (3, 0.057224278803914785), (13, 0.05892290035262704), (11, 0.05924913194030523), (52, 0.06033281981945038), (17, 0.06095684925094247), (0, 0.0630098064430058), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4360685385763645), (18, 0.5108213126659393), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945483967662), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.01942429505288601), (48, 0.021467272890731692), (25, 0.02197260269895196), (44, 0.02202691650018096), (40, 0.022179660852998495), (42, 0.022206429857760668), (50, 0.022256129188463092), (23, 0.02237953571602702), (45, 0.022931481711566448), (49, 0.023708513006567955), (21, 0.024924598401412368), (22, 0.02516876789741218), (47, 0.025829139398410916), (24, 0.025899537140503526), (20, 0.02685900731012225), (38, 0.02895654644817114), (39, 0.029667828464880586), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03600902622565627), (37, 0.036512387450784445), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548464715480804), (52, 0.0561072863638401), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.41757645830512047), (18, 0.5108212903141975), (53, 0.9117144644260406)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102009117603), (41, 0.018849018262699246), (27, 0.018882446689531207), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.021832420956343412), (44, 0.02184053068049252), (50, 0.021869863849133253), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.02249284810386598), (49, 0.023123498540371656), (21, 0.02492459793575108), (47, 0.02506713825277984), (22, 0.025168768363073468), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.028114069253206253), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.035454337019473314), (37, 0.035977637860924006), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.047493682242929935), (14, 0.04783663526177406), (2, 0.054548464715480804), (52, 0.05469645978882909), (3, 0.057224278803914785), (13, 0.058922899421304464), (11, 0.059249126352369785), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4135979227721691), (18, 0.5108213126659393), (53, 0.9246632233262062)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.01888244622386992), (46, 0.019302030559629202), (42, 0.021432004403322935), (48, 0.021544843213632703), (40, 0.021832421189174056), (50, 0.02194626978598535), (25, 0.021972602466121316), (23, 0.022379535483196378), (49, 0.02300687017850578), (44, 0.02310851076617837), (45, 0.023535606916993856), (21, 0.02492459793575108), (22, 0.025168768130242825), (47, 0.02582044550217688), (24, 0.025899537606164813), (20, 0.026859006844460964), (38, 0.02811406902037561), (39, 0.0292069090064615), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.035091488156467676), (37, 0.03597763879224658), (9, 0.04340187832713127), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.053329029120504856), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832509428263), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.019070089096203446), (48, 0.02067816792987287), (50, 0.021344397915527225), (40, 0.0218324214220047), (25, 0.021972602931782603), (42, 0.02198694064281881), (23, 0.02237953571602702), (49, 0.02253474830649793), (45, 0.02392991678789258), (44, 0.024054002948105335), (21, 0.024924597702920437), (22, 0.025168768828734756), (24, 0.025899537606164813), (47, 0.026043936843052506), (20, 0.026859007542952895), (38, 0.02811406832188368), (39, 0.0292069090064615), (15, 0.03192339325323701), (7, 0.03228544723242521), (19, 0.03262859443202615), (51, 0.033794480841606855), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.05047609517350793), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.0592491258867085), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 1 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 2 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 5 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 6 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 7 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 8 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 9 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.1]
training epoch 10 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707972854376), (50, 0.020775062264874578), (40, 0.021085952874273062), (42, 0.021369647700339556), (49, 0.021910030394792557), (25, 0.021972602233290672), (23, 0.02237953571602702), (44, 0.02323931222781539), (45, 0.023585308576002717), (21, 0.024924597470089793), (47, 0.025076947640627623), (22, 0.025168768595904112), (24, 0.02589953737333417), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.03281426033936441), (37, 0.03542024455964565), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.048523630015552044), (2, 0.05454846750944853), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300981109961867), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.020831161877140403), (40, 0.021085952874273062), (42, 0.021369647700339556), (25, 0.02197260200046003), (23, 0.022379535483196378), (49, 0.0225369893014431), (44, 0.02323931152932346), (45, 0.023585307877510786), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026583049213513732), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.032850812654942274), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.04812479903921485), (2, 0.05454846518114209), (3, 0.05722428020089865), (13, 0.05892290221527219), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667386744171381), (36, 0.4065233804285526), (18, 0.5108213052153587), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952641442418), (42, 0.021369648166000843), (25, 0.021972602466121316), (23, 0.022379535250365734), (50, 0.02247006306424737), (44, 0.023239311762154102), (45, 0.023585307877510786), (21, 0.024924598401412368), (22, 0.025168768828734756), (49, 0.025234102504327893), (24, 0.025899537140503526), (47, 0.0265830485150218), (20, 0.026859007542952895), (38, 0.027183361118659377), (39, 0.028580757789313793), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.03296921169385314), (37, 0.03542024362832308), (9, 0.04340187832713127), (6, 0.046609030570834875), (4, 0.04749368270859122), (14, 0.04783663246780634), (52, 0.05089045176282525), (2, 0.054548462852835655), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952641442418
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.0209686818998307), (50, 0.02128476556390524), (25, 0.02197260200046003), (23, 0.02237953571602702), (45, 0.023098316974937916), (44, 0.024240857921540737), (49, 0.02450086921453476), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.0258995380718261), (47, 0.02651969832368195), (20, 0.02685900591313839), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.03192339092493057), (51, 0.032220850232988596), (7, 0.0322854476980865), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.04885757341980934), (2, 0.054548466578125954), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.0840828325599432), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.371861606836319)]
computing accuracy for after removing block 42 . block score: 0.0209686818998307
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658070251346), (25, 0.02197260200046003), (23, 0.022379535483196378), (45, 0.02376196556724608), (49, 0.024602338206022978), (44, 0.02471218165010214), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.026220474625006318), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580758022144437), (51, 0.031279068207368255), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.04340187879279256), (52, 0.0461017107591033), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.4178233742713928)]
computing accuracy for after removing block 50 . block score: 0.021202658070251346
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.023761966032907367), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026220475090667605), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03344302158802748), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.05265179369598627), (2, 0.054548466112464666), (3, 0.05722427926957607), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065233953297138), (18, 0.5108213126659393), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 1 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 2 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 3 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 4 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.1]
training epoch 5 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 6 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 8 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 9 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 10 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.965000)
finished training. finished 50 epochs. accuracy 0.965 topk_dict {'top1': 0.965}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.046458. All blocks and scores: [(49, 0.04645844316110015), (44, 0.04803041834384203), (21, 0.049981094896793365), (45, 0.050076869782060385), (47, 0.054266135673969984), (23, 0.054571921937167645), (22, 0.0546881603077054), (20, 0.05548479687422514), (19, 0.057385680731385946), (15, 0.05960096884518862), (51, 0.06009714910760522), (38, 0.06089458242058754), (7, 0.06368818646296859), (37, 0.06433664355427027), (39, 0.06549235712736845), (52, 0.06820302084088326), (24, 0.06857497151941061), (4, 0.07396921701729298), (9, 0.07919247634708881), (6, 0.09549262002110481), (11, 0.1011538514867425), (2, 0.1012426596134901), (14, 0.10362653248012066), (17, 0.10499057080596685), (3, 0.10558538418263197), (0, 0.11002307664602995), (1, 0.11276993993669748), (13, 0.11453649029135704), (8, 0.1198759600520134), (12, 0.14775480143725872), (10, 0.153001906350255), (16, 0.16985243745148182), (5, 0.20017247088253498), (36, 0.6290662288665771), (18, 0.7098673209547997), (53, 1.0213859379291534)]
computing accuracy for after removing block 49 . block score: 0.04645844316110015
removed block 49 current accuracy 0.9552 loss from initial  0.04479999999999995
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.048030. All blocks and scores: [(44, 0.048030417412519455), (21, 0.049981093499809504), (45, 0.05007686885073781), (47, 0.05426613613963127), (23, 0.05457191914319992), (22, 0.05468816123902798), (20, 0.05548479640856385), (19, 0.057385680731385946), (15, 0.059600969310849905), (38, 0.060894581489264965), (7, 0.06368818879127502), (37, 0.06433664448559284), (51, 0.06469605583697557), (39, 0.06549235712736845), (24, 0.06857497058808804), (4, 0.07396921515464783), (52, 0.07701912522315979), (9, 0.07919247634708881), (6, 0.09549261908978224), (11, 0.10115385334938765), (2, 0.1012426633387804), (14, 0.10362653899937868), (17, 0.1049905689433217), (3, 0.10558538511395454), (0, 0.11002307757735252), (1, 0.11276993993669748), (13, 0.11453649122267962), (8, 0.11987595353275537), (12, 0.14775479957461357), (10, 0.15300190821290016), (16, 0.16985243931412697), (5, 0.20017246715724468), (36, 0.6290662586688995), (18, 0.7098673284053802), (53, 1.1273865103721619)]
computing accuracy for after removing block 44 . block score: 0.048030417412519455
removed block 44 current accuracy 0.9432 loss from initial  0.05679999999999996
since last training loss: 0.02179999999999993 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.049981. All blocks and scores: [(21, 0.049981094896793365), (45, 0.05279933521524072), (23, 0.054571920074522495), (22, 0.05468816217035055), (20, 0.05548479687422514), (19, 0.05738568212836981), (15, 0.05960096884518862), (47, 0.059697299264371395), (38, 0.06089458195492625), (51, 0.06330519774928689), (7, 0.06368818646296859), (37, 0.06433664169162512), (39, 0.06549235712736845), (24, 0.06857497151941061), (4, 0.0739692160859704), (52, 0.07650663796812296), (9, 0.07919247634708881), (6, 0.09549262002110481), (11, 0.10115385055541992), (2, 0.10124265681952238), (14, 0.10362653620541096), (17, 0.10499057080596685), (3, 0.10558538045734167), (0, 0.11002308130264282), (1, 0.11276994086802006), (13, 0.11453649029135704), (8, 0.11987595446407795), (12, 0.14775480143725872), (10, 0.15300190821290016), (16, 0.16985244117677212), (5, 0.20017247460782528), (36, 0.6290662437677383), (18, 0.7098673358559608), (53, 1.2093046605587006)]
computing accuracy for after removing block 21 . block score: 0.049981094896793365
removed block 21 current accuracy 0.936 loss from initial  0.06399999999999995
since last training loss: 0.028999999999999915 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.047379. All blocks and scores: [(23, 0.047378999181091785), (22, 0.04788498720154166), (45, 0.050460340455174446), (20, 0.05548479687422514), (47, 0.05705299228429794), (19, 0.057385682594031096), (38, 0.05766675295308232), (24, 0.05933546321466565), (15, 0.05960096837952733), (51, 0.060439868830144405), (37, 0.06075119040906429), (39, 0.0627525714226067), (7, 0.06368818646296859), (52, 0.06981474813073874), (4, 0.07396921794861555), (9, 0.07919247541576624), (6, 0.09549261722713709), (11, 0.1011538514867425), (2, 0.1012426596134901), (14, 0.10362653341144323), (17, 0.10499057080596685), (3, 0.10558538418263197), (0, 0.11002307664602995), (1, 0.1127699427306652), (13, 0.11453649308532476), (8, 0.11987595539540052), (12, 0.14775480143725872), (10, 0.15300190448760986), (16, 0.16985243558883667), (5, 0.20017247274518013), (36, 0.5944517999887466), (18, 0.709867350757122), (53, 1.2371713370084763)]
computing accuracy for after removing block 23 . block score: 0.047378999181091785
removed block 23 current accuracy 0.9216 loss from initial  0.07840000000000003
since last training loss: 0.043399999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.047885. All blocks and scores: [(22, 0.04788498813286424), (45, 0.049409253988415), (47, 0.05536357266828418), (20, 0.055484797805547714), (24, 0.0569341192021966), (19, 0.05738568305969238), (38, 0.0575087470933795), (15, 0.05960096837952733), (51, 0.05982171976938844), (7, 0.06368818646296859), (39, 0.06382113788276911), (37, 0.06523448321968317), (52, 0.06828484684228897), (4, 0.07396921794861555), (9, 0.07919247727841139), (6, 0.09549262095242739), (11, 0.10115385334938765), (2, 0.10124266054481268), (14, 0.10362653341144323), (17, 0.10499056987464428), (3, 0.1055853832513094), (0, 0.11002307943999767), (1, 0.11276994086802006), (13, 0.11453649308532476), (8, 0.11987595446407795), (12, 0.14775479957461357), (10, 0.15300190448760986), (16, 0.16985243558883667), (5, 0.20017247088253498), (36, 0.6132306307554245), (18, 0.7098673433065414), (53, 1.237801343202591)]
computing accuracy for after removing block 22 . block score: 0.04788498813286424
removed block 22 current accuracy 0.8898 loss from initial  0.11019999999999996
since last training loss: 0.07519999999999993 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.047427. All blocks and scores: [(45, 0.04742690781131387), (47, 0.05263778707012534), (24, 0.05414386931806803), (20, 0.05548479687422514), (38, 0.05707588652148843), (51, 0.05720888124778867), (19, 0.057385680731385946), (15, 0.059600969310849905), (52, 0.06287669064477086), (39, 0.06313204020261765), (7, 0.06368818785995245), (37, 0.06818521860986948), (4, 0.07396921422332525), (9, 0.07919247634708881), (6, 0.09549261908978224), (11, 0.10115385055541992), (2, 0.10124265681952238), (14, 0.10362653341144323), (17, 0.1049905689433217), (3, 0.1055853869765997), (0, 0.11002307571470737), (1, 0.11276994179934263), (13, 0.11453649215400219), (8, 0.11987595167011023), (12, 0.14775479771196842), (10, 0.15300190448760986), (16, 0.16985243745148182), (5, 0.20017247088253498), (36, 0.6168972626328468), (18, 0.7098673284053802), (53, 1.2634429633617401)]
computing accuracy for after removing block 45 . block score: 0.04742690781131387
removed block 45 current accuracy 0.8668 loss from initial  0.13319999999999999
since last training loss: 0.09819999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.054144. All blocks and scores: [(24, 0.05414386745542288), (20, 0.05548479733988643), (51, 0.05655166367068887), (38, 0.05707588838413358), (19, 0.05738568166270852), (15, 0.05960096884518862), (47, 0.06102370796725154), (39, 0.0631320420652628), (7, 0.06368818785995245), (37, 0.06818522047251463), (52, 0.06861174385994673), (4, 0.07396921515464783), (9, 0.07919247541576624), (6, 0.09549261908978224), (11, 0.10115385241806507), (2, 0.10124265681952238), (14, 0.10362653248012066), (17, 0.1049905689433217), (3, 0.1055853832513094), (0, 0.11002307664602995), (1, 0.1127699427306652), (13, 0.11453649215400219), (8, 0.11987595353275537), (12, 0.14775479957461357), (10, 0.15300190821290016), (16, 0.16985243931412697), (5, 0.20017246529459953), (36, 0.6168972700834274), (18, 0.7098673209547997), (53, 1.3930272608995438)]
computing accuracy for after removing block 24 . block score: 0.05414386745542288
removed block 24 current accuracy 0.843 loss from initial  0.15700000000000003
since last training loss: 0.122 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.053701. All blocks and scores: [(38, 0.05370130203664303), (51, 0.05414155824109912), (20, 0.05548479547724128), (47, 0.0564656937494874), (19, 0.05738568492233753), (15, 0.059600967448204756), (39, 0.061379015911370516), (52, 0.06332713784649968), (7, 0.06368818739429116), (37, 0.06875484064221382), (4, 0.07396921515464783), (9, 0.07919247541576624), (6, 0.09549262002110481), (11, 0.10115384962409735), (2, 0.10124266054481268), (14, 0.10362653341144323), (17, 0.10499056708067656), (3, 0.10558538418263197), (0, 0.1100230785086751), (1, 0.11276994179934263), (13, 0.11453649029135704), (8, 0.11987595353275537), (12, 0.14775479584932327), (10, 0.15300190076231956), (16, 0.16985243745148182), (5, 0.20017246715724468), (36, 0.6064517349004745), (18, 0.7098673358559608), (53, 1.3834503293037415)]
computing accuracy for after removing block 38 . block score: 0.05370130203664303
removed block 38 current accuracy 0.812 loss from initial  0.18799999999999994
since last training loss: 0.1529999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.055485. All blocks and scores: [(20, 0.05548479640856385), (51, 0.055721239652484655), (47, 0.05654156021773815), (19, 0.05738568305969238), (15, 0.05960096791386604), (52, 0.06178941298276186), (7, 0.06368818739429116), (39, 0.06703153345733881), (37, 0.0687548415735364), (4, 0.0739692160859704), (9, 0.07919247634708881), (6, 0.09549261722713709), (11, 0.1011538477614522), (2, 0.10124265775084496), (14, 0.10362653527408838), (17, 0.10499057080596685), (3, 0.10558538418263197), (0, 0.11002308037132025), (1, 0.11276993993669748), (13, 0.11453649401664734), (8, 0.11987595539540052), (12, 0.14775480143725872), (10, 0.153001906350255), (16, 0.16985243931412697), (5, 0.20017247833311558), (36, 0.6064517423510551), (18, 0.7098673433065414), (53, 1.4149826020002365)]
computing accuracy for after removing block 20 . block score: 0.05548479640856385
removed block 20 current accuracy 0.7758 loss from initial  0.22419999999999995
training start
training epoch 0 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.1]
training epoch 1 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best True lr [0.1]
training epoch 2 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 3 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.1]
training epoch 4 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.1]
training epoch 5 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 6 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 7 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 8 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 9 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
