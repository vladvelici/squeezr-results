start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996031552553), (32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.010361600201576948), (34, 0.013312275987118483), (29, 0.013541154679842293), (35, 0.016018463065847754), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02023245650343597), (46, 0.021044540451839566), (25, 0.021972602466121316), (23, 0.022379535483196378), (41, 0.0228266476187855), (44, 0.023395078955218196), (40, 0.024025024380534887), (45, 0.024295410607010126), (21, 0.024924598168581724), (22, 0.025168768595904112), (48, 0.025341259315609932), (24, 0.025899537140503526), (50, 0.026409972459077835), (42, 0.026674100197851658), (20, 0.02685900661163032), (49, 0.027037164429202676), (47, 0.029306468553841114), (39, 0.031570712802931666), (38, 0.03163786977529526), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.04173417296260595), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.06862937472760677), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.43757999688386917), (18, 0.5108212977647781), (53, 0.8211488947272301)]
computing accuracy for after removing block 33 . block score: 0.007061996031552553
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.010039400309324265), (31, 0.010361600434407592), (34, 0.01313394762109965), (29, 0.013541154097765684), (26, 0.016037590336054564), (35, 0.016169289126992226), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02007247693836689), (46, 0.020731385797262192), (25, 0.021972602931782603), (41, 0.022347092628479004), (23, 0.022379535483196378), (44, 0.0232356870546937), (40, 0.0238410672172904), (45, 0.02396554173901677), (48, 0.024917915696278214), (21, 0.024924598401412368), (22, 0.025168768363073468), (50, 0.025840813294053078), (24, 0.025899536907672882), (42, 0.026315323309972882), (49, 0.02665567514486611), (20, 0.02685900777578354), (47, 0.028728797333315015), (39, 0.03131764172576368), (38, 0.031380363274365664), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03802584297955036), (51, 0.041223939042538404), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663526177406), (2, 0.05454846518114209), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.0630098101682961), (1, 0.06676734331995249), (52, 0.06745155062526464), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.43538711965084076), (18, 0.5108212903141975), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400891400874), (31, 0.010361600085161626), (34, 0.012765232590027153), (29, 0.01354115444701165), (35, 0.015992750646546483), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020075131906196475), (46, 0.020841406425461173), (25, 0.021972602233290672), (41, 0.0223197671584785), (23, 0.022379535250365734), (44, 0.02315405081026256), (40, 0.02388568385504186), (45, 0.024071688763797283), (48, 0.024877465097233653), (21, 0.024924597470089793), (22, 0.025168768595904112), (50, 0.025691178161650896), (24, 0.025899536907672882), (42, 0.02612374839372933), (49, 0.026479422114789486), (20, 0.026859006378799677), (47, 0.02869313070550561), (38, 0.031236796407029033), (39, 0.03129529138095677), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03837669035419822), (51, 0.04111403273418546), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836634796112776), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06700456328690052), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.43640000745654106), (18, 0.5108212977647781), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400891400874
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.012387836584821343), (29, 0.013541154330596328), (35, 0.016008096048608422), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02008363325148821), (46, 0.02070444426499307), (25, 0.02197260269895196), (41, 0.022253196919336915), (23, 0.022379535250365734), (44, 0.023267761571332812), (40, 0.02401388087309897), (45, 0.02409299253486097), (48, 0.024665280943736434), (21, 0.024924597470089793), (22, 0.025168768130242825), (50, 0.02545973425731063), (42, 0.02565571293234825), (24, 0.02589953737333417), (49, 0.026287756161764264), (20, 0.026859007077291608), (47, 0.02836342342197895), (38, 0.031047646654769778), (39, 0.03138077235780656), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.038971245754510164), (51, 0.04075620323419571), (9, 0.04340187832713127), (6, 0.0466090333648026), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.058922899421304464), (11, 0.05924912868067622), (17, 0.06095685064792633), (0, 0.06300980970263481), (52, 0.0658631594851613), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4389924518764019), (18, 0.5108213052153587), (53, 0.8391561284661293)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.01248961966484785), (29, 0.013541154679842293), (26, 0.01603759080171585), (35, 0.016057363245636225), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020049349637702107), (46, 0.020552986999973655), (25, 0.021972602466121316), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132365435362), (40, 0.02385834720917046), (45, 0.02412470313720405), (48, 0.02438612375408411), (21, 0.02492459793575108), (50, 0.025042241206392646), (22, 0.025168768363073468), (42, 0.025414507603272796), (49, 0.025842699455097318), (24, 0.025899538304656744), (20, 0.02685900661163032), (47, 0.028050735127180815), (38, 0.03104005940258503), (39, 0.03150080284103751), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.03262859582901001), (37, 0.03911284822970629), (51, 0.0402462724596262), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980737432837), (52, 0.06486208969727159), (1, 0.06676734145730734), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4381278492510319), (18, 0.5108213052153587), (53, 0.8458427488803864)]
computing accuracy for after removing block 34 . block score: 0.01248961966484785
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.016037589870393276), (35, 0.01665342040359974), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020503456005826592), (46, 0.020725322887301445), (25, 0.021972602931782603), (23, 0.022379535948857665), (41, 0.02245262893848121), (44, 0.023364474065601826), (48, 0.024290355620905757), (45, 0.024438712978735566), (40, 0.02447055815719068), (21, 0.024924598401412368), (50, 0.02504217275418341), (22, 0.025168768595904112), (49, 0.02587597002275288), (24, 0.025899537140503526), (42, 0.026205406757071614), (20, 0.02685900731012225), (47, 0.028178583132103086), (15, 0.03192339092493057), (38, 0.03208350110799074), (7, 0.032285446766763926), (39, 0.03233744064345956), (19, 0.0326285962946713), (51, 0.039947257842868567), (37, 0.04073968343436718), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.05454846424981952), (3, 0.05722427926957607), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095685064792633), (0, 0.06300980737432837), (52, 0.06433630315586925), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.45053431019186974), (18, 0.5108212903141975), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.016470608301460743), (28, 0.017728675389662385), (27, 0.019127048086374998), (43, 0.020046867430210114), (46, 0.020376994274556637), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.022379536414518952), (44, 0.02302833739668131), (48, 0.023771876469254494), (40, 0.023930812953040004), (45, 0.024178662803024054), (50, 0.02439029887318611), (21, 0.024924598168581724), (22, 0.025168768130242825), (42, 0.025188250932842493), (49, 0.025361528620123863), (24, 0.025899537140503526), (20, 0.02685900661163032), (47, 0.0273632793687284), (38, 0.03136561904102564), (15, 0.03192339185625315), (39, 0.03212768491357565), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.03893592394888401), (37, 0.040206344332545996), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095684878528118), (52, 0.06232855003327131), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.44442018866539), (18, 0.5108213052153587), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500317186117), (27, 0.018882446689531207), (43, 0.019595165504142642), (46, 0.020073580788448453), (41, 0.02096158522181213), (25, 0.02197260269895196), (23, 0.022379535483196378), (44, 0.022814956959336996), (48, 0.023128160508349538), (40, 0.02334519545547664), (50, 0.02375614712946117), (42, 0.023847303353250027), (45, 0.02387388003990054), (21, 0.024924597702920437), (49, 0.02496031508781016), (22, 0.025168768595904112), (24, 0.02589953737333417), (47, 0.026855542324483395), (20, 0.026859007542952895), (38, 0.030424013501033187), (39, 0.03151404415257275), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.037824881728738546), (37, 0.03936835238710046), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.059249130077660084), (52, 0.06033281981945038), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034483902156353), (16, 0.0840828251093626), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4360685497522354), (18, 0.5108213052153587), (53, 0.8749377578496933)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500084355474), (43, 0.018555945483967662), (27, 0.018882446689531207), (46, 0.019160085124894977), (41, 0.019424294820055366), (48, 0.021467273123562336), (25, 0.021972602931782603), (44, 0.02202691650018096), (40, 0.022179660852998495), (42, 0.0222064305562526), (50, 0.022256129421293736), (23, 0.022379535483196378), (45, 0.022931481478735805), (49, 0.02370851207524538), (21, 0.024924597702920437), (22, 0.025168768595904112), (47, 0.025829139864072204), (24, 0.02589953667484224), (20, 0.02685900661163032), (38, 0.02895654598250985), (39, 0.029667827766388655), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03600902669131756), (37, 0.03651238605380058), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368643388152), (14, 0.04783663200214505), (2, 0.054548466112464666), (52, 0.056107287760823965), (3, 0.05722427647560835), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.41757645457983017), (18, 0.5108213126659393), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.017088500084355474
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 1 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 2 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 3 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 4 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 5 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 6 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 7 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.1]
training epoch 8 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 9 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 10 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302505344152), (46, 0.01865610247477889), (41, 0.018849018262699246), (27, 0.01888244692236185), (48, 0.020903734024614096), (42, 0.021432003937661648), (40, 0.021832421189174056), (44, 0.021840531146153808), (50, 0.02186986361630261), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.022492847871035337), (49, 0.023123498540371656), (21, 0.024924597470089793), (47, 0.025067138951271772), (22, 0.0251687690615654), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.029206909239292145), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03545433655381203), (37, 0.03597763832658529), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548466112464666), (52, 0.054696458391845226), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.018140302505344152
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882447155192494), (46, 0.019302030093967915), (42, 0.021432004403322935), (48, 0.021544844144955277), (40, 0.0218324214220047), (50, 0.021946269320324063), (25, 0.021972602466121316), (23, 0.02237953501753509), (49, 0.023006869945675135), (44, 0.023108510300517082), (45, 0.023535606916993856), (21, 0.024924597702920437), (22, 0.0251687690615654), (47, 0.0258204466663301), (24, 0.025899537140503526), (20, 0.026859007542952895), (38, 0.02811406971886754), (39, 0.029206908540800214), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.035091488622128963), (37, 0.03597763879224658), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.053329029120504856), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213126659393), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.01907008863054216), (48, 0.020678168162703514), (50, 0.021344397449865937), (40, 0.021832421189174056), (25, 0.02197260269895196), (42, 0.021986939944326878), (23, 0.02237953571602702), (49, 0.02253474830649793), (45, 0.023929917253553867), (44, 0.024054003413766623), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.0258995380718261), (47, 0.02604393637739122), (20, 0.026859006378799677), (38, 0.02811406902037561), (39, 0.029206907842308283), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.032628594897687435), (51, 0.03379448037594557), (37, 0.03597763832658529), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05047609657049179), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.05892290314659476), (11, 0.059249129611998796), (17, 0.06095685018226504), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.01866446272470057), (48, 0.019989707274362445), (50, 0.02077506249770522), (40, 0.021085952874273062), (42, 0.0213696479331702), (49, 0.021910030860453844), (25, 0.02197260269895196), (23, 0.022379535250365734), (44, 0.023239311762154102), (45, 0.02358530880883336), (21, 0.02492459863424301), (47, 0.02507694810628891), (22, 0.025168768130242825), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.032814261270686984), (37, 0.035420244093984365), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368270859122), (14, 0.04783663526177406), (52, 0.048523630015552044), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924913100898266), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734052598476), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108212903141975), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.01866446272470057
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560370787978), (50, 0.020831162109971046), (40, 0.021085952641442418), (42, 0.021369648166000843), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.022536989068612456), (44, 0.02323931152932346), (45, 0.02358530811034143), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026583049213513732), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.028580759186297655), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03285081218928099), (37, 0.03542024455964565), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.04812479577958584), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924913054332137), (17, 0.06095685064792633), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4065233916044235), (18, 0.5108212903141975), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560370787978
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.02108595333993435), (42, 0.02136964723467827), (25, 0.021972603164613247), (23, 0.022379534784704447), (50, 0.022470062598586082), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.024924598401412368), (22, 0.025168768363073468), (49, 0.025234102038666606), (24, 0.02589953737333417), (47, 0.026583048747852445), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.03296921122819185), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903289914131), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.050890450831502676), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667386744171381), (36, 0.4065233953297138), (18, 0.5108213126659393), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.02108595333993435
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284765331074595), (25, 0.02197260269895196), (23, 0.02237953618168831), (45, 0.02309831720776856), (44, 0.02424085745587945), (49, 0.024500869447365403), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899537606164813), (47, 0.026519699255004525), (20, 0.026859007077291608), (38, 0.027183361118659377), (39, 0.028580757789313793), (15, 0.03192339185625315), (51, 0.032220850232988596), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.047836634796112776), (52, 0.048857571091502905), (2, 0.054548466112464666), (3, 0.057224278803914785), (13, 0.05892289895564318), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065234065055847), (18, 0.5108212977647781), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.02376196556724608), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.02492459863424301), (22, 0.025168768130242825), (24, 0.02589953667484224), (47, 0.026220474857836962), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580759186297655), (51, 0.03127906727604568), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.04340187972411513), (52, 0.046101709827780724), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722428020089865), (13, 0.05892289988696575), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4065233953297138), (18, 0.5108212903141975), (53, 1.4178233742713928)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.02376196626573801), (49, 0.02460233890451491), (44, 0.024712181417271495), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.025899536907672882), (47, 0.026220474857836962), (20, 0.02685900777578354), (38, 0.027183361118659377), (39, 0.028580758487805724), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03344302158802748), (37, 0.03542024455964565), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.04783663293346763), (52, 0.05265179509297013), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4065233953297138), (18, 0.5108212903141975), (53, 1.6287681013345718)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8168 topk_dict {'top1': 0.8168} is_best False lr [0.1]
training epoch 1 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 2 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 3 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 4 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 5 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 6 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 7 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 9 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 10 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.969000)
finished training. finished 50 epochs. accuracy 0.969 topk_dict {'top1': 0.969}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.045600. All blocks and scores: [(49, 0.04560015955939889), (45, 0.049219760578125715), (44, 0.051563192158937454), (21, 0.05297831166535616), (23, 0.05455199256539345), (47, 0.05714812921360135), (20, 0.05720080900937319), (19, 0.057457567658275366), (51, 0.05831197556108236), (22, 0.05862101074308157), (38, 0.058821984101086855), (7, 0.059283089358359575), (39, 0.05929629085585475), (24, 0.0629882994107902), (15, 0.06335228495299816), (37, 0.06769497226923704), (52, 0.07606881950050592), (4, 0.07798174116760492), (9, 0.08662498649209738), (6, 0.08838690631091595), (2, 0.09528278931975365), (14, 0.09983508568257093), (1, 0.10388317052274942), (3, 0.10391980968415737), (11, 0.10448611341416836), (17, 0.10687809623777866), (0, 0.10917379055172205), (8, 0.11648548021912575), (13, 0.12401974201202393), (12, 0.14703048393130302), (10, 0.15271483175456524), (16, 0.1596058439463377), (5, 0.1837306208908558), (36, 0.6275354698300362), (18, 0.6753501370549202), (53, 0.9802170246839523)]
computing accuracy for after removing block 49 . block score: 0.04560015955939889
removed block 49 current accuracy 0.956 loss from initial  0.04400000000000004
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.049220. All blocks and scores: [(45, 0.04921976150944829), (44, 0.05156319309026003), (21, 0.0529783102683723), (23, 0.054551993031054735), (47, 0.057148128747940063), (20, 0.05720081087201834), (19, 0.05745756858959794), (22, 0.05862101120874286), (38, 0.05882198130711913), (7, 0.059283087495714426), (39, 0.0592962889932096), (24, 0.06298830080777407), (15, 0.06335228122770786), (51, 0.06382426898926497), (37, 0.06769497320055962), (4, 0.07798174023628235), (52, 0.08585015218704939), (9, 0.08662498649209738), (6, 0.08838689886033535), (2, 0.09528278652578592), (14, 0.09983508195728064), (1, 0.10388317052274942), (3, 0.10391980689018965), (11, 0.10448611434549093), (17, 0.10687809716910124), (0, 0.10917379055172205), (8, 0.11648548394441605), (13, 0.12401974480599165), (12, 0.14703048393130302), (10, 0.1527148261666298), (16, 0.159605847671628), (5, 0.1837306134402752), (36, 0.6275354698300362), (18, 0.6753501296043396), (53, 1.0087975412607193)]
computing accuracy for after removing block 45 . block score: 0.04921976150944829
removed block 45 current accuracy 0.9452 loss from initial  0.05479999999999996
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.051563. All blocks and scores: [(44, 0.05156319169327617), (21, 0.052978312131017447), (23, 0.0545519944280386), (20, 0.05720081087201834), (19, 0.057457567658275366), (22, 0.05862100934609771), (38, 0.058821984101086855), (7, 0.059283088427037), (39, 0.0592962889932096), (24, 0.06298830127343535), (15, 0.06335228215903044), (47, 0.06442858278751373), (51, 0.06471645273268223), (37, 0.06769497226923704), (4, 0.07798173744231462), (9, 0.08662498649209738), (6, 0.08838690165430307), (52, 0.08955675922334194), (2, 0.09528278838843107), (14, 0.09983508195728064), (1, 0.10388316679745913), (3, 0.1039198050275445), (11, 0.10448611620813608), (17, 0.10687809810042381), (0, 0.10917379055172205), (8, 0.11648548301309347), (13, 0.1240197429433465), (12, 0.14703047834336758), (10, 0.15271482802927494), (16, 0.15960584208369255), (5, 0.1837306134402752), (36, 0.6275354772806168), (18, 0.6753501445055008), (53, 1.0426208227872849)]
computing accuracy for after removing block 44 . block score: 0.05156319169327617
removed block 44 current accuracy 0.9236 loss from initial  0.07640000000000002
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.052978. All blocks and scores: [(21, 0.05297830933704972), (23, 0.054551994893699884), (20, 0.0572008122690022), (19, 0.057457567658275366), (22, 0.05862101074308157), (38, 0.05882198316976428), (7, 0.05928308656439185), (39, 0.059296288061887026), (51, 0.06288959411904216), (24, 0.06298830034211278), (15, 0.06335228215903044), (37, 0.06769497226923704), (47, 0.07089405413717031), (4, 0.07798174023628235), (9, 0.08662498649209738), (6, 0.08838690165430307), (52, 0.09048658888787031), (2, 0.09528278838843107), (14, 0.09983508009463549), (1, 0.10388316959142685), (3, 0.10391980689018965), (11, 0.10448611620813608), (17, 0.10687809903174639), (0, 0.1091737961396575), (8, 0.11648548021912575), (13, 0.12401974201202393), (12, 0.14703048393130302), (10, 0.1527148261666298), (16, 0.15960584208369255), (5, 0.1837306171655655), (36, 0.6275354474782944), (18, 0.6753501370549202), (53, 1.0833532810211182)]
computing accuracy for after removing block 21 . block score: 0.05297830933704972
removed block 21 current accuracy 0.9162 loss from initial  0.08379999999999999
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.048377. All blocks and scores: [(23, 0.04837665893137455), (22, 0.05248786974698305), (24, 0.054055110551416874), (38, 0.05466945329681039), (20, 0.057200811337679625), (19, 0.05745756905525923), (39, 0.05750086344778538), (7, 0.05928308796137571), (51, 0.05962748918682337), (15, 0.06335228309035301), (37, 0.06389255542308092), (47, 0.06402457738295197), (52, 0.07738388888537884), (4, 0.0779817420989275), (9, 0.08662498649209738), (6, 0.0883869044482708), (2, 0.09528278931975365), (14, 0.09983508288860321), (1, 0.10388316866010427), (3, 0.10391980968415737), (11, 0.10448611713945866), (17, 0.10687809716910124), (0, 0.1091737924143672), (8, 0.11648548301309347), (13, 0.1240197466686368), (12, 0.14703048393130302), (10, 0.15271482802927494), (16, 0.1596058402210474), (5, 0.18373061530292034), (36, 0.5872962400317192), (18, 0.6753501370549202), (53, 1.1512354165315628)]
computing accuracy for after removing block 23 . block score: 0.04837665893137455
removed block 23 current accuracy 0.8926 loss from initial  0.10740000000000005
since last training loss: 0.07640000000000002 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.051126. All blocks and scores: [(24, 0.051126493606716394), (22, 0.05248786695301533), (38, 0.05560318473726511), (20, 0.05720081040635705), (19, 0.05745756858959794), (39, 0.05920436978340149), (7, 0.05928308889269829), (51, 0.0607876917347312), (47, 0.061830338556319475), (15, 0.06335228029638529), (37, 0.06992222182452679), (52, 0.07732608169317245), (4, 0.07798174023628235), (9, 0.08662498276680708), (6, 0.08838690165430307), (2, 0.09528278838843107), (14, 0.09983508102595806), (1, 0.10388316866010427), (3, 0.1039198087528348), (11, 0.10448611807078123), (17, 0.10687809996306896), (0, 0.10917379055172205), (8, 0.11648548021912575), (13, 0.1240197466686368), (12, 0.14703048393130302), (10, 0.15271482802927494), (16, 0.15960584580898285), (5, 0.1837306059896946), (36, 0.6159874945878983), (18, 0.6753501519560814), (53, 1.150401547551155)]
computing accuracy for after removing block 24 . block score: 0.051126493606716394
removed block 24 current accuracy 0.8608 loss from initial  0.1392
since last training loss: 0.10819999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.052488. All blocks and scores: [(22, 0.05248786974698305), (38, 0.05310251237824559), (51, 0.05600767023861408), (39, 0.05610185442492366), (47, 0.05660587176680565), (20, 0.057200811337679625), (19, 0.05745756672695279), (7, 0.05928308982402086), (15, 0.06335228215903044), (37, 0.06708757020533085), (52, 0.06942156981676817), (4, 0.07798174023628235), (9, 0.08662498649209738), (6, 0.08838690631091595), (2, 0.09528278931975365), (14, 0.09983508288860321), (1, 0.10388317238539457), (3, 0.1039198087528348), (11, 0.10448611620813608), (17, 0.10687809623777866), (0, 0.10917379148304462), (8, 0.11648547928780317), (13, 0.12401974108070135), (12, 0.14703048020601273), (10, 0.1527148261666298), (16, 0.159605847671628), (5, 0.1837306134402752), (36, 0.6075731962919235), (18, 0.6753501519560814), (53, 1.1925692856311798)]
computing accuracy for after removing block 22 . block score: 0.05248786974698305
removed block 22 current accuracy 0.8184 loss from initial  0.18159999999999998
since last training loss: 0.15059999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.052113. All blocks and scores: [(38, 0.0521127600222826), (47, 0.052226471714675426), (51, 0.05363350873813033), (39, 0.05439136177301407), (20, 0.0572008122690022), (19, 0.057457566261291504), (7, 0.05928308889269829), (52, 0.06260819919407368), (15, 0.06335228122770786), (37, 0.07054236903786659), (4, 0.07798174023628235), (9, 0.08662498835474253), (6, 0.08838690537959337), (2, 0.0952827874571085), (14, 0.09983508009463549), (1, 0.10388317052274942), (3, 0.10391981061547995), (11, 0.10448611713945866), (17, 0.10687809810042381), (0, 0.10917379055172205), (8, 0.11648548115044832), (13, 0.1240197429433465), (12, 0.14703048206865788), (10, 0.1527148261666298), (16, 0.159605847671628), (5, 0.18373061530292034), (36, 0.6100462079048157), (18, 0.6753501445055008), (53, 1.2228531390428543)]
computing accuracy for after removing block 38 . block score: 0.0521127600222826
removed block 38 current accuracy 0.792 loss from initial  0.20799999999999996
since last training loss: 0.17699999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.052406. All blocks and scores: [(47, 0.05240573547780514), (51, 0.05340120755136013), (20, 0.05720081180334091), (19, 0.05745756719261408), (52, 0.05830651614814997), (7, 0.059283088427037), (39, 0.060448877047747374), (15, 0.06335228029638529), (37, 0.07054236624389887), (4, 0.07798173744231462), (9, 0.08662498369812965), (6, 0.08838690351694822), (2, 0.09528278559446335), (14, 0.09983508102595806), (1, 0.10388316866010427), (3, 0.10391980782151222), (11, 0.10448611527681351), (17, 0.10687809623777866), (0, 0.10917379148304462), (8, 0.11648547649383545), (13, 0.12401974480599165), (12, 0.14703048206865788), (10, 0.15271482802927494), (16, 0.15960584953427315), (5, 0.1837306134402752), (36, 0.6100462153553963), (18, 0.6753501445055008), (53, 1.2748567163944244)]
computing accuracy for after removing block 47 . block score: 0.05240573547780514
removed block 47 current accuracy 0.709 loss from initial  0.29100000000000004
training start
training epoch 0 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best True lr [0.1]
training epoch 1 val accuracy 0.866 topk_dict {'top1': 0.866} is_best True lr [0.1]
training epoch 2 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.1]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 4 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 5 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 6 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 7 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 8 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 9 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 10 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.078209. All blocks and scores: [(7, 0.07820945139974356), (15, 0.08199923671782017), (52, 0.08646800555288792), (51, 0.08843945432454348), (4, 0.0901945661753416), (19, 0.09186881128698587), (6, 0.09391175955533981), (20, 0.10058502573519945), (37, 0.10116406343877316), (39, 0.10398249235004187), (9, 0.10457765031605959), (14, 0.11926970817148685), (3, 0.12017464824020863), (11, 0.1202492406591773), (0, 0.12244773097336292), (2, 0.12332062143832445), (1, 0.12474216613918543), (8, 0.13879693858325481), (17, 0.14223484694957733), (13, 0.14917564392089844), (10, 0.1750453058630228), (12, 0.17871625907719135), (16, 0.20030660554766655), (5, 0.21315557695925236), (36, 0.5433951988816261), (18, 0.6243045479059219), (53, 1.0978058874607086)]
computing accuracy for after removing block 7 . block score: 0.07820945139974356
removed block 7 current accuracy 0.9396 loss from initial  0.06040000000000001
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.080366. All blocks and scores: [(15, 0.0803662333637476), (52, 0.08422524575144053), (51, 0.08639987837523222), (19, 0.08778765145689249), (4, 0.09019456431269646), (6, 0.09391175862401724), (37, 0.09766007401049137), (20, 0.09835524391382933), (39, 0.10233021900057793), (9, 0.10524116456508636), (14, 0.11344565823674202), (11, 0.11474368441849947), (3, 0.12017465010285378), (0, 0.12244772724807262), (2, 0.1233206270262599), (1, 0.12474216427654028), (17, 0.1247477401047945), (13, 0.13049143180251122), (8, 0.13473991677165031), (12, 0.16627166792750359), (10, 0.17646151967346668), (16, 0.17949779517948627), (5, 0.21315557323396206), (36, 0.5294070020318031), (18, 0.6044774129986763), (53, 1.0976471155881882)]
computing accuracy for after removing block 15 . block score: 0.0803662333637476
removed block 15 current accuracy 0.9326 loss from initial  0.06740000000000002
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 52, with score 0.082003. All blocks and scores: [(52, 0.0820031650364399), (19, 0.08568220864981413), (51, 0.08657955564558506), (4, 0.09019456338137388), (20, 0.0915708988904953), (6, 0.09391176048666239), (37, 0.09538493026047945), (39, 0.10047359764575958), (9, 0.10524116922169924), (14, 0.11344566009938717), (11, 0.11474368814378977), (3, 0.12017464730888605), (0, 0.1224477281793952), (2, 0.12332062236964703), (1, 0.12474216613918543), (17, 0.12722091376781464), (13, 0.13049142993986607), (8, 0.1347399204969406), (12, 0.16627166606485844), (10, 0.17646151967346668), (16, 0.1955344807356596), (5, 0.2131555788218975), (36, 0.5095436573028564), (18, 0.5769095420837402), (53, 1.0984538942575455)]
computing accuracy for after removing block 52 . block score: 0.0820031650364399
removed block 52 current accuracy 0.888 loss from initial  0.11199999999999999
since last training loss: 0.05699999999999994 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 19, with score 0.085682. All blocks and scores: [(19, 0.08568220864981413), (51, 0.08657955657690763), (4, 0.09019456524401903), (20, 0.09157089609652758), (6, 0.09391176234930754), (37, 0.09538493119180202), (39, 0.10047359764575958), (9, 0.10524116549640894), (14, 0.11344566103070974), (11, 0.1147436797618866), (3, 0.12017464358359575), (0, 0.12244772631675005), (2, 0.12332062795758247), (1, 0.124742167070508), (17, 0.12722092308104038), (13, 0.13049142621457577), (8, 0.13473992235958576), (12, 0.16627166606485844), (10, 0.17646151222288609), (16, 0.19553447887301445), (5, 0.2131555825471878), (36, 0.5095436573028564), (18, 0.5769095569849014), (53, 1.1990200579166412)]
computing accuracy for after removing block 19 . block score: 0.08568220864981413
removed block 19 current accuracy 0.8538 loss from initial  0.1462
since last training loss: 0.09119999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.083099. All blocks and scores: [(51, 0.0830985177308321), (20, 0.08353998325765133), (4, 0.09019456338137388), (6, 0.09391176048666239), (39, 0.09805304743349552), (37, 0.10268179047852755), (9, 0.10524116456508636), (14, 0.1134456554427743), (11, 0.11474368534982204), (3, 0.1201746491715312), (0, 0.12244772911071777), (2, 0.1233206233009696), (1, 0.12474216241389513), (17, 0.12722091376781464), (13, 0.1304914355278015), (8, 0.1347399242222309), (12, 0.16627166233956814), (10, 0.17646151781082153), (16, 0.195534473285079), (5, 0.21315557695925236), (36, 0.5103442817926407), (18, 0.5769095569849014), (53, 1.088875487446785)]
computing accuracy for after removing block 51 . block score: 0.0830985177308321
removed block 51 current accuracy 0.746 loss from initial  0.254
since last training loss: 0.19899999999999995 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 20, with score 0.083540. All blocks and scores: [(20, 0.08353998325765133), (4, 0.09019456431269646), (6, 0.09391176328063011), (39, 0.09805304557085037), (37, 0.10268178954720497), (9, 0.10524116642773151), (14, 0.1134456591680646), (11, 0.11474368441849947), (3, 0.12017464451491833), (0, 0.1224477244541049), (2, 0.1233206233009696), (1, 0.12474216241389513), (17, 0.12722091376781464), (13, 0.1304914355278015), (8, 0.1347399204969406), (12, 0.16627166792750359), (10, 0.17646151967346668), (16, 0.19553447887301445), (5, 0.21315557695925236), (36, 0.5103442966938019), (18, 0.576909564435482), (53, 1.2108161598443985)]
computing accuracy for after removing block 20 . block score: 0.08353998325765133
removed block 20 current accuracy 0.6956 loss from initial  0.3044
since last training loss: 0.24939999999999996 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.090195. All blocks and scores: [(4, 0.09019456338137388), (6, 0.09391176328063011), (39, 0.09554909076541662), (9, 0.10524116829037666), (14, 0.11344565451145172), (11, 0.11474368441849947), (3, 0.1201746454462409), (37, 0.12063344195485115), (0, 0.12244772538542747), (2, 0.12332062236964703), (1, 0.12474216613918543), (17, 0.12722091935575008), (13, 0.13049142807722092), (8, 0.13473992235958576), (12, 0.16627166606485844), (10, 0.17646151408553123), (16, 0.19553447887301445), (5, 0.21315557323396206), (36, 0.5420164465904236), (18, 0.5769095569849014), (53, 1.1179180592298508)]
computing accuracy for after removing block 4 . block score: 0.09019456338137388
removed block 4 current accuracy 0.672 loss from initial  0.32799999999999996
since last training loss: 0.2729999999999999 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.095185. All blocks and scores: [(39, 0.0951851038262248), (9, 0.10566380806267262), (11, 0.10805445443838835), (14, 0.1098854262381792), (6, 0.11102301627397537), (37, 0.12000237684696913), (3, 0.1201746454462409), (17, 0.12061396148055792), (0, 0.12244772724807262), (2, 0.12332062236964703), (13, 0.12461953796446323), (1, 0.12474216613918543), (8, 0.1374099962413311), (12, 0.15944837406277657), (10, 0.1678014900535345), (16, 0.18369677662849426), (5, 0.2279775831848383), (36, 0.539800763130188), (18, 0.5754646807909012), (53, 1.082160547375679)]
computing accuracy for after removing block 39 . block score: 0.0951851038262248
removed block 39 current accuracy 0.5406 loss from initial  0.45940000000000003
since last training loss: 0.4044 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 9, with score 0.105664. All blocks and scores: [(9, 0.10566380992531776), (11, 0.10805445443838835), (14, 0.10988542903214693), (6, 0.11102302093058825), (37, 0.12000237591564655), (3, 0.12017464451491833), (17, 0.12061395309865475), (0, 0.1224477319046855), (2, 0.12332062423229218), (13, 0.12461953889578581), (1, 0.12474216427654028), (8, 0.13740999810397625), (12, 0.15944837220013142), (10, 0.1678014937788248), (16, 0.18369677290320396), (5, 0.22797758877277374), (36, 0.5398007705807686), (18, 0.5754646882414818), (53, 1.3148213028907776)]
computing accuracy for after removing block 9 . block score: 0.10566380992531776
removed block 9 current accuracy 0.4896 loss from initial  0.5104
since last training loss: 0.45539999999999997 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 11, with score 0.095916. All blocks and scores: [(11, 0.09591550845652819), (37, 0.09769971761852503), (14, 0.1007362175732851), (17, 0.10486945230513811), (6, 0.11102301813662052), (13, 0.11594478692859411), (3, 0.12017464358359575), (0, 0.12244772631675005), (2, 0.12332061771303415), (1, 0.12474216800183058), (12, 0.13294268399477005), (8, 0.13740999810397625), (16, 0.14829669147729874), (10, 0.16012786701321602), (5, 0.22797758504748344), (36, 0.4934607408940792), (18, 0.5535503923892975), (53, 1.2493548691272736)]
computing accuracy for after removing block 11 . block score: 0.09591550845652819
removed block 11 current accuracy 0.432 loss from initial  0.5680000000000001
since last training loss: 0.5129999999999999 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 37, with score 0.095314. All blocks and scores: [(37, 0.09531386569142342), (17, 0.09635766502469778), (14, 0.09668797254562378), (6, 0.11102301813662052), (13, 0.11154208052903414), (12, 0.11299091577529907), (16, 0.11627288535237312), (3, 0.12017464637756348), (0, 0.12244772911071777), (2, 0.12332062423229218), (1, 0.1247421633452177), (8, 0.13740999810397625), (10, 0.16012786515057087), (5, 0.2279775831848383), (36, 0.4906783550977707), (18, 0.5576541349291801), (53, 1.175760641694069)]
computing accuracy for after removing block 37 . block score: 0.09531386569142342
removed block 37 current accuracy 0.3952 loss from initial  0.6048
since last training loss: 0.5498 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.096358. All blocks and scores: [(17, 0.09635766688734293), (14, 0.0966879753395915), (6, 0.1110230190679431), (13, 0.11154207866638899), (12, 0.1129909185692668), (16, 0.11627288721501827), (3, 0.1201746454462409), (0, 0.1224477281793952), (2, 0.12332062423229218), (1, 0.12474216613918543), (8, 0.1374099925160408), (10, 0.16012786887586117), (5, 0.22797758504748344), (36, 0.4906783662736416), (18, 0.557654120028019), (53, 1.5780362039804459)]
computing accuracy for after removing block 17 . block score: 0.09635766688734293
removed block 17 current accuracy 0.367 loss from initial  0.633
training start
training epoch 0 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best True lr [0.1]
training epoch 1 val accuracy 0.7846 topk_dict {'top1': 0.7846} is_best False lr [0.1]
training epoch 2 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best True lr [0.1]
training epoch 3 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best False lr [0.1]
training epoch 4 val accuracy 0.83 topk_dict {'top1': 0.83} is_best False lr [0.1]
training epoch 5 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.1]
training epoch 6 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best True lr [0.1]
training epoch 7 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best True lr [0.1]
training epoch 8 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 9 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 10 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.912600)
finished training. finished 50 epochs. accuracy 0.9126 topk_dict {'top1': 0.9126}
