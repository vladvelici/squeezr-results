start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.00706199643900618), (32, 0.009233050630427897), (30, 0.01003940065857023), (31, 0.010361599619500339), (34, 0.013312276103533804), (29, 0.013541154912672937), (35, 0.016018463065847754), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02023245650343597), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.022379535948857665), (41, 0.022826648550108075), (44, 0.023395079420879483), (40, 0.024025025311857462), (45, 0.024295411072671413), (21, 0.02492459793575108), (22, 0.025168768595904112), (48, 0.02534125978127122), (24, 0.025899536907672882), (50, 0.026409972459077835), (42, 0.02667409973219037), (20, 0.026859006844460964), (49, 0.027037164196372032), (47, 0.029306469717994332), (39, 0.031570712802931666), (38, 0.03163787070661783), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.037960262037813663), (51, 0.04173417389392853), (9, 0.04340188158676028), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663526177406), (2, 0.0545484684407711), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684738829732), (0, 0.06300981063395739), (1, 0.06676734331995249), (52, 0.06862937286496162), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.43758000433444977), (18, 0.5108212903141975), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.00706199643900618
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400542154908), (31, 0.010361599968746305), (34, 0.013133947388269007), (29, 0.013541154330596328), (26, 0.016037590336054564), (35, 0.01616928935982287), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020072476705536246), (46, 0.020731385331600904), (25, 0.021972602233290672), (41, 0.022347092628479004), (23, 0.022379535250365734), (44, 0.023235686821863055), (40, 0.02384106651879847), (45, 0.02396554290316999), (48, 0.024917916394770145), (21, 0.024924597702920437), (22, 0.025168768595904112), (50, 0.025840812595561147), (24, 0.02589953737333417), (42, 0.026315323542803526), (49, 0.02665567514486611), (20, 0.026859006844460964), (47, 0.02872879756614566), (39, 0.03131764242425561), (38, 0.031380363972857594), (15, 0.03192339092493057), (7, 0.0322854476980865), (19, 0.03262859582901001), (37, 0.038025843910872936), (51, 0.04122393950819969), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922899421304464), (11, 0.05924912681803107), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734331995249), (52, 0.0674515487626195), (8, 0.07467832136899233), (10, 0.08034484647214413), (16, 0.0840828325599432), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.43538709357380867), (18, 0.5108213126659393), (53, 0.8222573921084404)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.012765232590027153), (29, 0.013541154796257615), (35, 0.015992750879377127), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020075131906196475), (46, 0.020841406425461173), (25, 0.02197260200046003), (41, 0.0223197671584785), (23, 0.022379535483196378), (44, 0.023154049646109343), (40, 0.023885684553533792), (45, 0.02407169039361179), (48, 0.02487746486440301), (21, 0.024924597702920437), (22, 0.0251687690615654), (50, 0.025691178161650896), (24, 0.025899537140503526), (42, 0.026123747928068042), (49, 0.026479421416297555), (20, 0.026859007077291608), (47, 0.02869313256815076), (38, 0.031236795475706458), (39, 0.03129529161378741), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.038376690819859505), (51, 0.04111403413116932), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368270859122), (14, 0.0478366338647902), (2, 0.054548467975109816), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06700456235557795), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387396097183), (36, 0.43640001863241196), (18, 0.5108213052153587), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400774985552
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371552072465), (34, 0.012387836817651987), (29, 0.01354115444701165), (35, 0.01600809651426971), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020083633018657565), (46, 0.020704444032162428), (25, 0.02197260269895196), (41, 0.022253197384998202), (23, 0.02237953501753509), (44, 0.02326776133850217), (40, 0.02401388017460704), (45, 0.02409299206919968), (48, 0.02466528071090579), (21, 0.02492459793575108), (22, 0.025168767664581537), (50, 0.025459734722971916), (42, 0.025655713165178895), (24, 0.025899537140503526), (49, 0.026287756394594908), (20, 0.026859006378799677), (47, 0.028363423654809594), (38, 0.031047646654769778), (39, 0.03138077212497592), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03897124482318759), (51, 0.040756203699857), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980783998966), (52, 0.06586316227912903), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4389924518764019), (18, 0.5108213052153587), (53, 0.8391561433672905)]
computing accuracy for after removing block 31 . block score: 0.010375371552072465
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.016057363711297512), (28, 0.01772867445833981), (27, 0.019127048552036285), (43, 0.020049349404871464), (46, 0.020552986999973655), (25, 0.021972602233290672), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132132604718), (40, 0.02385834651067853), (45, 0.024124702205881476), (48, 0.02438612305559218), (21, 0.024924597470089793), (50, 0.025042241672053933), (22, 0.025168768130242825), (42, 0.02541450783610344), (49, 0.025842698756605387), (24, 0.02589953737333417), (20, 0.026859007542952895), (47, 0.02805073489435017), (38, 0.0310400587040931), (39, 0.031500803073868155), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.039112847764045), (51, 0.04024627339094877), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.05722428020089865), (13, 0.05892290221527219), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980877131224), (52, 0.06486208736896515), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4381278343498707), (18, 0.5108212903141975), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154912672937), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020503455540165305), (46, 0.020725322188809514), (25, 0.02197260269895196), (23, 0.022379535948857665), (41, 0.0224526294041425), (44, 0.023364474531263113), (48, 0.024290354922413826), (45, 0.024438712745904922), (40, 0.02447055815719068), (21, 0.024924597702920437), (50, 0.025042172521352768), (22, 0.025168768130242825), (49, 0.025875970255583525), (24, 0.025899537606164813), (42, 0.026205406989902258), (20, 0.02685900661163032), (47, 0.028178583830595016), (15, 0.03192339139059186), (38, 0.03208350017666817), (7, 0.03228544583544135), (39, 0.03233744157478213), (19, 0.0326285962946713), (51, 0.03994725737720728), (37, 0.04073968343436718), (9, 0.04340187879279256), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.05892290314659476), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980970263481), (52, 0.06433630362153053), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.08034484554082155), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.45053431019186974), (18, 0.5108213126659393), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.013541154912672937
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759010322392), (35, 0.016470607835799456), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02004686719737947), (46, 0.020376994041725993), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.022379535948857665), (44, 0.023028337163850665), (48, 0.023771876702085137), (40, 0.023930813185870647), (45, 0.024178662803024054), (50, 0.02439029887318611), (21, 0.024924598401412368), (22, 0.025168768595904112), (42, 0.025188251165673137), (49, 0.025361529318615794), (24, 0.025899537838995457), (20, 0.026859007542952895), (47, 0.027363279601559043), (38, 0.031365618808194995), (15, 0.03192339185625315), (39, 0.03212768491357565), (7, 0.03228544630110264), (19, 0.03262859722599387), (51, 0.03893592394888401), (37, 0.04020634386688471), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095685018226504), (52, 0.062328549567610025), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.0803448399528861), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4444202072918415), (18, 0.5108213052153587), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.01603759010322392
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366145811975), (28, 0.01708850055001676), (27, 0.018882446456700563), (43, 0.01959516596980393), (46, 0.020073581486940384), (41, 0.020961584523320198), (25, 0.021972603164613247), (23, 0.022379535483196378), (44, 0.02281495602801442), (48, 0.023128160275518894), (40, 0.02334519545547664), (50, 0.023756146896630526), (42, 0.023847302421927452), (45, 0.023873879807069898), (21, 0.02492459723725915), (49, 0.024960315320640802), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.02685554255731404), (20, 0.026859006844460964), (38, 0.030424013501033187), (39, 0.031514043686911464), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.037824880331754684), (37, 0.03936835192143917), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.05722427600994706), (13, 0.0589229017496109), (11, 0.05924912774935365), (52, 0.06033282075077295), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4360685460269451), (18, 0.5108213052153587), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597366145811975
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 1 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 2 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 3 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 4 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 5 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.1]
training epoch 6 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 7 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 8 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.1]
training epoch 9 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 10 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945251137018), (27, 0.018882447155192494), (46, 0.01916008465923369), (41, 0.019424294587224722), (48, 0.02146727219223976), (25, 0.021972602931782603), (44, 0.022026916965842247), (40, 0.02217966108582914), (42, 0.02220643009059131), (50, 0.022256129421293736), (23, 0.022379535948857665), (45, 0.022931481478735805), (49, 0.023708513006567955), (21, 0.024924598168581724), (22, 0.025168769294396043), (47, 0.025829139398410916), (24, 0.025899537606164813), (20, 0.026859007077291608), (38, 0.028956545749679208), (39, 0.029667828232049942), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.036009025294333696), (37, 0.03651238651946187), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.05454846564680338), (52, 0.056107287760823965), (3, 0.05722427787259221), (13, 0.058922899421304464), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448399528861), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.41757645457983017), (18, 0.5108213052153587), (53, 0.9117145091295242)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.01865610177628696), (41, 0.01884901849552989), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.021432003937661648), (40, 0.021832420956343412), (44, 0.02184052998200059), (50, 0.021869864081963897), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.022492847871035337), (49, 0.02312349807471037), (21, 0.024924598401412368), (47, 0.025067138485610485), (22, 0.025168768130242825), (24, 0.025899537838995457), (20, 0.02685900661163032), (38, 0.02811406971886754), (39, 0.02920690947212279), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.035454337019473314), (37, 0.03597763832658529), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.05454846704378724), (52, 0.054696458857506514), (3, 0.05722427926957607), (13, 0.05892289895564318), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.01888244692236185), (46, 0.019302030093967915), (42, 0.02143200417049229), (48, 0.021544843213632703), (40, 0.021832421887665987), (50, 0.02194626978598535), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.023006869945675135), (44, 0.02310850960202515), (45, 0.02353560645133257), (21, 0.02492459793575108), (22, 0.025168768595904112), (47, 0.025820446433499455), (24, 0.025899537140503526), (20, 0.02685900731012225), (38, 0.02811406971886754), (39, 0.029206908773630857), (15, 0.03192339278757572), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.035091488156467676), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.04783663526177406), (52, 0.05332902818918228), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290035262704), (11, 0.059249129611998796), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 0.9678284004330635)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.019070088397711515), (48, 0.020678168395534158), (50, 0.02134439768269658), (40, 0.021832421654835343), (25, 0.02197260269895196), (42, 0.021986939944326878), (23, 0.022379534784704447), (49, 0.022534748073667288), (45, 0.02392991678789258), (44, 0.024054003413766623), (21, 0.024924597702920437), (22, 0.02516876789741218), (24, 0.025899536442011595), (47, 0.026043936843052506), (20, 0.026859007077291608), (38, 0.028114069253206253), (39, 0.0292069090064615), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.05047609470784664), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924913054332137), (17, 0.06095684692263603), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4135979041457176), (18, 0.5108213052153587), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.01866446272470057), (48, 0.01998970750719309), (50, 0.020775061333552003), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.021910030161961913), (25, 0.02197260200046003), (23, 0.022379535250365734), (44, 0.02323931152932346), (45, 0.023585308343172073), (21, 0.02492459793575108), (47, 0.025076947640627623), (22, 0.025168768130242825), (24, 0.025899536907672882), (20, 0.026859007542952895), (38, 0.02718336065299809), (39, 0.028580759186297655), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03281426173634827), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.04852363048121333), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.01866446272470057
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831161877140403), (40, 0.021085952874273062), (42, 0.0213696479331702), (25, 0.02197260269895196), (23, 0.022379534784704447), (49, 0.022536989767104387), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924598401412368), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.02685900731012225), (38, 0.02718336135149002), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.0328508117236197), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663526177406), (52, 0.048124798107892275), (2, 0.05454846518114209), (3, 0.0572242820635438), (13, 0.058922902680933475), (11, 0.05924912681803107), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.0904204910621047), (5, 0.10667387116700411), (36, 0.4065233878791332), (18, 0.5108213126659393), (53, 1.153771162033081)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953572764993), (42, 0.021369647001847625), (25, 0.02197260269895196), (23, 0.022379535948857665), (50, 0.022470063529908657), (44, 0.023239311296492815), (45, 0.023585308343172073), (21, 0.024924597702920437), (22, 0.025168768595904112), (49, 0.02523410157300532), (24, 0.025899537838995457), (47, 0.026583049446344376), (20, 0.02685900661163032), (38, 0.027183360187336802), (39, 0.02858075755648315), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.032628596760332584), (51, 0.03296921169385314), (37, 0.035420242697000504), (9, 0.043401881121098995), (6, 0.046609030570834875), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.05089045036584139), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249126352369785), (17, 0.06095684692263603), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.266390934586525)]
computing accuracy for after removing block 40 . block score: 0.021085953572764993
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.02128476626239717), (25, 0.021972602466121316), (23, 0.022379535948857665), (45, 0.02309831720776856), (44, 0.02424085815437138), (49, 0.024500869447365403), (21, 0.02492459723725915), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.026519699255004525), (20, 0.026859007077291608), (38, 0.02718336135149002), (39, 0.028580759651958942), (15, 0.031923390459269285), (51, 0.032220850232988596), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.04885757248848677), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249126352369785), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667386651039124), (36, 0.4065233990550041), (18, 0.5108213052153587), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 1 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 2 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 3 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 4 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 5 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 6 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 7 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 8 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 9 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 10 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.966600)
finished training. finished 50 epochs. accuracy 0.9666 topk_dict {'top1': 0.9666}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.041640. All blocks and scores: [(50, 0.04164047632366419), (49, 0.0429899194277823), (23, 0.04749077511951327), (22, 0.04975135764107108), (45, 0.049851709976792336), (44, 0.050440491642802954), (20, 0.05139837320894003), (21, 0.051674940157681704), (15, 0.05328792193904519), (51, 0.05430852808058262), (19, 0.055232787039130926), (47, 0.056166102178394794), (25, 0.05757036991417408), (24, 0.058804615400731564), (7, 0.05889252154156566), (38, 0.060968161560595036), (4, 0.06256429897621274), (52, 0.06348356790840626), (39, 0.06463395059108734), (37, 0.07080910075455904), (6, 0.08287292905151844), (9, 0.08350091241300106), (2, 0.08657802641391754), (14, 0.09178552310913801), (13, 0.0941709941253066), (17, 0.10117769986391068), (11, 0.10398845933377743), (1, 0.10462741460651159), (3, 0.1064180200919509), (0, 0.10724749602377415), (10, 0.13561865873634815), (8, 0.1357146892696619), (12, 0.1516209989786148), (16, 0.1690682526677847), (5, 0.1925351619720459), (36, 0.6517476215958595), (18, 0.7168467715382576), (53, 0.9962320849299431)]
computing accuracy for after removing block 50 . block score: 0.04164047632366419
removed block 50 current accuracy 0.9592 loss from initial  0.04079999999999995
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.042990. All blocks and scores: [(49, 0.04298992035910487), (23, 0.04749077605083585), (22, 0.04975135577842593), (45, 0.04985171044245362), (44, 0.05044049257412553), (20, 0.05139837274327874), (21, 0.051674940157681704), (15, 0.053287921473383904), (19, 0.05523278471082449), (47, 0.056166102178394794), (25, 0.057570368982851505), (51, 0.05840777978301048), (24, 0.058804617729038), (7, 0.058892520144581795), (38, 0.06096816109493375), (4, 0.06256429711356759), (39, 0.06463395059108734), (37, 0.07080910168588161), (52, 0.07447052840143442), (6, 0.08287292998284101), (9, 0.08350091334432364), (2, 0.08657802641391754), (14, 0.09178552031517029), (13, 0.09417099040001631), (17, 0.10117770079523325), (11, 0.10398845840245485), (1, 0.10462741460651159), (3, 0.1064180200919509), (0, 0.10724749136716127), (10, 0.1356186605989933), (8, 0.1357146892696619), (12, 0.1516209989786148), (16, 0.1690682489424944), (5, 0.1925351582467556), (36, 0.651747576892376), (18, 0.716846764087677), (53, 1.1652816385030746)]
computing accuracy for after removing block 49 . block score: 0.04298992035910487
removed block 49 current accuracy 0.9468 loss from initial  0.053200000000000025
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.047491. All blocks and scores: [(23, 0.04749077558517456), (22, 0.049751355312764645), (45, 0.049851709976792336), (44, 0.05044049210846424), (20, 0.05139837274327874), (21, 0.051674939692020416), (15, 0.053287921007722616), (19, 0.05523278657346964), (47, 0.056166104041039944), (25, 0.057570368982851505), (24, 0.058804618660360575), (7, 0.05889252247288823), (51, 0.059978312347084284), (38, 0.060968160163611174), (4, 0.06256429711356759), (39, 0.06463395338505507), (37, 0.07080910168588161), (52, 0.07912528607994318), (6, 0.08287292812019587), (9, 0.08350091148167849), (2, 0.08657802734524012), (14, 0.09178552031517029), (13, 0.09417099226266146), (17, 0.1011776989325881), (11, 0.10398845840245485), (1, 0.10462741553783417), (3, 0.1064180200919509), (0, 0.10724749509245157), (10, 0.1356186643242836), (8, 0.13571469113230705), (12, 0.1516209989786148), (16, 0.16906824707984924), (5, 0.1925351656973362), (36, 0.6517475843429565), (18, 0.7168467491865158), (53, 1.215031623840332)]
computing accuracy for after removing block 23 . block score: 0.04749077558517456
removed block 23 current accuracy 0.9422 loss from initial  0.05779999999999996
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.049224. All blocks and scores: [(44, 0.049223973881453276), (45, 0.049484158400446177), (22, 0.04975135624408722), (20, 0.05139837320894003), (21, 0.05167494108900428), (15, 0.05328792007640004), (47, 0.054628098383545876), (19, 0.055232785642147064), (24, 0.05543573061004281), (25, 0.05765430582687259), (7, 0.05889252247288823), (51, 0.05989902652800083), (38, 0.06028746115043759), (4, 0.06256429711356759), (39, 0.06584926228970289), (37, 0.07473964430391788), (52, 0.07812602259218693), (6, 0.08287292905151844), (9, 0.08350091427564621), (2, 0.08657802734524012), (14, 0.09178552124649286), (13, 0.09417099226266146), (17, 0.10117769986391068), (11, 0.10398845560848713), (1, 0.10462741553783417), (3, 0.1064180200919509), (0, 0.10724749509245157), (10, 0.1356186605989933), (8, 0.1357146892696619), (12, 0.1516209952533245), (16, 0.1690682526677847), (5, 0.1925351582467556), (36, 0.6616581752896309), (18, 0.716846764087677), (53, 1.209643080830574)]
computing accuracy for after removing block 44 . block score: 0.049223973881453276
removed block 44 current accuracy 0.9238 loss from initial  0.07620000000000005
since last training loss: 0.04280000000000006 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.049751. All blocks and scores: [(22, 0.049751355312764645), (45, 0.050744745414704084), (20, 0.05139837181195617), (21, 0.05167494108900428), (15, 0.05328791914507747), (19, 0.055232785642147064), (24, 0.05543572921305895), (51, 0.05676680337637663), (47, 0.05696800909936428), (25, 0.05765430489555001), (7, 0.05889252061024308), (38, 0.06028746115043759), (4, 0.06256429897621274), (39, 0.06584926228970289), (37, 0.07473964523524046), (52, 0.07703387085348368), (6, 0.08287292998284101), (9, 0.08350091241300106), (2, 0.08657802827656269), (14, 0.09178552124649286), (13, 0.09417099598795176), (17, 0.10117769800126553), (11, 0.10398845560848713), (1, 0.10462741460651159), (3, 0.10641801822930574), (0, 0.10724749695509672), (10, 0.1356186605989933), (8, 0.1357146892696619), (12, 0.1516209989786148), (16, 0.1690682489424944), (5, 0.19253516010940075), (36, 0.6616581752896309), (18, 0.7168467715382576), (53, 1.3264722675085068)]
computing accuracy for after removing block 22 . block score: 0.049751355312764645
removed block 22 current accuracy 0.9116 loss from initial  0.08840000000000003
since last training loss: 0.05500000000000005 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.049458. All blocks and scores: [(45, 0.049458094872534275), (20, 0.051398373674601316), (21, 0.05167494108900428), (24, 0.051899544429033995), (15, 0.05328792193904519), (47, 0.05429658340290189), (51, 0.05480221239849925), (19, 0.05523278657346964), (25, 0.05577784078195691), (7, 0.05889252247288823), (38, 0.0597756109200418), (4, 0.06256429944187403), (39, 0.06452426221221685), (52, 0.07261667121201754), (37, 0.07617097906768322), (6, 0.08287292812019587), (9, 0.08350091334432364), (2, 0.08657802455127239), (14, 0.09178552124649286), (13, 0.0941709941253066), (17, 0.10117769986391068), (11, 0.10398845560848713), (1, 0.10462741367518902), (3, 0.1064180200919509), (0, 0.107247494161129), (10, 0.13561865873634815), (8, 0.13571469113230705), (12, 0.15162100084125996), (16, 0.1690682489424944), (5, 0.19253516383469105), (36, 0.6565206274390221), (18, 0.7168467566370964), (53, 1.3331659585237503)]
computing accuracy for after removing block 45 . block score: 0.049458094872534275
removed block 45 current accuracy 0.8816 loss from initial  0.11839999999999995
since last training loss: 0.08499999999999996 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.051398. All blocks and scores: [(20, 0.05139837181195617), (21, 0.051674939692020416), (24, 0.051899544429033995), (15, 0.053287921007722616), (51, 0.05375123955309391), (19, 0.05523278610780835), (25, 0.055777841713279486), (7, 0.05889251874759793), (47, 0.0589055479504168), (38, 0.0597756109200418), (4, 0.06256429851055145), (39, 0.06452426221221685), (52, 0.07541570719331503), (37, 0.07617098093032837), (6, 0.08287292998284101), (9, 0.08350091148167849), (2, 0.08657802734524012), (14, 0.09178552124649286), (13, 0.09417099040001631), (17, 0.10117770079523325), (11, 0.10398845560848713), (1, 0.10462741181254387), (3, 0.1064180200919509), (0, 0.10724749322980642), (10, 0.13561865873634815), (8, 0.13571469485759735), (12, 0.1516209989786148), (16, 0.1690682452172041), (5, 0.19253516755998135), (36, 0.6565206050872803), (18, 0.7168467566370964), (53, 1.4171452969312668)]
computing accuracy for after removing block 20 . block score: 0.05139837181195617
removed block 20 current accuracy 0.864 loss from initial  0.136
since last training loss: 0.10260000000000002 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.050962. All blocks and scores: [(24, 0.050962237641215324), (21, 0.05125173972919583), (51, 0.052860391326248646), (15, 0.05328792054206133), (19, 0.05523278610780835), (25, 0.055466309655457735), (47, 0.05646750424057245), (38, 0.05888610379770398), (7, 0.05889252293854952), (4, 0.06256429757922888), (39, 0.06433339975774288), (52, 0.07120866607874632), (37, 0.07870014570653439), (6, 0.08287292905151844), (9, 0.08350091334432364), (2, 0.08657802548259497), (14, 0.09178552404046059), (13, 0.0941709978505969), (17, 0.10117769986391068), (11, 0.10398845560848713), (1, 0.10462741460651159), (3, 0.10641801822930574), (0, 0.10724749602377415), (10, 0.1356186643242836), (8, 0.1357146892696619), (12, 0.1516210027039051), (16, 0.16906824707984924), (5, 0.1925351619720459), (36, 0.6533010601997375), (18, 0.7168467566370964), (53, 1.4141171872615814)]
computing accuracy for after removing block 24 . block score: 0.050962237641215324
removed block 24 current accuracy 0.8338 loss from initial  0.16620000000000001
training start
training epoch 0 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 1 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 2 val accuracy 0.805 topk_dict {'top1': 0.805} is_best False lr [0.1]
training epoch 3 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 4 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 5 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 6 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 7 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 8 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.953200)
finished training. finished 50 epochs. accuracy 0.9532 topk_dict {'top1': 0.9532}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.062972. All blocks and scores: [(7, 0.0629723547026515), (15, 0.0683482913300395), (51, 0.07423182856291533), (38, 0.07724606618285179), (52, 0.0785094304010272), (19, 0.07857271749526262), (4, 0.08020439371466637), (47, 0.08114860020577908), (37, 0.08256534021347761), (39, 0.08327070064842701), (9, 0.08380484487861395), (21, 0.0898455549031496), (25, 0.0947761433199048), (6, 0.09545719623565674), (2, 0.10221956297755241), (0, 0.11290082708001137), (3, 0.11439472995698452), (17, 0.11467699334025383), (14, 0.12039716355502605), (1, 0.12132793478667736), (11, 0.1246885322034359), (13, 0.1253348682075739), (8, 0.14587052911520004), (12, 0.16107051633298397), (10, 0.16554032638669014), (16, 0.18358562514185905), (5, 0.2155258059501648), (36, 0.6091848611831665), (18, 0.6860654726624489), (53, 1.0719026923179626)]
computing accuracy for after removing block 7 . block score: 0.0629723547026515
removed block 7 current accuracy 0.9478 loss from initial  0.052200000000000024
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.067241. All blocks and scores: [(15, 0.06724061444401741), (51, 0.07099625933915377), (19, 0.07458742242306471), (52, 0.07546187937259674), (38, 0.07602629531174898), (37, 0.07815661933273077), (47, 0.078577627427876), (4, 0.08020439464598894), (39, 0.08196468837559223), (9, 0.08527966309338808), (21, 0.08588189538568258), (25, 0.09083647560328245), (6, 0.09545719530433416), (17, 0.09784681722521782), (2, 0.10221956111490726), (13, 0.10750051401555538), (0, 0.11290082894265652), (3, 0.11439472623169422), (11, 0.11446651816368103), (14, 0.11663979943841696), (1, 0.12132793758064508), (12, 0.14459134452044964), (8, 0.1449886281043291), (16, 0.16871480643749237), (10, 0.168768173083663), (5, 0.21552580408751965), (36, 0.5839276686310768), (18, 0.6628189012408257), (53, 1.0762662589550018)]
computing accuracy for after removing block 15 . block score: 0.06724061444401741
removed block 15 current accuracy 0.9426 loss from initial  0.05740000000000001
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.070775. All blocks and scores: [(51, 0.07077488955110312), (19, 0.07266185525804758), (52, 0.07384305540472269), (38, 0.07549276761710644), (37, 0.07700739707797766), (47, 0.0780199570581317), (21, 0.07973453029990196), (39, 0.07994729559868574), (4, 0.08020439371466637), (9, 0.0852796621620655), (25, 0.08653267938643694), (6, 0.09545719437301159), (17, 0.09917199239134789), (2, 0.10221955738961697), (13, 0.10750051308423281), (0, 0.11290082428604364), (3, 0.1143947271630168), (11, 0.11446652002632618), (14, 0.11663980036973953), (1, 0.12132793571799994), (12, 0.1445913463830948), (8, 0.14498862624168396), (10, 0.16876817122101784), (16, 0.1868849042803049), (5, 0.2155258022248745), (36, 0.5597985908389091), (18, 0.637875534594059), (53, 1.0837052762508392)]
computing accuracy for after removing block 51 . block score: 0.07077488955110312
removed block 51 current accuracy 0.9086 loss from initial  0.09140000000000004
since last training loss: 0.044600000000000084 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 19, with score 0.072662. All blocks and scores: [(19, 0.07266185525804758), (38, 0.07549276761710644), (37, 0.07700739614665508), (52, 0.07762109860777855), (47, 0.0780199533328414), (21, 0.07973452750593424), (39, 0.07994729746133089), (4, 0.08020439464598894), (9, 0.08527965936809778), (25, 0.08653267845511436), (6, 0.09545719623565674), (17, 0.09917199425399303), (2, 0.10221956204622984), (13, 0.10750051494687796), (0, 0.11290082521736622), (3, 0.11439472623169422), (11, 0.1144665190950036), (14, 0.11663980036973953), (1, 0.12132793478667736), (12, 0.1445913463830948), (8, 0.14498862996697426), (10, 0.16876817680895329), (16, 0.1868849005550146), (5, 0.21552580408751965), (36, 0.5597985908389091), (18, 0.637875534594059), (53, 1.2617860287427902)]
computing accuracy for after removing block 19 . block score: 0.07266185525804758
removed block 19 current accuracy 0.8908 loss from initial  0.10919999999999996
since last training loss: 0.06240000000000001 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 38, with score 0.072308. All blocks and scores: [(38, 0.07230769656598568), (52, 0.07262910809367895), (47, 0.07369830273091793), (21, 0.07453071605414152), (39, 0.07845904864370823), (37, 0.07892523985356092), (4, 0.08020439185202122), (25, 0.08139197342097759), (9, 0.08527966029942036), (6, 0.09545719716697931), (17, 0.09917199239134789), (2, 0.10221956111490726), (13, 0.10750051215291023), (0, 0.11290082801133394), (3, 0.1143947234377265), (11, 0.1144665190950036), (14, 0.11663979664444923), (1, 0.12132793571799994), (12, 0.1445913463830948), (8, 0.14498862996697426), (10, 0.16876817122101784), (16, 0.18688489869236946), (5, 0.21552580408751965), (36, 0.5421243757009506), (18, 0.6378755420446396), (53, 1.2300273478031158)]
computing accuracy for after removing block 38 . block score: 0.07230769656598568
removed block 38 current accuracy 0.8572 loss from initial  0.14280000000000004
since last training loss: 0.09600000000000009 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 52, with score 0.067987. All blocks and scores: [(52, 0.06798735447227955), (47, 0.07238717749714851), (21, 0.07453071605414152), (37, 0.0789252407848835), (4, 0.08020439185202122), (25, 0.08139197528362274), (9, 0.08527966123074293), (39, 0.09361115284264088), (6, 0.09545719530433416), (17, 0.09917198959738016), (2, 0.10221956018358469), (13, 0.10750051308423281), (0, 0.11290083080530167), (3, 0.11439472157508135), (11, 0.11446652188897133), (14, 0.11663980130106211), (1, 0.12132793106138706), (12, 0.14459134824573994), (8, 0.14498862996697426), (10, 0.168768173083663), (16, 0.1868849042803049), (5, 0.21552579291164875), (36, 0.5421243384480476), (18, 0.6378755420446396), (53, 1.3028564006090164)]
computing accuracy for after removing block 52 . block score: 0.06798735447227955
removed block 52 current accuracy 0.7956 loss from initial  0.20440000000000003
since last training loss: 0.15760000000000007 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.072387. All blocks and scores: [(47, 0.07238717656582594), (21, 0.07453071605414152), (37, 0.0789252407848835), (4, 0.08020439464598894), (25, 0.08139197621494532), (9, 0.0852796621620655), (39, 0.0936111519113183), (6, 0.09545719530433416), (17, 0.09917198959738016), (2, 0.10221956390887499), (13, 0.10750051122158766), (0, 0.11290083080530167), (3, 0.1143947271630168), (11, 0.11446652002632618), (14, 0.11663979850709438), (1, 0.12132793851196766), (12, 0.1445913463830948), (8, 0.1449886243790388), (10, 0.16876817122101784), (16, 0.1868848968297243), (5, 0.21552580036222935), (36, 0.5421243533492088), (18, 0.637875534594059), (53, 1.3526065647602081)]
computing accuracy for after removing block 47 . block score: 0.07238717656582594
removed block 47 current accuracy 0.7204 loss from initial  0.27959999999999996
since last training loss: 0.2328 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 21, with score 0.074531. All blocks and scores: [(21, 0.07453071605414152), (37, 0.07892523985356092), (4, 0.08020439371466637), (25, 0.08139197248965502), (9, 0.08527966029942036), (39, 0.0936111556366086), (6, 0.09545719716697931), (17, 0.09917198959738016), (2, 0.10221956018358469), (13, 0.10750051401555538), (0, 0.11290082521736622), (3, 0.11439472530037165), (11, 0.11446651816368103), (14, 0.11663979850709438), (1, 0.12132793478667736), (12, 0.1445913463830948), (8, 0.14498862624168396), (10, 0.16876816749572754), (16, 0.1868848968297243), (5, 0.21552580036222935), (36, 0.5421243757009506), (18, 0.6378755420446396), (53, 1.3874752670526505)]
computing accuracy for after removing block 21 . block score: 0.07453071605414152
removed block 21 current accuracy 0.6774 loss from initial  0.3226
since last training loss: 0.27580000000000005 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 25, with score 0.078986. All blocks and scores: [(25, 0.07898565288633108), (4, 0.08020439092069864), (37, 0.08203405048698187), (9, 0.08527966123074293), (39, 0.08966646529734135), (6, 0.09545719902962446), (17, 0.09917199146002531), (2, 0.10221956297755241), (13, 0.10750051308423281), (0, 0.11290082987397909), (3, 0.11439472157508135), (11, 0.1144665228202939), (14, 0.11663979664444923), (1, 0.12132793758064508), (12, 0.14459135010838509), (8, 0.14498862624168396), (10, 0.16876817680895329), (16, 0.1868849005550146), (5, 0.2155258096754551), (36, 0.5356686487793922), (18, 0.6378755196928978), (53, 1.29071906208992)]
computing accuracy for after removing block 25 . block score: 0.07898565288633108
removed block 25 current accuracy 0.59 loss from initial  0.41000000000000003
training start
training epoch 0 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best True lr [0.1]
training epoch 1 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.1]
training epoch 2 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 3 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.1]
training epoch 4 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.1]
training epoch 5 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 6 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 7 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best False lr [0.1]
training epoch 8 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 9 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 10 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.930600)
finished training. finished 50 epochs. accuracy 0.9306 topk_dict {'top1': 0.9306}
