start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050746843219), (30, 0.010039401124231517), (31, 0.010361600201576948), (34, 0.013312275987118483), (29, 0.013541154796257615), (35, 0.016018462367355824), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020232456736266613), (46, 0.021044540451839566), (25, 0.021972602931782603), (23, 0.02237953571602702), (41, 0.02282664831727743), (44, 0.023395078722387552), (40, 0.024025024846196175), (45, 0.024295411072671413), (21, 0.02492459723725915), (22, 0.0251687690615654), (48, 0.025341259548440576), (24, 0.02589953667484224), (50, 0.026409972459077835), (42, 0.026674099965021014), (20, 0.026859007077291608), (49, 0.02703716396354139), (47, 0.029306468786671758), (39, 0.031570712802931666), (38, 0.031637870240956545), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.041734172496944666), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663572743535), (2, 0.054548466578125954), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.06095685111358762), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06862937659025192), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.43758000060915947), (18, 0.5108213052153587), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.010361599852330983), (34, 0.013133947388269007), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169289592653513), (28, 0.01772867562249303), (27, 0.019127048086374998), (43, 0.020072476705536246), (46, 0.020731384633108974), (25, 0.02197260269895196), (41, 0.022347092861309648), (23, 0.02237953571602702), (44, 0.023235687520354986), (40, 0.023841066751629114), (45, 0.02396554220467806), (48, 0.024917916161939502), (21, 0.024924597702920437), (22, 0.025168768595904112), (50, 0.02584081352688372), (24, 0.02589953737333417), (42, 0.026315322378650308), (49, 0.026655674446374178), (20, 0.02685900661163032), (47, 0.028728798031806946), (39, 0.03131764126010239), (38, 0.031380362808704376), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.038025844376534224), (51, 0.041223939042538404), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846378415823), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734425127506), (52, 0.06745154969394207), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.43538708984851837), (18, 0.5108212977647781), (53, 0.8222574070096016)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.010361600434407592), (34, 0.012765232706442475), (29, 0.013541154563426971), (35, 0.015992751345038414), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.019127047853544354), (43, 0.020075131440535188), (46, 0.020841405959799886), (25, 0.02197260269895196), (41, 0.022319766925647855), (23, 0.022379535483196378), (44, 0.023154051043093204), (40, 0.023885683389380574), (45, 0.024071690160781145), (48, 0.024877464631572366), (21, 0.02492459863424301), (22, 0.02516876789741218), (50, 0.02569117839448154), (24, 0.025899537140503526), (42, 0.026123747928068042), (49, 0.026479422114789486), (20, 0.026859007542952895), (47, 0.02869313256815076), (38, 0.031236795242875814), (39, 0.03129529161378741), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.038376690819859505), (51, 0.041114034596830606), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.0670045642182231), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.43640001118183136), (18, 0.5108213052153587), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387837166897953), (29, 0.013541155029088259), (35, 0.016008096048608422), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02008363394998014), (46, 0.020704444963485003), (25, 0.021972602931782603), (41, 0.022253197384998202), (23, 0.022379535250365734), (44, 0.023267761105671525), (40, 0.02401387970894575), (45, 0.024092992302030325), (48, 0.02466528001241386), (21, 0.02492459793575108), (22, 0.02516876789741218), (50, 0.025459735421463847), (42, 0.025655712699517608), (24, 0.025899537140503526), (49, 0.026287756394594908), (20, 0.02685900731012225), (47, 0.028363423887640238), (38, 0.031047646654769778), (39, 0.031380773056298494), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628594897687435), (37, 0.038971245754510164), (51, 0.04075620323419571), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.05722427647560835), (13, 0.05892290035262704), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300980830565095), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4389924518764019), (18, 0.5108212977647781), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.01248961966484785), (29, 0.013541154214181006), (26, 0.016037590568885207), (35, 0.01605736231431365), (28, 0.01772867515683174), (27, 0.019127049017697573), (43, 0.020049349637702107), (46, 0.0205529872328043), (25, 0.021972602931782603), (41, 0.02206748421303928), (23, 0.022379535483196378), (44, 0.022979132132604718), (40, 0.023858347442001104), (45, 0.02412470243871212), (48, 0.02438612375408411), (21, 0.024924598168581724), (50, 0.02504224143922329), (22, 0.025168768595904112), (42, 0.025414508767426014), (49, 0.025842698523774743), (24, 0.025899535976350307), (20, 0.026859006378799677), (47, 0.028050735592842102), (38, 0.03104006010107696), (39, 0.03150080353952944), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.039112848695367575), (51, 0.04024627339094877), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.05454846424981952), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300980923697352), (52, 0.06486208783462644), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.438127838075161), (18, 0.5108213052153587), (53, 0.8458427786827087)]
computing accuracy for after removing block 34 . block score: 0.01248961966484785
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154679842293), (26, 0.016037590336054564), (35, 0.01665342040359974), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020503456238657236), (46, 0.020725322188809514), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.022452628705650568), (44, 0.023364473367109895), (48, 0.024290354922413826), (45, 0.024438712978735566), (40, 0.024470559088513255), (21, 0.02492459793575108), (50, 0.02504217275418341), (22, 0.0251687690615654), (49, 0.025875970255583525), (24, 0.025899537140503526), (42, 0.026205406757071614), (20, 0.02685900661163032), (47, 0.028178583132103086), (15, 0.031923392321914434), (38, 0.03208350110799074), (7, 0.03228544630110264), (39, 0.032337441109120846), (19, 0.03262859536334872), (51, 0.039947258308529854), (37, 0.040739682503044605), (9, 0.043401877861469984), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846378415823), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684599131346), (0, 0.06300980923697352), (52, 0.06433630175888538), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484647214413), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.45053430646657944), (18, 0.5108212903141975), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.013541154679842293
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 1 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 2 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 3 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best False lr [0.1]
training epoch 4 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 5 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 6 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 7 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 8 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 9 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 10 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.016470607602968812), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020046866964548826), (46, 0.020376993576064706), (41, 0.021723243407905102), (25, 0.021972603164613247), (23, 0.022379536414518952), (44, 0.023028336698189378), (48, 0.023771876003593206), (40, 0.023930813651531935), (45, 0.024178662104532123), (50, 0.02439029887318611), (21, 0.024924597702920437), (22, 0.025168767664581537), (42, 0.025188251631334424), (49, 0.02536152838729322), (24, 0.0258995380718261), (20, 0.02685900731012225), (47, 0.027363278437405825), (38, 0.03136561834253371), (15, 0.03192339185625315), (39, 0.03212768491357565), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.038935923017561436), (37, 0.04020634340122342), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095684925094247), (52, 0.0623285504989326), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4444201998412609), (18, 0.5108213052153587), (53, 0.8537911847233772)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366029396653), (28, 0.017088501015678048), (27, 0.018882446689531207), (43, 0.019595166202634573), (46, 0.02007358125410974), (41, 0.020961584988981485), (25, 0.02197260200046003), (23, 0.022379535483196378), (44, 0.02281495602801442), (48, 0.02312816074118018), (40, 0.02334519592113793), (50, 0.02375614643096924), (42, 0.023847302654758096), (45, 0.02387388050556183), (21, 0.024924598401412368), (49, 0.024960315320640802), (22, 0.0251687690615654), (24, 0.025899537140503526), (47, 0.026855543022975326), (20, 0.02685900731012225), (38, 0.030424014199525118), (39, 0.03151404461823404), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.03782488126307726), (37, 0.03936835192143917), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368643388152), (14, 0.0478366338647902), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.05892290314659476), (11, 0.05924912728369236), (52, 0.06033282168209553), (17, 0.06095685064792633), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4360685460269451), (18, 0.5108212977647781), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366029396653
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945716798306), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.01942429505288601), (48, 0.021467271959409118), (25, 0.021972603164613247), (44, 0.022026916034519672), (40, 0.022179660852998495), (42, 0.02220643009059131), (50, 0.022256128955632448), (23, 0.02237953571602702), (45, 0.022931481711566448), (49, 0.02370851207524538), (21, 0.024924598401412368), (22, 0.0251687690615654), (47, 0.02582913963124156), (24, 0.025899537606164813), (20, 0.026859007542952895), (38, 0.02895654644817114), (39, 0.029667827766388655), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.036009027156978846), (37, 0.03651238838210702), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846378415823), (52, 0.05610728869214654), (3, 0.057224276941269636), (13, 0.05892289848998189), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.41757645085453987), (18, 0.5108213052153587), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.018882447155192494), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.021832421887665987), (44, 0.021840530913323164), (50, 0.021869864081963897), (25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.022492847638204694), (49, 0.02312349807471037), (21, 0.02492459863424301), (47, 0.02506713871844113), (22, 0.025168768363073468), (24, 0.025899537606164813), (20, 0.02685900731012225), (38, 0.028114068554714322), (39, 0.029206909704953432), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03545433655381203), (37, 0.035977639723569155), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.054548466112464666), (52, 0.054696458391845226), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 0.9246633052825928)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018728360534), (27, 0.018882446689531207), (46, 0.019302030792459846), (42, 0.021432004403322935), (48, 0.02154484367929399), (40, 0.021832421189174056), (50, 0.021946269320324063), (25, 0.02197260269895196), (23, 0.02237953571602702), (49, 0.023006869945675135), (44, 0.02310851006768644), (45, 0.023535606684163213), (21, 0.024924597702920437), (22, 0.0251687690615654), (47, 0.025820446433499455), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.02811406971886754), (39, 0.02920690947212279), (15, 0.031923390459269285), (7, 0.03228544630110264), (19, 0.03262859722599387), (51, 0.03509148769080639), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.05332903191447258), (2, 0.05454846378415823), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 0.9678284451365471)]
computing accuracy for after removing block 41 . block score: 0.018849018728360534
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447388023138), (46, 0.019070088397711515), (48, 0.020678167697042227), (50, 0.021344397449865937), (40, 0.0218324214220047), (25, 0.021972602931782603), (42, 0.02198693947866559), (23, 0.022379535483196378), (49, 0.02253474830649793), (45, 0.023929918184876442), (44, 0.02405400387942791), (21, 0.024924597470089793), (22, 0.025168768130242825), (24, 0.02589953667484224), (47, 0.026043936843052506), (20, 0.026859007077291608), (38, 0.02811406902037561), (39, 0.02920690830796957), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.033794480841606855), (37, 0.03597763879224658), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.04783663526177406), (52, 0.05047609517350793), (2, 0.05454846378415823), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448399528861), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979227721691), (18, 0.5108213052153587), (53, 1.0278180241584778)]
computing accuracy for after removing block 27 . block score: 0.018882447388023138
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.7764 topk_dict {'top1': 0.7764} is_best False lr [0.1]
training epoch 1 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 2 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 3 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 4 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 5 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 6 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.1]
training epoch 7 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 8 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 9 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 10 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707274362445), (50, 0.020775061566382647), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.021910030161961913), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.02323931222781539), (45, 0.023585308343172073), (21, 0.024924598168581724), (47, 0.02507694880478084), (22, 0.02516876789741218), (24, 0.025899536907672882), (20, 0.02685900777578354), (38, 0.02718336065299809), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.032814261270686984), (37, 0.03542024362832308), (9, 0.04340188205242157), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.047836633399128914), (52, 0.04852363094687462), (2, 0.054548466578125954), (3, 0.05722427973523736), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300981109961867), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065233878791332), (18, 0.5108212903141975), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831161877140403), (40, 0.021085952874273062), (42, 0.0213696479331702), (25, 0.021972602233290672), (23, 0.02237953501753509), (49, 0.022536989534273744), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.02492459723725915), (22, 0.025168768363073468), (24, 0.025899536907672882), (47, 0.026583049213513732), (20, 0.026859006844460964), (38, 0.027183360420167446), (39, 0.02858075825497508), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03285081218928099), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04812479764223099), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.0213696479331702), (25, 0.021972602931782603), (23, 0.02237953501753509), (50, 0.022470063529908657), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.024924598168581724), (22, 0.025168768363073468), (49, 0.025234101805835962), (24, 0.025899537606164813), (47, 0.026583048747852445), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.03296921122819185), (37, 0.03542024362832308), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.05089045129716396), (2, 0.054548464715480804), (3, 0.05722427973523736), (13, 0.05892290361225605), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.2663909196853638)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284765331074595), (25, 0.021972602931782603), (23, 0.02237953618168831), (45, 0.02309831790626049), (44, 0.02424085815437138), (49, 0.024500868748873472), (21, 0.02492459863424301), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026519699255004525), (20, 0.026859006844460964), (38, 0.027183360187336802), (39, 0.02858075825497508), (15, 0.031923390459269285), (51, 0.03222084930166602), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03542024316266179), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.047836634796112776), (52, 0.04885757202282548), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095685064792633), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.3718615770339966)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.021972603164613247), (23, 0.022379535250365734), (45, 0.023761966032907367), (49, 0.024602338671684265), (44, 0.024712182115763426), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026220475090667605), (20, 0.02685900661163032), (38, 0.02718335995450616), (39, 0.028580758720636368), (51, 0.03127906681038439), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340187879279256), (52, 0.046101711224764585), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300981063395739), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065234027802944), (18, 0.5108213126659393), (53, 1.4178234189748764)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.023761965334415436), (49, 0.024602338671684265), (44, 0.024712180951610208), (21, 0.024924598168581724), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026220474392175674), (20, 0.02685900661163032), (38, 0.027183360420167446), (39, 0.02858075825497508), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.0334430206567049), (37, 0.03542024316266179), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.047493685968220234), (14, 0.04783663572743535), (52, 0.05265179369598627), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 1 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 2 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 4 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 5 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 6 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 7 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 8 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 9 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.967400)
finished training. finished 50 epochs. accuracy 0.9674 topk_dict {'top1': 0.9674}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.045092. All blocks and scores: [(49, 0.045091860461980104), (45, 0.04832645412534475), (44, 0.049563284032046795), (15, 0.052656395360827446), (20, 0.05477128550410271), (47, 0.05489500658586621), (23, 0.05594340851530433), (21, 0.05624921107664704), (19, 0.05749964248389006), (22, 0.057787083089351654), (7, 0.05814340803772211), (38, 0.0590838803909719), (51, 0.06019147578626871), (24, 0.06430238299071789), (39, 0.06558403838425875), (37, 0.06750380992889404), (52, 0.07247169595211744), (4, 0.07523301802575588), (6, 0.08760551828891039), (2, 0.09000264666974545), (9, 0.0945687172934413), (14, 0.09625023137778044), (0, 0.09942931588739157), (3, 0.10174636263400316), (17, 0.10282181389629841), (1, 0.10633822344243526), (11, 0.11204721126705408), (8, 0.11468962486833334), (13, 0.13383160717785358), (10, 0.14416266046464443), (12, 0.16035646572709084), (16, 0.17000244371592999), (5, 0.1983046680688858), (36, 0.6255028024315834), (18, 0.6888621374964714), (53, 0.957742340862751)]
computing accuracy for after removing block 49 . block score: 0.045091860461980104
removed block 49 current accuracy 0.9566 loss from initial  0.043399999999999994
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.048326. All blocks and scores: [(45, 0.048326453659683466), (44, 0.04956328542903066), (15, 0.05265639582648873), (20, 0.05477128783240914), (47, 0.0548950070515275), (23, 0.05594340804964304), (21, 0.056249210610985756), (19, 0.05749964341521263), (22, 0.05778708355501294), (7, 0.058143408969044685), (38, 0.05908387992531061), (24, 0.06430238019675016), (51, 0.0652454998344183), (39, 0.06558403838425875), (37, 0.06750380992889404), (4, 0.07523301802575588), (52, 0.07888736762106419), (6, 0.08760552108287811), (2, 0.0900026485323906), (9, 0.09456871822476387), (14, 0.09625022858381271), (0, 0.09942931775003672), (3, 0.10174635890871286), (17, 0.10282181203365326), (1, 0.10633822251111269), (11, 0.11204721312969923), (8, 0.11468962859362364), (13, 0.133831599727273), (10, 0.14416266232728958), (12, 0.16035646945238113), (16, 0.17000244930386543), (5, 0.19830467738211155), (36, 0.6255028247833252), (18, 0.6888621300458908), (53, 1.0552406162023544)]
computing accuracy for after removing block 45 . block score: 0.048326453659683466
removed block 45 current accuracy 0.9432 loss from initial  0.05679999999999996
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.049563. All blocks and scores: [(44, 0.049563284032046795), (15, 0.05265639629215002), (20, 0.054771287366747856), (23, 0.05594340758398175), (21, 0.05624921107664704), (19, 0.05749964015558362), (22, 0.05778708355501294), (7, 0.05814340943470597), (38, 0.059083879459649324), (47, 0.06058543222025037), (24, 0.06430238019675016), (51, 0.065026193857193), (39, 0.06558403745293617), (37, 0.0675038080662489), (4, 0.07523301709443331), (52, 0.08015898615121841), (6, 0.08760551922023296), (2, 0.09000265039503574), (9, 0.09456872195005417), (14, 0.09625022858381271), (0, 0.09942931775003672), (3, 0.10174636263400316), (17, 0.10282181110233068), (1, 0.10633822157979012), (11, 0.11204721499234438), (8, 0.11468962766230106), (13, 0.13383160158991814), (10, 0.14416266605257988), (12, 0.16035647131502628), (16, 0.17000244744122028), (5, 0.19830467365682125), (36, 0.6255028247833252), (18, 0.6888621300458908), (53, 1.1311353594064713)]
computing accuracy for after removing block 44 . block score: 0.049563284032046795
removed block 44 current accuracy 0.9304 loss from initial  0.0696
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 15, with score 0.052656. All blocks and scores: [(15, 0.05265639675781131), (20, 0.05477128829807043), (23, 0.05594340758398175), (21, 0.056249212473630905), (19, 0.05749964155256748), (22, 0.05778708215802908), (7, 0.0581434085033834), (38, 0.059083881322294474), (24, 0.06430238112807274), (47, 0.06456570699810982), (51, 0.06523758172988892), (39, 0.06558403838425875), (37, 0.06750380992889404), (4, 0.07523301895707846), (52, 0.08074726723134518), (6, 0.08760552201420069), (2, 0.09000264666974545), (9, 0.09456871915608644), (14, 0.09625022765249014), (0, 0.09942931681871414), (3, 0.10174635890871286), (17, 0.10282181110233068), (1, 0.10633822157979012), (11, 0.11204721592366695), (8, 0.11468962766230106), (13, 0.13383160345256329), (10, 0.14416266046464443), (12, 0.1603564564138651), (16, 0.17000244557857513), (5, 0.19830466993153095), (36, 0.6255028247833252), (18, 0.6888621523976326), (53, 1.1836946159601212)]
computing accuracy for after removing block 15 . block score: 0.05265639675781131
removed block 15 current accuracy 0.923 loss from initial  0.07699999999999996
since last training loss: 0.044399999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.051807. All blocks and scores: [(20, 0.05180685967206955), (21, 0.05297147762030363), (23, 0.053346510510891676), (22, 0.054496259428560734), (19, 0.057161040138453245), (7, 0.0581434085033834), (38, 0.05902561778202653), (24, 0.061201948672533035), (47, 0.06454569566994905), (39, 0.06483523454517126), (51, 0.065044772811234), (37, 0.06716999132186174), (4, 0.07523301709443331), (52, 0.07968799211084843), (6, 0.08760551642626524), (2, 0.0900026485323906), (9, 0.09456872008740902), (14, 0.09625022765249014), (0, 0.09942931681871414), (3, 0.10174635797739029), (1, 0.10633822157979012), (17, 0.1107998052611947), (11, 0.1120472140610218), (8, 0.11468962673097849), (13, 0.13383160717785358), (10, 0.14416266232728958), (12, 0.16035646572709084), (16, 0.1888655573129654), (5, 0.19830467365682125), (36, 0.6109596341848373), (18, 0.6700616329908371), (53, 1.2097465693950653)]
computing accuracy for after removing block 20 . block score: 0.05180685967206955
removed block 20 current accuracy 0.9122 loss from initial  0.08779999999999999
since last training loss: 0.05520000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.051440. All blocks and scores: [(23, 0.05143988644704223), (21, 0.053676055278629065), (22, 0.053985027596354485), (19, 0.05716104153543711), (7, 0.05814340757206082), (38, 0.05831397324800491), (24, 0.058509246446192265), (47, 0.061806976329535246), (51, 0.0633822102099657), (39, 0.0647758711129427), (37, 0.07105462718755007), (4, 0.07523301709443331), (52, 0.07622857764363289), (6, 0.08760552015155554), (2, 0.09000264946371317), (9, 0.0945687210187316), (14, 0.09625022765249014), (0, 0.09942931868135929), (3, 0.10174635797739029), (1, 0.10633822157979012), (17, 0.11079980805516243), (11, 0.11204721126705408), (8, 0.11468962859362364), (13, 0.13383160717785358), (10, 0.14416266046464443), (12, 0.16035647131502628), (16, 0.18886556662619114), (5, 0.1983046755194664), (36, 0.6139413490891457), (18, 0.6700616478919983), (53, 1.2081382125616074)]
computing accuracy for after removing block 23 . block score: 0.05143988644704223
removed block 23 current accuracy 0.8896 loss from initial  0.11040000000000005
since last training loss: 0.07780000000000009 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 21, with score 0.053676. All blocks and scores: [(21, 0.05367605248466134), (22, 0.05398502852767706), (24, 0.05605084588751197), (19, 0.057161040138453245), (7, 0.05814340757206082), (38, 0.05857634823769331), (47, 0.06061937427148223), (51, 0.062733159866184), (39, 0.06596862431615591), (4, 0.07523301802575588), (52, 0.07575565669685602), (37, 0.07655608002096415), (6, 0.08760552201420069), (2, 0.09000264666974545), (9, 0.09456872474402189), (14, 0.09625022765249014), (0, 0.09942931775003672), (3, 0.10174636077135801), (1, 0.10633822530508041), (17, 0.11079980432987213), (11, 0.1120472103357315), (8, 0.11468962859362364), (13, 0.13383160717785358), (10, 0.14416266605257988), (12, 0.16035646200180054), (16, 0.18886556290090084), (5, 0.1983046643435955), (36, 0.631551668047905), (18, 0.6700616329908371), (53, 1.2135516554117203)]
computing accuracy for after removing block 21 . block score: 0.05367605248466134
removed block 21 current accuracy 0.8632 loss from initial  0.13680000000000003
since last training loss: 0.10420000000000007 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.049505. All blocks and scores: [(22, 0.04950493760406971), (24, 0.050460562109947205), (38, 0.05528147565200925), (19, 0.05716103920713067), (47, 0.05721151363104582), (7, 0.05814340803772211), (51, 0.06014401139691472), (39, 0.06384095828980207), (52, 0.06700326967984438), (37, 0.07325887307524681), (4, 0.07523301802575588), (6, 0.08760551828891039), (2, 0.09000265039503574), (9, 0.09456872008740902), (14, 0.09625022951513529), (0, 0.09942931681871414), (3, 0.10174635890871286), (1, 0.10633821878582239), (17, 0.110799808986485), (11, 0.11204721126705408), (8, 0.11468962766230106), (13, 0.13383160531520844), (10, 0.14416265860199928), (12, 0.16035646200180054), (16, 0.188865564763546), (5, 0.1983046680688858), (36, 0.6017363965511322), (18, 0.6700616478919983), (53, 1.2720228433609009)]
computing accuracy for after removing block 22 . block score: 0.04950493760406971
removed block 22 current accuracy 0.822 loss from initial  0.17800000000000005
since last training loss: 0.14540000000000008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.047250. All blocks and scores: [(24, 0.047249792609363794), (47, 0.05338564654812217), (38, 0.054201615042984486), (19, 0.05716103874146938), (51, 0.05758102471008897), (7, 0.05814340803772211), (39, 0.0636002579703927), (52, 0.06374085694551468), (4, 0.07523301988840103), (37, 0.07800285425037146), (6, 0.08760551922023296), (2, 0.0900026485323906), (9, 0.09456872195005417), (14, 0.09625022858381271), (0, 0.09942931961268187), (3, 0.10174636263400316), (1, 0.10633821878582239), (17, 0.110799808986485), (11, 0.1120472103357315), (8, 0.11468962859362364), (13, 0.13383160531520844), (10, 0.14416266418993473), (12, 0.16035646758973598), (16, 0.18886555917561054), (5, 0.19830466620624065), (36, 0.6083019822835922), (18, 0.6700616478919983), (53, 1.2952548414468765)]
computing accuracy for after removing block 24 . block score: 0.047249792609363794
removed block 24 current accuracy 0.784 loss from initial  0.21599999999999997
training start
training epoch 0 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best True lr [0.1]
training epoch 1 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.1]
training epoch 2 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 3 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 4 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 5 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 6 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 7 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.1]
training epoch 8 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 9 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
