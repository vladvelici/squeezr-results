start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996380798519), (32, 0.009233050630427897), (30, 0.010039401124231517), (31, 0.010361599968746305), (34, 0.013312276103533804), (29, 0.013541154679842293), (35, 0.01601846213452518), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020232456969097257), (46, 0.02104454068467021), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.02282664831727743), (44, 0.023395079420879483), (40, 0.024025025544688106), (45, 0.024295411072671413), (21, 0.024924598168581724), (22, 0.0251687690615654), (48, 0.025341259548440576), (24, 0.02589953667484224), (50, 0.026409973157569766), (42, 0.0266741004306823), (20, 0.02685900731012225), (49, 0.02703716396354139), (47, 0.029306469252333045), (39, 0.031570712802931666), (38, 0.03163787070661783), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.0379602606408298), (51, 0.04173417203128338), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846424981952), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (52, 0.06862937472760677), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049758136272), (5, 0.10667387023568153), (36, 0.43758000805974007), (18, 0.5108213126659393), (53, 0.8211488798260689)]
computing accuracy for after removing block 33 . block score: 0.007061996380798519
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.01003940065857023), (31, 0.010361600434407592), (34, 0.01313394692260772), (29, 0.01354115444701165), (26, 0.01603759080171585), (35, 0.016169288894161582), (28, 0.01772867515683174), (27, 0.019127049017697573), (43, 0.02007247693836689), (46, 0.020731385564431548), (25, 0.021972602931782603), (41, 0.02234709239564836), (23, 0.022379535250365734), (44, 0.023235687287524343), (40, 0.023841066984459758), (45, 0.023965542437508702), (48, 0.024917915696278214), (21, 0.024924598168581724), (22, 0.025168768363073468), (50, 0.025840813061222434), (24, 0.025899537140503526), (42, 0.026315323309972882), (49, 0.02665567514486611), (20, 0.02685900777578354), (47, 0.028728798730298877), (39, 0.03131764312274754), (38, 0.031380363274365664), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628594897687435), (37, 0.038025843910872936), (51, 0.041223939042538404), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663246780634), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095685018226504), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.06745154969394207), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.43538709357380867), (18, 0.5108212977647781), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.01276523305568844), (29, 0.013541154330596328), (35, 0.015992750879377127), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.02007513213902712), (46, 0.020841405959799886), (25, 0.021972602466121316), (41, 0.022319766925647855), (23, 0.022379535948857665), (44, 0.023154050577431917), (40, 0.02388568432070315), (45, 0.024071690160781145), (48, 0.024877465097233653), (21, 0.024924598401412368), (22, 0.025168768130242825), (50, 0.02569117769598961), (24, 0.025899536907672882), (42, 0.026123747928068042), (49, 0.026479421416297555), (20, 0.026859006844460964), (47, 0.02869313210248947), (38, 0.031236795475706458), (39, 0.0312952920794487), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03837669035419822), (51, 0.04111403413116932), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685204491019), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.06700456142425537), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.43640001863241196), (18, 0.5108212977647781), (53, 0.828934907913208)]
computing accuracy for after removing block 30 . block score: 0.010039400774985552
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.01238783705048263), (29, 0.013541154330596328), (35, 0.01600809581577778), (26, 0.01603759080171585), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.02070444473065436), (25, 0.021972602233290672), (41, 0.022253197384998202), (23, 0.02237953571602702), (44, 0.023267761571332812), (40, 0.02401388017460704), (45, 0.02409299253486097), (48, 0.024665280478075147), (21, 0.024924597702920437), (22, 0.025168768828734756), (50, 0.02545973425731063), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.026287755696102977), (20, 0.026859006844460964), (47, 0.028363423189148307), (38, 0.031047646887600422), (39, 0.03138077212497592), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.03897124528884888), (51, 0.040756203699857), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.059249131474643946), (17, 0.060956849716603756), (0, 0.06300980783998966), (52, 0.06586316134780645), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4389924667775631), (18, 0.5108212977647781), (53, 0.8391561880707741)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489620014093816), (29, 0.013541154912672937), (26, 0.016037590336054564), (35, 0.016057362547144294), (28, 0.017728674924001098), (27, 0.01912704878486693), (43, 0.02004934987053275), (46, 0.02055298676714301), (25, 0.021972602931782603), (41, 0.02206748421303928), (23, 0.02237953571602702), (44, 0.022979131899774075), (40, 0.02385834720917046), (45, 0.02412470313720405), (48, 0.024386123288422823), (21, 0.024924598168581724), (50, 0.02504224143922329), (22, 0.025168768828734756), (42, 0.025414507370442152), (49, 0.025842698756605387), (24, 0.02589953667484224), (20, 0.026859006844460964), (47, 0.028050734428688884), (38, 0.031040058936923742), (39, 0.031500803772360086), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03911284962669015), (51, 0.04024627385661006), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663526177406), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.0592491258867085), (17, 0.06095685018226504), (0, 0.06300980830565095), (52, 0.06486208830028772), (1, 0.06676734052598476), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4381278231739998), (18, 0.5108212903141975), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489620014093816
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154912672937), (26, 0.016037590336054564), (35, 0.016653420636430383), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.021972602233290672), (23, 0.022379535250365734), (41, 0.02245262893848121), (44, 0.023364474531263113), (48, 0.024290355620905757), (45, 0.02443871321156621), (40, 0.02447055815719068), (21, 0.02492459723725915), (50, 0.025042172987014055), (22, 0.02516876789741218), (49, 0.025875969557091594), (24, 0.025899537606164813), (42, 0.026205406989902258), (20, 0.026859006145969033), (47, 0.028178583132103086), (15, 0.03192339139059186), (38, 0.03208350110799074), (7, 0.03228544630110264), (39, 0.032337441109120846), (19, 0.03262859536334872), (51, 0.039947257842868567), (37, 0.04073968296870589), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.04783663246780634), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980923697352), (52, 0.06433630082756281), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.45053429901599884), (18, 0.5108212977647781), (53, 0.8443200886249542)]
computing accuracy for after removing block 29 . block score: 0.013541154912672937
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470608301460743), (28, 0.017728675855323672), (27, 0.019127047853544354), (43, 0.020046867430210114), (46, 0.020376993343234062), (41, 0.021723243175074458), (25, 0.02197260200046003), (23, 0.022379534784704447), (44, 0.02302833693102002), (48, 0.02377187623642385), (40, 0.023930813185870647), (45, 0.024178662337362766), (50, 0.02439029817469418), (21, 0.02492459793575108), (22, 0.025168768828734756), (42, 0.025188251165673137), (49, 0.025361528154462576), (24, 0.02589953667484224), (20, 0.026859006378799677), (47, 0.027363280532881618), (38, 0.03136561973951757), (15, 0.03192339139059186), (39, 0.03212768491357565), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03893592348322272), (37, 0.04020634479820728), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663200214505), (2, 0.05454846378415823), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956848319619894), (52, 0.06232854910194874), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4444202072918415), (18, 0.5108213052153587), (53, 0.8537912368774414)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366029396653), (28, 0.01708850055001676), (27, 0.018882446456700563), (43, 0.01959516596980393), (46, 0.02007358055561781), (41, 0.020961584988981485), (25, 0.021972602931782603), (23, 0.022379535948857665), (44, 0.022814956959336996), (48, 0.023128160974010825), (40, 0.02334519592113793), (50, 0.02375614643096924), (42, 0.02384730218909681), (45, 0.023873880272731185), (21, 0.0249245990999043), (49, 0.024960315553471446), (22, 0.0251687690615654), (24, 0.025899537140503526), (47, 0.02685554255731404), (20, 0.026859007077291608), (38, 0.030424014665186405), (39, 0.03151404391974211), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427926957607), (13, 0.058922900818288326), (11, 0.05924912868067622), (52, 0.060332820285111666), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.4360685534775257), (18, 0.5108213052153587), (53, 0.8749377131462097)]
computing accuracy for after removing block 35 . block score: 0.015597366029396653
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.018555945716798306), (27, 0.018882447155192494), (46, 0.01916008465923369), (41, 0.019424294820055366), (48, 0.02146727265790105), (25, 0.021972602466121316), (44, 0.02202691650018096), (40, 0.02217966108582914), (42, 0.022206430323421955), (50, 0.022256128955632448), (23, 0.02237953571602702), (45, 0.02293148124590516), (49, 0.02370851207524538), (21, 0.024924597470089793), (22, 0.02516876789741218), (47, 0.02582913963124156), (24, 0.02589953737333417), (20, 0.026859007542952895), (38, 0.02895654598250985), (39, 0.02966782869771123), (15, 0.03192339092493057), (7, 0.0322854476980865), (19, 0.03262859582901001), (51, 0.03600902669131756), (37, 0.036512387450784445), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.04783663433045149), (2, 0.054548466112464666), (52, 0.056107287760823965), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.41757645085453987), (18, 0.5108213052153587), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140303203836083), (46, 0.01865610247477889), (41, 0.018849018029868603), (27, 0.018882447155192494), (48, 0.020903734024614096), (42, 0.02143200463615358), (40, 0.021832421189174056), (44, 0.02184053068049252), (50, 0.021869864081963897), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.022492848336696625), (49, 0.023123497143387794), (21, 0.024924597702920437), (47, 0.025067139184102416), (22, 0.025168767664581537), (24, 0.025899537140503526), (20, 0.02685900777578354), (38, 0.028114069486036897), (39, 0.0292069090064615), (15, 0.031923392321914434), (7, 0.03228544816374779), (19, 0.0326285962946713), (51, 0.0354543374851346), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846564680338), (52, 0.05469645652920008), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832509428263), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.018140303203836083
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882447155192494), (46, 0.019302030326798558), (42, 0.02143200417049229), (48, 0.02154484298080206), (40, 0.021832420956343412), (50, 0.021946269553154707), (25, 0.02197260269895196), (23, 0.022379535948857665), (49, 0.02300687017850578), (44, 0.023108509834855795), (45, 0.0235356071498245), (21, 0.024924597470089793), (22, 0.0251687690615654), (47, 0.025820446433499455), (24, 0.02589953620918095), (20, 0.026859008707106113), (38, 0.028114069486036897), (39, 0.029206908540800214), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.035091488622128963), (37, 0.03597763832658529), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05332902818918228), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.058922900818288326), (11, 0.059249126352369785), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049665004015), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9678284376859665)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 1 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 2 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 3 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 4 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.1]
training epoch 7 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 8 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 10 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.019070089096203446), (48, 0.020678168395534158), (50, 0.021344397217035294), (40, 0.02183242072351277), (25, 0.021972602466121316), (42, 0.021986939944326878), (23, 0.022379534784704447), (49, 0.022534748539328575), (45, 0.023929916555061936), (44, 0.024054004345089197), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026043936843052506), (20, 0.02685900661163032), (38, 0.028114068554714322), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03379447944462299), (37, 0.03597763832658529), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.050476094242185354), (2, 0.05454846518114209), (3, 0.05722427600994706), (13, 0.058922900818288326), (11, 0.05924913054332137), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 1.0278180092573166)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707740023732), (50, 0.020775062264874578), (40, 0.02108595333993435), (42, 0.0213696479331702), (49, 0.021910030161961913), (25, 0.02197260269895196), (23, 0.022379535250365734), (44, 0.023239311296492815), (45, 0.023585308576002717), (21, 0.024924597702920437), (47, 0.025076947640627623), (22, 0.025168767431750894), (24, 0.025899537606164813), (20, 0.02685900777578354), (38, 0.027183360885828733), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.032814261270686984), (37, 0.03542024362832308), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.048523630015552044), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.05892290314659476), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980783998966), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065233953297138), (18, 0.5108213126659393), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327561302110553), (50, 0.020831161877140403), (40, 0.021085953572764993), (42, 0.02136964723467827), (25, 0.021972602233290672), (23, 0.022379535250365734), (49, 0.022536989534273744), (44, 0.023239312460646033), (45, 0.02358530880883336), (21, 0.02492459723725915), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.0328508117236197), (37, 0.03542024455964565), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836633399128914), (52, 0.04812479950487614), (2, 0.05454846424981952), (3, 0.05722427973523736), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734052598476), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327561302110553
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647467508912), (25, 0.021972602466121316), (23, 0.022379535483196378), (50, 0.022470062831416726), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.024924597702920437), (22, 0.025168768130242825), (49, 0.025234101805835962), (24, 0.02589953667484224), (47, 0.026583049446344376), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.028580759186297655), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.032969210762530565), (37, 0.035420244093984365), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.05089045036584139), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108212903141975), (53, 1.266390934586525)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.021284766029566526), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.024500869447365403), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.02651969948783517), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339185625315), (51, 0.03222084930166602), (7, 0.03228544583544135), (19, 0.032628596760332584), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.04885757341980934), (2, 0.0545484684407711), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249126352369785), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387582361698), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658070251346), (25, 0.021972603164613247), (23, 0.022379535483196378), (45, 0.02376196556724608), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924597470089793), (22, 0.0251687690615654), (24, 0.025899537140503526), (47, 0.026220474857836962), (20, 0.02685900661163032), (38, 0.027183360420167446), (39, 0.0285807594191283), (51, 0.031279068207368255), (15, 0.03192339185625315), (7, 0.032285445369780064), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.043401879258453846), (52, 0.0461017107591033), (6, 0.04660903289914131), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.05892289848998189), (11, 0.05924912681803107), (17, 0.060956851579248905), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.4178234189748764)]
computing accuracy for after removing block 50 . block score: 0.021202658070251346
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.023761966498568654), (49, 0.02460233843885362), (44, 0.02471218165010214), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.02589953737333417), (47, 0.026220474857836962), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03344302158802748), (37, 0.03542024316266179), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.047493682242929935), (14, 0.04783663293346763), (52, 0.05265179416164756), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.05924912681803107), (17, 0.06095685111358762), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034483902156353), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.6287681460380554)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535948857665), (45, 0.023382084211334586), (49, 0.023860316956415772), (44, 0.023948066867887974), (21, 0.02492459863424301), (22, 0.025168767664581537), (47, 0.025361904175952077), (24, 0.025899536907672882), (38, 0.026533205062150955), (20, 0.026859006844460964), (39, 0.028472806327044964), (15, 0.03192339278757572), (7, 0.03228544723242521), (51, 0.032473248429596424), (19, 0.0326285962946713), (37, 0.034854767844080925), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05042571108788252), (2, 0.05454846564680338), (3, 0.05722428020089865), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.3996613621711731), (18, 0.5108212977647781), (53, 1.6311722546815872)]
computing accuracy for after removing block 23 . block score: 0.022379535948857665
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.02356328465975821), (45, 0.02358233160339296), (49, 0.023707157699391246), (24, 0.024551384150981903), (47, 0.024688830133527517), (21, 0.02492459793575108), (22, 0.025168768595904112), (38, 0.026409979443997145), (20, 0.026859007542952895), (39, 0.028432969469577074), (15, 0.03192339185625315), (7, 0.03228544723242521), (51, 0.03235368151217699), (19, 0.03262859536334872), (37, 0.035908338613808155), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.048856368754059076), (2, 0.05454846564680338), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.05924913054332137), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.40237871184945107), (18, 0.5108212977647781), (53, 1.617948278784752)]
computing accuracy for after removing block 44 . block score: 0.02356328465975821
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.02324675233103335), (49, 0.02354176272638142), (24, 0.024551384383812547), (21, 0.024924598168581724), (22, 0.02516876719892025), (47, 0.025985259329900146), (38, 0.026409979443997145), (20, 0.02685900731012225), (39, 0.028432969003915787), (15, 0.03192339139059186), (51, 0.03204912506043911), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.035908338613808155), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (52, 0.0481629204005003), (2, 0.05454846424981952), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049665004015), (5, 0.10667387116700411), (36, 0.40237870439887047), (18, 0.5108213052153587), (53, 1.7482215017080307)]
computing accuracy for after removing block 45 . block score: 0.02324675233103335
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.0241570514626801), (24, 0.024551384383812547), (21, 0.024924597004428506), (22, 0.025168768363073468), (38, 0.026409979443997145), (20, 0.026859007542952895), (47, 0.027429412119090557), (39, 0.028432970168069005), (51, 0.03189300326630473), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.035908338613808155), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663526177406), (52, 0.049079653806984425), (2, 0.054548464715480804), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980783998966), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.40237871184945107), (18, 0.5108213052153587), (53, 1.8955670297145844)]
computing accuracy for after removing block 49 . block score: 0.0241570514626801
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.1]
training epoch 1 val accuracy 0.776 topk_dict {'top1': 0.776} is_best False lr [0.1]
training epoch 2 val accuracy 0.805 topk_dict {'top1': 0.805} is_best False lr [0.1]
training epoch 3 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.1]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 5 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 6 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 7 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 8 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.1]
training epoch 9 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
loading model_best from epoch 19 (acc 0.960400)
finished training. finished 50 epochs. accuracy 0.9604 topk_dict {'top1': 0.9604}
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.059319. All blocks and scores: [(20, 0.059318913612514734), (19, 0.05952324206009507), (21, 0.06125954631716013), (15, 0.06382861267775297), (38, 0.06425139587372541), (7, 0.06516454741358757), (22, 0.0675711240619421), (51, 0.06817496661096811), (39, 0.07166770473122597), (47, 0.07187890727072954), (52, 0.07226919010281563), (37, 0.0727006969973445), (4, 0.07587655168026686), (24, 0.07699756231158972), (9, 0.08996616117656231), (6, 0.09502936899662018), (2, 0.09945000614970922), (0, 0.10036712046712637), (17, 0.10166949685662985), (14, 0.1023362735286355), (3, 0.10436835139989853), (11, 0.10715106874704361), (1, 0.11663924623280764), (13, 0.1205300884321332), (8, 0.12547582108527422), (10, 0.15345722623169422), (12, 0.15851589664816856), (16, 0.1729510836303234), (5, 0.1919800005853176), (36, 0.5578794777393341), (18, 0.672000914812088), (53, 1.0513016432523727)]
computing accuracy for after removing block 20 . block score: 0.059318913612514734
removed block 20 current accuracy 0.9508 loss from initial  0.04920000000000002
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 19, with score 0.059523. All blocks and scores: [(19, 0.05952324206009507), (21, 0.0601530154235661), (38, 0.062144177965819836), (15, 0.06382861454039812), (22, 0.06403483636677265), (7, 0.06516454555094242), (51, 0.0658492911607027), (47, 0.06891296803951263), (52, 0.0698807267472148), (39, 0.07088567037135363), (24, 0.07341626286506653), (37, 0.07478767354041338), (4, 0.07587655168026686), (9, 0.08996616117656231), (6, 0.09502936899662018), (2, 0.09945000614970922), (0, 0.10036712232977152), (17, 0.10166949965059757), (14, 0.10233627166599035), (3, 0.10436834674328566), (11, 0.10715106315910816), (1, 0.11663924623280764), (13, 0.12053008563816547), (8, 0.12547582015395164), (10, 0.15345722623169422), (12, 0.15851590037345886), (16, 0.1729510799050331), (5, 0.1919800005853176), (36, 0.5490555465221405), (18, 0.6720009073615074), (53, 1.029713287949562)]
computing accuracy for after removing block 19 . block score: 0.05952324206009507
removed block 19 current accuracy 0.942 loss from initial  0.05800000000000005
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.059752. All blocks and scores: [(38, 0.059752182103693485), (21, 0.06124520907178521), (22, 0.06125764595344663), (15, 0.06382861267775297), (51, 0.06466451147571206), (7, 0.065164546482265), (52, 0.06651661638170481), (47, 0.06656510755419731), (39, 0.07056842464953661), (24, 0.07072426378726959), (4, 0.07587655168026686), (37, 0.07852033339440823), (9, 0.08996615931391716), (6, 0.09502937272191048), (2, 0.09945000428706408), (0, 0.10036712419241667), (17, 0.1016694949939847), (14, 0.10233627259731293), (3, 0.10436834767460823), (11, 0.10715106595307589), (1, 0.11663924716413021), (13, 0.1205300847068429), (8, 0.12547581922262907), (10, 0.15345722623169422), (12, 0.15851590037345886), (16, 0.1729510873556137), (5, 0.19198000617325306), (36, 0.5448384806513786), (18, 0.672000914812088), (53, 0.9908206760883331)]
computing accuracy for after removing block 38 . block score: 0.059752182103693485
removed block 38 current accuracy 0.9314 loss from initial  0.0686
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 21, with score 0.061245. All blocks and scores: [(21, 0.06124520814046264), (22, 0.061257646419107914), (51, 0.06353017315268517), (15, 0.06382861081510782), (7, 0.06516454461961985), (52, 0.06526295281946659), (47, 0.0685596102848649), (24, 0.07072426658123732), (4, 0.07587655168026686), (37, 0.07852033525705338), (39, 0.08190304134041071), (9, 0.08996615931391716), (6, 0.09502937085926533), (2, 0.09945000428706408), (0, 0.10036712419241667), (17, 0.101669498719275), (14, 0.10233627166599035), (3, 0.10436834953725338), (11, 0.10715106874704361), (1, 0.11663925275206566), (13, 0.12053008284419775), (8, 0.1254758220165968), (10, 0.15345722436904907), (12, 0.1585158985108137), (16, 0.1729510799050331), (5, 0.1919800080358982), (36, 0.5448384881019592), (18, 0.6720009222626686), (53, 1.0118421837687492)]
computing accuracy for after removing block 21 . block score: 0.06124520814046264
removed block 21 current accuracy 0.911 loss from initial  0.08899999999999997
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 22, with score 0.055729. All blocks and scores: [(22, 0.05572947859764099), (52, 0.058744250331074), (51, 0.05905253812670708), (24, 0.06315898755565286), (15, 0.06382861360907555), (47, 0.06435369979590178), (7, 0.06516454555094242), (37, 0.07561704330146313), (4, 0.075876553542912), (39, 0.07809289544820786), (9, 0.08996615745127201), (6, 0.09502936899662018), (2, 0.09945000521838665), (0, 0.10036712046712637), (17, 0.10166949965059757), (14, 0.1023362735286355), (3, 0.10436834767460823), (11, 0.10715106502175331), (1, 0.11663924250751734), (13, 0.1205300847068429), (8, 0.12547581549733877), (10, 0.15345722250640392), (12, 0.15851590037345886), (16, 0.17295108921825886), (5, 0.1919800043106079), (36, 0.5132783129811287), (18, 0.672000914812088), (53, 0.9721711128950119)]
computing accuracy for after removing block 22 . block score: 0.05572947859764099
removed block 22 current accuracy 0.8808 loss from initial  0.11919999999999997
since last training loss: 0.0796 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.055262. All blocks and scores: [(52, 0.05526178190484643), (51, 0.056840814650058746), (47, 0.05988265248015523), (24, 0.06355444341897964), (15, 0.0638286117464304), (7, 0.06516454368829727), (4, 0.07587655074894428), (39, 0.07800738047808409), (37, 0.08392911590635777), (9, 0.08996615838259459), (6, 0.09502936899662018), (2, 0.0994500033557415), (0, 0.10036712232977152), (17, 0.101669498719275), (14, 0.10233627166599035), (3, 0.10436835046857595), (11, 0.10715106874704361), (1, 0.11663924716413021), (13, 0.12053008563816547), (8, 0.12547581735998392), (10, 0.15345721878111362), (12, 0.15851589664816856), (16, 0.17295108176767826), (5, 0.1919800080358982), (36, 0.5275675505399704), (18, 0.672000914812088), (53, 0.9244944825768471)]
computing accuracy for after removing block 52 . block score: 0.05526178190484643
removed block 52 current accuracy 0.8338 loss from initial  0.16620000000000001
since last training loss: 0.12660000000000005 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.056841. All blocks and scores: [(51, 0.05684081558138132), (47, 0.05988265387713909), (24, 0.06355444062501192), (15, 0.0638286117464304), (7, 0.065164546482265), (4, 0.07587655168026686), (39, 0.07800737954676151), (37, 0.08392911218106747), (9, 0.08996616117656231), (6, 0.09502936992794275), (2, 0.0994500070810318), (0, 0.10036712046712637), (17, 0.101669498719275), (14, 0.1023362735286355), (3, 0.10436834953725338), (11, 0.10715107060968876), (1, 0.11663924902677536), (13, 0.12053008750081062), (8, 0.12547581735998392), (10, 0.15345722809433937), (12, 0.15851590037345886), (16, 0.17295108549296856), (5, 0.1919800117611885), (36, 0.5275675430893898), (18, 0.6720009222626686), (53, 0.8612703904509544)]
computing accuracy for after removing block 51 . block score: 0.05684081558138132
removed block 51 current accuracy 0.7786 loss from initial  0.22140000000000004
since last training loss: 0.18180000000000007 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 47, with score 0.059883. All blocks and scores: [(47, 0.05988265201449394), (24, 0.06355444248765707), (15, 0.06382861360907555), (7, 0.065164546482265), (4, 0.07587655168026686), (39, 0.07800737954676151), (37, 0.08392911031842232), (9, 0.08996616210788488), (6, 0.09502936992794275), (2, 0.0994500070810318), (0, 0.1003671232610941), (17, 0.101669498719275), (14, 0.10233627632260323), (3, 0.10436834767460823), (11, 0.10715106688439846), (1, 0.11663924623280764), (13, 0.1205300847068429), (8, 0.12547582108527422), (10, 0.15345722623169422), (12, 0.158515902236104), (16, 0.17295108176767826), (5, 0.1919800080358982), (36, 0.5275675281882286), (18, 0.6720009073615074), (53, 0.9390338882803917)]
computing accuracy for after removing block 47 . block score: 0.05988265201449394
removed block 47 current accuracy 0.7064 loss from initial  0.29359999999999997
since last training loss: 0.254 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 24, with score 0.063554. All blocks and scores: [(24, 0.0635544415563345), (15, 0.0638286117464304), (7, 0.06516454555094242), (4, 0.075876553542912), (39, 0.07800738047808409), (37, 0.08392911218106747), (9, 0.08996616210788488), (6, 0.09502936713397503), (2, 0.0994500033557415), (0, 0.10036712419241667), (17, 0.1016694949939847), (14, 0.10233627445995808), (3, 0.1043683486059308), (11, 0.10715106688439846), (1, 0.11663924623280764), (13, 0.12053008656948805), (8, 0.12547581922262907), (10, 0.15345722436904907), (12, 0.15851590037345886), (16, 0.17295108176767826), (5, 0.1919799968600273), (36, 0.5275675505399704), (18, 0.6720009222626686), (53, 1.0036419779062271)]
computing accuracy for after removing block 24 . block score: 0.0635544415563345
removed block 24 current accuracy 0.664 loss from initial  0.33599999999999997
since last training loss: 0.2964 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 15, with score 0.063829. All blocks and scores: [(15, 0.06382861360907555), (7, 0.06516454834491014), (4, 0.07587655168026686), (39, 0.07589144166558981), (37, 0.08882125932723284), (9, 0.08996616024523973), (6, 0.09502937085926533), (2, 0.09945000614970922), (0, 0.10036712605506182), (17, 0.10166950058192015), (14, 0.10233627445995808), (3, 0.10436834953725338), (11, 0.10715106874704361), (1, 0.11663925088942051), (13, 0.12053008563816547), (8, 0.12547581549733877), (10, 0.15345722250640392), (12, 0.1585158985108137), (16, 0.17295108549296856), (5, 0.1919799968600273), (36, 0.539747953414917), (18, 0.6720009073615074), (53, 0.9560050144791603)]
computing accuracy for after removing block 15 . block score: 0.06382861360907555
removed block 15 current accuracy 0.6338 loss from initial  0.36619999999999997
since last training loss: 0.3266 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 7, with score 0.065165. All blocks and scores: [(7, 0.06516454555094242), (39, 0.07432974502444267), (4, 0.07587654888629913), (37, 0.08928288891911507), (9, 0.08996615931391716), (6, 0.09502936992794275), (2, 0.09945000521838665), (0, 0.10036712512373924), (14, 0.10233627259731293), (3, 0.1043683486059308), (17, 0.10601590387523174), (11, 0.10715106874704361), (1, 0.11663924530148506), (13, 0.1205300847068429), (8, 0.12547581735998392), (10, 0.15345722250640392), (12, 0.15851590037345886), (5, 0.1919800080358982), (16, 0.19716362468898296), (36, 0.53584223985672), (18, 0.6520530134439468), (53, 0.951040543615818)]
computing accuracy for after removing block 7 . block score: 0.06516454555094242
removed block 7 current accuracy 0.6028 loss from initial  0.3972
training start
training epoch 0 val accuracy 0.8294 topk_dict {'top1': 0.8294} is_best True lr [0.1]
training epoch 1 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best True lr [0.1]
training epoch 2 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 3 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best True lr [0.1]
training epoch 4 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 5 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best True lr [0.1]
training epoch 6 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 7 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 8 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.1]
training epoch 9 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.096896. All blocks and scores: [(4, 0.09689601790159941), (37, 0.10817732196301222), (0, 0.1092687277123332), (9, 0.11101365182548761), (2, 0.1235736208036542), (3, 0.12452582083642483), (1, 0.1266919607296586), (39, 0.12780584581196308), (6, 0.13814086839556694), (11, 0.14858920313417912), (14, 0.15696576423943043), (13, 0.1569758988916874), (8, 0.16723546385765076), (17, 0.1747123133391142), (10, 0.2111144084483385), (12, 0.22262024134397507), (16, 0.22585229203104973), (5, 0.2360340692102909), (36, 0.4643707498908043), (18, 0.605993315577507), (53, 1.3030427396297455)]
computing accuracy for after removing block 4 . block score: 0.09689601790159941
removed block 4 current accuracy 0.9344 loss from initial  0.06559999999999999
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.105620. All blocks and scores: [(37, 0.10562003683298826), (0, 0.10926872864365578), (9, 0.11038277763873339), (2, 0.12357362266629934), (3, 0.12452581711113453), (39, 0.12654133513569832), (1, 0.1266919570043683), (11, 0.13620154932141304), (14, 0.15480997040867805), (13, 0.1560577228665352), (6, 0.1635855995118618), (17, 0.1689809150993824), (8, 0.17297744005918503), (10, 0.20278638787567616), (16, 0.20510541275143623), (12, 0.2162269912660122), (5, 0.2675485536456108), (36, 0.4540231227874756), (18, 0.5951402336359024), (53, 1.2758301347494125)]
computing accuracy for after removing block 37 . block score: 0.10562003683298826
removed block 37 current accuracy 0.8898 loss from initial  0.11019999999999996
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 0, with score 0.109269. All blocks and scores: [(0, 0.10926872864365578), (9, 0.11038277857005596), (2, 0.12357361800968647), (3, 0.12452581990510225), (1, 0.1266919607296586), (11, 0.1362015511840582), (14, 0.15480997040867805), (13, 0.1560577228665352), (39, 0.1605883166193962), (6, 0.1635856032371521), (17, 0.168980922549963), (8, 0.17297743819653988), (10, 0.20278639160096645), (16, 0.2051054034382105), (12, 0.21622700057923794), (5, 0.2675485536456108), (36, 0.454023115336895), (18, 0.5951402336359024), (53, 1.2896428108215332)]
computing accuracy for after removing block 0 . block score: 0.10926872864365578
removed block 0 current accuracy 0.8634 loss from initial  0.13660000000000005
since last training loss: 0.07360000000000011 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.102669. All blocks and scores: [(3, 0.10266857594251633), (9, 0.10856426879763603), (11, 0.13044157065451145), (2, 0.13144169375300407), (1, 0.1343910302966833), (13, 0.15275142900645733), (14, 0.15386697463691235), (39, 0.15876641869544983), (6, 0.16224178113043308), (17, 0.16281163319945335), (8, 0.1687795575708151), (10, 0.17997732758522034), (16, 0.19430029578506947), (12, 0.23056423477828503), (5, 0.24678373709321022), (36, 0.442129660397768), (18, 0.5812086090445518), (53, 1.2876204252243042)]
computing accuracy for after removing block 3 . block score: 0.10266857594251633
removed block 3 current accuracy 0.8182 loss from initial  0.18179999999999996
since last training loss: 0.11880000000000002 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 9, with score 0.116962. All blocks and scores: [(9, 0.11696201842278242), (11, 0.12157908082008362), (2, 0.13144169189035892), (1, 0.1343910340219736), (17, 0.14518343657255173), (14, 0.14757698774337769), (39, 0.14999865926802158), (13, 0.15740784630179405), (16, 0.16047708690166473), (6, 0.1653696857392788), (8, 0.1695745438337326), (10, 0.1884465403854847), (12, 0.24171415530145168), (5, 0.2598489485681057), (36, 0.4172104746103287), (18, 0.5480624288320541), (53, 1.2270369976758957)]
computing accuracy for after removing block 9 . block score: 0.11696201842278242
removed block 9 current accuracy 0.7684 loss from initial  0.23160000000000003
since last training loss: 0.16860000000000008 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.114151. All blocks and scores: [(11, 0.1141509423032403), (17, 0.12975170649588108), (2, 0.13144169189035892), (1, 0.13439102843403816), (16, 0.13697760924696922), (14, 0.13798748143017292), (13, 0.1419282853603363), (39, 0.14281250163912773), (6, 0.16536969132721424), (8, 0.1695745475590229), (10, 0.18318742513656616), (12, 0.21852892078459263), (5, 0.2598489448428154), (36, 0.3897685445845127), (18, 0.5274571850895882), (53, 1.0892573595046997)]
computing accuracy for after removing block 11 . block score: 0.1141509423032403
removed block 11 current accuracy 0.7078 loss from initial  0.2922
since last training loss: 0.22920000000000007 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 16, with score 0.119952. All blocks and scores: [(16, 0.11995249893516302), (17, 0.12319308612495661), (2, 0.13144169375300407), (14, 0.13260944932699203), (13, 0.13317763432860374), (1, 0.13439102843403816), (39, 0.1473342664539814), (6, 0.16536969132721424), (8, 0.16957454197108746), (10, 0.18318742886185646), (12, 0.19342258013784885), (5, 0.2598489560186863), (36, 0.3893570899963379), (18, 0.5374433249235153), (53, 1.0494902580976486)]
computing accuracy for after removing block 16 . block score: 0.11995249893516302
removed block 16 current accuracy 0.631 loss from initial  0.369
since last training loss: 0.30600000000000005 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.125173. All blocks and scores: [(17, 0.12517258059233427), (2, 0.13144169189035892), (14, 0.13260944560170174), (13, 0.1331776361912489), (1, 0.13439102843403816), (39, 0.14852416701614857), (6, 0.16536968760192394), (8, 0.16957454942166805), (10, 0.18318741768598557), (12, 0.1934225782752037), (5, 0.2598489448428154), (36, 0.3737168163061142), (18, 0.5283507481217384), (53, 1.0150297433137894)]
computing accuracy for after removing block 17 . block score: 0.12517258059233427
removed block 17 current accuracy 0.5612 loss from initial  0.43879999999999997
since last training loss: 0.3758 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 2, with score 0.131442. All blocks and scores: [(2, 0.13144169561564922), (14, 0.13260944746434689), (13, 0.1331776324659586), (1, 0.1343910340219736), (39, 0.13705327734351158), (6, 0.1653696894645691), (8, 0.16957454569637775), (10, 0.18318741768598557), (12, 0.19342258013784885), (5, 0.2598489485681057), (36, 0.3418053314089775), (18, 0.4964851178228855), (53, 0.8485521525144577)]
computing accuracy for after removing block 2 . block score: 0.13144169561564922
removed block 2 current accuracy 0.4074 loss from initial  0.5926
since last training loss: 0.5296000000000001 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 14, with score 0.120781. All blocks and scores: [(14, 0.1207808693870902), (13, 0.1231498084962368), (1, 0.13439103215932846), (39, 0.13651113957166672), (8, 0.1608007587492466), (6, 0.16864230297505856), (10, 0.1793077141046524), (12, 0.18510284461081028), (5, 0.2624143548309803), (36, 0.32246096804738045), (18, 0.47337357699871063), (53, 0.6854424998164177)]
computing accuracy for after removing block 14 . block score: 0.1207808693870902
removed block 14 current accuracy 0.2858 loss from initial  0.7142
since last training loss: 0.6512 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 13, with score 0.123150. All blocks and scores: [(13, 0.1231498122215271), (1, 0.13439102843403816), (39, 0.1426091007888317), (8, 0.1608007587492466), (6, 0.16864229924976826), (10, 0.1793077103793621), (12, 0.18510283902287483), (5, 0.2624143473803997), (36, 0.3492632061243057), (18, 0.4998949281871319), (53, 0.7903553992509842)]
computing accuracy for after removing block 13 . block score: 0.1231498122215271
removed block 13 current accuracy 0.2006 loss from initial  0.7994
since last training loss: 0.7364 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 1, with score 0.134391. All blocks and scores: [(1, 0.13439102843403816), (39, 0.14418217353522778), (8, 0.16080076061189175), (6, 0.16864229924976826), (10, 0.17930771224200726), (12, 0.18510284274816513), (5, 0.26241435110569), (36, 0.3722037523984909), (18, 0.5447998642921448), (53, 0.9192909151315689)]
computing accuracy for after removing block 1 . block score: 0.13439102843403816
removed block 1 current accuracy 0.1642 loss from initial  0.8358
training start
training epoch 0 val accuracy 0.8156 topk_dict {'top1': 0.8156} is_best True lr [0.1]
training epoch 1 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best True lr [0.1]
training epoch 2 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 3 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 4 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best False lr [0.1]
training epoch 5 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 6 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best True lr [0.1]
training epoch 7 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.1]
training epoch 8 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 9 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 10 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.923400)
finished training. finished 50 epochs. accuracy 0.9234 topk_dict {'top1': 0.9234}
