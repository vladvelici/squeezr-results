start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.0070619964972138405), (32, 0.009233050979673862), (30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.013312276103533804), (29, 0.013541154563426971), (35, 0.01601846213452518), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020232456270605326), (46, 0.021044540219008923), (25, 0.021972603630274534), (23, 0.022379535250365734), (41, 0.022826647851616144), (44, 0.023395079420879483), (40, 0.02402502507902682), (45, 0.024295410374179482), (21, 0.024924598867073655), (22, 0.025168768130242825), (48, 0.025341259548440576), (24, 0.025899537140503526), (50, 0.026409972924739122), (42, 0.026674101129174232), (20, 0.026859006844460964), (49, 0.027037164429202676), (47, 0.029306468786671758), (39, 0.03157071233727038), (38, 0.031637872103601694), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628594897687435), (37, 0.037960261572152376), (51, 0.04173417342826724), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846378415823), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.059249130077660084), (17, 0.060956846456974745), (0, 0.06300980970263481), (1, 0.06676734425127506), (52, 0.06862937472760677), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.43758000060915947), (18, 0.5108212903141975), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.0070619964972138405
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.013133947853930295), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169289592653513), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020072476705536246), (46, 0.020731385797262192), (25, 0.021972603164613247), (41, 0.022347092861309648), (23, 0.022379535483196378), (44, 0.023235687287524343), (40, 0.0238410672172904), (45, 0.023965542670339346), (48, 0.024917915929108858), (21, 0.024924598168581724), (22, 0.025168768130242825), (50, 0.025840813061222434), (24, 0.025899537606164813), (42, 0.026315323309972882), (49, 0.02665567467920482), (20, 0.026859007077291608), (47, 0.02872879756614566), (39, 0.031317642191424966), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.038025842513889074), (51, 0.04122393950819969), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300980830565095), (1, 0.06676734331995249), (52, 0.06745155155658722), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.43538709729909897), (18, 0.5108212903141975), (53, 0.8222573548555374)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.01036160031799227), (34, 0.012765233288519084), (29, 0.01354115444701165), (35, 0.015992751345038414), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02007513167336583), (46, 0.020841406658291817), (25, 0.021972602931782603), (41, 0.0223197671584785), (23, 0.02237953501753509), (44, 0.0231540494132787), (40, 0.02388568432070315), (45, 0.02407169039361179), (48, 0.024877465097233653), (21, 0.02492459723725915), (22, 0.025168768828734756), (50, 0.025691178860142827), (24, 0.025899537606164813), (42, 0.026123747695237398), (49, 0.026479422580450773), (20, 0.026859007077291608), (47, 0.02869313210248947), (38, 0.031236795708537102), (39, 0.03129529161378741), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03837669128552079), (51, 0.041114034596830606), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06700456142425537), (8, 0.0746783260256052), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.43640001490712166), (18, 0.5108213126659393), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387837516143918), (29, 0.013541154563426971), (35, 0.01600809581577778), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020083633717149496), (46, 0.02070444473065436), (25, 0.021972603164613247), (41, 0.02225319715216756), (23, 0.022379535250365734), (44, 0.02326776133850217), (40, 0.02401387970894575), (45, 0.02409299206919968), (48, 0.024665280943736434), (21, 0.024924598401412368), (22, 0.025168768828734756), (50, 0.025459734490141273), (42, 0.025655712699517608), (24, 0.02589953667484224), (49, 0.026287756860256195), (20, 0.02685900661163032), (47, 0.02836342342197895), (38, 0.03104764805175364), (39, 0.03138077235780656), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03897124622017145), (51, 0.04075620323419571), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846704378724), (3, 0.057224276941269636), (13, 0.05892290407791734), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.0630098101682961), (52, 0.06586316134780645), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4389924481511116), (18, 0.5108213126659393), (53, 0.8391561806201935)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619432017207), (29, 0.013541154796257615), (26, 0.016037590336054564), (35, 0.016057363711297512), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020049350103363395), (46, 0.020552987698465586), (25, 0.021972602931782603), (41, 0.022067483980208635), (23, 0.022379535483196378), (44, 0.022979132365435362), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.02438612235710025), (21, 0.02492459793575108), (50, 0.025042241206392646), (22, 0.025168767431750894), (42, 0.025414507603272796), (49, 0.0258426982909441), (24, 0.02589953667484224), (20, 0.026859007077291608), (47, 0.02805073489435017), (38, 0.031040059635415673), (39, 0.03150080284103751), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03911284916102886), (51, 0.04024627432227135), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.047836634796112776), (2, 0.054548466578125954), (3, 0.05722427973523736), (13, 0.05892290361225605), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980830565095), (52, 0.06486208736896515), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4381278418004513), (18, 0.5108212977647781), (53, 0.8458428010344505)]
computing accuracy for after removing block 34 . block score: 0.012489619432017207
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.016037590336054564), (35, 0.016653420869261026), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.021972602931782603), (23, 0.022379535948857665), (41, 0.0224526294041425), (44, 0.023364473367109895), (48, 0.024290354922413826), (45, 0.024438712280243635), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.025042172521352768), (22, 0.025168768130242825), (49, 0.02587597048841417), (24, 0.025899537140503526), (42, 0.026205406757071614), (20, 0.026859006844460964), (47, 0.028178583830595016), (15, 0.03192339185625315), (38, 0.03208350110799074), (7, 0.03228544630110264), (39, 0.03233744157478213), (19, 0.03262859582901001), (51, 0.03994725923985243), (37, 0.040739682503044605), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980877131224), (52, 0.06433630269020796), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386744171381), (36, 0.45053430274128914), (18, 0.5108213126659393), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.0164706080686301), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020046866964548826), (46, 0.020376994274556637), (41, 0.021723242243751884), (25, 0.021972602233290672), (23, 0.022379535250365734), (44, 0.023028337163850665), (48, 0.023771876469254494), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.02439029887318611), (21, 0.02492459793575108), (22, 0.025168768363073468), (42, 0.025188250932842493), (49, 0.025361528852954507), (24, 0.025899537606164813), (20, 0.026859007077291608), (47, 0.027363279135897756), (38, 0.03136561927385628), (15, 0.03192339185625315), (39, 0.032127685844898224), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.0389359244145453), (37, 0.04020634386688471), (9, 0.043401877861469984), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846704378724), (3, 0.057224278803914785), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956849716603756), (52, 0.062328551430255175), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.4444201961159706), (18, 0.5108213052153587), (53, 0.8537911772727966)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365563735366), (28, 0.017088500317186117), (27, 0.018882447155192494), (43, 0.019595165736973286), (46, 0.020073581486940384), (41, 0.020961584988981485), (25, 0.02197260269895196), (23, 0.02237953571602702), (44, 0.022814955795183778), (48, 0.023128160508349538), (40, 0.023345195222645998), (50, 0.023756146896630526), (42, 0.02384730218909681), (45, 0.023873880272731185), (21, 0.02492459793575108), (49, 0.02496031578630209), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026855543022975326), (20, 0.02685900661163032), (38, 0.030424014199525118), (39, 0.03151404415257275), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859722599387), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912868067622), (52, 0.06033282168209553), (17, 0.060956849716603756), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4360685534775257), (18, 0.5108213052153587), (53, 0.8749377131462097)]
computing accuracy for after removing block 35 . block score: 0.015597365563735366
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555946182459593), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.019424295518547297), (48, 0.02146727219223976), (25, 0.021972602931782603), (44, 0.022026916267350316), (40, 0.022179660387337208), (42, 0.02220643009059131), (50, 0.022256128955632448), (23, 0.02237953571602702), (45, 0.022931481711566448), (49, 0.02370851207524538), (21, 0.024924597702920437), (22, 0.025168768595904112), (47, 0.025829139864072204), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.028956546681001782), (39, 0.0296678279992193), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.032628594897687435), (51, 0.03600902622565627), (37, 0.03651238791644573), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.054548466112464666), (52, 0.05610728682950139), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.41757646575570107), (18, 0.5108212977647781), (53, 0.9117144644260406)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 1 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 2 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 3 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 4 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 5 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 6 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 7 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 8 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 9 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.1]
training epoch 10 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.018882446456700563), (48, 0.020903733791783452), (42, 0.02143200417049229), (40, 0.0218324214220047), (44, 0.021840530913323164), (50, 0.021869863383471966), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.02249284810386598), (49, 0.023123498307541013), (21, 0.02492459793575108), (47, 0.025067138951271772), (22, 0.025168768828734756), (24, 0.025899537838995457), (20, 0.026859006378799677), (38, 0.02811406832188368), (39, 0.0292069090064615), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.03545433655381203), (37, 0.03597763879224658), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548464715480804), (52, 0.054696458391845226), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4135979153215885), (18, 0.5108212903141975), (53, 0.9246632605791092)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882447155192494), (46, 0.019302030093967915), (42, 0.021432004403322935), (48, 0.021544844144955277), (40, 0.021832421654835343), (50, 0.02194626978598535), (25, 0.021972603164613247), (23, 0.02237953618168831), (49, 0.02300687017850578), (44, 0.02310851006768644), (45, 0.023535606218501925), (21, 0.024924598168581724), (22, 0.025168768363073468), (47, 0.025820446200668812), (24, 0.025899537838995457), (20, 0.026859007542952895), (38, 0.028114069253206253), (39, 0.02920690830796957), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.035091488622128963), (37, 0.03597764018923044), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.04783663433045149), (52, 0.05332902958616614), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.0592491258867085), (17, 0.06095685018226504), (0, 0.06300981063395739), (1, 0.06676734052598476), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.1066738748922944), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9678284302353859)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.01907008863054216), (48, 0.020678167464211583), (50, 0.021344397449865937), (40, 0.0218324214220047), (25, 0.021972602931782603), (42, 0.021986940409988165), (23, 0.022379535483196378), (49, 0.022534748539328575), (45, 0.023929917253553867), (44, 0.02405400318093598), (21, 0.02492459863424301), (22, 0.025168767664581537), (24, 0.025899535976350307), (47, 0.026043936610221863), (20, 0.026859007077291608), (38, 0.028114070184528828), (39, 0.029206908773630857), (15, 0.031923390459269285), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.03379448037594557), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.04783663293346763), (52, 0.050476094242185354), (2, 0.05454846750944853), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684738829732), (0, 0.06300981109961867), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.01998970750719309), (50, 0.020775061566382647), (40, 0.021085952874273062), (42, 0.021369647467508912), (49, 0.02191002992913127), (25, 0.021972602931782603), (23, 0.022379535948857665), (44, 0.023239311994984746), (45, 0.023585309274494648), (21, 0.024924598401412368), (47, 0.02507694880478084), (22, 0.025168768828734756), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.028580758022144437), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859443202615), (51, 0.0328142608050257), (37, 0.03542024362832308), (9, 0.043401877861469984), (6, 0.04660903010517359), (4, 0.047493684105575085), (14, 0.04783663619309664), (52, 0.048523631412535906), (2, 0.05454846704378724), (3, 0.05722427926957607), (13, 0.05892289988696575), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831162109971046), (40, 0.02108595333993435), (42, 0.02136964676901698), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.0225369893014431), (44, 0.02323931152932346), (45, 0.023585308343172073), (21, 0.02492459793575108), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.026583049446344376), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.02858075895346701), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.0328508117236197), (37, 0.03542024316266179), (9, 0.04340187832713127), (6, 0.04660903010517359), (4, 0.04749368317425251), (14, 0.04783663246780634), (52, 0.04812479857355356), (2, 0.054548466578125954), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233953297138), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.02108595333993435), (42, 0.021369647700339556), (25, 0.021972602233290672), (23, 0.022379535250365734), (50, 0.022470062831416726), (44, 0.023239311994984746), (45, 0.02358530811034143), (21, 0.024924598168581724), (22, 0.025168768130242825), (49, 0.02523410157300532), (24, 0.02589953737333417), (47, 0.02658304967917502), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.028580758022144437), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03296921169385314), (37, 0.03542024362832308), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05089045036584139), (2, 0.05454846750944853), (3, 0.05722427740693092), (13, 0.05892289988696575), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.2663909196853638)]
computing accuracy for after removing block 40 . block score: 0.02108595333993435
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868143416941), (50, 0.021284765796735883), (25, 0.02197260269895196), (23, 0.02237953571602702), (45, 0.02309831790626049), (44, 0.024240857688710093), (49, 0.024500868981704116), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.025899537140503526), (47, 0.026519699720665812), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.03192339139059186), (51, 0.03222084976732731), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.035420244093984365), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.04885757248848677), (2, 0.054548464715480804), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.3718616217374802)]
computing accuracy for after removing block 42 . block score: 0.02096868143416941
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658535912633), (25, 0.02197260269895196), (23, 0.02237953501753509), (45, 0.023761966731399298), (49, 0.024602339137345552), (44, 0.02471218165010214), (21, 0.02492459863424301), (22, 0.025168768130242825), (24, 0.02589953667484224), (47, 0.026220474625006318), (20, 0.02685900731012225), (38, 0.027183360187336802), (39, 0.02858075895346701), (51, 0.03127906727604568), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628596760332584), (37, 0.03542024455964565), (9, 0.04340187879279256), (52, 0.04610171029344201), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663526177406), (2, 0.05454846518114209), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.4178234338760376)]
computing accuracy for after removing block 50 . block score: 0.021202658535912633
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.023761966032907367), (49, 0.024602339137345552), (44, 0.02471218118444085), (21, 0.02492459793575108), (22, 0.025168767664581537), (24, 0.025899537838995457), (47, 0.026220475090667605), (20, 0.02685900777578354), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.0334430206567049), (37, 0.03542024316266179), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.052651794627308846), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.05892290314659476), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734425127506), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.6287680566310883)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.1]
training epoch 1 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 2 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 3 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 4 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 5 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 6 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 7 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.1]
training epoch 8 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 9 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 10 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.968400)
finished training. finished 50 epochs. accuracy 0.9684 topk_dict {'top1': 0.9684}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.046998. All blocks and scores: [(49, 0.046998223289847374), (23, 0.049077358096838), (45, 0.05045906733721495), (44, 0.05130183044821024), (21, 0.053424468729645014), (47, 0.05404895218089223), (22, 0.054755376651883125), (19, 0.05797920795157552), (38, 0.05917804595082998), (20, 0.05919374292716384), (51, 0.0595029816031456), (7, 0.05993036646395922), (39, 0.060694664251059294), (24, 0.06318058678880334), (15, 0.06354189943522215), (37, 0.06963288597762585), (4, 0.07147323153913021), (52, 0.07190542668104172), (9, 0.07790680788457394), (6, 0.0903936717659235), (3, 0.09453909005969763), (14, 0.09571047686040401), (2, 0.09607014060020447), (11, 0.09977336693555117), (0, 0.10676553938537836), (1, 0.1095652561634779), (17, 0.11392071470618248), (13, 0.1155335521325469), (8, 0.12077831756323576), (10, 0.13947135210037231), (12, 0.14123888686299324), (16, 0.15148848295211792), (5, 0.18606825172901154), (36, 0.6193802729249), (18, 0.6758366674184799), (53, 0.9791240766644478)]
computing accuracy for after removing block 49 . block score: 0.046998223289847374
removed block 49 current accuracy 0.9584 loss from initial  0.04159999999999997
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.049077. All blocks and scores: [(23, 0.049077358562499285), (45, 0.05045906733721495), (44, 0.05130183091387153), (21, 0.05342446779832244), (47, 0.054048952646553516), (22, 0.05475537572056055), (19, 0.05797920608893037), (38, 0.05917804501950741), (20, 0.0591937443241477), (7, 0.05993036646395922), (39, 0.06069466471672058), (24, 0.0631805844604969), (15, 0.0635419012978673), (51, 0.06483707623556256), (37, 0.06963288690894842), (4, 0.07147323060780764), (9, 0.07790681067854166), (52, 0.08092744555324316), (6, 0.09039367269724607), (3, 0.09453908819705248), (14, 0.09571047592908144), (2, 0.09607014525681734), (11, 0.09977336879819632), (0, 0.10676554311066866), (1, 0.10956525430083275), (17, 0.11392071098089218), (13, 0.11553354747593403), (8, 0.12077831570059061), (10, 0.13947135023772717), (12, 0.1412388812750578), (16, 0.15148847922682762), (5, 0.1860682498663664), (36, 0.6193802654743195), (18, 0.6758366748690605), (53, 1.0733840316534042)]
computing accuracy for after removing block 23 . block score: 0.049077358562499285
removed block 23 current accuracy 0.9514 loss from initial  0.04859999999999998
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.050684. All blocks and scores: [(45, 0.05068436497822404), (44, 0.05122099258005619), (47, 0.05277766287326813), (21, 0.05342446593567729), (22, 0.054755376651883125), (24, 0.057759261690080166), (19, 0.05797920934855938), (38, 0.05911297304555774), (20, 0.0591937443241477), (7, 0.05993036460131407), (39, 0.062057594768702984), (15, 0.0635419012978673), (51, 0.06467784056439996), (4, 0.07147323153913021), (37, 0.07399414572864771), (9, 0.07790680881589651), (52, 0.0800970895215869), (6, 0.09039366990327835), (3, 0.09453909005969763), (14, 0.09571047499775887), (2, 0.0960701396688819), (11, 0.09977336600422859), (0, 0.10676554217934608), (1, 0.10956525430083275), (17, 0.11392071098089218), (13, 0.1155335484072566), (8, 0.12077831663191319), (10, 0.13947135396301746), (12, 0.14123888313770294), (16, 0.15148848295211792), (5, 0.18606825172901154), (36, 0.6335878893733025), (18, 0.6758366972208023), (53, 1.0782311409711838)]
computing accuracy for after removing block 45 . block score: 0.05068436497822404
removed block 45 current accuracy 0.9424 loss from initial  0.057599999999999985
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.051221. All blocks and scores: [(44, 0.05122099397704005), (21, 0.05342446733266115), (22, 0.05475537711754441), (24, 0.05775926122441888), (19, 0.05797920702025294), (38, 0.05911297304555774), (20, 0.0591937443241477), (7, 0.05993036599829793), (47, 0.06114756828173995), (39, 0.062057594768702984), (15, 0.06354190036654472), (51, 0.06405841885134578), (4, 0.07147323060780764), (37, 0.07399414665997028), (9, 0.07790680788457394), (52, 0.08563515916466713), (6, 0.09039367083460093), (3, 0.09453909005969763), (14, 0.09571047686040401), (2, 0.09607014060020447), (11, 0.09977336879819632), (0, 0.10676553752273321), (1, 0.10956525150686502), (17, 0.11392071470618248), (13, 0.11553355120122433), (8, 0.12077831476926804), (10, 0.13947135396301746), (12, 0.1412388850003481), (16, 0.15148848295211792), (5, 0.18606825172901154), (36, 0.6335878893733025), (18, 0.6758366674184799), (53, 1.1591614931821823)]
computing accuracy for after removing block 44 . block score: 0.05122099397704005
removed block 44 current accuracy 0.924 loss from initial  0.07599999999999996
since last training loss: 0.044399999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.053424. All blocks and scores: [(21, 0.053424468263983727), (22, 0.05475537618622184), (24, 0.05775925982743502), (19, 0.057979208417236805), (38, 0.059112975373864174), (20, 0.05919374339282513), (7, 0.05993036646395922), (39, 0.062057594768702984), (51, 0.06349289137870073), (15, 0.06354190036654472), (47, 0.06750259269028902), (4, 0.07147323060780764), (37, 0.07399414572864771), (9, 0.07790680695325136), (52, 0.08562784921377897), (6, 0.09039367362856865), (3, 0.09453908819705248), (14, 0.09571047592908144), (2, 0.0960701396688819), (11, 0.09977336786687374), (0, 0.10676554031670094), (1, 0.1095652561634779), (17, 0.1139207137748599), (13, 0.11553354933857918), (8, 0.12077831383794546), (10, 0.13947135210037231), (12, 0.1412388850003481), (16, 0.15148847736418247), (5, 0.1860682498663664), (36, 0.6335878893733025), (18, 0.6758366823196411), (53, 1.2369078546762466)]
computing accuracy for after removing block 21 . block score: 0.053424468263983727
removed block 21 current accuracy 0.9094 loss from initial  0.09060000000000001
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.050374. All blocks and scores: [(22, 0.05037366459146142), (24, 0.05140805756673217), (38, 0.056621442548930645), (19, 0.05797920608893037), (20, 0.059193743858486414), (7, 0.05993036553263664), (39, 0.06011731829494238), (51, 0.060678777284920216), (47, 0.0634225569665432), (15, 0.06354189943522215), (37, 0.07123883534222841), (4, 0.07147322874516249), (52, 0.07772437389940023), (9, 0.07790680881589651), (6, 0.0903936717659235), (3, 0.09453909005969763), (14, 0.09571047686040401), (2, 0.09607014060020447), (11, 0.09977336786687374), (0, 0.10676554124802351), (1, 0.10956525336951017), (17, 0.11392070818692446), (13, 0.11553354933857918), (8, 0.12077831570059061), (10, 0.13947135210037231), (12, 0.1412388812750578), (16, 0.15148848295211792), (5, 0.18606825545430183), (36, 0.6039332449436188), (18, 0.6758366748690605), (53, 1.2748594135046005)]
computing accuracy for after removing block 22 . block score: 0.05037366459146142
removed block 22 current accuracy 0.8862 loss from initial  0.11380000000000001
since last training loss: 0.08220000000000005 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.048665. All blocks and scores: [(24, 0.04866519710049033), (38, 0.05670979106798768), (51, 0.05772579461336136), (19, 0.05797920702025294), (20, 0.059193741995841265), (39, 0.05923400027677417), (7, 0.05993036739528179), (47, 0.060329895466566086), (15, 0.06354190036654472), (4, 0.07147323060780764), (52, 0.07352868840098381), (37, 0.07432339247316122), (9, 0.07790680881589651), (6, 0.09039366990327835), (3, 0.09453908819705248), (14, 0.09571047686040401), (2, 0.09607014060020447), (11, 0.09977336972951889), (0, 0.10676554497331381), (1, 0.1095652561634779), (17, 0.1139207137748599), (13, 0.11553354747593403), (8, 0.12077831849455833), (10, 0.13947135023772717), (12, 0.14123888686299324), (16, 0.15148848108947277), (5, 0.1860682498663664), (36, 0.6102446988224983), (18, 0.6758366748690605), (53, 1.2869674265384674)]
computing accuracy for after removing block 24 . block score: 0.04866519710049033
removed block 24 current accuracy 0.8578 loss from initial  0.1422
since last training loss: 0.11060000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.053075. All blocks and scores: [(38, 0.053075358271598816), (51, 0.0533975618891418), (47, 0.05520946253091097), (39, 0.05571718513965607), (19, 0.05797920702025294), (20, 0.05919374246150255), (7, 0.059930365066975355), (15, 0.06354189943522215), (52, 0.06722513306885958), (37, 0.07092822715640068), (4, 0.07147323060780764), (9, 0.07790680974721909), (6, 0.09039367083460093), (3, 0.0945390909910202), (14, 0.09571047592908144), (2, 0.0960701396688819), (11, 0.09977336786687374), (0, 0.10676554124802351), (1, 0.1095652561634779), (17, 0.11392071098089218), (13, 0.11553355026990175), (8, 0.12077831663191319), (10, 0.13947135396301746), (12, 0.14123888313770294), (16, 0.15148848295211792), (5, 0.18606824800372124), (36, 0.59554672986269), (18, 0.6758366897702217), (53, 1.3240836709737778)]
computing accuracy for after removing block 38 . block score: 0.053075358271598816
removed block 38 current accuracy 0.8262 loss from initial  0.17379999999999995
since last training loss: 0.1422 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.051928. All blocks and scores: [(51, 0.05192839400842786), (47, 0.05413713352754712), (19, 0.05797920981422067), (20, 0.059193745255470276), (7, 0.05993036553263664), (39, 0.061179795768111944), (15, 0.0635419012978673), (52, 0.06517250463366508), (37, 0.07092822901904583), (4, 0.07147323153913021), (9, 0.07790680881589651), (6, 0.09039367269724607), (3, 0.09453909005969763), (14, 0.09571047686040401), (2, 0.09607014060020447), (11, 0.09977336600422859), (0, 0.10676554124802351), (1, 0.10956525336951017), (17, 0.11392071191221476), (13, 0.11553354933857918), (8, 0.12077831383794546), (10, 0.13947135023772717), (12, 0.1412388850003481), (16, 0.15148847736418247), (5, 0.18606825172901154), (36, 0.5955467224121094), (18, 0.6758366748690605), (53, 1.3617452830076218)]
computing accuracy for after removing block 51 . block score: 0.05192839400842786
removed block 51 current accuracy 0.7674 loss from initial  0.23260000000000003
training start
training epoch 0 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best True lr [0.1]
training epoch 1 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best True lr [0.1]
training epoch 2 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.1]
training epoch 3 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 4 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 6 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 7 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 8 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 9 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.076854. All blocks and scores: [(7, 0.07685395423322916), (15, 0.08291306253522635), (4, 0.0890824319794774), (52, 0.09052481595426798), (37, 0.09131701942533255), (19, 0.09187365509569645), (47, 0.09265026729553938), (39, 0.09895568434149027), (20, 0.10480000264942646), (9, 0.10646119248121977), (14, 0.11102610267698765), (2, 0.11226018145680428), (0, 0.11657962203025818), (3, 0.11705231200903654), (6, 0.1194050358608365), (1, 0.12397438287734985), (17, 0.1259274622425437), (11, 0.12729308102279902), (8, 0.1407007984817028), (13, 0.14939386397600174), (10, 0.17285178042948246), (16, 0.17475507780909538), (12, 0.17484496533870697), (5, 0.20068157836794853), (36, 0.5384365171194077), (18, 0.6347741261124611), (53, 1.0768115520477295)]
computing accuracy for after removing block 7 . block score: 0.07685395423322916
removed block 7 current accuracy 0.936 loss from initial  0.06399999999999995
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.080573. All blocks and scores: [(15, 0.08057298325002193), (37, 0.08390748128294945), (52, 0.08586732670664787), (19, 0.08667094074189663), (4, 0.08908243384212255), (47, 0.09033951722085476), (39, 0.09852742496877909), (20, 0.09880961570888758), (14, 0.10161485150456429), (9, 0.10266291536390781), (17, 0.10480264388024807), (2, 0.112260184250772), (0, 0.11657961923629045), (3, 0.11705231387168169), (6, 0.11940504051744938), (11, 0.11962025985121727), (1, 0.12397438660264015), (13, 0.12503213994204998), (8, 0.12870603241026402), (12, 0.1606409177184105), (16, 0.16117889806628227), (10, 0.17341058887541294), (5, 0.20068158768117428), (36, 0.5139722153544426), (18, 0.6036918088793755), (53, 1.0720915496349335)]
computing accuracy for after removing block 15 . block score: 0.08057298325002193
removed block 15 current accuracy 0.9342 loss from initial  0.06579999999999997
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 37, with score 0.080972. All blocks and scores: [(37, 0.0809721713885665), (52, 0.0842713164165616), (19, 0.08600377012044191), (4, 0.08908243384212255), (20, 0.09099452756345272), (47, 0.09198694862425327), (39, 0.096451579593122), (14, 0.10161485336720943), (9, 0.10266291536390781), (17, 0.108086122199893), (2, 0.11226018145680428), (0, 0.11657961923629045), (3, 0.11705231107771397), (6, 0.11940503679215908), (11, 0.11962025705724955), (1, 0.12397437915205956), (13, 0.12503214180469513), (8, 0.1287060361355543), (12, 0.1606409177184105), (10, 0.17341058887541294), (16, 0.18371832184493542), (5, 0.20068158395588398), (36, 0.49014850333333015), (18, 0.5805392637848854), (53, 1.066944658756256)]
computing accuracy for after removing block 37 . block score: 0.0809721713885665
removed block 37 current accuracy 0.9096 loss from initial  0.09040000000000004
since last training loss: 0.03660000000000008 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.073729. All blocks and scores: [(52, 0.073728590272367), (19, 0.08600377105176449), (4, 0.0890824319794774), (47, 0.08931200206279755), (20, 0.09099452942609787), (14, 0.10161485802382231), (9, 0.10266291163861752), (17, 0.108086122199893), (39, 0.11099170055240393), (2, 0.11226017959415913), (0, 0.11657962016761303), (3, 0.11705231387168169), (6, 0.11940503772348166), (11, 0.11962025612592697), (1, 0.123974384739995), (13, 0.12503213994204998), (8, 0.1287060398608446), (12, 0.1606409177184105), (10, 0.1734105907380581), (16, 0.18371832743287086), (5, 0.20068158023059368), (36, 0.49014849588274956), (18, 0.580539271235466), (53, 1.0817598700523376)]
computing accuracy for after removing block 52 . block score: 0.073728590272367
removed block 52 current accuracy 0.8332 loss from initial  0.16679999999999995
since last training loss: 0.11299999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 19, with score 0.086004. All blocks and scores: [(19, 0.08600377198308706), (4, 0.08908243477344513), (47, 0.08931199926882982), (20, 0.09099452663213015), (14, 0.10161485522985458), (9, 0.10266291256994009), (17, 0.10808612313121557), (39, 0.11099170055240393), (2, 0.11226018238812685), (0, 0.11657962016761303), (3, 0.11705231573432684), (6, 0.11940503679215908), (11, 0.11962025612592697), (1, 0.12397438287734985), (13, 0.12503214087337255), (8, 0.12870603427290916), (12, 0.1606409177184105), (10, 0.17341059260070324), (16, 0.18371831811964512), (5, 0.20068157836794853), (36, 0.49014849960803986), (18, 0.580539271235466), (53, 1.2617052644491196)]
computing accuracy for after removing block 19 . block score: 0.08600377198308706
removed block 19 current accuracy 0.7992 loss from initial  0.20079999999999998
since last training loss: 0.14700000000000002 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 20, with score 0.083648. All blocks and scores: [(20, 0.08364814799278975), (47, 0.08565943036228418), (4, 0.0890824319794774), (14, 0.10161485522985458), (9, 0.10266291815787554), (17, 0.10808612685650587), (39, 0.11029304657131433), (2, 0.11226018331944942), (0, 0.11657962016761303), (3, 0.11705231573432684), (6, 0.11940503679215908), (11, 0.1196202551946044), (1, 0.12397438567131758), (13, 0.1250321390107274), (8, 0.1287060361355543), (12, 0.16064092703163624), (10, 0.1734105870127678), (16, 0.18371831811964512), (5, 0.20068157650530338), (36, 0.4868762120604515), (18, 0.580539271235466), (53, 1.1937469840049744)]
computing accuracy for after removing block 20 . block score: 0.08364814799278975
removed block 20 current accuracy 0.6854 loss from initial  0.3146
since last training loss: 0.26080000000000003 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 47, with score 0.081171. All blocks and scores: [(47, 0.08117121644318104), (4, 0.08908243384212255), (14, 0.10161484964191914), (9, 0.10266291629523039), (17, 0.10808612313121557), (2, 0.11226018238812685), (0, 0.11657961923629045), (3, 0.11705231666564941), (6, 0.11940503679215908), (11, 0.11962025798857212), (39, 0.121316684409976), (1, 0.12397438287734985), (13, 0.12503213807940483), (8, 0.1287060361355543), (12, 0.16064092330634594), (10, 0.17341058887541294), (16, 0.18371832557022572), (5, 0.20068157650530338), (36, 0.5224769040942192), (18, 0.5805392637848854), (53, 1.164746642112732)]
computing accuracy for after removing block 47 . block score: 0.08117121644318104
removed block 47 current accuracy 0.6182 loss from initial  0.38180000000000003
since last training loss: 0.32800000000000007 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.089082. All blocks and scores: [(4, 0.0890824357047677), (14, 0.10161484964191914), (9, 0.10266291256994009), (17, 0.10808612778782845), (2, 0.112260184250772), (0, 0.11657961830496788), (3, 0.11705231014639139), (6, 0.11940503679215908), (11, 0.11962025612592697), (39, 0.12131668627262115), (1, 0.12397438660264015), (13, 0.1250321390107274), (8, 0.12870603799819946), (12, 0.16064092330634594), (10, 0.17341059260070324), (16, 0.18371832370758057), (5, 0.20068158209323883), (36, 0.5224769040942192), (18, 0.5805392637848854), (53, 1.3968737125396729)]
computing accuracy for after removing block 4 . block score: 0.0890824357047677
removed block 4 current accuracy 0.6052 loss from initial  0.39480000000000004
since last training loss: 0.3410000000000001 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 14, with score 0.100343. All blocks and scores: [(14, 0.10034302808344364), (9, 0.10148364957422018), (17, 0.10268842056393623), (2, 0.112260184250772), (11, 0.11330890189856291), (0, 0.1165796210989356), (3, 0.11705231294035912), (39, 0.12118867598474026), (13, 0.12243279907852411), (1, 0.12397438194602728), (6, 0.1297811921685934), (8, 0.13686875812709332), (12, 0.15514596737921238), (16, 0.167349461466074), (10, 0.16761750169098377), (5, 0.21966949477791786), (36, 0.5256293788552284), (18, 0.586760863661766), (53, 1.3767197281122208)]
computing accuracy for after removing block 14 . block score: 0.10034302808344364
removed block 14 current accuracy 0.5268 loss from initial  0.47319999999999995
since last training loss: 0.4194 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 17, with score 0.099723. All blocks and scores: [(17, 0.09972320776432753), (9, 0.10148364584892988), (2, 0.1122601805254817), (11, 0.11330890376120806), (0, 0.1165796210989356), (3, 0.11705231480300426), (39, 0.11958349589258432), (13, 0.12243279814720154), (1, 0.12397438380867243), (6, 0.12978119403123856), (8, 0.13686875626444817), (12, 0.15514596179127693), (10, 0.16761750169098377), (16, 0.21953343227505684), (5, 0.219669496640563), (36, 0.5128750130534172), (18, 0.5738750547170639), (53, 1.3696786016225815)]
computing accuracy for after removing block 17 . block score: 0.09972320776432753
removed block 17 current accuracy 0.5126 loss from initial  0.48740000000000006
since last training loss: 0.4336000000000001 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 9, with score 0.101484. All blocks and scores: [(9, 0.1014836523681879), (39, 0.10838263016194105), (2, 0.11226018238812685), (11, 0.11330890003591776), (0, 0.1165796248242259), (3, 0.11705231294035912), (13, 0.12243280000984669), (1, 0.12397438194602728), (6, 0.12978119775652885), (8, 0.1368687618523836), (12, 0.15514596365392208), (10, 0.16761750355362892), (16, 0.2195334266871214), (5, 0.219669496640563), (36, 0.48161523416638374), (18, 0.5448843687772751), (53, 1.2806891798973083)]
computing accuracy for after removing block 9 . block score: 0.1014836523681879
removed block 9 current accuracy 0.4572 loss from initial  0.5428
since last training loss: 0.48900000000000005 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 39, with score 0.102810. All blocks and scores: [(39, 0.10280970297753811), (11, 0.10494721680879593), (2, 0.11226018331944942), (13, 0.11339795682579279), (0, 0.1165796210989356), (3, 0.11705231200903654), (1, 0.1239743810147047), (12, 0.12896887212991714), (6, 0.12978118658065796), (8, 0.1368687618523836), (10, 0.15616217255592346), (16, 0.1794110331684351), (5, 0.21966949850320816), (36, 0.44336066767573357), (18, 0.5308303982019424), (53, 1.1316701769828796)]
computing accuracy for after removing block 39 . block score: 0.10280970297753811
removed block 39 current accuracy 0.4066 loss from initial  0.5933999999999999
training start
training epoch 0 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best True lr [0.1]
training epoch 1 val accuracy 0.7816 topk_dict {'top1': 0.7816} is_best False lr [0.1]
training epoch 2 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.1]
training epoch 3 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best True lr [0.1]
training epoch 4 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.1]
training epoch 5 val accuracy 0.8278 topk_dict {'top1': 0.8278} is_best False lr [0.1]
training epoch 6 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 7 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 8 val accuracy 0.867 topk_dict {'top1': 0.867} is_best True lr [0.1]
training epoch 9 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.1]
training epoch 10 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.909000)
finished training. finished 50 epochs. accuracy 0.909 topk_dict {'top1': 0.909}
