start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996206175536), (32, 0.009233050514012575), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013312275987118483), (29, 0.013541154796257615), (35, 0.01601846283301711), (26, 0.016037590568885207), (28, 0.017728675855323672), (27, 0.01912704948335886), (43, 0.020232456736266613), (46, 0.021044540451839566), (25, 0.021972602931782603), (23, 0.022379535948857665), (41, 0.022826647153124213), (44, 0.02339507918804884), (40, 0.024025025311857462), (45, 0.024295410607010126), (21, 0.024924598168581724), (22, 0.02516876789741218), (48, 0.025341259548440576), (24, 0.025899536907672882), (50, 0.026409972459077835), (42, 0.0266741004306823), (20, 0.026859007077291608), (49, 0.02703716466203332), (47, 0.029306468786671758), (39, 0.03157071233727038), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03796026110649109), (51, 0.04173417342826724), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300980830565095), (1, 0.06676734238862991), (52, 0.06862937565892935), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049665004015), (5, 0.10667387116700411), (36, 0.43758000433444977), (18, 0.5108213201165199), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996206175536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.013133947388269007), (29, 0.013541154796257615), (26, 0.01603759080171585), (35, 0.01616928935982287), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020072476705536246), (46, 0.020731386030092835), (25, 0.02197260269895196), (41, 0.022347092628479004), (23, 0.022379535483196378), (44, 0.023235687986016273), (40, 0.023841066285967827), (45, 0.023965542437508702), (48, 0.024917916161939502), (21, 0.024924598401412368), (22, 0.025168767664581537), (50, 0.02584081352688372), (24, 0.02589953737333417), (42, 0.026315322844311595), (49, 0.02665567514486611), (20, 0.026859007542952895), (47, 0.028728798031806946), (39, 0.03131764242425561), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.038025843910872936), (51, 0.04122393857687712), (9, 0.04340188205242157), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095684692263603), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.06745155155658722), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4353870861232281), (18, 0.5108212977647781), (53, 0.8222573697566986)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400891400874), (31, 0.010361600550822914), (34, 0.012765232706442475), (29, 0.013541154796257615), (35, 0.015992750879377127), (26, 0.016037590568885207), (28, 0.01772867445833981), (27, 0.019127048086374998), (43, 0.020075131207704544), (46, 0.020841405959799886), (25, 0.02197260269895196), (41, 0.022319766925647855), (23, 0.02237953571602702), (44, 0.02315405011177063), (40, 0.023885684087872505), (45, 0.024071688763797283), (48, 0.024877465097233653), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.02569117839448154), (24, 0.025899536442011595), (42, 0.026123747462406754), (49, 0.026479422114789486), (20, 0.026859006844460964), (47, 0.028693131636828184), (38, 0.031236795475706458), (39, 0.03129529161378741), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859722599387), (37, 0.03837669035419822), (51, 0.04111403366550803), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734238862991), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.43640000373125076), (18, 0.5108212977647781), (53, 0.828934907913208)]
computing accuracy for after removing block 30 . block score: 0.010039400891400874
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.012387836934067309), (29, 0.01354115444701165), (35, 0.016008096747100353), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.02008363325148821), (46, 0.020704444497823715), (25, 0.021972602931782603), (41, 0.022253197384998202), (23, 0.022379535948857665), (44, 0.023267761105671525), (40, 0.024013880407437682), (45, 0.024092993000522256), (48, 0.024665279546752572), (21, 0.024924598401412368), (22, 0.02516876789741218), (50, 0.025459734722971916), (42, 0.02565571339800954), (24, 0.0258995380718261), (49, 0.026287757325917482), (20, 0.026859007077291608), (47, 0.02836342342197895), (38, 0.03104764735326171), (39, 0.031380771892145276), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.0389712443575263), (51, 0.040756204165518284), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427600994706), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980737432837), (52, 0.0658631594851613), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.0904204910621047), (5, 0.10667387302964926), (36, 0.4389924518764019), (18, 0.5108212977647781), (53, 0.8391561582684517)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154679842293), (26, 0.016037590336054564), (35, 0.016057363245636225), (28, 0.017728675855323672), (27, 0.019127048086374998), (43, 0.020049349404871464), (46, 0.020552986999973655), (25, 0.021972602931782603), (41, 0.022067483514547348), (23, 0.02237953571602702), (44, 0.02297913166694343), (40, 0.02385834720917046), (45, 0.02412470243871212), (48, 0.024386122589930892), (21, 0.02492459793575108), (50, 0.025042241206392646), (22, 0.025168768130242825), (42, 0.025414507603272796), (49, 0.0258426982909441), (24, 0.02589953667484224), (20, 0.02685900661163032), (47, 0.028050734661519527), (38, 0.031040059169754386), (39, 0.03150080284103751), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.039112848695367575), (51, 0.040246272925287485), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.05722427926957607), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980830565095), (52, 0.0648620892316103), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386651039124), (36, 0.4381278418004513), (18, 0.5108213126659393), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154330596328), (26, 0.016037590336054564), (35, 0.016653420170769095), (28, 0.017728674924001098), (27, 0.019127048086374998), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.021972602466121316), (23, 0.022379534784704447), (41, 0.0224526294041425), (44, 0.023364474065601826), (48, 0.02429035515524447), (45, 0.024438711814582348), (40, 0.024470558390021324), (21, 0.024924597004428506), (50, 0.025042172288522124), (22, 0.025168768595904112), (49, 0.02587597002275288), (24, 0.025899537140503526), (42, 0.026205406757071614), (20, 0.026859006844460964), (47, 0.028178583597764373), (15, 0.03192339185625315), (38, 0.032083502039313316), (7, 0.032285446766763926), (39, 0.03233744017779827), (19, 0.0326285962946713), (51, 0.039947258308529854), (37, 0.04073968296870589), (9, 0.04340188018977642), (6, 0.04660903010517359), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.0545484684407711), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.059249126352369785), (17, 0.060956849716603756), (0, 0.06300981109961867), (52, 0.06433630408719182), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.45053432136774063), (18, 0.5108212977647781), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154330596328
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.0164706080686301), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020046867663040757), (46, 0.020376993576064706), (41, 0.021723242942243814), (25, 0.021972602931782603), (23, 0.022379535483196378), (44, 0.02302833693102002), (48, 0.02377187740057707), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.02439029817469418), (21, 0.024924598401412368), (22, 0.025168768130242825), (42, 0.025188250932842493), (49, 0.025361528852954507), (24, 0.025899537838995457), (20, 0.02685900661163032), (47, 0.027363278903067112), (38, 0.03136561857536435), (15, 0.03192339092493057), (39, 0.032127685844898224), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.03893592348322272), (37, 0.040206344332545996), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368270859122), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.060956848319619894), (52, 0.062328551430255175), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4444201923906803), (18, 0.5108213126659393), (53, 0.8537912219762802)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365680150688), (28, 0.017088500317186117), (27, 0.01888244692236185), (43, 0.019595165504142642), (46, 0.02007358125410974), (41, 0.02096158522181213), (25, 0.021972602931782603), (23, 0.022379535483196378), (44, 0.02281495649367571), (48, 0.02312816004268825), (40, 0.023345195688307285), (50, 0.023756146663799882), (42, 0.02384730288758874), (45, 0.02387388050556183), (21, 0.024924598168581724), (49, 0.024960315553471446), (22, 0.025168768130242825), (24, 0.025899537838995457), (47, 0.02685554255731404), (20, 0.026859006844460964), (38, 0.030424014665186405), (39, 0.03151404415257275), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03782488079741597), (37, 0.03936835192143917), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249130077660084), (52, 0.06033281935378909), (17, 0.06095684925094247), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4360685423016548), (18, 0.5108213126659393), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597365680150688
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 1 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 2 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 3 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 4 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 5 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 6 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.1]
training epoch 7 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 8 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 9 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.1]
training epoch 10 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555945716798306), (27, 0.018882447155192494), (46, 0.019160085124894977), (41, 0.019424295518547297), (48, 0.021467272425070405), (25, 0.021972601767629385), (44, 0.02202691719867289), (40, 0.022179660154506564), (42, 0.02220643009059131), (50, 0.022256129188463092), (23, 0.02237953571602702), (45, 0.022931480780243874), (49, 0.023708512308076024), (21, 0.02492459793575108), (22, 0.025168768130242825), (47, 0.025829139165580273), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.02895654644817114), (39, 0.029667827766388655), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.03600902622565627), (37, 0.03651238791644573), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.054548464715480804), (52, 0.056107287760823965), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.05924912681803107), (17, 0.06095684785395861), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387396097183), (36, 0.41757645085453987), (18, 0.5108213052153587), (53, 0.9117145016789436)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302505344152), (46, 0.018656101543456316), (41, 0.018849018262699246), (27, 0.01888244692236185), (48, 0.020903735421597958), (42, 0.021432004868984222), (40, 0.0218324214220047), (44, 0.021840530447661877), (50, 0.021869863849133253), (25, 0.02197260269895196), (23, 0.022379535948857665), (45, 0.02249284810386598), (49, 0.023123498540371656), (21, 0.024924597470089793), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.026859007077291608), (38, 0.028114069486036897), (39, 0.02920690830796957), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.03545433655381203), (37, 0.03597763879224658), (9, 0.043401877861469984), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663526177406), (2, 0.054548466578125954), (52, 0.054696458391845226), (3, 0.0572242783382535), (13, 0.058922899421304464), (11, 0.05924913054332137), (17, 0.06095684785395861), (0, 0.06300980737432837), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979078710079), (18, 0.5108213126659393), (53, 0.9246633052825928)]
computing accuracy for after removing block 43 . block score: 0.018140302505344152
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.018882446456700563), (46, 0.019302030326798558), (42, 0.021432004403322935), (48, 0.02154484367929399), (40, 0.021832421654835343), (50, 0.02194626908749342), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.023006869480013847), (44, 0.0231085114646703), (45, 0.02353560645133257), (21, 0.024924597702920437), (22, 0.025168768595904112), (47, 0.025820445036515594), (24, 0.025899537838995457), (20, 0.02685900731012225), (38, 0.028114069486036897), (39, 0.02920690830796957), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.035091488156467676), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (52, 0.05332902958616614), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912681803107), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.0904204910621047), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 0.9678284004330635)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.01907008863054216), (48, 0.0206781686283648), (50, 0.02134439768269658), (40, 0.0218324214220047), (25, 0.021972602931782603), (42, 0.02198694017715752), (23, 0.022379535483196378), (49, 0.022534748073667288), (45, 0.023929917253553867), (44, 0.02405400271527469), (21, 0.024924597470089793), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.026043936843052506), (20, 0.02685900731012225), (38, 0.02811406902037561), (39, 0.029206908540800214), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.033794480841606855), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368643388152), (14, 0.0478366338647902), (52, 0.05047609331086278), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734052598476), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408283162862062), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 1.0278180092573166)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707740023732), (50, 0.02077506179921329), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.02191002992913127), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.023239311762154102), (45, 0.02358530880883336), (21, 0.024924597470089793), (47, 0.025076948339119554), (22, 0.025168768363073468), (24, 0.025899537838995457), (20, 0.02685900731012225), (38, 0.027183360187336802), (39, 0.028580758487805724), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03281426033936441), (37, 0.03542024362832308), (9, 0.043401881121098995), (6, 0.046609032433480024), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.048523630015552044), (2, 0.05454846750944853), (3, 0.05722427647560835), (13, 0.0589229017496109), (11, 0.059249126352369785), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831162109971046), (40, 0.021085952874273062), (42, 0.0213696479331702), (25, 0.021972602233290672), (23, 0.022379535483196378), (49, 0.022536989767104387), (44, 0.023239311994984746), (45, 0.023585307644680142), (21, 0.024924597702920437), (22, 0.025168769527226686), (24, 0.025899537838995457), (47, 0.026583048747852445), (20, 0.02685900777578354), (38, 0.02718336135149002), (39, 0.028580758487805724), (15, 0.03192339278757572), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.032850812654942274), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903010517359), (4, 0.04749368457123637), (14, 0.04783663526177406), (52, 0.04812479950487614), (2, 0.05454846424981952), (3, 0.05722428020089865), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.060956851579248905), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953572764993), (42, 0.02136964723467827), (25, 0.02197260269895196), (23, 0.02237953501753509), (50, 0.022470062598586082), (44, 0.023239311762154102), (45, 0.02358530880883336), (21, 0.024924598401412368), (22, 0.025168768130242825), (49, 0.025234101340174675), (24, 0.025899537140503526), (47, 0.026583048747852445), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03296921215951443), (37, 0.03542024502530694), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.047493682242929935), (14, 0.04783663433045149), (52, 0.05089045222848654), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4065233990550041), (18, 0.5108213126659393), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085953572764993
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.02128476626239717), (25, 0.021972602931782603), (23, 0.022379536414518952), (45, 0.023098317673429847), (44, 0.02424085745587945), (49, 0.02450086921453476), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899536907672882), (47, 0.02651969832368195), (20, 0.026859006145969033), (38, 0.027183360885828733), (39, 0.02858075895346701), (15, 0.03192339139059186), (51, 0.032220848836004734), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03542024455964565), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.04783663433045149), (52, 0.04885757202282548), (2, 0.054548466112464666), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108213052153587), (53, 1.3718615621328354)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.7714 topk_dict {'top1': 0.7714} is_best False lr [0.1]
training epoch 1 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 3 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 5 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 6 val accuracy 0.835 topk_dict {'top1': 0.835} is_best False lr [0.1]
training epoch 7 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 8 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 9 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 10 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.969200)
finished training. finished 50 epochs. accuracy 0.9692 topk_dict {'top1': 0.9692}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.040246. All blocks and scores: [(50, 0.04024609597399831), (49, 0.04564830055460334), (23, 0.04632880073040724), (45, 0.04702294338494539), (44, 0.04707931587472558), (22, 0.049821719992905855), (51, 0.0516413077712059), (21, 0.05185528099536896), (47, 0.05542600806802511), (25, 0.055648204404860735), (24, 0.05674045532941818), (20, 0.05692283296957612), (15, 0.059623814187943935), (7, 0.059895829763263464), (19, 0.06004906166344881), (38, 0.06091275345534086), (39, 0.06266149086877704), (52, 0.06513901567086577), (37, 0.07081708498299122), (9, 0.08824490569531918), (4, 0.08911045547574759), (6, 0.09140553511679173), (2, 0.09403648693114519), (3, 0.09414482768625021), (14, 0.09610768500715494), (11, 0.10014722496271133), (17, 0.1070632915943861), (0, 0.10885859373956919), (1, 0.10999760683625937), (13, 0.11438065767288208), (8, 0.11961984541267157), (16, 0.14723092131316662), (10, 0.14762461744248867), (12, 0.1571166981011629), (5, 0.196055194362998), (36, 0.6646211296319962), (18, 0.7385746091604233), (53, 0.9727693274617195)]
computing accuracy for after removing block 50 . block score: 0.04024609597399831
removed block 50 current accuracy 0.9584 loss from initial  0.04159999999999997
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.045648. All blocks and scores: [(49, 0.04564830148592591), (23, 0.046328801196068525), (45, 0.04702294385060668), (44, 0.04707931634038687), (22, 0.04982172045856714), (21, 0.051855281461030245), (47, 0.05542600899934769), (25, 0.05564820719882846), (51, 0.05667950073257089), (24, 0.056740453001111746), (20, 0.05692283483222127), (15, 0.05962381511926651), (7, 0.05989583022892475), (19, 0.0600490621291101), (38, 0.060912752989679575), (39, 0.0626614922657609), (37, 0.07081708498299122), (52, 0.07999643217772245), (9, 0.08824490569531918), (4, 0.08911045454442501), (6, 0.09140553325414658), (2, 0.09403648506850004), (3, 0.09414483141154051), (14, 0.09610768035054207), (11, 0.10014722123742104), (17, 0.10706328973174095), (0, 0.10885859373956919), (1, 0.10999760590493679), (13, 0.11438066139817238), (8, 0.11961984168738127), (16, 0.14723092503845692), (10, 0.14762461930513382), (12, 0.15711669996380806), (5, 0.1960551906377077), (36, 0.664621114730835), (18, 0.7385746166110039), (53, 1.1335223764181137)]
computing accuracy for after removing block 49 . block score: 0.04564830148592591
removed block 49 current accuracy 0.95 loss from initial  0.050000000000000044
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.046329. All blocks and scores: [(23, 0.04632880073040724), (45, 0.04702294431626797), (44, 0.04707931727170944), (22, 0.04982172138988972), (21, 0.05185528099536896), (47, 0.055426009465008974), (25, 0.055648206267505884), (24, 0.05674045393243432), (20, 0.05692283250391483), (51, 0.05932998098433018), (15, 0.059623814187943935), (7, 0.059895829763263464), (19, 0.06004906306043267), (38, 0.06091275392100215), (39, 0.06266149180009961), (37, 0.0708170859143138), (52, 0.08491841144859791), (9, 0.08824490569531918), (4, 0.08911045081913471), (6, 0.09140553139150143), (2, 0.09403648320585489), (3, 0.09414483048021793), (14, 0.09610768314450979), (11, 0.10014722310006618), (17, 0.10706329066306353), (0, 0.10885859746485949), (1, 0.10999760404229164), (13, 0.11438066232949495), (8, 0.11961984261870384), (16, 0.14723092317581177), (10, 0.14762461557984352), (12, 0.15711669996380806), (5, 0.19605519995093346), (36, 0.6646211072802544), (18, 0.7385746091604233), (53, 1.2091664224863052)]
computing accuracy for after removing block 23 . block score: 0.04632880073040724
removed block 23 current accuracy 0.9422 loss from initial  0.05779999999999996
since last training loss: 0.026999999999999913 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.046324. All blocks and scores: [(44, 0.04632355086505413), (45, 0.04701008880510926), (22, 0.04982172138988972), (21, 0.05185528099536896), (24, 0.05282021127641201), (47, 0.054213406052440405), (25, 0.05496189510449767), (20, 0.05692283250391483), (51, 0.058674284256994724), (15, 0.05962381372228265), (7, 0.059895829763263464), (19, 0.060049062594771385), (38, 0.0605530203320086), (39, 0.06253051105886698), (37, 0.07548503018915653), (52, 0.08374624978750944), (9, 0.08824490755796432), (4, 0.08911045175045729), (6, 0.09140553325414658), (2, 0.09403648506850004), (3, 0.09414482861757278), (14, 0.09610768593847752), (11, 0.10014722123742104), (17, 0.10706328880041838), (0, 0.10885859094560146), (1, 0.10999760590493679), (13, 0.11438065767288208), (8, 0.11961984634399414), (16, 0.14723092503845692), (10, 0.14762461557984352), (12, 0.1571167055517435), (5, 0.1960551980882883), (36, 0.6776968538761139), (18, 0.7385746240615845), (53, 1.1994960308074951)]
computing accuracy for after removing block 44 . block score: 0.04632355086505413
removed block 44 current accuracy 0.927 loss from initial  0.07299999999999995
since last training loss: 0.042199999999999904 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.049767. All blocks and scores: [(45, 0.04976739315316081), (22, 0.04982171952724457), (21, 0.05185528006404638), (24, 0.052820212207734585), (25, 0.05496189324185252), (20, 0.05692283296957612), (51, 0.0577126513235271), (47, 0.05811454774811864), (15, 0.059623816050589085), (7, 0.05989583022892475), (19, 0.06004906119778752), (38, 0.06055302172899246), (39, 0.06253051199018955), (37, 0.0754850311204791), (52, 0.08139230869710445), (9, 0.08824490662664175), (4, 0.08911045361310244), (6, 0.0914055360481143), (2, 0.09403648413717747), (3, 0.09414482861757278), (14, 0.09610768593847752), (11, 0.10014722403138876), (17, 0.10706328507512808), (0, 0.10885859187692404), (1, 0.10999760590493679), (13, 0.1143806604668498), (8, 0.11961984355002642), (16, 0.14723092317581177), (10, 0.14762461744248867), (12, 0.1571167018264532), (5, 0.1960551906377077), (36, 0.6776968464255333), (18, 0.7385746389627457), (53, 1.2962866127490997)]
computing accuracy for after removing block 45 . block score: 0.04976739315316081
removed block 45 current accuracy 0.905 loss from initial  0.09499999999999997
since last training loss: 0.06419999999999992 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.049822. All blocks and scores: [(22, 0.04982172045856714), (21, 0.051855281461030245), (24, 0.052820210345089436), (25, 0.05496189324185252), (20, 0.056922830641269684), (51, 0.057555082719773054), (15, 0.059623816050589085), (7, 0.05989582929760218), (19, 0.0600490621291101), (38, 0.060553021263331175), (39, 0.0625305101275444), (47, 0.06367525272071362), (37, 0.07548503298312426), (52, 0.08431602269411087), (9, 0.08824490662664175), (4, 0.08911045361310244), (6, 0.091405532322824), (2, 0.09403648786246777), (3, 0.09414482861757278), (14, 0.09610768314450979), (11, 0.10014722123742104), (17, 0.10706328973174095), (0, 0.10885859280824661), (1, 0.10999760869890451), (13, 0.1143806641921401), (8, 0.11961984448134899), (16, 0.14723091945052147), (10, 0.14762461744248867), (12, 0.15711669996380806), (5, 0.19605519250035286), (36, 0.6776968464255333), (18, 0.7385745793581009), (53, 1.3991788625717163)]
computing accuracy for after removing block 22 . block score: 0.04982172045856714
removed block 22 current accuracy 0.8938 loss from initial  0.10619999999999996
since last training loss: 0.07539999999999991 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.047731. All blocks and scores: [(24, 0.04773124260827899), (21, 0.05185528239235282), (25, 0.052373704966157675), (51, 0.055446427315473557), (20, 0.05692283436655998), (38, 0.05930276960134506), (15, 0.05962381372228265), (47, 0.05977592431008816), (7, 0.05989583069458604), (19, 0.0600490621291101), (39, 0.06150691956281662), (37, 0.07823637593537569), (52, 0.0789017491042614), (9, 0.08824490662664175), (4, 0.08911045733839273), (6, 0.09140553418546915), (2, 0.09403648413717747), (3, 0.09414482954889536), (14, 0.09610768314450979), (11, 0.10014722589403391), (17, 0.10706328973174095), (0, 0.10885859373956919), (1, 0.10999761149287224), (13, 0.11438066232949495), (8, 0.11961984820663929), (16, 0.14723091945052147), (10, 0.14762461557984352), (12, 0.1571166981011629), (5, 0.19605519250035286), (36, 0.674971766769886), (18, 0.7385746240615845), (53, 1.3801654428243637)]
computing accuracy for after removing block 24 . block score: 0.04773124260827899
removed block 24 current accuracy 0.8766 loss from initial  0.12339999999999995
since last training loss: 0.0925999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.050843. All blocks and scores: [(25, 0.050843366887420416), (51, 0.05162735329940915), (21, 0.051855281461030245), (38, 0.055040981620550156), (47, 0.0551691260188818), (20, 0.05692283296957612), (39, 0.05788438068702817), (15, 0.059623816050589085), (7, 0.059895829763263464), (19, 0.0600490621291101), (52, 0.07076939009130001), (37, 0.07230111677199602), (9, 0.0882449084892869), (4, 0.08911045454442501), (6, 0.09140553418546915), (2, 0.09403648506850004), (3, 0.09414483141154051), (14, 0.09610768407583237), (11, 0.10014722216874361), (17, 0.10706328600645065), (0, 0.10885859373956919), (1, 0.10999760963022709), (13, 0.11438066139817238), (8, 0.11961984634399414), (16, 0.14723092131316662), (10, 0.14762461930513382), (12, 0.15711670368909836), (5, 0.19605519250035286), (36, 0.6437323838472366), (18, 0.7385746166110039), (53, 1.3768489211797714)]
computing accuracy for after removing block 25 . block score: 0.050843366887420416
removed block 25 current accuracy 0.8532 loss from initial  0.14680000000000004
training start
training epoch 0 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.1]
training epoch 1 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 4 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 6 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 7 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.955200)
finished training. finished 50 epochs. accuracy 0.9552 topk_dict {'top1': 0.9552}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.066875. All blocks and scores: [(7, 0.06687547732144594), (15, 0.07407105155289173), (38, 0.07712000329047441), (51, 0.07800041325390339), (52, 0.07898739073425531), (19, 0.081412716768682), (37, 0.0817069448530674), (47, 0.0837387191131711), (20, 0.08437913563102484), (39, 0.08756377268582582), (21, 0.09236204158514738), (9, 0.0942902211099863), (4, 0.09642445016652346), (6, 0.09977708011865616), (2, 0.10752804018557072), (14, 0.11293953284621239), (1, 0.11522702220827341), (0, 0.11571189761161804), (17, 0.11716376710683107), (11, 0.11801437102258205), (3, 0.1185639277100563), (13, 0.12835113890469074), (8, 0.1365250777453184), (12, 0.17054147459566593), (10, 0.17130209878087044), (16, 0.18843630142509937), (5, 0.21850397065281868), (36, 0.6205174028873444), (18, 0.6644458398222923), (53, 1.0704305469989777)]
computing accuracy for after removing block 7 . block score: 0.06687547732144594
removed block 7 current accuracy 0.949 loss from initial  0.051000000000000045
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.070118. All blocks and scores: [(15, 0.07011785265058279), (52, 0.07525331992655993), (51, 0.07593136932700872), (37, 0.07625116687268019), (19, 0.07763517741113901), (38, 0.07834012899547815), (20, 0.08073996007442474), (47, 0.0818028012290597), (39, 0.08633329998701811), (21, 0.08822692651301622), (9, 0.09212552104145288), (4, 0.09642444830387831), (6, 0.09977707918733358), (17, 0.10065018385648727), (14, 0.10502986703068018), (2, 0.10752804204821587), (13, 0.10849676840007305), (11, 0.11090224329382181), (1, 0.11522702034562826), (0, 0.11571189854294062), (3, 0.11856392491608858), (8, 0.13010850176215172), (12, 0.15725106932222843), (10, 0.1717454195022583), (16, 0.17738000862300396), (5, 0.21850396879017353), (36, 0.6020675450563431), (18, 0.6392868608236313), (53, 1.0625069886446)]
computing accuracy for after removing block 15 . block score: 0.07011785265058279
removed block 15 current accuracy 0.9434 loss from initial  0.056599999999999984
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.073464. All blocks and scores: [(52, 0.07346416916698217), (37, 0.07398936804383993), (20, 0.07566558662801981), (38, 0.07578926719725132), (51, 0.07585667259991169), (19, 0.07763183955103159), (47, 0.08072376903146505), (21, 0.08411137852817774), (39, 0.08470270410180092), (9, 0.09212552011013031), (4, 0.09642444644123316), (6, 0.09977707825601101), (17, 0.10211019311100245), (14, 0.10502986703068018), (2, 0.10752803739160299), (13, 0.10849676933139563), (11, 0.11090224329382181), (1, 0.11522702313959599), (0, 0.11571189761161804), (3, 0.11856392864137888), (8, 0.13010849803686142), (12, 0.15725106559693813), (10, 0.171745415776968), (16, 0.19936241582036018), (5, 0.21850396133959293), (36, 0.572890892624855), (18, 0.6082177460193634), (53, 1.05207958817482)]
computing accuracy for after removing block 52 . block score: 0.07346416916698217
removed block 52 current accuracy 0.9214 loss from initial  0.0786
since last training loss: 0.03380000000000005 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 37, with score 0.073989. All blocks and scores: [(37, 0.07398936804383993), (20, 0.07566558662801981), (38, 0.0757892644032836), (51, 0.07585666980594397), (19, 0.07763183955103159), (47, 0.08072376903146505), (21, 0.08411138318479061), (39, 0.0847027050331235), (9, 0.09212552011013031), (4, 0.09642445016652346), (6, 0.09977707825601101), (17, 0.10211019311100245), (14, 0.10502986703068018), (2, 0.10752804018557072), (13, 0.10849677212536335), (11, 0.11090224422514439), (1, 0.11522702034562826), (0, 0.11571189481765032), (3, 0.11856392864137888), (8, 0.13010850176215172), (12, 0.15725106559693813), (10, 0.17174541763961315), (16, 0.19936242513358593), (5, 0.21850397624075413), (36, 0.5728909000754356), (18, 0.6082177460193634), (53, 1.297113761305809)]
computing accuracy for after removing block 37 . block score: 0.07398936804383993
removed block 37 current accuracy 0.8928 loss from initial  0.10719999999999996
since last training loss: 0.06240000000000001 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.067945. All blocks and scores: [(51, 0.06794501841068268), (47, 0.07524999044835567), (20, 0.07566558569669724), (19, 0.07763183955103159), (39, 0.08303281106054783), (21, 0.08411138039082289), (38, 0.0863201105967164), (9, 0.09212551731616259), (4, 0.09642444830387831), (6, 0.09977707732468843), (17, 0.1021101949736476), (14, 0.10502986889332533), (2, 0.10752804204821587), (13, 0.10849677212536335), (11, 0.11090224236249924), (1, 0.11522702407091856), (0, 0.11571190226823092), (3, 0.11856392677873373), (8, 0.13010850548744202), (12, 0.15725106745958328), (10, 0.17174541763961315), (16, 0.19936241582036018), (5, 0.21850397251546383), (36, 0.5728909000754356), (18, 0.6082177460193634), (53, 1.2506221383810043)]
computing accuracy for after removing block 51 . block score: 0.06794501841068268
removed block 51 current accuracy 0.8262 loss from initial  0.17379999999999995
since last training loss: 0.129 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 47, with score 0.075250. All blocks and scores: [(47, 0.07524999044835567), (20, 0.07566558569669724), (19, 0.07763184048235416), (39, 0.08303281012922525), (21, 0.08411138318479061), (38, 0.08632011152803898), (9, 0.09212552197277546), (4, 0.09642444923520088), (6, 0.09977707825601101), (17, 0.1021101949736476), (14, 0.10502986889332533), (2, 0.10752804204821587), (13, 0.10849676746875048), (11, 0.11090224049985409), (1, 0.11522702034562826), (0, 0.11571189295500517), (3, 0.11856392584741116), (8, 0.13010850176215172), (12, 0.15725107118487358), (10, 0.1717454195022583), (16, 0.19936242140829563), (5, 0.21850396879017353), (36, 0.572890892624855), (18, 0.6082177311182022), (53, 1.5047969669103622)]
computing accuracy for after removing block 47 . block score: 0.07524999044835567
removed block 47 current accuracy 0.7482 loss from initial  0.2518
since last training loss: 0.20700000000000007 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 20, with score 0.075666. All blocks and scores: [(20, 0.07566558569669724), (19, 0.07763184141367674), (39, 0.08303281292319298), (21, 0.08411138132214546), (38, 0.08632011152803898), (9, 0.09212552104145288), (4, 0.09642444644123316), (6, 0.09977707918733358), (17, 0.10211019217967987), (14, 0.10502987075597048), (2, 0.10752804297953844), (13, 0.10849676746875048), (11, 0.11090224608778954), (1, 0.11522702220827341), (0, 0.11571189668029547), (3, 0.11856392677873373), (8, 0.13010849803686142), (12, 0.15725106745958328), (10, 0.17174542136490345), (16, 0.19936241954565048), (5, 0.21850396692752838), (36, 0.572890892624855), (18, 0.6082177311182022), (53, 1.6704837530851364)]
computing accuracy for after removing block 20 . block score: 0.07566558569669724
removed block 20 current accuracy 0.739 loss from initial  0.261
since last training loss: 0.21620000000000006 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 19, with score 0.077632. All blocks and scores: [(19, 0.07763184141367674), (21, 0.08376676868647337), (39, 0.0875256210565567), (38, 0.09004393685609102), (9, 0.09212551545351744), (4, 0.09642444923520088), (6, 0.09977707918733358), (17, 0.10211019031703472), (14, 0.10502986889332533), (2, 0.10752804204821587), (13, 0.1084967739880085), (11, 0.11090224422514439), (1, 0.11522702407091856), (0, 0.11571189854294062), (3, 0.11856392677873373), (8, 0.13010849617421627), (12, 0.15725106559693813), (10, 0.17174541391432285), (16, 0.19936242140829563), (5, 0.21850396506488323), (36, 0.5915271267294884), (18, 0.6082177236676216), (53, 1.6267808079719543)]
computing accuracy for after removing block 19 . block score: 0.07763184141367674
removed block 19 current accuracy 0.6898 loss from initial  0.31020000000000003
since last training loss: 0.2654000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 21, with score 0.079071. All blocks and scores: [(21, 0.0790710961446166), (38, 0.08549624960869551), (39, 0.08981293812394142), (9, 0.09212551731616259), (4, 0.09642444830387831), (6, 0.09977708011865616), (17, 0.10211019217967987), (14, 0.10502986703068018), (2, 0.10752804018557072), (13, 0.1084967702627182), (11, 0.11090224329382181), (1, 0.11522702686488628), (0, 0.11571189574897289), (3, 0.11856392491608858), (8, 0.13010850176215172), (12, 0.15725106932222843), (10, 0.1717454195022583), (16, 0.19936242513358593), (5, 0.21850396320223808), (36, 0.5900658369064331), (18, 0.6082177460193634), (53, 1.6100856959819794)]
computing accuracy for after removing block 21 . block score: 0.0790710961446166
removed block 21 current accuracy 0.6442 loss from initial  0.3558
training start
training epoch 0 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best True lr [0.1]
training epoch 1 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 2 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 3 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.1]
training epoch 4 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 5 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 6 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 7 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 8 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 9 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 10 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.935200)
finished training. finished 50 epochs. accuracy 0.9352 topk_dict {'top1': 0.9352}
