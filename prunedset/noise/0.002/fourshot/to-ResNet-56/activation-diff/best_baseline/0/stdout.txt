start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050746843219), (30, 0.010039400891400874), (31, 0.010361600085161626), (34, 0.01331227645277977), (29, 0.013541154563426971), (35, 0.016018463065847754), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020232456969097257), (46, 0.02104453998617828), (25, 0.021972602233290672), (23, 0.02237953571602702), (41, 0.0228266476187855), (44, 0.02339507918804884), (40, 0.024025024846196175), (45, 0.024295410607010126), (21, 0.024924598168581724), (22, 0.02516876789741218), (48, 0.025341259315609932), (24, 0.025899537838995457), (50, 0.026409972459077835), (42, 0.0266741004306823), (20, 0.02685900731012225), (49, 0.027037163730710745), (47, 0.029306469950824976), (39, 0.03157071373425424), (38, 0.031637872103601694), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.0379602606408298), (51, 0.04173417389392853), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734238862991), (52, 0.06862937472760677), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.43757999688386917), (18, 0.5108212903141975), (53, 0.8211488872766495)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039401007816195), (31, 0.010361600201576948), (34, 0.013133947737514973), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169289592653513), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020072476705536246), (46, 0.02073138509877026), (25, 0.021972602931782603), (41, 0.022347092628479004), (23, 0.02237953501753509), (44, 0.023235687520354986), (40, 0.023841066984459758), (45, 0.023965542437508702), (48, 0.024917915696278214), (21, 0.02492459793575108), (22, 0.025168768363073468), (50, 0.02584081282839179), (24, 0.025899537606164813), (42, 0.026315322844311595), (49, 0.02665567584335804), (20, 0.02685900777578354), (47, 0.028728798497468233), (39, 0.03131764195859432), (38, 0.031380364671349525), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.038025843910872936), (51, 0.041223940439522266), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.057224278803914785), (13, 0.05892289988696575), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06745155062526464), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.43538710847496986), (18, 0.5108213052153587), (53, 0.822257399559021)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400192908943), (31, 0.010361600434407592), (34, 0.012765232473611832), (29, 0.013541154679842293), (35, 0.015992751345038414), (26, 0.01603759080171585), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020075131906196475), (46, 0.02084140619263053), (25, 0.021972603164613247), (41, 0.0223197671584785), (23, 0.02237953501753509), (44, 0.023154050577431917), (40, 0.023885684553533792), (45, 0.024071688996627927), (48, 0.024877465330064297), (21, 0.024924598401412368), (22, 0.025168768595904112), (50, 0.025691178627312183), (24, 0.02589953667484224), (42, 0.026123747462406754), (49, 0.026479421881958842), (20, 0.026859006844460964), (47, 0.028693131636828184), (38, 0.031236796407029033), (39, 0.03129529138095677), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03837669128552079), (51, 0.041114034596830606), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.05892289988696575), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734331995249), (52, 0.06700456235557795), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.43640001118183136), (18, 0.5108213052153587), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039400192908943
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387836934067309), (29, 0.013541154330596328), (35, 0.01600809581577778), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02008363325148821), (46, 0.020704444497823715), (25, 0.021972602233290672), (41, 0.02225319715216756), (23, 0.022379535483196378), (44, 0.02326776087284088), (40, 0.02401388087309897), (45, 0.024092992767691612), (48, 0.02466528001241386), (21, 0.024924597702920437), (22, 0.025168768595904112), (50, 0.025459734722971916), (42, 0.025655713165178895), (24, 0.025899537140503526), (49, 0.02628775662742555), (20, 0.026859007542952895), (47, 0.02836342342197895), (38, 0.031047646654769778), (39, 0.03138077212497592), (15, 0.03192339278757572), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.05454846750944853), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980923697352), (52, 0.06586316041648388), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4389924630522728), (18, 0.5108213126659393), (53, 0.8391561731696129)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.013541154330596328), (26, 0.016037591034546494), (35, 0.016057363245636225), (28, 0.017728674924001098), (27, 0.019127048552036285), (43, 0.020049349637702107), (46, 0.020552986999973655), (25, 0.02197260269895196), (41, 0.02206748374737799), (23, 0.02237953571602702), (44, 0.022979132598266006), (40, 0.023858347442001104), (45, 0.024124702205881476), (48, 0.02438612305559218), (21, 0.024924597470089793), (50, 0.025042241672053933), (22, 0.025168767664581537), (42, 0.025414507603272796), (49, 0.02584269898943603), (24, 0.02589953737333417), (20, 0.026859007542952895), (47, 0.028050734661519527), (38, 0.03104005940258503), (39, 0.03150080353952944), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.032628596760332584), (37, 0.03911284916102886), (51, 0.04024627339094877), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.054548466578125954), (3, 0.05722427740693092), (13, 0.05892290314659476), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.0630098101682961), (52, 0.06486208783462644), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4381278343498707), (18, 0.5108213052153587), (53, 0.8458427786827087)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.016037591267377138), (35, 0.01665342040359974), (28, 0.01772867515683174), (27, 0.019127048319205642), (43, 0.020503456005826592), (46, 0.020725322188809514), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.02245262893848121), (44, 0.023364474531263113), (48, 0.02429035515524447), (45, 0.024438712280243635), (40, 0.024470558622851968), (21, 0.024924597470089793), (50, 0.02504217275418341), (22, 0.025168768130242825), (49, 0.025875970721244812), (24, 0.02589953737333417), (42, 0.02620540652424097), (20, 0.026859006844460964), (47, 0.028178583830595016), (15, 0.03192339139059186), (38, 0.032083502039313316), (7, 0.0322854476980865), (39, 0.03233744157478213), (19, 0.03262859582901001), (51, 0.039947259705513716), (37, 0.04073968157172203), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.04783663572743535), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.0630098101682961), (52, 0.06433630269020796), (1, 0.06676734238862991), (8, 0.07467831950634718), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.45053431019186974), (18, 0.5108213201165199), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 1 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 2 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 3 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 4 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 5 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 6 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 7 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.1]
training epoch 8 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 9 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 10 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.016470608301460743), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.0200468678958714), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.02197260339744389), (23, 0.022379535948857665), (44, 0.023028337163850665), (48, 0.02377187693491578), (40, 0.023930813185870647), (45, 0.024178663501515985), (50, 0.02439029887318611), (21, 0.02492459863424301), (22, 0.025168768595904112), (42, 0.025188251165673137), (49, 0.025361529318615794), (24, 0.025899537140503526), (20, 0.02685900731012225), (47, 0.0273632793687284), (38, 0.03136561857536435), (15, 0.031923392321914434), (39, 0.03212768491357565), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.038935924880206585), (37, 0.040206344332545996), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663293346763), (2, 0.05454846331849694), (3, 0.05722427926957607), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.06095684878528118), (52, 0.06232855189591646), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4444201923906803), (18, 0.5108213052153587), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365680150688), (28, 0.01708850055001676), (27, 0.01888244762085378), (43, 0.019595166202634573), (46, 0.02007358125410974), (41, 0.02096158522181213), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.022814956260845065), (48, 0.023128160974010825), (40, 0.023345195222645998), (50, 0.023756146896630526), (42, 0.023847303353250027), (45, 0.02387388003990054), (21, 0.02492459793575108), (49, 0.024960315553471446), (22, 0.0251687690615654), (24, 0.02589953737333417), (47, 0.02685554209165275), (20, 0.026859006844460964), (38, 0.030424013268202543), (39, 0.03151404485106468), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03782488126307726), (37, 0.03936835192143917), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.054548466578125954), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.059249128215014935), (52, 0.060332820285111666), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4360685423016548), (18, 0.5108213052153587), (53, 0.8749377205967903)]
computing accuracy for after removing block 35 . block score: 0.015597365680150688
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.01708850055001676), (43, 0.018555945716798306), (27, 0.018882447155192494), (46, 0.019160084892064333), (41, 0.019424295285716653), (48, 0.021467272425070405), (25, 0.021972602931782603), (44, 0.02202691580168903), (40, 0.02217966108582914), (42, 0.02220643009059131), (50, 0.02225612965412438), (23, 0.022379535948857665), (45, 0.022931481013074517), (49, 0.023708512308076024), (21, 0.024924597702920437), (22, 0.025168767431750894), (47, 0.025829139165580273), (24, 0.025899537606164813), (20, 0.026859006378799677), (38, 0.02895654598250985), (39, 0.029667828232049942), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.036009025294333696), (37, 0.036512387450784445), (9, 0.04340188018977642), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.05454846424981952), (52, 0.05610728915780783), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.05924913054332137), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.41757645457983017), (18, 0.5108213052153587), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.01708850055001676
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102241948247), (41, 0.018849018262699246), (27, 0.018882446456700563), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.021832421189174056), (44, 0.02184053068049252), (50, 0.021869863849133253), (25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.022492847638204694), (49, 0.023123498307541013), (21, 0.024924598401412368), (47, 0.02506713941693306), (22, 0.025168767664581537), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.028114070184528828), (39, 0.0292069090064615), (15, 0.031923392321914434), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.0354543374851346), (37, 0.03597763925790787), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.04783663526177406), (2, 0.05454846424981952), (52, 0.05469645792618394), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.1066738748922944), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9246632605791092)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018262699246), (27, 0.018882447155192494), (46, 0.019302030326798558), (42, 0.02143200463615358), (48, 0.021544843446463346), (40, 0.021832421654835343), (50, 0.021946269553154707), (25, 0.02197260339744389), (23, 0.022379535483196378), (49, 0.023006869480013847), (44, 0.023108510533347726), (45, 0.023535606218501925), (21, 0.024924598867073655), (22, 0.025168768363073468), (47, 0.0258204466663301), (24, 0.025899537140503526), (20, 0.026859006378799677), (38, 0.028114069486036897), (39, 0.029206909239292145), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.035091488156467676), (37, 0.03597763832658529), (9, 0.043401881121098995), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.05332902958616614), (2, 0.054548466578125954), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.1066738748922944), (36, 0.4135979153215885), (18, 0.5108213126659393), (53, 0.9678284078836441)]
computing accuracy for after removing block 41 . block score: 0.018849018262699246
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.019070088397711515), (48, 0.020678168162703514), (50, 0.02134439768269658), (40, 0.021832420956343412), (25, 0.021972602233290672), (42, 0.02198694064281881), (23, 0.022379535483196378), (49, 0.02253474830649793), (45, 0.023929917719215155), (44, 0.02405400318093598), (21, 0.024924597470089793), (22, 0.025168767664581537), (24, 0.025899537140503526), (47, 0.02604393707588315), (20, 0.026859006844460964), (38, 0.028114069951698184), (39, 0.02920690947212279), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859769165516), (51, 0.03379447991028428), (37, 0.03597764065489173), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.05047609470784664), (2, 0.05454846518114209), (3, 0.057224275544285774), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108212903141975), (53, 1.027817964553833)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
training start
training epoch 0 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 1 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 2 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 3 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 4 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 5 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 6 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 7 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 8 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 9 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 10 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.987000)
finished training. finished 50 epochs. accuracy 0.987 topk_dict {'top1': 0.987}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.019989707740023732), (50, 0.020775061566382647), (40, 0.021085953107103705), (42, 0.021369647700339556), (49, 0.0219100306276232), (25, 0.02197260269895196), (23, 0.022379535948857665), (44, 0.02323931152932346), (45, 0.023585309041664004), (21, 0.024924598867073655), (47, 0.025076948339119554), (22, 0.025168768595904112), (24, 0.02589953620918095), (20, 0.026859007542952895), (38, 0.02718336065299809), (39, 0.02858076011762023), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.0328142608050257), (37, 0.03542024549096823), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.048523630015552044), (2, 0.05454846378415823), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4065234065055847), (18, 0.5108212977647781), (53, 1.038420483469963)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831161178648472), (40, 0.021085953805595636), (42, 0.02136964723467827), (25, 0.021972603164613247), (23, 0.022379535483196378), (49, 0.022536988835781813), (44, 0.023239311762154102), (45, 0.02358530811034143), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.0265830485150218), (20, 0.02685900777578354), (38, 0.027183360420167446), (39, 0.028580758022144437), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628596760332584), (51, 0.032850812654942274), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.046609030570834875), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.04812479950487614), (2, 0.05454846704378724), (3, 0.057224276941269636), (13, 0.058922902680933475), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386744171381), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952874273062), (42, 0.021369648166000843), (25, 0.02197260269895196), (23, 0.022379535483196378), (50, 0.02247006236575544), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924597004428506), (22, 0.025168769527226686), (49, 0.02523410157300532), (24, 0.02589953737333417), (47, 0.026583050144836307), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.028580758022144437), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03296921029686928), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.05089045176282525), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.05892290035262704), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.2663908749818802)]
computing accuracy for after removing block 40 . block score: 0.021085952874273062
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284765796735883), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.024500869447365403), (21, 0.024924597702920437), (22, 0.0251687690615654), (24, 0.025899536907672882), (47, 0.026519698789343238), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339092493057), (51, 0.03222084976732731), (7, 0.03228544816374779), (19, 0.03262859536334872), (37, 0.03542024362832308), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663246780634), (52, 0.04885757155716419), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.0589228980243206), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300981156527996), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.3718615770339966)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.041000000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.021972603164613247), (23, 0.02237953571602702), (45, 0.023761966032907367), (49, 0.024602338206022978), (44, 0.024712180951610208), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.025899537140503526), (47, 0.02622047532349825), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580758720636368), (51, 0.03127906774170697), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.04340188018977642), (52, 0.0461017107591033), (6, 0.04660903289914131), (4, 0.04749368457123637), (14, 0.04783663572743535), (2, 0.05454846518114209), (3, 0.05722427973523736), (13, 0.05892290221527219), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734052598476), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.023761966498568654), (49, 0.02460233890451491), (44, 0.024712180951610208), (21, 0.024924598401412368), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.02622047415934503), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03344302112236619), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493682242929935), (14, 0.047836633399128914), (52, 0.05265179229900241), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.058922902680933475), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.6287681013345718)]
computing accuracy for after removing block 25 . block score: 0.02197260269895196
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 1 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 2 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 3 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 4 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 5 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 6 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 7 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 8 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 9 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 10 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9668 topk_dict {'top1': 0.9668}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.047332. All blocks and scores: [(49, 0.047332147136330605), (45, 0.04957417957484722), (44, 0.05061302939429879), (47, 0.05390011006966233), (21, 0.05434793373569846), (22, 0.05478412425145507), (7, 0.055655133444815874), (15, 0.05618477892130613), (23, 0.05644521862268448), (20, 0.059040597174316645), (38, 0.05905816052109003), (19, 0.059765465557575226), (51, 0.06144768884405494), (39, 0.06442509312182665), (24, 0.06528338510543108), (52, 0.06986850406974554), (37, 0.07208052556961775), (4, 0.07496406976133585), (9, 0.08432543091475964), (6, 0.08507355209439993), (2, 0.09631566237658262), (14, 0.09797481540590525), (3, 0.09861726779490709), (0, 0.10505311749875546), (11, 0.10667584091424942), (17, 0.11036605853587389), (13, 0.1166662834584713), (8, 0.11893209721893072), (1, 0.12126562930643559), (10, 0.15461401641368866), (12, 0.15614106692373753), (16, 0.16408103518188), (5, 0.20791307277977467), (36, 0.621783472597599), (18, 0.6836854591965675), (53, 0.9948142319917679)]
computing accuracy for after removing block 49 . block score: 0.047332147136330605
removed block 49 current accuracy 0.9552 loss from initial  0.04479999999999995
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.049574. All blocks and scores: [(45, 0.04957418097183108), (44, 0.05061302753165364), (47, 0.05390010913833976), (21, 0.054347934667021036), (22, 0.054784124717116356), (7, 0.05565513204783201), (15, 0.056184778455644846), (23, 0.05644521955400705), (20, 0.05904059763997793), (38, 0.05905815865844488), (19, 0.05976546322926879), (39, 0.06442509312182665), (24, 0.06528338603675365), (51, 0.06641353107988834), (37, 0.07208052650094032), (52, 0.07451953645795584), (4, 0.074964071623981), (9, 0.08432543277740479), (6, 0.08507355209439993), (2, 0.0963156633079052), (14, 0.09797481074929237), (3, 0.09861727152019739), (0, 0.10505311843007803), (11, 0.10667584091424942), (17, 0.11036606319248676), (13, 0.11666628438979387), (8, 0.1189320981502533), (1, 0.12126563303172588), (10, 0.1546140145510435), (12, 0.15614106692373753), (16, 0.16408104076981544), (5, 0.20791307464241982), (36, 0.6217834651470184), (18, 0.6836854368448257), (53, 1.0784312933683395)]
computing accuracy for after removing block 45 . block score: 0.04957418097183108
removed block 45 current accuracy 0.9476 loss from initial  0.0524
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.050613. All blocks and scores: [(44, 0.05061302753165364), (21, 0.054347934667021036), (22, 0.05478412425145507), (7, 0.055655134841799736), (15, 0.05618477612733841), (23, 0.056445220950990915), (20, 0.05904059810563922), (38, 0.05905816005542874), (19, 0.059765464160591364), (47, 0.06015660800039768), (39, 0.06442509219050407), (51, 0.06450745789334178), (24, 0.06528338696807623), (37, 0.07208052556961775), (4, 0.07496407069265842), (52, 0.07579664327204227), (9, 0.08432543091475964), (6, 0.08507355023175478), (2, 0.0963156633079052), (14, 0.0979748135432601), (3, 0.09861726965755224), (0, 0.10505311843007803), (11, 0.10667584277689457), (17, 0.11036606505513191), (13, 0.1166662834584713), (8, 0.11893209628760815), (1, 0.12126563023775816), (10, 0.15461401268839836), (12, 0.15614106878638268), (16, 0.16408103704452515), (5, 0.20791307091712952), (36, 0.6217834427952766), (18, 0.6836854368448257), (53, 1.188035249710083)]
computing accuracy for after removing block 44 . block score: 0.05061302753165364
removed block 44 current accuracy 0.9274 loss from initial  0.0726
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.054348. All blocks and scores: [(21, 0.054347933270037174), (22, 0.05478412518277764), (7, 0.05565513111650944), (15, 0.05618477798998356), (23, 0.05644522048532963), (20, 0.059040595311671495), (38, 0.059058158192783594), (19, 0.059765467420220375), (51, 0.0632620956748724), (39, 0.06442509312182665), (24, 0.06528338324278593), (47, 0.06718905083835125), (37, 0.07208052556961775), (4, 0.07496407255530357), (52, 0.07859824411571026), (9, 0.08432543184608221), (6, 0.08507355023175478), (2, 0.09631566237658262), (14, 0.09797481819987297), (3, 0.09861726965755224), (0, 0.1050531230866909), (11, 0.10667584463953972), (17, 0.11036605853587389), (13, 0.1166662871837616), (8, 0.11893209721893072), (1, 0.12126562837511301), (10, 0.1546140145510435), (12, 0.15614106506109238), (16, 0.16408104076981544), (5, 0.20791308023035526), (36, 0.6217834651470184), (18, 0.6836854368448257), (53, 1.311419889330864)]
computing accuracy for after removing block 21 . block score: 0.054347933270037174
removed block 21 current accuracy 0.9192 loss from initial  0.08079999999999998
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.048242. All blocks and scores: [(22, 0.0482422667555511), (23, 0.04997833026573062), (38, 0.05482493154704571), (7, 0.055655133444815874), (15, 0.0561847765929997), (24, 0.05638369219377637), (20, 0.05904059810563922), (19, 0.05976546602323651), (51, 0.05984022794291377), (47, 0.062450898345559835), (39, 0.06261081201955676), (37, 0.068341463804245), (52, 0.07234642840921879), (4, 0.07496407069265842), (9, 0.08432542905211449), (6, 0.08507355023175478), (2, 0.0963156633079052), (14, 0.0979748135432601), (3, 0.09861727152019739), (0, 0.10505312029272318), (11, 0.10667584091424942), (17, 0.11036606412380934), (13, 0.1166662834584713), (8, 0.1189320981502533), (1, 0.12126563210040331), (10, 0.1546140145510435), (12, 0.15614106878638268), (16, 0.16408103518188), (5, 0.20791307650506496), (36, 0.5841816142201424), (18, 0.6836854368448257), (53, 1.3369049727916718)]
computing accuracy for after removing block 22 . block score: 0.0482422667555511
removed block 22 current accuracy 0.9006 loss from initial  0.09940000000000004
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.047621. All blocks and scores: [(23, 0.04762138007208705), (24, 0.05191837623715401), (38, 0.05325333122164011), (7, 0.05565513297915459), (15, 0.05618477752432227), (51, 0.057268917094916105), (47, 0.05745420791208744), (20, 0.05904059624299407), (19, 0.05976546462625265), (39, 0.061642144341021776), (52, 0.06833787728101015), (37, 0.07017447985708714), (4, 0.07496407255530357), (9, 0.08432542905211449), (6, 0.0850735493004322), (2, 0.0963156633079052), (14, 0.0979748172685504), (3, 0.09861727152019739), (0, 0.10505311656743288), (11, 0.106675841845572), (17, 0.11036605853587389), (13, 0.11666628252714872), (8, 0.11893210094422102), (1, 0.12126563210040331), (10, 0.1546140145510435), (12, 0.15614106692373753), (16, 0.1640810389071703), (5, 0.207913089543581), (36, 0.5772966891527176), (18, 0.6836854293942451), (53, 1.3551808446645737)]
computing accuracy for after removing block 23 . block score: 0.04762138007208705
removed block 23 current accuracy 0.8726 loss from initial  0.12739999999999996
since last training loss: 0.09419999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.051236. All blocks and scores: [(24, 0.051235883962363005), (38, 0.05424748873338103), (7, 0.055655131582170725), (15, 0.056184778455644846), (51, 0.05643364880234003), (47, 0.05683186883106828), (20, 0.05904059857130051), (19, 0.05976546322926879), (39, 0.0632473137229681), (52, 0.06848227139562368), (4, 0.07496407255530357), (37, 0.07661114726215601), (9, 0.08432543091475964), (6, 0.08507355209439993), (2, 0.09631566237658262), (14, 0.0979748135432601), (3, 0.09861727058887482), (0, 0.1050531156361103), (11, 0.10667584277689457), (17, 0.11036606039851904), (13, 0.11666628438979387), (8, 0.11893209535628557), (1, 0.12126563210040331), (10, 0.15461401641368866), (12, 0.15614106319844723), (16, 0.1640810389071703), (5, 0.20791307464241982), (36, 0.6047494411468506), (18, 0.6836854368448257), (53, 1.3587181270122528)]
computing accuracy for after removing block 24 . block score: 0.051235883962363005
removed block 24 current accuracy 0.8322 loss from initial  0.16779999999999995
since last training loss: 0.13459999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.052217. All blocks and scores: [(38, 0.0522165521979332), (47, 0.05292921978980303), (51, 0.052975071128457785), (7, 0.055655133444815874), (15, 0.056184777058660984), (20, 0.05904059810563922), (19, 0.059765465557575226), (39, 0.06120038637891412), (52, 0.06461673229932785), (37, 0.07458374369889498), (4, 0.07496407255530357), (9, 0.08432542812079191), (6, 0.08507355023175478), (2, 0.09631566144526005), (14, 0.09797481540590525), (3, 0.09861727058887482), (0, 0.10505311843007803), (11, 0.106675841845572), (17, 0.11036606132984161), (13, 0.1166662834584713), (8, 0.11893209721893072), (1, 0.12126563210040331), (10, 0.15461401641368866), (12, 0.15614106506109238), (16, 0.1640810389071703), (5, 0.20791307464241982), (36, 0.6030275151133537), (18, 0.6836854219436646), (53, 1.3822975307703018)]
computing accuracy for after removing block 38 . block score: 0.0522165521979332
removed block 38 current accuracy 0.7994 loss from initial  0.2006
since last training loss: 0.1674 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.051886. All blocks and scores: [(51, 0.0518857822753489), (47, 0.05212138220667839), (7, 0.055655131582170725), (15, 0.05618477752432227), (20, 0.05904059810563922), (19, 0.05976546509191394), (52, 0.0635622632689774), (39, 0.06687507778406143), (37, 0.07458374463021755), (4, 0.07496407255530357), (9, 0.08432543091475964), (6, 0.08507355209439993), (2, 0.0963156633079052), (14, 0.09797481540590525), (3, 0.09861727152019739), (0, 0.10505311470478773), (11, 0.10667584463953972), (17, 0.11036606132984161), (13, 0.11666628252714872), (8, 0.11893209721893072), (1, 0.12126563396304846), (10, 0.1546140145510435), (12, 0.15614106506109238), (16, 0.16408104076981544), (5, 0.20791307277977467), (36, 0.6030274853110313), (18, 0.6836854293942451), (53, 1.4559396505355835)]
computing accuracy for after removing block 51 . block score: 0.0518857822753489
removed block 51 current accuracy 0.729 loss from initial  0.271
training start
training epoch 0 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.1]
training epoch 1 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 2 val accuracy 0.822 topk_dict {'top1': 0.822} is_best False lr [0.1]
training epoch 3 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 5 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 6 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.1]
training epoch 7 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.1]
training epoch 8 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 9 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
