start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.00923305086325854), (30, 0.01003940065857023), (31, 0.01036160031799227), (34, 0.013312276219949126), (29, 0.013541154330596328), (35, 0.016018462600186467), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02023245650343597), (46, 0.021044540451839566), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.0228266476187855), (44, 0.023395078955218196), (40, 0.02402502507902682), (45, 0.024295411072671413), (21, 0.024924597470089793), (22, 0.02516876789741218), (48, 0.025341259548440576), (24, 0.02589953737333417), (50, 0.026409972459077835), (42, 0.02667410089634359), (20, 0.026859007077291608), (49, 0.02703716466203332), (47, 0.029306468553841114), (39, 0.031570712802931666), (38, 0.03163787163794041), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.0379602606408298), (51, 0.041734172496944666), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734145730734), (52, 0.06862937472760677), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.43758001178503036), (18, 0.5108212903141975), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050979673862), (30, 0.010039400309324265), (31, 0.01036160031799227), (34, 0.013133946806192398), (29, 0.013541154563426971), (26, 0.01603759010322392), (35, 0.016169289592653513), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02007247693836689), (46, 0.020731384865939617), (25, 0.02197260269895196), (41, 0.022347092628479004), (23, 0.022379535483196378), (44, 0.023235687287524343), (40, 0.0238410672172904), (45, 0.02396554220467806), (48, 0.024917916161939502), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.025840812595561147), (24, 0.02589953667484224), (42, 0.02631532377563417), (49, 0.02665567514486611), (20, 0.02685900731012225), (47, 0.028728798031806946), (39, 0.03131764172576368), (38, 0.031380362808704376), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03802584297955036), (51, 0.041223940439522266), (9, 0.043401877861469984), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.05892290314659476), (11, 0.05924913100898266), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734331995249), (52, 0.0674515487626195), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.43538710847496986), (18, 0.5108212977647781), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050979673862
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400891400874), (31, 0.010361600201576948), (34, 0.012765232939273119), (29, 0.01354115444701165), (35, 0.015992750879377127), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048086374998), (43, 0.020075131906196475), (46, 0.020841405959799886), (25, 0.021972602466121316), (41, 0.022319766925647855), (23, 0.022379535250365734), (44, 0.02315405081026256), (40, 0.02388568432070315), (45, 0.024071688996627927), (48, 0.024877465795725584), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.02569117769598961), (24, 0.025899537838995457), (42, 0.02612374722957611), (49, 0.026479422114789486), (20, 0.026859007077291608), (47, 0.028693131636828184), (38, 0.031236795475706458), (39, 0.031295292312279344), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03837669128552079), (51, 0.04111403273418546), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846704378724), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249126352369785), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734425127506), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049571871758), (5, 0.1066738748922944), (36, 0.43640000745654106), (18, 0.5108212977647781), (53, 0.8289349228143692)]
computing accuracy for after removing block 30 . block score: 0.010039400891400874
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.01238783705048263), (29, 0.013541154563426971), (35, 0.01600809581577778), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.02070444426499307), (25, 0.021972602466121316), (41, 0.022253196919336915), (23, 0.022379535483196378), (44, 0.023267761105671525), (40, 0.02401388087309897), (45, 0.024092993466183543), (48, 0.024665280245244503), (21, 0.024924598168581724), (22, 0.025168768595904112), (50, 0.02545973425731063), (42, 0.02565571293234825), (24, 0.025899538537487388), (49, 0.02628775709308684), (20, 0.026859007542952895), (47, 0.028363423654809594), (38, 0.031047647818922997), (39, 0.03138077235780656), (15, 0.031923390459269285), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03897124482318759), (51, 0.04075620323419571), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300981063395739), (52, 0.06586316134780645), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4389924630522728), (18, 0.5108213052153587), (53, 0.8391561806201935)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.01248961966484785), (29, 0.013541154563426971), (26, 0.01603759010322392), (35, 0.016057363245636225), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02004934917204082), (46, 0.020552986999973655), (25, 0.02197260269895196), (41, 0.022067484445869923), (23, 0.022379535250365734), (44, 0.02297913283109665), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.024386123521253467), (21, 0.02492459793575108), (50, 0.025042241672053933), (22, 0.025168768130242825), (42, 0.025414507370442152), (49, 0.025842698756605387), (24, 0.025899536907672882), (20, 0.026859006844460964), (47, 0.028050735127180815), (38, 0.031040059635415673), (39, 0.031500802375376225), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.039112848695367575), (51, 0.04024627339094877), (9, 0.04340188065543771), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095684692263603), (0, 0.06300980830565095), (52, 0.0648620892316103), (1, 0.06676734052598476), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.438127838075161), (18, 0.5108213126659393), (53, 0.845842756330967)]
computing accuracy for after removing block 34 . block score: 0.01248961966484785
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.016037591034546494), (35, 0.016653420636430383), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.022452628705650568), (44, 0.023364474764093757), (48, 0.02429035445675254), (45, 0.02443871251307428), (40, 0.0244705593213439), (21, 0.024924597702920437), (50, 0.02504217205569148), (22, 0.025168768363073468), (49, 0.025875969789922237), (24, 0.025899537140503526), (42, 0.02620540652424097), (20, 0.02685900777578354), (47, 0.028178583132103086), (15, 0.03192339092493057), (38, 0.03208350157365203), (7, 0.032285446766763926), (39, 0.03233744157478213), (19, 0.03262859582901001), (51, 0.039947257842868567), (37, 0.04073968203738332), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.05722427647560835), (13, 0.05892290314659476), (11, 0.059249129611998796), (17, 0.06095685111358762), (0, 0.06300980970263481), (52, 0.06433630175888538), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.45053430274128914), (18, 0.5108212977647781), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470607835799456), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020046867663040757), (46, 0.020376993576064706), (41, 0.021723243640735745), (25, 0.02197260269895196), (23, 0.02237953501753509), (44, 0.02302833739668131), (48, 0.023771876702085137), (40, 0.02393081272020936), (45, 0.02417866326868534), (50, 0.02439029887318611), (21, 0.024924597702920437), (22, 0.0251687690615654), (42, 0.025188251165673137), (49, 0.02536152838729322), (24, 0.025899536907672882), (20, 0.02685900731012225), (47, 0.027363279135897756), (38, 0.03136561857536435), (15, 0.03192339185625315), (39, 0.03212768537923694), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.0389359244145453), (37, 0.04020634386688471), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368270859122), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.06095684925094247), (52, 0.062328549567610025), (0, 0.06300980737432837), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4444202072918415), (18, 0.5108212903141975), (53, 0.8537911772727966)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500317186117), (27, 0.01888244692236185), (43, 0.019595165504142642), (46, 0.02007358055561781), (41, 0.02096158522181213), (25, 0.02197260200046003), (23, 0.022379534784704447), (44, 0.02281495649367571), (48, 0.023128160275518894), (40, 0.023345195222645998), (50, 0.02375614712946117), (42, 0.023847301956266165), (45, 0.023873879807069898), (21, 0.024924597470089793), (49, 0.02496031578630209), (22, 0.025168768828734756), (24, 0.025899537140503526), (47, 0.026855543022975326), (20, 0.02685900661163032), (38, 0.03042401373386383), (39, 0.03151404415257275), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.037824881728738546), (37, 0.03936835331842303), (9, 0.04340187879279256), (6, 0.0466090296395123), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912728369236), (52, 0.060332820285111666), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.4360685423016548), (18, 0.5108213126659393), (53, 0.8749377354979515)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500084355474), (43, 0.018555945483967662), (27, 0.018882446689531207), (46, 0.019160085124894977), (41, 0.019424294820055366), (48, 0.02146727219223976), (25, 0.02197260269895196), (44, 0.022026916733011603), (40, 0.022179661318659782), (42, 0.02220643009059131), (50, 0.022256129421293736), (23, 0.022379535250365734), (45, 0.022931481711566448), (49, 0.023708512540906668), (21, 0.024924598168581724), (22, 0.025168768595904112), (47, 0.025829139398410916), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.028956545749679208), (39, 0.029667828930541873), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03600902622565627), (37, 0.036512387450784445), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548466112464666), (52, 0.056107287760823965), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667386837303638), (36, 0.41757645085453987), (18, 0.5108212977647781), (53, 0.9117145016789436)]
computing accuracy for after removing block 28 . block score: 0.017088500084355474
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102241948247), (41, 0.018849018262699246), (27, 0.018882446456700563), (48, 0.020903734723106027), (42, 0.021432003937661648), (40, 0.021832420956343412), (44, 0.02184052998200059), (50, 0.02186986361630261), (25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.022492847871035337), (49, 0.023123499006032944), (21, 0.024924597702920437), (47, 0.02506713871844113), (22, 0.025168768363073468), (24, 0.025899537140503526), (20, 0.026859007542952895), (38, 0.028114069486036897), (39, 0.029206909239292145), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03545433562248945), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.05454846518114209), (52, 0.05469645978882909), (3, 0.05722427973523736), (13, 0.058922899421304464), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300981156527996), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387116700411), (36, 0.4135979004204273), (18, 0.5108213052153587), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882446689531207), (46, 0.01930202986113727), (42, 0.021432003937661648), (48, 0.021544843912124634), (40, 0.021832421887665987), (50, 0.02194626978598535), (25, 0.02197260269895196), (23, 0.02237953571602702), (49, 0.023006869480013847), (44, 0.023108509834855795), (45, 0.023535607382655144), (21, 0.024924597470089793), (22, 0.025168768595904112), (47, 0.025820446433499455), (24, 0.02589953737333417), (20, 0.02685900731012225), (38, 0.028114069253206253), (39, 0.029206909704953432), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.035091488622128963), (37, 0.035977639723569155), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.047836634796112776), (52, 0.053329027723520994), (2, 0.0545484684407711), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 0.9678284302353859)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 1 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 2 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 3 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.1]
training epoch 4 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 5 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 6 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 7 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 8 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 9 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 10 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.01907008863054216), (48, 0.02067816792987287), (50, 0.021344397915527225), (40, 0.02183242072351277), (25, 0.02197260269895196), (42, 0.02198693947866559), (23, 0.022379535250365734), (49, 0.02253474830649793), (45, 0.02392991748638451), (44, 0.024054003413766623), (21, 0.024924597470089793), (22, 0.025168768595904112), (24, 0.025899537140503526), (47, 0.02604393777437508), (20, 0.02685900661163032), (38, 0.028114068787544966), (39, 0.0292069090064615), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03379448037594557), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.05047609331086278), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892290035262704), (11, 0.059249126352369785), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 1.027817964553833)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707972854376), (50, 0.020775062264874578), (40, 0.02108595333993435), (42, 0.021369648166000843), (49, 0.021910030394792557), (25, 0.021972602931782603), (23, 0.022379535948857665), (44, 0.02323931152932346), (45, 0.023585309041664004), (21, 0.024924597702920437), (47, 0.025076947873458266), (22, 0.025168768363073468), (24, 0.02589953737333417), (20, 0.026859006844460964), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.03281425987370312), (37, 0.03542024362832308), (9, 0.043401877861469984), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.04852363048121333), (2, 0.05454846378415823), (3, 0.05722427647560835), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831161877140403), (40, 0.02108595333993435), (42, 0.02136964723467827), (25, 0.02197260269895196), (23, 0.02237953501753509), (49, 0.022536989534273744), (44, 0.02323931152932346), (45, 0.023585309041664004), (21, 0.02492459863424301), (22, 0.025168767431750894), (24, 0.025899537140503526), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183361118659377), (39, 0.028580758720636368), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.03285081125795841), (37, 0.03542024316266179), (9, 0.04340188158676028), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.04812479671090841), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980783998966), (1, 0.06676733959466219), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.1537711173295975)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953572764993), (42, 0.021369648166000843), (25, 0.02197260339744389), (23, 0.022379535250365734), (50, 0.022470062831416726), (44, 0.023239311296492815), (45, 0.023585309041664004), (21, 0.02492459793575108), (22, 0.025168768828734756), (49, 0.02523410227149725), (24, 0.025899537606164813), (47, 0.026583049213513732), (20, 0.02685900731012225), (38, 0.02718336135149002), (39, 0.028580758487805724), (15, 0.03192339092493057), (7, 0.03228544583544135), (19, 0.032628596760332584), (51, 0.03296921169385314), (37, 0.03542024316266179), (9, 0.043401879258453846), (6, 0.0466090296395123), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.05089045129716396), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892289895564318), (11, 0.059249130077660084), (17, 0.06095685018226504), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4065234065055847), (18, 0.5108213052153587), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085953572764993
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.021284766029566526), (25, 0.02197260269895196), (23, 0.022379535948857665), (45, 0.023098317440599203), (44, 0.024240857688710093), (49, 0.02450086921453476), (21, 0.024924597702920437), (22, 0.025168769294396043), (24, 0.025899537140503526), (47, 0.026519699720665812), (20, 0.026859007077291608), (38, 0.027183360187336802), (39, 0.028580758720636368), (15, 0.03192339185625315), (51, 0.032220850232988596), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.03542024455964565), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.048857572954148054), (2, 0.05454846378415823), (3, 0.05722427787259221), (13, 0.05892290035262704), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4065233953297138), (18, 0.5108213052153587), (53, 1.3718615919351578)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658535912633), (25, 0.02197260269895196), (23, 0.022379535483196378), (45, 0.02376196696422994), (49, 0.02460233890451491), (44, 0.024712180718779564), (21, 0.02492459863424301), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026220474625006318), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.028580758487805724), (51, 0.031279068207368255), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.043401879258453846), (52, 0.046101709362119436), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663526177406), (2, 0.05454846704378724), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.07467831950634718), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4065234065055847), (18, 0.5108213052153587), (53, 1.417823389172554)]
computing accuracy for after removing block 50 . block score: 0.021202658535912633
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.022379535250365734), (45, 0.023761966498568654), (49, 0.024602339137345552), (44, 0.024712181882932782), (21, 0.024924597702920437), (22, 0.025168768595904112), (24, 0.02589953737333417), (47, 0.02622047532349825), (20, 0.026859006378799677), (38, 0.02718336065299809), (39, 0.028580759651958942), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03344302112236619), (37, 0.03542024455964565), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663293346763), (52, 0.052651792764663696), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734425127506), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.6287680864334106)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535250365734), (45, 0.023382084211334586), (49, 0.02386031672358513), (44, 0.0239480659365654), (21, 0.02492459793575108), (22, 0.025168768363073468), (47, 0.025361904175952077), (24, 0.025899537606164813), (38, 0.026533205527812243), (20, 0.026859006844460964), (39, 0.028472805861383677), (15, 0.03192339185625315), (7, 0.03228544723242521), (51, 0.032473246566951275), (19, 0.03262859536334872), (37, 0.03485476830974221), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (52, 0.05042571248486638), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.3996613472700119), (18, 0.5108213052153587), (53, 1.6311722546815872)]
computing accuracy for after removing block 23 . block score: 0.022379535250365734
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.023563285125419497), (45, 0.02358233113773167), (49, 0.02370715863071382), (24, 0.02455138461664319), (47, 0.024688831064850092), (21, 0.02492459723725915), (22, 0.025168769294396043), (38, 0.02640997967682779), (20, 0.026859006844460964), (39, 0.02843296923674643), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.03235368151217699), (19, 0.03262859582901001), (37, 0.03590833814814687), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (52, 0.048856367357075214), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922902680933475), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.40237871184945107), (18, 0.5108213052153587), (53, 1.6179482489824295)]
computing accuracy for after removing block 44 . block score: 0.023563285125419497
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246751632541418), (49, 0.02354176319204271), (24, 0.02455138461664319), (21, 0.024924597702920437), (22, 0.02516876789741218), (47, 0.025985260028392076), (38, 0.02640997967682779), (20, 0.026859006844460964), (39, 0.02843296923674643), (15, 0.03192339139059186), (51, 0.03204912506043911), (7, 0.03228544630110264), (19, 0.03262859722599387), (37, 0.035908338613808155), (9, 0.043401879258453846), (6, 0.046609030570834875), (4, 0.04749368550255895), (14, 0.04783663433045149), (52, 0.04816291853785515), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.06300980783998966), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.40237871184945107), (18, 0.5108212977647781), (53, 1.7482214719057083)]
computing accuracy for after removing block 45 . block score: 0.023246751632541418
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157051229849458), (24, 0.02455138461664319), (21, 0.024924598168581724), (22, 0.025168768595904112), (38, 0.026409979909658432), (20, 0.026859007077291608), (47, 0.027429412584751844), (39, 0.02843296993523836), (51, 0.031893002800643444), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03590833814814687), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (52, 0.049079655669629574), (2, 0.05454846564680338), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828325599432), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.40237870067358017), (18, 0.5108213052153587), (53, 1.895566999912262)]
computing accuracy for after removing block 49 . block score: 0.024157051229849458
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best True lr [0.1]
training epoch 1 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 3 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 4 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 5 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 6 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best True lr [0.1]
training epoch 7 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 8 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 9 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 10 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.963000)
finished training. finished 50 epochs. accuracy 0.963 topk_dict {'top1': 0.963}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.058600. All blocks and scores: [(15, 0.058599743992090225), (7, 0.0590455112978816), (19, 0.06394117511808872), (20, 0.06416098307818174), (21, 0.06645568553358316), (22, 0.06690244283527136), (38, 0.06703690346330404), (51, 0.06944802775979042), (37, 0.07278794050216675), (39, 0.07308852206915617), (52, 0.07360676117241383), (47, 0.07453258521854877), (4, 0.07824517041444778), (24, 0.07964591961354017), (6, 0.08950317744165659), (9, 0.08954103011637926), (14, 0.09845746587961912), (3, 0.09848012775182724), (2, 0.1028219722211361), (17, 0.1084188474342227), (0, 0.10885090753436089), (11, 0.1100598769262433), (13, 0.11036432348191738), (1, 0.12295079417526722), (8, 0.1458930280059576), (12, 0.15551652386784554), (10, 0.1571000162512064), (16, 0.16690012998878956), (5, 0.19521641544997692), (36, 0.5396116897463799), (18, 0.6652027741074562), (53, 1.015807643532753)]
computing accuracy for after removing block 15 . block score: 0.058599743992090225
removed block 15 current accuracy 0.9554 loss from initial  0.04459999999999997
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.059046. All blocks and scores: [(7, 0.0590455112978816), (20, 0.06084927637130022), (21, 0.06290534604340792), (22, 0.06330893095582724), (19, 0.0633186511695385), (38, 0.0661541810259223), (51, 0.06903776712715626), (37, 0.07210557069629431), (39, 0.07234481628984213), (52, 0.07325673941522837), (47, 0.07395340129733086), (24, 0.07520737778395414), (4, 0.07824517134577036), (6, 0.08950317744165659), (9, 0.08954103197902441), (14, 0.09845746774226427), (3, 0.09848013147711754), (2, 0.10282196663320065), (0, 0.10885090660303831), (11, 0.11005987599492073), (13, 0.11036432906985283), (17, 0.11796667985618114), (1, 0.12295079044997692), (8, 0.14589302614331245), (12, 0.15551651641726494), (10, 0.1571000199764967), (16, 0.18507308512926102), (5, 0.19521641731262207), (36, 0.5214199796319008), (18, 0.6471701115369797), (53, 1.0218759328126907)]
computing accuracy for after removing block 7 . block score: 0.0590455112978816
removed block 7 current accuracy 0.9544 loss from initial  0.045599999999999974
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.059780. All blocks and scores: [(22, 0.05977956112474203), (20, 0.06005375040695071), (21, 0.0612746337428689), (19, 0.06190675124526024), (38, 0.06581291742622852), (51, 0.06674299202859402), (24, 0.06932789739221334), (37, 0.06943306513130665), (52, 0.07095516845583916), (39, 0.07179222907871008), (47, 0.07262517232447863), (4, 0.07824516762048006), (9, 0.08929248433560133), (6, 0.08950317744165659), (14, 0.09214088320732117), (13, 0.09643511474132538), (3, 0.09848012961447239), (17, 0.10142725892364979), (2, 0.10282197128981352), (11, 0.10351697914302349), (0, 0.10885090846568346), (1, 0.12295078951865435), (12, 0.14403889328241348), (8, 0.1443880833685398), (10, 0.16115104407072067), (16, 0.1702606026083231), (5, 0.19521641358733177), (36, 0.505086425691843), (18, 0.6344225257635117), (53, 1.024627447128296)]
computing accuracy for after removing block 22 . block score: 0.05977956112474203
removed block 22 current accuracy 0.9406 loss from initial  0.05940000000000001
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 20, with score 0.060054. All blocks and scores: [(20, 0.06005375040695071), (21, 0.061274636536836624), (19, 0.06190675217658281), (24, 0.0636680768802762), (51, 0.0638738558627665), (38, 0.06513330992311239), (52, 0.06607599928975105), (47, 0.06798271276056767), (39, 0.0701149944216013), (37, 0.07173352967947721), (4, 0.07824516855180264), (9, 0.08929248433560133), (6, 0.08950317557901144), (14, 0.09214088320732117), (13, 0.0964351138100028), (3, 0.09848012775182724), (17, 0.10142725892364979), (2, 0.1028219722211361), (11, 0.10351697821170092), (0, 0.10885091032832861), (1, 0.12295079417526722), (12, 0.14403888955712318), (8, 0.1443880759179592), (10, 0.16115104034543037), (16, 0.17026060074567795), (5, 0.19521641172468662), (36, 0.50216855853796), (18, 0.6344225704669952), (53, 1.0283519178628922)]
computing accuracy for after removing block 20 . block score: 0.06005375040695071
removed block 20 current accuracy 0.9278 loss from initial  0.07220000000000004
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.060813. All blocks and scores: [(24, 0.060813103802502155), (21, 0.06178352516144514), (19, 0.0619067526422441), (51, 0.06268912646919489), (52, 0.06293135276064277), (38, 0.06414208561182022), (47, 0.06627815309911966), (39, 0.0709034176543355), (37, 0.0773002440109849), (4, 0.07824516855180264), (9, 0.08929248619824648), (6, 0.08950317744165659), (14, 0.09214088320732117), (13, 0.0964351138100028), (3, 0.09848012775182724), (17, 0.10142726078629494), (2, 0.10282196942716837), (11, 0.10351697914302349), (0, 0.10885090939700603), (1, 0.12295079417526722), (12, 0.14403888583183289), (8, 0.1443880796432495), (10, 0.16115104593336582), (16, 0.17026060447096825), (5, 0.19521640613675117), (36, 0.508021853864193), (18, 0.6344225481152534), (53, 1.0096467211842537)]
computing accuracy for after removing block 24 . block score: 0.060813103802502155
removed block 24 current accuracy 0.9034 loss from initial  0.09660000000000002
since last training loss: 0.059599999999999986 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.058139. All blocks and scores: [(52, 0.05813871091231704), (51, 0.0582457329146564), (21, 0.06178352329879999), (19, 0.06190675450488925), (47, 0.06219754321500659), (38, 0.06376348994672298), (39, 0.0693838344886899), (37, 0.07565424870699644), (4, 0.07824516855180264), (9, 0.08929248619824648), (6, 0.08950318116694689), (14, 0.09214088413864374), (13, 0.0964351100847125), (3, 0.09848012961447239), (17, 0.10142725612968206), (2, 0.10282197128981352), (11, 0.10351698007434607), (0, 0.10885090660303831), (1, 0.12295079417526722), (12, 0.14403888583183289), (8, 0.1443880833685398), (10, 0.16115104034543037), (16, 0.1702605988830328), (5, 0.19521641358733177), (36, 0.5058415904641151), (18, 0.634422555565834), (53, 0.9884533733129501)]
computing accuracy for after removing block 52 . block score: 0.05813871091231704
removed block 52 current accuracy 0.8558 loss from initial  0.1442
since last training loss: 0.10719999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.058246. All blocks and scores: [(51, 0.05824573524296284), (21, 0.061783526558429), (19, 0.061906753573566675), (47, 0.062197544146329165), (38, 0.06376348994672298), (39, 0.06938383262604475), (37, 0.07565424777567387), (4, 0.07824516855180264), (9, 0.0892924852669239), (6, 0.08950317464768887), (14, 0.09214088320732117), (13, 0.09643511194735765), (3, 0.09848013240844011), (17, 0.10142725985497236), (2, 0.1028219684958458), (11, 0.10351698100566864), (0, 0.10885090660303831), (1, 0.12295079324394464), (12, 0.14403888955712318), (8, 0.1443880833685398), (10, 0.16115104220807552), (16, 0.1702606026083231), (5, 0.19521640427410603), (36, 0.505841575562954), (18, 0.634422555565834), (53, 1.0496467798948288)]
computing accuracy for after removing block 51 . block score: 0.05824573524296284
removed block 51 current accuracy 0.7692 loss from initial  0.2308
since last training loss: 0.19379999999999997 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 21, with score 0.061784. All blocks and scores: [(21, 0.061783522833138704), (19, 0.06190675310790539), (47, 0.06219754321500659), (38, 0.06376349087804556), (39, 0.06938383262604475), (37, 0.07565424684435129), (4, 0.07824516855180264), (9, 0.0892924852669239), (6, 0.08950317930430174), (14, 0.09214088413864374), (13, 0.09643511287868023), (3, 0.09848012682050467), (17, 0.10142725892364979), (2, 0.10282197035849094), (11, 0.10351698007434607), (0, 0.10885090474039316), (1, 0.12295079324394464), (12, 0.14403888955712318), (8, 0.14438808150589466), (10, 0.16115104220807552), (16, 0.17026060074567795), (5, 0.19521641544997692), (36, 0.5058415904641151), (18, 0.6344225332140923), (53, 1.1588017344474792)]
computing accuracy for after removing block 21 . block score: 0.061783522833138704
removed block 21 current accuracy 0.7206 loss from initial  0.2794
since last training loss: 0.24239999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.057751. All blocks and scores: [(47, 0.057750947773456573), (38, 0.06096795154735446), (19, 0.06190675124526024), (39, 0.06697273626923561), (37, 0.07387981098145247), (4, 0.07824517041444778), (9, 0.08929248619824648), (6, 0.08950317744165659), (14, 0.09214088506996632), (13, 0.09643511194735765), (3, 0.09848012868314981), (17, 0.10142725985497236), (2, 0.1028219722211361), (11, 0.10351697914302349), (0, 0.10885090846568346), (1, 0.12295079417526722), (12, 0.14403888955712318), (8, 0.14438807778060436), (10, 0.16115104220807552), (16, 0.17026060074567795), (5, 0.19521641917526722), (36, 0.4892720505595207), (18, 0.634422555565834), (53, 1.0916730612516403)]
computing accuracy for after removing block 47 . block score: 0.057750947773456573
removed block 47 current accuracy 0.642 loss from initial  0.358
since last training loss: 0.32099999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 38, with score 0.060968. All blocks and scores: [(38, 0.06096794968470931), (19, 0.0619067526422441), (39, 0.06697273720055819), (37, 0.07387981098145247), (4, 0.07824516855180264), (9, 0.08929248806089163), (6, 0.08950317744165659), (14, 0.09214088320732117), (13, 0.09643511474132538), (3, 0.09848012961447239), (17, 0.10142726078629494), (2, 0.10282197315245867), (11, 0.10351698007434607), (0, 0.10885090753436089), (1, 0.12295079417526722), (12, 0.14403888769447803), (8, 0.1443880796432495), (10, 0.16115104220807552), (16, 0.1702605988830328), (5, 0.19521641172468662), (36, 0.4892720617353916), (18, 0.6344225704669952), (53, 1.2347455471754074)]
computing accuracy for after removing block 38 . block score: 0.06096794968470931
removed block 38 current accuracy 0.6296 loss from initial  0.37039999999999995
since last training loss: 0.3333999999999999 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.061907. All blocks and scores: [(19, 0.0619067526422441), (37, 0.07387981098145247), (4, 0.07824516855180264), (39, 0.08096349146217108), (9, 0.0892924852669239), (6, 0.08950317744165659), (14, 0.09214088506996632), (13, 0.09643511287868023), (3, 0.09848013147711754), (17, 0.10142725799232721), (2, 0.10282197408378124), (11, 0.10351697914302349), (0, 0.10885090846568346), (1, 0.1229507913812995), (12, 0.14403888955712318), (8, 0.1443880833685398), (10, 0.16115103848278522), (16, 0.17026060074567795), (5, 0.19521641358733177), (36, 0.4892720617353916), (18, 0.6344225630164146), (53, 1.2306369841098785)]
computing accuracy for after removing block 19 . block score: 0.0619067526422441
removed block 19 current accuracy 0.5598 loss from initial  0.44020000000000004
training start
training epoch 0 val accuracy 0.84 topk_dict {'top1': 0.84} is_best True lr [0.1]
training epoch 1 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.1]
training epoch 2 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 3 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 4 val accuracy 0.841 topk_dict {'top1': 0.841} is_best False lr [0.1]
training epoch 5 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.1]
training epoch 6 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 7 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.1]
training epoch 9 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 10 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.096621. All blocks and scores: [(4, 0.09662060253322124), (37, 0.11358254309743643), (6, 0.11510568577796221), (2, 0.11657073441892862), (0, 0.1197867477312684), (9, 0.12499693408608437), (3, 0.12693141028285027), (39, 0.12751896306872368), (14, 0.14532823488116264), (11, 0.1478074286133051), (1, 0.1528883520513773), (8, 0.17756708525121212), (13, 0.18110423162579536), (17, 0.18316295556724072), (10, 0.20856434665620327), (12, 0.21998034231364727), (5, 0.23368891142308712), (16, 0.2380192093551159), (36, 0.4640001803636551), (18, 0.5955848172307014), (53, 1.3436731100082397)]
computing accuracy for after removing block 4 . block score: 0.09662060253322124
removed block 4 current accuracy 0.9296 loss from initial  0.07040000000000002
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.114068. All blocks and scores: [(37, 0.11406809836626053), (2, 0.11657073814421892), (0, 0.11978674679994583), (3, 0.12693141028285027), (39, 0.12750844098627567), (9, 0.12958580441772938), (6, 0.1364499107003212), (14, 0.14275242760777473), (11, 0.14452020451426506), (1, 0.15288835018873215), (13, 0.1762019358575344), (17, 0.1786478366702795), (8, 0.17978281155228615), (10, 0.20729540847241879), (12, 0.2126234769821167), (16, 0.22335359640419483), (5, 0.26954034715890884), (36, 0.46353257447481155), (18, 0.594749428331852), (53, 1.3238551169633865)]
computing accuracy for after removing block 37 . block score: 0.11406809836626053
removed block 37 current accuracy 0.8858 loss from initial  0.11419999999999997
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 2, with score 0.116571. All blocks and scores: [(2, 0.11657073628157377), (0, 0.11978674400597811), (3, 0.12693141121417284), (9, 0.12958580255508423), (6, 0.13644991256296635), (14, 0.14275242388248444), (11, 0.1445202026516199), (1, 0.15288834646344185), (39, 0.171713562682271), (13, 0.17620193772017956), (17, 0.17864783108234406), (8, 0.1797828134149313), (10, 0.20729541406035423), (12, 0.21262347511947155), (16, 0.22335359640419483), (5, 0.26954033970832825), (36, 0.46353257074952126), (18, 0.594749428331852), (53, 1.4135190099477768)]
computing accuracy for after removing block 2 . block score: 0.11657073628157377
removed block 2 current accuracy 0.865 loss from initial  0.135
since last training loss: 0.0736 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.112468. All blocks and scores: [(3, 0.11246765311807394), (6, 0.11788380146026611), (0, 0.1197867514565587), (9, 0.12422229535877705), (14, 0.13025543093681335), (11, 0.13077714294195175), (17, 0.15002215094864368), (1, 0.1528883520513773), (39, 0.15412024781107903), (13, 0.156701497733593), (8, 0.1711496990174055), (16, 0.19365722872316837), (10, 0.19541923142969608), (12, 0.19958378188312054), (5, 0.2630001977086067), (36, 0.4148842357099056), (18, 0.5309775844216347), (53, 1.254805102944374)]
computing accuracy for after removing block 3 . block score: 0.11246765311807394
removed block 3 current accuracy 0.8344 loss from initial  0.16559999999999997
since last training loss: 0.10419999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 0, with score 0.119787. All blocks and scores: [(0, 0.11978674866259098), (14, 0.12016580998897552), (6, 0.1210096962749958), (11, 0.12298365775495768), (9, 0.130697937682271), (17, 0.13511963561177254), (39, 0.14155559241771698), (13, 0.1448155902326107), (1, 0.15288835018873215), (16, 0.16025961190462112), (8, 0.16336308605968952), (12, 0.18723683059215546), (10, 0.19797750376164913), (5, 0.28231818974018097), (36, 0.3776623122394085), (18, 0.48034220188856125), (53, 1.0996843576431274)]
computing accuracy for after removing block 0 . block score: 0.11978674866259098
removed block 0 current accuracy 0.7552 loss from initial  0.24480000000000002
since last training loss: 0.1834 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.117009. All blocks and scores: [(11, 0.11700932774692774), (14, 0.11807925440371037), (6, 0.12094904854893684), (9, 0.12252763099968433), (17, 0.13136699795722961), (39, 0.13710481487214565), (13, 0.1451958306133747), (16, 0.1527895461767912), (8, 0.15742857567965984), (1, 0.16320853494107723), (10, 0.18565410934388638), (12, 0.21751132793724537), (5, 0.2728285528719425), (36, 0.36168551817536354), (18, 0.4709813743829727), (53, 1.0071245059370995)]
computing accuracy for after removing block 11 . block score: 0.11700932774692774
removed block 11 current accuracy 0.6882 loss from initial  0.31179999999999997
since last training loss: 0.25039999999999996 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 14, with score 0.108221. All blocks and scores: [(14, 0.10822074115276337), (6, 0.12094904482364655), (9, 0.12252763193100691), (17, 0.1259106956422329), (39, 0.13701009191572666), (13, 0.14123595133423805), (16, 0.14142666943371296), (8, 0.15742857567965984), (1, 0.16320853121578693), (10, 0.18565410934388638), (12, 0.22990917041897774), (5, 0.2728285603225231), (36, 0.3571770712733269), (18, 0.4689772427082062), (53, 0.952153742313385)]
computing accuracy for after removing block 14 . block score: 0.10822074115276337
removed block 14 current accuracy 0.599 loss from initial  0.401
since last training loss: 0.3396 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.119950. All blocks and scores: [(17, 0.11995001696050167), (6, 0.12094904202967882), (9, 0.12252763193100691), (39, 0.13982593640685081), (13, 0.14123595505952835), (8, 0.15742857567965984), (16, 0.16142071969807148), (1, 0.16320853307843208), (10, 0.18565411493182182), (12, 0.22990917973220348), (5, 0.2728285640478134), (36, 0.353648342192173), (18, 0.46174776181578636), (53, 0.956934005022049)]
computing accuracy for after removing block 17 . block score: 0.11995001696050167
removed block 17 current accuracy 0.5036 loss from initial  0.49639999999999995
since last training loss: 0.43499999999999994 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 6, with score 0.120949. All blocks and scores: [(6, 0.12094904482364655), (9, 0.12252763193100691), (39, 0.13148421421647072), (13, 0.14123595133423805), (8, 0.1574285812675953), (16, 0.16142071411013603), (1, 0.16320853307843208), (10, 0.18565411120653152), (12, 0.2299091722816229), (5, 0.2728285491466522), (36, 0.3286114074289799), (18, 0.43158310279250145), (53, 0.8180424720048904)]
computing accuracy for after removing block 6 . block score: 0.12094904482364655
removed block 6 current accuracy 0.3894 loss from initial  0.6106
since last training loss: 0.5491999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 39, with score 0.125325. All blocks and scores: [(39, 0.12532455381006002), (9, 0.12590765301138163), (13, 0.13411536067724228), (16, 0.139333950355649), (1, 0.16320853121578693), (8, 0.16707915253937244), (10, 0.1851354818791151), (12, 0.22907858528196812), (5, 0.2728285528719425), (36, 0.30937765166163445), (18, 0.40436695516109467), (53, 0.6776378974318504)]
computing accuracy for after removing block 39 . block score: 0.12532455381006002
removed block 39 current accuracy 0.1978 loss from initial  0.8022
since last training loss: 0.7408 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 9, with score 0.125908. All blocks and scores: [(9, 0.12590765301138163), (13, 0.13411535695195198), (16, 0.13933394849300385), (1, 0.16320852935314178), (8, 0.1670791506767273), (10, 0.18513548001646996), (12, 0.22907858714461327), (5, 0.2728285491466522), (36, 0.30937764793634415), (18, 0.40436697751283646), (53, 1.0951032638549805)]
computing accuracy for after removing block 9 . block score: 0.12590765301138163
removed block 9 current accuracy 0.1934 loss from initial  0.8066
since last training loss: 0.7452 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 13, with score 0.119568. All blocks and scores: [(13, 0.11956840753555298), (16, 0.14407408982515335), (10, 0.157121904194355), (1, 0.16320853494107723), (8, 0.1670791544020176), (12, 0.16756530106067657), (36, 0.2615838162600994), (5, 0.2728285603225231), (18, 0.37840263545513153), (53, 0.6179937869310379)]
computing accuracy for after removing block 13 . block score: 0.11956840753555298
removed block 13 current accuracy 0.1516 loss from initial  0.8484
training start
training epoch 0 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best True lr [0.1]
training epoch 1 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best False lr [0.1]
training epoch 2 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best False lr [0.1]
training epoch 3 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best True lr [0.1]
training epoch 4 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best True lr [0.1]
training epoch 5 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best True lr [0.1]
training epoch 6 val accuracy 0.835 topk_dict {'top1': 0.835} is_best True lr [0.1]
training epoch 7 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best True lr [0.1]
training epoch 8 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 9 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best True lr [0.1]
training epoch 10 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.907600)
finished training. finished 50 epochs. accuracy 0.9076 topk_dict {'top1': 0.9076}
