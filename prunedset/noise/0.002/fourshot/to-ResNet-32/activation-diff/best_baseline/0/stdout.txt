start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996147967875), (32, 0.009233050397597253), (30, 0.010039400774985552), (31, 0.010361600085161626), (34, 0.013312276219949126), (29, 0.01354115444701165), (35, 0.016018461901694536), (26, 0.016037590568885207), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020232456969097257), (46, 0.02104453998617828), (25, 0.02197260269895196), (23, 0.022379535250365734), (41, 0.022826648084446788), (44, 0.023395078955218196), (40, 0.024025025311857462), (45, 0.024295410607010126), (21, 0.02492459793575108), (22, 0.02516876789741218), (48, 0.025341259315609932), (24, 0.025899536442011595), (50, 0.026409972459077835), (42, 0.026674099965021014), (20, 0.02685900777578354), (49, 0.027037164196372032), (47, 0.029306468553841114), (39, 0.031570712802931666), (38, 0.03163787163794041), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03796026110649109), (51, 0.04173417203128338), (9, 0.04340187879279256), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846424981952), (3, 0.057224275544285774), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734331995249), (52, 0.06862937659025192), (8, 0.07467832416296005), (10, 0.0803448399528861), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.43758000805974007), (18, 0.5108213052153587), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996147967875
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.00923305086325854), (30, 0.010039400309324265), (31, 0.010361600085161626), (34, 0.013133947388269007), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.016169289592653513), (28, 0.01772867562249303), (27, 0.019127048086374998), (43, 0.020072477171197534), (46, 0.02073138509877026), (25, 0.021972603630274534), (41, 0.022347092628479004), (23, 0.02237953501753509), (44, 0.023235688218846917), (40, 0.023841066984459758), (45, 0.023965542437508702), (48, 0.024917916161939502), (21, 0.024924597702920437), (22, 0.02516876789741218), (50, 0.025840812595561147), (24, 0.025899537606164813), (42, 0.026315324008464813), (49, 0.02665567514486611), (20, 0.026859007542952895), (47, 0.028728798497468233), (39, 0.031317642191424966), (38, 0.031380363274365664), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03802584484219551), (51, 0.04122393950819969), (9, 0.04340188158676028), (6, 0.046609030570834875), (4, 0.04749368550255895), (14, 0.0478366338647902), (2, 0.05454846704378724), (3, 0.05722428020089865), (13, 0.05892290361225605), (11, 0.059249129611998796), (17, 0.06095684692263603), (0, 0.06300980923697352), (1, 0.06676734238862991), (52, 0.0674515524879098), (8, 0.07467832509428263), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386651039124), (36, 0.43538709357380867), (18, 0.5108213126659393), (53, 0.8222573697566986)]
computing accuracy for after removing block 32 . block score: 0.00923305086325854
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.010361600201576948), (34, 0.012765232473611832), (29, 0.013541154796257615), (35, 0.01599275111220777), (26, 0.016037590568885207), (28, 0.017728674924001098), (27, 0.019127048319205642), (43, 0.02007513213902712), (46, 0.020841405959799886), (25, 0.021972602233290672), (41, 0.022319767624139786), (23, 0.022379535483196378), (44, 0.023154050577431917), (40, 0.02388568432070315), (45, 0.0240716899279505), (48, 0.024877464398741722), (21, 0.02492459793575108), (22, 0.025168767431750894), (50, 0.025691178627312183), (24, 0.025899537606164813), (42, 0.026123748160898685), (49, 0.026479421881958842), (20, 0.026859007077291608), (47, 0.02869313256815076), (38, 0.031236796639859676), (39, 0.031295291148126125), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.038376690819859505), (51, 0.04111403366550803), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06700456235557795), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.43640001863241196), (18, 0.5108213126659393), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372250564396), (34, 0.01238783705048263), (29, 0.013541154097765684), (35, 0.016008096281439066), (26, 0.016037590568885207), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020083633717149496), (46, 0.02070444473065436), (25, 0.021972603164613247), (41, 0.02225319715216756), (23, 0.022379535483196378), (44, 0.023267760640010238), (40, 0.024013879941776395), (45, 0.024092993000522256), (48, 0.024665279779583216), (21, 0.024924598168581724), (22, 0.025168768595904112), (50, 0.025459734490141273), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.026287756394594908), (20, 0.026859006844460964), (47, 0.02836342342197895), (38, 0.031047647586092353), (39, 0.031380771892145276), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03897124482318759), (51, 0.040756204165518284), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.06095685064792633), (0, 0.06300980783998966), (52, 0.06586316134780645), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4389924705028534), (18, 0.5108213052153587), (53, 0.8391561731696129)]
computing accuracy for after removing block 31 . block score: 0.010375372250564396
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.01354115444701165), (26, 0.01603759080171585), (35, 0.01605736301280558), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020049350103363395), (46, 0.020552987465634942), (25, 0.021972602466121316), (41, 0.022067483980208635), (23, 0.02237953571602702), (44, 0.022979132365435362), (40, 0.023858346976339817), (45, 0.02412470243871212), (48, 0.024386122822761536), (21, 0.024924597004428506), (50, 0.025042241672053933), (22, 0.025168768595904112), (42, 0.02541450783610344), (49, 0.025842699222266674), (24, 0.02589953737333417), (20, 0.02685900777578354), (47, 0.028050733730196953), (38, 0.03104005940258503), (39, 0.03150080284103751), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03911284822970629), (51, 0.04024627152830362), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922899421304464), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980877131224), (52, 0.06486208830028772), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.438127838075161), (18, 0.5108213052153587), (53, 0.8458427861332893)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.016653419937938452), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020503456005826592), (46, 0.020725322887301445), (25, 0.021972603164613247), (23, 0.02237953618168831), (41, 0.022452629171311855), (44, 0.023364474764093757), (48, 0.024290354689583182), (45, 0.024438712978735566), (40, 0.024470558622851968), (21, 0.02492459793575108), (50, 0.02504217135719955), (22, 0.025168767431750894), (49, 0.025875969789922237), (24, 0.025899536442011595), (42, 0.0262054072227329), (20, 0.026859007077291608), (47, 0.028178582433611155), (15, 0.03192339185625315), (38, 0.03208350110799074), (7, 0.03228544583544135), (39, 0.03233744064345956), (19, 0.0326285962946713), (51, 0.03994725877419114), (37, 0.04073968390002847), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493682242929935), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.059249126352369785), (17, 0.06095684785395861), (0, 0.0630098101682961), (52, 0.06433630315586925), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049013078213), (5, 0.1066738748922944), (36, 0.45053431764245033), (18, 0.5108213052153587), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.016470608534291387), (28, 0.01772867562249303), (27, 0.019127048086374998), (43, 0.020046867663040757), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.022379535483196378), (44, 0.02302833739668131), (48, 0.02377187693491578), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.024390298407524824), (21, 0.02492459793575108), (22, 0.025168768828734756), (42, 0.025188251165673137), (49, 0.025361528620123863), (24, 0.025899537606164813), (20, 0.02685900661163032), (47, 0.027363278903067112), (38, 0.03136561904102564), (15, 0.03192339139059186), (39, 0.032127683982253075), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.038935923017561436), (37, 0.04020634340122342), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.04783663293346763), (2, 0.05454846704378724), (3, 0.057224276941269636), (13, 0.05892289988696575), (11, 0.05924912868067622), (17, 0.060956846456974745), (52, 0.06232855189591646), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387396097183), (36, 0.4444202110171318), (18, 0.5108212977647781), (53, 0.8537912219762802)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366145811975), (28, 0.017088500782847404), (27, 0.018882447155192494), (43, 0.01959516596980393), (46, 0.02007358125410974), (41, 0.020961584988981485), (25, 0.02197260269895196), (23, 0.02237953571602702), (44, 0.022814956260845065), (48, 0.02312816074118018), (40, 0.023345195688307285), (50, 0.02375614643096924), (42, 0.02384730288758874), (45, 0.023873879574239254), (21, 0.02492459863424301), (49, 0.024960316251963377), (22, 0.025168767664581537), (24, 0.02589953667484224), (47, 0.02685554255731404), (20, 0.02685900661163032), (38, 0.030424013966694474), (39, 0.031514044385403395), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.037824881728738546), (37, 0.03936835192143917), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.05722428020089865), (13, 0.058922901283949614), (11, 0.059249128215014935), (52, 0.06033282075077295), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.4360685497522354), (18, 0.5108213052153587), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366145811975
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500084355474), (43, 0.018555945716798306), (27, 0.01888244692236185), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.02146727265790105), (25, 0.02197260269895196), (44, 0.022026916965842247), (40, 0.022179660387337208), (42, 0.02220643009059131), (50, 0.022256129188463092), (23, 0.02237953501753509), (45, 0.022931482177227736), (49, 0.023708512540906668), (21, 0.024924598168581724), (22, 0.025168768363073468), (47, 0.025829139398410916), (24, 0.02589953737333417), (20, 0.026859007077291608), (38, 0.028956545749679208), (39, 0.02966782869771123), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.036009025759994984), (37, 0.03651238698512316), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.05454846518114209), (52, 0.056107287760823965), (3, 0.05722427740693092), (13, 0.05892290314659476), (11, 0.05924913054332137), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.41757645830512047), (18, 0.5108212977647781), (53, 0.9117144867777824)]
computing accuracy for after removing block 28 . block score: 0.017088500084355474
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 1 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 2 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 3 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 4 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 5 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.1]
training epoch 6 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 7 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 8 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.1]
training epoch 9 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.01865610247477889), (41, 0.01884901849552989), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.021832421654835343), (44, 0.021840530913323164), (50, 0.021869863849133253), (25, 0.021972603164613247), (23, 0.02237953501753509), (45, 0.022492847871035337), (49, 0.023123498307541013), (21, 0.024924597702920437), (47, 0.025067138485610485), (22, 0.025168768130242825), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.02811406971886754), (39, 0.02920690830796957), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03545433655381203), (37, 0.03597763925790787), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.05454846750944853), (52, 0.05469645746052265), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.060956848319619894), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 0.9246632531285286)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.01888244692236185), (46, 0.019302030326798558), (42, 0.021432004403322935), (48, 0.02154484298080206), (40, 0.021832421654835343), (50, 0.02194626908749342), (25, 0.02197260269895196), (23, 0.022379536414518952), (49, 0.023006869247183204), (44, 0.023108509834855795), (45, 0.023535606684163213), (21, 0.02492459863424301), (22, 0.025168767431750894), (47, 0.0258204466663301), (24, 0.025899537140503526), (20, 0.026859007077291608), (38, 0.02811406902037561), (39, 0.02920690830796957), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628594897687435), (51, 0.035091488156467676), (37, 0.03597763832658529), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.05332902958616614), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.05892290314659476), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980877131224), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.0904204910621047), (5, 0.10667386930435896), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008863054216), (48, 0.020678168162703514), (50, 0.021344397449865937), (40, 0.021832421189174056), (25, 0.02197260269895196), (42, 0.02198694017715752), (23, 0.022379535483196378), (49, 0.022534747608006), (45, 0.023929917253553867), (44, 0.024054002948105335), (21, 0.024924597702920437), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.02604393707588315), (20, 0.026859007542952895), (38, 0.028114069951698184), (39, 0.0292069090064615), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03379448037594557), (37, 0.03597763832658529), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (52, 0.05047609331086278), (2, 0.054548466112464666), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095684738829732), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4135979041457176), (18, 0.5108212903141975), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.01998970750719309), (50, 0.02077506249770522), (40, 0.02108595333993435), (42, 0.021369647700339556), (49, 0.02191002992913127), (25, 0.021972602233290672), (23, 0.022379535483196378), (44, 0.023239311762154102), (45, 0.02358530811034143), (21, 0.024924597470089793), (47, 0.025076948571950197), (22, 0.025168768130242825), (24, 0.02589953667484224), (20, 0.026859007542952895), (38, 0.027183360420167446), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.032814261270686984), (37, 0.03542024362832308), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.04852363094687462), (2, 0.054548466578125954), (3, 0.057224278803914785), (13, 0.058922899421304464), (11, 0.05924912681803107), (17, 0.06095685018226504), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.0384205430746078)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327561302110553), (50, 0.02083116164430976), (40, 0.021085952874273062), (42, 0.021369647467508912), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.022536989534273744), (44, 0.023239311994984746), (45, 0.023585307644680142), (21, 0.02492459793575108), (22, 0.02516876789741218), (24, 0.02589953737333417), (47, 0.026583050144836307), (20, 0.02685900731012225), (38, 0.027183360420167446), (39, 0.028580759186297655), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.03262859536334872), (51, 0.03285081218928099), (37, 0.035420244093984365), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.047836633399128914), (52, 0.048124799970537424), (2, 0.054548464715480804), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095685111358762), (0, 0.06300980923697352), (1, 0.06676734052598476), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.153771162033081)]
computing accuracy for after removing block 48 . block score: 0.020327561302110553
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952641442418), (42, 0.0213696479331702), (25, 0.021972602931782603), (23, 0.022379535483196378), (50, 0.022470062598586082), (44, 0.023239311994984746), (45, 0.023585309041664004), (21, 0.024924597702920437), (22, 0.025168767664581537), (49, 0.02523410110734403), (24, 0.02589953737333417), (47, 0.02658304898068309), (20, 0.026859006844460964), (38, 0.027183360420167446), (39, 0.0285807594191283), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03296921122819185), (37, 0.035420244093984365), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05089045129716396), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.0803448399528861), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065234027802944), (18, 0.5108213126659393), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952641442418
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284766495227814), (25, 0.021972602233290672), (23, 0.022379535483196378), (45, 0.023098317673429847), (44, 0.024240857688710093), (49, 0.02450086921453476), (21, 0.024924597004428506), (22, 0.0251687690615654), (24, 0.025899537606164813), (47, 0.026519698556512594), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075895346701), (15, 0.03192339139059186), (51, 0.032220850232988596), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.03542024455964565), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368270859122), (14, 0.0478366338647902), (52, 0.04885757202282548), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.05892289988696575), (11, 0.05924913054332137), (17, 0.060956849716603756), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448399528861), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.3718615472316742)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.021972603164613247), (23, 0.022379535483196378), (45, 0.023761966032907367), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924597702920437), (22, 0.025168768130242825), (24, 0.025899537140503526), (47, 0.026220474857836962), (20, 0.026859006378799677), (38, 0.02718336135149002), (39, 0.028580758487805724), (51, 0.031279068207368255), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03542024362832308), (9, 0.04340188018977642), (52, 0.04610171029344201), (6, 0.046609032433480024), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846704378724), (3, 0.0572242783382535), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212903141975), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.02376196626573801), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.025899537838995457), (47, 0.026220474857836962), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.028580757789313793), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03344302112236619), (37, 0.03542024455964565), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493685968220234), (14, 0.0478366338647902), (52, 0.052651793230324984), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.05892290035262704), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.8006 topk_dict {'top1': 0.8006} is_best False lr [0.1]
training epoch 1 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 2 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 3 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 4 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 5 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 6 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 7 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.1]
training epoch 8 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.967200)
finished training. finished 50 epochs. accuracy 0.9672 topk_dict {'top1': 0.9672}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.048347. All blocks and scores: [(49, 0.048346579540520906), (44, 0.04876592289656401), (45, 0.0499448012560606), (23, 0.054098831955343485), (47, 0.055148711893707514), (21, 0.05524790147319436), (20, 0.05767687316983938), (19, 0.05785005260258913), (22, 0.05846042186021805), (38, 0.059672060422599316), (51, 0.061294921673834324), (39, 0.061863431707024574), (7, 0.06362577062100172), (24, 0.06389435473829508), (15, 0.06565314065665007), (52, 0.06819689925760031), (37, 0.07099430542439222), (9, 0.0779225742444396), (4, 0.08492974005639553), (2, 0.09411752317100763), (6, 0.09790991339832544), (0, 0.1012362539768219), (14, 0.10164476465433836), (3, 0.10388921201229095), (17, 0.10463755670934916), (1, 0.10697670932859182), (13, 0.10826499294489622), (11, 0.1122444262728095), (8, 0.13240522891283035), (12, 0.15265413373708725), (10, 0.16146832890808582), (16, 0.16169797629117966), (5, 0.18085327371954918), (36, 0.6285974010825157), (18, 0.6953109726309776), (53, 0.9653254970908165)]
computing accuracy for after removing block 49 . block score: 0.048346579540520906
removed block 49 current accuracy 0.9556 loss from initial  0.044399999999999995
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.048766. All blocks and scores: [(44, 0.04876592382788658), (45, 0.049944800324738026), (23, 0.05409882916137576), (47, 0.055148711893707514), (21, 0.0552479000762105), (20, 0.057676874566823244), (19, 0.057850050274282694), (22, 0.058460420928895473), (38, 0.059672058559954166), (39, 0.061863430775702), (7, 0.06362577062100172), (24, 0.06389435287564993), (15, 0.06565314158797264), (51, 0.06643006578087807), (37, 0.0709943063557148), (52, 0.0759071409702301), (9, 0.0779225742444396), (4, 0.08492973912507296), (2, 0.09411752689629793), (6, 0.09790991432964802), (0, 0.10123625490814447), (14, 0.10164476651698351), (3, 0.10388921108096838), (17, 0.10463755950331688), (1, 0.10697671305388212), (13, 0.10826499573886395), (11, 0.11224442534148693), (8, 0.13240523263812065), (12, 0.15265413001179695), (10, 0.16146833449602127), (16, 0.16169797629117966), (5, 0.18085327185690403), (36, 0.6285974085330963), (18, 0.6953109577298164), (53, 1.1229515373706818)]
computing accuracy for after removing block 44 . block score: 0.04876592382788658
removed block 44 current accuracy 0.9422 loss from initial  0.05779999999999996
since last training loss: 0.02499999999999991 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.053969. All blocks and scores: [(45, 0.05396928917616606), (23, 0.05409883055835962), (21, 0.05524789867922664), (20, 0.05767687410116196), (19, 0.057850053533911705), (22, 0.05846042139455676), (38, 0.05967205949127674), (47, 0.0606429660692811), (39, 0.06186343031004071), (7, 0.0636257715523243), (24, 0.06389435660094023), (51, 0.06517880130559206), (15, 0.06565314065665007), (37, 0.07099430821835995), (52, 0.07573952991515398), (9, 0.07792257610708475), (4, 0.08492973819375038), (2, 0.09411752130836248), (6, 0.09790991246700287), (0, 0.1012362539768219), (14, 0.10164476279169321), (3, 0.10388921294361353), (17, 0.10463755764067173), (1, 0.10697671305388212), (13, 0.10826499201357365), (11, 0.11224442813545465), (8, 0.1324052307754755), (12, 0.1526541318744421), (10, 0.16146833449602127), (16, 0.1616979744285345), (5, 0.18085327930748463), (36, 0.6285974010825157), (18, 0.695310965180397), (53, 1.2544011324644089)]
computing accuracy for after removing block 45 . block score: 0.05396928917616606
removed block 45 current accuracy 0.9292 loss from initial  0.07079999999999997
since last training loss: 0.03799999999999992 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.054099. All blocks and scores: [(23, 0.05409883055835962), (21, 0.05524790147319436), (20, 0.05767687410116196), (19, 0.057850053533911705), (22, 0.05846042279154062), (38, 0.05967205949127674), (39, 0.06186343124136329), (7, 0.06362577248364687), (24, 0.06389435334131122), (51, 0.06508568860590458), (15, 0.06565313972532749), (47, 0.0700491163879633), (37, 0.0709943063557148), (52, 0.07623652555048466), (9, 0.07792257517576218), (4, 0.08492974005639553), (2, 0.09411752596497536), (6, 0.09790991339832544), (0, 0.10123625211417675), (14, 0.10164476558566093), (3, 0.1038892138749361), (17, 0.10463755950331688), (1, 0.10697671212255955), (13, 0.10826499108225107), (11, 0.1122444262728095), (8, 0.13240523263812065), (12, 0.1526541281491518), (10, 0.16146833263337612), (16, 0.1616979744285345), (5, 0.18085328489542007), (36, 0.6285974010825157), (18, 0.695310965180397), (53, 1.457760900259018)]
computing accuracy for after removing block 23 . block score: 0.05409883055835962
removed block 23 current accuracy 0.9158 loss from initial  0.08420000000000005
since last training loss: 0.0514 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.055248. All blocks and scores: [(21, 0.055247899144887924), (20, 0.057676872704178095), (19, 0.057850051671266556), (22, 0.058460422325879335), (38, 0.0595093434676528), (24, 0.06032770965248346), (39, 0.06271821167320013), (7, 0.06362577248364687), (51, 0.06482801213860512), (15, 0.06565314065665007), (47, 0.06714700907468796), (52, 0.07480480149388313), (37, 0.07521831896156073), (9, 0.07792257517576218), (4, 0.08492973819375038), (2, 0.09411752410233021), (6, 0.09790991246700287), (0, 0.1012362539768219), (14, 0.10164476651698351), (3, 0.10388921294361353), (17, 0.10463755670934916), (1, 0.1069767139852047), (13, 0.1082649901509285), (11, 0.11224442720413208), (8, 0.1324052345007658), (12, 0.1526541318744421), (10, 0.16146833263337612), (16, 0.1616979707032442), (5, 0.18085327371954918), (36, 0.6407878920435905), (18, 0.695310965180397), (53, 1.446803942322731)]
computing accuracy for after removing block 21 . block score: 0.055247899144887924
removed block 21 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.051072. All blocks and scores: [(24, 0.05107220867648721), (22, 0.051197285298258066), (38, 0.056501466780900955), (20, 0.057676872704178095), (19, 0.05785005120560527), (39, 0.060182669665664434), (51, 0.061622046399861574), (47, 0.06268928479403257), (7, 0.06362576875835657), (15, 0.06565314158797264), (52, 0.06880132015794516), (37, 0.07117259968072176), (9, 0.07792257610708475), (4, 0.0849297372624278), (2, 0.0941175278276205), (6, 0.09790991432964802), (0, 0.10123625304549932), (14, 0.10164476186037064), (3, 0.10388921480625868), (17, 0.1046375585719943), (1, 0.10697671305388212), (13, 0.10826498921960592), (11, 0.11224442813545465), (8, 0.1324052307754755), (12, 0.15265413001179695), (10, 0.16146833077073097), (16, 0.16169797629117966), (5, 0.18085327558219433), (36, 0.6044105738401413), (18, 0.6953109502792358), (53, 1.4905036687850952)]
computing accuracy for after removing block 24 . block score: 0.05107220867648721
removed block 24 current accuracy 0.869 loss from initial  0.131
since last training loss: 0.09819999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.051197. All blocks and scores: [(22, 0.05119728296995163), (38, 0.05492439912632108), (51, 0.05737143289297819), (20, 0.05767687363550067), (19, 0.057850051671266556), (39, 0.058106753043830395), (47, 0.05849126586690545), (7, 0.06362576968967915), (52, 0.06425640918314457), (15, 0.06565314065665007), (37, 0.06979569792747498), (9, 0.0779225742444396), (4, 0.08492973912507296), (2, 0.09411752410233021), (6, 0.09790991339832544), (0, 0.10123625490814447), (14, 0.10164476558566093), (3, 0.10388920921832323), (17, 0.1046375585719943), (1, 0.10697671212255955), (13, 0.10826498828828335), (11, 0.1122444299980998), (8, 0.13240523263812065), (12, 0.15265412628650665), (10, 0.16146832704544067), (16, 0.1616979744285345), (5, 0.18085327558219433), (36, 0.59516841173172), (18, 0.6953109577298164), (53, 1.5233128666877747)]
computing accuracy for after removing block 22 . block score: 0.05119728296995163
removed block 22 current accuracy 0.8246 loss from initial  0.1754
since last training loss: 0.14259999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.053977. All blocks and scores: [(38, 0.05397727759554982), (47, 0.05423704395070672), (51, 0.05520621594041586), (39, 0.05732561135664582), (20, 0.05767687316983938), (19, 0.05785005073994398), (52, 0.06059317523613572), (7, 0.0636257715523243), (15, 0.06565314065665007), (37, 0.07579071633517742), (9, 0.07792257610708475), (4, 0.08492973819375038), (2, 0.09411752223968506), (6, 0.09790991619229317), (0, 0.10123625490814447), (14, 0.10164476372301579), (3, 0.10388921666890383), (17, 0.10463755764067173), (1, 0.1069767102599144), (13, 0.10826499294489622), (11, 0.11224442347884178), (8, 0.13240523263812065), (12, 0.15265413373708725), (10, 0.16146833077073097), (16, 0.1616979781538248), (5, 0.18085327744483948), (36, 0.6079359948635101), (18, 0.6953109726309776), (53, 1.5237434059381485)]
computing accuracy for after removing block 38 . block score: 0.05397727759554982
removed block 38 current accuracy 0.7948 loss from initial  0.20520000000000005
since last training loss: 0.1724 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.052454. All blocks and scores: [(47, 0.052454077173024416), (51, 0.05517876101657748), (20, 0.05767687363550067), (19, 0.05785005073994398), (52, 0.05867084115743637), (7, 0.063625767827034), (39, 0.06374369841068983), (15, 0.06565314251929522), (37, 0.07579071633517742), (9, 0.07792257610708475), (4, 0.0849297372624278), (2, 0.09411752037703991), (6, 0.09790991526097059), (0, 0.10123625583946705), (14, 0.10164476744830608), (3, 0.10388921201229095), (17, 0.10463755950331688), (1, 0.10697671305388212), (13, 0.1082649938762188), (11, 0.11224442813545465), (8, 0.13240523263812065), (12, 0.15265413001179695), (10, 0.16146833449602127), (16, 0.16169797629117966), (5, 0.18085327371954918), (36, 0.6079359948635101), (18, 0.695310965180397), (53, 1.6217668950557709)]
computing accuracy for after removing block 47 . block score: 0.052454077173024416
removed block 47 current accuracy 0.6976 loss from initial  0.3024
training start
training epoch 0 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best True lr [0.1]
training epoch 1 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best True lr [0.1]
training epoch 2 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 3 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 4 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.1]
training epoch 5 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 7 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 8 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 9 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.071317. All blocks and scores: [(7, 0.0713173234835267), (15, 0.0836474196985364), (52, 0.08625145629048347), (51, 0.0874921316280961), (19, 0.09122132789343596), (9, 0.09531967714428902), (20, 0.0985594792291522), (6, 0.1016871677711606), (37, 0.10200971085578203), (4, 0.10361312329769135), (39, 0.10516641382128), (2, 0.11209696158766747), (17, 0.11954936757683754), (14, 0.11999531835317612), (11, 0.12106388155370951), (1, 0.12733217887580395), (0, 0.12755077704787254), (3, 0.1291719451546669), (13, 0.13198541291058064), (8, 0.1544952653348446), (12, 0.16620894335210323), (10, 0.1901891939342022), (16, 0.20560415647923946), (5, 0.22923588752746582), (36, 0.5414248779416084), (18, 0.6350946053862572), (53, 1.0773932188749313)]
computing accuracy for after removing block 7 . block score: 0.0713173234835267
removed block 7 current accuracy 0.9396 loss from initial  0.06040000000000001
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.080805. All blocks and scores: [(15, 0.08080476988106966), (52, 0.08286972437053919), (19, 0.08474387042224407), (51, 0.08478352800011635), (20, 0.09429978393018246), (9, 0.09445575252175331), (37, 0.09531077183783054), (6, 0.10168717056512833), (39, 0.10209908243268728), (4, 0.10361311957240105), (17, 0.10458514280617237), (2, 0.11209695879369974), (14, 0.11264821141958237), (13, 0.11284198239445686), (11, 0.11352034751325846), (1, 0.12733218166977167), (0, 0.12755078077316284), (3, 0.1291719451546669), (8, 0.1473494991660118), (12, 0.15526143088936806), (16, 0.18670723028481007), (10, 0.19494839198887348), (5, 0.22923588193953037), (36, 0.5193224623799324), (18, 0.6087348908185959), (53, 1.0820160061120987)]
computing accuracy for after removing block 15 . block score: 0.08080476988106966
removed block 15 current accuracy 0.9322 loss from initial  0.06779999999999997
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 19, with score 0.081832. All blocks and scores: [(19, 0.08183220494538546), (52, 0.0826252643018961), (51, 0.08350757695734501), (20, 0.0876177903264761), (37, 0.09437025990337133), (9, 0.09445575531572104), (39, 0.10123048350214958), (6, 0.10168717429041862), (4, 0.1036131214350462), (17, 0.10814626701176167), (2, 0.11209695413708687), (14, 0.11264820955693722), (13, 0.11284198146313429), (11, 0.11352034565061331), (1, 0.12733218260109425), (0, 0.12755078449845314), (3, 0.12917194701731205), (8, 0.14734949730336666), (12, 0.15526143088936806), (10, 0.19494839385151863), (16, 0.20432370342314243), (5, 0.2292359061539173), (36, 0.5045569874346256), (18, 0.5924935340881348), (53, 1.086649090051651)]
computing accuracy for after removing block 19 . block score: 0.08183220494538546
removed block 19 current accuracy 0.9048 loss from initial  0.09519999999999995
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.075342. All blocks and scores: [(52, 0.07534249778836966), (20, 0.07859777472913265), (51, 0.08122807834297419), (9, 0.09445575065910816), (39, 0.10107164829969406), (6, 0.10168717242777348), (4, 0.10361312329769135), (37, 0.10526584181934595), (17, 0.10814626887440681), (2, 0.11209696065634489), (14, 0.11264820862561464), (13, 0.11284198518842459), (11, 0.11352034471929073), (1, 0.12733218260109425), (0, 0.1275507789105177), (3, 0.12917194701731205), (8, 0.14734948985278606), (12, 0.15526142716407776), (10, 0.19494839012622833), (16, 0.20432369969785213), (5, 0.22923589311540127), (36, 0.5126948431134224), (18, 0.5924935415387154), (53, 1.0738408267498016)]
computing accuracy for after removing block 52 . block score: 0.07534249778836966
removed block 52 current accuracy 0.849 loss from initial  0.15100000000000002
since last training loss: 0.09560000000000002 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.078598. All blocks and scores: [(20, 0.0785977765917778), (51, 0.08122808020561934), (9, 0.09445575159043074), (39, 0.10107164736837149), (6, 0.1016871714964509), (4, 0.10361312236636877), (37, 0.10526584461331367), (17, 0.10814627073705196), (2, 0.11209695506840944), (14, 0.11264821048825979), (13, 0.11284198332577944), (11, 0.11352034751325846), (1, 0.1273321807384491), (0, 0.127550782635808), (3, 0.12917194701731205), (8, 0.1473494917154312), (12, 0.15526143088936806), (10, 0.19494839198887348), (16, 0.20432370156049728), (5, 0.22923588752746582), (36, 0.5126948356628418), (18, 0.5924935266375542), (53, 1.0974520593881607)]
computing accuracy for after removing block 20 . block score: 0.0785977765917778
removed block 20 current accuracy 0.777 loss from initial  0.22299999999999998
since last training loss: 0.16759999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.074520. All blocks and scores: [(51, 0.0745195522904396), (9, 0.09445575159043074), (39, 0.10029795952141285), (6, 0.10168717335909605), (4, 0.1036131251603365), (17, 0.10814626887440681), (2, 0.11209695972502232), (14, 0.11264820862561464), (13, 0.11284198239445686), (37, 0.1134134205058217), (11, 0.11352034471929073), (1, 0.12733217887580395), (0, 0.12755078077316284), (3, 0.12917194701731205), (8, 0.1473494954407215), (12, 0.15526142716407776), (10, 0.19494839385151863), (16, 0.20432369597256184), (5, 0.22923588193953037), (36, 0.5324067249894142), (18, 0.5924935415387154), (53, 1.0351050794124603)]
computing accuracy for after removing block 51 . block score: 0.0745195522904396
removed block 51 current accuracy 0.618 loss from initial  0.382
since last training loss: 0.3266 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 9, with score 0.094456. All blocks and scores: [(9, 0.09445575065910816), (39, 0.1002979576587677), (6, 0.10168717242777348), (4, 0.10361311957240105), (17, 0.10814626887440681), (2, 0.11209696158766747), (14, 0.11264820862561464), (13, 0.11284198053181171), (37, 0.11341341864317656), (11, 0.11352035030722618), (1, 0.1273321807384491), (0, 0.127550782635808), (3, 0.12917194701731205), (8, 0.14734949357807636), (12, 0.15526143088936806), (10, 0.19494839012622833), (16, 0.20432369969785213), (5, 0.22923588939011097), (36, 0.5324067175388336), (18, 0.5924935191869736), (53, 1.2983590066432953)]
computing accuracy for after removing block 9 . block score: 0.09445575065910816
removed block 9 current accuracy 0.5578 loss from initial  0.44220000000000004
since last training loss: 0.38680000000000003 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.095138. All blocks and scores: [(39, 0.0951377460733056), (37, 0.09612218104302883), (14, 0.09893988817930222), (11, 0.09954771492630243), (17, 0.10065921489149332), (6, 0.10168716963380575), (4, 0.10361311957240105), (13, 0.10789762809872627), (2, 0.11209695413708687), (12, 0.12233219761401415), (1, 0.12733217887580395), (0, 0.12755077704787254), (3, 0.12917194701731205), (8, 0.1473494917154312), (16, 0.1610057447105646), (10, 0.18632834404706955), (5, 0.22923588752746582), (36, 0.488630261272192), (18, 0.5646627470850945), (53, 1.2920961827039719)]
computing accuracy for after removing block 39 . block score: 0.0951377460733056
removed block 39 current accuracy 0.4702 loss from initial  0.5298
since last training loss: 0.4744 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 37, with score 0.096122. All blocks and scores: [(37, 0.09612218011170626), (14, 0.09893989190459251), (11, 0.09954771306365728), (17, 0.10065921768546104), (6, 0.10168717242777348), (4, 0.10361312609165907), (13, 0.10789762996137142), (2, 0.11209695506840944), (12, 0.1223321994766593), (1, 0.12733217887580395), (0, 0.1275507789105177), (3, 0.12917194329202175), (8, 0.14734948799014091), (16, 0.16100574657320976), (10, 0.18632834777235985), (5, 0.22923588752746582), (36, 0.4886302649974823), (18, 0.5646627694368362), (53, 1.3215823322534561)]
computing accuracy for after removing block 37 . block score: 0.09612218011170626
removed block 37 current accuracy 0.4498 loss from initial  0.5502
since last training loss: 0.4948 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 14, with score 0.098940. All blocks and scores: [(14, 0.09893988911062479), (11, 0.09954771213233471), (17, 0.10065921675413847), (6, 0.1016871714964509), (4, 0.10361312050372362), (13, 0.10789762809872627), (2, 0.11209695879369974), (12, 0.12233219668269157), (1, 0.1273321770131588), (0, 0.12755078077316284), (3, 0.1291719451546669), (8, 0.1473494954407215), (16, 0.16100573912262917), (10, 0.186328349635005), (5, 0.22923588566482067), (36, 0.488630261272192), (18, 0.5646627619862556), (53, 1.916493982076645)]
computing accuracy for after removing block 14 . block score: 0.09893988911062479
removed block 14 current accuracy 0.3864 loss from initial  0.6135999999999999
since last training loss: 0.5582 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.099548. All blocks and scores: [(11, 0.09954771492630243), (6, 0.10168717242777348), (4, 0.10361311957240105), (17, 0.10494628082960844), (13, 0.10789762996137142), (2, 0.11209695879369974), (12, 0.12233219668269157), (1, 0.1273321807384491), (0, 0.1275507789105177), (3, 0.12917194329202175), (8, 0.1473494991660118), (10, 0.1863283459097147), (16, 0.20490694232285023), (5, 0.22923588939011097), (36, 0.49797050654888153), (18, 0.5678260698914528), (53, 2.1259016692638397)]
computing accuracy for after removing block 11 . block score: 0.09954771492630243
removed block 11 current accuracy 0.34 loss from initial  0.6599999999999999
since last training loss: 0.6046 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.098538. All blocks and scores: [(17, 0.09853824879974127), (6, 0.1016871714964509), (4, 0.10361312329769135), (13, 0.10409256536513567), (12, 0.10709244292229414), (2, 0.11209695972502232), (1, 0.12733218260109425), (0, 0.1275507863610983), (3, 0.1291719451546669), (8, 0.1473494917154312), (16, 0.14799745939671993), (10, 0.1863283459097147), (5, 0.22923588007688522), (36, 0.5061926394701004), (18, 0.5957873687148094), (53, 2.1377283930778503)]
computing accuracy for after removing block 17 . block score: 0.09853824879974127
removed block 17 current accuracy 0.332 loss from initial  0.6679999999999999
training start
training epoch 0 val accuracy 0.7732 topk_dict {'top1': 0.7732} is_best True lr [0.1]
training epoch 1 val accuracy 0.811 topk_dict {'top1': 0.811} is_best True lr [0.1]
training epoch 2 val accuracy 0.813 topk_dict {'top1': 0.813} is_best True lr [0.1]
training epoch 3 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best True lr [0.1]
training epoch 4 val accuracy 0.832 topk_dict {'top1': 0.832} is_best True lr [0.1]
training epoch 5 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.1]
training epoch 6 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.1]
training epoch 7 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.1]
training epoch 8 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 9 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best False lr [0.1]
training epoch 10 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.915000)
finished training. finished 50 epochs. accuracy 0.915 topk_dict {'top1': 0.915}
