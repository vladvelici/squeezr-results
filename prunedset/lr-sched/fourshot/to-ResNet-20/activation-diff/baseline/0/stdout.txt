start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806221771985), (30, 0.007531446171924472), (2, 0.00772880477597937), (31, 0.009409212623722851), (34, 0.01063339039683342), (33, 0.010768219246529043), (35, 0.010826650890521705), (32, 0.011131544597446918), (28, 0.012192570604383945), (29, 0.013092639623209834), (26, 0.013270106166601181), (25, 0.014763001585379243), (27, 0.015783544396981597), (24, 0.015805189963430166), (22, 0.01584369910415262), (23, 0.01730801025405526), (39, 0.01998384390026331), (42, 0.020841386634856462), (38, 0.02102866186760366), (14, 0.021516708191484213), (43, 0.021687703672796488), (5, 0.021877117920666933), (41, 0.02212515496648848), (44, 0.022776450496166945), (45, 0.023535518441349268), (40, 0.024229633389040828), (47, 0.024651852436363697), (37, 0.025173959555104375), (49, 0.025184793397784233), (3, 0.02567107044160366), (21, 0.025702943792566657), (50, 0.025765859754756093), (20, 0.027230344247072935), (46, 0.028618558775633574), (17, 0.029949784744530916), (51, 0.031313665676862), (48, 0.03152880142442882), (19, 0.03474585758522153), (16, 0.04510569619014859), (15, 0.04667254630476236), (0, 0.04746154695749283), (6, 0.05039409967139363), (7, 0.050692159216850996), (4, 0.05092597473412752), (10, 0.06328557664528489), (13, 0.06400972791016102), (8, 0.06672556232661009), (52, 0.0682881223037839), (12, 0.07267716992646456), (11, 0.0741947004571557), (9, 0.07928675040602684), (36, 0.3385251797735691), (18, 0.4787600487470627), (53, 0.9074814692139626)]
computing accuracy for after removing block 1 . block score: 0.004111806221771985
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.007558359357062727), (2, 0.007992399856448174), (31, 0.009376696078106761), (34, 0.010569097707048059), (33, 0.010759366676211357), (35, 0.010833792272023857), (32, 0.011090524611063302), (28, 0.012191424728371203), (29, 0.013140873634256423), (26, 0.013311112066730857), (25, 0.014746291330084205), (24, 0.015801146626472473), (22, 0.015853286837227643), (27, 0.015870402567088604), (23, 0.017250196309760213), (39, 0.019925505854189396), (42, 0.020839827368035913), (38, 0.02093886467628181), (5, 0.021410029381513596), (14, 0.021470680134370923), (43, 0.02164699067361653), (41, 0.02209674404002726), (44, 0.022830850211903453), (45, 0.023494189837947488), (40, 0.024263028986752033), (47, 0.02462643221952021), (37, 0.025157071417197585), (49, 0.02518477221019566), (21, 0.02562487288378179), (50, 0.025800990872085094), (3, 0.02626762050203979), (20, 0.027126540895551443), (46, 0.02863829699344933), (17, 0.03002214594744146), (51, 0.03129110159352422), (48, 0.03151489049196243), (19, 0.034666630905121565), (16, 0.04479835741221905), (15, 0.046408084221184254), (0, 0.04746154695749283), (4, 0.050930495373904705), (6, 0.051349631045013666), (7, 0.051561571191996336), (10, 0.06291997665539384), (13, 0.06426404416561127), (52, 0.06817463133484125), (8, 0.0683986721560359), (12, 0.07294023595750332), (11, 0.07450826559215784), (9, 0.08042858727276325), (36, 0.3383275605738163), (18, 0.4787031002342701), (53, 0.9076696112751961)]
computing accuracy for after removing block 30 . block score: 0.007558359357062727
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992399914655834), (31, 0.009402871248312294), (34, 0.010204409714788198), (35, 0.01043578318785876), (33, 0.01097452687099576), (32, 0.011320485384203494), (28, 0.012191424728371203), (29, 0.01314087409991771), (26, 0.013311112066730857), (25, 0.014746291446499527), (24, 0.015801146859303117), (22, 0.015853286837227643), (27, 0.015870402567088604), (23, 0.017250196309760213), (39, 0.019866376416757703), (38, 0.020629743114113808), (42, 0.02069183182902634), (5, 0.021410029381513596), (14, 0.021470679668709636), (43, 0.021839084336534142), (41, 0.02201103698462248), (44, 0.02278478746302426), (45, 0.0233374263625592), (47, 0.024608810199424624), (40, 0.024793640710413456), (49, 0.025005090283229947), (21, 0.025624873116612434), (37, 0.025666437577456236), (50, 0.025765020167455077), (3, 0.026267620967701077), (20, 0.027126540429890156), (46, 0.028450446436181664), (17, 0.030022146180272102), (51, 0.030892511131241918), (48, 0.03145507094450295), (19, 0.034666632767766714), (16, 0.04479835648089647), (15, 0.046408083755522966), (0, 0.04746154695749283), (4, 0.05093049630522728), (6, 0.05134963011369109), (7, 0.05156157165765762), (10, 0.06291997665539384), (13, 0.06426404323428869), (52, 0.06774707604199648), (8, 0.0683986721560359), (12, 0.07294023223221302), (11, 0.07450826559215784), (9, 0.0804285854101181), (36, 0.3417893499135971), (18, 0.4787031039595604), (53, 0.9106026664376259)]
computing accuracy for after removing block 2 . block score: 0.007992399914655834
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.0093913838500157), (34, 0.010356180020608008), (35, 0.01053083362057805), (33, 0.010978628415614367), (32, 0.011285086395218968), (28, 0.012222225312143564), (29, 0.013395004672929645), (26, 0.013411890831775963), (25, 0.014773015980608761), (24, 0.015895847463980317), (22, 0.015945045743137598), (27, 0.016057065688073635), (23, 0.01718751946464181), (39, 0.019868448842316866), (42, 0.020744004286825657), (38, 0.020750499796122313), (5, 0.021117351483553648), (14, 0.02132761781103909), (43, 0.0217928234487772), (41, 0.021959960227832198), (44, 0.022877608193084598), (45, 0.02328475913964212), (47, 0.024535594042390585), (40, 0.024922656826674938), (49, 0.024976717540994287), (21, 0.02554046711884439), (50, 0.025736609008163214), (37, 0.025740001583471894), (3, 0.026626083767041564), (20, 0.02713091135956347), (46, 0.02835425199009478), (17, 0.03005285863764584), (51, 0.03080705483444035), (48, 0.03136400459334254), (19, 0.034590966533869505), (16, 0.04449417348951101), (15, 0.04618462733924389), (0, 0.0474615478888154), (4, 0.05093384999781847), (7, 0.05248213326558471), (6, 0.053186831530183554), (10, 0.06307358667254448), (13, 0.06417542230337858), (52, 0.06737186759710312), (8, 0.07143167965114117), (12, 0.07294508069753647), (11, 0.07423979043960571), (9, 0.08192321378737688), (36, 0.3429319001734257), (18, 0.48187144100666046), (53, 0.9105552807450294)]
computing accuracy for after removing block 31 . block score: 0.0093913838500157
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670191518962), (35, 0.010449821478687227), (33, 0.010985722299665213), (32, 0.011304144863970578), (28, 0.012222225777804852), (29, 0.01339500502217561), (26, 0.01341189059894532), (25, 0.014773016097024083), (24, 0.015895847463980317), (22, 0.015945044811815023), (27, 0.016057065688073635), (23, 0.017187519930303097), (39, 0.019797147484496236), (38, 0.02034430461935699), (42, 0.02058867714367807), (5, 0.021117352414876223), (14, 0.021327618043869734), (43, 0.02176103019155562), (41, 0.021869145100936294), (44, 0.022828259970992804), (45, 0.023396300384774804), (47, 0.024508256698027253), (49, 0.02499568462371826), (40, 0.025056051556020975), (21, 0.02554046781733632), (37, 0.025701351929455996), (50, 0.025906251510605216), (3, 0.026626084931194782), (20, 0.027130909962579608), (46, 0.028551972238346934), (17, 0.03005285933613777), (51, 0.03091105679050088), (48, 0.031486503314226866), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.04618462594226003), (0, 0.0474615478888154), (4, 0.050933849066495895), (7, 0.05248213419690728), (6, 0.05318683199584484), (10, 0.06307358760386705), (13, 0.0641754250973463), (52, 0.0673162592574954), (8, 0.07143167965114117), (12, 0.0729450760409236), (11, 0.07423978857696056), (9, 0.08192321565002203), (36, 0.34496789798140526), (18, 0.48187142238020897), (53, 0.9170897379517555)]
computing accuracy for after removing block 34 . block score: 0.010089670191518962
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489317821338773), (33, 0.010985722532495856), (32, 0.011304144863970578), (28, 0.012222225777804852), (29, 0.013395005255006254), (26, 0.01341189059894532), (25, 0.014773015747778118), (24, 0.015895846765488386), (22, 0.015945045044645667), (27, 0.01605706592090428), (23, 0.017187519930303097), (39, 0.019266640534624457), (38, 0.019315700512379408), (42, 0.019673911621794105), (5, 0.021117351250723004), (41, 0.021174799418076873), (43, 0.021180002484470606), (14, 0.021327618043869734), (44, 0.02225361135788262), (45, 0.02322493796236813), (47, 0.02422352065332234), (49, 0.02466233097948134), (40, 0.024751328164711595), (37, 0.02511494606733322), (21, 0.025540466653183103), (50, 0.025639905594289303), (3, 0.02662608353421092), (20, 0.02713091019541025), (46, 0.02807540842331946), (17, 0.030052857706323266), (51, 0.03030704567208886), (48, 0.031094568548724055), (19, 0.03459096606820822), (16, 0.04449417209252715), (15, 0.04618462547659874), (0, 0.04746154649183154), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358853518963), (13, 0.06417542230337858), (52, 0.06632223632186651), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321751266718), (36, 0.3418983370065689), (18, 0.48187144100666046), (53, 0.9368007332086563)]
computing accuracy for after removing block 35 . block score: 0.010489317821338773
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.01098572218324989), (32, 0.011304144631139934), (28, 0.012222225777804852), (29, 0.01339500502217561), (26, 0.013411890482529998), (25, 0.014773016097024083), (24, 0.015895848162472248), (22, 0.015945045044645667), (27, 0.01605706592090428), (23, 0.017187519930303097), (38, 0.01836523856036365), (39, 0.018731158692389727), (42, 0.01884545711800456), (41, 0.02022721921093762), (43, 0.020478624617680907), (5, 0.021117352414876223), (14, 0.021327618043869734), (44, 0.021796140586957335), (45, 0.022849174682050943), (47, 0.023645550245419145), (40, 0.02389344177208841), (49, 0.024012631503865123), (37, 0.024080609437078238), (50, 0.025119469966739416), (21, 0.025540467351675034), (3, 0.026626083999872208), (20, 0.027130911592394114), (46, 0.027472961461171508), (51, 0.029444649582728744), (17, 0.030052859568968415), (48, 0.030196279054507613), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.047461546026170254), (4, 0.05093384813517332), (7, 0.052482135128229856), (6, 0.053186829667538404), (10, 0.06307358760386705), (13, 0.0641754250973463), (52, 0.06433123350143433), (8, 0.07143167592585087), (12, 0.0729450797662139), (11, 0.07423979043960571), (9, 0.0819232128560543), (36, 0.335262943059206), (18, 0.48187144845724106), (53, 0.9589025154709816)]
computing accuracy for after removing block 33 . block score: 0.01098572218324989
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144514724612), (28, 0.012222225544974208), (29, 0.013395004672929645), (26, 0.01341189059894532), (25, 0.014773015747778118), (24, 0.015895847463980317), (22, 0.015945045743137598), (27, 0.01605706592090428), (23, 0.017187519930303097), (38, 0.017859898041933775), (39, 0.018481214297935367), (42, 0.018494685646146536), (41, 0.019707750994712114), (43, 0.01980409794487059), (5, 0.021117351949214935), (14, 0.02132761850953102), (44, 0.021341139683499932), (45, 0.02275731205008924), (47, 0.02288467437028885), (40, 0.022964164381846786), (49, 0.023509372025728226), (37, 0.023596109356731176), (50, 0.02473079040646553), (21, 0.025540467351675034), (3, 0.026626083767041564), (46, 0.026851587928831577), (20, 0.027130910893902183), (51, 0.02867021202109754), (48, 0.029500650009140372), (17, 0.03005285933613777), (19, 0.034590966533869505), (16, 0.044494170229882), (15, 0.04618462594226003), (0, 0.047461546026170254), (4, 0.05093384766951203), (7, 0.052482133731245995), (6, 0.053186829667538404), (52, 0.062409013975411654), (10, 0.06307358480989933), (13, 0.06417542602866888), (8, 0.07143167778849602), (12, 0.0729450797662139), (11, 0.07423978764563799), (9, 0.08192321471869946), (36, 0.3304997459053993), (18, 0.48187143728137016), (53, 0.9826682507991791)]
computing accuracy for after removing block 32 . block score: 0.011304144514724612
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012222. All blocks and scores: [(28, 0.012222225777804852), (29, 0.013395004672929645), (26, 0.013411890366114676), (25, 0.014773015980608761), (24, 0.01589584769681096), (22, 0.015945045510306954), (27, 0.01605706592090428), (23, 0.017187519697472453), (38, 0.017423494020476937), (42, 0.017853327095508575), (39, 0.01824311213567853), (41, 0.019577455008402467), (43, 0.019590672105550766), (44, 0.020979802357032895), (5, 0.02111735218204558), (14, 0.021327618043869734), (47, 0.022578312316909432), (45, 0.022697478532791138), (37, 0.022853391710668802), (49, 0.023190517211332917), (40, 0.023227871395647526), (50, 0.024362222757190466), (21, 0.025540467351675034), (46, 0.02650547376833856), (3, 0.026626083999872208), (20, 0.02713091135956347), (51, 0.028193608159199357), (48, 0.029435487929731607), (17, 0.030052859568968415), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.0461846268735826), (0, 0.04746154835447669), (4, 0.050933847203850746), (7, 0.05248213419690728), (6, 0.053186831530183554), (52, 0.061633951496332884), (10, 0.06307358667254448), (13, 0.06417542602866888), (8, 0.07143167685717344), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.0819232128560543), (36, 0.3290293663740158), (18, 0.48187144473195076), (53, 0.9939456880092621)]
computing accuracy for after removing block 28 . block score: 0.012222225777804852
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.013134. All blocks and scores: [(29, 0.013134446926414967), (26, 0.013411890715360641), (25, 0.01477301586419344), (24, 0.01589584699831903), (22, 0.01594504527747631), (27, 0.016057066153734922), (38, 0.017168684862554073), (23, 0.01718752016313374), (42, 0.01737769739702344), (39, 0.01826188713312149), (43, 0.019126569386571646), (41, 0.019421309931203723), (44, 0.02071693423204124), (5, 0.021117350552231073), (14, 0.021327617578208447), (47, 0.022124751703813672), (45, 0.022405647207051516), (37, 0.02259774226695299), (40, 0.02269273577257991), (49, 0.022759285755455494), (50, 0.024160553235560656), (21, 0.02554046781733632), (46, 0.026188244810327888), (3, 0.02662608469836414), (20, 0.02713091135956347), (51, 0.027606616029515862), (48, 0.028955485904589295), (17, 0.030052858171984553), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.04618462547659874), (0, 0.04746154695749283), (4, 0.05093384673818946), (7, 0.052482135593891144), (6, 0.05318683013319969), (52, 0.060717643704265356), (10, 0.06307358760386705), (13, 0.06417542695999146), (8, 0.07143167778849602), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3257451541721821), (18, 0.48187143728137016), (53, 1.0072815790772438)]
computing accuracy for after removing block 29 . block score: 0.013134446926414967
removed block 29 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013412. All blocks and scores: [(26, 0.01341189059894532), (25, 0.014773016097024083), (24, 0.015895847929641604), (22, 0.015945045743137598), (27, 0.016057065688073635), (38, 0.016528347972780466), (23, 0.017187519930303097), (42, 0.01752680167555809), (39, 0.018013010267168283), (43, 0.018969025928527117), (41, 0.019220215501263738), (44, 0.020273723639547825), (5, 0.02111735101789236), (14, 0.02132761850953102), (47, 0.021955855190753937), (45, 0.022276046918705106), (49, 0.022341078147292137), (37, 0.022382006514817476), (40, 0.02295848447829485), (50, 0.024057542672380805), (21, 0.025540467584505677), (46, 0.02629394782707095), (3, 0.02662608353421092), (20, 0.02713091019541025), (51, 0.027329841163009405), (48, 0.028983933152630925), (17, 0.030052859568968415), (19, 0.03459096699953079), (16, 0.044494173023849726), (15, 0.04618462733924389), (0, 0.04746154649183154), (4, 0.05093384766951203), (7, 0.05248213233426213), (6, 0.05318683199584484), (52, 0.0603490243665874), (10, 0.06307358667254448), (13, 0.06417542416602373), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321378737688), (36, 0.33013898879289627), (18, 0.48187143728137016), (53, 1.0144704431295395)]
computing accuracy for after removing block 26 . block score: 0.01341189059894532
removed block 26 current accuracy 0.9956 loss from initial  0.0043999999999999595
training start
training epoch 0 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 1 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 2 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.1]
training epoch 5 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.1]
training epoch 9 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 10 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.995600)
finished training. finished 50 epochs. accuracy 0.9956 topk_dict {'top1': 0.9956}
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014773. All blocks and scores: [(25, 0.014773015980608761), (24, 0.015895847929641604), (22, 0.015945045510306954), (38, 0.016351457219570875), (27, 0.016416134545579553), (42, 0.016968311509117484), (23, 0.017187519930303097), (39, 0.01759598543867469), (43, 0.01864881836809218), (41, 0.01897320244461298), (44, 0.02003990998491645), (5, 0.021117351250723004), (14, 0.02132761781103909), (47, 0.02177123911678791), (45, 0.02202610089443624), (49, 0.022116392850875854), (37, 0.022165502654388547), (40, 0.022654107306152582), (50, 0.024147538002580404), (21, 0.02554046711884439), (46, 0.025726865278556943), (51, 0.02658225712366402), (3, 0.02662608353421092), (20, 0.027130910428240895), (48, 0.028896389063447714), (17, 0.03005285933613777), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.0461846268735826), (0, 0.0474615478888154), (4, 0.050933849066495895), (7, 0.05248213419690728), (6, 0.05318683199584484), (52, 0.059312851168215275), (10, 0.06307358713820577), (13, 0.06417542789131403), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423979137092829), (9, 0.08192321751266718), (36, 0.32769153639674187), (18, 0.48187143355607986), (53, 1.034986436367035)]
computing accuracy for after removing block 25 . block score: 0.014773015980608761
removed block 25 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.015896. All blocks and scores: [(24, 0.015895847463980317), (22, 0.015945045510306954), (38, 0.016116746701300144), (27, 0.016201818827539682), (42, 0.01680090045556426), (39, 0.017148226033896208), (23, 0.01718752016313374), (43, 0.01856321026571095), (41, 0.018886165227741003), (44, 0.019977419869974256), (5, 0.02111735101789236), (14, 0.021327618276700377), (47, 0.021370713133364916), (49, 0.02168397232890129), (45, 0.02175015676766634), (37, 0.02176444698125124), (40, 0.022557187592610717), (50, 0.024213683092966676), (21, 0.02554046781733632), (46, 0.025579196866601706), (51, 0.02589200669899583), (3, 0.026626083999872208), (20, 0.027130911126732826), (48, 0.028420996153727174), (17, 0.03005285933613777), (19, 0.034590966533869505), (16, 0.044494173023849726), (15, 0.04618462594226003), (0, 0.04746154649183154), (4, 0.050933847203850746), (7, 0.05248213466256857), (6, 0.053186831530183554), (52, 0.05805372120812535), (10, 0.06307358760386705), (13, 0.06417542602866888), (8, 0.07143167685717344), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.0819232165813446), (36, 0.3308594338595867), (18, 0.48187144100666046), (53, 1.048815280199051)]
computing accuracy for after removing block 24 . block score: 0.015895847463980317
removed block 24 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015644. All blocks and scores: [(27, 0.015644041821360588), (38, 0.01593761029653251), (22, 0.015945045510306954), (42, 0.016610756050795317), (39, 0.017013835487887263), (23, 0.017187519930303097), (43, 0.018406943418085575), (41, 0.01871691015549004), (44, 0.01980676525272429), (47, 0.02102361200377345), (5, 0.021117351250723004), (14, 0.021327618043869734), (49, 0.021376667078584433), (45, 0.02166589885018766), (37, 0.022019793977960944), (40, 0.02235984825529158), (50, 0.024096908746287227), (46, 0.025163474259898067), (51, 0.025269009871408343), (21, 0.025540466886013746), (3, 0.026626083767041564), (20, 0.027130910893902183), (48, 0.027973036281764507), (17, 0.03005285793915391), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462594226003), (0, 0.04746154882013798), (4, 0.050933849066495895), (7, 0.052482133731245995), (6, 0.053186832927167416), (52, 0.05717874504625797), (10, 0.06307358900085092), (13, 0.0641754250973463), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423978950828314), (9, 0.0819232128560543), (36, 0.3319184184074402), (18, 0.48187144100666046), (53, 1.056150808930397)]
computing accuracy for after removing block 27 . block score: 0.015644041821360588
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.015308. All blocks and scores: [(38, 0.015307826222851872), (22, 0.01594504527747631), (42, 0.01651047053746879), (39, 0.016512590693309903), (23, 0.017187519697472453), (43, 0.017808301141485572), (41, 0.018523185746744275), (44, 0.019996798830106854), (47, 0.0205401957500726), (49, 0.021024908404797316), (5, 0.021117351483553648), (14, 0.021327617345377803), (45, 0.021421734942123294), (37, 0.021547694457694888), (40, 0.02197462203912437), (50, 0.024400704773142934), (46, 0.024719235254451632), (51, 0.024754389887675643), (21, 0.025540467351675034), (3, 0.026626083767041564), (20, 0.027130910428240895), (48, 0.02760885003954172), (17, 0.030052860034629703), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.04618462594226003), (0, 0.04746154695749283), (4, 0.05093384813517332), (7, 0.052482133731245995), (6, 0.053186831064522266), (52, 0.05619245721027255), (10, 0.06307358667254448), (13, 0.06417542602866888), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.330477949231863), (18, 0.48187143728137016), (53, 1.0667929649353027)]
computing accuracy for after removing block 38 . block score: 0.015307826222851872
removed block 38 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.015945. All blocks and scores: [(22, 0.015945045510306954), (42, 0.01670120097696781), (39, 0.017114691203460097), (23, 0.017187519930303097), (43, 0.017193771433085203), (41, 0.018250516382977366), (44, 0.019619957776740193), (47, 0.02009118953719735), (49, 0.020288462517783046), (45, 0.02080282778479159), (5, 0.02111735171638429), (14, 0.021327618276700377), (37, 0.021547694690525532), (40, 0.022401680005714297), (50, 0.023554304149001837), (51, 0.023709413828328252), (46, 0.024713726714253426), (21, 0.02554046711884439), (3, 0.02662608353421092), (48, 0.02690607844851911), (20, 0.027130910893902183), (17, 0.03005285863764584), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.0474615478888154), (4, 0.05093384813517332), (7, 0.05248213419690728), (6, 0.053186831064522266), (52, 0.054677230305969715), (10, 0.06307358760386705), (13, 0.06417542602866888), (8, 0.07143167592585087), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321378737688), (36, 0.3304779380559921), (18, 0.48187144100666046), (53, 1.0992354601621628)]
computing accuracy for after removing block 22 . block score: 0.015945045510306954
removed block 22 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.016116. All blocks and scores: [(42, 0.016115854727104306), (23, 0.016751634422689676), (39, 0.01716357981786132), (43, 0.017340539023280144), (41, 0.01835115230642259), (44, 0.01973160356283188), (47, 0.019744616001844406), (49, 0.01996712014079094), (45, 0.02083969279192388), (5, 0.021117351483553648), (14, 0.021327618742361665), (37, 0.021559265442192554), (40, 0.021836146945133805), (51, 0.02322521130554378), (50, 0.023681905353441834), (46, 0.02471964107826352), (21, 0.025540467584505677), (48, 0.026413153391331434), (3, 0.026626083999872208), (20, 0.027130910428240895), (17, 0.03005285793915391), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.046184624545276165), (0, 0.04746154695749283), (4, 0.050933847203850746), (7, 0.05248213419690728), (6, 0.053186831064522266), (52, 0.054122107569128275), (10, 0.06307358667254448), (13, 0.06417542695999146), (8, 0.07143167871981859), (12, 0.07294508069753647), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3307998664677143), (18, 0.48187144845724106), (53, 1.1102152168750763)]
computing accuracy for after removing block 42 . block score: 0.016115854727104306
removed block 42 current accuracy 0.9696 loss from initial  0.030399999999999983
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016752. All blocks and scores: [(23, 0.01675163395702839), (39, 0.017163579585030675), (41, 0.018351151840761304), (43, 0.01839060429483652), (49, 0.019832696998491883), (47, 0.01992953522130847), (44, 0.02070042653940618), (5, 0.021117351483553648), (14, 0.02132761781103909), (37, 0.021559264976531267), (45, 0.021742522018030286), (40, 0.021836147410795093), (51, 0.02259360929019749), (50, 0.023519961861893535), (46, 0.02537697833031416), (21, 0.025540467584505677), (48, 0.02606480778194964), (3, 0.026626083767041564), (20, 0.02713091066107154), (17, 0.030052858171984553), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462733924389), (0, 0.0474615478888154), (4, 0.05093384766951203), (52, 0.05230193678289652), (7, 0.052482135128229856), (6, 0.05318683013319969), (10, 0.06307358806952834), (13, 0.06417542695999146), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.3307998813688755), (18, 0.48187142238020897), (53, 1.1384830176830292)]
computing accuracy for after removing block 23 . block score: 0.01675163395702839
removed block 23 current accuracy 0.9584 loss from initial  0.04159999999999997
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 39, with score 0.016881. All blocks and scores: [(39, 0.016880576964467764), (41, 0.018102025846019387), (43, 0.018480214988812804), (49, 0.01939964178018272), (47, 0.01949230721220374), (44, 0.020657918881624937), (37, 0.02109104674309492), (5, 0.02111735171638429), (45, 0.021201944211497903), (14, 0.021327618276700377), (40, 0.021531845442950726), (51, 0.02205352485179901), (50, 0.02336074272170663), (46, 0.024864061269909143), (21, 0.025540466886013746), (48, 0.02576295076869428), (3, 0.02662608353421092), (20, 0.02713091066107154), (17, 0.030052858404815197), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462733924389), (0, 0.047461545560508966), (4, 0.050933849066495895), (52, 0.05140139767900109), (7, 0.052482135128229856), (6, 0.053186831530183554), (10, 0.06307359132915735), (13, 0.06417542416602373), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423979230225086), (9, 0.08192321378737688), (36, 0.3335048072040081), (18, 0.48187145218253136), (53, 1.1530401110649109)]
computing accuracy for after removing block 39 . block score: 0.016880576964467764
removed block 39 current accuracy 0.9516 loss from initial  0.0484
since last training loss: 0.04400000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 41, with score 0.018354. All blocks and scores: [(41, 0.018354227300733328), (43, 0.01853087544441223), (49, 0.019299121340736747), (47, 0.019307703943923116), (37, 0.021091047674417496), (5, 0.021117351483553648), (51, 0.02130503044463694), (14, 0.02132761781103909), (44, 0.021386134438216686), (40, 0.021602723747491837), (45, 0.021840069675818086), (50, 0.022813046583905816), (46, 0.02475375938229263), (21, 0.02554046781733632), (48, 0.0260433207731694), (3, 0.026626083767041564), (20, 0.027130910893902183), (17, 0.03005285933613777), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.04746154695749283), (4, 0.050933847203850746), (52, 0.05102795595303178), (7, 0.052482133731245995), (6, 0.05318683013319969), (10, 0.06307358713820577), (13, 0.0641754288226366), (8, 0.07143167965114117), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.08192321751266718), (36, 0.3335048072040081), (18, 0.48187144100666046), (53, 1.2039358466863632)]
computing accuracy for after removing block 41 . block score: 0.018354227300733328
removed block 41 current accuracy 0.9472 loss from initial  0.05279999999999996
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 47, with score 0.018820. All blocks and scores: [(47, 0.018819912802428007), (49, 0.0189357060007751), (43, 0.01949500059708953), (51, 0.020423234906047583), (37, 0.02109104720875621), (5, 0.021117351949214935), (14, 0.02132761781103909), (45, 0.02155023836530745), (40, 0.02160272398032248), (44, 0.021712582791224122), (50, 0.022176146507263184), (46, 0.024738195119425654), (21, 0.02554046781733632), (48, 0.02603754703886807), (3, 0.026626084465533495), (20, 0.027130910893902183), (17, 0.030052858404815197), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.046184626407921314), (0, 0.04746154835447669), (52, 0.05015529925003648), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.053186831064522266), (10, 0.06307358853518963), (13, 0.06417542602866888), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423979043960571), (9, 0.0819232128560543), (36, 0.3335048109292984), (18, 0.48187144845724106), (53, 1.2834498584270477)]
computing accuracy for after removing block 47 . block score: 0.018819912802428007
removed block 47 current accuracy 0.9228 loss from initial  0.07720000000000005
since last training loss: 0.07280000000000009 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.019495. All blocks and scores: [(43, 0.019494999898597598), (49, 0.020387135446071625), (37, 0.021091047441586852), (5, 0.021117351483553648), (14, 0.021327617578208447), (51, 0.021424151491373777), (45, 0.021550237433984876), (40, 0.02160272398032248), (44, 0.021712582791224122), (50, 0.023240457056090236), (46, 0.02473819558508694), (21, 0.02554046711884439), (3, 0.026626083767041564), (20, 0.02713091135956347), (48, 0.02790107694454491), (17, 0.03005285863764584), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462733924389), (0, 0.047461547423154116), (4, 0.05093384999781847), (52, 0.05177585035562515), (7, 0.05248213466256857), (6, 0.05318683059886098), (10, 0.06307358667254448), (13, 0.0641754250973463), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423979230225086), (9, 0.08192321471869946), (36, 0.3335048034787178), (18, 0.48187143355607986), (53, 1.4368782192468643)]
computing accuracy for after removing block 43 . block score: 0.019494999898597598
removed block 43 current accuracy 0.9048 loss from initial  0.09519999999999995
training start
training epoch 0 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 1 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 2 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 3 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 4 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 5 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 6 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 7 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 8 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 9 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 10 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.962200)
finished training. finished 50 epochs. accuracy 0.9622 topk_dict {'top1': 0.9622}
start iteration 22
[activation diff]: block to remove picked: 50, with score 0.036829. All blocks and scores: [(50, 0.03682904038578272), (5, 0.042287086602300406), (49, 0.04485107958316803), (3, 0.04546564957126975), (51, 0.04577117599546909), (45, 0.046985172200948), (14, 0.048762927297502756), (44, 0.051072989124804735), (48, 0.054868016857653856), (46, 0.055888311471790075), (17, 0.058592078275978565), (52, 0.05956592597067356), (40, 0.05979789420962334), (37, 0.06622369308024645), (20, 0.0678075896576047), (21, 0.08114435989409685), (0, 0.08123695384711027), (19, 0.08448005095124245), (15, 0.0917744878679514), (6, 0.09618295263499022), (16, 0.10192209202796221), (4, 0.10507264360785484), (7, 0.11365998070687056), (10, 0.11422258336097002), (8, 0.12416790798306465), (13, 0.1294749490916729), (11, 0.1303351428359747), (9, 0.14890670217573643), (12, 0.15011662431061268), (36, 0.5930935889482498), (18, 0.6172169297933578), (53, 1.133944794535637)]
computing accuracy for after removing block 50 . block score: 0.03682904038578272
removed block 50 current accuracy 0.9548 loss from initial  0.04520000000000002
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 5, with score 0.042287. All blocks and scores: [(5, 0.04228708567097783), (49, 0.04485107958316803), (3, 0.04546564817428589), (45, 0.04698517266660929), (14, 0.04876292683184147), (44, 0.05107299145311117), (51, 0.05269546341150999), (48, 0.05486801313236356), (46, 0.05588831007480621), (17, 0.05859207920730114), (40, 0.059797894675284624), (52, 0.06474509090185165), (37, 0.06622369028627872), (20, 0.06780759058892727), (21, 0.08114435896277428), (0, 0.08123695012181997), (19, 0.08448005001991987), (15, 0.09177448228001595), (6, 0.09618295636028051), (16, 0.10192209295928478), (4, 0.10507264547049999), (7, 0.11365998163819313), (10, 0.11422257870435715), (8, 0.1241679098457098), (13, 0.12947495095431805), (11, 0.1303351428359747), (9, 0.14890670031309128), (12, 0.15011661872267723), (36, 0.5930935740470886), (18, 0.6172169297933578), (53, 1.2391493320465088)]
computing accuracy for after removing block 5 . block score: 0.04228708567097783
removed block 5 current accuracy 0.9466 loss from initial  0.0534
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 49, with score 0.044574. All blocks and scores: [(49, 0.044574370607733727), (3, 0.045465648639947176), (14, 0.046705327928066254), (45, 0.04710655985400081), (44, 0.050837081391364336), (51, 0.05192138720303774), (48, 0.05497316876426339), (17, 0.055909967981278896), (46, 0.05599216651171446), (52, 0.06420023459941149), (40, 0.06424009799957275), (20, 0.06536473799496889), (37, 0.06810576654970646), (21, 0.07911545410752296), (0, 0.0812369529157877), (19, 0.08454426284879446), (15, 0.09183643292635679), (6, 0.09990754816681147), (16, 0.09998374711722136), (4, 0.1050726417452097), (10, 0.11294187046587467), (7, 0.11513296980410814), (11, 0.1176622649654746), (13, 0.12450084462761879), (8, 0.126074624247849), (12, 0.1409972794353962), (9, 0.1511133834719658), (36, 0.6063389852643013), (18, 0.6250857934355736), (53, 1.2579957395792007)]
computing accuracy for after removing block 49 . block score: 0.044574370607733727
removed block 49 current accuracy 0.9336 loss from initial  0.06640000000000001
since last training loss: 0.02860000000000007 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 3, with score 0.045466. All blocks and scores: [(3, 0.04546564910560846), (14, 0.046705329325050116), (45, 0.04710656078532338), (44, 0.050837081391364336), (48, 0.05497317016124725), (17, 0.055909966584295034), (46, 0.05599216651171446), (51, 0.05721648735925555), (40, 0.06424009799957275), (20, 0.06536473799496889), (37, 0.06810576654970646), (52, 0.06875249743461609), (21, 0.07911545317620039), (0, 0.08123695384711027), (19, 0.08454426564276218), (15, 0.09183643199503422), (6, 0.09990755002945662), (16, 0.0999837489798665), (4, 0.1050726417452097), (10, 0.11294187232851982), (7, 0.11513297166675329), (11, 0.11766226030886173), (13, 0.12450084276497364), (8, 0.1260746233165264), (12, 0.14099728129804134), (9, 0.1511133760213852), (36, 0.6063389852643013), (18, 0.6250858008861542), (53, 1.3487642258405685)]
computing accuracy for after removing block 3 . block score: 0.04546564910560846
removed block 3 current accuracy 0.9296 loss from initial  0.07040000000000002
since last training loss: 0.03260000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 14, with score 0.045910. All blocks and scores: [(14, 0.04590978706255555), (45, 0.04669359792023897), (44, 0.050465451553463936), (48, 0.05458596907556057), (46, 0.05524780182167888), (17, 0.05575360218062997), (51, 0.056409855373203754), (20, 0.06399975065141916), (40, 0.06570651847869158), (37, 0.06832954566925764), (52, 0.06840837839990854), (21, 0.07735824771225452), (0, 0.08123695105314255), (19, 0.08280987199395895), (15, 0.09021980687975883), (16, 0.09663295466452837), (4, 0.09958005789667368), (6, 0.09993805922567844), (7, 0.10924239736050367), (11, 0.11256125755608082), (8, 0.12070042174309492), (10, 0.12113182246685028), (13, 0.1230885861441493), (12, 0.13608205690979958), (9, 0.14948414452373981), (36, 0.6029719635844231), (18, 0.6239076480269432), (53, 1.3572379052639008)]
computing accuracy for after removing block 14 . block score: 0.04590978706255555
removed block 14 current accuracy 0.9268 loss from initial  0.07320000000000004
since last training loss: 0.0354000000000001 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 45, with score 0.047864. All blocks and scores: [(45, 0.047863724175840616), (44, 0.05408468842506409), (51, 0.05477118585258722), (48, 0.05515279481187463), (46, 0.055448382161557674), (17, 0.05843813391402364), (20, 0.06437289156019688), (40, 0.0645982027053833), (37, 0.06823176331818104), (52, 0.06936525646597147), (21, 0.07556743174791336), (0, 0.08123695105314255), (19, 0.08888614550232887), (15, 0.0942728566005826), (16, 0.09841415379196405), (4, 0.09958005975931883), (6, 0.09993805643171072), (7, 0.1092424001544714), (11, 0.11256126221269369), (8, 0.12070041801780462), (10, 0.12113182619214058), (13, 0.123088582418859), (12, 0.13608206436038017), (9, 0.14948414266109467), (36, 0.597076877951622), (18, 0.6154773607850075), (53, 1.3449773639440536)]
computing accuracy for after removing block 45 . block score: 0.047863724175840616
removed block 45 current accuracy 0.909 loss from initial  0.09099999999999997
since last training loss: 0.053200000000000025 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 44, with score 0.054085. All blocks and scores: [(44, 0.05408468749374151), (51, 0.05414685932919383), (48, 0.05618157749995589), (17, 0.05843813577666879), (46, 0.05925465142354369), (20, 0.06437289249151945), (40, 0.0645982027053833), (37, 0.06823176331818104), (52, 0.07047419250011444), (21, 0.07556743081659079), (0, 0.08123695477843285), (19, 0.08888613991439342), (15, 0.09427285473793745), (16, 0.09841415006667376), (4, 0.0995800606906414), (6, 0.09993805922567844), (7, 0.10924239829182625), (11, 0.11256125755608082), (8, 0.12070041988044977), (10, 0.12113182060420513), (13, 0.12308858800679445), (12, 0.13608206063508987), (9, 0.14948414638638496), (36, 0.5970768630504608), (18, 0.6154773533344269), (53, 1.403521716594696)]
computing accuracy for after removing block 44 . block score: 0.05408468749374151
removed block 44 current accuracy 0.8706 loss from initial  0.12939999999999996
since last training loss: 0.09160000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.052074. All blocks and scores: [(51, 0.05207400303333998), (48, 0.05644067097455263), (17, 0.058438136242330074), (46, 0.06314840819686651), (20, 0.06437289156019688), (40, 0.06459820084273815), (37, 0.06823176611214876), (52, 0.07140219770371914), (21, 0.07556742988526821), (0, 0.08123695384711027), (19, 0.08888614177703857), (15, 0.0942728566005826), (16, 0.0984141482040286), (4, 0.09958005975931883), (6, 0.0999380573630333), (7, 0.10924239922314882), (11, 0.11256126128137112), (8, 0.12070042081177235), (10, 0.12113182060420513), (13, 0.12308859452605247), (12, 0.13608206063508987), (9, 0.14948414266109467), (36, 0.5970768630504608), (18, 0.6154773682355881), (53, 1.496897742152214)]
computing accuracy for after removing block 51 . block score: 0.05207400303333998
removed block 51 current accuracy 0.8134 loss from initial  0.1866
since last training loss: 0.14880000000000004 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 48, with score 0.056441. All blocks and scores: [(48, 0.056440670508891344), (17, 0.05843813484534621), (46, 0.06314840726554394), (20, 0.06437289342284203), (40, 0.06459820177406073), (37, 0.06823176611214876), (21, 0.07556742988526821), (0, 0.08123695384711027), (52, 0.08223886229097843), (19, 0.088886140845716), (15, 0.09427285939455032), (16, 0.0984141519293189), (4, 0.09958005975931883), (6, 0.0999380573630333), (7, 0.10924239549785852), (11, 0.11256126128137112), (8, 0.12070042081177235), (10, 0.12113181967288256), (13, 0.12308858335018158), (12, 0.13608205877244473), (9, 0.14948414266109467), (36, 0.5970768705010414), (18, 0.6154773682355881), (53, 1.8968593627214432)]
computing accuracy for after removing block 48 . block score: 0.056440670508891344
removed block 48 current accuracy 0.727 loss from initial  0.273
since last training loss: 0.23520000000000008 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.058438. All blocks and scores: [(17, 0.058438134379684925), (46, 0.06314840726554394), (20, 0.06437289342284203), (40, 0.06459820363670588), (37, 0.06823176238685846), (21, 0.07556743081659079), (0, 0.08123695198446512), (52, 0.08735826425254345), (19, 0.08888614363968372), (15, 0.09427285473793745), (16, 0.09841415099799633), (4, 0.0995800606906414), (6, 0.0999380573630333), (7, 0.10924239456653595), (11, 0.11256126035004854), (8, 0.12070041615515947), (10, 0.1211318215355277), (13, 0.1230885898694396), (12, 0.13608205318450928), (9, 0.14948414266109467), (36, 0.5970768854022026), (18, 0.6154773607850075), (53, 2.168969690799713)]
computing accuracy for after removing block 17 . block score: 0.058438134379684925
removed block 17 current accuracy 0.7182 loss from initial  0.28180000000000005
since last training loss: 0.2440000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 20, with score 0.060713. All blocks and scores: [(20, 0.06071288883686066), (40, 0.060847554821521044), (46, 0.06184204062446952), (37, 0.06559303309768438), (21, 0.07034207787364721), (0, 0.08123695105314255), (52, 0.08659744635224342), (19, 0.08866841159760952), (15, 0.09427285473793745), (16, 0.09841415099799633), (4, 0.0995800606906414), (6, 0.09993805829435587), (7, 0.1092423964291811), (11, 0.11256125848740339), (8, 0.12070041801780462), (10, 0.12113182246685028), (13, 0.12308858707547188), (12, 0.13608206063508987), (9, 0.14948414266109467), (36, 0.5662550181150436), (18, 0.5954305455088615), (53, 2.155880182981491)]
computing accuracy for after removing block 20 . block score: 0.06071288883686066
removed block 20 current accuracy 0.6804 loss from initial  0.3196
training start
training epoch 0 val accuracy 0.8066 topk_dict {'top1': 0.8066} is_best True lr [0.1]
training epoch 1 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.1]
training epoch 2 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best True lr [0.1]
training epoch 3 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 4 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 5 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.1]
training epoch 6 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 8 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 9 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.081328. All blocks and scores: [(37, 0.0813281424343586), (40, 0.08302391413599253), (52, 0.09163881372660398), (0, 0.0947752371430397), (46, 0.09728865139186382), (15, 0.1110075693577528), (21, 0.11382997129112482), (19, 0.121091746725142), (6, 0.1287402231246233), (10, 0.13366840593516827), (16, 0.13442017696797848), (7, 0.1375631894916296), (8, 0.14357649348676205), (11, 0.15242604352533817), (13, 0.1625099889934063), (4, 0.16898721642792225), (9, 0.17052646167576313), (12, 0.18496357649564743), (36, 0.4897508844733238), (18, 0.6304535940289497), (53, 1.2358243614435196)]
computing accuracy for after removing block 37 . block score: 0.0813281424343586
removed block 37 current accuracy 0.9344 loss from initial  0.06559999999999999
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 52, with score 0.092298. All blocks and scores: [(52, 0.09229802712798119), (0, 0.09477524179965258), (40, 0.10288921929895878), (46, 0.10466945078223944), (15, 0.11100756842643023), (21, 0.11382997687906027), (19, 0.12109174765646458), (6, 0.12874022498726845), (10, 0.13366841152310371), (16, 0.13442018255591393), (7, 0.13756318762898445), (8, 0.14357649348676205), (11, 0.15242604166269302), (13, 0.16250998713076115), (4, 0.16898721642792225), (9, 0.17052645981311798), (12, 0.18496357835829258), (36, 0.4897508844733238), (18, 0.6304535791277885), (53, 1.241301879286766)]
computing accuracy for after removing block 52 . block score: 0.09229802712798119
removed block 52 current accuracy 0.8506 loss from initial  0.14939999999999998
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 0, with score 0.094775. All blocks and scores: [(0, 0.09477523807436228), (40, 0.10288922395557165), (46, 0.10466944891959429), (15, 0.11100756656378508), (21, 0.1138299759477377), (19, 0.121091746725142), (6, 0.12874022498726845), (10, 0.13366840593516827), (16, 0.13442018069326878), (7, 0.1375631894916296), (8, 0.1435764878988266), (11, 0.15242603793740273), (13, 0.1625099927186966), (4, 0.1689872220158577), (9, 0.17052646353840828), (12, 0.18496358022093773), (36, 0.4897508844733238), (18, 0.6304535642266273), (53, 1.13049978017807)]
computing accuracy for after removing block 0 . block score: 0.09477523807436228
removed block 0 current accuracy 0.8414 loss from initial  0.15859999999999996
since last training loss: 0.10499999999999998 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 40, with score 0.098753. All blocks and scores: [(40, 0.09875335078686476), (46, 0.10087084956467152), (15, 0.10513372719287872), (21, 0.10981153510510921), (19, 0.11939148046076298), (16, 0.1262618750333786), (10, 0.13051548786461353), (6, 0.13270504586398602), (7, 0.13774427212774754), (11, 0.14334094151854515), (8, 0.14425834640860558), (13, 0.15898066945374012), (9, 0.1617134902626276), (4, 0.1783621869981289), (12, 0.17868451960384846), (36, 0.46693800389766693), (18, 0.6075399816036224), (53, 1.0529918819665909)]
computing accuracy for after removing block 40 . block score: 0.09875335078686476
removed block 40 current accuracy 0.741 loss from initial  0.259
since last training loss: 0.20540000000000003 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 15, with score 0.105134. All blocks and scores: [(15, 0.10513372533023357), (21, 0.10981154069304466), (19, 0.1193914795294404), (16, 0.1262618750333786), (10, 0.13051549158990383), (6, 0.13270504400134087), (7, 0.1377442702651024), (46, 0.13843209110200405), (11, 0.14334094524383545), (8, 0.14425835199654102), (13, 0.15898066945374012), (9, 0.16171348839998245), (4, 0.17836218513548374), (12, 0.17868451960384846), (36, 0.46693800762295723), (18, 0.607539989054203), (53, 1.3563125133514404)]
computing accuracy for after removing block 15 . block score: 0.10513372533023357
removed block 15 current accuracy 0.7276 loss from initial  0.2724
since last training loss: 0.2188 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 21, with score 0.096036. All blocks and scores: [(21, 0.09603642672300339), (19, 0.12626258004456758), (10, 0.13051549158990383), (16, 0.1320863850414753), (6, 0.13270504027605057), (7, 0.1377442702651024), (46, 0.13799493573606014), (11, 0.1433409471064806), (8, 0.14425835199654102), (13, 0.15898066945374012), (9, 0.1617134902626276), (4, 0.17836218513548374), (12, 0.1786845214664936), (36, 0.4586205780506134), (18, 0.5788792669773102), (53, 1.2228594273328781)]
computing accuracy for after removing block 21 . block score: 0.09603642672300339
removed block 21 current accuracy 0.6496 loss from initial  0.35040000000000004
since last training loss: 0.29680000000000006 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 19, with score 0.126263. All blocks and scores: [(19, 0.12626258004456758), (10, 0.13051548972725868), (16, 0.132086381316185), (6, 0.13270504027605057), (7, 0.1377442702651024), (46, 0.1400334443897009), (11, 0.14334094151854515), (8, 0.14425835013389587), (13, 0.15898066945374012), (9, 0.1617134902626276), (4, 0.17836218513548374), (12, 0.1786845177412033), (36, 0.46251970529556274), (18, 0.5788792744278908), (53, 1.1815884411334991)]
computing accuracy for after removing block 19 . block score: 0.12626258004456758
removed block 19 current accuracy 0.5368 loss from initial  0.46319999999999995
since last training loss: 0.40959999999999996 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 10, with score 0.130515. All blocks and scores: [(10, 0.13051548600196838), (16, 0.13208637945353985), (6, 0.13270504213869572), (7, 0.1377442702651024), (11, 0.14334094524383545), (8, 0.14425834454596043), (46, 0.15312367118895054), (13, 0.15898066572844982), (9, 0.1617134902626276), (4, 0.17836218141019344), (12, 0.17868451960384846), (36, 0.5146737769246101), (18, 0.578879289329052), (53, 1.3497025221586227)]
computing accuracy for after removing block 10 . block score: 0.13051548600196838
removed block 10 current accuracy 0.4102 loss from initial  0.5898
since last training loss: 0.5362 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 16, with score 0.108185. All blocks and scores: [(16, 0.10818539746105671), (13, 0.12548868730664253), (6, 0.13270504213869572), (11, 0.13389713130891323), (46, 0.13473118655383587), (7, 0.1377442702651024), (8, 0.14425834454596043), (12, 0.15359459817409515), (9, 0.1617134902626276), (4, 0.17836218513548374), (36, 0.48567042499780655), (18, 0.5359170883893967), (53, 1.5531118363142014)]
computing accuracy for after removing block 16 . block score: 0.10818539746105671
removed block 16 current accuracy 0.3986 loss from initial  0.6013999999999999
since last training loss: 0.5478000000000001 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.125489. All blocks and scores: [(13, 0.12548868730664253), (6, 0.13270504213869572), (11, 0.13389712944626808), (7, 0.1377442702651024), (46, 0.13877368532121181), (8, 0.14425834454596043), (12, 0.1535946000367403), (9, 0.16171348467469215), (4, 0.1783621832728386), (36, 0.47906315326690674), (18, 0.5205380469560623), (53, 1.3523387610912323)]
computing accuracy for after removing block 13 . block score: 0.12548868730664253
removed block 13 current accuracy 0.3338 loss from initial  0.6662
since last training loss: 0.6126 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 6, with score 0.132705. All blocks and scores: [(6, 0.13270503841340542), (11, 0.13389713503420353), (7, 0.1377442702651024), (8, 0.14425835013389587), (46, 0.14642153307795525), (12, 0.15359459817409515), (9, 0.16171348467469215), (4, 0.17836218513548374), (36, 0.4915083013474941), (18, 0.5212121680378914), (53, 1.2271986454725266)]
computing accuracy for after removing block 6 . block score: 0.13270503841340542
removed block 6 current accuracy 0.2378 loss from initial  0.7622
since last training loss: 0.7086 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 46, with score 0.127185. All blocks and scores: [(46, 0.12718506902456284), (11, 0.1353152822703123), (7, 0.14328580163419247), (8, 0.14645383320748806), (12, 0.14770019240677357), (9, 0.1481675449758768), (4, 0.17836218886077404), (18, 0.4867217093706131), (36, 0.5122538954019547), (53, 1.6483089923858643)]
computing accuracy for after removing block 46 . block score: 0.12718506902456284
removed block 46 current accuracy 0.162 loss from initial  0.838
training start
training epoch 0 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.1]
training epoch 1 val accuracy 0.832 topk_dict {'top1': 0.832} is_best True lr [0.1]
training epoch 2 val accuracy 0.7766 topk_dict {'top1': 0.7766} is_best False lr [0.1]
training epoch 3 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.1]
training epoch 4 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best False lr [0.1]
training epoch 5 val accuracy 0.8294 topk_dict {'top1': 0.8294} is_best False lr [0.1]
training epoch 6 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 7 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best True lr [0.1]
training epoch 8 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 9 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 10 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.901800)
finished training. finished 50 epochs. accuracy 0.9018 topk_dict {'top1': 0.9018}
