start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101574242115), (24, 0.006592476973310113), (25, 0.007601776102092117), (21, 0.008612961508333683), (27, 0.008965069777332246), (5, 0.009674609638750553), (23, 0.011229233001358807), (19, 0.011454988270998001), (35, 0.01151972881052643), (32, 0.013281174469739199), (29, 0.014178814948536456), (20, 0.0145084384130314), (31, 0.01461589417885989), (3, 0.014681299915537238), (26, 0.014724895008839667), (30, 0.014915360836312175), (7, 0.015097477938979864), (28, 0.016234831418842077), (37, 0.018546361941844225), (33, 0.021617853082716465), (39, 0.021876288345083594), (6, 0.022251417161896825), (50, 0.022445981623604894), (34, 0.022565887309610844), (49, 0.022602886660024524), (8, 0.02347445604391396), (38, 0.02385126263834536), (41, 0.024523034691810608), (40, 0.024661970790475607), (1, 0.025388095760717988), (46, 0.026244731387123466), (45, 0.026683186879381537), (48, 0.026970998384058475), (44, 0.028061730787158012), (51, 0.028739838860929012), (42, 0.02876956621184945), (43, 0.03079548547975719), (47, 0.031195558607578278), (0, 0.03271650895476341), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.04341263743117452), (16, 0.0443306602537632), (12, 0.04965688567608595), (4, 0.05115430895239115), (11, 0.05217862268909812), (52, 0.05327532812952995), (2, 0.05518383393064141), (10, 0.060167096555233), (9, 0.08553026523441076), (17, 0.18986637890338898), (18, 0.2766866125166416), (36, 0.2898172102868557), (53, 0.8816948309540749)]
computing accuracy for after removing block 22 . block score: 0.005787101574242115
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.006946946494281292), (25, 0.007925601676106453), (21, 0.008612961508333683), (27, 0.0088845418067649), (5, 0.009674609522335231), (19, 0.011454987805336714), (23, 0.01149947417434305), (35, 0.011587338522076607), (32, 0.013315335847437382), (29, 0.014122493215836585), (20, 0.0145084384130314), (31, 0.014535366324707866), (3, 0.014681299799121916), (30, 0.014953502104617655), (7, 0.015097477938979864), (26, 0.015386729501187801), (28, 0.016657372005283833), (37, 0.018698561936616898), (33, 0.021836149971932173), (6, 0.022251416696235538), (39, 0.022278542863205075), (50, 0.022396721644327044), (34, 0.022579425247386098), (49, 0.022588348714634776), (8, 0.02347445674240589), (38, 0.024010849185287952), (41, 0.02471063449047506), (40, 0.024832447059452534), (1, 0.025388095527887344), (46, 0.026328841224312782), (45, 0.02651964919641614), (48, 0.02686534752137959), (51, 0.028594729490578175), (44, 0.028690784238278866), (42, 0.028934543021023273), (47, 0.03059899155050516), (43, 0.030889178160578012), (0, 0.03271650895476341), (13, 0.036019420716911554), (15, 0.04315127804875374), (14, 0.04341263556852937), (16, 0.04433066118508577), (12, 0.049656884744763374), (4, 0.051154309418052435), (11, 0.05217862268909812), (52, 0.052744821179658175), (2, 0.05518383299931884), (10, 0.06016709702089429), (9, 0.08553026523441076), (17, 0.18986639007925987), (18, 0.2766866199672222), (36, 0.29418328776955605), (53, 0.8765672668814659)]
computing accuracy for after removing block 24 . block score: 0.006946946494281292
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.00796479161363095), (27, 0.008502036915160716), (21, 0.008612961159087718), (5, 0.009674609755165875), (35, 0.01112444803584367), (19, 0.011454988038167357), (23, 0.011499473941512406), (32, 0.01266787585336715), (29, 0.013618955039419234), (31, 0.014255343819968402), (30, 0.014440409140661359), (20, 0.014508438762277365), (3, 0.014681299915537238), (7, 0.015097478055395186), (26, 0.015341690741479397), (28, 0.016541524790227413), (37, 0.018848978215828538), (34, 0.02149180043488741), (33, 0.02174661122262478), (50, 0.02214478445239365), (6, 0.022251417161896825), (49, 0.022573675960302353), (39, 0.022594625828787684), (8, 0.023474456276744604), (38, 0.023919350234791636), (41, 0.02473141113296151), (40, 0.025212144013494253), (1, 0.025388095527887344), (45, 0.026285272324457765), (46, 0.02629989478737116), (48, 0.02681394899263978), (51, 0.028448980068787932), (44, 0.028867240995168686), (42, 0.028876986587420106), (47, 0.030472575454041362), (43, 0.030837931903079152), (0, 0.03271650895476341), (13, 0.036019418854266405), (15, 0.04315127758309245), (14, 0.043412636034190655), (16, 0.04433066118508577), (12, 0.04965688334777951), (4, 0.051154307555407286), (11, 0.05217862082645297), (52, 0.05221219314262271), (2, 0.05518383393064141), (10, 0.06016709841787815), (9, 0.08553026709705591), (17, 0.18986638449132442), (18, 0.2766866236925125), (36, 0.2956240698695183), (53, 0.8761104568839073)]
computing accuracy for after removing block 25 . block score: 0.00796479161363095
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.00820748379919678), (21, 0.008612961159087718), (5, 0.009674609522335231), (35, 0.010663896333426237), (19, 0.01145498757250607), (23, 0.011499474523589015), (32, 0.012014233157970011), (29, 0.012787628802470863), (31, 0.013865676242858171), (30, 0.013961306540295482), (20, 0.014508438645862043), (3, 0.014681299799121916), (26, 0.01491980126593262), (7, 0.015097478171810508), (28, 0.015723921591416), (37, 0.018793188268318772), (34, 0.02036181022413075), (33, 0.021328614791855216), (50, 0.021633303025737405), (49, 0.022232346003875136), (6, 0.02225141692906618), (39, 0.0225284188054502), (8, 0.02347445674240589), (38, 0.02384312474168837), (41, 0.02440304192714393), (40, 0.02525408356450498), (1, 0.025388095527887344), (45, 0.025693233590573072), (46, 0.02590800402686), (48, 0.026390639133751392), (51, 0.027748763095587492), (42, 0.02847559191286564), (44, 0.028856615535914898), (47, 0.029799401527270675), (43, 0.03020182903856039), (0, 0.032716508489102125), (13, 0.036019420716911554), (15, 0.04315127804875374), (14, 0.04341263556852937), (16, 0.044330660719424486), (12, 0.049656884744763374), (52, 0.050796682480722666), (4, 0.051154307555407286), (11, 0.05217862222343683), (2, 0.05518383486196399), (10, 0.06016709841787815), (9, 0.08553026523441076), (17, 0.18986638449132442), (18, 0.2766866162419319), (36, 0.29478897526860237), (53, 0.8695808798074722)]
computing accuracy for after removing block 27 . block score: 0.00820748379919678
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.008612961391918361), (5, 0.009674609522335231), (35, 0.010487185092642903), (19, 0.011454987921752036), (23, 0.011499473941512406), (32, 0.011747056501917541), (29, 0.012900045374408364), (31, 0.01373862533364445), (30, 0.013831986230798066), (20, 0.014508438645862043), (3, 0.014681300264783204), (26, 0.014919801033101976), (7, 0.015097477822564542), (28, 0.016265674028545618), (37, 0.018666349351406097), (34, 0.02014545421116054), (50, 0.021326794056221843), (33, 0.021582857705652714), (49, 0.0221185649279505), (6, 0.022251416696235538), (39, 0.022289567161351442), (8, 0.023474455811083317), (38, 0.02361668017692864), (41, 0.024516038363799453), (40, 0.02536682435311377), (45, 0.02536774007603526), (1, 0.025388095062226057), (46, 0.025604828726500273), (48, 0.02612509368918836), (51, 0.027203566394746304), (42, 0.02829334558919072), (44, 0.02932620490901172), (47, 0.029351704753935337), (43, 0.030030403519049287), (0, 0.032716508489102125), (13, 0.036019418854266405), (15, 0.043151278514415026), (14, 0.04341263696551323), (16, 0.04433065885677934), (12, 0.04965688334777951), (52, 0.05003825481981039), (4, 0.051154307555407286), (11, 0.052178623620420694), (2, 0.055183835327625275), (10, 0.06016709841787815), (9, 0.08553026616573334), (17, 0.18986638262867928), (18, 0.2766866236925125), (36, 0.29525747150182724), (53, 0.8683891147375107)]
computing accuracy for after removing block 21 . block score: 0.008612961391918361
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.00967460940591991), (35, 0.010542471893131733), (19, 0.011454987688921392), (23, 0.011545549961738288), (32, 0.011696714907884598), (29, 0.013034458039328456), (30, 0.01354199240449816), (31, 0.013661347213201225), (20, 0.014508438645862043), (26, 0.014561281888745725), (3, 0.01468130003195256), (7, 0.01509747828822583), (28, 0.016272223321720958), (37, 0.018855378031730652), (34, 0.020170693984255195), (50, 0.02119536278769374), (33, 0.021736357361078262), (49, 0.022025790996849537), (6, 0.022251416463404894), (39, 0.022593395318835974), (8, 0.02347445604391396), (38, 0.023794722510501742), (41, 0.024486313806846738), (45, 0.025174086214974523), (1, 0.025388095527887344), (46, 0.02559636766090989), (40, 0.02570292493328452), (48, 0.025935829151421785), (51, 0.026903112418949604), (42, 0.028371039079502225), (47, 0.029131257673725486), (44, 0.02926316251978278), (43, 0.030276518780738115), (0, 0.032716508489102125), (13, 0.03601941978558898), (15, 0.043151278514415026), (14, 0.04341263696551323), (16, 0.044330659322440624), (52, 0.04949297895655036), (12, 0.04965688427910209), (4, 0.05115430802106857), (11, 0.05217862222343683), (2, 0.05518383393064141), (10, 0.060167097486555576), (9, 0.08553026523441076), (17, 0.18986638262867928), (18, 0.2766866236925125), (36, 0.2977275922894478), (53, 0.8672097623348236)]
computing accuracy for after removing block 5 . block score: 0.00967460940591991
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010497. All blocks and scores: [(35, 0.010497342213056982), (19, 0.011364333564415574), (23, 0.011454000836238265), (32, 0.011731750215403736), (29, 0.012978376355022192), (30, 0.01356180151924491), (31, 0.013812810997478664), (20, 0.01402826712001115), (26, 0.014234645059332252), (3, 0.014681299799121916), (28, 0.016409628791734576), (37, 0.019115549745038152), (7, 0.019321492174640298), (34, 0.02049453160725534), (50, 0.021026555681601167), (33, 0.021409298526123166), (49, 0.022096335655078292), (39, 0.022289573680609465), (38, 0.023183461045846343), (41, 0.024258682038635015), (6, 0.02500285836867988), (8, 0.025038712192326784), (45, 0.025084451073780656), (46, 0.025368365459144115), (1, 0.025388094829395413), (48, 0.02579234540462494), (40, 0.026035186601802707), (51, 0.026855435920879245), (42, 0.028462824877351522), (44, 0.02884995099157095), (47, 0.02911300165578723), (43, 0.03023843909613788), (0, 0.03271650895476341), (13, 0.0360612478107214), (15, 0.04305668035522103), (16, 0.04365198872983456), (14, 0.043659396935254335), (52, 0.0493767405860126), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.05406309058889747), (2, 0.055183832067996264), (10, 0.062402027659118176), (9, 0.08971724100410938), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.2957078851759434), (53, 0.8705098405480385)]
computing accuracy for after removing block 35 . block score: 0.010497342213056982
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011364. All blocks and scores: [(19, 0.011364333680830896), (23, 0.011454000836238265), (32, 0.01173174986615777), (29, 0.012978376122191548), (30, 0.013561801635660231), (31, 0.013812811230309308), (20, 0.014028267469257116), (26, 0.01423464494291693), (3, 0.01468130003195256), (28, 0.01640962832607329), (37, 0.018872639164328575), (7, 0.01932149240747094), (34, 0.020494531141594052), (50, 0.02102121920324862), (33, 0.021409297361969948), (49, 0.021970301866531372), (39, 0.022241035709157586), (38, 0.022285724757239223), (41, 0.02406265353783965), (45, 0.024892093613743782), (46, 0.024894545320421457), (6, 0.025002859067171812), (8, 0.025038711726665497), (1, 0.025388095760717988), (48, 0.025495541281998158), (40, 0.0256039013620466), (51, 0.026838497258722782), (42, 0.028305645566433668), (44, 0.028504313668236136), (47, 0.028528794646263123), (43, 0.029594503110274673), (0, 0.03271650802344084), (13, 0.0360612478107214), (15, 0.04305668082088232), (16, 0.04365198966115713), (14, 0.04365939786657691), (52, 0.04860273515805602), (4, 0.05115430848672986), (12, 0.051509722135961056), (11, 0.05406309012323618), (2, 0.0551838343963027), (10, 0.062402027659118176), (9, 0.08971724472939968), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.29528703913092613), (53, 0.8746363073587418)]
computing accuracy for after removing block 19 . block score: 0.011364333680830896
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.011435. All blocks and scores: [(32, 0.011435218155384064), (23, 0.011625511338934302), (29, 0.013017931254580617), (31, 0.013358428492210805), (30, 0.013481265166774392), (26, 0.013551717158406973), (20, 0.014475058997049928), (3, 0.014681299799121916), (28, 0.016491984948515892), (37, 0.018982867943122983), (7, 0.019321492640301585), (34, 0.020425984635949135), (50, 0.020725763402879238), (33, 0.02151042129844427), (49, 0.021559856133535504), (39, 0.02184294955804944), (38, 0.02186038438230753), (41, 0.02357930806465447), (46, 0.024237519595772028), (45, 0.02440538303926587), (48, 0.02496637706644833), (6, 0.025002859300002456), (8, 0.025038712192326784), (1, 0.0253880952950567), (40, 0.025583632523193955), (51, 0.02626500208862126), (44, 0.027775868074968457), (42, 0.027991156792268157), (47, 0.028424981515854597), (43, 0.029187678592279553), (0, 0.0327165094204247), (13, 0.036061248276382685), (15, 0.04305668035522103), (16, 0.04365198826417327), (14, 0.04365939926356077), (52, 0.04771037260070443), (4, 0.051154307555407286), (12, 0.05150972306728363), (11, 0.05406309012323618), (2, 0.05518383393064141), (10, 0.062402027659118176), (9, 0.0897172437980771), (17, 0.18636954575777054), (18, 0.27677176520228386), (36, 0.28799719363451004), (53, 0.8807788342237473)]
computing accuracy for after removing block 32 . block score: 0.011435218155384064
removed block 32 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.011626. All blocks and scores: [(23, 0.011625511688180268), (29, 0.013017931254580617), (31, 0.013358428608626127), (30, 0.013481264701113105), (26, 0.013551716809161007), (20, 0.014475058997049928), (3, 0.014681299682706594), (28, 0.01649198471568525), (37, 0.018812528578564525), (7, 0.019321492640301585), (34, 0.020461332984268665), (50, 0.02082308242097497), (49, 0.021814766339957714), (38, 0.022025865269824862), (39, 0.022391145583242178), (33, 0.0224131743889302), (41, 0.024000401375815272), (46, 0.024349761195480824), (45, 0.024428083561360836), (6, 0.025002859300002456), (8, 0.025038711726665497), (1, 0.025388095062226057), (48, 0.025586012518033385), (51, 0.026234304765239358), (40, 0.026594599010422826), (42, 0.028401524294167757), (47, 0.02876698551699519), (44, 0.0288279817905277), (43, 0.02949392911978066), (0, 0.032716508489102125), (13, 0.036061248276382685), (15, 0.04305667895823717), (16, 0.04365198872983456), (14, 0.04365939786657691), (52, 0.04727818816900253), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.05406309058889747), (2, 0.055183835327625275), (10, 0.06240202719345689), (9, 0.08971724566072226), (17, 0.18636955320835114), (18, 0.27677176892757416), (36, 0.30095571279525757), (53, 0.8827565461397171)]
computing accuracy for after removing block 23 . block score: 0.011625511688180268
removed block 23 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.012718. All blocks and scores: [(26, 0.012718255980871618), (31, 0.013059877906925976), (30, 0.013245980022475123), (29, 0.013515455997548997), (20, 0.014475058880634606), (3, 0.014681299915537238), (28, 0.01654111221432686), (37, 0.018968473887071013), (7, 0.019321492174640298), (50, 0.020513229770585895), (34, 0.020617329981178045), (49, 0.021386134903877974), (38, 0.02212540782056749), (39, 0.022963948780670762), (33, 0.023589920718222857), (41, 0.023973098257556558), (46, 0.024251093855127692), (45, 0.02427463629283011), (6, 0.025002859300002456), (8, 0.025038711493834853), (48, 0.025167004903778434), (1, 0.025388095760717988), (51, 0.025717933662235737), (40, 0.026828006841242313), (47, 0.028098624665290117), (44, 0.028160852380096912), (42, 0.02847823267802596), (43, 0.029657084494829178), (0, 0.03271650895476341), (13, 0.0360612478107214), (15, 0.04305667942389846), (16, 0.04365198779851198), (14, 0.0436593983322382), (52, 0.04578007152304053), (4, 0.05115430895239115), (12, 0.05150972167029977), (11, 0.05406309058889747), (2, 0.05518383393064141), (10, 0.06240202905610204), (9, 0.08971724286675453), (17, 0.18636954948306084), (18, 0.27677176520228386), (36, 0.3048461228609085), (53, 0.883067861199379)]
computing accuracy for after removing block 26 . block score: 0.012718255980871618
removed block 26 current accuracy 0.9864 loss from initial  0.013599999999999945
training start
training epoch 0 val accuracy 0.7808 topk_dict {'top1': 0.7808} is_best False lr [0.1]
training epoch 1 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 2 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 3 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 5 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 6 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 7 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 8 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 9 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 10 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.986400)
finished training. finished 50 epochs. accuracy 0.9864 topk_dict {'top1': 0.9864}
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.012818. All blocks and scores: [(31, 0.012817569193430245), (30, 0.013015841715969145), (29, 0.013636851799674332), (20, 0.014475059229880571), (3, 0.014681299915537238), (37, 0.018351267790421844), (28, 0.018360018962994218), (34, 0.019276465522125363), (7, 0.01932149240747094), (50, 0.020073064602911472), (49, 0.020938759669661522), (38, 0.021544620161876082), (39, 0.022596267284825444), (46, 0.023219265742227435), (45, 0.023255802458152175), (41, 0.023414231836795807), (33, 0.023838804801926017), (48, 0.024398323148489), (51, 0.02474273950792849), (6, 0.025002859300002456), (8, 0.025038711493834853), (1, 0.0253880952950567), (40, 0.026659835129976273), (47, 0.02733475877903402), (42, 0.02795390016399324), (44, 0.028050450840964913), (43, 0.028797091217711568), (0, 0.03271650802344084), (13, 0.03606124874204397), (15, 0.04305667942389846), (52, 0.04358252789825201), (16, 0.043651989195495844), (14, 0.04365939740091562), (4, 0.05115430848672986), (12, 0.05150972120463848), (11, 0.05406308965757489), (2, 0.05518383393064141), (10, 0.062402027659118176), (9, 0.0897172437980771), (17, 0.1863695476204157), (18, 0.27677176520228386), (36, 0.2992885261774063), (53, 0.8849738091230392)]
computing accuracy for after removing block 31 . block score: 0.012817569193430245
removed block 31 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 30, with score 0.013016. All blocks and scores: [(30, 0.013015841715969145), (29, 0.013636851566843688), (20, 0.014475058997049928), (3, 0.014681300148367882), (37, 0.018212777329608798), (28, 0.018360018730163574), (7, 0.01932149240747094), (34, 0.019669849192723632), (50, 0.020156640093773603), (49, 0.021141210105270147), (38, 0.021776929730549455), (39, 0.023024214198812842), (45, 0.023322134278714657), (46, 0.023720957105979323), (41, 0.02372454898431897), (51, 0.02464952226728201), (48, 0.02475730120204389), (6, 0.025002859067171812), (8, 0.025038711726665497), (1, 0.025388095527887344), (33, 0.026504344772547483), (47, 0.027367586735635996), (40, 0.0274654901586473), (42, 0.02804913488216698), (44, 0.028787461575120687), (43, 0.028967604972422123), (0, 0.03271650895476341), (13, 0.03606124920770526), (15, 0.04305668082088232), (52, 0.04324783757328987), (16, 0.043651989195495844), (14, 0.0436593983322382), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.05406309384852648), (2, 0.055183835327625275), (10, 0.062402027659118176), (9, 0.08971724286675453), (17, 0.18636954948306084), (18, 0.27677176520228386), (36, 0.31426598876714706), (53, 0.8895440325140953)]
computing accuracy for after removing block 30 . block score: 0.013015841715969145
removed block 30 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.013637. All blocks and scores: [(29, 0.01363685168325901), (20, 0.014475059229880571), (3, 0.014681300264783204), (37, 0.017944879131391644), (28, 0.018360019428655505), (7, 0.01932149287313223), (34, 0.019725410267710686), (50, 0.019991705426946282), (49, 0.021314991638064384), (38, 0.02208718960173428), (45, 0.023139021592214704), (39, 0.023474510991945863), (41, 0.02387145278044045), (46, 0.024038309464231133), (51, 0.024538288824260235), (6, 0.025002858135849237), (8, 0.025038711726665497), (48, 0.025119444588199258), (1, 0.025388095062226057), (47, 0.02732791635207832), (42, 0.028182360576465726), (33, 0.028287381632253528), (40, 0.028367724968120456), (43, 0.029044684255495667), (44, 0.029352556681260467), (0, 0.03271650802344084), (13, 0.036061248276382685), (52, 0.042394925374537706), (15, 0.04305667895823717), (16, 0.043651989195495844), (14, 0.043659396935254335), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.054063091054558754), (2, 0.055183832067996264), (10, 0.062402027659118176), (9, 0.08971724566072226), (17, 0.18636955507099628), (18, 0.27677176147699356), (36, 0.3271830305457115), (53, 0.8959614112973213)]
computing accuracy for after removing block 29 . block score: 0.01363685168325901
removed block 29 current accuracy 0.958 loss from initial  0.04200000000000004
since last training loss: 0.028400000000000092 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.014475. All blocks and scores: [(20, 0.014475059462711215), (3, 0.014681300264783204), (37, 0.017688013846054673), (28, 0.01836001966148615), (7, 0.019321493105962873), (50, 0.019902902888134122), (34, 0.02044607256539166), (49, 0.021449923049658537), (38, 0.022830398054793477), (45, 0.023148912470787764), (41, 0.023782097967341542), (51, 0.023966893553733826), (46, 0.024161772802472115), (39, 0.024319971911609173), (6, 0.0250028595328331), (8, 0.02503871126100421), (48, 0.02513158624060452), (1, 0.025388095062226057), (47, 0.026900453260168433), (42, 0.028658576775342226), (40, 0.028860508929938078), (43, 0.029123117215931416), (44, 0.030179518507793546), (33, 0.030993567313998938), (0, 0.032716508489102125), (13, 0.03606124734506011), (52, 0.04165757494047284), (15, 0.04305668128654361), (16, 0.04365198872983456), (14, 0.04365939740091562), (4, 0.05115430895239115), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.055183833464980125), (10, 0.0624020267277956), (9, 0.08971724193543196), (17, 0.18636955134570599), (18, 0.27677176520228386), (36, 0.3362649716436863), (53, 0.8946184366941452)]
computing accuracy for after removing block 20 . block score: 0.014475059462711215
removed block 20 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.045600000000000085 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 3, with score 0.014681. All blocks and scores: [(3, 0.01468130003195256), (37, 0.01753528928384185), (28, 0.018479035468772054), (7, 0.019321492640301585), (50, 0.019452705280855298), (49, 0.020851465174928308), (34, 0.020893771899864078), (38, 0.021935275988653302), (45, 0.02225391985848546), (46, 0.022808663547039032), (51, 0.02301283529959619), (41, 0.023610252887010574), (39, 0.024020644137635827), (48, 0.024894542759284377), (6, 0.025002859067171812), (8, 0.025038712192326784), (1, 0.0253880952950567), (47, 0.02620476158335805), (42, 0.028308543609455228), (43, 0.028871111338958144), (40, 0.029305310919880867), (44, 0.029724607011303306), (0, 0.032716508489102125), (33, 0.03295760788023472), (13, 0.03606124874204397), (52, 0.03952924255281687), (15, 0.04305668035522103), (16, 0.04365198966115713), (14, 0.04365939786657691), (4, 0.05115430802106857), (12, 0.05150972120463848), (11, 0.05406309058889747), (2, 0.05518383113667369), (10, 0.062402026262134314), (9, 0.08971724566072226), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.3319150358438492), (53, 0.8919048383831978)]
computing accuracy for after removing block 3 . block score: 0.01468130003195256
removed block 3 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 28, with score 0.018655. All blocks and scores: [(28, 0.018655424006283283), (37, 0.018990264972671866), (50, 0.019352634204551578), (38, 0.020607825834304094), (34, 0.021370295202359557), (49, 0.02147139864973724), (45, 0.02249637246131897), (7, 0.022563793463632464), (46, 0.02301787957549095), (51, 0.02335710870102048), (39, 0.023751773638650775), (6, 0.02429414796642959), (41, 0.024343542754650116), (48, 0.02498826221562922), (1, 0.0253880952950567), (8, 0.025867065880447626), (47, 0.026250995928421617), (44, 0.028660246403887868), (42, 0.028714660787954926), (43, 0.02956711151637137), (40, 0.03209337452426553), (33, 0.03214730229228735), (0, 0.032716508489102125), (13, 0.0336373052559793), (14, 0.03939402662217617), (52, 0.0399103001691401), (16, 0.042494493536651134), (15, 0.04269892815500498), (12, 0.05363550502806902), (11, 0.054042018949985504), (4, 0.05474466364830732), (2, 0.0551838343963027), (10, 0.0646433038637042), (9, 0.09361164178699255), (17, 0.18750124238431454), (18, 0.27515244111418724), (36, 0.34003007784485817), (53, 0.8942566514015198)]
computing accuracy for after removing block 28 . block score: 0.018655424006283283
removed block 28 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.07260000000000011 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.018354. All blocks and scores: [(37, 0.018354135332629085), (50, 0.018611087929457426), (38, 0.020466344198212028), (49, 0.020779793616384268), (45, 0.021783865755423903), (34, 0.022262955782935023), (51, 0.022289655869826674), (7, 0.02256379253230989), (39, 0.02273762528784573), (46, 0.02280928287655115), (6, 0.02429414796642959), (48, 0.024323247838765383), (41, 0.024347293889150023), (1, 0.0253880952950567), (47, 0.025682266801595688), (8, 0.02586706611327827), (42, 0.028105770470574498), (44, 0.028211602242663503), (43, 0.029053979786112905), (40, 0.031712270341813564), (0, 0.03271650895476341), (13, 0.03363730385899544), (33, 0.03551091579720378), (52, 0.03843055386096239), (14, 0.03939402662217617), (16, 0.04249449307098985), (15, 0.04269892815500498), (12, 0.053635504096746445), (11, 0.054042018949985504), (4, 0.05474466737359762), (2, 0.05518383393064141), (10, 0.0646433038637042), (9, 0.09361164551228285), (17, 0.18750124610960484), (18, 0.27515243738889694), (36, 0.3470934070646763), (53, 0.9132807850837708)]
computing accuracy for after removing block 37 . block score: 0.018354135332629085
removed block 37 current accuracy 0.8968 loss from initial  0.10319999999999996
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.018042. All blocks and scores: [(50, 0.018042205832898617), (49, 0.020119183929637074), (45, 0.02088622935116291), (51, 0.02163904206827283), (46, 0.021794973639771342), (38, 0.02215082198381424), (34, 0.02226295624859631), (7, 0.022563792997971177), (48, 0.023926986614242196), (39, 0.024016898358240724), (47, 0.024249384878203273), (6, 0.024294147500768304), (41, 0.02462375396862626), (1, 0.025388095760717988), (8, 0.025867066346108913), (44, 0.026392090832814574), (42, 0.027722187573090196), (43, 0.02780671580694616), (40, 0.032188847195357084), (0, 0.0327165094204247), (13, 0.03363730572164059), (33, 0.03551091533154249), (52, 0.0373685359954834), (14, 0.03939402708783746), (16, 0.042494493536651134), (15, 0.04269892768934369), (12, 0.05363550363108516), (11, 0.05404201801866293), (4, 0.05474466597661376), (2, 0.05518383486196399), (10, 0.06464330665767193), (9, 0.093611647374928), (17, 0.18750125169754028), (18, 0.27515244111418724), (36, 0.347093403339386), (53, 0.9323131516575813)]
computing accuracy for after removing block 50 . block score: 0.018042205832898617
removed block 50 current accuracy 0.8816 loss from initial  0.11839999999999995
since last training loss: 0.1048 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.020119. All blocks and scores: [(49, 0.020119183463975787), (45, 0.02088622935116291), (46, 0.021794973872601986), (38, 0.02215082198381424), (34, 0.022262955084443092), (7, 0.022563792299479246), (51, 0.023517727619037032), (48, 0.023926985915750265), (39, 0.024016899056732655), (47, 0.024249385111033916), (6, 0.024294147500768304), (41, 0.024623752804473042), (1, 0.025388094829395413), (8, 0.025867066578939557), (44, 0.02639209059998393), (42, 0.027722188271582127), (43, 0.02780671580694616), (40, 0.032188847195357084), (0, 0.03271650895476341), (13, 0.03363730479031801), (33, 0.035510914865881205), (14, 0.03939402662217617), (52, 0.04043895052745938), (16, 0.042494493536651134), (15, 0.04269892768934369), (12, 0.05363550456240773), (11, 0.054042018949985504), (4, 0.0547446645796299), (2, 0.055183832067996264), (10, 0.0646433038637042), (9, 0.09361164551228285), (17, 0.18750124983489513), (18, 0.27515243738889694), (36, 0.347093403339386), (53, 1.1329583525657654)]
computing accuracy for after removing block 49 . block score: 0.020119183463975787
removed block 49 current accuracy 0.8564 loss from initial  0.14359999999999995
since last training loss: 0.13 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.020886. All blocks and scores: [(45, 0.02088622935116291), (46, 0.021794973174110055), (38, 0.022150821518152952), (34, 0.02226295624859631), (7, 0.022563793463632464), (48, 0.023926986614242196), (39, 0.024016898591071367), (47, 0.024249385809525847), (6, 0.024294146802276373), (41, 0.02462375327013433), (1, 0.025388095527887344), (8, 0.025867065880447626), (51, 0.026040717726573348), (44, 0.02639209129847586), (42, 0.02772218780592084), (43, 0.027806716039776802), (40, 0.032188847195357084), (0, 0.03271650895476341), (13, 0.033637304324656725), (33, 0.035510916262865067), (14, 0.03939402801916003), (16, 0.04249449260532856), (15, 0.042698927223682404), (52, 0.04534667357802391), (12, 0.053635505959391594), (11, 0.054042017087340355), (4, 0.05474466551095247), (2, 0.05518383393064141), (10, 0.06464330572634935), (9, 0.0936116436496377), (17, 0.18750124238431454), (18, 0.27515244483947754), (36, 0.3470933996140957), (53, 1.3978236615657806)]
computing accuracy for after removing block 45 . block score: 0.02088622935116291
removed block 45 current accuracy 0.8282 loss from initial  0.17179999999999995
since last training loss: 0.1582 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.022151. All blocks and scores: [(38, 0.02215082198381424), (34, 0.02226295555010438), (7, 0.022563792765140533), (46, 0.023506081197410822), (39, 0.02401689742691815), (6, 0.024294147035107017), (48, 0.02435985510237515), (41, 0.024623753735795617), (47, 0.025360825238749385), (1, 0.025388095062226057), (8, 0.025867065647616982), (51, 0.026005247374996543), (44, 0.026392090134322643), (42, 0.027722187340259552), (43, 0.027806714875623584), (40, 0.0321888467296958), (0, 0.0327165094204247), (13, 0.033637304324656725), (33, 0.03551091533154249), (14, 0.03939402801916003), (16, 0.04249449213966727), (15, 0.04269892815500498), (52, 0.04616398550570011), (12, 0.053635504096746445), (11, 0.05404201615601778), (4, 0.0547446645796299), (2, 0.0551838343963027), (10, 0.06464330479502678), (9, 0.09361164644360542), (17, 0.18750124797224998), (18, 0.27515243366360664), (36, 0.347093403339386), (53, 1.5272499918937683)]
computing accuracy for after removing block 38 . block score: 0.02215082198381424
removed block 38 current accuracy 0.8074 loss from initial  0.1926
training start
training epoch 0 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best False lr [0.1]
training epoch 1 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best False lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.1]
training epoch 3 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 5 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 6 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 7 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 8 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.1]
training epoch 9 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.953400)
finished training. finished 50 epochs. accuracy 0.9534 topk_dict {'top1': 0.9534}
start iteration 22
[activation diff]: block to remove picked: 7, with score 0.038158. All blocks and scores: [(7, 0.03815784165635705), (51, 0.04894995270296931), (1, 0.05200096871703863), (8, 0.052130923606455326), (41, 0.054026429541409016), (48, 0.05411524046212435), (46, 0.05583543796092272), (44, 0.057005918119102716), (40, 0.05714844912290573), (52, 0.05853707017377019), (39, 0.05898764403536916), (47, 0.06149252876639366), (42, 0.06523836590349674), (0, 0.06723449006676674), (43, 0.06875873077660799), (34, 0.07696004770696163), (6, 0.08051009941846132), (13, 0.08909663092345), (14, 0.10240781679749489), (15, 0.10270334221422672), (16, 0.10934299509972334), (11, 0.11266085784882307), (33, 0.12920288927853107), (12, 0.1313890777528286), (2, 0.13392319157719612), (10, 0.1474599465727806), (4, 0.1598201896995306), (9, 0.17671119421720505), (17, 0.4522709883749485), (18, 0.4659140259027481), (36, 0.6085677966475487), (53, 1.1087068915367126)]
computing accuracy for after removing block 7 . block score: 0.03815784165635705
removed block 7 current accuracy 0.949 loss from initial  0.051000000000000045
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 51, with score 0.048629. All blocks and scores: [(51, 0.04862898727878928), (41, 0.05111816432327032), (1, 0.05200096592307091), (44, 0.05336667085066438), (48, 0.05377203552052379), (46, 0.055123863741755486), (39, 0.05543240485712886), (40, 0.05768485367298126), (8, 0.057929071597754955), (52, 0.058893786277621984), (47, 0.06150447158142924), (42, 0.06390034779906273), (0, 0.06723449099808931), (43, 0.06775795482099056), (34, 0.07444619666785002), (6, 0.08051010128110647), (13, 0.08509634993970394), (14, 0.08947889320552349), (15, 0.09979451633989811), (16, 0.10584171768277884), (11, 0.11039757076650858), (33, 0.1227867379784584), (12, 0.1306496262550354), (2, 0.13392318598926067), (10, 0.14573865197598934), (4, 0.15982019156217575), (9, 0.17993240244686604), (17, 0.4105365313589573), (18, 0.4486762396991253), (36, 0.584593877196312), (53, 1.1213808506727219)]
computing accuracy for after removing block 51 . block score: 0.04862898727878928
removed block 51 current accuracy 0.9402 loss from initial  0.059799999999999964
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.051118. All blocks and scores: [(41, 0.05111816478893161), (1, 0.05200096871703863), (44, 0.053366669453680515), (48, 0.05377203552052379), (46, 0.05512386420741677), (39, 0.05543240811675787), (40, 0.05768485413864255), (8, 0.05792907252907753), (47, 0.06150447251275182), (42, 0.0639003487303853), (52, 0.06710127368569374), (0, 0.06723449099808931), (43, 0.06775795668363571), (34, 0.07444619666785002), (6, 0.08051010500639677), (13, 0.08509635180234909), (14, 0.08947889320552349), (15, 0.09979451261460781), (16, 0.10584172140806913), (11, 0.11039756890386343), (33, 0.12278673518449068), (12, 0.1306496262550354), (2, 0.13392319530248642), (10, 0.1457386463880539), (4, 0.15982018783688545), (9, 0.17993240244686604), (17, 0.4105365499854088), (18, 0.4486762285232544), (36, 0.584593877196312), (53, 1.312939092516899)]
computing accuracy for after removing block 41 . block score: 0.05111816478893161
removed block 41 current accuracy 0.93 loss from initial  0.06999999999999995
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.049823. All blocks and scores: [(48, 0.049823261331766844), (1, 0.05200096685439348), (46, 0.05405436037108302), (44, 0.05425774212926626), (39, 0.055432407185435295), (40, 0.05768485367298126), (8, 0.05792907113209367), (47, 0.06027854233980179), (42, 0.0669086892157793), (0, 0.06723448913544416), (52, 0.06777632143348455), (43, 0.06928150448948145), (34, 0.07444619759917259), (6, 0.0805101003497839), (13, 0.08509634993970394), (14, 0.08947889227420092), (15, 0.09979451261460781), (16, 0.10584172233939171), (11, 0.11039756704121828), (33, 0.1227867379784584), (12, 0.1306496299803257), (2, 0.13392318785190582), (10, 0.1457386463880539), (4, 0.1598201934248209), (9, 0.17993240244686604), (17, 0.4105365425348282), (18, 0.4486762546002865), (36, 0.5845938846468925), (53, 1.355235993862152)]
computing accuracy for after removing block 48 . block score: 0.049823261331766844
removed block 48 current accuracy 0.9176 loss from initial  0.08240000000000003
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 1, with score 0.052001. All blocks and scores: [(1, 0.05200096685439348), (46, 0.05405435897409916), (44, 0.05425774306058884), (39, 0.05543240625411272), (40, 0.0576848522759974), (8, 0.05792907299473882), (47, 0.0602785418741405), (42, 0.0669086892157793), (0, 0.06723449286073446), (43, 0.06928150448948145), (34, 0.07444619666785002), (52, 0.07539758551865816), (6, 0.0805101003497839), (13, 0.08509635087102652), (14, 0.08947889320552349), (15, 0.09979451447725296), (16, 0.10584172233939171), (11, 0.11039756517857313), (33, 0.12278673890978098), (12, 0.13064962811768055), (2, 0.13392319157719612), (10, 0.14573864825069904), (4, 0.15982019156217575), (9, 0.1799324005842209), (17, 0.4105365499854088), (18, 0.4486762471497059), (36, 0.5845938995480537), (53, 1.6417817324399948)]
computing accuracy for after removing block 1 . block score: 0.05200096685439348
removed block 1 current accuracy 0.905 loss from initial  0.09499999999999997
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 44, with score 0.052306. All blocks and scores: [(44, 0.05230565648525953), (46, 0.05521395895630121), (39, 0.055663881823420525), (8, 0.05742395715788007), (47, 0.06099273823201656), (40, 0.06218266952782869), (0, 0.06723449099808931), (42, 0.06813742965459824), (43, 0.07077210489660501), (34, 0.07498248666524887), (52, 0.075943554751575), (6, 0.07739441376179457), (13, 0.08047468774020672), (14, 0.08465109020471573), (15, 0.09349780716001987), (16, 0.1036401903256774), (11, 0.11251201014965773), (33, 0.12043837737292051), (12, 0.12679376918822527), (2, 0.14351291209459305), (10, 0.15275693871080875), (9, 0.17324782721698284), (4, 0.17783250287175179), (17, 0.41293393075466156), (18, 0.44483382999897003), (36, 0.5987336561083794), (53, 1.620922178030014)]
computing accuracy for after removing block 44 . block score: 0.05230565648525953
removed block 44 current accuracy 0.8746 loss from initial  0.12539999999999996
since last training loss: 0.07879999999999998 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 39, with score 0.055664. All blocks and scores: [(39, 0.05566388135775924), (8, 0.057423960883170366), (46, 0.05996772367507219), (40, 0.06218266859650612), (47, 0.06544315721839666), (0, 0.06723449099808931), (42, 0.06813742686063051), (43, 0.07077210582792759), (34, 0.07498248759657145), (52, 0.07637577690184116), (6, 0.07739441655576229), (13, 0.08047468680888414), (14, 0.08465108461678028), (15, 0.09349780902266502), (16, 0.10364018473774195), (11, 0.11251201294362545), (33, 0.12043837737292051), (12, 0.12679376918822527), (2, 0.1435129139572382), (10, 0.15275693871080875), (9, 0.173247829079628), (4, 0.17783250845968723), (17, 0.41293393820524216), (18, 0.44483381137251854), (36, 0.5987336561083794), (53, 1.7087895274162292)]
computing accuracy for after removing block 39 . block score: 0.05566388135775924
removed block 39 current accuracy 0.8482 loss from initial  0.15180000000000005
since last training loss: 0.10520000000000007 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 46, with score 0.055989. All blocks and scores: [(46, 0.05598865728825331), (8, 0.05742395855486393), (47, 0.06133069610223174), (40, 0.06626642122864723), (0, 0.06723449006676674), (43, 0.06879673898220062), (42, 0.06955031398683786), (52, 0.07284653000533581), (34, 0.07498248666524887), (6, 0.07739441469311714), (13, 0.08047469053417444), (14, 0.08465108554810286), (15, 0.0934978099539876), (16, 0.1036401903256774), (11, 0.11251201387494802), (33, 0.12043837271630764), (12, 0.12679376918822527), (2, 0.1435129139572382), (10, 0.15275694243609905), (9, 0.1732478328049183), (4, 0.17783250473439693), (17, 0.41293394938111305), (18, 0.44483380764722824), (36, 0.5987336710095406), (53, 1.664245143532753)]
computing accuracy for after removing block 46 . block score: 0.05598865728825331
removed block 46 current accuracy 0.8052 loss from initial  0.19479999999999997
since last training loss: 0.1482 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 8, with score 0.057424. All blocks and scores: [(8, 0.05742395669221878), (40, 0.0662664221599698), (0, 0.06723449099808931), (47, 0.06804682034999132), (43, 0.06879673898220062), (42, 0.06955031305551529), (34, 0.07498248480260372), (6, 0.07739441469311714), (52, 0.07840771693736315), (13, 0.08047468401491642), (14, 0.08465108647942543), (15, 0.09349780529737473), (16, 0.10364019125699997), (11, 0.11251201294362545), (33, 0.12043837178498507), (12, 0.12679377105087042), (2, 0.14351291209459305), (10, 0.1527569368481636), (9, 0.1732478328049183), (4, 0.17783250100910664), (17, 0.41293393075466156), (18, 0.44483382999897003), (36, 0.59873366355896), (53, 1.8285602182149887)]
computing accuracy for after removing block 8 . block score: 0.05742395669221878
removed block 8 current accuracy 0.7448 loss from initial  0.2552
since last training loss: 0.2086 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.061556. All blocks and scores: [(40, 0.06155568873509765), (42, 0.06473789643496275), (47, 0.065031080506742), (0, 0.06723448913544416), (43, 0.0673000868409872), (34, 0.07221516408026218), (14, 0.07617604453116655), (6, 0.07739441655576229), (52, 0.07827072869986296), (13, 0.08419487532228231), (15, 0.09475319925695658), (11, 0.10793089680373669), (16, 0.11432077642530203), (33, 0.11653394997119904), (12, 0.12092750705778599), (2, 0.1435129139572382), (10, 0.1485572401434183), (4, 0.17783250287175179), (9, 0.18743090704083443), (17, 0.35747019201517105), (18, 0.4192053861916065), (36, 0.5726947039365768), (53, 1.7146284133195877)]
computing accuracy for after removing block 40 . block score: 0.06155568873509765
removed block 40 current accuracy 0.6856 loss from initial  0.3144
since last training loss: 0.26780000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 47, with score 0.062344. All blocks and scores: [(47, 0.062344301491975784), (0, 0.06723449006676674), (43, 0.0707710012793541), (42, 0.0715053053572774), (34, 0.07221516314893961), (14, 0.07617604453116655), (6, 0.07739441562443972), (52, 0.07800453715026379), (13, 0.08419487532228231), (15, 0.0947532020509243), (11, 0.10793089307844639), (16, 0.11432077828794718), (33, 0.11653395462781191), (12, 0.12092751078307629), (2, 0.14351291209459305), (10, 0.14855724573135376), (4, 0.17783250473439693), (9, 0.18743091076612473), (17, 0.35747018083930016), (18, 0.4192053899168968), (36, 0.5726947039365768), (53, 1.7750627249479294)]
computing accuracy for after removing block 47 . block score: 0.062344301491975784
removed block 47 current accuracy 0.5732 loss from initial  0.42679999999999996
training start
training epoch 0 val accuracy 0.842 topk_dict {'top1': 0.842} is_best True lr [0.1]
training epoch 1 val accuracy 0.852 topk_dict {'top1': 0.852} is_best True lr [0.1]
training epoch 2 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best True lr [0.1]
training epoch 3 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.1]
training epoch 4 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 5 val accuracy 0.8088 topk_dict {'top1': 0.8088} is_best False lr [0.1]
training epoch 6 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 7 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 8 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.1]
training epoch 9 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 10 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.934800)
finished training. finished 50 epochs. accuracy 0.9348 topk_dict {'top1': 0.9348}
start iteration 33
[activation diff]: block to remove picked: 0, with score 0.088157. All blocks and scores: [(0, 0.08815668057650328), (52, 0.0956864571198821), (6, 0.09768311120569706), (15, 0.1087030628696084), (13, 0.10887206997722387), (16, 0.11045642103999853), (14, 0.11111485585570335), (34, 0.11268756445497274), (42, 0.11586181726306677), (43, 0.11709093675017357), (12, 0.14001624286174774), (11, 0.145067336037755), (33, 0.19408908672630787), (10, 0.20324164256453514), (2, 0.21756941638886929), (4, 0.2311127930879593), (9, 0.23613940738141537), (36, 0.4919946603477001), (17, 0.4998890459537506), (18, 0.5246868655085564), (53, 1.2473402917385101)]
computing accuracy for after removing block 0 . block score: 0.08815668057650328
removed block 0 current accuracy 0.9188 loss from initial  0.08120000000000005
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 6, with score 0.085244. All blocks and scores: [(6, 0.08524354919791222), (15, 0.08743386808782816), (14, 0.09433301445096731), (52, 0.09572637360543013), (13, 0.09800195507705212), (34, 0.10611461196094751), (16, 0.11258505284786224), (42, 0.11487413756549358), (43, 0.116382647305727), (12, 0.13297941163182259), (11, 0.13730229623615742), (33, 0.17876044660806656), (10, 0.1913057640194893), (2, 0.22269266098737717), (9, 0.25041764602065086), (4, 0.29510168358683586), (17, 0.4841398112475872), (36, 0.4914443679153919), (18, 0.4944031983613968), (53, 1.178533062338829)]
computing accuracy for after removing block 6 . block score: 0.08524354919791222
removed block 6 current accuracy 0.9102 loss from initial  0.08979999999999999
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 15, with score 0.090085. All blocks and scores: [(15, 0.09008496813476086), (14, 0.09127827174961567), (52, 0.0937697933986783), (34, 0.09806107264012098), (13, 0.10065498854964972), (42, 0.10846766456961632), (43, 0.11173114646226168), (16, 0.11708127148449421), (11, 0.14008371159434319), (12, 0.14202186278998852), (33, 0.16627787798643112), (10, 0.19926269352436066), (2, 0.22269266657531261), (9, 0.252047061920166), (4, 0.29510168731212616), (36, 0.4683123491704464), (17, 0.49412278831005096), (18, 0.4999289885163307), (53, 1.1474049389362335)]
computing accuracy for after removing block 15 . block score: 0.09008496813476086
removed block 15 current accuracy 0.8916 loss from initial  0.10840000000000005
since last training loss: 0.043200000000000016 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 14, with score 0.091278. All blocks and scores: [(14, 0.09127827361226082), (52, 0.09351875446736813), (34, 0.09836533758789301), (13, 0.10065498761832714), (42, 0.10648633912205696), (43, 0.10927684884518385), (11, 0.14008371159434319), (12, 0.14202185720205307), (16, 0.1461862102150917), (33, 0.1644022949039936), (10, 0.19926269352436066), (2, 0.22269265726208687), (9, 0.2520470656454563), (4, 0.29510168731212616), (36, 0.4706844538450241), (18, 0.515521764755249), (17, 0.742406390607357), (53, 1.1059231013059616)]
computing accuracy for after removing block 14 . block score: 0.09127827361226082
removed block 14 current accuracy 0.8532 loss from initial  0.14680000000000004
since last training loss: 0.0816 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 52, with score 0.092570. All blocks and scores: [(52, 0.09256975259631872), (34, 0.09987734165042639), (13, 0.10065498761832714), (42, 0.10510329063981771), (43, 0.1066344054415822), (11, 0.14008371159434319), (12, 0.14202186092734337), (16, 0.15552868694067), (33, 0.1638435274362564), (10, 0.19926269352436066), (2, 0.22269266843795776), (9, 0.25204705633223057), (4, 0.29510167986154556), (36, 0.4704267345368862), (18, 0.5167555138468742), (17, 0.7708486318588257), (53, 1.0305799543857574)]
computing accuracy for after removing block 52 . block score: 0.09256975259631872
removed block 52 current accuracy 0.6558 loss from initial  0.34419999999999995
since last training loss: 0.2789999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 34, with score 0.099877. All blocks and scores: [(34, 0.09987734258174896), (13, 0.10065498854964972), (42, 0.10510328691452742), (43, 0.1066344091668725), (11, 0.14008371159434319), (12, 0.14202186465263367), (16, 0.15552868694067), (33, 0.1638435311615467), (10, 0.19926269352436066), (2, 0.22269265912473202), (9, 0.2520470544695854), (4, 0.29510168731212616), (36, 0.4704267419874668), (18, 0.5167554914951324), (17, 0.7708486318588257), (53, 0.8732854425907135)]
computing accuracy for after removing block 34 . block score: 0.09987734258174896
removed block 34 current accuracy 0.6176 loss from initial  0.38239999999999996
since last training loss: 0.3171999999999999 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 13, with score 0.100655. All blocks and scores: [(13, 0.10065498854964972), (43, 0.10853319335728884), (42, 0.10940893925726414), (11, 0.14008371345698833), (12, 0.14202185906469822), (16, 0.15552868135273457), (33, 0.1638435274362564), (10, 0.19926269352436066), (2, 0.22269265539944172), (9, 0.2520470581948757), (4, 0.29510168358683586), (36, 0.492661289870739), (18, 0.5167555063962936), (17, 0.7708486318588257), (53, 0.8433399498462677)]
computing accuracy for after removing block 13 . block score: 0.10065498854964972
removed block 13 current accuracy 0.5144 loss from initial  0.48560000000000003
since last training loss: 0.4204 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 43, with score 0.101655. All blocks and scores: [(43, 0.10165539383888245), (42, 0.10472239926457405), (11, 0.14008370973169804), (12, 0.14202186278998852), (16, 0.14962616190314293), (33, 0.16317377984523773), (10, 0.1992626991122961), (2, 0.22269266098737717), (9, 0.25204705633223057), (4, 0.29510168358683586), (36, 0.47907067835330963), (18, 0.5105137750506401), (17, 0.7114576622843742), (53, 0.811555989086628)]
computing accuracy for after removing block 43 . block score: 0.10165539383888245
removed block 43 current accuracy 0.3582 loss from initial  0.6417999999999999
since last training loss: 0.5766 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 42, with score 0.104722. All blocks and scores: [(42, 0.10472239274531603), (11, 0.14008370973169804), (12, 0.14202186092734337), (16, 0.14962616004049778), (33, 0.16317378170788288), (10, 0.1992626953870058), (2, 0.22269266098737717), (9, 0.25204705633223057), (4, 0.29510167986154556), (36, 0.47907067090272903), (18, 0.5105137750506401), (17, 0.711457647383213), (53, 1.3263311386108398)]
computing accuracy for after removing block 42 . block score: 0.10472239274531603
removed block 42 current accuracy 0.2946 loss from initial  0.7054
since last training loss: 0.6402 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 11, with score 0.140084. All blocks and scores: [(11, 0.14008371531963348), (12, 0.14202186278998852), (16, 0.14962616004049778), (33, 0.16317377798259258), (10, 0.1992626991122961), (2, 0.22269265539944172), (9, 0.25204705633223057), (4, 0.29510167986154556), (36, 0.47907068580389023), (18, 0.5105137825012207), (17, 0.7114576399326324), (53, 1.685251459479332)]
computing accuracy for after removing block 11 . block score: 0.14008371531963348
removed block 11 current accuracy 0.2254 loss from initial  0.7746
since last training loss: 0.7094 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 12, with score 0.143414. All blocks and scores: [(12, 0.14341440983116627), (16, 0.14817970246076584), (33, 0.16014863550662994), (10, 0.19926269352436066), (2, 0.22269265726208687), (9, 0.25204705260694027), (4, 0.29510167613625526), (36, 0.4451562315225601), (18, 0.4801791422069073), (17, 0.5347937643527985), (53, 1.8155798316001892)]
computing accuracy for after removing block 12 . block score: 0.14341440983116627
removed block 12 current accuracy 0.1986 loss from initial  0.8014
since last training loss: 0.7362 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 33, with score 0.160254. All blocks and scores: [(33, 0.16025433130562305), (16, 0.18220879696309566), (10, 0.1992626991122961), (2, 0.22269266098737717), (9, 0.25204705633223057), (4, 0.29510168358683586), (36, 0.43540389090776443), (18, 0.48376862332224846), (17, 0.7488241419196129), (53, 2.1279294192790985)]
computing accuracy for after removing block 33 . block score: 0.16025433130562305
removed block 33 current accuracy 0.1952 loss from initial  0.8048
training start
training epoch 0 val accuracy 0.7864 topk_dict {'top1': 0.7864} is_best True lr [0.1]
training epoch 1 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best True lr [0.1]
training epoch 2 val accuracy 0.789 topk_dict {'top1': 0.789} is_best False lr [0.1]
training epoch 3 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best True lr [0.1]
training epoch 4 val accuracy 0.8068 topk_dict {'top1': 0.8068} is_best False lr [0.1]
training epoch 5 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best True lr [0.1]
training epoch 6 val accuracy 0.7888 topk_dict {'top1': 0.7888} is_best False lr [0.1]
training epoch 7 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.1]
training epoch 8 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best False lr [0.1]
training epoch 9 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 10 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.897600)
finished training. finished 50 epochs. accuracy 0.8976 topk_dict {'top1': 0.8976}
