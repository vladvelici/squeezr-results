start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009340. All blocks and scores: [(35, 0.00934032560326159), (27, 0.011103683733381331), (21, 0.01133407384622842), (31, 0.011607039137743413), (34, 0.0119167867815122), (20, 0.012414054363034666), (10, 0.012957266764715314), (29, 0.013191591366194189), (28, 0.014451422146521509), (25, 0.015047203982248902), (32, 0.015597440884448588), (26, 0.01591388671658933), (9, 0.01594743807800114), (33, 0.01621382706798613), (19, 0.01623808452859521), (30, 0.01653508166782558), (13, 0.017304431181401014), (23, 0.01780766947194934), (24, 0.018264206126332283), (47, 0.01833463995717466), (43, 0.01882609468884766), (22, 0.019027542555704713), (42, 0.019418792333453894), (39, 0.019591449527069926), (11, 0.019892502343282104), (46, 0.019984069280326366), (45, 0.02017575711943209), (40, 0.02033784077502787), (44, 0.02035037102177739), (41, 0.021346834022551775), (17, 0.022294857306405902), (14, 0.023160054814070463), (48, 0.02396509051322937), (38, 0.024251851718872786), (49, 0.025340355467051268), (37, 0.02872352907434106), (50, 0.03070739726535976), (51, 0.03621984925121069), (15, 0.0371777294203639), (0, 0.045861792750656605), (12, 0.04737982153892517), (8, 0.04887042474001646), (4, 0.05213462980464101), (5, 0.052416717167943716), (7, 0.05547522334381938), (2, 0.060984639916568995), (16, 0.06157056242227554), (3, 0.062430717051029205), (6, 0.06518651731312275), (52, 0.0775811905041337), (1, 0.1571871768683195), (36, 0.31111687794327736), (18, 0.38249504193663597), (53, 0.8639278262853622)]
computing accuracy for after removing block 35 . block score: 0.00934032560326159
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.011104. All blocks and scores: [(27, 0.011103683733381331), (21, 0.011334074079059064), (31, 0.011607039021328092), (34, 0.011916786432266235), (20, 0.012414054363034666), (10, 0.012957266997545958), (29, 0.013191592181101441), (28, 0.01445142226293683), (25, 0.015047204797156155), (32, 0.015597440884448588), (26, 0.015913886250928044), (9, 0.01594743854366243), (33, 0.016213827300816774), (19, 0.016238084062933922), (30, 0.016535081434994936), (13, 0.017304430482909083), (23, 0.01780766947194934), (47, 0.018221579026430845), (24, 0.018264205660670996), (43, 0.01871312176808715), (22, 0.019027542090043426), (42, 0.019336250377818942), (39, 0.019576826598495245), (11, 0.01989250211045146), (46, 0.01998652401380241), (45, 0.02004792634397745), (40, 0.020296325907111168), (44, 0.020512878661975265), (41, 0.02144961222074926), (17, 0.022294857306405902), (14, 0.023160054115578532), (48, 0.023811295395717025), (38, 0.024050168925896287), (49, 0.02540840208530426), (37, 0.028856528224423528), (50, 0.03064044937491417), (51, 0.03598107257857919), (15, 0.0371777294203639), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213463073596358), (5, 0.052416717167943716), (7, 0.055475224275141954), (2, 0.06098464084789157), (16, 0.06157056335359812), (3, 0.062430717051029205), (6, 0.06518651638180017), (52, 0.07701416313648224), (1, 0.1571871843189001), (36, 0.3119105100631714), (18, 0.3824950344860554), (53, 0.873422808945179)]
computing accuracy for after removing block 27 . block score: 0.011103683733381331
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011334. All blocks and scores: [(21, 0.011334074195474386), (31, 0.011815687292255461), (34, 0.011877579614520073), (20, 0.012414054130204022), (10, 0.012957266648299992), (29, 0.013689619721844792), (28, 0.0147082096664235), (25, 0.015047204215079546), (32, 0.015121230040676892), (26, 0.01591388671658933), (9, 0.015947437845170498), (33, 0.016188491601496935), (19, 0.016238083597272635), (30, 0.016331732738763094), (13, 0.017304430715739727), (47, 0.017806177493184805), (23, 0.01780766947194934), (24, 0.018264206126332283), (43, 0.0185800117906183), (22, 0.019027541857212782), (42, 0.019391175359487534), (46, 0.019606942543759942), (39, 0.01960722799412906), (45, 0.01971504185348749), (40, 0.019747436046600342), (11, 0.019892503274604678), (44, 0.020142703782767057), (41, 0.02075307327322662), (17, 0.022294857306405902), (48, 0.022873759968206286), (14, 0.023160054348409176), (38, 0.023989601293578744), (49, 0.024799508275464177), (37, 0.02869816101156175), (50, 0.030612411443144083), (51, 0.03549663443118334), (15, 0.037177728954702616), (0, 0.045861792750656605), (12, 0.047379820607602596), (8, 0.04887042427435517), (4, 0.052134628873318434), (5, 0.052416717167943716), (7, 0.05547522380948067), (2, 0.06098463758826256), (16, 0.06157056242227554), (3, 0.062430717051029205), (6, 0.06518651731312275), (52, 0.07554570864886045), (1, 0.15718718618154526), (36, 0.31206290796399117), (18, 0.3824950382113457), (53, 0.8803881332278252)]
computing accuracy for after removing block 21 . block score: 0.011334074195474386
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011639. All blocks and scores: [(31, 0.011639060219749808), (34, 0.011946186539717019), (20, 0.012414054246619344), (10, 0.012957266881130636), (29, 0.013874796219170094), (28, 0.014550405205227435), (25, 0.014715025201439857), (32, 0.015309393173083663), (26, 0.015426586149260402), (9, 0.015947437845170498), (30, 0.016168840462341905), (19, 0.016238084062933922), (33, 0.016239795135334134), (13, 0.017304430715739727), (23, 0.017435556510463357), (47, 0.017666856292635202), (24, 0.018116667633876204), (43, 0.018401946872472763), (42, 0.018988731084391475), (22, 0.019208091776818037), (45, 0.01936020003631711), (40, 0.019363844534382224), (39, 0.019441344309598207), (46, 0.019487919751554728), (11, 0.019892502343282104), (44, 0.02018019580282271), (41, 0.020585639867931604), (17, 0.022294858004897833), (48, 0.022515942808240652), (14, 0.023160054348409176), (38, 0.024127490585669875), (49, 0.024722861126065254), (37, 0.029028163757175207), (50, 0.030450497288256884), (51, 0.035263814963400364), (15, 0.03717772988602519), (0, 0.04586179321631789), (12, 0.047379820607602596), (8, 0.04887042474001646), (4, 0.052134628873318434), (5, 0.052416715770959854), (7, 0.05547522474080324), (2, 0.060984638053923845), (16, 0.061570563819259405), (3, 0.062430718913674355), (6, 0.06518651824444532), (52, 0.07456282526254654), (1, 0.1571871805936098), (36, 0.31330903246998787), (18, 0.38249504938721657), (53, 0.8804345354437828)]
computing accuracy for after removing block 31 . block score: 0.011639060219749808
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012262. All blocks and scores: [(34, 0.012262114905752242), (20, 0.012414054363034666), (10, 0.012957266997545958), (29, 0.013874796219170094), (28, 0.014550405205227435), (25, 0.014715025085024536), (32, 0.01528472756035626), (26, 0.015426586149260402), (9, 0.015947437845170498), (33, 0.016090110410004854), (30, 0.016168840462341905), (19, 0.01623808452859521), (13, 0.017304431181401014), (47, 0.01738952216692269), (23, 0.01743555604480207), (43, 0.01795878983102739), (24, 0.018116668332368135), (42, 0.018551464891061187), (40, 0.01901159342378378), (45, 0.019096721429377794), (22, 0.019208091776818037), (46, 0.019322606967762113), (39, 0.01943867444060743), (11, 0.01989250280894339), (44, 0.020096177700906992), (41, 0.02039977116510272), (48, 0.022222393890842795), (17, 0.022294857073575258), (14, 0.023160055046901107), (38, 0.023856616113334894), (49, 0.02439989452250302), (37, 0.02922192169353366), (50, 0.030021414393559098), (51, 0.03500615153461695), (15, 0.03717772848904133), (0, 0.04586179368197918), (12, 0.047379820607602596), (8, 0.04887042474001646), (4, 0.05213462980464101), (5, 0.052416717633605), (7, 0.05547522380948067), (2, 0.060984641313552856), (16, 0.06157056521624327), (3, 0.06243071798235178), (6, 0.06518651824444532), (52, 0.07356802467256784), (1, 0.1571871843189001), (36, 0.31360403820872307), (18, 0.3824950344860554), (53, 0.8875407204031944)]
computing accuracy for after removing block 34 . block score: 0.012262114905752242
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012414. All blocks and scores: [(20, 0.012414054363034666), (10, 0.012957266997545958), (29, 0.01387479668483138), (28, 0.0145504055544734), (25, 0.014715025085024536), (32, 0.015284727443940938), (26, 0.015426585800014436), (9, 0.015947437845170498), (33, 0.016090110410004854), (30, 0.016168839996680617), (19, 0.016238084295764565), (47, 0.017113495618104935), (13, 0.017304430715739727), (23, 0.01743555604480207), (43, 0.017444000579416752), (42, 0.017953321570530534), (24, 0.01811666740104556), (40, 0.01862735440954566), (45, 0.018796849763020873), (46, 0.019162563141435385), (22, 0.019208092242479324), (39, 0.019221501192077994), (11, 0.019892502343282104), (44, 0.02002423210069537), (41, 0.020066209137439728), (48, 0.02205545175820589), (17, 0.02229485777206719), (14, 0.02316005458123982), (38, 0.023407893488183618), (49, 0.023943487089127302), (37, 0.02887884248048067), (50, 0.029550930485129356), (51, 0.03471436724066734), (15, 0.03717772802338004), (0, 0.04586179368197918), (12, 0.047379820607602596), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.05241671856492758), (7, 0.055475222412496805), (2, 0.06098463851958513), (16, 0.06157056149095297), (3, 0.06243071798235178), (6, 0.06518651824444532), (52, 0.07239074818789959), (1, 0.1571871843189001), (36, 0.313132181763649), (18, 0.38249504566192627), (53, 0.8949520960450172)]
computing accuracy for after removing block 20 . block score: 0.012414054363034666
removed block 20 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012957. All blocks and scores: [(10, 0.012957266997545958), (29, 0.013561785919591784), (28, 0.014028951525688171), (25, 0.014169098460115492), (32, 0.01497860869858414), (26, 0.014983123983256519), (30, 0.015398440416902304), (9, 0.01594743854366243), (33, 0.01612044684588909), (19, 0.016238084062933922), (47, 0.016815442591905594), (43, 0.01684385910630226), (23, 0.017247507581487298), (13, 0.017304430715739727), (42, 0.01734949997626245), (24, 0.017785267904400826), (40, 0.018032792722806334), (45, 0.018344406271353364), (39, 0.0189236372243613), (46, 0.01904189493507147), (22, 0.01921574934385717), (41, 0.01964655634947121), (11, 0.01989250280894339), (44, 0.020137505140155554), (48, 0.021741406759247184), (17, 0.022294857073575258), (14, 0.02316005458123982), (38, 0.023315483005717397), (49, 0.023662552470341325), (37, 0.02904578880406916), (50, 0.02913463767617941), (51, 0.034014496486634016), (15, 0.03717772988602519), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042427435517), (4, 0.052134630270302296), (5, 0.052416719030588865), (7, 0.05547522334381938), (2, 0.06098463898524642), (16, 0.06157056288793683), (3, 0.06243071611970663), (6, 0.06518651731312275), (52, 0.0706823468208313), (1, 0.15718718245625496), (36, 0.31336937844753265), (18, 0.38249504566192627), (53, 0.8989739865064621)]
computing accuracy for after removing block 10 . block score: 0.012957266997545958
removed block 10 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013780. All blocks and scores: [(29, 0.013779842643998563), (28, 0.013976978487335145), (25, 0.014224751270376146), (26, 0.014854759559966624), (32, 0.015099614509381354), (30, 0.015454857959412038), (9, 0.01594743807800114), (33, 0.0162667038384825), (13, 0.016542865429073572), (43, 0.01676264777779579), (47, 0.01678211963735521), (23, 0.017073968425393105), (19, 0.01718146982602775), (42, 0.017427340615540743), (40, 0.01776417507790029), (24, 0.017844599904492497), (45, 0.018063027877360582), (39, 0.018619783222675323), (46, 0.01876853476278484), (22, 0.018944737734273076), (41, 0.01944462489336729), (44, 0.01964278519153595), (11, 0.02028288133442402), (48, 0.02117547346279025), (17, 0.0227236095815897), (14, 0.022779475431889296), (38, 0.023119496647268534), (49, 0.023811477702111006), (37, 0.027783303521573544), (50, 0.028577968012541533), (51, 0.033666453789919615), (15, 0.03736387798562646), (12, 0.04314273316413164), (0, 0.045861792750656605), (8, 0.048870425671339035), (4, 0.05213462980464101), (5, 0.052416717633605), (7, 0.05547522380948067), (2, 0.06098463945090771), (16, 0.06162197142839432), (3, 0.062430717051029205), (6, 0.06518651824444532), (52, 0.0700069461017847), (1, 0.1571871843189001), (36, 0.3039804436266422), (18, 0.3742111884057522), (53, 0.8993168026208878)]
computing accuracy for after removing block 29 . block score: 0.013779842643998563
removed block 29 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.013977. All blocks and scores: [(28, 0.013976978254504502), (25, 0.014224751270376146), (26, 0.014854759676381946), (32, 0.015656630275771022), (9, 0.01594743807800114), (33, 0.016093431506305933), (30, 0.01633106591179967), (13, 0.016542865661904216), (47, 0.016583282267674804), (43, 0.016609041951596737), (42, 0.01673181401565671), (23, 0.01707396819256246), (19, 0.017181470058858395), (40, 0.01759379543364048), (45, 0.017683780286461115), (24, 0.01784460013732314), (39, 0.01834291312843561), (46, 0.018452940275892615), (22, 0.01894473726861179), (41, 0.019309211056679487), (44, 0.019369024550542235), (11, 0.02028288133442402), (48, 0.020786920562386513), (17, 0.022723610512912273), (14, 0.02277947496622801), (38, 0.0230357910040766), (49, 0.023334231227636337), (37, 0.02778223785571754), (50, 0.027876751264557242), (51, 0.03319639712572098), (15, 0.037363878451287746), (12, 0.04314273223280907), (0, 0.04586179181933403), (8, 0.04887042427435517), (4, 0.05213462933897972), (5, 0.052416715770959854), (7, 0.055475224275141954), (2, 0.06098463758826256), (16, 0.06162197282537818), (3, 0.06243071472272277), (6, 0.0651865154504776), (52, 0.06813919637352228), (1, 0.1571871843189001), (36, 0.30388377606868744), (18, 0.3742111809551716), (53, 0.9086464792490005)]
computing accuracy for after removing block 28 . block score: 0.013976978254504502
removed block 28 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.014225. All blocks and scores: [(25, 0.01422475150320679), (26, 0.014854759559966624), (32, 0.015713009517639875), (9, 0.01594743807800114), (33, 0.016001068288460374), (47, 0.016190798953175545), (42, 0.016318539856001735), (43, 0.016331236576661468), (13, 0.016542865661904216), (30, 0.016802769852802157), (23, 0.01707396819256246), (19, 0.01718147029168904), (40, 0.017207596683874726), (45, 0.017318607307970524), (24, 0.01784460013732314), (39, 0.017898976104333997), (46, 0.01805210579186678), (22, 0.018944737035781145), (44, 0.019007600378245115), (41, 0.01906347321346402), (48, 0.020253473427146673), (11, 0.02028288203291595), (38, 0.02265586005523801), (17, 0.022723609814420342), (49, 0.02274867962114513), (14, 0.02277947496622801), (50, 0.027034819591790438), (37, 0.027097024489194155), (51, 0.032346240943297744), (15, 0.037363878916949034), (12, 0.043142732698470354), (0, 0.04586179368197918), (8, 0.04887042474001646), (4, 0.05213462933897972), (5, 0.05241671670228243), (7, 0.055475224275141954), (2, 0.06098463665693998), (16, 0.06162197422236204), (3, 0.06243071798235178), (6, 0.0651865191757679), (52, 0.06599841173738241), (1, 0.15718718245625496), (36, 0.3030109480023384), (18, 0.374211173504591), (53, 0.920085683465004)]
computing accuracy for after removing block 25 . block score: 0.01422475150320679
removed block 25 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014321. All blocks and scores: [(26, 0.014321206486783922), (32, 0.0157251360360533), (47, 0.01581348234321922), (9, 0.01594743854366243), (33, 0.016175352036952972), (43, 0.016194914234802127), (13, 0.016542865429073572), (42, 0.016636511543765664), (40, 0.016900550574064255), (30, 0.01692401454783976), (45, 0.017010100418701768), (23, 0.017073968658223748), (19, 0.017181470757350326), (24, 0.01784460013732314), (46, 0.01793461199849844), (39, 0.018276611575856805), (41, 0.018938244320452213), (22, 0.018944737501442432), (44, 0.018969442462548614), (48, 0.019875064957886934), (11, 0.02028288203291595), (49, 0.022301002871245146), (17, 0.0227236095815897), (14, 0.02277947566471994), (38, 0.02295250166207552), (50, 0.02660952159203589), (37, 0.027367463801056147), (51, 0.032106865430250764), (15, 0.03736387798562646), (12, 0.043142732698470354), (0, 0.045861792750656605), (8, 0.048870425671339035), (4, 0.052134630270302296), (5, 0.052416717633605), (7, 0.05547522520646453), (2, 0.06098463945090771), (16, 0.06162197468802333), (3, 0.062430718913674355), (52, 0.06422236375510693), (6, 0.06518651824444532), (1, 0.15718718245625496), (36, 0.30919431149959564), (18, 0.3742111921310425), (53, 0.9223421886563301)]
computing accuracy for after removing block 26 . block score: 0.014321206486783922
removed block 26 current accuracy 0.9856 loss from initial  0.014399999999999968
training start
training epoch 0 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 1 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 2 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 3 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 4 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 5 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 6 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 7 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.1]
training epoch 8 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 9 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 10 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.985600)
finished training. finished 50 epochs. accuracy 0.9856 topk_dict {'top1': 0.9856}
start iteration 11
[activation diff]: block to remove picked: 47, with score 0.015591. All blocks and scores: [(47, 0.015591378672979772), (9, 0.015947438310831785), (33, 0.016119681764394045), (43, 0.01647080690599978), (13, 0.016542865661904216), (32, 0.016675117425620556), (45, 0.01684827939607203), (40, 0.016965946415439248), (23, 0.017073967959731817), (19, 0.01718146982602775), (42, 0.01737767714075744), (30, 0.017694465583190322), (46, 0.01773152989335358), (24, 0.017844599904492497), (44, 0.018625709228217602), (22, 0.01894473726861179), (39, 0.018995221005752683), (41, 0.019389544147998095), (48, 0.019601588137447834), (11, 0.020282882265746593), (49, 0.022070482606068254), (17, 0.022723608883097768), (14, 0.022779475431889296), (38, 0.023785780416801572), (50, 0.026121150236576796), (37, 0.02803548122756183), (51, 0.0319701861590147), (15, 0.03736387798562646), (12, 0.04314273362979293), (0, 0.045861792750656605), (8, 0.0488704233430326), (4, 0.052134630270302296), (5, 0.052416719030588865), (7, 0.055475222412496805), (2, 0.06098463945090771), (16, 0.06162197422236204), (3, 0.062430718913674355), (52, 0.06296230852603912), (6, 0.0651865154504776), (1, 0.15718717873096466), (36, 0.31919989734888077), (18, 0.3742111809551716), (53, 0.919974647462368)]
computing accuracy for after removing block 47 . block score: 0.015591378672979772
removed block 47 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.015947. All blocks and scores: [(9, 0.015947437612339854), (33, 0.01611968083307147), (43, 0.016470806440338492), (13, 0.016542865429073572), (32, 0.016675117425620556), (45, 0.01684827939607203), (40, 0.016965946182608604), (23, 0.01707396819256246), (19, 0.01718146982602775), (42, 0.017377677373588085), (30, 0.017694465117529035), (46, 0.01773152989335358), (24, 0.01784460060298443), (44, 0.018625709926709533), (22, 0.018944736570119858), (39, 0.018995221238583326), (41, 0.019389544380828738), (11, 0.020282881567254663), (48, 0.02207162883132696), (17, 0.022723609814420342), (14, 0.022779475431889296), (49, 0.023477208334952593), (38, 0.023785779951140285), (50, 0.027219211449846625), (37, 0.02803548169322312), (51, 0.03351395716890693), (15, 0.037363878916949034), (12, 0.04314273362979293), (0, 0.04586179368197918), (8, 0.04887042520567775), (4, 0.05213462980464101), (5, 0.05241671623662114), (7, 0.055475226137787104), (2, 0.060984639916568995), (16, 0.06162197329103947), (3, 0.06243071658536792), (52, 0.06439626775681973), (6, 0.06518652010709047), (1, 0.1571871843189001), (36, 0.31919990479946136), (18, 0.3742111884057522), (53, 0.9626970291137695)]
computing accuracy for after removing block 9 . block score: 0.015947437612339854
removed block 9 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.016096. All blocks and scores: [(32, 0.016096387524157763), (45, 0.01626696577295661), (43, 0.016269845888018608), (33, 0.01637544692493975), (23, 0.016607447061687708), (40, 0.0168795813806355), (46, 0.017053304007276893), (30, 0.017178396694362164), (19, 0.017349787754938006), (24, 0.01750320103019476), (44, 0.017811866477131844), (42, 0.017975983442738652), (13, 0.018235396593809128), (41, 0.018629115540534258), (22, 0.019067520974203944), (39, 0.01935331174172461), (48, 0.020966512383893132), (11, 0.02122950181365013), (14, 0.022726128343492746), (49, 0.023100799415260553), (17, 0.02356058545410633), (38, 0.02391230990178883), (50, 0.025870413053780794), (37, 0.026413641637191176), (51, 0.03238258697092533), (15, 0.037934979889541864), (12, 0.04165834467858076), (0, 0.04586179228499532), (8, 0.04887042427435517), (4, 0.05213462933897972), (5, 0.052416717633605), (7, 0.055475224275141954), (2, 0.06098463851958513), (3, 0.06243071798235178), (52, 0.06280327774584293), (16, 0.06422330066561699), (6, 0.06518651731312275), (1, 0.15718718245625496), (36, 0.3088325262069702), (18, 0.3658624030649662), (53, 0.9575238227844238)]
computing accuracy for after removing block 32 . block score: 0.016096387524157763
removed block 32 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.016016. All blocks and scores: [(43, 0.016015663975849748), (45, 0.016113010817207396), (40, 0.016530798748135567), (23, 0.016607446828857064), (46, 0.017001276602968574), (30, 0.01717839646153152), (19, 0.017349788220599294), (24, 0.01750320103019476), (44, 0.01758742146193981), (33, 0.01765732537023723), (13, 0.018235396593809128), (42, 0.01836430188268423), (41, 0.01858894433826208), (22, 0.019067521207034588), (39, 0.01930249622091651), (48, 0.020728603238239884), (11, 0.0212295011151582), (14, 0.022726127179339528), (49, 0.022927335929125547), (17, 0.023560585221275687), (38, 0.023623194079846144), (50, 0.02546685724519193), (37, 0.02566047408618033), (51, 0.031882936833426356), (15, 0.037934979889541864), (12, 0.04165834281593561), (0, 0.04586179135367274), (8, 0.04887042520567775), (4, 0.05213462794199586), (5, 0.052416715770959854), (7, 0.055475224275141954), (2, 0.06098463898524642), (52, 0.06119305640459061), (3, 0.062430717051029205), (16, 0.06422330345958471), (6, 0.0651865154504776), (1, 0.1571871843189001), (36, 0.3131869360804558), (18, 0.3658623956143856), (53, 0.986202672123909)]
computing accuracy for after removing block 43 . block score: 0.016015663975849748
removed block 43 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.04080000000000006 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.016531. All blocks and scores: [(40, 0.01653079898096621), (23, 0.01660744729451835), (45, 0.016902157803997397), (30, 0.01717839646153152), (19, 0.017349788453429937), (24, 0.01750320103019476), (33, 0.017657326068729162), (13, 0.018235396593809128), (46, 0.01833604951389134), (42, 0.01836430188268423), (44, 0.018507370026782155), (41, 0.01858894433826208), (22, 0.019067521207034588), (39, 0.019302495988085866), (11, 0.021229501347988844), (48, 0.021513469284400344), (14, 0.02272612857632339), (49, 0.0232954490929842), (17, 0.023560584988445044), (38, 0.02362319454550743), (37, 0.025660475250333548), (50, 0.026300600497052073), (51, 0.0323826193343848), (15, 0.037934979889541864), (12, 0.04165834281593561), (0, 0.04586179321631789), (8, 0.04887042613700032), (4, 0.05213462933897972), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.060984639916568995), (52, 0.06122089549899101), (3, 0.06243071611970663), (16, 0.06422330252826214), (6, 0.06518651638180017), (1, 0.15718718245625496), (36, 0.3131869398057461), (18, 0.3658623956143856), (53, 1.0472510606050491)]
computing accuracy for after removing block 40 . block score: 0.01653079898096621
removed block 40 current accuracy 0.9298 loss from initial  0.07020000000000004
since last training loss: 0.05580000000000007 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.016446. All blocks and scores: [(45, 0.01644567516632378), (23, 0.01660744729451835), (30, 0.017178396228700876), (19, 0.017349787522107363), (24, 0.017503200797364116), (33, 0.017657325603067875), (46, 0.018193190218880773), (13, 0.01823539612814784), (44, 0.018392325146123767), (42, 0.019028428476303816), (22, 0.019067521207034588), (39, 0.019302496686577797), (41, 0.01945992512628436), (48, 0.02112151891924441), (11, 0.021229501580819488), (49, 0.022725160466507077), (14, 0.02272612787783146), (17, 0.023560585221275687), (38, 0.02362319454550743), (50, 0.0251889128703624), (37, 0.025660474551841617), (51, 0.031149048591032624), (15, 0.03793498035520315), (12, 0.041658344212919474), (0, 0.045861792750656605), (8, 0.04887042520567775), (4, 0.052134630270302296), (5, 0.052416715770959854), (7, 0.05547522380948067), (52, 0.057828042190521955), (2, 0.06098463712260127), (3, 0.062430718913674355), (16, 0.06422330252826214), (6, 0.06518651731312275), (1, 0.15718717873096466), (36, 0.3131869360804558), (18, 0.3658623993396759), (53, 1.070447251200676)]
computing accuracy for after removing block 45 . block score: 0.01644567516632378
removed block 45 current accuracy 0.9122 loss from initial  0.08779999999999999
since last training loss: 0.07340000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016607. All blocks and scores: [(23, 0.016607447061687708), (30, 0.017178396228700876), (19, 0.017349788453429937), (24, 0.017503201263025403), (33, 0.017657326068729162), (13, 0.018235396593809128), (44, 0.018392324447631836), (46, 0.018523868406191468), (42, 0.019028428476303816), (22, 0.01906752143986523), (39, 0.019302496453747153), (41, 0.019459924893453717), (11, 0.0212295011151582), (48, 0.021385453874245286), (14, 0.02272612787783146), (49, 0.023496739100664854), (17, 0.02356058545410633), (38, 0.02362319501116872), (37, 0.02566047478467226), (50, 0.025855144718661904), (51, 0.030737492721527815), (15, 0.03793497895821929), (12, 0.041658344212919474), (0, 0.045861794613301754), (8, 0.04887042474001646), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.05547522334381938), (52, 0.05644993856549263), (2, 0.06098464038223028), (3, 0.062430718913674355), (16, 0.06422330159693956), (6, 0.0651865191757679), (1, 0.15718717873096466), (36, 0.3131869398057461), (18, 0.3658623918890953), (53, 1.1521297544240952)]
computing accuracy for after removing block 23 . block score: 0.016607447061687708
removed block 23 current accuracy 0.8804 loss from initial  0.11960000000000004
since last training loss: 0.10520000000000007 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.017189. All blocks and scores: [(24, 0.017188638215884566), (33, 0.01728927413932979), (19, 0.01734978798776865), (30, 0.017376618226990104), (44, 0.018123291665688157), (13, 0.018235396593809128), (46, 0.018551092129200697), (22, 0.019067521207034588), (41, 0.019821990514174104), (39, 0.020520461490377784), (42, 0.02057700394652784), (48, 0.021223647752776742), (11, 0.021229500882327557), (14, 0.022726127645000815), (49, 0.02317718672566116), (17, 0.02356058545410633), (38, 0.02453630603849888), (50, 0.025460730073973536), (37, 0.025982010643929243), (51, 0.030619037803262472), (15, 0.037934979889541864), (12, 0.0416583432815969), (0, 0.045861792750656605), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.052416717167943716), (52, 0.055433415342122316), (7, 0.05547522334381938), (2, 0.060984639916568995), (3, 0.06243071798235178), (16, 0.06422330345958471), (6, 0.06518651731312275), (1, 0.15718718245625496), (36, 0.3220418058335781), (18, 0.3658623956143856), (53, 1.1451562196016312)]
computing accuracy for after removing block 24 . block score: 0.017188638215884566
removed block 24 current accuracy 0.8434 loss from initial  0.15659999999999996
since last training loss: 0.1422 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 33, with score 0.016881. All blocks and scores: [(33, 0.016881095245480537), (19, 0.017349788220599294), (44, 0.017830361612141132), (13, 0.018235396593809128), (46, 0.01846640696749091), (30, 0.01858976809307933), (22, 0.019067521207034588), (41, 0.01998015190474689), (48, 0.02092443802393973), (11, 0.021229500882327557), (39, 0.021618139697238803), (42, 0.021670245565474033), (49, 0.02271375129930675), (14, 0.022726128110662103), (17, 0.023560585919767618), (38, 0.024504398927092552), (50, 0.025048252195119858), (37, 0.02640376752242446), (51, 0.030667853774502873), (15, 0.037934978492558), (12, 0.041658342350274324), (0, 0.04586179321631789), (8, 0.0488704270683229), (4, 0.05213462933897972), (5, 0.05241671623662114), (52, 0.054163075517863035), (7, 0.05547522474080324), (2, 0.06098464038223028), (3, 0.06243071798235178), (16, 0.06422330345958471), (6, 0.06518651824444532), (1, 0.1571871843189001), (36, 0.33175234496593475), (18, 0.3658623956143856), (53, 1.1537490785121918)]
computing accuracy for after removing block 33 . block score: 0.016881095245480537
removed block 33 current accuracy 0.8222 loss from initial  0.17779999999999996
since last training loss: 0.1634 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 19, with score 0.017350. All blocks and scores: [(19, 0.017349788220599294), (13, 0.01823539612814784), (44, 0.018404127098619938), (30, 0.01858976809307933), (46, 0.01880270428955555), (22, 0.019067521672695875), (41, 0.020169985480606556), (11, 0.021229502046480775), (48, 0.02137578255496919), (39, 0.02170371008105576), (42, 0.022311690729111433), (14, 0.022726128343492746), (49, 0.022778567858040333), (17, 0.023560584988445044), (38, 0.023721860721707344), (50, 0.025014484068378806), (37, 0.02617480349726975), (51, 0.03072114964015782), (15, 0.03793497942388058), (12, 0.041658344212919474), (0, 0.04586179181933403), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.052416717633605), (52, 0.05387095920741558), (7, 0.05547522287815809), (2, 0.06098463945090771), (3, 0.06243071658536792), (16, 0.06422330066561699), (6, 0.06518651638180017), (1, 0.1571871805936098), (36, 0.3453988693654537), (18, 0.3658623956143856), (53, 1.1763148754835129)]
computing accuracy for after removing block 19 . block score: 0.017349788220599294
removed block 19 current accuracy 0.804 loss from initial  0.19599999999999995
since last training loss: 0.18159999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 13, with score 0.018235. All blocks and scores: [(13, 0.01823539612814784), (44, 0.018631003331393003), (46, 0.018870288506150246), (30, 0.01936570880934596), (22, 0.019633196759968996), (41, 0.021085450891405344), (11, 0.021229501580819488), (48, 0.021270350320264697), (39, 0.021773428423330188), (42, 0.022591188782826066), (14, 0.022726127179339528), (49, 0.02338213357143104), (17, 0.023560585686936975), (38, 0.024066759273409843), (50, 0.024741497123613954), (37, 0.026745253009721637), (51, 0.030232727294787765), (15, 0.03793497942388058), (12, 0.041658343747258186), (0, 0.04586179368197918), (8, 0.04887042660266161), (4, 0.05213462980464101), (5, 0.05241671623662114), (52, 0.05371788889169693), (7, 0.05547522380948067), (2, 0.06098464084789157), (3, 0.06243071611970663), (16, 0.06422330345958471), (6, 0.06518651824444532), (1, 0.1571871805936098), (36, 0.34978847578167915), (18, 0.3658623956143856), (53, 1.1712626069784164)]
computing accuracy for after removing block 13 . block score: 0.01823539612814784
removed block 13 current accuracy 0.7732 loss from initial  0.2268
training start
training epoch 0 val accuracy 0.828 topk_dict {'top1': 0.828} is_best True lr [0.1]
training epoch 1 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best True lr [0.1]
training epoch 2 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best True lr [0.1]
training epoch 3 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.1]
training epoch 4 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 5 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.1]
training epoch 6 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 7 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 8 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 9 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.1]
training epoch 10 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.962600)
finished training. finished 50 epochs. accuracy 0.9626 topk_dict {'top1': 0.9626}
start iteration 22
[activation diff]: block to remove picked: 42, with score 0.040841. All blocks and scores: [(42, 0.04084105556830764), (46, 0.04338884772732854), (39, 0.04396059596911073), (41, 0.04573447024449706), (48, 0.046344191301614046), (44, 0.048220349941402674), (50, 0.04832920292392373), (38, 0.04880838515236974), (11, 0.04913975764065981), (51, 0.04932210315018892), (49, 0.05004666140303016), (37, 0.06084834039211273), (17, 0.06711362209171057), (14, 0.0684623122215271), (52, 0.08249296993017197), (22, 0.08721144497394562), (30, 0.08999335393309593), (15, 0.0958606917411089), (0, 0.1087803365662694), (12, 0.11155330576002598), (8, 0.11905881483107805), (2, 0.12143038492649794), (4, 0.12543393205851316), (7, 0.1255938345566392), (3, 0.1402032356709242), (5, 0.1434948816895485), (16, 0.15715245716273785), (6, 0.16042192094027996), (1, 0.33799247816205025), (18, 0.4858163148164749), (36, 0.6447911411523819), (53, 1.064095988869667)]
computing accuracy for after removing block 42 . block score: 0.04084105556830764
removed block 42 current accuracy 0.9558 loss from initial  0.04420000000000002
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 39, with score 0.043961. All blocks and scores: [(39, 0.04396059364080429), (41, 0.045734469313174486), (46, 0.04583040485158563), (38, 0.04880838701501489), (11, 0.04913975764065981), (48, 0.04945993237197399), (50, 0.05035564862191677), (51, 0.05074174655601382), (44, 0.052307517267763615), (49, 0.05266020214185119), (37, 0.060848338063806295), (17, 0.06711362116038799), (14, 0.06846230942755938), (52, 0.08331209141761065), (22, 0.08721144776791334), (30, 0.08999335765838623), (15, 0.09586068987846375), (0, 0.10878033377230167), (12, 0.11155330389738083), (8, 0.11905881203711033), (2, 0.12143038213253021), (4, 0.12543393019586802), (7, 0.12559383641928434), (3, 0.14020323753356934), (5, 0.1434948742389679), (16, 0.15715246088802814), (6, 0.16042192094027996), (1, 0.33799247816205025), (18, 0.4858163185417652), (36, 0.6447911411523819), (53, 1.099138855934143)]
computing accuracy for after removing block 39 . block score: 0.04396059364080429
removed block 39 current accuracy 0.9488 loss from initial  0.05120000000000002
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 46, with score 0.046712. All blocks and scores: [(46, 0.04671168280765414), (41, 0.0476176175288856), (38, 0.04880838701501489), (11, 0.04913975903764367), (51, 0.050138340797275305), (50, 0.05052349343895912), (48, 0.05057874135673046), (49, 0.05280644493177533), (44, 0.055223900359123945), (37, 0.060848339926451445), (17, 0.06711361836642027), (14, 0.0684623122215271), (52, 0.08159080985933542), (22, 0.08721144590526819), (30, 0.08999335393309593), (15, 0.09586068987846375), (0, 0.10878033097833395), (12, 0.11155330296605825), (8, 0.11905881110578775), (2, 0.12143038213253021), (4, 0.1254339311271906), (7, 0.1255938382819295), (3, 0.1402032356709242), (5, 0.1434948779642582), (16, 0.157152459025383), (6, 0.1604219153523445), (1, 0.33799247816205025), (18, 0.4858163073658943), (36, 0.6447911486029625), (53, 1.0895294696092606)]
computing accuracy for after removing block 46 . block score: 0.04671168280765414
removed block 46 current accuracy 0.9354 loss from initial  0.06459999999999999
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.047618. All blocks and scores: [(41, 0.04761761799454689), (38, 0.04880838608369231), (11, 0.04913975950330496), (51, 0.05259457370266318), (50, 0.05477477656677365), (44, 0.055223902221769094), (48, 0.05583692900836468), (49, 0.05631919903680682), (37, 0.06084833852946758), (17, 0.06711361929774284), (14, 0.06846231129020452), (52, 0.08397207222878933), (22, 0.08721144590526819), (30, 0.08999335207045078), (15, 0.09586068894714117), (0, 0.10878033190965652), (12, 0.1115533011034131), (8, 0.11905881203711033), (2, 0.12143037747591734), (4, 0.12543393205851316), (7, 0.12559383548796177), (3, 0.14020323753356934), (5, 0.14349487610161304), (16, 0.1571524627506733), (6, 0.1604219153523445), (1, 0.33799248933792114), (18, 0.4858163148164749), (36, 0.6447911635041237), (53, 1.1312423199415207)]
computing accuracy for after removing block 41 . block score: 0.04761761799454689
removed block 41 current accuracy 0.921 loss from initial  0.07899999999999996
since last training loss: 0.04159999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.048808. All blocks and scores: [(38, 0.04880838701501489), (11, 0.049139758571982384), (51, 0.052928189281374216), (50, 0.05423743091523647), (48, 0.055347698740661144), (44, 0.05870739556849003), (49, 0.059779294300824404), (37, 0.06084833852946758), (17, 0.06711361929774284), (14, 0.06846231035888195), (52, 0.08331103436648846), (22, 0.08721144683659077), (30, 0.08999335207045078), (15, 0.09586068987846375), (0, 0.10878033190965652), (12, 0.11155330669134855), (8, 0.11905881203711033), (2, 0.12143038213253021), (4, 0.1254339339211583), (7, 0.12559383362531662), (3, 0.1402032356709242), (5, 0.1434948742389679), (16, 0.1571524553000927), (6, 0.16042191348969936), (1, 0.33799248188734055), (18, 0.4858163148164749), (36, 0.6447911635041237), (53, 1.163011834025383)]
computing accuracy for after removing block 38 . block score: 0.04880838701501489
removed block 38 current accuracy 0.8992 loss from initial  0.1008
since last training loss: 0.06340000000000001 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 11, with score 0.049140. All blocks and scores: [(11, 0.04913975764065981), (51, 0.05231928080320358), (50, 0.05394328525289893), (48, 0.05432163272053003), (44, 0.05958229396492243), (49, 0.060506003908813), (37, 0.06084833852946758), (17, 0.06711362116038799), (14, 0.06846231035888195), (52, 0.08184049930423498), (22, 0.08721144776791334), (30, 0.08999335393309593), (15, 0.09586068615317345), (0, 0.1087803328409791), (12, 0.1115533048287034), (8, 0.11905881203711033), (2, 0.12143037747591734), (4, 0.12543393205851316), (7, 0.1255938345566392), (3, 0.14020323753356934), (5, 0.14349487610161304), (16, 0.15715246088802814), (6, 0.1604219190776348), (1, 0.33799247071146965), (18, 0.485816303640604), (36, 0.6447911411523819), (53, 1.1755739152431488)]
computing accuracy for after removing block 11 . block score: 0.04913975764065981
removed block 11 current accuracy 0.9016 loss from initial  0.09840000000000004
since last training loss: 0.061000000000000054 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.051074. All blocks and scores: [(51, 0.05107418214902282), (50, 0.05258074961602688), (48, 0.05442194966599345), (37, 0.05848001595586538), (44, 0.059155084658414125), (49, 0.06124654272571206), (17, 0.0697580948472023), (14, 0.07089216448366642), (52, 0.07993974629789591), (22, 0.08503236621618271), (30, 0.08660467434674501), (15, 0.10133741796016693), (0, 0.10878033004701138), (8, 0.11905881483107805), (12, 0.12094012554734945), (2, 0.12143037840723991), (4, 0.12543393019586802), (7, 0.12559383362531662), (3, 0.1402032356709242), (5, 0.14349487610161304), (6, 0.16042191721498966), (16, 0.16782338730990887), (1, 0.33799248188734055), (18, 0.47024526447057724), (36, 0.6292268708348274), (53, 1.157002717256546)]
computing accuracy for after removing block 51 . block score: 0.05107418214902282
removed block 51 current accuracy 0.861 loss from initial  0.139
since last training loss: 0.10160000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 50, with score 0.052581. All blocks and scores: [(50, 0.05258075054734945), (48, 0.054421949200332165), (37, 0.058480015490204096), (44, 0.05915508372709155), (49, 0.06124654319137335), (17, 0.06975809298455715), (14, 0.07089216448366642), (22, 0.08503236528486013), (30, 0.08660467434674501), (52, 0.08733030967414379), (15, 0.10133741796016693), (0, 0.10878032818436623), (8, 0.11905881203711033), (12, 0.12094013206660748), (2, 0.12143038120120764), (4, 0.1254339311271906), (7, 0.12559383921325207), (3, 0.14020323939621449), (5, 0.14349487982690334), (6, 0.1604219190776348), (16, 0.16782338730990887), (1, 0.33799246698617935), (18, 0.47024525701999664), (36, 0.6292268633842468), (53, 1.3121079504489899)]
computing accuracy for after removing block 50 . block score: 0.05258075054734945
removed block 50 current accuracy 0.7988 loss from initial  0.20120000000000005
since last training loss: 0.16380000000000006 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 48, with score 0.054422. All blocks and scores: [(48, 0.05442195013165474), (37, 0.05848001502454281), (44, 0.059155084658414125), (49, 0.06124654412269592), (17, 0.0697580948472023), (14, 0.07089216820895672), (22, 0.08503236714750528), (30, 0.08660467248409986), (52, 0.09274200443178415), (15, 0.10133741423487663), (0, 0.10878033190965652), (8, 0.11905881110578775), (12, 0.1209401311352849), (2, 0.12143037840723991), (4, 0.1254339311271906), (7, 0.12559383269399405), (3, 0.1402032356709242), (5, 0.14349487610161304), (6, 0.1604219190776348), (16, 0.16782338917255402), (1, 0.33799248933792114), (18, 0.47024525329470634), (36, 0.629226878285408), (53, 1.5033578425645828)]
computing accuracy for after removing block 48 . block score: 0.05442195013165474
removed block 48 current accuracy 0.7566 loss from initial  0.24339999999999995
since last training loss: 0.20599999999999996 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 37, with score 0.058480. All blocks and scores: [(37, 0.05848001455888152), (44, 0.059155084658414125), (17, 0.06975809298455715), (14, 0.07089216448366642), (49, 0.07108236383646727), (22, 0.08503236528486013), (30, 0.08660467341542244), (52, 0.09654809348285198), (15, 0.1013374188914895), (0, 0.10878033190965652), (8, 0.11905881203711033), (12, 0.12094013299793005), (2, 0.12143038120120764), (4, 0.12543393205851316), (7, 0.12559383735060692), (3, 0.14020323753356934), (5, 0.1434948779642582), (6, 0.16042191721498966), (16, 0.16782338358461857), (1, 0.33799247816205025), (18, 0.47024525701999664), (36, 0.6292268559336662), (53, 1.5249045938253403)]
computing accuracy for after removing block 37 . block score: 0.05848001455888152
removed block 37 current accuracy 0.7244 loss from initial  0.27559999999999996
since last training loss: 0.23819999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 44, with score 0.057867. All blocks and scores: [(44, 0.057866516057401896), (49, 0.06783493235707283), (17, 0.06975809391587973), (14, 0.07089216634631157), (22, 0.08503236528486013), (30, 0.08660467341542244), (52, 0.09373292420059443), (15, 0.1013374188914895), (0, 0.10878033470362425), (8, 0.11905881483107805), (12, 0.12094013206660748), (2, 0.12143037561327219), (4, 0.12543393019586802), (7, 0.12559383269399405), (3, 0.14020323753356934), (5, 0.14349487982690334), (6, 0.1604219190776348), (16, 0.16782338730990887), (1, 0.33799247443675995), (18, 0.47024526074528694), (36, 0.6292268708348274), (53, 1.5271389037370682)]
computing accuracy for after removing block 44 . block score: 0.057866516057401896
removed block 44 current accuracy 0.6556 loss from initial  0.34440000000000004
training start
training epoch 0 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 1 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 2 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 4 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 5 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 7 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 8 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 9 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 10 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 33
[activation diff]: block to remove picked: 17, with score 0.090452. All blocks and scores: [(17, 0.0904521644115448), (52, 0.099073919467628), (14, 0.10150929819792509), (49, 0.10913675278425217), (15, 0.11112990416586399), (0, 0.12810692936182022), (22, 0.128657765686512), (4, 0.14467485807836056), (30, 0.14670440554618835), (8, 0.15754620358347893), (12, 0.15986932069063187), (2, 0.16216410137712955), (3, 0.16654334031045437), (7, 0.17160651832818985), (5, 0.17231634445488453), (16, 0.19491397961974144), (6, 0.19566186517477036), (1, 0.37927762418985367), (36, 0.4973549470305443), (18, 0.5796852484345436), (53, 1.1943944245576859)]
computing accuracy for after removing block 17 . block score: 0.0904521644115448
removed block 17 current accuracy 0.9324 loss from initial  0.0676
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 52, with score 0.097022. All blocks and scores: [(52, 0.09702193271368742), (14, 0.10150930099189281), (49, 0.10792413167655468), (15, 0.11112990509718657), (22, 0.12649539206176996), (0, 0.12810692936182022), (30, 0.13923526741564274), (4, 0.1446748562157154), (8, 0.15754620544612408), (12, 0.15986932441592216), (2, 0.16216410137712955), (3, 0.16654334217309952), (7, 0.1716065164655447), (5, 0.17231633886694908), (16, 0.19491398707032204), (6, 0.19566186517477036), (1, 0.37927763164043427), (36, 0.48747510462999344), (18, 0.5719001293182373), (53, 1.1826095283031464)]
computing accuracy for after removing block 52 . block score: 0.09702193271368742
removed block 52 current accuracy 0.8608 loss from initial  0.1392
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 14, with score 0.101509. All blocks and scores: [(14, 0.10150930006057024), (49, 0.10792413912713528), (15, 0.11112990695983171), (22, 0.1264953901991248), (0, 0.12810693122446537), (30, 0.1392352692782879), (4, 0.14467486180365086), (8, 0.15754620544612408), (12, 0.15986932069063187), (2, 0.1621641032397747), (3, 0.16654334217309952), (7, 0.17160651460289955), (5, 0.17231634259223938), (16, 0.1949139814823866), (6, 0.1956618670374155), (1, 0.37927763164043427), (36, 0.48747507855296135), (18, 0.5719001367688179), (53, 0.9402023106813431)]
computing accuracy for after removing block 14 . block score: 0.10150930006057024
removed block 14 current accuracy 0.8462 loss from initial  0.15380000000000005
since last training loss: 0.09440000000000004 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 49, with score 0.107090. All blocks and scores: [(49, 0.10708975605666637), (15, 0.1195614505559206), (22, 0.121769561432302), (0, 0.1281069340184331), (30, 0.13200410082936287), (4, 0.14467485435307026), (8, 0.15754620358347893), (12, 0.15986931882798672), (2, 0.16216410137712955), (3, 0.16654333844780922), (7, 0.17160652205348015), (5, 0.17231633886694908), (16, 0.19353903643786907), (6, 0.1956618707627058), (1, 0.37927763536572456), (36, 0.4825190380215645), (18, 0.55782151222229), (53, 0.931471548974514)]
computing accuracy for after removing block 49 . block score: 0.10708975605666637
removed block 49 current accuracy 0.64 loss from initial  0.36
since last training loss: 0.3006 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 15, with score 0.119561. All blocks and scores: [(15, 0.11956145334988832), (22, 0.1217695577070117), (0, 0.12810692936182022), (30, 0.13200410269200802), (4, 0.14467485435307026), (8, 0.15754620358347893), (12, 0.15986932255327702), (2, 0.162164106965065), (3, 0.16654333844780922), (7, 0.17160651460289955), (5, 0.17231633886694908), (16, 0.19353903271257877), (6, 0.19566186517477036), (1, 0.37927762046456337), (36, 0.482519019395113), (18, 0.55782151222229), (53, 1.2983593940734863)]
computing accuracy for after removing block 15 . block score: 0.11956145334988832
removed block 15 current accuracy 0.6084 loss from initial  0.39159999999999995
since last training loss: 0.33219999999999994 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 22, with score 0.115787. All blocks and scores: [(22, 0.11578674335032701), (30, 0.12123452499508858), (0, 0.12810693122446537), (4, 0.1446748562157154), (8, 0.15754620544612408), (12, 0.15986931882798672), (2, 0.16216410137712955), (3, 0.16654334217309952), (7, 0.171606520190835), (5, 0.17231634445488453), (6, 0.1956618595868349), (16, 0.2129455041140318), (1, 0.37927762418985367), (36, 0.4729972258210182), (18, 0.533501461148262), (53, 1.2339450120925903)]
computing accuracy for after removing block 22 . block score: 0.11578674335032701
removed block 22 current accuracy 0.5324 loss from initial  0.4676
since last training loss: 0.4082 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 30, with score 0.115713. All blocks and scores: [(30, 0.11571258679032326), (0, 0.12810692749917507), (4, 0.1446748562157154), (8, 0.15754620544612408), (12, 0.15986932627856731), (2, 0.1621641032397747), (3, 0.16654334217309952), (7, 0.171606520190835), (5, 0.17231634072959423), (6, 0.19566186144948006), (16, 0.2129455003887415), (1, 0.37927762418985367), (36, 0.4875495582818985), (18, 0.5335014536976814), (53, 1.4533583521842957)]
computing accuracy for after removing block 30 . block score: 0.11571258679032326
removed block 30 current accuracy 0.3962 loss from initial  0.6038
since last training loss: 0.5444 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 0, with score 0.128107. All blocks and scores: [(0, 0.12810692749917507), (4, 0.1446748599410057), (8, 0.15754620730876923), (12, 0.15986932069063187), (2, 0.1621640995144844), (3, 0.16654334217309952), (7, 0.1716065239161253), (5, 0.17231634259223938), (6, 0.19566185772418976), (16, 0.21294550225138664), (1, 0.37927763164043427), (18, 0.5335014462471008), (36, 0.5663459077477455), (53, 2.0622403621673584)]
computing accuracy for after removing block 0 . block score: 0.12810692749917507
removed block 0 current accuracy 0.4138 loss from initial  0.5862
since last training loss: 0.5267999999999999 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 4, with score 0.137700. All blocks and scores: [(4, 0.13769991137087345), (3, 0.14559312909841537), (8, 0.15150525979697704), (5, 0.15671002306044102), (12, 0.16456685401499271), (2, 0.1873722318559885), (6, 0.19489244371652603), (7, 0.19569886848330498), (16, 0.2060326784849167), (1, 0.3806033991277218), (18, 0.49885959550738335), (36, 0.5396331250667572), (53, 1.8771081268787384)]
computing accuracy for after removing block 4 . block score: 0.13769991137087345
removed block 4 current accuracy 0.3774 loss from initial  0.6226
since last training loss: 0.5631999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 8, with score 0.140896. All blocks and scores: [(8, 0.1408955529332161), (3, 0.14559313096106052), (5, 0.15943104028701782), (12, 0.1595984287559986), (7, 0.17502127960324287), (16, 0.18201641365885735), (2, 0.18737223744392395), (6, 0.21051543951034546), (1, 0.3806033991277218), (18, 0.4414067491889), (36, 0.5113999173045158), (53, 1.8623365610837936)]
computing accuracy for after removing block 8 . block score: 0.1408955529332161
removed block 8 current accuracy 0.253 loss from initial  0.747
since last training loss: 0.6876 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 3, with score 0.145593. All blocks and scores: [(3, 0.14559313282370567), (5, 0.15943104028701782), (7, 0.17502128146588802), (2, 0.1873722393065691), (12, 0.19909833185374737), (16, 0.20732487738132477), (6, 0.21051543578505516), (1, 0.3806034103035927), (18, 0.39721299335360527), (36, 0.5025241151452065), (53, 2.030486434698105)]
computing accuracy for after removing block 3 . block score: 0.14559313282370567
removed block 3 current accuracy 0.2376 loss from initial  0.7624
since last training loss: 0.703 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 7, with score 0.157430. All blocks and scores: [(7, 0.1574297994375229), (5, 0.16229422949254513), (16, 0.1667086835950613), (2, 0.1873722393065691), (12, 0.2028384879231453), (6, 0.22671154513955116), (18, 0.35786790400743484), (1, 0.3806034065783024), (36, 0.4516816660761833), (53, 1.9350081384181976)]
computing accuracy for after removing block 7 . block score: 0.1574297994375229
removed block 7 current accuracy 0.1922 loss from initial  0.8078
training start
training epoch 0 val accuracy 0.7552 topk_dict {'top1': 0.7552} is_best True lr [0.1]
training epoch 1 val accuracy 0.7988 topk_dict {'top1': 0.7988} is_best True lr [0.1]
training epoch 2 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best True lr [0.1]
training epoch 3 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best False lr [0.1]
training epoch 4 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best True lr [0.1]
training epoch 5 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 6 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.1]
training epoch 7 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best True lr [0.1]
training epoch 8 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 9 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best False lr [0.1]
training epoch 10 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.908000)
finished training. finished 50 epochs. accuracy 0.908 topk_dict {'top1': 0.908}
