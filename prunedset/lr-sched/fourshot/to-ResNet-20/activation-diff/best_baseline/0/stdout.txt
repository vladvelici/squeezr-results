start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.00706199643900618), (32, 0.00923305086325854), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013312276685610414), (29, 0.013541154214181006), (35, 0.01601846213452518), (26, 0.016037590336054564), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020232456969097257), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.02237953501753509), (41, 0.022826648084446788), (44, 0.023395079653710127), (40, 0.024025025311857462), (45, 0.02429541083984077), (21, 0.02492459723725915), (22, 0.025168768130242825), (48, 0.02534125978127122), (24, 0.025899537140503526), (50, 0.026409971993416548), (42, 0.0266741004306823), (20, 0.02685900661163032), (49, 0.02703716466203332), (47, 0.029306469717994332), (39, 0.031570713268592954), (38, 0.031637872103601694), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.037960262037813663), (51, 0.04173417296260595), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.05722427926957607), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734331995249), (52, 0.06862937472760677), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43758000060915947), (18, 0.5108213126659393), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.00706199643900618
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050514012575), (30, 0.010039400425739586), (31, 0.010361599852330983), (34, 0.01313394762109965), (29, 0.013541154563426971), (26, 0.016037590336054564), (35, 0.01616928935982287), (28, 0.017728675855323672), (27, 0.019127049017697573), (43, 0.020072476472705603), (46, 0.020731385797262192), (25, 0.021972602466121316), (41, 0.02234709239564836), (23, 0.022379534784704447), (44, 0.023235687287524343), (40, 0.023841066751629114), (45, 0.02396554173901677), (48, 0.024917916394770145), (21, 0.024924597702920437), (22, 0.025168768130242825), (50, 0.02584081282839179), (24, 0.025899536907672882), (42, 0.026315324008464813), (49, 0.026655675377696753), (20, 0.02685900661163032), (47, 0.028728798031806946), (39, 0.03131764242425561), (38, 0.031380362808704376), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.038025843910872936), (51, 0.041223939042538404), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (52, 0.06745154969394207), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.43538710847496986), (18, 0.5108213052153587), (53, 0.8222573697566986)]
computing accuracy for after removing block 32 . block score: 0.009233050514012575
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.01276523305568844), (29, 0.013541154563426971), (35, 0.015992750879377127), (26, 0.01603759010322392), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020075131440535188), (46, 0.02084140619263053), (25, 0.021972602931782603), (41, 0.022319767391309142), (23, 0.02237953571602702), (44, 0.023154050577431917), (40, 0.023885683389380574), (45, 0.024071688996627927), (48, 0.02487746556289494), (21, 0.024924597470089793), (22, 0.025168767664581537), (50, 0.025691178161650896), (24, 0.025899537140503526), (42, 0.026123748160898685), (49, 0.026479422114789486), (20, 0.026859008008614182), (47, 0.028693132800981402), (38, 0.031236795941367745), (39, 0.03129529138095677), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03837669128552079), (51, 0.04111403366550803), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.05892290314659476), (11, 0.059249130077660084), (17, 0.060956849716603756), (0, 0.06300981156527996), (1, 0.06676734145730734), (52, 0.06700456328690052), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.43640001118183136), (18, 0.5108213052153587), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372366979718), (34, 0.012387836701236665), (29, 0.013541154563426971), (35, 0.016008096048608422), (26, 0.016037590568885207), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.02008363325148821), (46, 0.020704444963485003), (25, 0.021972603164613247), (41, 0.02225319715216756), (23, 0.02237953571602702), (44, 0.023267761105671525), (40, 0.024013880407437682), (45, 0.024092993000522256), (48, 0.024665279779583216), (21, 0.02492459793575108), (22, 0.025168768130242825), (50, 0.025459734722971916), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.026287756394594908), (20, 0.026859008008614182), (47, 0.028363423887640238), (38, 0.031047646421939135), (39, 0.03138077259063721), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628596760332584), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.05892290221527219), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980877131224), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4389924593269825), (18, 0.5108212903141975), (53, 0.8391561433672905)]
computing accuracy for after removing block 31 . block score: 0.010375372366979718
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619897678494), (29, 0.01354115444701165), (26, 0.016037590336054564), (35, 0.016057363245636225), (28, 0.017728675855323672), (27, 0.019127048552036285), (43, 0.020049350103363395), (46, 0.020552986999973655), (25, 0.02197260269895196), (41, 0.022067483980208635), (23, 0.022379535250365734), (44, 0.022979132598266006), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.02438612305559218), (21, 0.02492459793575108), (50, 0.025042241672053933), (22, 0.025168768130242825), (42, 0.02541450783610344), (49, 0.02584269898943603), (24, 0.025899536907672882), (20, 0.02685900661163032), (47, 0.02805073419585824), (38, 0.031040059635415673), (39, 0.03150080284103751), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03911284822970629), (51, 0.040246272925287485), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980923697352), (52, 0.0648620892316103), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4381278343498707), (18, 0.5108213126659393), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489619897678494
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154796257615), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020503456238657236), (46, 0.0207253226544708), (25, 0.021972603164613247), (23, 0.022379535483196378), (41, 0.02245262893848121), (44, 0.023364474531263113), (48, 0.024290354922413826), (45, 0.024438712745904922), (40, 0.024470558622851968), (21, 0.024924598168581724), (50, 0.02504217205569148), (22, 0.025168768363073468), (49, 0.025875970255583525), (24, 0.025899537606164813), (42, 0.02620540652424097), (20, 0.02685900731012225), (47, 0.028178582899272442), (15, 0.03192339139059186), (38, 0.032083500642329454), (7, 0.03228544583544135), (39, 0.03233744017779827), (19, 0.0326285962946713), (51, 0.03994725923985243), (37, 0.04073968296870589), (9, 0.04340187832713127), (6, 0.046609030570834875), (4, 0.047493684105575085), (14, 0.04783663293346763), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300981063395739), (52, 0.06433630269020796), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667386744171381), (36, 0.45053431391716003), (18, 0.5108212977647781), (53, 0.844320073723793)]
computing accuracy for after removing block 29 . block score: 0.013541154796257615
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470607835799456), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02004686719737947), (46, 0.020376993343234062), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.02237953571602702), (44, 0.02302833693102002), (48, 0.02377187693491578), (40, 0.023930813651531935), (45, 0.024178662803024054), (50, 0.02439029817469418), (21, 0.024924597470089793), (22, 0.0251687690615654), (42, 0.025188251165673137), (49, 0.025361528154462576), (24, 0.025899537140503526), (20, 0.02685900777578354), (47, 0.027363280532881618), (38, 0.03136561927385628), (15, 0.03192339185625315), (39, 0.03212768491357565), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.038935923017561436), (37, 0.040206342935562134), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846331849694), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684785395861), (52, 0.062328549567610025), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4444202110171318), (18, 0.5108213052153587), (53, 0.8537912219762802)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365447320044), (28, 0.017088500317186117), (27, 0.018882447155192494), (43, 0.019595165504142642), (46, 0.020073581021279097), (41, 0.020961585687473416), (25, 0.021972602233290672), (23, 0.022379535948857665), (44, 0.022814956260845065), (48, 0.02312816074118018), (40, 0.023345195688307285), (50, 0.023756146896630526), (42, 0.023847303353250027), (45, 0.02387388003990054), (21, 0.02492459863424301), (49, 0.02496031578630209), (22, 0.025168768130242825), (24, 0.025899537606164813), (47, 0.026855542324483395), (20, 0.026859007077291608), (38, 0.030424013966694474), (39, 0.03151404415257275), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03782488079741597), (37, 0.03936835238710046), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.054548462852835655), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912728369236), (52, 0.06033282168209553), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4360685609281063), (18, 0.5108213052153587), (53, 0.8749377429485321)]
computing accuracy for after removing block 35 . block score: 0.015597365447320044
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500084355474), (43, 0.018555945483967662), (27, 0.018882446689531207), (46, 0.019160084892064333), (41, 0.019424294587224722), (48, 0.02146727265790105), (25, 0.02197260269895196), (44, 0.022026916733011603), (40, 0.022179660852998495), (42, 0.02220643009059131), (50, 0.022256129421293736), (23, 0.022379535250365734), (45, 0.022931481013074517), (49, 0.023708513006567955), (21, 0.024924598168581724), (22, 0.025168768130242825), (47, 0.02582913963124156), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.028956545749679208), (39, 0.029667829163372517), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03600902669131756), (37, 0.03651238838210702), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663246780634), (2, 0.05454846564680338), (52, 0.05610728682950139), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924913054332137), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.41757645085453987), (18, 0.5108212977647781), (53, 0.9117145091295242)]
computing accuracy for after removing block 28 . block score: 0.017088500084355474
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102707609534), (41, 0.018849018262699246), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.02143200463615358), (40, 0.021832421887665987), (44, 0.021840531146153808), (50, 0.021869863849133253), (25, 0.02197260200046003), (23, 0.02237953501753509), (45, 0.02249284810386598), (49, 0.023123498307541013), (21, 0.02492459863424301), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899537606164813), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.0292069090064615), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03545433655381203), (37, 0.035977639723569155), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846378415823), (52, 0.05469645792618394), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.0803448399528861), (16, 0.08408283162862062), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 0.9246632903814316)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.01888244692236185), (46, 0.019302030559629202), (42, 0.02143200417049229), (48, 0.02154484367929399), (40, 0.021832421189174056), (50, 0.02194626978598535), (25, 0.021972602931782603), (23, 0.02237953571602702), (49, 0.02300686971284449), (44, 0.023108509834855795), (45, 0.023535606916993856), (21, 0.024924598168581724), (22, 0.025168767431750894), (47, 0.025820445735007524), (24, 0.02589953667484224), (20, 0.02685900661163032), (38, 0.028114069951698184), (39, 0.02920690947212279), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.035091488622128963), (37, 0.03597763925790787), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663246780634), (52, 0.05332902958616614), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249126352369785), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 0.9678284153342247)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 1 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 2 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 3 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 4 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 5 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 6 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 7 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 8 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.1]
training epoch 9 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 10 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447155192494), (46, 0.019070088397711515), (48, 0.020678168861195445), (50, 0.021344397217035294), (40, 0.021832421189174056), (25, 0.021972602931782603), (42, 0.02198694064281881), (23, 0.022379535948857665), (49, 0.022534748073667288), (45, 0.02392991748638451), (44, 0.02405400271527469), (21, 0.024924597702920437), (22, 0.025168768130242825), (24, 0.025899537606164813), (47, 0.026043937308713794), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.0292069090064615), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.033794480841606855), (37, 0.035977637860924006), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.05047609470784664), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.05892290035262704), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108212977647781), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882447155192494
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.019989707274362445), (50, 0.020775062032043934), (40, 0.021085952641442418), (42, 0.021369647467508912), (49, 0.021910029696300626), (25, 0.021972602931782603), (23, 0.022379535250365734), (44, 0.02323931222781539), (45, 0.02358530811034143), (21, 0.02492459863424301), (47, 0.025076947640627623), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.026859006145969033), (38, 0.02718336065299809), (39, 0.028580759186297655), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.03262859536334872), (51, 0.032814259408041835), (37, 0.03542024455964565), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.0478366338647902), (52, 0.048523631412535906), (2, 0.05454846704378724), (3, 0.0572242783382535), (13, 0.0589229017496109), (11, 0.05924912681803107), (17, 0.06095685064792633), (0, 0.06300980877131224), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.4065233953297138), (18, 0.5108212903141975), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560836449265), (50, 0.020831162575632334), (40, 0.02108595333993435), (42, 0.021369647700339556), (25, 0.021972602931782603), (23, 0.022379535948857665), (49, 0.0225369893014431), (44, 0.02323931222781539), (45, 0.023585308576002717), (21, 0.024924597702920437), (22, 0.02516876789741218), (24, 0.02589953737333417), (47, 0.026583049213513732), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03285081218928099), (37, 0.03542024362832308), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.04812479764223099), (2, 0.05454846378415823), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980737432837), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.153771162033081)]
computing accuracy for after removing block 48 . block score: 0.020327560836449265
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952408611774), (42, 0.02136964723467827), (25, 0.021972603164613247), (23, 0.022379535483196378), (50, 0.02247006236575544), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.024924598168581724), (22, 0.025168768130242825), (49, 0.025234101805835962), (24, 0.025899537140503526), (47, 0.02658304898068309), (20, 0.026859006844460964), (38, 0.027183360187336802), (39, 0.02858075825497508), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03296921122819185), (37, 0.03542024362832308), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.05089045176282525), (2, 0.05454846424981952), (3, 0.05722428020089865), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952408611774
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968681201338768), (50, 0.021284765796735883), (25, 0.021972603164613247), (23, 0.022379535483196378), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.024500869447365403), (21, 0.024924598168581724), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026519699255004525), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075825497508), (15, 0.031923390459269285), (51, 0.032220850232988596), (7, 0.03228544723242521), (19, 0.032628594897687435), (37, 0.03542024316266179), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368177726865), (14, 0.0478366338647902), (52, 0.04885757248848677), (2, 0.054548466112464666), (3, 0.05722427973523736), (13, 0.058922900818288326), (11, 0.05924912774935365), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.1066738748922944), (36, 0.4065233916044235), (18, 0.5108213052153587), (53, 1.3718615621328354)]
computing accuracy for after removing block 42 . block score: 0.020968681201338768
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658768743277), (25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.023761966032907367), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.02492459793575108), (22, 0.02516876789741218), (24, 0.0258995380718261), (47, 0.026220474625006318), (20, 0.026859008008614182), (38, 0.027183360420167446), (39, 0.028580758487805724), (51, 0.03127906681038439), (15, 0.03192339092493057), (7, 0.032285445369780064), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.04340187879279256), (52, 0.04610171029344201), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.04783663293346763), (2, 0.05454846378415823), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408283069729805), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4065234139561653), (18, 0.5108213052153587), (53, 1.417823389172554)]
computing accuracy for after removing block 50 . block score: 0.021202658768743277
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.02237953501753509), (45, 0.023761967197060585), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924598168581724), (22, 0.0251687690615654), (24, 0.02589953737333417), (47, 0.026220474625006318), (20, 0.02685900731012225), (38, 0.02718335995450616), (39, 0.028580758022144437), (15, 0.03192339185625315), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.03344302112236619), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.05265179416164756), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832043766975), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.6287680864334106)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535948857665), (45, 0.0233820837456733), (49, 0.023860316490754485), (44, 0.023948066402226686), (21, 0.02492459793575108), (22, 0.025168767431750894), (47, 0.025361904175952077), (24, 0.02589953737333417), (38, 0.02653320482932031), (20, 0.026859008008614182), (39, 0.02847280679270625), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.032473248429596424), (19, 0.03262859443202615), (37, 0.034854767844080925), (9, 0.043401879258453846), (6, 0.04660903010517359), (4, 0.0474936836399138), (14, 0.047836633399128914), (52, 0.05042571201920509), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249129611998796), (17, 0.060956848319619894), (0, 0.06300980830565095), (1, 0.06676734425127506), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667386651039124), (36, 0.3996613621711731), (18, 0.5108213052153587), (53, 1.6311722695827484)]
computing accuracy for after removing block 23 . block score: 0.022379535948857665
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.023563285125419497), (45, 0.02358233160339296), (49, 0.023707158165052533), (24, 0.02455138461664319), (47, 0.02468883036635816), (21, 0.02492459793575108), (22, 0.025168768595904112), (38, 0.026409980142489076), (20, 0.026859007077291608), (39, 0.02843296923674643), (15, 0.03192339185625315), (7, 0.03228544630110264), (51, 0.03235368151217699), (19, 0.032628596760332584), (37, 0.03590833768248558), (9, 0.04340187879279256), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.0478366338647902), (52, 0.04885636828839779), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.059249126352369785), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.40237870812416077), (18, 0.5108212977647781), (53, 1.6179482638835907)]
computing accuracy for after removing block 44 . block score: 0.023563285125419497
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246752098202705), (49, 0.02354176272638142), (24, 0.02455138391815126), (21, 0.024924597702920437), (22, 0.025168767664581537), (47, 0.025985258864238858), (38, 0.026409980608150363), (20, 0.02685900777578354), (39, 0.02843296923674643), (15, 0.03192339139059186), (51, 0.0320491255261004), (7, 0.0322854476980865), (19, 0.0326285962946713), (37, 0.03590833721682429), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836634796112776), (52, 0.048162917606532574), (2, 0.054548462852835655), (3, 0.05722427647560835), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.40237870067358017), (18, 0.5108212977647781), (53, 1.7482215017080307)]
computing accuracy for after removing block 45 . block score: 0.023246752098202705
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157052161172032), (24, 0.024551384150981903), (21, 0.024924597702920437), (22, 0.025168768828734756), (38, 0.02640997967682779), (20, 0.026859006844460964), (47, 0.027429412817582488), (39, 0.02843296923674643), (51, 0.03189300140365958), (15, 0.03192339278757572), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.03590833814814687), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.047493682242929935), (14, 0.04783663293346763), (52, 0.04907965334132314), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049571871758), (5, 0.10667387396097183), (36, 0.40237871557474136), (18, 0.5108212903141975), (53, 1.8955670148134232)]
computing accuracy for after removing block 49 . block score: 0.024157052161172032
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.1]
training epoch 1 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.1]
training epoch 2 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.1]
training epoch 3 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.1]
training epoch 5 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 8 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 9 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.1]
training epoch 10 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.959000)
finished training. finished 50 epochs. accuracy 0.959 topk_dict {'top1': 0.959}
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.059644. All blocks and scores: [(20, 0.05964371655136347), (19, 0.060223518405109644), (15, 0.06382488738745451), (38, 0.06469987984746695), (51, 0.06625325605273247), (22, 0.06664757896214724), (7, 0.06684950739145279), (21, 0.06938802823424339), (39, 0.0701439967378974), (37, 0.0716686025261879), (24, 0.07397504430264235), (47, 0.07586294133216143), (52, 0.07828506920486689), (9, 0.08255517855286598), (6, 0.08425294421613216), (4, 0.08493323624134064), (14, 0.08795285504311323), (11, 0.09452408831566572), (2, 0.09495358541607857), (0, 0.10038331337273121), (3, 0.10200550314038992), (17, 0.10638629365712404), (13, 0.11259697191417217), (1, 0.11840636376291513), (8, 0.1283833011984825), (10, 0.14834942668676376), (12, 0.16088294424116611), (16, 0.1651864591985941), (5, 0.19515877217054367), (36, 0.542482927441597), (18, 0.6492421850562096), (53, 1.0278215557336807)]
computing accuracy for after removing block 20 . block score: 0.05964371655136347
removed block 20 current accuracy 0.9518 loss from initial  0.04820000000000002
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 19, with score 0.060224. All blocks and scores: [(19, 0.06022351887077093), (15, 0.06382488831877708), (38, 0.06403960287570953), (51, 0.06449326360598207), (22, 0.06454742141067982), (7, 0.06684950832277536), (21, 0.06828203145414591), (39, 0.06933809723705053), (24, 0.07005018088966608), (47, 0.07219683937728405), (52, 0.07301272079348564), (37, 0.07333318889141083), (9, 0.08255517855286598), (6, 0.08425294328480959), (4, 0.08493323624134064), (14, 0.08795285876840353), (11, 0.094524085521698), (2, 0.09495358541607857), (0, 0.10038331430405378), (3, 0.1020055040717125), (17, 0.10638629458844662), (13, 0.11259697284549475), (1, 0.11840636283159256), (8, 0.1283833011984825), (10, 0.14834942668676376), (12, 0.16088294424116611), (16, 0.1651864591985941), (5, 0.19515877589583397), (36, 0.5329937413334846), (18, 0.6492421999573708), (53, 0.9956347495317459)]
computing accuracy for after removing block 19 . block score: 0.06022351887077093
removed block 19 current accuracy 0.9416 loss from initial  0.05840000000000001
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.062574. All blocks and scores: [(22, 0.06257402151823044), (15, 0.06382488925009966), (38, 0.0643456568941474), (51, 0.06553931254893541), (24, 0.06599786877632141), (7, 0.06684950925409794), (39, 0.06980853620916605), (47, 0.07006941270083189), (21, 0.07073216140270233), (52, 0.07168694119900465), (37, 0.0794837512075901), (9, 0.08255517948418856), (6, 0.08425294049084187), (4, 0.08493323624134064), (14, 0.0879528596997261), (11, 0.094524085521698), (2, 0.09495358541607857), (0, 0.10038331430405378), (3, 0.10200550593435764), (17, 0.10638629458844662), (13, 0.11259697284549475), (1, 0.11840636283159256), (8, 0.12838330306112766), (10, 0.14834942109882832), (12, 0.16088294424116611), (16, 0.1651864554733038), (5, 0.19515877030789852), (36, 0.5371886342763901), (18, 0.6492421627044678), (53, 0.9646927565336227)]
computing accuracy for after removing block 22 . block score: 0.06257402151823044
removed block 22 current accuracy 0.9254 loss from initial  0.0746
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.060688. All blocks and scores: [(24, 0.06068755267187953), (51, 0.06270149117335677), (15, 0.06382489018142223), (47, 0.06513701938092709), (52, 0.06534184236079454), (38, 0.0655294805765152), (7, 0.06684951018542051), (39, 0.06886571180075407), (21, 0.07073216140270233), (9, 0.08255517855286598), (6, 0.08425294235348701), (4, 0.08493323344737291), (37, 0.08588392846286297), (14, 0.08795285690575838), (11, 0.09452408738434315), (2, 0.09495358634740114), (0, 0.10038330964744091), (3, 0.10200550779700279), (17, 0.10638629272580147), (13, 0.11259697377681732), (1, 0.11840635817497969), (8, 0.1283833049237728), (10, 0.14834942482411861), (12, 0.16088294237852097), (16, 0.16518646106123924), (5, 0.19515877775847912), (36, 0.5493767857551575), (18, 0.6492421701550484), (53, 0.9375607147812843)]
computing accuracy for after removing block 24 . block score: 0.06068755267187953
removed block 24 current accuracy 0.905 loss from initial  0.09499999999999997
since last training loss: 0.05399999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.058429. All blocks and scores: [(51, 0.05842862371355295), (52, 0.05886642914265394), (47, 0.0604782085865736), (38, 0.06262423563748598), (15, 0.06382489111274481), (39, 0.06623134389519691), (7, 0.06684950832277536), (21, 0.0707321623340249), (9, 0.08255518041551113), (37, 0.08353208564221859), (6, 0.08425294235348701), (4, 0.08493323903530836), (14, 0.0879528559744358), (11, 0.094524085521698), (2, 0.09495358262211084), (0, 0.10038331244140863), (3, 0.10200550314038992), (17, 0.10638629272580147), (13, 0.11259696912020445), (1, 0.11840636283159256), (8, 0.12838330306112766), (10, 0.14834942296147346), (12, 0.16088294982910156), (16, 0.16518646106123924), (5, 0.19515877217054367), (36, 0.5377593487501144), (18, 0.6492421850562096), (53, 0.9105496183037758)]
computing accuracy for after removing block 51 . block score: 0.05842862371355295
removed block 51 current accuracy 0.8536 loss from initial  0.14639999999999997
since last training loss: 0.10539999999999994 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 47, with score 0.060478. All blocks and scores: [(47, 0.06047820718958974), (38, 0.06262423656880856), (15, 0.06382488831877708), (52, 0.0638415408320725), (39, 0.06623134575784206), (7, 0.06684951018542051), (21, 0.07073216140270233), (9, 0.08255517855286598), (37, 0.08353208564221859), (6, 0.08425294328480959), (4, 0.08493323437869549), (14, 0.08795285876840353), (11, 0.09452407900243998), (2, 0.09495358634740114), (0, 0.10038331430405378), (3, 0.10200550593435764), (17, 0.10638629272580147), (13, 0.11259697191417217), (1, 0.11840636003762484), (8, 0.1283833049237728), (10, 0.14834942296147346), (12, 0.16088294051587582), (16, 0.1651864517480135), (5, 0.19515877589583397), (36, 0.5377593636512756), (18, 0.6492421850562096), (53, 1.0813000202178955)]
computing accuracy for after removing block 47 . block score: 0.06047820718958974
removed block 47 current accuracy 0.7838 loss from initial  0.21619999999999995
since last training loss: 0.1751999999999999 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 38, with score 0.062624. All blocks and scores: [(38, 0.06262423750013113), (15, 0.06382488925009966), (39, 0.06623134482651949), (7, 0.06684950832277536), (52, 0.06968877371400595), (21, 0.07073215860873461), (9, 0.08255518041551113), (37, 0.08353208843618631), (6, 0.08425294421613216), (4, 0.08493323531001806), (14, 0.08795285690575838), (11, 0.09452408365905285), (2, 0.09495358355343342), (0, 0.10038331057876348), (3, 0.10200550314038992), (17, 0.10638629458844662), (13, 0.11259697191417217), (1, 0.11840635910630226), (8, 0.12838330306112766), (10, 0.14834942296147346), (12, 0.16088294610381126), (16, 0.16518645361065865), (5, 0.19515877775847912), (36, 0.537759356200695), (18, 0.6492421925067902), (53, 1.2591710835695267)]
computing accuracy for after removing block 38 . block score: 0.06262423750013113
removed block 38 current accuracy 0.7446 loss from initial  0.25539999999999996
since last training loss: 0.21439999999999992 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 15, with score 0.063825. All blocks and scores: [(15, 0.06382488831877708), (7, 0.06684951018542051), (21, 0.07073216140270233), (52, 0.07090619020164013), (39, 0.07990739494562149), (9, 0.08255517762154341), (37, 0.08353208843618631), (6, 0.08425294328480959), (4, 0.08493323344737291), (14, 0.0879528559744358), (11, 0.094524085521698), (2, 0.09495358541607857), (0, 0.10038330871611834), (3, 0.1020055040717125), (17, 0.10638628993183374), (13, 0.11259697191417217), (1, 0.11840636003762484), (8, 0.12838330678641796), (10, 0.14834942482411861), (12, 0.16088294237852097), (16, 0.1651864554733038), (5, 0.19515877589583397), (36, 0.537759356200695), (18, 0.6492421925067902), (53, 1.2983300983905792)]
computing accuracy for after removing block 15 . block score: 0.06382488831877708
removed block 15 current accuracy 0.7214 loss from initial  0.27859999999999996
since last training loss: 0.23759999999999992 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 7, with score 0.066850. All blocks and scores: [(7, 0.06684950925409794), (21, 0.06840594299137592), (52, 0.07004010304808617), (39, 0.07724612671881914), (9, 0.08255517762154341), (37, 0.08265932183712721), (6, 0.08425294142216444), (4, 0.08493323531001806), (14, 0.08795285783708096), (11, 0.0945240817964077), (2, 0.09495358541607857), (0, 0.10038331151008606), (3, 0.10200550314038992), (17, 0.11190470866858959), (13, 0.11259697284549475), (1, 0.11840635817497969), (8, 0.1283833049237728), (10, 0.14834942109882832), (12, 0.16088294424116611), (16, 0.17647804878652096), (5, 0.19515878148376942), (36, 0.5224046558141708), (18, 0.6327371299266815), (53, 1.3395866751670837)]
computing accuracy for after removing block 7 . block score: 0.06684950925409794
removed block 7 current accuracy 0.677 loss from initial  0.32299999999999995
since last training loss: 0.2819999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 21, with score 0.066801. All blocks and scores: [(21, 0.06680070143193007), (52, 0.06943816412240267), (37, 0.07541803643107414), (39, 0.07591835502535105), (9, 0.08114138524979353), (14, 0.0832946365699172), (6, 0.08425294235348701), (4, 0.08493323717266321), (11, 0.08699702471494675), (17, 0.0940926419571042), (2, 0.09495358541607857), (13, 0.09851307701319456), (0, 0.10038331057876348), (3, 0.10200550314038992), (1, 0.11840635724365711), (8, 0.12381425593048334), (12, 0.14737114682793617), (10, 0.14978912845253944), (16, 0.1595572642982006), (5, 0.19515877403318882), (36, 0.5033391416072845), (18, 0.6106205433607101), (53, 1.3753894120454788)]
computing accuracy for after removing block 21 . block score: 0.06680070143193007
removed block 21 current accuracy 0.6264 loss from initial  0.37360000000000004
since last training loss: 0.3326 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 52, with score 0.067210. All blocks and scores: [(52, 0.06721009779721498), (39, 0.07575210835784674), (37, 0.0779937170445919), (9, 0.08114138338714838), (14, 0.08329463377594948), (6, 0.08425294142216444), (4, 0.08493323624134064), (11, 0.08699702471494675), (17, 0.09409264381974936), (2, 0.09495358262211084), (13, 0.09851307608187199), (0, 0.10038331057876348), (3, 0.10200550686568022), (1, 0.11840636096894741), (8, 0.12381425686180592), (12, 0.14737114869058132), (10, 0.1497891265898943), (16, 0.15955726616084576), (5, 0.19515878148376942), (36, 0.49585773795843124), (18, 0.6106205582618713), (53, 1.397083267569542)]
computing accuracy for after removing block 52 . block score: 0.06721009779721498
removed block 52 current accuracy 0.5766 loss from initial  0.4234
training start
training epoch 0 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best True lr [0.1]
training epoch 1 val accuracy 0.8052 topk_dict {'top1': 0.8052} is_best True lr [0.1]
training epoch 2 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.1]
training epoch 3 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.1]
training epoch 4 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 5 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 6 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 7 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 8 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 10 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9308 topk_dict {'top1': 0.9308}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.096083. All blocks and scores: [(4, 0.0960825877264142), (0, 0.10576493199914694), (37, 0.10616163536906242), (9, 0.11893695686012506), (3, 0.11933998297899961), (6, 0.12199859973043203), (2, 0.12551882397383451), (11, 0.12679203692823648), (39, 0.12868249416351318), (1, 0.150670999661088), (14, 0.15799005329608917), (13, 0.17235823348164558), (8, 0.17253435403108597), (10, 0.18943688832223415), (17, 0.19715026393532753), (12, 0.22158428095281124), (5, 0.23450922593474388), (16, 0.24643144011497498), (36, 0.4587363786995411), (18, 0.5880363211035728), (53, 1.361164852976799)]
computing accuracy for after removing block 4 . block score: 0.0960825877264142
removed block 4 current accuracy 0.9254 loss from initial  0.0746
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 0, with score 0.105765. All blocks and scores: [(0, 0.10576493013650179), (37, 0.10654205735772848), (3, 0.11933998111635447), (11, 0.12056205049157143), (9, 0.12254185695201159), (2, 0.12551882397383451), (39, 0.12798303179442883), (6, 0.14109162986278534), (1, 0.1506710071116686), (14, 0.15619673393666744), (13, 0.16909954138100147), (10, 0.17841164208948612), (8, 0.18073949962854385), (17, 0.19171869941055775), (12, 0.21844294667243958), (16, 0.2274486217647791), (5, 0.2626185044646263), (36, 0.45767829194664955), (18, 0.5854222849011421), (53, 1.3392902314662933)]
computing accuracy for after removing block 0 . block score: 0.10576493013650179
removed block 0 current accuracy 0.9058 loss from initial  0.09419999999999995
since last training loss: 0.02499999999999991 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.094451. All blocks and scores: [(3, 0.09445140045136213), (37, 0.10408619046211243), (9, 0.11434005107730627), (11, 0.11524035967886448), (39, 0.1260829707607627), (2, 0.13126373663544655), (6, 0.14423520490527153), (1, 0.15085672959685326), (14, 0.15468002669513226), (10, 0.15933099389076233), (13, 0.16755274683237076), (8, 0.17977083660662174), (17, 0.18079861998558044), (16, 0.21732458285987377), (12, 0.24080099165439606), (5, 0.24612326174974442), (36, 0.44983988627791405), (18, 0.5719150081276894), (53, 1.3221548348665237)]
computing accuracy for after removing block 3 . block score: 0.09445140045136213
removed block 3 current accuracy 0.8812 loss from initial  0.11880000000000002
since last training loss: 0.04959999999999998 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 37, with score 0.098649. All blocks and scores: [(37, 0.09864876698702574), (11, 0.10894060414284468), (39, 0.11986827570945024), (9, 0.12037736643105745), (2, 0.1312637384980917), (14, 0.1417225580662489), (6, 0.1441262699663639), (1, 0.1508567351847887), (10, 0.15529629215598106), (13, 0.16348026879131794), (17, 0.16562423668801785), (8, 0.17605146393179893), (16, 0.1854675281792879), (12, 0.24818497523665428), (5, 0.2753000482916832), (36, 0.4247835613787174), (18, 0.5316200479865074), (53, 1.2536041885614395)]
computing accuracy for after removing block 37 . block score: 0.09864876698702574
removed block 37 current accuracy 0.8216 loss from initial  0.1784
since last training loss: 0.10919999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.108941. All blocks and scores: [(11, 0.1089406032115221), (9, 0.12037736270576715), (2, 0.1312637384980917), (14, 0.14172255992889404), (6, 0.14412627182900906), (39, 0.1487292405217886), (1, 0.1508567351847887), (10, 0.15529629029333591), (13, 0.1634802706539631), (17, 0.16562422923743725), (8, 0.17605146765708923), (16, 0.18546752631664276), (12, 0.24818496964871883), (5, 0.2753000445663929), (36, 0.4247835613787174), (18, 0.5316200405359268), (53, 1.253551870584488)]
computing accuracy for after removing block 11 . block score: 0.1089406032115221
removed block 11 current accuracy 0.791 loss from initial  0.20899999999999996
since last training loss: 0.13979999999999992 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 9, with score 0.120377. All blocks and scores: [(9, 0.12037736177444458), (2, 0.13126374036073685), (14, 0.13974587991833687), (6, 0.14412627182900906), (1, 0.15085673704743385), (39, 0.15438014641404152), (10, 0.15529629029333591), (16, 0.1604379005730152), (13, 0.1617559064179659), (17, 0.16643365658819675), (8, 0.17605146393179893), (12, 0.24574736133217812), (5, 0.2753000482916832), (36, 0.43630825728178024), (18, 0.5380103886127472), (53, 1.2640378177165985)]
computing accuracy for after removing block 9 . block score: 0.12037736177444458
removed block 9 current accuracy 0.7448 loss from initial  0.2552
since last training loss: 0.18599999999999994 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 2, with score 0.131264. All blocks and scores: [(2, 0.13126373663544655), (13, 0.13261778093874454), (14, 0.13386302068829536), (17, 0.14095032215118408), (10, 0.14131394401192665), (39, 0.143814479932189), (6, 0.14412627182900906), (16, 0.14455242827534676), (1, 0.150856738910079), (8, 0.17605146206915379), (12, 0.18916751630604267), (5, 0.2753000482916832), (36, 0.3987395316362381), (18, 0.5019554831087589), (53, 1.0512503534555435)]
computing accuracy for after removing block 2 . block score: 0.13126373663544655
removed block 2 current accuracy 0.609 loss from initial  0.391
since last training loss: 0.3218 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 13, with score 0.113350. All blocks and scores: [(13, 0.11335043981671333), (17, 0.11709069646894932), (14, 0.11729601118713617), (16, 0.13044090196490288), (39, 0.13518351688981056), (10, 0.13697840459644794), (6, 0.1458369828760624), (1, 0.150856738910079), (8, 0.1688651330769062), (12, 0.18870647624135017), (5, 0.2851131111383438), (36, 0.36688586324453354), (18, 0.45345649495720863), (53, 0.8580046966671944)]
computing accuracy for after removing block 13 . block score: 0.11335043981671333
removed block 13 current accuracy 0.5176 loss from initial  0.48240000000000005
since last training loss: 0.4132 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 17, with score 0.129372. All blocks and scores: [(17, 0.12937186285853386), (16, 0.13215535320341587), (39, 0.13230420649051666), (14, 0.13684857450425625), (10, 0.1369783990085125), (6, 0.145836990326643), (1, 0.150856738910079), (8, 0.1688651293516159), (12, 0.18870647810399532), (5, 0.2851131111383438), (36, 0.366102896630764), (18, 0.4447537176311016), (53, 0.86574287712574)]
computing accuracy for after removing block 17 . block score: 0.12937186285853386
removed block 17 current accuracy 0.4328 loss from initial  0.5671999999999999
since last training loss: 0.49799999999999994 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 39, with score 0.126254. All blocks and scores: [(39, 0.12625382468104362), (16, 0.13215535506606102), (14, 0.13684857450425625), (10, 0.1369784027338028), (6, 0.1458369866013527), (1, 0.15085673704743385), (8, 0.1688651330769062), (12, 0.18870648182928562), (5, 0.2851131074130535), (36, 0.3509608283638954), (18, 0.43397829681634903), (53, 0.7864708676934242)]
computing accuracy for after removing block 39 . block score: 0.12625382468104362
removed block 39 current accuracy 0.2534 loss from initial  0.7465999999999999
since last training loss: 0.6774 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 16, with score 0.132155. All blocks and scores: [(16, 0.13215535320341587), (14, 0.1368485726416111), (10, 0.1369783990085125), (6, 0.1458369866013527), (1, 0.15085673704743385), (8, 0.1688651293516159), (12, 0.18870647996664047), (5, 0.2851131074130535), (36, 0.3509608283638954), (18, 0.4339783042669296), (53, 1.101772055029869)]
computing accuracy for after removing block 16 . block score: 0.13215535320341587
removed block 16 current accuracy 0.218 loss from initial  0.782
since last training loss: 0.7128 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 14, with score 0.136849. All blocks and scores: [(14, 0.1368485726416111), (10, 0.1369784064590931), (6, 0.14583698473870754), (1, 0.1508567314594984), (8, 0.1688651293516159), (12, 0.18870648369193077), (5, 0.2851131111383438), (36, 0.3314139358699322), (18, 0.4446056857705116), (53, 1.0955836325883865)]
computing accuracy for after removing block 14 . block score: 0.1368485726416111
removed block 14 current accuracy 0.1848 loss from initial  0.8152
training start
training epoch 0 val accuracy 0.7926 topk_dict {'top1': 0.7926} is_best True lr [0.1]
training epoch 1 val accuracy 0.809 topk_dict {'top1': 0.809} is_best True lr [0.1]
training epoch 2 val accuracy 0.802 topk_dict {'top1': 0.802} is_best False lr [0.1]
training epoch 3 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.1]
training epoch 4 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best False lr [0.1]
training epoch 5 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best True lr [0.1]
training epoch 6 val accuracy 0.846 topk_dict {'top1': 0.846} is_best True lr [0.1]
training epoch 7 val accuracy 0.811 topk_dict {'top1': 0.811} is_best False lr [0.1]
training epoch 8 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.1]
training epoch 9 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 10 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.907800)
finished training. finished 50 epochs. accuracy 0.9078 topk_dict {'top1': 0.9078}
