start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.00845510873477906), (30, 0.00970324594527483), (33, 0.011115942965261638), (34, 0.011622709920629859), (31, 0.012275202898308635), (28, 0.012290219659917057), (29, 0.014791248831897974), (27, 0.016729247989133), (26, 0.01744490279816091), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532452803105116), (25, 0.019648710964247584), (35, 0.01978794764727354), (24, 0.020829484099522233), (22, 0.02102166134864092), (23, 0.02157451305538416), (47, 0.022546384250745177), (44, 0.023842158960178494), (41, 0.024168545613065362), (46, 0.02465107524767518), (6, 0.02466858015395701), (21, 0.025249343365430832), (43, 0.02580355410464108), (10, 0.02636369620449841), (42, 0.026426069671288133), (4, 0.026659545954316854), (45, 0.02682359144091606), (39, 0.026881904108449817), (40, 0.026893552858382463), (49, 0.027856425615027547), (48, 0.028491603210568428), (50, 0.028780476888641715), (11, 0.029002359602600336), (38, 0.02966292086057365), (3, 0.032272040378302336), (13, 0.033336535561829805), (37, 0.03576205763965845), (20, 0.03646321780979633), (12, 0.037992720026522875), (9, 0.03963937144726515), (51, 0.03964210767298937), (19, 0.044218875002115965), (52, 0.04580832691863179), (15, 0.04691674932837486), (14, 0.04904163861647248), (2, 0.057227456010878086), (0, 0.05888257594779134), (16, 0.062252288684248924), (5, 0.09379573818296194), (17, 0.25432227551937103), (36, 0.41727546229958534), (18, 0.4852069169282913), (53, 0.7453346699476242)]
computing accuracy for after removing block 32 . block score: 0.00845510873477906
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.00970324594527483), (33, 0.01119989005383104), (34, 0.011937809642404318), (31, 0.012275203131139278), (28, 0.012290219659917057), (29, 0.014791248715482652), (27, 0.016729247989133), (26, 0.017444903030991554), (1, 0.01825959305278957), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.01964871073141694), (35, 0.020431341603398323), (24, 0.02082948386669159), (22, 0.021021660417318344), (23, 0.021574513521045446), (47, 0.022262109676375985), (44, 0.02329323277808726), (41, 0.023795815650373697), (46, 0.024043596116825938), (6, 0.024668579222634435), (21, 0.025249343598261476), (43, 0.025525057455524802), (42, 0.02623676648363471), (40, 0.026315771974623203), (10, 0.026363696670159698), (4, 0.026659546419978142), (45, 0.02666713879443705), (39, 0.026886870618909597), (49, 0.0273270255420357), (48, 0.027911514276638627), (50, 0.02820870536379516), (38, 0.028610608773306012), (11, 0.029002360068261623), (3, 0.03227204084396362), (13, 0.03333653416484594), (37, 0.03469931520521641), (20, 0.03646321874111891), (12, 0.037992720026522875), (51, 0.03937024949118495), (9, 0.039639371912926435), (19, 0.04421887453645468), (52, 0.04512502206489444), (15, 0.04691674839705229), (14, 0.049041636288166046), (2, 0.05722745694220066), (0, 0.05888257687911391), (16, 0.06225228728726506), (5, 0.09379573632031679), (17, 0.2543222904205322), (36, 0.4077852889895439), (18, 0.485206913203001), (53, 0.7581149190664291)]
computing accuracy for after removing block 30 . block score: 0.00970324594527483
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006312310696), (34, 0.01188752893358469), (28, 0.012290219077840447), (31, 0.012499805307015777), (29, 0.014791248016990721), (27, 0.016729247756302357), (26, 0.01744490349665284), (1, 0.01825959305278957), (7, 0.01837918604724109), (8, 0.01953245303593576), (25, 0.019648710964247584), (35, 0.020717003382742405), (24, 0.02082948316819966), (22, 0.02102166088297963), (23, 0.02157451305538416), (47, 0.022107098484411836), (44, 0.023113694274798036), (46, 0.023742159828543663), (41, 0.02392919873818755), (6, 0.024668580386787653), (21, 0.025249343132600188), (43, 0.025264927418902516), (40, 0.0262474506162107), (10, 0.026363695738837123), (42, 0.026527423644438386), (4, 0.026659545255824924), (45, 0.026712610153481364), (39, 0.0270345292519778), (49, 0.027338512474671006), (48, 0.02790993917733431), (50, 0.027956509962677956), (38, 0.02870898274704814), (11, 0.029002360068261623), (3, 0.03227204130962491), (13, 0.03333653509616852), (37, 0.034348325338214636), (20, 0.03646321874111891), (12, 0.03799272095784545), (51, 0.039133232086896896), (9, 0.03963937144726515), (19, 0.044218875002115965), (52, 0.044780018739402294), (15, 0.04691674839705229), (14, 0.04904163768514991), (2, 0.05722745647653937), (0, 0.05888257501646876), (16, 0.06225228775292635), (5, 0.09379573818296194), (17, 0.2543222904205322), (36, 0.40603339672088623), (18, 0.4852069430053234), (53, 0.7581836357712746)]
computing accuracy for after removing block 33 . block score: 0.011317006312310696
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.012240082607604563), (28, 0.012290219077840447), (31, 0.012499805307015777), (29, 0.014791249297559261), (27, 0.016729248221963644), (26, 0.017444903030991554), (1, 0.01825959305278957), (7, 0.01837918534874916), (8, 0.019532452104613185), (25, 0.01964871073141694), (24, 0.020829483633860946), (22, 0.021021661115810275), (35, 0.021477245958521962), (23, 0.02157451375387609), (47, 0.021933730924502015), (44, 0.022819967474788427), (46, 0.02339849784038961), (41, 0.024046602426096797), (6, 0.02466858015395701), (21, 0.025249343132600188), (43, 0.025404765037819743), (40, 0.026019647484645247), (10, 0.02636369620449841), (4, 0.026659545954316854), (42, 0.026750181568786502), (45, 0.026783813489601016), (49, 0.02706983359530568), (39, 0.02749611996114254), (48, 0.027574571315199137), (50, 0.0279463694896549), (38, 0.02873630286194384), (11, 0.02900235983543098), (3, 0.03227204084396362), (13, 0.033336535561829805), (37, 0.0340590481646359), (20, 0.03646321827545762), (12, 0.03799272095784545), (51, 0.03880897955968976), (9, 0.03963937144726515), (19, 0.04421887407079339), (52, 0.044503950513899326), (15, 0.04691674932837486), (14, 0.04904163768514991), (2, 0.05722745507955551), (0, 0.05888257687911391), (16, 0.0622522896155715), (5, 0.09379574097692966), (17, 0.25432228669524193), (36, 0.40450605377554893), (18, 0.4852069430053234), (53, 0.7641192972660065)]
computing accuracy for after removing block 34 . block score: 0.012240082607604563
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.012290219427086413), (31, 0.012499805423431098), (29, 0.014791248831897974), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.01953245303593576), (25, 0.01964871073141694), (24, 0.020829484332352877), (22, 0.021021660650148988), (23, 0.021574513521045446), (35, 0.021708656335249543), (47, 0.02180175483226776), (44, 0.022438113810494542), (46, 0.023336908780038357), (41, 0.023686284432187676), (6, 0.024668579921126366), (21, 0.025249343598261476), (43, 0.025404839543625712), (40, 0.025569377234205604), (10, 0.026363696670159698), (42, 0.02655180124565959), (39, 0.026582872960716486), (49, 0.02664924180135131), (4, 0.026659545255824924), (45, 0.026776783633977175), (48, 0.026865947293117642), (50, 0.027566451113671064), (38, 0.027829118072986603), (11, 0.02900235983543098), (3, 0.032272040378302336), (37, 0.033198120072484016), (13, 0.03333653509616852), (20, 0.03646321874111891), (12, 0.03799272095784545), (51, 0.0380599251948297), (9, 0.03963937144726515), (52, 0.04353108163923025), (19, 0.04421887546777725), (15, 0.04691674746572971), (14, 0.049041638150811195), (2, 0.05722745740786195), (0, 0.058882576413452625), (16, 0.062252290081232786), (5, 0.09379573632031679), (17, 0.2543222848325968), (36, 0.3958275318145752), (18, 0.4852069206535816), (53, 0.7794358879327774)]
computing accuracy for after removing block 28 . block score: 0.012290219427086413
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645482748747), (29, 0.014790620538406074), (27, 0.016729247756302357), (26, 0.017444903729483485), (1, 0.01825959258712828), (7, 0.01837918534874916), (8, 0.019532453268766403), (25, 0.019648710498586297), (24, 0.02082948316819966), (22, 0.02102166088297963), (47, 0.02134651760570705), (23, 0.02157451375387609), (35, 0.021596733946353197), (44, 0.021918716840445995), (46, 0.022734675090759993), (41, 0.023228028556331992), (6, 0.024668580619618297), (40, 0.024839135818183422), (43, 0.024858604883775115), (21, 0.025249343365430832), (39, 0.02596626291051507), (48, 0.025971463415771723), (42, 0.02599131502211094), (49, 0.026064810808748007), (10, 0.02636369550600648), (45, 0.026453920640051365), (4, 0.026659545488655567), (50, 0.0266801284160465), (38, 0.027020083041861653), (11, 0.029002359602600336), (37, 0.032236404716968536), (3, 0.032272040378302336), (13, 0.03333653509616852), (20, 0.036463219206780195), (51, 0.03758792346343398), (12, 0.03799272095784545), (9, 0.039639370050281286), (52, 0.042884900234639645), (19, 0.04421887453645468), (15, 0.04691674932837486), (14, 0.04904163908213377), (2, 0.05722745740786195), (0, 0.05888257548213005), (16, 0.06225228775292635), (5, 0.09379573725163937), (17, 0.25432228669524193), (36, 0.3858989179134369), (18, 0.4852069467306137), (53, 0.788181945681572)]
computing accuracy for after removing block 31 . block score: 0.011874645482748747
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.014790620538406074), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.018259592819958925), (7, 0.01837918604724109), (8, 0.019532452803105116), (25, 0.019648710964247584), (24, 0.02082948316819966), (47, 0.020932047627866268), (22, 0.021021660650148988), (44, 0.021379180951043963), (23, 0.02157451375387609), (46, 0.02206319011747837), (35, 0.022440450033172965), (41, 0.022648891899734735), (40, 0.02413078211247921), (43, 0.024664208758622408), (6, 0.024668580386787653), (21, 0.025249343132600188), (48, 0.02525039715692401), (49, 0.025515809888020158), (42, 0.025626871269196272), (39, 0.025647579925134778), (38, 0.02585478196851909), (50, 0.025972345378249884), (45, 0.026165933348238468), (10, 0.026363695738837123), (4, 0.026659546652808785), (11, 0.029002359369769692), (37, 0.03128928830847144), (3, 0.03227204084396362), (13, 0.03333653463050723), (20, 0.036463219206780195), (51, 0.037289760541170835), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.041992184706032276), (19, 0.044218875002115965), (15, 0.04691674979403615), (14, 0.049041638150811195), (2, 0.0572274555452168), (0, 0.058882576413452625), (16, 0.062252288684248924), (5, 0.09379573725163937), (17, 0.2543222904205322), (36, 0.3760596886277199), (18, 0.485206913203001), (53, 0.8019541278481483)]
computing accuracy for after removing block 29 . block score: 0.014790620538406074
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729247989133), (26, 0.017444903030991554), (1, 0.01825959305278957), (7, 0.01837918604724109), (8, 0.01953245303593576), (25, 0.019648711197078228), (47, 0.020515700336545706), (24, 0.020829483401030302), (44, 0.0209751317743212), (22, 0.02102166088297963), (23, 0.021574513521045446), (46, 0.021652451949194074), (41, 0.022661817958578467), (35, 0.022723624017089605), (40, 0.023883075220510364), (43, 0.02418972342275083), (6, 0.024668579222634435), (48, 0.02488158317282796), (49, 0.025212351931259036), (42, 0.02522930083796382), (21, 0.025249343132600188), (38, 0.02545714331790805), (50, 0.025512879248708487), (39, 0.025584626477211714), (45, 0.02621095417998731), (10, 0.02636369620449841), (4, 0.026659545954316854), (11, 0.029002360068261623), (37, 0.031102393986657262), (3, 0.032272040378302336), (13, 0.03333653602749109), (20, 0.036463217344135046), (51, 0.03752173902466893), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.041576672811061144), (19, 0.044218875002115965), (15, 0.046916748862713575), (14, 0.04904163768514991), (2, 0.057227457873523235), (0, 0.05888257548213005), (16, 0.06225228914991021), (5, 0.09379573725163937), (17, 0.25432227924466133), (36, 0.3744278997182846), (18, 0.4852069243788719), (53, 0.8058174252510071)]
computing accuracy for after removing block 27 . block score: 0.016729247989133
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017445. All blocks and scores: [(26, 0.017444903030991554), (1, 0.018259592819958925), (7, 0.018379185581579804), (8, 0.019532452570274472), (25, 0.019648710498586297), (47, 0.020196364959701896), (44, 0.020198779879137874), (24, 0.02082948386669159), (22, 0.021021660650148988), (46, 0.021314961137250066), (23, 0.021574512822553515), (35, 0.02166120195761323), (41, 0.02226245147176087), (40, 0.023434572154656053), (43, 0.023669749265536666), (48, 0.023870018310844898), (49, 0.02427303814329207), (39, 0.024631957756355405), (6, 0.02466858015395701), (50, 0.02470592618919909), (38, 0.024713971884921193), (42, 0.024764889385551214), (21, 0.025249344063922763), (45, 0.02590922126546502), (10, 0.026363695273175836), (4, 0.02665954688563943), (11, 0.029002359369769692), (37, 0.030295762000605464), (3, 0.03227203991264105), (13, 0.03333653602749109), (20, 0.03646321780979633), (51, 0.036868576891720295), (12, 0.03799272049218416), (9, 0.03963937098160386), (52, 0.04049280658364296), (19, 0.0442188736051321), (15, 0.04691674932837486), (14, 0.049041638150811195), (2, 0.05722745833918452), (0, 0.0588825773447752), (16, 0.062252290546894073), (5, 0.09379573818296194), (17, 0.2543222904205322), (36, 0.3650362640619278), (18, 0.4852069169282913), (53, 0.834727331995964)]
computing accuracy for after removing block 26 . block score: 0.017444903030991554
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018260. All blocks and scores: [(1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532452570274472), (25, 0.01964871073141694), (44, 0.019705433631315827), (47, 0.01974601368419826), (46, 0.02080916124396026), (24, 0.020829483401030302), (22, 0.021021660650148988), (35, 0.021195970242843032), (23, 0.021574514219537377), (41, 0.02216319413855672), (48, 0.022673572413623333), (40, 0.02284447872079909), (43, 0.02321144612506032), (49, 0.023580190492793918), (38, 0.02393691544421017), (39, 0.024143035290762782), (50, 0.024241250474005938), (42, 0.024461105465888977), (6, 0.024668579921126366), (21, 0.025249343598261476), (45, 0.025508656166493893), (10, 0.026363695273175836), (4, 0.02665954688563943), (11, 0.029002360068261623), (37, 0.029677377082407475), (3, 0.032272040378302336), (13, 0.03333653509616852), (51, 0.03632144583389163), (20, 0.03646321874111891), (12, 0.03799272095784545), (9, 0.039639370050281286), (52, 0.03989553265273571), (19, 0.04421887546777725), (15, 0.046916747931391), (14, 0.04904163908213377), (2, 0.057227456010878086), (0, 0.05888257548213005), (16, 0.062252290081232786), (5, 0.09379573818296194), (17, 0.2543222811073065), (36, 0.36152271553874016), (18, 0.4852069355547428), (53, 0.8471468463540077)]
computing accuracy for after removing block 1 . block score: 0.018259592819958925
removed block 1 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017854. All blocks and scores: [(7, 0.017853511963039637), (8, 0.018682819325476885), (25, 0.019129085820168257), (44, 0.01960266730748117), (24, 0.019680223194882274), (47, 0.01984298857860267), (22, 0.020383452530950308), (35, 0.020452447468414903), (46, 0.02082586125470698), (23, 0.021086918655782938), (41, 0.021640336140990257), (48, 0.022305728867650032), (40, 0.022332167252898216), (43, 0.022896901471540332), (38, 0.023239595582708716), (39, 0.02338676364161074), (49, 0.023744063451886177), (50, 0.024021205259487033), (6, 0.024041746044531465), (42, 0.024278491269797087), (21, 0.024377909488976002), (45, 0.02549561788327992), (10, 0.02596128173172474), (11, 0.02800380578264594), (4, 0.028626713203266263), (37, 0.029063858091831207), (3, 0.03240096475929022), (13, 0.03324462799355388), (20, 0.03517247689887881), (51, 0.03656556410714984), (12, 0.03718129312619567), (9, 0.0386830335482955), (52, 0.039694709703326225), (19, 0.04354847967624664), (15, 0.047371077816933393), (14, 0.04812177224084735), (2, 0.05715902103111148), (0, 0.05888257548213005), (16, 0.06086174910888076), (5, 0.09224656224250793), (17, 0.25094924680888653), (36, 0.34972936660051346), (18, 0.46861380338668823), (53, 0.849854126572609)]
computing accuracy for after removing block 7 . block score: 0.017853511963039637
removed block 7 current accuracy 0.9926 loss from initial  0.007399999999999962
training start
training epoch 0 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 1 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 2 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 3 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 4 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 5 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.1]
training epoch 6 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 7 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.1]
training epoch 8 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 9 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.1]
training epoch 10 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.992600)
finished training. finished 50 epochs. accuracy 0.9926 topk_dict {'top1': 0.9926}
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.018390. All blocks and scores: [(25, 0.018389767734333873), (24, 0.018951865611597896), (35, 0.019241959787905216), (47, 0.019434643210843205), (44, 0.019624896347522736), (23, 0.019739443669095635), (22, 0.019956301199272275), (8, 0.01996665564365685), (46, 0.020434766076505184), (41, 0.021304226480424404), (40, 0.021420421777293086), (48, 0.021825639996677637), (43, 0.02223287522792816), (38, 0.022553730523213744), (39, 0.022905306424945593), (21, 0.023317469283938408), (50, 0.023608924355357885), (49, 0.023631910793483257), (42, 0.024006217950955033), (6, 0.024041746044531465), (45, 0.02504535671323538), (10, 0.026167658157646656), (11, 0.028026719810441136), (37, 0.028401087736710906), (4, 0.028626713203266263), (3, 0.03240096429362893), (13, 0.032924074213951826), (20, 0.03404331021010876), (51, 0.03644962003454566), (12, 0.03690121416002512), (52, 0.03922955971211195), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.046306457836180925), (14, 0.0473039117641747), (2, 0.05715902242809534), (0, 0.058882576413452625), (16, 0.05941257905215025), (5, 0.09224656596779823), (17, 0.2388458400964737), (36, 0.3409247398376465), (18, 0.45438621938228607), (53, 0.8508737683296204)]
computing accuracy for after removing block 25 . block score: 0.018389767734333873
removed block 25 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.018641. All blocks and scores: [(35, 0.018640690250322223), (24, 0.01895186584442854), (47, 0.019162753596901894), (44, 0.019372919807210565), (23, 0.01973944390192628), (22, 0.01995630096644163), (8, 0.01996665634214878), (46, 0.0201800677459687), (41, 0.020792828407138586), (40, 0.020806472515687346), (48, 0.021095545031130314), (38, 0.021664810134097934), (43, 0.02204225491732359), (39, 0.022102958289906383), (50, 0.022921857191249728), (49, 0.02298674383200705), (21, 0.023317469051107764), (42, 0.02369047701358795), (6, 0.024041746510192752), (45, 0.025103284046053886), (10, 0.026167658623307943), (37, 0.027708851732313633), (11, 0.02802672074176371), (4, 0.028626713203266263), (3, 0.03240096615627408), (13, 0.0329240751452744), (20, 0.03404331021010876), (51, 0.035923190880566835), (12, 0.03690121369436383), (52, 0.03849219623953104), (9, 0.03934459341689944), (19, 0.04198857489973307), (15, 0.046306459698826075), (14, 0.047303914092481136), (2, 0.05715901963412762), (0, 0.05888257501646876), (16, 0.059412581380456686), (5, 0.09224656689912081), (17, 0.238845843821764), (36, 0.33257047459483147), (18, 0.4543862156569958), (53, 0.8579950109124184)]
computing accuracy for after removing block 35 . block score: 0.018640690250322223
removed block 35 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.018301. All blocks and scores: [(47, 0.018301398493349552), (44, 0.01887912000529468), (24, 0.018951865611597896), (48, 0.0195496566593647), (46, 0.019557365216314793), (40, 0.019585497211664915), (23, 0.019739444367587566), (22, 0.01995630143210292), (8, 0.019966655876487494), (41, 0.019993558758869767), (38, 0.02027663611806929), (39, 0.020718254381790757), (43, 0.02132464968599379), (50, 0.02192226378247142), (49, 0.022055699722841382), (42, 0.022884832695126534), (21, 0.02331746951676905), (6, 0.024041746044531465), (45, 0.024267783854156733), (10, 0.026167658157646656), (37, 0.02648388408124447), (11, 0.028026720276102424), (4, 0.02862671297043562), (3, 0.03240096429362893), (13, 0.032924076076596975), (20, 0.03404330974444747), (51, 0.03433887893334031), (12, 0.03690121369436383), (52, 0.03733885195106268), (9, 0.039344592951238155), (19, 0.04198857583105564), (15, 0.04630645923316479), (14, 0.047303912695497274), (2, 0.05715902242809534), (0, 0.058882574550807476), (16, 0.059412581380456686), (5, 0.09224656410515308), (17, 0.238845843821764), (36, 0.31887493282556534), (18, 0.45438623055815697), (53, 0.8835926577448845)]
computing accuracy for after removing block 47 . block score: 0.018301398493349552
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.018879. All blocks and scores: [(44, 0.018879120238125324), (24, 0.018951865611597896), (46, 0.019557365914806724), (40, 0.01958549697883427), (23, 0.01973944390192628), (22, 0.019956301664933562), (8, 0.019966655410826206), (41, 0.019993559457361698), (48, 0.02010236238129437), (38, 0.020276635885238647), (39, 0.020718253683298826), (43, 0.021324649453163147), (42, 0.02288483316078782), (50, 0.022935190936550498), (49, 0.02326167724095285), (21, 0.023317469283938408), (6, 0.024041745578870177), (45, 0.024267783854156733), (10, 0.02616765908896923), (37, 0.026483882684260607), (11, 0.028026721673086286), (4, 0.028626714134588838), (3, 0.03240096475929022), (13, 0.032924076076596975), (20, 0.03404330974444747), (51, 0.034763844683766365), (12, 0.03690121369436383), (52, 0.03751523233950138), (9, 0.03934459201991558), (19, 0.04198857489973307), (15, 0.04630645737051964), (14, 0.047303914558142424), (2, 0.05715902056545019), (0, 0.058882574550807476), (16, 0.0594125809147954), (5, 0.09224656689912081), (17, 0.238845843821764), (36, 0.31887491419911385), (18, 0.45438623055815697), (53, 0.960755467414856)]
computing accuracy for after removing block 44 . block score: 0.018879120238125324
removed block 44 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.02180000000000004 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.018952. All blocks and scores: [(24, 0.018951865611597896), (40, 0.019585497211664915), (23, 0.019739444367587566), (22, 0.019956301199272275), (8, 0.01996665564365685), (41, 0.019993558526039124), (38, 0.020276635885238647), (48, 0.02038996503688395), (46, 0.020573836285620928), (39, 0.020718254381790757), (43, 0.021324649220332503), (42, 0.022884832927957177), (50, 0.02312457258813083), (21, 0.02331746951676905), (49, 0.023369598668068647), (6, 0.024041745578870177), (45, 0.02438455680385232), (10, 0.026167658623307943), (37, 0.026483882451429963), (11, 0.028026721673086286), (4, 0.02862671297043562), (3, 0.03240096569061279), (13, 0.0329240751452744), (20, 0.03404331021010876), (51, 0.03477862337604165), (12, 0.03690121462568641), (52, 0.03756985208019614), (9, 0.03934459341689944), (19, 0.04198857629671693), (15, 0.04630646016448736), (14, 0.0473039117641747), (2, 0.05715902196243405), (0, 0.05888257548213005), (16, 0.05941258184611797), (5, 0.09224656224250793), (17, 0.23884583823382854), (36, 0.31887491792440414), (18, 0.45438623800873756), (53, 1.021526761353016)]
computing accuracy for after removing block 24 . block score: 0.018951865611597896
removed block 24 current accuracy 0.9534 loss from initial  0.046599999999999975
since last training loss: 0.03920000000000001 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.019207. All blocks and scores: [(40, 0.01920685893855989), (48, 0.019635459640994668), (23, 0.01973944390192628), (41, 0.019740517484024167), (22, 0.019956301199272275), (38, 0.019963711500167847), (8, 0.019966655177995563), (39, 0.020108413184061646), (46, 0.020233235554769635), (43, 0.020772279240190983), (50, 0.022506374400109053), (42, 0.022604696452617645), (49, 0.02272270037792623), (21, 0.023317469283938408), (45, 0.02385062025859952), (6, 0.024041746510192752), (37, 0.025998201686888933), (10, 0.026167659554630518), (11, 0.028026720276102424), (4, 0.028626712737604976), (3, 0.03240096475929022), (13, 0.032924074213951826), (20, 0.03404331021010876), (51, 0.03416633792221546), (12, 0.03690121416002512), (52, 0.03711421974003315), (9, 0.03934459388256073), (19, 0.04198857489973307), (15, 0.04630645690485835), (14, 0.04730391362681985), (2, 0.0571590238250792), (0, 0.0588825773447752), (16, 0.05941257905215025), (5, 0.09224656503647566), (17, 0.2388458400964737), (36, 0.31504474580287933), (18, 0.45438623428344727), (53, 1.0337043702602386)]
computing accuracy for after removing block 40 . block score: 0.01920685893855989
removed block 40 current accuracy 0.9372 loss from initial  0.06279999999999997
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.018811. All blocks and scores: [(48, 0.01881053065881133), (46, 0.019371640868484974), (41, 0.019517681561410427), (43, 0.01962347375229001), (23, 0.019739444367587566), (22, 0.019956300733610988), (38, 0.019963711965829134), (8, 0.019966656109318137), (39, 0.020108412951231003), (50, 0.021321625681594014), (49, 0.021479649236425757), (42, 0.021748679457232356), (45, 0.022593648172914982), (21, 0.023317469749599695), (6, 0.024041745578870177), (37, 0.02599820145405829), (10, 0.026167658623307943), (11, 0.028026720508933067), (4, 0.02862671227194369), (51, 0.03205896192230284), (3, 0.032400965224951506), (13, 0.03292407467961311), (20, 0.03404330974444747), (52, 0.0368790365755558), (12, 0.03690121462568641), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.04630645923316479), (14, 0.047303912695497274), (2, 0.057159020099788904), (0, 0.05888257594779134), (16, 0.05941258044913411), (5, 0.09224656224250793), (17, 0.2388458475470543), (36, 0.31504474580287933), (18, 0.45438621938228607), (53, 1.1355613768100739)]
computing accuracy for after removing block 48 . block score: 0.01881053065881133
removed block 48 current accuracy 0.9258 loss from initial  0.07420000000000004
since last training loss: 0.06680000000000008 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.019372. All blocks and scores: [(46, 0.019371640402823687), (41, 0.019517680630087852), (43, 0.019623473519459367), (23, 0.01973944390192628), (22, 0.019956301199272275), (38, 0.019963711500167847), (8, 0.019966655410826206), (39, 0.020108412951231003), (42, 0.021748679224401712), (45, 0.022593647940084338), (50, 0.023009002907201648), (21, 0.02331746951676905), (49, 0.02373818657360971), (6, 0.024041746510192752), (37, 0.025998201221227646), (10, 0.026167658157646656), (11, 0.028026720508933067), (4, 0.028626713436096907), (3, 0.03240096569061279), (13, 0.03292407467961311), (20, 0.03404331021010876), (51, 0.03674577549099922), (12, 0.03690121369436383), (52, 0.038727105129510164), (9, 0.03934459248557687), (19, 0.04198857583105564), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.05715902196243405), (0, 0.05888257548213005), (16, 0.059412579983472824), (5, 0.09224656596779823), (17, 0.23884584940969944), (36, 0.31504474952816963), (18, 0.45438622310757637), (53, 1.1955047249794006)]
computing accuracy for after removing block 46 . block score: 0.019371640402823687
removed block 46 current accuracy 0.909 loss from initial  0.09099999999999997
since last training loss: 0.08360000000000001 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 41, with score 0.019518. All blocks and scores: [(41, 0.019517680630087852), (43, 0.01962347445078194), (23, 0.019739443669095635), (22, 0.019956301199272275), (38, 0.019963711965829134), (8, 0.019966655410826206), (39, 0.020108413649722934), (42, 0.021748679457232356), (45, 0.022593648405745625), (50, 0.02330001792870462), (21, 0.02331747068092227), (49, 0.02380967396311462), (6, 0.024041746510192752), (37, 0.025998201919719577), (10, 0.0261676583904773), (11, 0.028026720974594355), (4, 0.028626712737604976), (3, 0.03240096569061279), (13, 0.03292407467961311), (20, 0.034043310675770044), (12, 0.03690121462568641), (51, 0.03806409193202853), (9, 0.03934459341689944), (52, 0.0397917777299881), (19, 0.04198857443407178), (15, 0.046306459698826075), (14, 0.047303915955126286), (2, 0.05715902196243405), (0, 0.05888257687911391), (16, 0.05941257951781154), (5, 0.09224656503647566), (17, 0.238845843821764), (36, 0.31504473835229874), (18, 0.4543862156569958), (53, 1.3054354339838028)]
computing accuracy for after removing block 41 . block score: 0.019517680630087852
removed block 41 current accuracy 0.8814 loss from initial  0.11860000000000004
since last training loss: 0.11120000000000008 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.018951. All blocks and scores: [(43, 0.01895094756036997), (23, 0.01973944390192628), (22, 0.01995630143210292), (38, 0.019963711500167847), (8, 0.019966655876487494), (39, 0.020108413184061646), (42, 0.020852958085015416), (45, 0.021516732638701797), (49, 0.022420424269512296), (50, 0.022458170307800174), (21, 0.02331746998243034), (6, 0.024041746044531465), (37, 0.025998201221227646), (10, 0.026167657924816012), (11, 0.028026720276102424), (4, 0.028626713203266263), (3, 0.032400965224951506), (13, 0.03292407561093569), (20, 0.034043310675770044), (51, 0.036283417604863644), (12, 0.03690121416002512), (9, 0.03934459201991558), (52, 0.04020116804167628), (19, 0.041988575365394354), (15, 0.04630646016448736), (14, 0.047303914558142424), (2, 0.05715902289375663), (0, 0.05888257501646876), (16, 0.05941258044913411), (5, 0.09224656596779823), (17, 0.2388458475470543), (36, 0.31504474580287933), (18, 0.4543862156569958), (53, 1.4619959890842438)]
computing accuracy for after removing block 43 . block score: 0.01895094756036997
removed block 43 current accuracy 0.8458 loss from initial  0.1542
since last training loss: 0.14680000000000004 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.019739. All blocks and scores: [(23, 0.019739443669095635), (22, 0.01995630143210292), (38, 0.01996371173299849), (8, 0.019966656109318137), (39, 0.020108413184061646), (42, 0.020852958085015416), (45, 0.02091054478660226), (50, 0.021857055136933923), (49, 0.022643964737653732), (21, 0.02331746951676905), (6, 0.024041746743023396), (37, 0.025998199824243784), (10, 0.026167659321799874), (11, 0.028026720508933067), (4, 0.02862671227194369), (3, 0.03240096475929022), (13, 0.03292407467961311), (20, 0.03404331021010876), (51, 0.035452775191515684), (12, 0.03690121369436383), (9, 0.03934459201991558), (52, 0.04142751032486558), (19, 0.04198857583105564), (15, 0.04630645737051964), (14, 0.04730391222983599), (2, 0.05715902056545019), (0, 0.05888257687911391), (16, 0.059412579983472824), (5, 0.09224656689912081), (17, 0.23884584568440914), (36, 0.31504474207758904), (18, 0.45438621938228607), (53, 1.6125071793794632)]
computing accuracy for after removing block 23 . block score: 0.019739443669095635
removed block 23 current accuracy 0.8344 loss from initial  0.16559999999999997
training start
training epoch 0 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best True lr [0.1]
training epoch 1 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 2 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.1]
training epoch 3 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 4 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 5 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 6 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 7 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 8 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 9 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.963000)
finished training. finished 50 epochs. accuracy 0.963 topk_dict {'top1': 0.963}
start iteration 22
[activation diff]: block to remove picked: 6, with score 0.036745. All blocks and scores: [(6, 0.0367452590726316), (4, 0.040829666424542665), (8, 0.0443674111738801), (50, 0.04748097201809287), (52, 0.04899140028283), (11, 0.05039843637496233), (49, 0.05142888054251671), (51, 0.05168348224833608), (10, 0.05596039816737175), (39, 0.060153561644256115), (3, 0.061317183542996645), (38, 0.0624415329657495), (13, 0.06377221178263426), (45, 0.06509334687143564), (42, 0.06764472927898169), (22, 0.06853090226650238), (37, 0.0736174825578928), (12, 0.07425274048000574), (21, 0.0784477824345231), (20, 0.08317927829921246), (9, 0.0833479231223464), (15, 0.08431272022426128), (19, 0.08751040883362293), (2, 0.10011450294405222), (14, 0.10124646592885256), (0, 0.114441754296422), (16, 0.11765002086758614), (5, 0.17933383397758007), (17, 0.4250214621424675), (18, 0.5965321883559227), (36, 0.6254375278949738), (53, 0.9340718910098076)]
computing accuracy for after removing block 6 . block score: 0.0367452590726316
removed block 6 current accuracy 0.9612 loss from initial  0.038799999999999946
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 4, with score 0.040830. All blocks and scores: [(4, 0.040829666424542665), (50, 0.046383075416088104), (52, 0.04880820494145155), (8, 0.04890287993475795), (49, 0.05068845674395561), (51, 0.05074008461087942), (11, 0.05331633519381285), (39, 0.05957332020625472), (10, 0.060481758788228035), (38, 0.06075696460902691), (3, 0.06131718214601278), (45, 0.06343894032761455), (42, 0.06630009785294533), (22, 0.06652665138244629), (13, 0.06767919287085533), (37, 0.07270664069801569), (12, 0.07456284295767546), (21, 0.07723018527030945), (20, 0.0802740752696991), (19, 0.08530101738870144), (15, 0.08591051492840052), (9, 0.08766147121787071), (2, 0.10011450201272964), (14, 0.10634677577763796), (0, 0.11444175150245428), (16, 0.11986178997904062), (5, 0.17933383770287037), (17, 0.41409511491656303), (18, 0.5848009362816811), (36, 0.6183436512947083), (53, 0.9264561980962753)]
computing accuracy for after removing block 4 . block score: 0.040829666424542665
removed block 4 current accuracy 0.9586 loss from initial  0.04139999999999999
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.045692. All blocks and scores: [(50, 0.04569205781444907), (52, 0.048422346357256174), (8, 0.04987587267532945), (49, 0.050043567083776), (51, 0.05014798836782575), (11, 0.05128004727885127), (38, 0.05847673490643501), (39, 0.05860561691224575), (10, 0.06025902647525072), (3, 0.06131718400865793), (45, 0.06235337955877185), (22, 0.0644616186618805), (42, 0.06543096713721752), (13, 0.06738075241446495), (37, 0.07001577597111464), (12, 0.07582387421280146), (21, 0.0763926263898611), (20, 0.07672453019768), (9, 0.08323653601109982), (19, 0.08366102911531925), (15, 0.08420217595994473), (2, 0.10011450294405222), (14, 0.10129638947546482), (0, 0.114441754296422), (16, 0.11981589905917645), (5, 0.1845150627195835), (17, 0.41199686378240585), (18, 0.5707258880138397), (36, 0.6013174653053284), (53, 0.9315165802836418)]
computing accuracy for after removing block 50 . block score: 0.04569205781444907
removed block 50 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 8, with score 0.049876. All blocks and scores: [(8, 0.04987587267532945), (49, 0.050043567083776), (11, 0.05128004774451256), (52, 0.05411458294838667), (51, 0.0571251530200243), (38, 0.058476733043789864), (39, 0.05860561691224575), (10, 0.060259027406573296), (3, 0.061317181680351496), (45, 0.06235337955877185), (22, 0.0644616186618805), (42, 0.06543096527457237), (13, 0.0673807505518198), (37, 0.07001577783375978), (12, 0.07582387141883373), (21, 0.07639262545853853), (20, 0.07672452833503485), (9, 0.08323653694242239), (19, 0.08366102911531925), (15, 0.0842021768912673), (2, 0.1001145038753748), (14, 0.1012963904067874), (0, 0.1144417505711317), (16, 0.11981589905917645), (5, 0.18451506085693836), (17, 0.41199686750769615), (18, 0.5707258954644203), (36, 0.6013174504041672), (53, 1.0748216658830643)]
computing accuracy for after removing block 8 . block score: 0.04987587267532945
removed block 8 current accuracy 0.9424 loss from initial  0.057599999999999985
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.048996. All blocks and scores: [(49, 0.04899615468457341), (52, 0.053493882063776255), (51, 0.05516692204400897), (38, 0.055666483007371426), (11, 0.05719225574284792), (39, 0.0574203715659678), (45, 0.05977795086801052), (3, 0.061317179817706347), (22, 0.06204782659187913), (42, 0.06402443535625935), (10, 0.06650760117918253), (37, 0.06832711026072502), (13, 0.0697602927684784), (21, 0.0733758695423603), (20, 0.07368276733905077), (12, 0.07675044238567352), (19, 0.0807932261377573), (15, 0.08478428609669209), (9, 0.08821946755051613), (14, 0.09607863426208496), (2, 0.10011450108140707), (0, 0.11444174684584141), (16, 0.12158391252160072), (5, 0.1845150589942932), (17, 0.38113631680607796), (18, 0.551216796040535), (36, 0.586241751909256), (53, 1.0676240921020508)]
computing accuracy for after removing block 49 . block score: 0.04899615468457341
removed block 49 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 38, with score 0.055666. All blocks and scores: [(38, 0.055666481144726276), (52, 0.05691941920667887), (11, 0.05719225713983178), (39, 0.05742037342861295), (45, 0.05977795226499438), (51, 0.06063184095546603), (3, 0.061317181680351496), (22, 0.06204782659187913), (42, 0.06402443442493677), (10, 0.06650760024785995), (37, 0.06832710932940245), (13, 0.06976029090583324), (21, 0.0733758695423603), (20, 0.0736827664077282), (12, 0.07675044424831867), (19, 0.08079322520643473), (15, 0.08478428516536951), (9, 0.08821946661919355), (14, 0.09607863239943981), (2, 0.10011450201272964), (0, 0.11444175243377686), (16, 0.12158391159027815), (5, 0.18451505340635777), (17, 0.38113630563020706), (18, 0.5512168109416962), (36, 0.5862417668104172), (53, 1.2444422841072083)]
computing accuracy for after removing block 38 . block score: 0.055666481144726276
removed block 38 current accuracy 0.9102 loss from initial  0.08979999999999999
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 52, with score 0.054468. All blocks and scores: [(52, 0.054467891342937946), (51, 0.05610277922824025), (45, 0.056332327891141176), (11, 0.057192258071154356), (39, 0.0611845925450325), (3, 0.06131718074902892), (22, 0.06204782612621784), (42, 0.06306903390213847), (10, 0.06650760117918253), (37, 0.06832710839807987), (13, 0.06976029183715582), (21, 0.07337586861103773), (20, 0.07368276827037334), (12, 0.0767504433169961), (19, 0.0807932261377573), (15, 0.08478428516536951), (9, 0.08821946755051613), (14, 0.09607863426208496), (2, 0.10011450294405222), (0, 0.11444175336509943), (16, 0.12158390693366528), (5, 0.18451505526900291), (17, 0.38113631308078766), (18, 0.5512168034911156), (36, 0.586241751909256), (53, 1.3501489758491516)]
computing accuracy for after removing block 52 . block score: 0.054467891342937946
removed block 52 current accuracy 0.8674 loss from initial  0.13260000000000005
since last training loss: 0.09560000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.056103. All blocks and scores: [(51, 0.05610277922824025), (45, 0.056332329753786325), (11, 0.05719225620850921), (39, 0.06118459301069379), (3, 0.061317180283367634), (22, 0.06204782659187913), (42, 0.06306903390213847), (10, 0.06650759931653738), (37, 0.06832710839807987), (13, 0.06976029369980097), (21, 0.07337586861103773), (20, 0.0736827664077282), (12, 0.07675044145435095), (19, 0.0807932261377573), (15, 0.08478428609669209), (9, 0.08821946941316128), (14, 0.09607863239943981), (2, 0.10011450201272964), (0, 0.11444175243377686), (16, 0.12158390879631042), (5, 0.18451506085693836), (17, 0.38113630935549736), (18, 0.5512168034911156), (36, 0.5862417593598366), (53, 1.0812787860631943)]
computing accuracy for after removing block 51 . block score: 0.05610277922824025
removed block 51 current accuracy 0.786 loss from initial  0.21399999999999997
since last training loss: 0.17699999999999994 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 45, with score 0.056332. All blocks and scores: [(45, 0.05633233021944761), (11, 0.057192256674170494), (39, 0.06118459301069379), (3, 0.06131718214601278), (22, 0.06204782798886299), (42, 0.06306903483346105), (10, 0.0665076021105051), (37, 0.06832710932940245), (13, 0.06976029183715582), (21, 0.07337587047368288), (20, 0.0736827664077282), (12, 0.07675044517964125), (19, 0.08079322520643473), (15, 0.08478428702801466), (9, 0.08821946661919355), (14, 0.09607863333076239), (2, 0.10011450201272964), (0, 0.11444175336509943), (16, 0.12158391252160072), (5, 0.1845150627195835), (17, 0.38113630935549736), (18, 0.551216796040535), (36, 0.5862417668104172), (53, 0.9144705310463905)]
computing accuracy for after removing block 45 . block score: 0.05633233021944761
removed block 45 current accuracy 0.6442 loss from initial  0.3558
since last training loss: 0.3188 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 11, with score 0.057192. All blocks and scores: [(11, 0.05719225900247693), (39, 0.061184595339000225), (3, 0.06131718214601278), (22, 0.06204782612621784), (42, 0.06306903483346105), (10, 0.06650760117918253), (37, 0.06832711026072502), (13, 0.0697602927684784), (21, 0.07337587047368288), (20, 0.0736827664077282), (12, 0.07675044238567352), (19, 0.08079322427511215), (15, 0.08478428609669209), (9, 0.08821946755051613), (14, 0.09607863426208496), (2, 0.10011450201272964), (0, 0.1144417505711317), (16, 0.121583909727633), (5, 0.18451506458222866), (17, 0.38113631308078766), (18, 0.5512167885899544), (36, 0.5862417593598366), (53, 0.9297081381082535)]
computing accuracy for after removing block 11 . block score: 0.05719225900247693
removed block 11 current accuracy 0.6498 loss from initial  0.35019999999999996
since last training loss: 0.3131999999999999 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 39, with score 0.057936. All blocks and scores: [(39, 0.05793554987758398), (42, 0.05904421815648675), (22, 0.059302655048668385), (3, 0.06131718121469021), (37, 0.06470950972288847), (10, 0.06650760117918253), (21, 0.06740571837872267), (20, 0.0726410374045372), (12, 0.07622711732983589), (19, 0.07733392529189587), (13, 0.08040853962302208), (15, 0.08489908371120691), (9, 0.08821946755051613), (14, 0.09441283904016018), (2, 0.10011450294405222), (0, 0.1144417505711317), (16, 0.12899139150977135), (5, 0.18451506085693836), (17, 0.35777197033166885), (18, 0.5294061526656151), (36, 0.5629300102591515), (53, 0.8691304922103882)]
computing accuracy for after removing block 39 . block score: 0.05793554987758398
removed block 39 current accuracy 0.5646 loss from initial  0.4354
training start
training epoch 0 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best True lr [0.1]
training epoch 1 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.1]
training epoch 2 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 3 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 4 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 5 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 6 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 7 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best False lr [0.1]
training epoch 8 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 9 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 19 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 33
[activation diff]: block to remove picked: 13, with score 0.088860. All blocks and scores: [(13, 0.08885976113379002), (10, 0.09303582739084959), (37, 0.10433888249099255), (22, 0.10476905759423971), (21, 0.10486799106001854), (12, 0.10785975214093924), (19, 0.11122302897274494), (15, 0.11223717872053385), (20, 0.11380317341536283), (14, 0.11466236878186464), (3, 0.11625413876026869), (42, 0.12026839144527912), (2, 0.12304046005010605), (9, 0.12578463926911354), (0, 0.1269418429583311), (16, 0.13537569902837276), (5, 0.27608709409832954), (36, 0.4619290642440319), (17, 0.46909797191619873), (18, 0.664977952837944), (53, 1.2660729140043259)]
computing accuracy for after removing block 13 . block score: 0.08885976113379002
removed block 13 current accuracy 0.9388 loss from initial  0.06120000000000003
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 10, with score 0.093036. All blocks and scores: [(10, 0.09303582925349474), (37, 0.10068711545318365), (21, 0.10076265875250101), (22, 0.10136406775563955), (12, 0.10785974841564894), (14, 0.11017235834151506), (15, 0.11126582231372595), (19, 0.11168803460896015), (20, 0.11606888566166162), (3, 0.11625413689762354), (42, 0.11832112167030573), (2, 0.12304045911878347), (9, 0.12578464206308126), (0, 0.12694184016436338), (16, 0.14081055112183094), (5, 0.27608709037303925), (36, 0.44880236312747), (17, 0.4618893004953861), (18, 0.6376890316605568), (53, 1.2324292212724686)]
computing accuracy for after removing block 10 . block score: 0.09303582925349474
removed block 10 current accuracy 0.9324 loss from initial  0.0676
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 21, with score 0.093413. All blocks and scores: [(21, 0.09341279324144125), (37, 0.09628619905561209), (22, 0.0974536370486021), (19, 0.10500157624483109), (20, 0.10854499973356724), (15, 0.10932533908635378), (12, 0.1096337903290987), (14, 0.11491151247173548), (3, 0.11625413596630096), (42, 0.11752247158437967), (2, 0.12304045539349318), (9, 0.12578464020043612), (0, 0.12694184109568596), (16, 0.15202058292925358), (5, 0.27608709409832954), (36, 0.4404413141310215), (17, 0.4504196159541607), (18, 0.6168835163116455), (53, 1.2064939141273499)]
computing accuracy for after removing block 21 . block score: 0.09341279324144125
removed block 21 current accuracy 0.9206 loss from initial  0.07940000000000003
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 22, with score 0.083849. All blocks and scores: [(22, 0.08384929224848747), (37, 0.08838242292404175), (19, 0.10500157717615366), (20, 0.10854500159621239), (15, 0.10932534374296665), (12, 0.10963378846645355), (42, 0.10971881728619337), (14, 0.11491151060909033), (3, 0.11625414341688156), (2, 0.12304045725613832), (9, 0.12578464020043612), (0, 0.12694184016436338), (16, 0.15202058292925358), (5, 0.27608708664774895), (36, 0.4096328765153885), (17, 0.4504196122288704), (18, 0.6168835014104843), (53, 1.099707379937172)]
computing accuracy for after removing block 22 . block score: 0.08384929224848747
removed block 22 current accuracy 0.897 loss from initial  0.10299999999999998
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 37, with score 0.082016. All blocks and scores: [(37, 0.08201550785452127), (42, 0.10242442321032286), (19, 0.10500157345086336), (20, 0.10854500159621239), (15, 0.10932534467428923), (12, 0.10963378939777613), (14, 0.1149115115404129), (3, 0.11625414062291384), (2, 0.12304045259952545), (9, 0.12578464020043612), (0, 0.12694184202700853), (16, 0.15202058479189873), (5, 0.27608709037303925), (36, 0.39027559012174606), (17, 0.4504196159541607), (18, 0.6168834939599037), (53, 0.9797543063759804)]
computing accuracy for after removing block 37 . block score: 0.08201550785452127
removed block 37 current accuracy 0.8138 loss from initial  0.18620000000000003
since last training loss: 0.12880000000000003 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 19, with score 0.105002. All blocks and scores: [(19, 0.10500157717615366), (20, 0.10854500159621239), (15, 0.10932533908635378), (12, 0.10963379126042128), (42, 0.11397561617195606), (14, 0.11491150967776775), (3, 0.11625413876026869), (2, 0.12304045353084803), (9, 0.12578463833779097), (0, 0.12694184388965368), (16, 0.15202058106660843), (5, 0.27608708292245865), (36, 0.39027558639645576), (17, 0.4504196047782898), (18, 0.6168835237622261), (53, 1.0013036206364632)]
computing accuracy for after removing block 19 . block score: 0.10500157717615366
removed block 19 current accuracy 0.7686 loss from initial  0.23140000000000005
since last training loss: 0.17400000000000004 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 42, with score 0.105985. All blocks and scores: [(42, 0.10598535276949406), (15, 0.10932534374296665), (12, 0.10963378753513098), (14, 0.11491150967776775), (3, 0.11625413782894611), (20, 0.12031774409115314), (2, 0.12304045632481575), (9, 0.1257846439257264), (0, 0.12694184202700853), (16, 0.15202058479189873), (5, 0.27608708292245865), (36, 0.3650886230170727), (17, 0.4504196234047413), (18, 0.6168835088610649), (53, 0.9376622065901756)]
computing accuracy for after removing block 42 . block score: 0.10598535276949406
removed block 42 current accuracy 0.5916 loss from initial  0.4084
since last training loss: 0.351 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 15, with score 0.109325. All blocks and scores: [(15, 0.1093253418803215), (12, 0.1096337903290987), (14, 0.11491150688380003), (3, 0.11625414062291384), (20, 0.120317742228508), (2, 0.12304045911878347), (9, 0.12578464206308126), (0, 0.12694184202700853), (16, 0.15202058106660843), (5, 0.27608707919716835), (36, 0.3650886192917824), (17, 0.450419619679451), (18, 0.6168835237622261), (53, 1.4622898697853088)]
computing accuracy for after removing block 15 . block score: 0.1093253418803215
removed block 15 current accuracy 0.5756 loss from initial  0.4244
since last training loss: 0.367 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 12, with score 0.109634. All blocks and scores: [(12, 0.10963379126042128), (14, 0.11491151060909033), (3, 0.11625414062291384), (20, 0.12015802133828402), (2, 0.12304045632481575), (9, 0.12578463833779097), (0, 0.12694184482097626), (16, 0.16970141790807247), (5, 0.27608708664774895), (36, 0.3560790456831455), (17, 0.4367891810834408), (18, 0.591343030333519), (53, 1.3045046627521515)]
computing accuracy for after removing block 12 . block score: 0.10963379126042128
removed block 12 current accuracy 0.5004 loss from initial  0.49960000000000004
since last training loss: 0.44220000000000004 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 20, with score 0.101662. All blocks and scores: [(20, 0.10166209191083908), (14, 0.11113815288990736), (3, 0.11625413596630096), (2, 0.1230404507368803), (9, 0.12578463833779097), (0, 0.12694183830171824), (16, 0.16037519834935665), (5, 0.27608709409832954), (36, 0.33102552592754364), (17, 0.3580133616924286), (18, 0.5332197546958923), (53, 1.1752989590168)]
computing accuracy for after removing block 20 . block score: 0.10166209191083908
removed block 20 current accuracy 0.3876 loss from initial  0.6124
since last training loss: 0.5549999999999999 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 14, with score 0.111138. All blocks and scores: [(14, 0.11113815288990736), (3, 0.11625414062291384), (2, 0.1230404544621706), (9, 0.12578463647514582), (0, 0.12694184016436338), (16, 0.16037519834935665), (5, 0.27608709037303925), (36, 0.3305009566247463), (17, 0.3580133616924286), (18, 0.5332197621464729), (53, 1.2001134604215622)]
computing accuracy for after removing block 14 . block score: 0.11113815288990736
removed block 14 current accuracy 0.2544 loss from initial  0.7456
since last training loss: 0.6881999999999999 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 3, with score 0.116254. All blocks and scores: [(3, 0.11625413689762354), (2, 0.12304045911878347), (9, 0.12578464206308126), (0, 0.12694184202700853), (16, 0.16689777001738548), (5, 0.27608709409832954), (17, 0.328796848654747), (36, 0.3338291049003601), (18, 0.5184275433421135), (53, 1.3837183713912964)]
computing accuracy for after removing block 3 . block score: 0.11625413689762354
removed block 3 current accuracy 0.2008 loss from initial  0.7992
training start
training epoch 0 val accuracy 0.7868 topk_dict {'top1': 0.7868} is_best True lr [0.1]
training epoch 1 val accuracy 0.7814 topk_dict {'top1': 0.7814} is_best False lr [0.1]
training epoch 2 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best True lr [0.1]
training epoch 3 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best False lr [0.1]
training epoch 4 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 5 val accuracy 0.801 topk_dict {'top1': 0.801} is_best False lr [0.1]
training epoch 6 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best False lr [0.1]
training epoch 7 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best False lr [0.1]
training epoch 8 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best True lr [0.1]
training epoch 9 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.1]
training epoch 10 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.910400)
finished training. finished 50 epochs. accuracy 0.9104 topk_dict {'top1': 0.9104}
