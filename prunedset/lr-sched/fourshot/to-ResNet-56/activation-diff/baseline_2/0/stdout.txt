start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975077856332), (20, 0.008696247707121074), (27, 0.009198295185342431), (31, 0.00967550405766815), (29, 0.01003042096272111), (22, 0.010588386794552207), (23, 0.010651617776602507), (21, 0.010725351166911423), (28, 0.011828799615614116), (24, 0.01205872860737145), (17, 0.01219945086631924), (19, 0.01317794865462929), (33, 0.013279787148348987), (35, 0.013483815942890942), (25, 0.0138393419329077), (11, 0.013912908965721726), (32, 0.013956585549749434), (16, 0.014766237582080066), (30, 0.015491604921407998), (9, 0.015547690214589238), (40, 0.0159863349981606), (34, 0.016656322870403528), (39, 0.017517175991088152), (44, 0.01864156615920365), (37, 0.01879900461062789), (43, 0.018935034284368157), (42, 0.019514338579028845), (41, 0.019590020878240466), (45, 0.019901464693248272), (38, 0.020000958116725087), (14, 0.0200475356541574), (8, 0.021667921217158437), (7, 0.02180621144361794), (15, 0.024833296425640583), (46, 0.025212791515514255), (10, 0.02590036136098206), (49, 0.027116776211187243), (48, 0.02751143998466432), (47, 0.02782087796367705), (50, 0.028723245719447732), (51, 0.031788796186447144), (12, 0.03298327000811696), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.03804349387064576), (3, 0.043747184332460165), (52, 0.0525340442545712), (13, 0.05450336076319218), (2, 0.06120603624731302), (1, 0.07061250507831573), (0, 0.14636892452836037), (36, 0.2727429233491421), (18, 0.30386047437787056), (53, 0.8891633078455925)]
computing accuracy for after removing block 26 . block score: 0.007451975077856332
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.008696248172782362), (27, 0.009569326997734606), (31, 0.009736894513480365), (29, 0.010370097937993705), (22, 0.010588386445306242), (23, 0.01065161800943315), (21, 0.010725351050496101), (24, 0.01205872860737145), (28, 0.012067585834302008), (17, 0.012199450517073274), (19, 0.013177948887459934), (33, 0.01320033858064562), (35, 0.013297738856635988), (32, 0.013540125684812665), (25, 0.013839342165738344), (11, 0.013912908965721726), (16, 0.014766237698495388), (30, 0.015476006898097694), (9, 0.01554769033100456), (34, 0.016335653606802225), (40, 0.0164897080976516), (39, 0.018151729367673397), (44, 0.01880926568992436), (43, 0.019272045930847526), (37, 0.019370622700080276), (41, 0.019797630608081818), (42, 0.019846386509016156), (14, 0.0200475356541574), (38, 0.020208331989124417), (45, 0.020282168872654438), (8, 0.021667920984327793), (7, 0.021806210977956653), (15, 0.024833296425640583), (46, 0.025710681220516562), (10, 0.02590036136098206), (49, 0.02717575733549893), (48, 0.027807614766061306), (47, 0.02826968301087618), (50, 0.02872340497560799), (51, 0.031959859654307365), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.052661973517388105), (13, 0.05450336076319218), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636892080307007), (36, 0.2777215540409088), (18, 0.30386047810316086), (53, 0.882565014064312)]
computing accuracy for after removing block 20 . block score: 0.008696248172782362
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.009247071226127446), (31, 0.0094903550343588), (29, 0.01014147000387311), (23, 0.010720769059844315), (21, 0.010873694787733257), (22, 0.010951440199278295), (28, 0.011602517683058977), (17, 0.012199450517073274), (24, 0.012428545160219073), (33, 0.013006685767322779), (32, 0.013030687463469803), (35, 0.013141492963768542), (19, 0.013177949120290577), (11, 0.013912908965721726), (25, 0.014337054453790188), (30, 0.014731098664924502), (16, 0.01476623781491071), (9, 0.01554769033100456), (34, 0.015950741479173303), (40, 0.01667696633376181), (39, 0.018123318441212177), (44, 0.019042733823880553), (43, 0.01952570490539074), (37, 0.019535947358235717), (41, 0.02002391265705228), (42, 0.020024611614644527), (14, 0.020047535886988044), (38, 0.02022995171137154), (45, 0.020495346514508128), (8, 0.02166792005300522), (7, 0.021806211676448584), (15, 0.024833296658471227), (10, 0.025900361128151417), (46, 0.026008820859715343), (49, 0.02735820971429348), (48, 0.027944063767790794), (47, 0.02855871431529522), (50, 0.02887403266504407), (51, 0.031975782942026854), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.05319312820211053), (13, 0.05450336169451475), (2, 0.06120603531599045), (1, 0.07061250880360603), (0, 0.14636892266571522), (36, 0.27894822135567665), (18, 0.30386047810316086), (53, 0.8746765404939651)]
computing accuracy for after removing block 27 . block score: 0.009247071226127446
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.00970343966037035), (29, 0.010401993640698493), (23, 0.010720769292674959), (21, 0.010873694554902613), (22, 0.010951440199278295), (28, 0.01190426992252469), (17, 0.012199450633488595), (24, 0.012428545043803751), (33, 0.012989282491616905), (35, 0.01303201261907816), (32, 0.013032321352511644), (19, 0.01317794865462929), (11, 0.013912908965721726), (25, 0.01433705457020551), (30, 0.014530949643813074), (16, 0.014766238164156675), (34, 0.015523915993981063), (9, 0.015547690447419882), (40, 0.017428284510970116), (39, 0.018635700456798077), (44, 0.0193233760073781), (43, 0.01989502110518515), (14, 0.020047535886988044), (37, 0.020162818022072315), (38, 0.020197830395773053), (42, 0.02029576594941318), (41, 0.020331317326053977), (45, 0.020738494815304875), (8, 0.02166792075149715), (7, 0.021806211210787296), (15, 0.02483329689130187), (10, 0.025900361593812704), (46, 0.026298312935978174), (49, 0.027372207026928663), (48, 0.02811374538578093), (47, 0.028824042761698365), (50, 0.029082486405968666), (51, 0.03204397298395634), (12, 0.03298327000811696), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.053347036242485046), (13, 0.0545033598318696), (2, 0.061206035781651735), (1, 0.07061250507831573), (0, 0.14636891894042492), (36, 0.2865508459508419), (18, 0.30386047810316086), (53, 0.8739226534962654)]
computing accuracy for after removing block 31 . block score: 0.00970343966037035
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401994339190423), (23, 0.010720769292674959), (21, 0.010873694904148579), (22, 0.010951439617201686), (28, 0.011904270155355334), (17, 0.012199450749903917), (24, 0.01242854492738843), (33, 0.01307527325116098), (19, 0.01317794865462929), (32, 0.01322194084059447), (35, 0.013311224873177707), (11, 0.013912908965721726), (25, 0.014337054919451475), (30, 0.014530949643813074), (16, 0.014766237349249423), (34, 0.015109014231711626), (9, 0.015547690563835204), (40, 0.017963847843930125), (44, 0.019172759726643562), (39, 0.019229266559705138), (38, 0.019627248868346214), (43, 0.019773421809077263), (42, 0.020014990121126175), (14, 0.020047535886988044), (41, 0.020369442412629724), (45, 0.020458239829167724), (37, 0.020535162184387445), (8, 0.02166792075149715), (7, 0.021806211210787296), (15, 0.024833296658471227), (10, 0.025900361128151417), (46, 0.02643989003263414), (49, 0.027319708839058876), (48, 0.02830672264099121), (47, 0.028651983244344592), (50, 0.029288704739883542), (51, 0.03214396629482508), (12, 0.03298326954245567), (5, 0.03333624452352524), (6, 0.03351968387141824), (4, 0.03804349387064576), (3, 0.043747184332460165), (52, 0.05252913711592555), (13, 0.0545033598318696), (2, 0.06120603531599045), (1, 0.07061250600963831), (0, 0.14636892266571522), (36, 0.29571831971406937), (18, 0.30386047437787056), (53, 0.8852703794836998)]
computing accuracy for after removing block 29 . block score: 0.010401994339190423
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.010720769059844315), (21, 0.010873694554902613), (22, 0.010951439966447651), (28, 0.011904270271770656), (17, 0.01219945086631924), (24, 0.01242854492738843), (33, 0.01309553359169513), (19, 0.01317794865462929), (32, 0.01333179126959294), (35, 0.013342681690119207), (11, 0.013912908732891083), (25, 0.014337054686620831), (16, 0.01476623781491071), (34, 0.014780625235289335), (30, 0.014848081627860665), (9, 0.015547690214589238), (40, 0.017947440268471837), (44, 0.018570147920399904), (38, 0.018818871583789587), (39, 0.019284183625131845), (42, 0.01955016772262752), (43, 0.019667527871206403), (41, 0.020019967574626207), (14, 0.020047536119818687), (45, 0.02014507818967104), (37, 0.020778113743290305), (8, 0.02166792075149715), (7, 0.02180621074512601), (15, 0.024833296658471227), (10, 0.025900361593812704), (46, 0.02635196619667113), (49, 0.026999606052413583), (48, 0.027823996730148792), (47, 0.02850809460505843), (50, 0.02933459309861064), (51, 0.03217176906764507), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.043747182469815016), (52, 0.051905466709285975), (13, 0.05450335890054703), (2, 0.061206035781651735), (1, 0.07061250600963831), (0, 0.14636892080307007), (36, 0.2995104193687439), (18, 0.30386047437787056), (53, 0.8962140008807182)]
computing accuracy for after removing block 23 . block score: 0.010720769059844315
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
training start
training epoch 0 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best False lr [0.1]
training epoch 1 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 2 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 3 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 4 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 5 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 6 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.1]
training epoch 7 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.1]
training epoch 8 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.998200)
finished training. finished 50 epochs. accuracy 0.9982 topk_dict {'top1': 0.9982}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.010873694787733257), (22, 0.010951439733617008), (28, 0.01145462435670197), (24, 0.01198412268422544), (17, 0.01219945086631924), (35, 0.013001650688238442), (32, 0.013018106110394001), (33, 0.013115601730532944), (19, 0.013177949353121221), (25, 0.013824696186929941), (11, 0.013912908849306405), (30, 0.014240248478017747), (34, 0.01470337773207575), (16, 0.014766237931326032), (9, 0.015547689981758595), (40, 0.018065203446894884), (44, 0.01830046670511365), (38, 0.018600984010845423), (42, 0.019345171051099896), (43, 0.01955112931318581), (39, 0.01982236676849425), (45, 0.019911037990823388), (41, 0.020028739236295223), (14, 0.020047535421326756), (37, 0.02084771986119449), (8, 0.02166792075149715), (7, 0.021806210512295365), (15, 0.024833296658471227), (10, 0.02590036136098206), (46, 0.026478100568056107), (49, 0.02697809273377061), (48, 0.027518167858943343), (47, 0.028530238661915064), (50, 0.029085059417411685), (51, 0.03238660376518965), (12, 0.03298327140510082), (5, 0.03333624405786395), (6, 0.033519684337079525), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.051870775409042835), (13, 0.05450336029753089), (2, 0.061206037644296885), (1, 0.07061250600963831), (0, 0.14636892266571522), (36, 0.3020646683871746), (18, 0.30386046692728996), (53, 0.8938302919268608)]
computing accuracy for after removing block 21 . block score: 0.010873694787733257
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718231205828488), (22, 0.011124414624646306), (24, 0.011734541854821146), (17, 0.012199450749903917), (32, 0.012339044129475951), (35, 0.0123503552749753), (33, 0.01277335628401488), (19, 0.013177948887459934), (30, 0.013385720667429268), (25, 0.013581673731096089), (11, 0.013912909082137048), (34, 0.014493828522972763), (16, 0.014766237349249423), (9, 0.015547689981758595), (40, 0.01817885460332036), (44, 0.018340062582865357), (38, 0.018629685742780566), (42, 0.019575109472498298), (43, 0.019729840336367488), (39, 0.019833360332995653), (14, 0.020047535886988044), (45, 0.0200941888615489), (41, 0.02073429198935628), (37, 0.02079579746350646), (8, 0.021667920285835862), (7, 0.021806210977956653), (15, 0.024833297124132514), (10, 0.025900361826643348), (46, 0.027196239680051804), (49, 0.027292133076116443), (48, 0.02760020294226706), (47, 0.028906626626849174), (50, 0.029168642358854413), (51, 0.03279080847278237), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.04374718340113759), (52, 0.05234553525224328), (13, 0.05450336076319218), (2, 0.06120603671297431), (1, 0.07061250787228346), (0, 0.14636891707777977), (18, 0.30386047437787056), (36, 0.3042290098965168), (53, 0.8967952728271484)]
computing accuracy for after removing block 28 . block score: 0.010718231205828488
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011124. All blocks and scores: [(22, 0.011124414741061628), (24, 0.011734541738405824), (32, 0.012095691403374076), (35, 0.012157876044511795), (17, 0.012199450749903917), (33, 0.013105917139910161), (19, 0.013177949003875256), (30, 0.013323650928214192), (25, 0.013581673381850123), (11, 0.013912909314967692), (34, 0.014369336538948119), (16, 0.014766237582080066), (9, 0.015547689981758595), (38, 0.01792138093151152), (44, 0.018197041004896164), (40, 0.01891227439045906), (42, 0.019364926032721996), (43, 0.019978849217295647), (14, 0.02004753495566547), (45, 0.02033782098442316), (39, 0.020597088616341352), (41, 0.02072914084419608), (37, 0.021321294363588095), (8, 0.021667919820174575), (7, 0.021806210977956653), (15, 0.024833297124132514), (10, 0.02590036136098206), (49, 0.027097659884020686), (48, 0.027195147471502423), (46, 0.027485697530210018), (47, 0.029074370861053467), (50, 0.029169489862397313), (12, 0.03298326954245567), (51, 0.03313342668116093), (5, 0.03333624452352524), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.043747182469815016), (52, 0.05157360201701522), (13, 0.05450336029753089), (2, 0.06120603624731302), (1, 0.07061250600963831), (0, 0.14636892452836037), (18, 0.30386047065258026), (36, 0.31568818539381027), (53, 0.905331514775753)]
computing accuracy for after removing block 22 . block score: 0.011124414741061628
removed block 22 current accuracy 0.9804 loss from initial  0.01959999999999995
since last training loss: 0.017799999999999927 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.010824. All blocks and scores: [(24, 0.010824102791957557), (32, 0.011274677468463778), (35, 0.01203703077044338), (17, 0.012199450749903917), (30, 0.012747167842462659), (33, 0.013064955710433424), (25, 0.013176510576158762), (19, 0.013177948421798646), (11, 0.013912908732891083), (34, 0.014271511929109693), (16, 0.01476623781491071), (9, 0.015547689981758595), (38, 0.017574150348082185), (44, 0.017618532292544842), (42, 0.018865567166358232), (40, 0.01895146956667304), (43, 0.019487120443955064), (45, 0.019938054960221052), (14, 0.020047535421326756), (39, 0.020676982821896672), (41, 0.020799742080271244), (37, 0.020918889436870813), (8, 0.02166792005300522), (7, 0.021806211210787296), (15, 0.02483329619280994), (10, 0.025900361593812704), (49, 0.02698867116123438), (48, 0.02712715370580554), (46, 0.02736985427327454), (50, 0.02874125842936337), (47, 0.029024813091382384), (12, 0.03298326954245567), (51, 0.033131759613752365), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.043747182469815016), (52, 0.05089538311585784), (13, 0.05450336029753089), (2, 0.061206037644296885), (1, 0.07061250880360603), (0, 0.14636892080307007), (18, 0.30386048182845116), (36, 0.3163903057575226), (53, 0.9149599969387054)]
computing accuracy for after removing block 24 . block score: 0.010824102791957557
removed block 24 current accuracy 0.9664 loss from initial  0.03359999999999996
since last training loss: 0.03179999999999994 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.010877. All blocks and scores: [(32, 0.010876586544327438), (35, 0.011955109657719731), (30, 0.012104445602744818), (17, 0.012199450982734561), (25, 0.013075435650534928), (19, 0.013177948887459934), (33, 0.013257879414595664), (11, 0.013912908849306405), (34, 0.014449170092120767), (16, 0.014766238047741354), (9, 0.015547690098173916), (38, 0.01698773866519332), (44, 0.01766943046823144), (42, 0.018743420718237758), (40, 0.019168381113559008), (43, 0.01985725574195385), (45, 0.019892358221113682), (14, 0.0200475356541574), (41, 0.0207320146728307), (37, 0.02104191668331623), (39, 0.021407434716820717), (8, 0.021667920984327793), (7, 0.02180621074512601), (15, 0.02483329689130187), (10, 0.025900361593812704), (49, 0.026679034577682614), (48, 0.026844707317650318), (46, 0.027388097252696753), (50, 0.028316200245171785), (47, 0.02873399737291038), (51, 0.032925904262810946), (12, 0.032983270939439535), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.049682377371937037), (13, 0.054503361228853464), (2, 0.061206035781651735), (1, 0.07061250694096088), (0, 0.14636892266571522), (18, 0.30386047810316086), (36, 0.3254365175962448), (53, 0.9151448607444763)]
computing accuracy for after removing block 32 . block score: 0.010876586544327438
removed block 32 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.04799999999999993 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.012104. All blocks and scores: [(30, 0.012104445835575461), (17, 0.012199450749903917), (35, 0.012797020957805216), (25, 0.013075435883365571), (19, 0.013177948887459934), (33, 0.01379762019496411), (11, 0.013912909314967692), (34, 0.014519993332214653), (16, 0.014766237698495388), (9, 0.01554769033100456), (38, 0.01624030666425824), (44, 0.01703395671211183), (42, 0.018259101314470172), (40, 0.019469282822683454), (45, 0.019506813026964664), (43, 0.01966427033767104), (14, 0.0200475356541574), (41, 0.02021115180104971), (37, 0.020982665941119194), (39, 0.021373850759118795), (8, 0.021667920285835862), (7, 0.02180621074512601), (15, 0.024833296658471227), (10, 0.02590036066249013), (49, 0.026327638421207666), (48, 0.026497263927012682), (46, 0.02732411795295775), (50, 0.028004023246467113), (47, 0.02862798934802413), (51, 0.03261660784482956), (12, 0.03298327047377825), (5, 0.03333624452352524), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.04806074174121022), (13, 0.05450336169451475), (2, 0.06120603438466787), (1, 0.07061250880360603), (0, 0.14636891894042492), (18, 0.30386047065258026), (36, 0.33333006873726845), (53, 0.9361404031515121)]
computing accuracy for after removing block 30 . block score: 0.012104445835575461
removed block 30 current accuracy 0.9186 loss from initial  0.08140000000000003
training start
training epoch 0 val accuracy 0.8024 topk_dict {'top1': 0.8024} is_best False lr [0.1]
training epoch 1 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 2 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 5 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 6 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 7 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 8 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.1]
training epoch 9 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 10 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.957 topk_dict {'top1': 0.957} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.963400)
finished training. finished 50 epochs. accuracy 0.9634 topk_dict {'top1': 0.9634}
start iteration 12
[activation diff]: block to remove picked: 40, with score 0.028998. All blocks and scores: [(40, 0.028998383320868015), (11, 0.029211007989943027), (44, 0.03186320164240897), (39, 0.033186400309205055), (16, 0.033622394781559706), (17, 0.03506672102957964), (45, 0.035270861349999905), (41, 0.037245457991957664), (43, 0.03775726351886988), (14, 0.0378185804001987), (9, 0.038518236950039864), (38, 0.0388521715067327), (42, 0.03905999334529042), (37, 0.04019903019070625), (33, 0.045460638124495745), (46, 0.04609723389148712), (51, 0.0466976398602128), (35, 0.04774533910676837), (49, 0.04822472995147109), (48, 0.048719880636781454), (50, 0.050245596561580896), (8, 0.05075564328581095), (47, 0.05255175847560167), (34, 0.05382930859923363), (19, 0.054292913526296616), (52, 0.056632725056260824), (15, 0.05906516080722213), (7, 0.0607254751957953), (25, 0.06075989222154021), (10, 0.06980285327881575), (5, 0.07466165628284216), (12, 0.08087721187621355), (6, 0.08775428030639887), (4, 0.09023308753967285), (3, 0.10196752287447453), (13, 0.13866636157035828), (2, 0.15326901711523533), (1, 0.17756241001188755), (0, 0.3312660753726959), (18, 0.5661643743515015), (36, 0.6555256396532059), (53, 1.1012599766254425)]
computing accuracy for after removing block 40 . block score: 0.028998383320868015
removed block 40 current accuracy 0.9618 loss from initial  0.03820000000000001
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 11, with score 0.029211. All blocks and scores: [(11, 0.029211007989943027), (44, 0.03275727387517691), (39, 0.033186398446559906), (16, 0.03362239431589842), (17, 0.03506672149524093), (45, 0.0362281552515924), (14, 0.0378185804001987), (9, 0.03851823462173343), (38, 0.038852171041071415), (43, 0.03896137047559023), (37, 0.04019903065636754), (41, 0.0402852282859385), (42, 0.041232796385884285), (33, 0.04546063579618931), (51, 0.04716724203899503), (46, 0.04739953903481364), (35, 0.04774533910676837), (48, 0.0486479215323925), (49, 0.0488042701035738), (8, 0.05075564235448837), (50, 0.05077713867649436), (47, 0.05301154172047973), (34, 0.05382930999621749), (19, 0.05429291492328048), (52, 0.05660358164459467), (15, 0.05906516034156084), (7, 0.06072547333315015), (25, 0.06075989129021764), (10, 0.06980285700410604), (5, 0.07466165814548731), (12, 0.08087721280753613), (6, 0.087754275649786), (4, 0.09023308753967285), (3, 0.1019675200805068), (13, 0.13866635970771313), (2, 0.15326902642846107), (1, 0.1775624044239521), (0, 0.3312660939991474), (18, 0.5661643669009209), (36, 0.6555256322026253), (53, 1.115926742553711)]
computing accuracy for after removing block 11 . block score: 0.029211007989943027
removed block 11 current accuracy 0.9612 loss from initial  0.038799999999999946
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.032051. All blocks and scores: [(44, 0.03205059841275215), (39, 0.03205424593761563), (17, 0.0341611965559423), (16, 0.03451070515438914), (45, 0.035754498559981585), (14, 0.03627118747681379), (38, 0.038045765832066536), (9, 0.038518236484378576), (43, 0.038613754324615), (37, 0.03903835825622082), (41, 0.03952155029401183), (42, 0.039971180725842714), (33, 0.04565188940614462), (51, 0.04689689027145505), (35, 0.04701460199430585), (46, 0.04708694387227297), (48, 0.04804088920354843), (49, 0.04888365650549531), (50, 0.0497698150575161), (8, 0.05075564282014966), (47, 0.052505613304674625), (19, 0.053124924190342426), (34, 0.05321259098127484), (52, 0.055931683629751205), (25, 0.05867591733112931), (15, 0.05874051712453365), (7, 0.06072547333315015), (10, 0.06980285607278347), (5, 0.07466165814548731), (12, 0.07937708683311939), (6, 0.08775427658110857), (4, 0.09023309033364058), (3, 0.10196752287447453), (13, 0.13519715331494808), (2, 0.15326901897788048), (1, 0.17756240256130695), (0, 0.3312660790979862), (18, 0.5489885434508324), (36, 0.6415397673845291), (53, 1.1149399727582932)]
computing accuracy for after removing block 44 . block score: 0.03205059841275215
removed block 44 current accuracy 0.9556 loss from initial  0.044399999999999995
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 39, with score 0.032054. All blocks and scores: [(39, 0.03205424640327692), (17, 0.03416119609028101), (16, 0.034510704688727856), (14, 0.036271187011152506), (45, 0.03787796897813678), (38, 0.0380457672290504), (9, 0.038518235553056), (43, 0.038613754324615), (37, 0.039038358721882105), (41, 0.03952155029401183), (42, 0.03997117979452014), (33, 0.045651890337467194), (35, 0.04701460152864456), (51, 0.0482508703134954), (48, 0.048606416676193476), (49, 0.050087766256183386), (50, 0.050505125895142555), (46, 0.050534098874777555), (8, 0.05075564328581095), (19, 0.05312492186203599), (34, 0.05321259098127484), (47, 0.05421140929684043), (52, 0.05675280326977372), (25, 0.05867591733112931), (15, 0.0587405189871788), (7, 0.060725473798811436), (10, 0.0698028551414609), (5, 0.07466165814548731), (12, 0.07937708869576454), (6, 0.08775427844375372), (4, 0.090233089402318), (3, 0.10196752101182938), (13, 0.13519715331494808), (2, 0.15326901897788048), (1, 0.1775624081492424), (0, 0.3312660865485668), (18, 0.5489885658025742), (36, 0.6415397673845291), (53, 1.1572263687849045)]
computing accuracy for after removing block 39 . block score: 0.03205424640327692
removed block 39 current accuracy 0.9532 loss from initial  0.04679999999999995
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 17, with score 0.034161. All blocks and scores: [(17, 0.034161195158958435), (16, 0.03451070562005043), (14, 0.036271187011152506), (45, 0.03797108959406614), (38, 0.038045765832066536), (9, 0.03851823462173343), (43, 0.03882116498425603), (37, 0.03903835918754339), (41, 0.041559167206287384), (42, 0.04184391722083092), (33, 0.04565189126878977), (35, 0.047014601062983274), (48, 0.04797696089372039), (51, 0.047994173131883144), (50, 0.04963227268308401), (49, 0.050318234134465456), (8, 0.05075564235448837), (46, 0.05078268190845847), (19, 0.053124924656003714), (34, 0.053212590515613556), (47, 0.053455691318959), (52, 0.0573520609177649), (25, 0.05867591965943575), (15, 0.0587405189871788), (7, 0.06072547286748886), (10, 0.06980285421013832), (5, 0.07466165535151958), (12, 0.07937708962708712), (6, 0.08775427751243114), (4, 0.09023308847099543), (3, 0.10196752194315195), (13, 0.13519715517759323), (2, 0.15326901897788048), (1, 0.1775624044239521), (0, 0.3312660790979862), (18, 0.5489885658025742), (36, 0.6415397450327873), (53, 1.1523883789777756)]
computing accuracy for after removing block 17 . block score: 0.034161195158958435
removed block 17 current accuracy 0.9518 loss from initial  0.04820000000000002
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 16, with score 0.034511. All blocks and scores: [(16, 0.03451070562005043), (14, 0.036271187011152506), (38, 0.036652914714068174), (45, 0.037009891122579575), (9, 0.03851823415607214), (37, 0.03908878890797496), (43, 0.039136060513556004), (42, 0.04065022338181734), (41, 0.04103174712508917), (33, 0.0448600254021585), (35, 0.04542017308995128), (48, 0.047086148988455534), (51, 0.04732725629583001), (50, 0.048680403269827366), (19, 0.05008692434057593), (49, 0.050331815611571074), (8, 0.050755643751472235), (34, 0.05083729000762105), (46, 0.051534860860556364), (47, 0.05288715660572052), (25, 0.05610688216984272), (52, 0.056147866416722536), (15, 0.058740518521517515), (7, 0.060725472401827574), (10, 0.0698028551414609), (5, 0.07466165628284216), (12, 0.07937708497047424), (6, 0.08775427658110857), (4, 0.09023308847099543), (3, 0.10196751914918423), (13, 0.13519715517759323), (2, 0.15326901338994503), (1, 0.1775624006986618), (0, 0.3312660790979862), (18, 0.5578543692827225), (36, 0.6387183740735054), (53, 1.1491248607635498)]
computing accuracy for after removing block 16 . block score: 0.03451070562005043
removed block 16 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 1 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 2 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 3 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 4 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 6 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 7 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 8 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 9 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 10 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.960800)
finished training. finished 50 epochs. accuracy 0.9608 topk_dict {'top1': 0.9608}
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.045895. All blocks and scores: [(45, 0.04589511128142476), (43, 0.046654858626425266), (38, 0.047105320263653994), (42, 0.04740304499864578), (41, 0.048633560072630644), (51, 0.04948913445696235), (35, 0.050828184466809034), (9, 0.05192589666694403), (48, 0.05192691087722778), (49, 0.052918321918696165), (37, 0.053876029793173075), (14, 0.05421915743499994), (33, 0.055257916916161776), (50, 0.05542685557156801), (34, 0.05569071089848876), (46, 0.056589847430586815), (8, 0.05798171600326896), (47, 0.06018697144463658), (52, 0.06029623048380017), (19, 0.06058653211221099), (7, 0.0672482568770647), (25, 0.0706710172817111), (10, 0.07391087431460619), (15, 0.07665211521089077), (5, 0.08056426607072353), (6, 0.09178371261805296), (12, 0.0954793319106102), (4, 0.11220650561153889), (3, 0.1203472102060914), (13, 0.16147456876933575), (2, 0.16648827493190765), (1, 0.17929274588823318), (0, 0.35818833485245705), (18, 0.6191935241222382), (36, 0.6818613484501839), (53, 1.1511209309101105)]
computing accuracy for after removing block 45 . block score: 0.04589511128142476
removed block 45 current accuracy 0.9554 loss from initial  0.04459999999999997
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.046655. All blocks and scores: [(43, 0.046654858626425266), (38, 0.047105319797992706), (42, 0.04740304546430707), (41, 0.04863355960696936), (51, 0.050021879374980927), (35, 0.05082818493247032), (9, 0.05192589620128274), (48, 0.05252998461946845), (37, 0.05387603025883436), (49, 0.054207620210945606), (14, 0.05421915650367737), (33, 0.0552579159848392), (34, 0.05569071043282747), (50, 0.056121337693184614), (8, 0.057981718331575394), (52, 0.05996525473892689), (19, 0.060586531180888414), (46, 0.06225545471534133), (47, 0.06303666951134801), (7, 0.06724825967103243), (25, 0.0706710210070014), (10, 0.07391087152063847), (15, 0.07665211614221334), (5, 0.08056426420807838), (6, 0.09178371727466583), (12, 0.0954793319106102), (4, 0.11220650095492601), (3, 0.12034720741212368), (13, 0.16147457249462605), (2, 0.16648827865719795), (1, 0.17929274961352348), (0, 0.35818834230303764), (18, 0.6191935166716576), (36, 0.6818613484501839), (53, 1.1548429876565933)]
computing accuracy for after removing block 43 . block score: 0.046654858626425266
removed block 43 current accuracy 0.9452 loss from initial  0.05479999999999996
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.047105. All blocks and scores: [(38, 0.047105320263653994), (42, 0.04740304546430707), (41, 0.048633560072630644), (51, 0.05038736294955015), (35, 0.05082818306982517), (9, 0.051925897132605314), (48, 0.05221312399953604), (37, 0.05387602839618921), (14, 0.05421915743499994), (33, 0.055257915519177914), (49, 0.05548251140862703), (50, 0.055540479719638824), (34, 0.05569071089848876), (8, 0.057981719728559256), (52, 0.059562227223068476), (19, 0.0605865316465497), (46, 0.06395015027374029), (47, 0.0651136594824493), (7, 0.06724825873970985), (25, 0.0706710210070014), (10, 0.07391086965799332), (15, 0.07665211707353592), (5, 0.08056426420807838), (6, 0.09178371448069811), (12, 0.09547933004796505), (4, 0.11220650840550661), (3, 0.12034720741212368), (13, 0.1614745669066906), (2, 0.16648827865719795), (1, 0.17929275333881378), (0, 0.35818833857774734), (18, 0.6191935166716576), (36, 0.6818613335490227), (53, 1.1891925781965256)]
computing accuracy for after removing block 38 . block score: 0.047105320263653994
removed block 38 current accuracy 0.9386 loss from initial  0.06140000000000001
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 42, with score 0.048005. All blocks and scores: [(42, 0.04800468869507313), (51, 0.049328908789902925), (35, 0.05082818539813161), (48, 0.05123892705887556), (41, 0.05125958193093538), (9, 0.051925897132605314), (37, 0.05387602839618921), (49, 0.05396440718322992), (50, 0.0540279527194798), (14, 0.05421915929764509), (33, 0.0552579159848392), (34, 0.055690711829811335), (52, 0.05704339547082782), (8, 0.05798171693459153), (19, 0.06058653071522713), (46, 0.06339766224846244), (47, 0.06348575465381145), (7, 0.06724825967103243), (25, 0.07067101914435625), (10, 0.07391087338328362), (15, 0.0766521180048585), (5, 0.08056426327675581), (6, 0.09178371448069811), (12, 0.09547933377325535), (4, 0.11220650374889374), (3, 0.12034720554947853), (13, 0.1614745706319809), (2, 0.1664882842451334), (1, 0.17929275147616863), (0, 0.35818833112716675), (18, 0.6191935166716576), (36, 0.6818613335490227), (53, 1.1758032441139221)]
computing accuracy for after removing block 42 . block score: 0.04800468869507313
removed block 42 current accuracy 0.922 loss from initial  0.07799999999999996
since last training loss: 0.038799999999999946 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 51, with score 0.049846. All blocks and scores: [(51, 0.04984571458771825), (35, 0.05082818353548646), (41, 0.05125958193093538), (9, 0.0519258975982666), (48, 0.05243585491552949), (37, 0.05387602746486664), (14, 0.054219156969338655), (49, 0.05438467999920249), (50, 0.05502105504274368), (33, 0.05525791412219405), (34, 0.05569071089848876), (52, 0.05635632015764713), (8, 0.057981718331575394), (19, 0.06058652885258198), (46, 0.06433958653360605), (47, 0.0651136226952076), (7, 0.06724825967103243), (25, 0.07067102007567883), (10, 0.07391087152063847), (15, 0.07665211521089077), (5, 0.08056426420807838), (6, 0.09178371448069811), (12, 0.09547933377325535), (4, 0.11220650561153889), (3, 0.12034720741212368), (13, 0.1614745743572712), (2, 0.1664882767945528), (1, 0.17929275147616863), (0, 0.35818834602832794), (18, 0.619193509221077), (36, 0.6818613559007645), (53, 1.2123736292123795)]
computing accuracy for after removing block 51 . block score: 0.04984571458771825
removed block 51 current accuracy 0.9044 loss from initial  0.09560000000000002
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 35, with score 0.050828. All blocks and scores: [(35, 0.05082818306982517), (41, 0.05125958193093538), (9, 0.0519258975982666), (48, 0.05243585351854563), (37, 0.053876029793173075), (14, 0.054219158831983805), (49, 0.05438468139618635), (50, 0.055021054577082396), (33, 0.0552579159848392), (34, 0.055690709967166185), (8, 0.057981716468930244), (19, 0.06058653211221099), (46, 0.06433958560228348), (47, 0.06511362455785275), (52, 0.06635467056185007), (7, 0.06724825780838728), (25, 0.07067102007567883), (10, 0.07391087524592876), (15, 0.07665211521089077), (5, 0.08056426513940096), (6, 0.09178371354937553), (12, 0.0954793319106102), (4, 0.11220650281757116), (3, 0.12034720834344625), (13, 0.16147456876933575), (2, 0.1664882767945528), (1, 0.17929274588823318), (0, 0.35818833112716675), (18, 0.6191935241222382), (36, 0.6818613484501839), (53, 1.313846915960312)]
computing accuracy for after removing block 35 . block score: 0.05082818306982517
removed block 35 current accuracy 0.895 loss from initial  0.10499999999999998
since last training loss: 0.06579999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 9, with score 0.051926. All blocks and scores: [(9, 0.05192589666694403), (41, 0.05291517777368426), (48, 0.05407612677663565), (14, 0.05421915650367737), (50, 0.05512397037819028), (33, 0.055257915053516626), (49, 0.0552796246483922), (34, 0.055690711829811335), (37, 0.057335492223501205), (8, 0.057981717865914106), (19, 0.060586533043533564), (47, 0.06641831062734127), (46, 0.06677604746073484), (52, 0.06700745411217213), (7, 0.06724825873970985), (25, 0.07067102007567883), (10, 0.07391087152063847), (15, 0.07665211614221334), (5, 0.08056426513940096), (6, 0.09178371448069811), (12, 0.0954793319106102), (4, 0.11220651026815176), (3, 0.12034721113741398), (13, 0.16147457249462605), (2, 0.16648827865719795), (1, 0.17929275147616863), (0, 0.35818833485245705), (18, 0.6191935017704964), (36, 0.713898628950119), (53, 1.3535167872905731)]
computing accuracy for after removing block 9 . block score: 0.05192589666694403
removed block 9 current accuracy 0.881 loss from initial  0.119
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 14, with score 0.050194. All blocks and scores: [(14, 0.05019425833597779), (33, 0.05244738142937422), (48, 0.05287441797554493), (41, 0.05407060915604234), (37, 0.05429463926702738), (49, 0.05457012727856636), (50, 0.054919660091400146), (34, 0.056475164368748665), (8, 0.05798171740025282), (19, 0.05889494018629193), (47, 0.06509531708434224), (46, 0.06626162491738796), (52, 0.06684280186891556), (7, 0.06724825967103243), (25, 0.06842861138284206), (10, 0.0704311653971672), (15, 0.0747058941051364), (5, 0.08056426513940096), (6, 0.09178371448069811), (12, 0.09275446087121964), (4, 0.11220650468021631), (3, 0.12034720927476883), (13, 0.14676670730113983), (2, 0.1664882767945528), (1, 0.17929274961352348), (0, 0.35818832740187645), (18, 0.5925654619932175), (36, 0.6970011442899704), (53, 1.3481571823358536)]
computing accuracy for after removing block 14 . block score: 0.05019425833597779
removed block 14 current accuracy 0.879 loss from initial  0.121
since last training loss: 0.08179999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 48, with score 0.051684. All blocks and scores: [(48, 0.051684306003153324), (33, 0.05283921444788575), (34, 0.05438451934605837), (50, 0.05457162717357278), (37, 0.05490023083984852), (49, 0.05520385643467307), (41, 0.05540347518399358), (19, 0.05785303143784404), (8, 0.057981718331575394), (47, 0.06375953741371632), (52, 0.06653888523578644), (7, 0.06724825780838728), (25, 0.067395213060081), (46, 0.06786721106618643), (10, 0.07043116725981236), (5, 0.08056426607072353), (15, 0.0827013524249196), (6, 0.09178371634334326), (12, 0.09275446273386478), (4, 0.11220650561153889), (3, 0.12034720741212368), (13, 0.14676670543849468), (2, 0.1664882767945528), (1, 0.17929275147616863), (0, 0.35818834602832794), (18, 0.6101205348968506), (36, 0.7142773121595383), (53, 1.3592175394296646)]
computing accuracy for after removing block 48 . block score: 0.051684306003153324
removed block 48 current accuracy 0.8584 loss from initial  0.14159999999999995
training start
training epoch 0 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 1 val accuracy 0.866 topk_dict {'top1': 0.866} is_best True lr [0.1]
training epoch 2 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 3 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 4 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 5 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 6 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 7 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 8 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 9 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.950200)
finished training. finished 50 epochs. accuracy 0.9502 topk_dict {'top1': 0.9502}
