start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.0041118061053566635), (30, 0.007531446113716811), (2, 0.007728804543148726), (31, 0.009409212623722851), (34, 0.010633390280418098), (33, 0.010768219362944365), (35, 0.010826651006937027), (32, 0.011131544481031597), (28, 0.012192570837214589), (29, 0.013092639623209834), (26, 0.013270105933770537), (25, 0.014763001585379243), (27, 0.01578354462981224), (24, 0.01580518949776888), (22, 0.015843698871321976), (23, 0.017308010021224618), (39, 0.019983843667432666), (42, 0.02084138779900968), (38, 0.02102866256609559), (14, 0.021516707725822926), (43, 0.0216877032071352), (5, 0.02187711768783629), (41, 0.02212515566498041), (44, 0.0227764502633363), (45, 0.023535518208518624), (40, 0.024229633389040828), (47, 0.024651852436363697), (37, 0.025173959555104375), (49, 0.02518479316495359), (3, 0.025671070907264948), (21, 0.025702943792566657), (50, 0.02576586022041738), (20, 0.027230343082919717), (46, 0.028618559474125504), (17, 0.029949784744530916), (51, 0.031313665676862), (48, 0.03152880095876753), (19, 0.034745858050882816), (16, 0.045105695724487305), (15, 0.046672547701746225), (0, 0.04746154882013798), (6, 0.05039409967139363), (7, 0.05069215735420585), (4, 0.05092597473412752), (10, 0.06328557385131717), (13, 0.06400972884148359), (8, 0.06672556139528751), (52, 0.06828812044113874), (12, 0.07267716713249683), (11, 0.07419469766318798), (9, 0.07928674854338169), (36, 0.3385251797735691), (18, 0.4787600599229336), (53, 0.9074814766645432)]
computing accuracy for after removing block 1 . block score: 0.0041118061053566635
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.007558359473478049), (2, 0.007992399565409869), (31, 0.009376695728860795), (34, 0.010569098521955311), (33, 0.010759366559796035), (35, 0.0108337925048545), (32, 0.011090524611063302), (28, 0.012191424611955881), (29, 0.013140873634256423), (26, 0.013311112183146179), (25, 0.014746290748007596), (24, 0.015801146859303117), (22, 0.015853286837227643), (27, 0.01587040233425796), (23, 0.017250196309760213), (39, 0.019925506552681327), (42, 0.020839826902374625), (38, 0.020938864443451166), (5, 0.021410029847174883), (14, 0.021470679668709636), (43, 0.021646991139277816), (41, 0.022096743574365973), (44, 0.022830850211903453), (45, 0.0234941893722862), (40, 0.024263028986752033), (47, 0.0246264326851815), (37, 0.02515707165002823), (49, 0.02518477221019566), (21, 0.02562487358227372), (50, 0.02580099180340767), (3, 0.026267620967701077), (20, 0.027126541128382087), (46, 0.028638296527788043), (17, 0.030022146878764033), (51, 0.031291102059185505), (48, 0.03151489142328501), (19, 0.03466663043946028), (16, 0.044798357877880335), (15, 0.046408084221184254), (0, 0.0474615478888154), (4, 0.05093049444258213), (6, 0.05134963011369109), (7, 0.05156157072633505), (10, 0.06291997572407126), (13, 0.06426404230296612), (52, 0.06817463226616383), (8, 0.0683986684307456), (12, 0.07294023595750332), (11, 0.07450826466083527), (9, 0.08042858634144068), (36, 0.338327556848526), (18, 0.4787031151354313), (53, 0.9076695814728737)]
computing accuracy for after removing block 30 . block score: 0.007558359473478049
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992400031071156), (31, 0.009402871131896973), (34, 0.010204409947618842), (35, 0.01043578318785876), (33, 0.01097452687099576), (32, 0.011320485034957528), (28, 0.012191424728371203), (29, 0.013140874216333032), (26, 0.0133111122995615), (25, 0.014746290748007596), (24, 0.015801147557795048), (22, 0.015853286837227643), (27, 0.015870402101427317), (23, 0.01725019607692957), (39, 0.01986637688241899), (38, 0.02062974264845252), (42, 0.020691832061856985), (5, 0.02141003031283617), (14, 0.02147067990154028), (43, 0.02183908480219543), (41, 0.02201103768311441), (44, 0.022784787230193615), (45, 0.02333742706105113), (47, 0.024608810199424624), (40, 0.02479364164173603), (49, 0.02500508981756866), (21, 0.02562487358227372), (37, 0.02566643781028688), (50, 0.02576501970179379), (3, 0.02626762120053172), (20, 0.027126540197059512), (46, 0.028450445970520377), (17, 0.030022146878764033), (51, 0.0308925099670887), (48, 0.031455071875825524), (19, 0.034666630905121565), (16, 0.04479835741221905), (15, 0.04640808515250683), (0, 0.047461547423154116), (4, 0.05093049397692084), (6, 0.05134963011369109), (7, 0.05156157165765762), (10, 0.06291997572407126), (13, 0.06426404230296612), (52, 0.06774707417935133), (8, 0.0683986684307456), (12, 0.07294023502618074), (11, 0.07450826559215784), (9, 0.08042858727276325), (36, 0.3417893536388874), (18, 0.4787031300365925), (53, 0.9106026813387871)]
computing accuracy for after removing block 2 . block score: 0.007992400031071156
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.009391383966431022), (34, 0.01035618083551526), (35, 0.010530833504162729), (33, 0.010978628299199045), (32, 0.011285086395218968), (28, 0.012222225894220173), (29, 0.01339500502217561), (26, 0.013411890715360641), (25, 0.014773015980608761), (24, 0.01589584769681096), (22, 0.01594504527747631), (27, 0.016057065222412348), (23, 0.017187519930303097), (39, 0.01986844907514751), (42, 0.020744004752486944), (38, 0.020750499330461025), (5, 0.021117351949214935), (14, 0.021327618043869734), (43, 0.021792822750285268), (41, 0.02195996092632413), (44, 0.022877607494592667), (45, 0.023284759605303407), (47, 0.024535594042390585), (40, 0.024922656593844295), (49, 0.02497671777382493), (21, 0.025540468050166965), (50, 0.02573660877533257), (37, 0.025740002281963825), (3, 0.026626085164025426), (20, 0.02713091066107154), (46, 0.028354250825941563), (17, 0.030052858404815197), (51, 0.030807055300101638), (48, 0.0313640043605119), (19, 0.034590966533869505), (16, 0.044494173023849726), (15, 0.046184624545276165), (0, 0.04746154975146055), (4, 0.050933849066495895), (7, 0.05248213279992342), (6, 0.05318683013319969), (10, 0.0630735894665122), (13, 0.0641754250973463), (52, 0.06737186666578054), (8, 0.07143167871981859), (12, 0.0729450760409236), (11, 0.07423979137092829), (9, 0.08192321565002203), (36, 0.3429319001734257), (18, 0.48187144100666046), (53, 0.9105552509427071)]
computing accuracy for after removing block 31 . block score: 0.009391383966431022
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670307934284), (35, 0.010449820780195296), (33, 0.01098572218324989), (32, 0.011304144631139934), (28, 0.012222225777804852), (29, 0.013395005371421576), (26, 0.01341189059894532), (25, 0.014773016213439405), (24, 0.01589584769681096), (22, 0.015945045510306954), (27, 0.01605706545524299), (23, 0.01718751946464181), (39, 0.019797147950157523), (38, 0.020344304386526346), (42, 0.02058867714367807), (5, 0.021117351949214935), (14, 0.021327617578208447), (43, 0.02176103019155562), (41, 0.021869145333766937), (44, 0.02282825973816216), (45, 0.02339630085043609), (47, 0.02450825646519661), (49, 0.024995683692395687), (40, 0.025056051556020975), (21, 0.025540467584505677), (37, 0.025701350765302777), (50, 0.025906251976266503), (3, 0.026626083999872208), (20, 0.027130910893902183), (46, 0.028551972471177578), (17, 0.030052858404815197), (51, 0.03091105679050088), (48, 0.031486503314226866), (19, 0.03459096606820822), (16, 0.044494171626865864), (15, 0.0461846268735826), (0, 0.0474615478888154), (4, 0.050933847203850746), (7, 0.052482135128229856), (6, 0.05318683059886098), (10, 0.06307358713820577), (13, 0.06417542602866888), (52, 0.06731625832617283), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423979230225086), (9, 0.08192321565002203), (36, 0.34496790543198586), (18, 0.48187142238020897), (53, 0.9170897081494331)]
computing accuracy for after removing block 34 . block score: 0.010089670307934284
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489318054169416), (33, 0.010985722066834569), (32, 0.011304144863970578), (28, 0.012222225195728242), (29, 0.013395005138590932), (26, 0.013411890831775963), (25, 0.014773015980608761), (24, 0.01589584769681096), (22, 0.015945045044645667), (27, 0.016057065688073635), (23, 0.01718752016313374), (39, 0.019266640534624457), (38, 0.01931570074521005), (42, 0.019673911621794105), (5, 0.02111735218204558), (41, 0.021174799418076873), (43, 0.021180002484470606), (14, 0.021327617578208447), (44, 0.022253611125051975), (45, 0.023224937496706843), (47, 0.02422352065332234), (49, 0.024662331445142627), (40, 0.02475132793188095), (37, 0.025114945834502578), (21, 0.025540467584505677), (50, 0.025639905128628016), (3, 0.026626084465533495), (20, 0.02713091135956347), (46, 0.02807540912181139), (17, 0.03005285863764584), (51, 0.03030704683624208), (48, 0.031094568548724055), (19, 0.03459096746519208), (16, 0.044494171161204576), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358900085092), (13, 0.0641754250973463), (52, 0.06632223632186651), (8, 0.07143167871981859), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3418983332812786), (18, 0.48187143355607986), (53, 0.9368007406592369)]
computing accuracy for after removing block 35 . block score: 0.010489318054169416
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 1 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 2 val accuracy 0.8198 topk_dict {'top1': 0.8198} is_best False lr [0.1]
training epoch 3 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 4 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 5 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 6 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 7 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 8 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 9 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 10 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.010985722066834569), (32, 0.011304144863970578), (28, 0.01222222566138953), (29, 0.013395005138590932), (26, 0.013411890366114676), (25, 0.01477301586419344), (24, 0.015895847463980317), (22, 0.01594504597596824), (27, 0.01605706592090428), (23, 0.017187519930303097), (38, 0.018365239491686225), (39, 0.018731158692389727), (42, 0.01884545711800456), (41, 0.020227219676598907), (43, 0.020478624617680907), (5, 0.02111735218204558), (14, 0.021327618043869734), (44, 0.02179614081978798), (45, 0.022849174914881587), (47, 0.023645550245419145), (40, 0.023893442703410983), (49, 0.02401263010688126), (37, 0.024080609204247594), (50, 0.025119470432400703), (21, 0.025540467351675034), (3, 0.02662608353421092), (20, 0.02713090949691832), (46, 0.027472960762679577), (51, 0.029444649815559387), (17, 0.030052859568968415), (48, 0.030196278588846326), (19, 0.034590966533869505), (16, 0.044494173023849726), (15, 0.04618462594226003), (0, 0.0474615478888154), (4, 0.05093385046347976), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358853518963), (13, 0.06417542695999146), (52, 0.06433123257011175), (8, 0.07143167685717344), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.335262943059206), (18, 0.48187144473195076), (53, 0.958902545273304)]
computing accuracy for after removing block 33 . block score: 0.010985722066834569
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144747555256), (28, 0.01222222566138953), (29, 0.013395004440099001), (26, 0.013411890482529998), (25, 0.014773015631362796), (24, 0.015895847463980317), (22, 0.015945045743137598), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.01785989780910313), (39, 0.018481213599443436), (42, 0.018494685413315892), (41, 0.019707751227542758), (43, 0.01980409841053188), (5, 0.021117352414876223), (14, 0.02132761850953102), (44, 0.021341139683499932), (45, 0.022757312515750527), (47, 0.022884674835950136), (40, 0.02296416345052421), (49, 0.023509372724220157), (37, 0.023596108658239245), (50, 0.024730789940804243), (21, 0.025540467584505677), (3, 0.026626083999872208), (46, 0.026851587928831577), (20, 0.027130910428240895), (51, 0.02867021202109754), (48, 0.02950064977630973), (17, 0.03005285863764584), (19, 0.034590966533869505), (16, 0.04449417348951101), (15, 0.04618462594226003), (0, 0.04746154509484768), (4, 0.050933849066495895), (7, 0.05248213233426213), (6, 0.05318683199584484), (52, 0.062409017235040665), (10, 0.06307358760386705), (13, 0.06417542416602373), (8, 0.07143167965114117), (12, 0.0729450797662139), (11, 0.07423978764563799), (9, 0.0819232165813446), (36, 0.3304997459053993), (18, 0.48187143355607986), (53, 0.9826682731509209)]
computing accuracy for after removing block 32 . block score: 0.011304144747555256
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012222. All blocks and scores: [(28, 0.012222225428558886), (29, 0.013395004789344966), (26, 0.013411891064606607), (25, 0.01477301586419344), (24, 0.015895847929641604), (22, 0.015945045510306954), (27, 0.01605706545524299), (23, 0.017187520395964384), (38, 0.017423493089154363), (42, 0.01785332732833922), (39, 0.018243112368509173), (41, 0.01957745524123311), (43, 0.019590671872720122), (44, 0.02097980212420225), (5, 0.021117351949214935), (14, 0.02132761781103909), (47, 0.022578312316909432), (45, 0.022697478532791138), (37, 0.02285339031368494), (49, 0.02319051558151841), (40, 0.02322787162847817), (50, 0.024362223222851753), (21, 0.02554046781733632), (46, 0.026505473535507917), (3, 0.026626083767041564), (20, 0.027130911126732826), (51, 0.02819360839203), (48, 0.02943548816256225), (17, 0.030052858404815197), (19, 0.034590966533869505), (16, 0.04449417348951101), (15, 0.04618462733924389), (0, 0.047461549285799265), (4, 0.050933847203850746), (7, 0.05248213326558471), (6, 0.053186831064522266), (52, 0.061633951030671597), (10, 0.06307358667254448), (13, 0.06417542789131403), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423978764563799), (9, 0.08192321471869946), (36, 0.3290293700993061), (18, 0.48187144100666046), (53, 0.9939456805586815)]
computing accuracy for after removing block 28 . block score: 0.012222225428558886
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.013134. All blocks and scores: [(29, 0.013134447624906898), (26, 0.013411890249699354), (25, 0.014773015980608761), (24, 0.01589584699831903), (22, 0.015945045510306954), (27, 0.01605706592090428), (38, 0.017168684862554073), (23, 0.01718752016313374), (42, 0.01737769739702344), (39, 0.01826188713312149), (43, 0.01912656961940229), (41, 0.01942130969837308), (44, 0.020716934697702527), (5, 0.021117350785061717), (14, 0.021327617578208447), (47, 0.022124751238152385), (45, 0.02240564743988216), (37, 0.02259774226695299), (40, 0.02269273530691862), (49, 0.022759286453947425), (50, 0.024160553701221943), (21, 0.025540467351675034), (46, 0.02618824504315853), (3, 0.02662608353421092), (20, 0.027130911126732826), (51, 0.02760661649517715), (48, 0.028955485206097364), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.04449417069554329), (15, 0.0461846268735826), (0, 0.04746154649183154), (4, 0.05093384999781847), (7, 0.05248213466256857), (6, 0.05318683013319969), (52, 0.06071764323860407), (10, 0.06307358993217349), (13, 0.0641754250973463), (8, 0.07143168058246374), (12, 0.07294507697224617), (11, 0.07423978950828314), (9, 0.08192321565002203), (36, 0.3257451429963112), (18, 0.48187143728137016), (53, 1.0072815790772438)]
computing accuracy for after removing block 29 . block score: 0.013134447624906898
removed block 29 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013412. All blocks and scores: [(26, 0.013411890366114676), (25, 0.014773016213439405), (24, 0.015895846765488386), (22, 0.015945045743137598), (27, 0.016057066386565566), (38, 0.01652834750711918), (23, 0.017187519231811166), (42, 0.017526801442727447), (39, 0.018013010499998927), (43, 0.018969026627019048), (41, 0.01922021503560245), (44, 0.020273722242563963), (5, 0.021117351483553648), (14, 0.02132761781103909), (47, 0.02195585472509265), (45, 0.02227604645304382), (49, 0.02234107838012278), (37, 0.02238200604915619), (40, 0.022958484711125493), (50, 0.02405754243955016), (21, 0.02554046781733632), (46, 0.026293947594240308), (3, 0.026626083767041564), (20, 0.027130910428240895), (51, 0.027329841628670692), (48, 0.02898393222130835), (17, 0.03005285863764584), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384860083461), (7, 0.052482133731245995), (6, 0.053186831530183554), (52, 0.060349025297909975), (10, 0.06307358667254448), (13, 0.06417542416602373), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321378737688), (36, 0.33013898879289627), (18, 0.48187143728137016), (53, 1.01447045058012)]
computing accuracy for after removing block 26 . block score: 0.013411890366114676
removed block 26 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014773. All blocks and scores: [(25, 0.014773015980608761), (24, 0.01589584769681096), (22, 0.015945045510306954), (38, 0.01635145698674023), (27, 0.016416134545579553), (42, 0.01696831127628684), (23, 0.017187519930303097), (39, 0.017595985671505332), (43, 0.018648818135261536), (41, 0.018973202910274267), (44, 0.02003990998491645), (5, 0.02111735171638429), (14, 0.021327617578208447), (47, 0.021771238651126623), (45, 0.02202610089443624), (49, 0.022116393083706498), (37, 0.02216550288721919), (40, 0.02265410707332194), (50, 0.02414753893390298), (21, 0.025540467584505677), (46, 0.025726865511387587), (51, 0.02658225712366402), (3, 0.02662608283571899), (20, 0.027130911126732826), (48, 0.02889638813212514), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462501093745), (0, 0.0474615478888154), (4, 0.05093384953215718), (7, 0.052482135128229856), (6, 0.05318683013319969), (52, 0.05931285256519914), (10, 0.06307358760386705), (13, 0.06417542602866888), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.32769154012203217), (18, 0.48187143728137016), (53, 1.0349864959716797)]
computing accuracy for after removing block 25 . block score: 0.014773015980608761
removed block 25 current accuracy 0.9936 loss from initial  0.006399999999999961
training start
training epoch 0 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 1 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 2 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 3 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.1]
training epoch 4 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 5 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 6 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 7 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 8 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 9 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 10 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993600)
finished training. finished 50 epochs. accuracy 0.9936 topk_dict {'top1': 0.9936}
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.015896. All blocks and scores: [(24, 0.015895847463980317), (22, 0.015945045510306954), (38, 0.0161167464684695), (27, 0.016201819060370326), (42, 0.016800900222733617), (39, 0.017148226033896208), (23, 0.017187519930303097), (43, 0.018563210498541594), (41, 0.01888616499491036), (44, 0.0199774201028049), (5, 0.021117351483553648), (14, 0.02132761897519231), (47, 0.021370713599026203), (49, 0.021683972794562578), (45, 0.021750156534835696), (37, 0.021764446748420596), (40, 0.022557188058272004), (50, 0.024213683092966676), (21, 0.025540467584505677), (46, 0.025579197565093637), (51, 0.02589200669899583), (3, 0.026626083301380277), (20, 0.027130911126732826), (48, 0.0284209952224046), (17, 0.030052858870476484), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.04618462501093745), (0, 0.0474615478888154), (4, 0.050933849066495895), (7, 0.05248213419690728), (6, 0.05318683013319969), (52, 0.05805371981114149), (10, 0.06307358806952834), (13, 0.06417542789131403), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3308594338595867), (18, 0.48187143728137016), (53, 1.048815280199051)]
computing accuracy for after removing block 24 . block score: 0.015895847463980317
removed block 24 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015644. All blocks and scores: [(27, 0.015644042170606554), (38, 0.015937610529363155), (22, 0.01594504527747631), (42, 0.016610756050795317), (39, 0.017013836186379194), (23, 0.017187519930303097), (43, 0.018406943418085575), (41, 0.01871691015549004), (44, 0.01980676525272429), (47, 0.021023611538112164), (5, 0.021117351250723004), (14, 0.02132761781103909), (49, 0.021376668009907007), (45, 0.021665899315848947), (37, 0.022019794210791588), (40, 0.022359848022460938), (50, 0.0240969096776098), (46, 0.025163474259898067), (51, 0.02526901033706963), (21, 0.025540467584505677), (3, 0.026626083999872208), (20, 0.027130910893902183), (48, 0.02797303651459515), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.04449417069554329), (15, 0.046184628270566463), (0, 0.04746154695749283), (4, 0.05093384813517332), (7, 0.05248213279992342), (6, 0.053186831530183554), (52, 0.05717874551191926), (10, 0.06307358713820577), (13, 0.0641754250973463), (8, 0.07143167965114117), (12, 0.07294508069753647), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3319184258580208), (18, 0.48187142610549927), (53, 1.0561507940292358)]
computing accuracy for after removing block 27 . block score: 0.015644042170606554
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.015308. All blocks and scores: [(38, 0.015307825873605907), (22, 0.01594504527747631), (42, 0.01651047053746879), (39, 0.016512590693309903), (23, 0.017187519697472453), (43, 0.017808300908654928), (41, 0.018523185746744275), (44, 0.019996798364445567), (47, 0.02054019528441131), (49, 0.021024908171966672), (5, 0.02111735218204558), (14, 0.021327617578208447), (45, 0.021421734942123294), (37, 0.021547694690525532), (40, 0.02197462203912437), (50, 0.02440070523880422), (46, 0.024719235487282276), (51, 0.024754389887675643), (21, 0.025540467351675034), (3, 0.02662608423270285), (20, 0.02713091066107154), (48, 0.027608850272372365), (17, 0.03005285793915391), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384860083461), (7, 0.05248213466256857), (6, 0.053186831064522266), (52, 0.05619245767593384), (10, 0.06307358667254448), (13, 0.06417542789131403), (8, 0.07143168058246374), (12, 0.07294507883489132), (11, 0.07423978950828314), (9, 0.08192321937531233), (36, 0.3304779417812824), (18, 0.48187142983078957), (53, 1.066792979836464)]
computing accuracy for after removing block 38 . block score: 0.015307825873605907
removed block 38 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.015945. All blocks and scores: [(22, 0.01594504527747631), (42, 0.0167012014426291), (39, 0.01711469143629074), (23, 0.01718752016313374), (43, 0.017193771665915847), (41, 0.018250516382977366), (44, 0.019619957078248262), (47, 0.02009119000285864), (49, 0.020288462284952402), (45, 0.0208028273191303), (5, 0.02111735171638429), (14, 0.02132761781103909), (37, 0.02154769515618682), (40, 0.022401680005714297), (50, 0.023554303450509906), (51, 0.023709412897005677), (46, 0.024713725550100207), (21, 0.025540467351675034), (3, 0.026626083767041564), (48, 0.026906078681349754), (20, 0.027130910893902183), (17, 0.030052859568968415), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.04618462594226003), (0, 0.04746154695749283), (4, 0.050933849066495895), (7, 0.052482135128229856), (6, 0.05318683013319969), (52, 0.05467723123729229), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143167965114117), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.330477949231863), (18, 0.48187144100666046), (53, 1.099235475063324)]
computing accuracy for after removing block 22 . block score: 0.01594504527747631
removed block 22 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.019400000000000084 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.016116. All blocks and scores: [(42, 0.016115854494273663), (23, 0.01675163395702839), (39, 0.017163580050691962), (43, 0.017340539023280144), (41, 0.018351152073591948), (44, 0.01973160356283188), (47, 0.019744617165997624), (49, 0.019967120373621583), (45, 0.020839693024754524), (5, 0.021117350785061717), (14, 0.021327618043869734), (37, 0.021559265442192554), (40, 0.02183614717796445), (51, 0.023225211538374424), (50, 0.023681906517595053), (46, 0.02471963968127966), (21, 0.025540468748658895), (48, 0.02641315315850079), (3, 0.026626083999872208), (20, 0.027130910428240895), (17, 0.030052859103307128), (19, 0.03459096606820822), (16, 0.044494171161204576), (15, 0.0461846268735826), (0, 0.0474615478888154), (4, 0.05093384813517332), (7, 0.05248213466256857), (6, 0.05318683059886098), (52, 0.05412210803478956), (10, 0.06307358667254448), (13, 0.06417542602866888), (8, 0.07143167685717344), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.0819232165813446), (36, 0.3307998776435852), (18, 0.48187143355607986), (53, 1.1102152317762375)]
computing accuracy for after removing block 42 . block score: 0.016115854494273663
removed block 42 current accuracy 0.9696 loss from initial  0.030399999999999983
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016752. All blocks and scores: [(23, 0.016751634189859033), (39, 0.017163580050691962), (41, 0.018351152539253235), (43, 0.01839060429483652), (49, 0.01983269746415317), (47, 0.019929534988477826), (44, 0.02070042653940618), (5, 0.021117351949214935), (14, 0.021327617345377803), (37, 0.02155926520936191), (45, 0.021742522018030286), (40, 0.021836147410795093), (51, 0.02259360929019749), (50, 0.02351996209472418), (46, 0.025376978097483516), (21, 0.02554046711884439), (48, 0.02606480778194964), (3, 0.02662608353421092), (20, 0.027130910893902183), (17, 0.03005285980179906), (19, 0.03459096746519208), (16, 0.04449417209252715), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384813517332), (52, 0.05230193678289652), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358900085092), (13, 0.0641754250973463), (8, 0.07143167778849602), (12, 0.07294507697224617), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3307998776435852), (18, 0.48187144845724106), (53, 1.1384830176830292)]
computing accuracy for after removing block 23 . block score: 0.016751634189859033
removed block 23 current accuracy 0.9584 loss from initial  0.04159999999999997
training start
training epoch 0 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 1 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 2 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 3 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 4 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 5 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 6 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 7 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 8 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 9 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.1]
training epoch 10 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.970600)
finished training. finished 50 epochs. accuracy 0.9706 topk_dict {'top1': 0.9706}
start iteration 18
[activation diff]: block to remove picked: 5, with score 0.035151. All blocks and scores: [(5, 0.03515057871118188), (44, 0.037407446186989546), (41, 0.03852835111320019), (50, 0.03895116224884987), (14, 0.040336221922189), (51, 0.04037300869822502), (39, 0.04039812460541725), (45, 0.04156510112807155), (43, 0.041882636956870556), (49, 0.04224662808701396), (47, 0.04427842749282718), (40, 0.04471792373806238), (48, 0.04708579648286104), (46, 0.04747142642736435), (3, 0.049340616911649704), (37, 0.05365279829129577), (20, 0.05846158927306533), (17, 0.06291204923763871), (52, 0.06687698978930712), (19, 0.0680356789380312), (21, 0.0766709828749299), (0, 0.08318337425589561), (15, 0.08648975100368261), (16, 0.08684494253247976), (6, 0.08884587325155735), (7, 0.10243787337094545), (4, 0.1052730642259121), (10, 0.10730440448969603), (8, 0.11555946804583073), (12, 0.128459881991148), (11, 0.13142779096961021), (13, 0.13948707655072212), (9, 0.1440690942108631), (18, 0.6301502734422684), (36, 0.650579184293747), (53, 1.0936191380023956)]
computing accuracy for after removing block 5 . block score: 0.03515057871118188
removed block 5 current accuracy 0.9632 loss from initial  0.036800000000000055
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.037471. All blocks and scores: [(44, 0.03747105598449707), (41, 0.03837376041337848), (14, 0.03858637949451804), (50, 0.03889452340081334), (51, 0.03995882533490658), (39, 0.040880429558455944), (49, 0.04164703842252493), (45, 0.04183072876185179), (43, 0.041857773903757334), (47, 0.04417440481483936), (40, 0.046547680627554655), (48, 0.04719084361568093), (46, 0.047499862033873796), (3, 0.04934061877429485), (37, 0.05517726205289364), (20, 0.0567641849629581), (17, 0.06007128953933716), (52, 0.06631333660334349), (19, 0.06717452872544527), (21, 0.07517245598137379), (0, 0.08318336959928274), (16, 0.08346603624522686), (15, 0.08487421367317438), (6, 0.0934289675205946), (7, 0.10373659990727901), (4, 0.10527306515723467), (10, 0.10619933437556028), (8, 0.11521568614989519), (11, 0.12172882631421089), (12, 0.12594631873071194), (13, 0.13724946416914463), (9, 0.1464559305459261), (18, 0.630235493183136), (36, 0.6557090803980827), (53, 1.0971560925245285)]
computing accuracy for after removing block 44 . block score: 0.03747105598449707
removed block 44 current accuracy 0.96 loss from initial  0.040000000000000036
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.037903. All blocks and scores: [(50, 0.037903057876974344), (41, 0.0383737594820559), (14, 0.03858637996017933), (51, 0.03876200458034873), (39, 0.04088042723014951), (49, 0.04149518860504031), (43, 0.041857773903757334), (47, 0.043803511187434196), (45, 0.04462567437440157), (40, 0.046547680627554655), (48, 0.047431763261556625), (46, 0.049156537745147943), (3, 0.049340616911649704), (37, 0.05517726205289364), (20, 0.05676418403163552), (17, 0.060071288608014584), (52, 0.06507677584886551), (19, 0.06717452872544527), (21, 0.07517245411872864), (0, 0.08318337239325047), (16, 0.08346603903919458), (15, 0.08487420994788408), (6, 0.0934289675205946), (7, 0.10373660176992416), (4, 0.10527306515723467), (10, 0.10619933251291513), (8, 0.11521568801254034), (11, 0.12172882817685604), (12, 0.12594631873071194), (13, 0.13724946789443493), (9, 0.14645593240857124), (18, 0.6302354857325554), (36, 0.6557090952992439), (53, 1.1419850289821625)]
computing accuracy for after removing block 50 . block score: 0.037903057876974344
removed block 50 current accuracy 0.95 loss from initial  0.050000000000000044
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.038374. All blocks and scores: [(41, 0.03837375994771719), (14, 0.03858637996017933), (39, 0.04088042862713337), (49, 0.041495188139379025), (43, 0.041857773903757334), (47, 0.043803511653095484), (45, 0.04462567437440157), (51, 0.044680843595415354), (40, 0.04654768109321594), (48, 0.047431765124201775), (46, 0.04915653867647052), (3, 0.04934061784297228), (37, 0.05517726158723235), (20, 0.056764187291264534), (17, 0.06007128953933716), (19, 0.06717452965676785), (52, 0.07130865473300219), (21, 0.07517245318740606), (0, 0.08318337239325047), (16, 0.08346603345125914), (15, 0.08487421087920666), (6, 0.0934289675205946), (7, 0.10373660176992416), (4, 0.10527306329458952), (10, 0.10619933251291513), (8, 0.11521568801254034), (11, 0.12172882910817862), (12, 0.12594632431864738), (13, 0.13724946416914463), (9, 0.1464559342712164), (18, 0.6302354782819748), (36, 0.6557090505957603), (53, 1.2295962274074554)]
computing accuracy for after removing block 41 . block score: 0.03837375994771719
removed block 41 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.026600000000000068 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 14, with score 0.038586. All blocks and scores: [(14, 0.03858637996017933), (49, 0.04009639611467719), (39, 0.04088042862713337), (47, 0.04239599732682109), (51, 0.04365607677027583), (43, 0.04415374808013439), (45, 0.04521658690646291), (40, 0.04654768109321594), (48, 0.0467283776961267), (46, 0.04877130640670657), (3, 0.04934061784297228), (37, 0.0551772634498775), (20, 0.05676418403163552), (17, 0.060071288142353296), (19, 0.06717452965676785), (52, 0.070712068118155), (21, 0.07517245598137379), (0, 0.08318337053060532), (16, 0.08346603624522686), (15, 0.08487421087920666), (6, 0.09342896845191717), (7, 0.10373659897595644), (4, 0.10527306329458952), (10, 0.10619933437556028), (8, 0.11521568894386292), (11, 0.12172883097082376), (12, 0.1259463168680668), (13, 0.13724945858120918), (9, 0.1464559342712164), (18, 0.6302355006337166), (36, 0.6557090878486633), (53, 1.2748916894197464)]
computing accuracy for after removing block 14 . block score: 0.03858637996017933
removed block 14 current accuracy 0.9442 loss from initial  0.05579999999999996
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 49, with score 0.041115. All blocks and scores: [(49, 0.041115098632872105), (51, 0.042605094611644745), (47, 0.043011216912418604), (39, 0.043438369408249855), (40, 0.04638607334345579), (45, 0.046681109350174665), (48, 0.046874493826180696), (43, 0.046893185935914516), (3, 0.04934061970561743), (46, 0.04981645569205284), (37, 0.05507069127634168), (20, 0.0555901606567204), (17, 0.06368632148951292), (52, 0.07124853692948818), (19, 0.07139779813587666), (21, 0.07284220308065414), (16, 0.08306612819433212), (0, 0.08318337332457304), (15, 0.08948625158518553), (6, 0.09342896938323975), (7, 0.10373660176992416), (4, 0.10527306329458952), (10, 0.10619933158159256), (8, 0.11521568521857262), (11, 0.12172882910817862), (12, 0.12594631873071194), (13, 0.13724946416914463), (9, 0.1464559342712164), (18, 0.6295243501663208), (36, 0.6616800352931023), (53, 1.2217440456151962)]
computing accuracy for after removing block 49 . block score: 0.041115098632872105
removed block 49 current accuracy 0.9282 loss from initial  0.07179999999999997
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.043011. All blocks and scores: [(47, 0.04301121924072504), (39, 0.04343837033957243), (40, 0.046386076137423515), (45, 0.04668110841885209), (48, 0.046874494291841984), (43, 0.04689318360760808), (51, 0.04816369852051139), (3, 0.049340616911649704), (46, 0.04981645569205284), (37, 0.0550706903450191), (20, 0.055590163450688124), (17, 0.06368632335215807), (19, 0.0713977999985218), (21, 0.07284220308065414), (52, 0.07794006168842316), (16, 0.08306612819433212), (0, 0.08318337332457304), (15, 0.08948625065386295), (6, 0.0934289712458849), (7, 0.10373660270124674), (4, 0.10527306143194437), (10, 0.10619933530688286), (8, 0.11521568987518549), (11, 0.12172882817685604), (12, 0.1259463205933571), (13, 0.13724946603178978), (9, 0.1464559305459261), (18, 0.629524365067482), (36, 0.6616800278425217), (53, 1.2601028680801392)]
computing accuracy for after removing block 47 . block score: 0.04301121924072504
removed block 47 current accuracy 0.899 loss from initial  0.10099999999999998
since last training loss: 0.0716 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 39, with score 0.043438. All blocks and scores: [(39, 0.04343837173655629), (40, 0.046386074274778366), (45, 0.046681109350174665), (43, 0.046893185935914516), (3, 0.04934061877429485), (46, 0.04981645755469799), (48, 0.05028112651780248), (51, 0.05077565088868141), (37, 0.055070691742002964), (20, 0.05559016112238169), (17, 0.06368632428348064), (19, 0.07139779720455408), (21, 0.0728422049432993), (52, 0.07871507480740547), (16, 0.08306613005697727), (0, 0.08318337518721819), (15, 0.08948625065386295), (6, 0.09342896845191717), (7, 0.10373660176992416), (4, 0.10527306608855724), (10, 0.10619933530688286), (8, 0.11521568894386292), (11, 0.12172882538288832), (12, 0.12594631873071194), (13, 0.13724946230649948), (9, 0.1464559342712164), (18, 0.629524365067482), (36, 0.6616800352931023), (53, 1.3694241791963577)]
computing accuracy for after removing block 39 . block score: 0.04343837173655629
removed block 39 current accuracy 0.8926 loss from initial  0.10740000000000005
since last training loss: 0.07800000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.048229. All blocks and scores: [(45, 0.0482294331304729), (43, 0.04906812496483326), (3, 0.049340618308633566), (40, 0.05048703774809837), (51, 0.05055925250053406), (48, 0.050588341895490885), (46, 0.05129841389134526), (37, 0.055070689879357815), (20, 0.0555901606567204), (17, 0.06368632521480322), (19, 0.07139779813587666), (21, 0.0728422049432993), (52, 0.07948218006640673), (16, 0.08306613098829985), (0, 0.08318337332457304), (15, 0.08948625344783068), (6, 0.09342896658927202), (7, 0.10373659990727901), (4, 0.10527306143194437), (10, 0.10619933158159256), (8, 0.11521568521857262), (11, 0.12172883003950119), (12, 0.1259463168680668), (13, 0.13724946603178978), (9, 0.1464559305459261), (18, 0.6295243501663208), (36, 0.6616800278425217), (53, 1.3814774453639984)]
computing accuracy for after removing block 45 . block score: 0.0482294331304729
removed block 45 current accuracy 0.8534 loss from initial  0.14659999999999995
training start
training epoch 0 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best True lr [0.1]
training epoch 1 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 2 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 3 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 4 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 5 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 7 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 8 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.1]
training epoch 9 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 10 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.952800)
finished training. finished 50 epochs. accuracy 0.9528 topk_dict {'top1': 0.9528}
