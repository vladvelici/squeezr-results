start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.008455108851194382), (30, 0.009703245712444186), (33, 0.01111594308167696), (34, 0.011622709920629859), (31, 0.012275203131139278), (28, 0.012290219543501735), (29, 0.014791248831897974), (27, 0.016729247756302357), (26, 0.017444903263822198), (1, 0.018259593285620213), (7, 0.018379185581579804), (8, 0.019532452803105116), (25, 0.019648710498586297), (35, 0.019787947181612253), (24, 0.020829483401030302), (22, 0.02102166088297963), (23, 0.021574512356892228), (47, 0.02254638378508389), (44, 0.023842158960178494), (41, 0.02416854677721858), (46, 0.024651075014844537), (6, 0.024668580386787653), (21, 0.025249343132600188), (43, 0.02580355410464108), (10, 0.026363696437329054), (42, 0.026426069671288133), (4, 0.026659545488655567), (45, 0.026823592837899923), (39, 0.026881904806941748), (40, 0.026893552858382463), (49, 0.027856426313519478), (48, 0.028491602977737784), (50, 0.028780476422980428), (11, 0.029002358205616474), (38, 0.029662920394912362), (3, 0.03227204084396362), (13, 0.033336535561829805), (37, 0.03576205763965845), (20, 0.03646321874111891), (12, 0.03799272142350674), (9, 0.03963937144726515), (51, 0.039642106741666794), (19, 0.044218875002115965), (52, 0.04580832691863179), (15, 0.04691674839705229), (14, 0.04904163861647248), (2, 0.05722745694220066), (0, 0.058882576413452625), (16, 0.06225228821858764), (5, 0.09379573911428452), (17, 0.25432228296995163), (36, 0.41727548465132713), (18, 0.4852069206535816), (53, 0.7453346624970436)]
computing accuracy for after removing block 32 . block score: 0.008455108851194382
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.00970324594527483), (33, 0.011199889704585075), (34, 0.011937809525988996), (31, 0.0122752032475546), (28, 0.012290219427086413), (29, 0.014791248016990721), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.018259592819958925), (7, 0.01837918604724109), (8, 0.019532453268766403), (25, 0.019648710265755653), (35, 0.02043134206905961), (24, 0.020829484099522233), (22, 0.02102166088297963), (23, 0.02157451305538416), (47, 0.02226210874505341), (44, 0.02329323347657919), (41, 0.02379581518471241), (46, 0.024043594487011433), (6, 0.02466858085244894), (21, 0.025249343598261476), (43, 0.025525057455524802), (42, 0.026236766017973423), (40, 0.02631577244028449), (10, 0.026363696670159698), (4, 0.026659545954316854), (45, 0.026667137863114476), (39, 0.026886871084570885), (49, 0.02732702624052763), (48, 0.027911514043807983), (50, 0.028208705596625805), (38, 0.028610609006136656), (11, 0.029002359369769692), (3, 0.03227203991264105), (13, 0.03333653509616852), (37, 0.03469931660220027), (20, 0.03646321874111891), (12, 0.03799272142350674), (51, 0.039370250422507524), (9, 0.039639370515942574), (19, 0.044218875002115965), (52, 0.04512502020224929), (15, 0.04691674839705229), (14, 0.04904163768514991), (2, 0.05722745694220066), (0, 0.0588825773447752), (16, 0.062252290081232786), (5, 0.09379573818296194), (17, 0.25432228296995163), (36, 0.4077853001654148), (18, 0.4852069243788719), (53, 0.7581149265170097)]
computing accuracy for after removing block 30 . block score: 0.00970324594527483
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006661556661), (34, 0.011887529166415334), (28, 0.012290219310671091), (31, 0.012499805074185133), (29, 0.014791248715482652), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.018259593285620213), (7, 0.018379185581579804), (8, 0.019532452803105116), (25, 0.01964871142990887), (35, 0.02071700314991176), (24, 0.02082948316819966), (22, 0.021021660650148988), (23, 0.021574512822553515), (47, 0.022107098484411836), (44, 0.02311369380913675), (46, 0.023742159828543663), (41, 0.023929199669510126), (6, 0.024668580619618297), (21, 0.025249343365430832), (43, 0.025264927418902516), (40, 0.026247451081871986), (10, 0.026363696670159698), (42, 0.026527423411607742), (4, 0.026659545954316854), (45, 0.02671261061914265), (39, 0.0270345292519778), (49, 0.027338512474671006), (48, 0.02790993917733431), (50, 0.02795650903135538), (38, 0.028708983212709427), (11, 0.029002359369769692), (3, 0.03227204130962491), (13, 0.03333653463050723), (37, 0.034348325338214636), (20, 0.036463219206780195), (12, 0.03799272095784545), (51, 0.039133232086896896), (9, 0.03963937098160386), (19, 0.04421887593343854), (52, 0.04478001967072487), (15, 0.04691674839705229), (14, 0.04904163768514991), (2, 0.0572274555452168), (0, 0.05888257781043649), (16, 0.06225228775292635), (5, 0.09379573818296194), (17, 0.25432227924466133), (36, 0.40603339672088623), (18, 0.4852069243788719), (53, 0.7581836208701134)]
computing accuracy for after removing block 33 . block score: 0.011317006661556661
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.012240082141943276), (28, 0.012290218961425126), (31, 0.012499805307015777), (29, 0.014791248482652009), (27, 0.016729248221963644), (26, 0.017444903263822198), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.019532452570274472), (25, 0.019648710964247584), (24, 0.020829483401030302), (22, 0.02102166088297963), (35, 0.0214772445615381), (23, 0.02157451375387609), (47, 0.021933730458840728), (44, 0.02281996817328036), (46, 0.02339849714189768), (41, 0.02404660196043551), (6, 0.024668580386787653), (21, 0.02524934383109212), (43, 0.0254047648049891), (40, 0.026019647484645247), (10, 0.026363696670159698), (4, 0.026659545488655567), (42, 0.026750181568786502), (45, 0.02678381372243166), (49, 0.027069833828136325), (39, 0.02749612065963447), (48, 0.027574570383876562), (50, 0.02794637018814683), (38, 0.028736303094774485), (11, 0.029002360068261623), (3, 0.03227203991264105), (13, 0.03333653509616852), (37, 0.034059048630297184), (20, 0.036463219206780195), (12, 0.03799272142350674), (51, 0.03880898002535105), (9, 0.039639370050281286), (19, 0.04421887639909983), (52, 0.04450395004823804), (15, 0.04691674979403615), (14, 0.049041638150811195), (2, 0.05722745507955551), (0, 0.058882576413452625), (16, 0.0622522896155715), (5, 0.09379574097692966), (17, 0.25432228669524193), (36, 0.40450604259967804), (18, 0.4852069206535816), (53, 0.7641192972660065)]
computing accuracy for after removing block 34 . block score: 0.012240082141943276
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.01229021919425577), (31, 0.012499805074185133), (29, 0.014791248482652009), (27, 0.016729247989133), (26, 0.01744490349665284), (1, 0.018259593285620213), (7, 0.01837918534874916), (8, 0.01953245303593576), (25, 0.019648710498586297), (24, 0.020829484099522233), (22, 0.021021660650148988), (23, 0.02157451375387609), (35, 0.021708655869588256), (47, 0.02180175483226776), (44, 0.0224381135776639), (46, 0.023336909012869), (41, 0.023686284897848964), (6, 0.02466858015395701), (21, 0.025249343132600188), (43, 0.025404839543625712), (40, 0.025569376768544316), (10, 0.02636369550600648), (42, 0.026551801012828946), (39, 0.026582872727885842), (49, 0.026649241568520665), (4, 0.026659545954316854), (45, 0.026776784798130393), (48, 0.026865947060287), (50, 0.027566449949517846), (38, 0.02782911784015596), (11, 0.029002359602600336), (3, 0.03227204084396362), (37, 0.033198120072484016), (13, 0.03333653416484594), (20, 0.036463219206780195), (12, 0.03799272095784545), (51, 0.038059926591813564), (9, 0.03963937144726515), (52, 0.04353108070790768), (19, 0.04421887593343854), (15, 0.04691674746572971), (14, 0.049041638150811195), (2, 0.057227456010878086), (0, 0.058882574550807476), (16, 0.062252290546894073), (5, 0.09379573632031679), (17, 0.25432228296995163), (36, 0.3958275355398655), (18, 0.4852069467306137), (53, 0.7794358655810356)]
computing accuracy for after removing block 28 . block score: 0.01229021919425577
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645366333425), (29, 0.014790621120482683), (27, 0.016729247756302357), (26, 0.01744490349665284), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532452803105116), (25, 0.019648709800094366), (24, 0.020829483401030302), (22, 0.021021660650148988), (47, 0.021346517838537693), (23, 0.021574513986706734), (35, 0.02159673348069191), (44, 0.021918716374784708), (46, 0.02273467485792935), (41, 0.02322802832350135), (6, 0.02466858015395701), (40, 0.024839135818183422), (43, 0.024858604883775115), (21, 0.025249343132600188), (39, 0.025966263841837645), (48, 0.02597146388143301), (42, 0.025991315487772226), (49, 0.026064811507239938), (10, 0.02636369550600648), (45, 0.026453920174390078), (4, 0.02665954572148621), (50, 0.026680127950385213), (38, 0.027020083041861653), (11, 0.02900235913693905), (37, 0.032236404716968536), (3, 0.0322720417752862), (13, 0.03333653509616852), (20, 0.03646321967244148), (51, 0.03758792392909527), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.04288490163162351), (19, 0.04421887453645468), (15, 0.046916748862713575), (14, 0.04904163721948862), (2, 0.0572274555452168), (0, 0.05888257548213005), (16, 0.06225228821858764), (5, 0.09379573725163937), (17, 0.2543222773820162), (36, 0.3858989290893078), (18, 0.485206913203001), (53, 0.7881819158792496)]
computing accuracy for after removing block 31 . block score: 0.011874645366333425
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
training start
training epoch 0 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best False lr [0.1]
training epoch 1 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 2 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.1]
training epoch 5 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 6 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 7 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 8 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.1]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 10 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.998200)
finished training. finished 50 epochs. accuracy 0.9982 topk_dict {'top1': 0.9982}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.01479062088765204), (27, 0.016729247989133), (26, 0.017444903729483485), (1, 0.01825959258712828), (7, 0.018379185581579804), (8, 0.019532453501597047), (25, 0.01964871073141694), (24, 0.020829484099522233), (47, 0.020932047627866268), (22, 0.021021660417318344), (44, 0.021379181649535894), (23, 0.021574513521045446), (46, 0.02206318941898644), (35, 0.022440449567511678), (41, 0.022648891899734735), (40, 0.024130780482664704), (43, 0.02466420829296112), (6, 0.024668579921126366), (21, 0.025249343598261476), (48, 0.025250396691262722), (49, 0.0255158101208508), (42, 0.025626870105043054), (39, 0.025647578993812203), (38, 0.02585478196851909), (50, 0.025972345378249884), (45, 0.026165933813899755), (10, 0.026363695971667767), (4, 0.026659546652808785), (11, 0.029002360068261623), (37, 0.03128928900696337), (3, 0.03227203991264105), (13, 0.03333653509616852), (20, 0.036463219206780195), (51, 0.03728976100683212), (12, 0.037992720026522875), (9, 0.039639370515942574), (52, 0.0419921837747097), (19, 0.04421887546777725), (15, 0.046916747931391), (14, 0.04904163721948862), (2, 0.05722745647653937), (0, 0.05888257548213005), (16, 0.062252288684248924), (5, 0.09379573725163937), (17, 0.2543222904205322), (36, 0.37605970725417137), (18, 0.4852069206535816), (53, 0.801954098045826)]
computing accuracy for after removing block 29 . block score: 0.01479062088765204
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729247756302357), (26, 0.017444903729483485), (1, 0.01825959258712828), (7, 0.01837918604724109), (8, 0.019532452803105116), (25, 0.01964871073141694), (47, 0.020515699638053775), (24, 0.020829483633860946), (44, 0.0209751317743212), (22, 0.021021660417318344), (23, 0.02157451305538416), (46, 0.02165245171636343), (41, 0.022661817725747824), (35, 0.022723624017089605), (40, 0.023883074522018433), (43, 0.024189723655581474), (6, 0.02466858015395701), (48, 0.024881582939997315), (49, 0.02521235216408968), (42, 0.02522930153645575), (21, 0.025249343365430832), (38, 0.02545714331790805), (50, 0.025512879248708487), (39, 0.025584627175703645), (45, 0.0262109546456486), (10, 0.026363695971667767), (4, 0.026659546187147498), (11, 0.02900235913693905), (37, 0.031102394917979836), (3, 0.03227204084396362), (13, 0.033336535561829805), (20, 0.036463219206780195), (51, 0.03752173809334636), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.041576670948415995), (19, 0.04421887639909983), (15, 0.04691674979403615), (14, 0.04904163768514991), (2, 0.05722745647653937), (0, 0.05888257594779134), (16, 0.062252288684248924), (5, 0.09379573632031679), (17, 0.2543222848325968), (36, 0.3744278997182846), (18, 0.4852069169282913), (53, 0.8058174327015877)]
computing accuracy for after removing block 27 . block score: 0.016729247756302357
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017445. All blocks and scores: [(26, 0.017444903030991554), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.01953245303593576), (25, 0.019648711197078228), (47, 0.020196364959701896), (44, 0.02019877964630723), (24, 0.020829482935369015), (22, 0.02102166088297963), (46, 0.021314961602911353), (23, 0.021574513521045446), (35, 0.021661202190443873), (41, 0.022262451238930225), (40, 0.02343457192182541), (43, 0.02366974949836731), (48, 0.02387001784518361), (49, 0.02427303814329207), (39, 0.024631957756355405), (6, 0.02466858015395701), (50, 0.024705926422029734), (38, 0.02471397095359862), (42, 0.024764888919889927), (21, 0.025249343132600188), (45, 0.02590922056697309), (10, 0.026363696670159698), (4, 0.026659545488655567), (11, 0.029002360301092267), (37, 0.03029576176777482), (3, 0.032272042240947485), (13, 0.03333653509616852), (20, 0.03646321967244148), (51, 0.03686857596039772), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.04049280611798167), (19, 0.04421887407079339), (15, 0.046916748862713575), (14, 0.04904163861647248), (2, 0.057227454613894224), (0, 0.05888257594779134), (16, 0.06225228821858764), (5, 0.09379573911428452), (17, 0.25432227924466133), (36, 0.3650362491607666), (18, 0.4852069206535816), (53, 0.834727331995964)]
computing accuracy for after removing block 26 . block score: 0.017444903030991554
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018260. All blocks and scores: [(1, 0.01825959305278957), (7, 0.018379185581579804), (8, 0.019532452570274472), (25, 0.019648710498586297), (44, 0.019705433398485184), (47, 0.019746013451367617), (46, 0.020809160778298974), (24, 0.02082948386669159), (22, 0.0210216601844877), (35, 0.02119597070850432), (23, 0.021574513521045446), (41, 0.022163193207234144), (48, 0.022673573112115264), (40, 0.022844478487968445), (43, 0.02321144682355225), (49, 0.023580190492793918), (38, 0.023936916375532746), (39, 0.02414303505793214), (50, 0.02424125070683658), (42, 0.02446110569871962), (6, 0.02466858015395701), (21, 0.025249342899769545), (45, 0.025508657097816467), (10, 0.026363695738837123), (4, 0.026659546652808785), (11, 0.02900235913693905), (37, 0.029677377315238118), (3, 0.03227204130962491), (13, 0.033336535561829805), (51, 0.03632144583389163), (20, 0.03646321967244148), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.03989553265273571), (19, 0.04421887453645468), (15, 0.046916747000068426), (14, 0.049041636288166046), (2, 0.05722745694220066), (0, 0.058882576413452625), (16, 0.06225228728726506), (5, 0.09379573725163937), (17, 0.25432228296995163), (36, 0.36152271181344986), (18, 0.4852069243788719), (53, 0.8471468687057495)]
computing accuracy for after removing block 1 . block score: 0.01825959305278957
removed block 1 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017854. All blocks and scores: [(7, 0.017853512428700924), (8, 0.01868281955830753), (25, 0.019129085820168257), (44, 0.019602667773142457), (24, 0.019680223427712917), (47, 0.019842988345772028), (22, 0.020383452996611595), (35, 0.020452447002753615), (46, 0.02082586125470698), (23, 0.02108691749162972), (41, 0.02164033567532897), (48, 0.022305728401988745), (40, 0.022332167252898216), (43, 0.022896901471540332), (38, 0.023239596048370004), (39, 0.02338676364161074), (49, 0.023744063917547464), (50, 0.02402120502665639), (6, 0.024041746510192752), (42, 0.0242784908041358), (21, 0.024377909488976002), (45, 0.025495619047433138), (10, 0.02596128173172474), (11, 0.028003806248307228), (4, 0.028626713203266263), (37, 0.029063857160508633), (3, 0.032400965224951506), (13, 0.033244628459215164), (20, 0.03517247596755624), (51, 0.03656556457281113), (12, 0.03718129312619567), (9, 0.038683032151311636), (52, 0.0396947106346488), (19, 0.04354848060756922), (15, 0.047371077816933393), (14, 0.048121771309524775), (2, 0.05715902289375663), (0, 0.05888257781043649), (16, 0.06086174910888076), (5, 0.09224656596779823), (17, 0.2509492505341768), (36, 0.34972937777638435), (18, 0.46861379593610764), (53, 0.8498541340231895)]
computing accuracy for after removing block 7 . block score: 0.017853512428700924
removed block 7 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.018390. All blocks and scores: [(25, 0.018389766803011298), (24, 0.018951866077259183), (35, 0.01924196002073586), (47, 0.019434643210843205), (44, 0.01962489727884531), (23, 0.019739444134756923), (22, 0.019956301199272275), (8, 0.019966655876487494), (46, 0.02043476584367454), (41, 0.021304226480424404), (40, 0.021420422242954373), (48, 0.02182563953101635), (43, 0.02223287569358945), (38, 0.0225537302903831), (39, 0.02290530689060688), (21, 0.02331746951676905), (50, 0.023608923889696598), (49, 0.023631911259144545), (42, 0.024006218882277608), (6, 0.024041746277362108), (45, 0.025045356480404735), (10, 0.02616765908896923), (11, 0.02802672004327178), (37, 0.028401087503880262), (4, 0.028626713203266263), (3, 0.03240096475929022), (13, 0.03292407561093569), (20, 0.03404331021010876), (51, 0.03644961956888437), (12, 0.03690121462568641), (52, 0.03922955971211195), (9, 0.03934459341689944), (19, 0.04198857489973307), (15, 0.04630645737051964), (14, 0.047303914092481136), (2, 0.05715902289375663), (0, 0.05888257501646876), (16, 0.059412578120827675), (5, 0.09224656689912081), (17, 0.238845843821764), (36, 0.3409247510135174), (18, 0.45438622310757637), (53, 0.8508737683296204)]
computing accuracy for after removing block 25 . block score: 0.018389766803011298
removed block 25 current accuracy 0.988 loss from initial  0.01200000000000001
training start
training epoch 0 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 1 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 2 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 3 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 4 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 5 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 6 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 8 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 9 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 10 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.988000)
finished training. finished 50 epochs. accuracy 0.988 topk_dict {'top1': 0.988}
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.018641. All blocks and scores: [(35, 0.018640689784660935), (24, 0.018951865611597896), (47, 0.019162753596901894), (44, 0.01937291957437992), (23, 0.01973944390192628), (22, 0.019956301199272275), (8, 0.01996665564365685), (46, 0.020180067280307412), (41, 0.020792828407138586), (40, 0.02080647344700992), (48, 0.0210955454967916), (38, 0.021664810832589865), (43, 0.02204225491732359), (39, 0.02210295875556767), (50, 0.022921857191249728), (49, 0.022986744297668338), (21, 0.02331746951676905), (42, 0.023690476547926664), (6, 0.024041746510192752), (45, 0.025103285210207105), (10, 0.026167659321799874), (37, 0.02770885149948299), (11, 0.02802672004327178), (4, 0.02862671227194369), (3, 0.032400965224951506), (13, 0.03292407467961311), (20, 0.03404331114143133), (51, 0.03592319134622812), (12, 0.036901213228702545), (52, 0.038492195308208466), (9, 0.039344592951238155), (19, 0.04198857583105564), (15, 0.046306459698826075), (14, 0.04730391362681985), (2, 0.057159021496772766), (0, 0.058882574550807476), (16, 0.05941258044913411), (5, 0.09224656224250793), (17, 0.2388458475470543), (36, 0.33257048577070236), (18, 0.4543862119317055), (53, 0.8579949960112572)]
computing accuracy for after removing block 35 . block score: 0.018640689784660935
removed block 35 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.018301. All blocks and scores: [(47, 0.018301398726180196), (44, 0.01887912070378661), (24, 0.01895186584442854), (48, 0.019549657125025988), (46, 0.019557365449145436), (40, 0.019585496746003628), (23, 0.019739443669095635), (22, 0.019956301199272275), (8, 0.01996665564365685), (41, 0.019993558758869767), (38, 0.020276635885238647), (39, 0.020718253450468183), (43, 0.021324649220332503), (50, 0.021922264015302062), (49, 0.02205569949001074), (42, 0.022884832927957177), (21, 0.02331746881827712), (6, 0.024041746510192752), (45, 0.024267784086987376), (10, 0.0261676583904773), (37, 0.026483883848413825), (11, 0.028026720508933067), (4, 0.028626713203266263), (3, 0.03240096662193537), (13, 0.032924074213951826), (20, 0.034043310675770044), (51, 0.03433887893334031), (12, 0.03690121416002512), (52, 0.03733885148540139), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.0463064587675035), (14, 0.04730391362681985), (2, 0.057159021496772766), (0, 0.0588825773447752), (16, 0.059412581380456686), (5, 0.09224656689912081), (17, 0.2388458475470543), (36, 0.31887492537498474), (18, 0.4543862156569958), (53, 0.8835926726460457)]
computing accuracy for after removing block 47 . block score: 0.018301398726180196
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.018879. All blocks and scores: [(44, 0.01887912000529468), (24, 0.018951865378767252), (46, 0.01955736498348415), (40, 0.019585496746003628), (23, 0.019739443669095635), (22, 0.019956301664933562), (8, 0.01996665564365685), (41, 0.01999355899170041), (48, 0.020102362148463726), (38, 0.020276635885238647), (39, 0.020718252984806895), (43, 0.021324649453163147), (42, 0.022884832695126534), (50, 0.022935191867873073), (49, 0.023261676775291562), (21, 0.02331746998243034), (6, 0.024041746044531465), (45, 0.024267783854156733), (10, 0.0261676583904773), (37, 0.02648388291709125), (11, 0.028026720508933067), (4, 0.02862671297043562), (3, 0.03240096475929022), (13, 0.03292407467961311), (20, 0.034043310675770044), (51, 0.03476384375244379), (12, 0.03690121416002512), (52, 0.03751523233950138), (9, 0.03934459434822202), (19, 0.04198857489973307), (15, 0.0463064587675035), (14, 0.047303914558142424), (2, 0.05715902196243405), (0, 0.05888257501646876), (16, 0.059412579983472824), (5, 0.09224656783044338), (17, 0.2388458475470543), (36, 0.31887492537498474), (18, 0.45438621938228607), (53, 0.9607554450631142)]
computing accuracy for after removing block 44 . block score: 0.01887912000529468
removed block 44 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.018952. All blocks and scores: [(24, 0.018951865378767252), (40, 0.019585497211664915), (23, 0.01973944390192628), (22, 0.019956301199272275), (8, 0.019966655876487494), (41, 0.019993558526039124), (38, 0.020276636350899935), (48, 0.02038996503688395), (46, 0.020573836751282215), (39, 0.02071825391612947), (43, 0.021324649220332503), (42, 0.022884832695126534), (50, 0.023124572355300188), (21, 0.02331746998243034), (49, 0.023369598668068647), (6, 0.02404174581170082), (45, 0.024384557968005538), (10, 0.02616765908896923), (37, 0.02648388361558318), (11, 0.028026719577610493), (4, 0.02862671297043562), (3, 0.03240096475929022), (13, 0.03292407467961311), (20, 0.034043310675770044), (51, 0.0347786252386868), (12, 0.03690121462568641), (52, 0.03756985208019614), (9, 0.03934459341689944), (19, 0.04198857629671693), (15, 0.04630645923316479), (14, 0.04730391222983599), (2, 0.057159021496772766), (0, 0.05888257594779134), (16, 0.059412581380456686), (5, 0.09224656689912081), (17, 0.23884584568440914), (36, 0.31887491792440414), (18, 0.45438622310757637), (53, 1.021526761353016)]
computing accuracy for after removing block 24 . block score: 0.018951865378767252
removed block 24 current accuracy 0.9534 loss from initial  0.046599999999999975
since last training loss: 0.034599999999999964 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.019207. All blocks and scores: [(40, 0.019206858705729246), (48, 0.019635460106655955), (23, 0.019739444367587566), (41, 0.01974051771685481), (22, 0.01995630213059485), (38, 0.019963711965829134), (8, 0.01996665564365685), (39, 0.02010841411538422), (46, 0.02023323578760028), (43, 0.02077227900736034), (50, 0.02250637486577034), (42, 0.022604697151109576), (49, 0.022722700145095587), (21, 0.02331746951676905), (45, 0.023850618861615658), (6, 0.024041746510192752), (37, 0.02599820145405829), (10, 0.0261676583904773), (11, 0.028026721440255642), (4, 0.028626713203266263), (3, 0.032400965224951506), (13, 0.032924074213951826), (20, 0.034043310675770044), (51, 0.0341663365252316), (12, 0.03690121416002512), (52, 0.03711422020569444), (9, 0.039344592951238155), (19, 0.04198857583105564), (15, 0.04630645830184221), (14, 0.047303912695497274), (2, 0.05715902242809534), (0, 0.05888257501646876), (16, 0.0594125809147954), (5, 0.09224656503647566), (17, 0.23884584940969944), (36, 0.31504473462700844), (18, 0.45438621938228607), (53, 1.0337043553590775)]
computing accuracy for after removing block 40 . block score: 0.019206858705729246
removed block 40 current accuracy 0.9372 loss from initial  0.06279999999999997
since last training loss: 0.050799999999999956 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.018811. All blocks and scores: [(48, 0.01881053065881133), (46, 0.019371640402823687), (41, 0.019517680862918496), (43, 0.01962347445078194), (23, 0.019739444134756923), (22, 0.019956301897764206), (38, 0.01996371173299849), (8, 0.019966655876487494), (39, 0.020108413184061646), (50, 0.0213216261472553), (49, 0.021479649236425757), (42, 0.021748678758740425), (45, 0.022593648172914982), (21, 0.023317469283938408), (6, 0.024041745346039534), (37, 0.02599820145405829), (10, 0.02616765908896923), (11, 0.028026720974594355), (4, 0.028626713203266263), (51, 0.03205896192230284), (3, 0.03240096475929022), (13, 0.0329240751452744), (20, 0.03404330974444747), (52, 0.03687903797253966), (12, 0.03690121462568641), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.05715902429074049), (0, 0.05888257594779134), (16, 0.05941257951781154), (5, 0.09224656503647566), (17, 0.23884584568440914), (36, 0.31504474952816963), (18, 0.45438621938228607), (53, 1.135561391711235)]
computing accuracy for after removing block 48 . block score: 0.01881053065881133
removed block 48 current accuracy 0.9258 loss from initial  0.07420000000000004
training start
training epoch 0 val accuracy 0.8246 topk_dict {'top1': 0.8246} is_best False lr [0.1]
training epoch 1 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 2 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 5 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 6 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 7 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 8 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.1]
training epoch 9 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 10 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.969600)
finished training. finished 50 epochs. accuracy 0.9696 topk_dict {'top1': 0.9696}
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.038746. All blocks and scores: [(50, 0.038746470119804144), (49, 0.04138904623687267), (4, 0.041776719968765974), (8, 0.042086887173354626), (41, 0.04341154079884291), (46, 0.04401580151170492), (6, 0.04535033693537116), (52, 0.046363544184714556), (51, 0.04840384190902114), (42, 0.04925473919138312), (43, 0.04925591824576259), (45, 0.050221343990415335), (39, 0.050642453134059906), (10, 0.05079079931601882), (22, 0.05104793421924114), (38, 0.05448533454909921), (23, 0.05714623350650072), (13, 0.05719943204894662), (11, 0.05833041947335005), (3, 0.06088816421106458), (37, 0.06380277592688799), (21, 0.06511818058788776), (19, 0.07259252853691578), (12, 0.07297686114907265), (9, 0.07323125191032887), (20, 0.0743839181959629), (15, 0.0916755860671401), (2, 0.09838281758129597), (14, 0.10062054451555014), (0, 0.10817589983344078), (16, 0.12550962809473276), (5, 0.17018304578959942), (17, 0.4505806043744087), (18, 0.6489836573600769), (36, 0.7002832144498825), (53, 0.933958075940609)]
computing accuracy for after removing block 50 . block score: 0.038746470119804144
removed block 50 current accuracy 0.9614 loss from initial  0.03859999999999997
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.041389. All blocks and scores: [(49, 0.04138904670253396), (4, 0.04177672043442726), (8, 0.042086887173354626), (41, 0.04341154173016548), (46, 0.04401580151170492), (6, 0.04535033740103245), (42, 0.049254738725721836), (43, 0.0492559177801013), (52, 0.05009602941572666), (45, 0.05022134492173791), (39, 0.05064245453104377), (10, 0.05079079978168011), (22, 0.051047933753579855), (51, 0.05177128314971924), (38, 0.054485333152115345), (23, 0.05714623350650072), (13, 0.05719943065196276), (11, 0.058330419939011335), (3, 0.06088816374540329), (37, 0.06380277499556541), (21, 0.06511818151921034), (19, 0.07259252946823835), (12, 0.07297686394304037), (9, 0.07323125377297401), (20, 0.07438391912728548), (15, 0.09167558886110783), (2, 0.09838281851261854), (14, 0.10062054265290499), (0, 0.10817590076476336), (16, 0.1255096299573779), (5, 0.17018304392695427), (17, 0.4505806043744087), (18, 0.6489836499094963), (36, 0.7002831920981407), (53, 1.0167485252022743)]
computing accuracy for after removing block 49 . block score: 0.04138904670253396
removed block 49 current accuracy 0.9492 loss from initial  0.050799999999999956
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 4, with score 0.041777. All blocks and scores: [(4, 0.041776719968765974), (8, 0.04208688624203205), (41, 0.04341154219582677), (46, 0.044015801046043634), (6, 0.04535033693537116), (42, 0.04925473965704441), (43, 0.0492559177801013), (45, 0.05022134492173791), (39, 0.05064245546236634), (10, 0.05079079978168011), (22, 0.05104793421924114), (52, 0.05218222737312317), (38, 0.054485333152115345), (23, 0.05714623210951686), (13, 0.057199429254978895), (51, 0.05776058556511998), (11, 0.05833041947335005), (3, 0.060888163279742), (37, 0.06380277685821056), (21, 0.06511818058788776), (19, 0.07259252667427063), (12, 0.0729768630117178), (9, 0.07323125377297401), (20, 0.0743839181959629), (15, 0.0916755860671401), (2, 0.09838282130658627), (14, 0.10062054265290499), (0, 0.10817590169608593), (16, 0.1255096299573779), (5, 0.17018304951488972), (17, 0.4505806043744087), (18, 0.6489836350083351), (36, 0.7002832069993019), (53, 1.1095886379480362)]
computing accuracy for after removing block 4 . block score: 0.041776719968765974
removed block 4 current accuracy 0.9478 loss from initial  0.052200000000000024
since last training loss: 0.02180000000000004 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.042615. All blocks and scores: [(41, 0.042615155689418316), (8, 0.042927300557494164), (46, 0.04328870726749301), (6, 0.045603929087519646), (43, 0.04787799250334501), (42, 0.04895039089024067), (22, 0.04914008779451251), (45, 0.05007721437141299), (39, 0.050530987326055765), (10, 0.051564427092671394), (52, 0.05195065075531602), (38, 0.05233798595145345), (23, 0.05475593497976661), (11, 0.056979460176080465), (51, 0.05733396811410785), (13, 0.05808106577023864), (3, 0.06088816374540329), (37, 0.06217359099537134), (21, 0.06438747327774763), (19, 0.07169391680508852), (20, 0.0722152478992939), (9, 0.07245860248804092), (12, 0.07445109076797962), (15, 0.0903812050819397), (2, 0.09838281944394112), (14, 0.09987187944352627), (0, 0.10817589797079563), (16, 0.1259684283286333), (5, 0.17713570035994053), (17, 0.44447215273976326), (18, 0.6443968117237091), (36, 0.6860101222991943), (53, 1.1174045354127884)]
computing accuracy for after removing block 41 . block score: 0.042615155689418316
removed block 41 current accuracy 0.9386 loss from initial  0.06140000000000001
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 8, with score 0.042927. All blocks and scores: [(8, 0.042927300557494164), (46, 0.04323177272453904), (6, 0.04560392862185836), (43, 0.047091553919017315), (42, 0.04895136086270213), (22, 0.04914008732885122), (45, 0.049314431846141815), (39, 0.0505309896543622), (10, 0.051564425230026245), (52, 0.052024324890226126), (38, 0.05233798734843731), (23, 0.05475593591108918), (51, 0.05579415522515774), (11, 0.05697945924475789), (13, 0.0580810671672225), (3, 0.060888166073709726), (37, 0.06217359099537134), (21, 0.06438747327774763), (19, 0.07169391680508852), (20, 0.07221524976193905), (9, 0.07245860248804092), (12, 0.07445109263062477), (15, 0.0903812050819397), (2, 0.09838281758129597), (14, 0.09987187664955854), (0, 0.10817590076476336), (16, 0.1259684283286333), (5, 0.17713569849729538), (17, 0.44447216391563416), (18, 0.6443968117237091), (36, 0.6860101073980331), (53, 1.2102694511413574)]
computing accuracy for after removing block 8 . block score: 0.042927300557494164
removed block 8 current accuracy 0.9362 loss from initial  0.06379999999999997
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 46, with score 0.042116. All blocks and scores: [(46, 0.0421161656267941), (43, 0.04536727396771312), (6, 0.04560392862185836), (22, 0.046866471879184246), (42, 0.04806138528510928), (45, 0.04852890782058239), (38, 0.04950793972238898), (39, 0.04954505246132612), (52, 0.05157178966328502), (23, 0.05191167537122965), (51, 0.05469957971945405), (10, 0.0553370644338429), (13, 0.056942293886095285), (11, 0.060148900374770164), (37, 0.06026961002498865), (3, 0.060888163279742), (21, 0.06221663439646363), (19, 0.06862111110240221), (20, 0.06990529410541058), (9, 0.07539531867951155), (12, 0.07551083993166685), (15, 0.08946067932993174), (14, 0.09773102216422558), (2, 0.09838282316923141), (0, 0.10817589983344078), (16, 0.12465994898229837), (5, 0.17713569290935993), (17, 0.4233761616051197), (18, 0.6243297532200813), (36, 0.6638838797807693), (53, 1.2142214179039001)]
computing accuracy for after removing block 46 . block score: 0.0421161656267941
removed block 46 current accuracy 0.9114 loss from initial  0.08860000000000001
since last training loss: 0.05820000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 43, with score 0.045367. All blocks and scores: [(43, 0.045367274433374405), (6, 0.04560392955318093), (22, 0.04686647234484553), (42, 0.048061384819447994), (45, 0.04852890549227595), (38, 0.049507939256727695), (39, 0.049545051995664835), (23, 0.0519116772338748), (10, 0.0553370644338429), (52, 0.05538265826180577), (13, 0.05694229295477271), (51, 0.058328854851424694), (11, 0.060148901771754026), (37, 0.06026961002498865), (3, 0.06088816514238715), (21, 0.062216637190431356), (19, 0.06862110830843449), (20, 0.06990529503673315), (9, 0.07539531961083412), (12, 0.07551083993166685), (15, 0.08946067839860916), (14, 0.09773102216422558), (2, 0.09838281758129597), (0, 0.10817590169608593), (16, 0.12465994898229837), (5, 0.17713570035994053), (17, 0.4233761429786682), (18, 0.6243297532200813), (36, 0.6638838574290276), (53, 1.2642478942871094)]
computing accuracy for after removing block 43 . block score: 0.045367274433374405
removed block 43 current accuracy 0.8794 loss from initial  0.12060000000000004
since last training loss: 0.09020000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 6, with score 0.045604. All blocks and scores: [(6, 0.04560392862185836), (22, 0.0468664700165391), (42, 0.04806138342246413), (38, 0.049507939256727695), (39, 0.049545051995664835), (45, 0.05036859214305878), (23, 0.05191167537122965), (10, 0.05533706396818161), (52, 0.05656960653141141), (13, 0.056942293420434), (51, 0.05804360192269087), (11, 0.06014890130609274), (37, 0.06026961049064994), (3, 0.060888166073709726), (21, 0.062216633930802345), (19, 0.06862111110240221), (20, 0.069905293174088), (9, 0.0753953205421567), (12, 0.07551084272563457), (15, 0.08946067839860916), (14, 0.09773102309554815), (2, 0.09838281758129597), (0, 0.10817589983344078), (16, 0.1246599480509758), (5, 0.17713570222258568), (17, 0.4233761429786682), (18, 0.6243297383189201), (36, 0.66388388723135), (53, 1.3049712479114532)]
computing accuracy for after removing block 6 . block score: 0.04560392862185836
removed block 6 current accuracy 0.8704 loss from initial  0.12960000000000005
since last training loss: 0.09920000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 22, with score 0.044338. All blocks and scores: [(22, 0.04433790547773242), (42, 0.046171887312084436), (23, 0.047347985208034515), (38, 0.04740298353135586), (39, 0.04821112006902695), (45, 0.04838122893124819), (52, 0.05584581522271037), (51, 0.05588488932698965), (10, 0.05673914076760411), (37, 0.05843548197299242), (13, 0.05910682398825884), (21, 0.059832744766026735), (3, 0.060888163279742), (11, 0.06292245257645845), (19, 0.06440519168972969), (20, 0.06689849030226469), (12, 0.07566137704998255), (9, 0.07779905665665865), (15, 0.09112324193120003), (2, 0.09838282130658627), (14, 0.09869403764605522), (0, 0.10817589983344078), (16, 0.12604412995278835), (5, 0.17713570035994053), (17, 0.4280153140425682), (18, 0.6073193922638893), (36, 0.6429403573274612), (53, 1.2994748950004578)]
computing accuracy for after removing block 22 . block score: 0.04433790547773242
removed block 22 current accuracy 0.8654 loss from initial  0.13460000000000005
training start
training epoch 0 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 1 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 2 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 3 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 4 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 8 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 9 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 10 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.955000)
finished training. finished 50 epochs. accuracy 0.955 topk_dict {'top1': 0.955}
