start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009340. All blocks and scores: [(35, 0.009340325486846268), (27, 0.011103684082627296), (21, 0.011334074195474386), (31, 0.011607038788497448), (34, 0.011916786315850914), (20, 0.012414053664542735), (10, 0.012957266881130636), (29, 0.013191591831855476), (28, 0.014451422030106187), (25, 0.015047203982248902), (32, 0.015597441117279232), (26, 0.015913886949419975), (9, 0.015947438310831785), (33, 0.01621382706798613), (19, 0.016238084295764565), (30, 0.01653508166782558), (13, 0.01730443094857037), (23, 0.01780766947194934), (24, 0.018264205427840352), (47, 0.01833463879302144), (43, 0.018826094223186374), (22, 0.019027542090043426), (42, 0.019418791867792606), (39, 0.019591449527069926), (11, 0.019892502576112747), (46, 0.019984069978818297), (45, 0.02017575642094016), (40, 0.020337841473519802), (44, 0.02035037032328546), (41, 0.02134683378972113), (17, 0.022294856375083327), (14, 0.023160054348409176), (48, 0.023965090047568083), (38, 0.02425185195170343), (49, 0.025340354535728693), (37, 0.028723529307171702), (50, 0.030707397032529116), (51, 0.03621984971687198), (15, 0.037177727557718754), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.05547522520646453), (2, 0.06098463898524642), (16, 0.061570561956614256), (3, 0.06243071611970663), (6, 0.06518651638180017), (52, 0.07758118957281113), (1, 0.1571871805936098), (36, 0.31111687794327736), (18, 0.3824950344860554), (53, 0.8639277964830399)]
computing accuracy for after removing block 35 . block score: 0.009340325486846268
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.011104. All blocks and scores: [(27, 0.011103683384135365), (21, 0.01133407384622842), (31, 0.011607039137743413), (34, 0.011916786432266235), (20, 0.012414054130204022), (10, 0.012957266881130636), (29, 0.013191591715440154), (28, 0.014451422379352152), (25, 0.015047204331494868), (32, 0.015597440651617944), (26, 0.015913886483758688), (9, 0.01594743807800114), (33, 0.016213827533647418), (19, 0.016238084062933922), (30, 0.01653508166782558), (13, 0.017304430715739727), (23, 0.017807669704779983), (47, 0.01822157925926149), (24, 0.01826420589350164), (43, 0.018713120836764574), (22, 0.019027542555704713), (42, 0.019336250377818942), (39, 0.01957682683132589), (11, 0.019892503041774035), (46, 0.019986523548141122), (45, 0.02004792634397745), (40, 0.02029632613994181), (44, 0.020512877963483334), (41, 0.02144961175508797), (17, 0.022294857539236546), (14, 0.023160054115578532), (48, 0.023811296559870243), (38, 0.024050168693065643), (49, 0.025408402318134904), (37, 0.028856528690084815), (50, 0.030640448909252882), (51, 0.03598107350990176), (15, 0.03717773035168648), (0, 0.045861792750656605), (12, 0.04737982014194131), (8, 0.048870423808693886), (4, 0.052134630270302296), (5, 0.05241671856492758), (7, 0.05547522380948067), (2, 0.06098463898524642), (16, 0.06157056428492069), (3, 0.062430718913674355), (6, 0.0651865154504776), (52, 0.07701416313648224), (1, 0.15718717873096466), (36, 0.3119104988873005), (18, 0.38249505311250687), (53, 0.8734227865934372)]
computing accuracy for after removing block 27 . block score: 0.011103683384135365
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011334. All blocks and scores: [(21, 0.011334073962643743), (31, 0.011815687292255461), (34, 0.011877579614520073), (20, 0.012414054246619344), (10, 0.01295726711396128), (29, 0.013689620071090758), (28, 0.014708209550008178), (25, 0.015047204215079546), (32, 0.015121230506338179), (26, 0.015913886483758688), (9, 0.01594743807800114), (33, 0.016188491601496935), (19, 0.01623808452859521), (30, 0.01633173250593245), (13, 0.017304430482909083), (47, 0.017806177027523518), (23, 0.017807669239118695), (24, 0.018264206126332283), (43, 0.018580012256279588), (22, 0.019027542090043426), (42, 0.01939117582514882), (46, 0.019606942543759942), (39, 0.01960722845979035), (45, 0.01971504185348749), (40, 0.01974743651226163), (11, 0.019892502343282104), (44, 0.020142704248428345), (41, 0.02075307327322662), (17, 0.022294857306405902), (48, 0.022873759968206286), (14, 0.023160054348409176), (38, 0.023989601293578744), (49, 0.024799506878480315), (37, 0.02869816031306982), (50, 0.030612412141636014), (51, 0.035496633499860764), (15, 0.03717772848904133), (0, 0.04586179368197918), (12, 0.04737981967628002), (8, 0.048870425671339035), (4, 0.052134630270302296), (5, 0.05241671670228243), (7, 0.05547522380948067), (2, 0.06098464084789157), (16, 0.06157056288793683), (3, 0.062430718913674355), (6, 0.06518651638180017), (52, 0.07554570864886045), (1, 0.1571871843189001), (36, 0.31206290423870087), (18, 0.38249504193663597), (53, 0.8803881332278252)]
computing accuracy for after removing block 21 . block score: 0.011334073962643743
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011639. All blocks and scores: [(31, 0.011639060219749808), (34, 0.011946186423301697), (20, 0.012414054130204022), (10, 0.012957266764715314), (29, 0.013874796801246703), (28, 0.01455040485598147), (25, 0.014715024619363248), (32, 0.015309393173083663), (26, 0.01542658603284508), (9, 0.015947437845170498), (30, 0.01616884022951126), (19, 0.016238083597272635), (33, 0.016239794669672847), (13, 0.0173044316470623), (23, 0.017435556510463357), (47, 0.017666856525465846), (24, 0.018116667633876204), (43, 0.018401946872472763), (42, 0.018988730618730187), (22, 0.01920809200964868), (45, 0.01936020003631711), (40, 0.019363844534382224), (39, 0.019441344775259495), (46, 0.019487919518724084), (11, 0.019892502343282104), (44, 0.02018019580282271), (41, 0.020585639867931604), (17, 0.022294857073575258), (48, 0.022515942808240652), (14, 0.023160054348409176), (38, 0.024127490585669875), (49, 0.02472286159172654), (37, 0.029028164688497782), (50, 0.030450497521087527), (51, 0.03526381449773908), (15, 0.03717772988602519), (0, 0.04586179228499532), (12, 0.04737982153892517), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.052416717633605), (7, 0.05547522474080324), (2, 0.060984638053923845), (16, 0.06157056428492069), (3, 0.062430717051029205), (6, 0.06518651638180017), (52, 0.07456282805651426), (1, 0.15718718245625496), (36, 0.31330902874469757), (18, 0.38249505311250687), (53, 0.8804345577955246)]
computing accuracy for after removing block 31 . block score: 0.011639060219749808
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012262. All blocks and scores: [(34, 0.012262115138582885), (20, 0.0124140540137887), (10, 0.012957266648299992), (29, 0.013874796568416059), (28, 0.014550405205227435), (25, 0.014715025434270501), (32, 0.015284726861864328), (26, 0.01542658603284508), (9, 0.01594743854366243), (33, 0.016090110410004854), (30, 0.016168839996680617), (19, 0.016238084062933922), (13, 0.017304430715739727), (47, 0.017389521468430758), (23, 0.017435556510463357), (43, 0.017958789598196745), (24, 0.018116667633876204), (42, 0.018551464658230543), (40, 0.019011592958122492), (45, 0.019096721662208438), (22, 0.01920809270814061), (46, 0.01932260673493147), (39, 0.019438674906268716), (11, 0.019892502343282104), (44, 0.020096178399398923), (41, 0.020399771630764008), (48, 0.02222239365801215), (17, 0.022294856840744615), (14, 0.023160055046901107), (38, 0.023856615414842963), (49, 0.024399894289672375), (37, 0.029221920762211084), (50, 0.030021414626389742), (51, 0.035006152000278234), (15, 0.0371777294203639), (0, 0.045861792750656605), (12, 0.047379820607602596), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.055475222412496805), (2, 0.06098463898524642), (16, 0.06157056335359812), (3, 0.062430718913674355), (6, 0.06518651638180017), (52, 0.07356802374124527), (1, 0.1571871843189001), (36, 0.31360404193401337), (18, 0.38249504193663597), (53, 0.8875407055020332)]
computing accuracy for after removing block 34 . block score: 0.012262115138582885
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012414. All blocks and scores: [(20, 0.012414054479449987), (10, 0.01295726653188467), (29, 0.01387479668483138), (28, 0.014550405088812113), (25, 0.014715025085024536), (32, 0.015284726629033685), (26, 0.01542658545076847), (9, 0.01594743807800114), (33, 0.01609011087566614), (30, 0.016168840462341905), (19, 0.016238084295764565), (47, 0.017113495618104935), (13, 0.017304430482909083), (23, 0.017435556510463357), (43, 0.017444000579416752), (42, 0.017953321803361177), (24, 0.018116667633876204), (40, 0.018627354176715016), (45, 0.018796850461512804), (46, 0.019162564305588603), (22, 0.019208092475309968), (39, 0.019221500726416707), (11, 0.019892502576112747), (44, 0.02002423140220344), (41, 0.02006620937027037), (48, 0.02205545105971396), (17, 0.02229485660791397), (14, 0.023160055046901107), (38, 0.02340789302252233), (49, 0.023943485924974084), (37, 0.028878843877464533), (50, 0.02955093001946807), (51, 0.03471436770632863), (15, 0.037177728954702616), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213462980464101), (5, 0.052416715770959854), (7, 0.05547522474080324), (2, 0.060984639916568995), (16, 0.061570563819259405), (3, 0.06243071844801307), (6, 0.06518651824444532), (52, 0.07239074725657701), (1, 0.1571871843189001), (36, 0.313132181763649), (18, 0.3824950382113457), (53, 0.894952081143856)]
computing accuracy for after removing block 20 . block score: 0.012414054479449987
removed block 20 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 1 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 3 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 4 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 5 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 7 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 8 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 9 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012957. All blocks and scores: [(10, 0.012957266764715314), (29, 0.013561785337515175), (28, 0.014028951525688171), (25, 0.014169098110869527), (32, 0.014978608814999461), (26, 0.014983123983256519), (30, 0.015398441115394235), (9, 0.01594743807800114), (33, 0.016120447078719735), (19, 0.01623808452859521), (47, 0.016815442591905594), (43, 0.01684385957196355), (23, 0.017247507348656654), (13, 0.017304430715739727), (42, 0.01734949997626245), (24, 0.017785267904400826), (40, 0.018032792955636978), (45, 0.018344406271353364), (39, 0.018923637690022588), (46, 0.019041894702240825), (22, 0.019215749111026525), (41, 0.019646556582301855), (11, 0.01989250280894339), (44, 0.02013750490732491), (48, 0.02174140722490847), (17, 0.022294857073575258), (14, 0.023160054814070463), (38, 0.023315483704209328), (49, 0.023662553168833256), (37, 0.02904578996822238), (50, 0.029134636977687478), (51, 0.03401449602097273), (15, 0.03717772848904133), (0, 0.045861792750656605), (12, 0.047379819210618734), (8, 0.04887042427435517), (4, 0.052134630270302296), (5, 0.05241671670228243), (7, 0.05547522334381938), (2, 0.06098463665693998), (16, 0.06157056242227554), (3, 0.06243071798235178), (6, 0.06518651638180017), (52, 0.07068234775215387), (1, 0.1571871805936098), (36, 0.31336938217282295), (18, 0.3824950307607651), (53, 0.8989739567041397)]
computing accuracy for after removing block 10 . block score: 0.012957266764715314
removed block 10 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013780. All blocks and scores: [(29, 0.01377984310965985), (28, 0.013976978487335145), (25, 0.014224751619622111), (26, 0.014854759443551302), (32, 0.01509961485862732), (30, 0.015454857260920107), (9, 0.015947437845170498), (33, 0.016266704304143786), (13, 0.016542865429073572), (43, 0.01676264777779579), (47, 0.01678212033584714), (23, 0.017073969123885036), (19, 0.017181469360366464), (42, 0.017427340848371387), (40, 0.017764175310730934), (24, 0.01784460013732314), (45, 0.018063028110191226), (39, 0.01861978298984468), (46, 0.01876853429712355), (22, 0.018944737501442432), (41, 0.019444624660536647), (44, 0.01964278519153595), (11, 0.020282881800085306), (48, 0.021175473695620894), (17, 0.02272361028008163), (14, 0.02277947566471994), (38, 0.023119496181607246), (49, 0.02381147793494165), (37, 0.027783304220065475), (50, 0.02857796847820282), (51, 0.03366645332425833), (15, 0.03736387798562646), (12, 0.043142732698470354), (0, 0.04586179228499532), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.052416717167943716), (7, 0.055475222412496805), (2, 0.06098463851958513), (16, 0.06162197329103947), (3, 0.062430717051029205), (6, 0.06518651731312275), (52, 0.07000694703310728), (1, 0.1571871805936098), (36, 0.30398042872548103), (18, 0.374211173504591), (53, 0.8993167877197266)]
computing accuracy for after removing block 29 . block score: 0.01377984310965985
removed block 29 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.013977. All blocks and scores: [(28, 0.013976978370919824), (25, 0.014224751852452755), (26, 0.014854759559966624), (32, 0.015656630625016987), (9, 0.01594743854366243), (33, 0.01609343127347529), (30, 0.0163310666102916), (13, 0.016542865661904216), (47, 0.016583282267674804), (43, 0.01660904218442738), (42, 0.016731813549995422), (23, 0.017073968658223748), (19, 0.017181469360366464), (40, 0.01759379543364048), (45, 0.017683781450614333), (24, 0.017844599904492497), (39, 0.018342912662774324), (46, 0.018452940741553903), (22, 0.018944737501442432), (41, 0.019309211056679487), (44, 0.01936902431771159), (11, 0.020282881567254663), (48, 0.020786920795217156), (17, 0.0227236095815897), (14, 0.02277947566471994), (38, 0.023035791469737887), (49, 0.02333423076197505), (37, 0.027782238088548183), (50, 0.02787675173021853), (51, 0.03319639712572098), (15, 0.037363878916949034), (12, 0.04314273316413164), (0, 0.045861792750656605), (8, 0.048870423808693886), (4, 0.05213462933897972), (5, 0.05241671670228243), (7, 0.05547522474080324), (2, 0.060984639916568995), (16, 0.061621973756700754), (3, 0.06243071798235178), (6, 0.06518651638180017), (52, 0.06813919637352228), (1, 0.15718718245625496), (36, 0.30388377606868744), (18, 0.3742111809551716), (53, 0.9086464941501617)]
computing accuracy for after removing block 28 . block score: 0.013976978370919824
removed block 28 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.014225. All blocks and scores: [(25, 0.014224751852452755), (26, 0.014854760025627911), (32, 0.015713009634055197), (9, 0.01594743807800114), (33, 0.016001068288460374), (47, 0.01619079802185297), (42, 0.016318539390340447), (43, 0.016331236343830824), (13, 0.01654286589473486), (30, 0.016802769619971514), (23, 0.017073968425393105), (19, 0.017181470058858395), (40, 0.01720759575255215), (45, 0.017318607540801167), (24, 0.017844600370153785), (39, 0.017898976569995284), (46, 0.018052106956019998), (22, 0.018944737501442432), (44, 0.019007600378245115), (41, 0.019063472980633378), (48, 0.02025347459129989), (11, 0.020282882265746593), (38, 0.022655859822407365), (17, 0.022723609348759055), (49, 0.02274868031963706), (14, 0.022779474733397365), (50, 0.027034818893298507), (37, 0.027097024023532867), (51, 0.03234624187462032), (15, 0.03736387798562646), (12, 0.04314273316413164), (0, 0.04586179321631789), (8, 0.048870423808693886), (4, 0.05213463120162487), (5, 0.052416715770959854), (7, 0.05547522287815809), (2, 0.060984639916568995), (16, 0.06162197422236204), (3, 0.06243071984499693), (6, 0.06518651731312275), (52, 0.06599840987473726), (1, 0.1571871805936098), (36, 0.3030109517276287), (18, 0.3742111884057522), (53, 0.920085683465004)]
computing accuracy for after removing block 25 . block score: 0.014224751852452755
removed block 25 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014321. All blocks and scores: [(26, 0.014321205904707313), (32, 0.015725135803222656), (47, 0.015813481877557933), (9, 0.01594743807800114), (33, 0.01617535250261426), (43, 0.01619491376914084), (13, 0.016542864963412285), (42, 0.016636511543765664), (40, 0.016900550108402967), (30, 0.016924014315009117), (45, 0.017010100418701768), (23, 0.01707396819256246), (19, 0.01718147029168904), (24, 0.017844599904492497), (46, 0.01793461199849844), (39, 0.018276611575856805), (41, 0.018938243854790926), (22, 0.018944737501442432), (44, 0.018969442695379257), (48, 0.019875064957886934), (11, 0.02028288203291595), (49, 0.02230100240558386), (17, 0.022723610047250986), (14, 0.02277947566471994), (38, 0.022952501894906163), (50, 0.026609521126374602), (37, 0.027367463801056147), (51, 0.03210686589591205), (15, 0.037363878451287746), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.048870425671339035), (4, 0.05213462980464101), (5, 0.052416717633605), (7, 0.05547522101551294), (2, 0.06098463898524642), (16, 0.06162197422236204), (3, 0.062430718913674355), (52, 0.06422236375510693), (6, 0.06518651731312275), (1, 0.15718717873096466), (36, 0.30919431522488594), (18, 0.3742111809551716), (53, 0.9223421886563301)]
computing accuracy for after removing block 26 . block score: 0.014321205904707313
removed block 26 current accuracy 0.9856 loss from initial  0.014399999999999968
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 47, with score 0.015591. All blocks and scores: [(47, 0.01559137855656445), (9, 0.015947438310831785), (33, 0.0161196815315634), (43, 0.016470806440338492), (13, 0.016542865661904216), (32, 0.0166751176584512), (45, 0.01684827939607203), (40, 0.016965946182608604), (23, 0.017073968891054392), (19, 0.017181470058858395), (42, 0.017377677839249372), (30, 0.017694465117529035), (46, 0.017731530591845512), (24, 0.01784460060298443), (44, 0.018625708995386958), (22, 0.018944737501442432), (39, 0.01899522077292204), (41, 0.019389543449506164), (48, 0.019601588370278478), (11, 0.020282882498577237), (49, 0.02207048237323761), (17, 0.022723609814420342), (14, 0.022779474733397365), (38, 0.023785779951140285), (50, 0.026121149538084865), (37, 0.02803548169322312), (51, 0.031970187555998564), (15, 0.037363878916949034), (12, 0.043142734095454216), (0, 0.04586179321631789), (8, 0.04887042520567775), (4, 0.05213462980464101), (5, 0.05241671623662114), (7, 0.05547522380948067), (2, 0.06098463945090771), (16, 0.06162197608500719), (3, 0.062430717051029205), (52, 0.06296230759471655), (6, 0.06518651731312275), (1, 0.15718718245625496), (36, 0.31919990479946136), (18, 0.3742111884057522), (53, 0.9199746400117874)]
computing accuracy for after removing block 47 . block score: 0.01559137855656445
removed block 47 current accuracy 0.9814 loss from initial  0.01859999999999995
training start
training epoch 0 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best False lr [0.1]
training epoch 1 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 2 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 3 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 4 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 5 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 8 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.1]
training epoch 9 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 10 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.981400)
finished training. finished 50 epochs. accuracy 0.9814 topk_dict {'top1': 0.9814}
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.015947. All blocks and scores: [(9, 0.015947439009323716), (33, 0.016119681298732758), (43, 0.01647080690599978), (13, 0.016542866127565503), (32, 0.0166751176584512), (45, 0.016848279628902674), (40, 0.016965945716947317), (23, 0.017073968658223748), (19, 0.017181469593197107), (42, 0.01737767714075744), (30, 0.017694465117529035), (46, 0.01773152989335358), (24, 0.01784460013732314), (44, 0.018625709461048245), (22, 0.018944737035781145), (39, 0.018995221005752683), (41, 0.01938954391516745), (11, 0.02028288203291595), (48, 0.02207162883132696), (17, 0.022723610047250986), (14, 0.022779475431889296), (49, 0.023477209033444524), (38, 0.023785780649632215), (50, 0.02721921051852405), (37, 0.028035480994731188), (51, 0.03351395716890693), (15, 0.037363878916949034), (12, 0.04314273316413164), (0, 0.04586179228499532), (8, 0.048870425671339035), (4, 0.052134628873318434), (5, 0.05241671670228243), (7, 0.05547522520646453), (2, 0.060984639916568995), (16, 0.061621975153684616), (3, 0.06243071611970663), (52, 0.06439626682549715), (6, 0.06518651824444532), (1, 0.15718718618154526), (36, 0.31919989734888077), (18, 0.3742111846804619), (53, 0.9626970216631889)]
computing accuracy for after removing block 9 . block score: 0.015947439009323716
removed block 9 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.016096. All blocks and scores: [(32, 0.016096387524157763), (45, 0.016266966238617897), (43, 0.016269845655187964), (33, 0.01637544692493975), (23, 0.016607446828857064), (40, 0.016879581147804856), (46, 0.01705330447293818), (30, 0.017178396694362164), (19, 0.017349787754938006), (24, 0.01750320103019476), (44, 0.017811866477131844), (42, 0.01797598320990801), (13, 0.018235396360978484), (41, 0.018629115307703614), (22, 0.019067520974203944), (39, 0.019353311974555254), (48, 0.02096651284955442), (11, 0.021229501580819488), (14, 0.02272612787783146), (49, 0.02310079918242991), (17, 0.023560585686936975), (38, 0.02391230990178883), (50, 0.025870412355288863), (37, 0.026413640705868602), (51, 0.03238258510828018), (15, 0.03793497942388058), (12, 0.041658342350274324), (0, 0.045861792750656605), (8, 0.04887042427435517), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.055475225672125816), (2, 0.06098463851958513), (3, 0.06243071565404534), (52, 0.06280327634885907), (16, 0.06422330252826214), (6, 0.06518651638180017), (1, 0.15718718245625496), (36, 0.3088325224816799), (18, 0.3658623918890953), (53, 0.9575238451361656)]
computing accuracy for after removing block 32 . block score: 0.016096387524157763
removed block 32 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.016016. All blocks and scores: [(43, 0.016015663743019104), (45, 0.016113010817207396), (40, 0.016530798748135567), (23, 0.01660744659602642), (46, 0.017001276137307286), (30, 0.017178395995870233), (19, 0.01734978798776865), (24, 0.01750320103019476), (44, 0.017587421229109168), (33, 0.017657326068729162), (13, 0.01823539612814784), (42, 0.018364301649853587), (41, 0.01858894363977015), (22, 0.019067521207034588), (39, 0.019302495755255222), (48, 0.020728602539747953), (11, 0.021229500882327557), (14, 0.022726127645000815), (49, 0.022927334997802973), (17, 0.023560585686936975), (38, 0.02362319454550743), (50, 0.02546685724519193), (37, 0.025660475017502904), (51, 0.03188293636776507), (15, 0.037934978492558), (12, 0.041658343747258186), (0, 0.04586179414764047), (8, 0.04887042520567775), (4, 0.05213463073596358), (5, 0.05241671949625015), (7, 0.05547522520646453), (2, 0.060984639916568995), (52, 0.06119305454194546), (3, 0.062430718913674355), (16, 0.06422330345958471), (6, 0.06518651731312275), (1, 0.15718717873096466), (36, 0.3131869323551655), (18, 0.3658623956143856), (53, 0.9862026199698448)]
computing accuracy for after removing block 43 . block score: 0.016015663743019104
removed block 43 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.03660000000000008 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.016531. All blocks and scores: [(40, 0.016530798748135567), (23, 0.01660744729451835), (45, 0.016902157803997397), (30, 0.017178395995870233), (19, 0.01734978798776865), (24, 0.01750320103019476), (33, 0.017657326301559806), (13, 0.018235396360978484), (46, 0.018336049746721983), (42, 0.018364302115514874), (44, 0.018507370026782155), (41, 0.01858894433826208), (22, 0.019067521207034588), (39, 0.019302496686577797), (11, 0.021229501347988844), (48, 0.021513469284400344), (14, 0.022726128343492746), (49, 0.023295448860153556), (17, 0.023560586152598262), (38, 0.023623194079846144), (37, 0.02566047478467226), (50, 0.026300600031390786), (51, 0.032382619800046086), (15, 0.03793497942388058), (12, 0.041658343747258186), (0, 0.04586179228499532), (8, 0.0488704233430326), (4, 0.05213463073596358), (5, 0.05241671809926629), (7, 0.055475224275141954), (2, 0.060984639916568995), (52, 0.06122089363634586), (3, 0.062430717051029205), (16, 0.06422330252826214), (6, 0.06518651824444532), (1, 0.1571871805936098), (36, 0.3131869398057461), (18, 0.3658623993396759), (53, 1.0472511053085327)]
computing accuracy for after removing block 40 . block score: 0.016530798748135567
removed block 40 current accuracy 0.9298 loss from initial  0.07020000000000004
since last training loss: 0.05160000000000009 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.016446. All blocks and scores: [(45, 0.016445675864815712), (23, 0.016607447061687708), (30, 0.01717839646153152), (19, 0.017349788220599294), (24, 0.017503201263025403), (33, 0.017657326068729162), (46, 0.018193190218880773), (13, 0.018235396360978484), (44, 0.018392324214801192), (42, 0.01902842801064253), (22, 0.019067521207034588), (39, 0.019302495988085866), (41, 0.019459924893453717), (48, 0.021121519384905696), (11, 0.021229501347988844), (49, 0.022725160466507077), (14, 0.022726128110662103), (17, 0.023560585221275687), (38, 0.02362319501116872), (50, 0.025188913568854332), (37, 0.025660475250333548), (51, 0.031149048591032624), (15, 0.037934979889541864), (12, 0.0416583432815969), (0, 0.04586179368197918), (8, 0.04887042613700032), (4, 0.052134628873318434), (5, 0.052416717167943716), (7, 0.05547522334381938), (52, 0.05782804358750582), (2, 0.06098463945090771), (3, 0.06243071937933564), (16, 0.06422330159693956), (6, 0.0651865154504776), (1, 0.1571871768683195), (36, 0.3131869286298752), (18, 0.3658623956143856), (53, 1.0704472661018372)]
computing accuracy for after removing block 45 . block score: 0.016445675864815712
removed block 45 current accuracy 0.9122 loss from initial  0.08779999999999999
since last training loss: 0.06920000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016607. All blocks and scores: [(23, 0.016607446363195777), (30, 0.017178396694362164), (19, 0.017349788220599294), (24, 0.017503200797364116), (33, 0.01765732537023723), (13, 0.018235396360978484), (44, 0.018392324214801192), (46, 0.018523868406191468), (42, 0.019028428243473172), (22, 0.01906752143986523), (39, 0.019302496453747153), (41, 0.019459924893453717), (11, 0.021229500649496913), (48, 0.021385453874245286), (14, 0.022726128110662103), (49, 0.02349673886783421), (17, 0.023560586851090193), (38, 0.02362319454550743), (37, 0.02566047548316419), (50, 0.025855144951492548), (51, 0.03073749248869717), (15, 0.037934979889541864), (12, 0.04165834467858076), (0, 0.04586179228499532), (8, 0.04887042520567775), (4, 0.05213463073596358), (5, 0.052416717167943716), (7, 0.05547522380948067), (52, 0.05644993996247649), (2, 0.06098463851958513), (3, 0.06243071611970663), (16, 0.06422330252826214), (6, 0.06518651731312275), (1, 0.15718718245625496), (36, 0.3131869360804558), (18, 0.3658623956143856), (53, 1.1521297544240952)]
computing accuracy for after removing block 23 . block score: 0.016607446363195777
removed block 23 current accuracy 0.8804 loss from initial  0.11960000000000004
training start
training epoch 0 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 1 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 2 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.1]
training epoch 3 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 4 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 5 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 6 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 7 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 8 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.1]
training epoch 9 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.1]
training epoch 10 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.966200)
finished training. finished 50 epochs. accuracy 0.9662 topk_dict {'top1': 0.9662}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.036211. All blocks and scores: [(19, 0.03621062682941556), (44, 0.04051907267421484), (42, 0.04184223059564829), (46, 0.04230153700336814), (39, 0.04317676043137908), (13, 0.045974884647876024), (48, 0.046793398447334766), (38, 0.047199235297739506), (41, 0.04736837279051542), (50, 0.04884469835087657), (49, 0.05015961127355695), (51, 0.051329645328223705), (11, 0.05374908447265625), (14, 0.056025208439677954), (37, 0.058344255201518536), (33, 0.05883460212498903), (30, 0.06069657253101468), (17, 0.06156042218208313), (22, 0.062255400232970715), (24, 0.0702460017055273), (52, 0.07939194794744253), (15, 0.09024007990956306), (12, 0.10107329580932856), (8, 0.11699037533253431), (0, 0.11893756873905659), (4, 0.12095255311578512), (5, 0.12831898219883442), (6, 0.13425293751060963), (7, 0.1343758124858141), (2, 0.13601023890078068), (16, 0.1428918819874525), (3, 0.1483506392687559), (1, 0.3155199810862541), (18, 0.5893439278006554), (36, 0.6294994354248047), (53, 1.071535050868988)]
computing accuracy for after removing block 19 . block score: 0.03621062682941556
removed block 19 current accuracy 0.9624 loss from initial  0.03759999999999997
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.039985. All blocks and scores: [(44, 0.03998513240367174), (42, 0.04096601391211152), (46, 0.04133310075849295), (39, 0.041997711174190044), (48, 0.04527798853814602), (13, 0.045974884647876024), (41, 0.04603934148326516), (38, 0.047277120873332024), (50, 0.0475675156340003), (49, 0.049003364983946085), (51, 0.04907471360638738), (11, 0.0537490863353014), (33, 0.05460026673972607), (14, 0.056025202851742506), (30, 0.05798990512266755), (37, 0.058637313544750214), (17, 0.06156042078509927), (22, 0.062119444366544485), (24, 0.07052978128194809), (52, 0.07820687908679247), (15, 0.09024007990956306), (12, 0.1010732939466834), (8, 0.11699037812650204), (0, 0.11893756594508886), (4, 0.1209525465965271), (5, 0.12831898033618927), (6, 0.13425293564796448), (7, 0.1343758087605238), (2, 0.13601024448871613), (16, 0.1428918819874525), (3, 0.1483506392687559), (1, 0.315519992262125), (18, 0.5893438905477524), (36, 0.623753510415554), (53, 1.0745299309492111)]
computing accuracy for after removing block 44 . block score: 0.03998513240367174
removed block 44 current accuracy 0.9576 loss from initial  0.04239999999999999
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.040966. All blocks and scores: [(42, 0.04096601437777281), (39, 0.04199771210551262), (46, 0.04458505613729358), (13, 0.04597488511353731), (41, 0.04603934194892645), (38, 0.047277122270315886), (50, 0.04846613761037588), (48, 0.04867205861955881), (51, 0.04936972726136446), (49, 0.0516408272087574), (11, 0.053749085403978825), (33, 0.054600270465016365), (14, 0.056025204714387655), (30, 0.057989906053990126), (37, 0.05863731261342764), (17, 0.06156042078509927), (22, 0.06211944343522191), (24, 0.07052978128194809), (52, 0.07838737033307552), (15, 0.09024007804691792), (12, 0.10107329487800598), (8, 0.11699037812650204), (0, 0.11893756780773401), (4, 0.1209525503218174), (5, 0.12831898219883442), (6, 0.13425293192267418), (7, 0.13437581434845924), (2, 0.13601024076342583), (16, 0.1428918782621622), (3, 0.14835063740611076), (1, 0.3155199959874153), (18, 0.5893439203500748), (36, 0.6237535253167152), (53, 1.1421411335468292)]
computing accuracy for after removing block 42 . block score: 0.04096601437777281
removed block 42 current accuracy 0.949 loss from initial  0.051000000000000045
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 39, with score 0.041998. All blocks and scores: [(39, 0.04199771163985133), (13, 0.04597488371655345), (41, 0.04603934194892645), (38, 0.04727712133899331), (46, 0.04833979345858097), (50, 0.05116898752748966), (51, 0.051700773648917675), (48, 0.052872922737151384), (11, 0.0537490863353014), (33, 0.054600268602371216), (14, 0.05602520424872637), (49, 0.056231743190437555), (30, 0.05798990558832884), (37, 0.0586373140104115), (17, 0.06156042078509927), (22, 0.06211944203823805), (24, 0.07052977941930294), (52, 0.08013988472521305), (15, 0.09024007990956306), (12, 0.10107329301536083), (8, 0.11699037440121174), (0, 0.11893756594508886), (4, 0.12095255590975285), (5, 0.12831898033618927), (6, 0.13425293564796448), (7, 0.13437581062316895), (2, 0.13601023890078068), (16, 0.1428918857127428), (3, 0.1483506392687559), (1, 0.3155199810862541), (18, 0.5893439203500748), (36, 0.6237535327672958), (53, 1.1781362444162369)]
computing accuracy for after removing block 39 . block score: 0.04199771163985133
removed block 39 current accuracy 0.9394 loss from initial  0.06059999999999999
since last training loss: 0.026799999999999935 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 13, with score 0.045975. All blocks and scores: [(13, 0.04597488511353731), (38, 0.04727712320163846), (46, 0.04817856661975384), (41, 0.0486913463100791), (51, 0.051057441625744104), (50, 0.05112269287928939), (48, 0.05361237749457359), (11, 0.0537490863353014), (33, 0.054600268602371216), (49, 0.055240859277546406), (14, 0.05602520704269409), (30, 0.05798990372568369), (37, 0.05863731261342764), (17, 0.06156042218208313), (22, 0.0621194439008832), (24, 0.07052977941930294), (52, 0.07831103354692459), (15, 0.09024007897824049), (12, 0.10107329301536083), (8, 0.11699037440121174), (0, 0.11893756967037916), (4, 0.12095255125313997), (5, 0.12831898033618927), (6, 0.13425293751060963), (7, 0.1343758124858141), (2, 0.13601024448871613), (16, 0.1428918819874525), (3, 0.1483506392687559), (1, 0.3155199885368347), (18, 0.589343897998333), (36, 0.623753510415554), (53, 1.1829732805490494)]
computing accuracy for after removing block 13 . block score: 0.04597488511353731
removed block 13 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.026999999999999913 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 46, with score 0.047625. All blocks and scores: [(46, 0.047625208273530006), (41, 0.047902642749249935), (38, 0.04886144446209073), (50, 0.049079899210482836), (51, 0.05105347465723753), (48, 0.05322073306888342), (33, 0.05327825574204326), (11, 0.053749085403978825), (30, 0.0550531055778265), (49, 0.05510181887075305), (37, 0.056944359093904495), (14, 0.058213741052895784), (22, 0.06133999861776829), (17, 0.06541034672409296), (24, 0.0694617573171854), (52, 0.07857505697757006), (15, 0.09663797821849585), (12, 0.10107329208403826), (8, 0.11699037905782461), (0, 0.11893756408244371), (4, 0.1209525503218174), (5, 0.12831898033618927), (6, 0.13425293378531933), (7, 0.13437581062316895), (2, 0.13601024076342583), (3, 0.1483506429940462), (16, 0.1636365931481123), (1, 0.3155199810862541), (18, 0.5885822996497154), (36, 0.6213864982128143), (53, 1.1616885960102081)]
computing accuracy for after removing block 46 . block score: 0.047625208273530006
removed block 46 current accuracy 0.926 loss from initial  0.07399999999999995
since last training loss: 0.0401999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.047903. All blocks and scores: [(41, 0.04790264228358865), (38, 0.04886144585907459), (51, 0.05322696454823017), (33, 0.053278256207704544), (50, 0.05351091222837567), (11, 0.053749087266623974), (30, 0.05505310324952006), (37, 0.056944357231259346), (14, 0.0582137405872345), (48, 0.05853596469387412), (49, 0.05953016225248575), (22, 0.061339997220784426), (17, 0.06541034393012524), (24, 0.06946175917983055), (52, 0.08092522248625755), (15, 0.09663797914981842), (12, 0.10107329580932856), (8, 0.11699038092046976), (0, 0.11893756315112114), (4, 0.1209525540471077), (5, 0.12831898406147957), (6, 0.13425293378531933), (7, 0.1343758087605238), (2, 0.13601023890078068), (3, 0.1483506392687559), (16, 0.16363659128546715), (1, 0.3155199773609638), (18, 0.5885822921991348), (36, 0.6213865280151367), (53, 1.1975736618041992)]
computing accuracy for after removing block 41 . block score: 0.04790264228358865
removed block 41 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.0524 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.048861. All blocks and scores: [(38, 0.04886144446209073), (51, 0.05319042829796672), (33, 0.05327825527638197), (11, 0.05374908680096269), (50, 0.05408280622214079), (30, 0.05505310324952006), (37, 0.056944357231259346), (14, 0.058213742449879646), (48, 0.05860772682353854), (22, 0.061339997220784426), (49, 0.06414147466421127), (17, 0.06541034486144781), (24, 0.0694617573171854), (52, 0.07986328657716513), (15, 0.09663798101246357), (12, 0.10107329674065113), (8, 0.11699037905782461), (0, 0.11893756501376629), (4, 0.12095254939049482), (5, 0.12831898033618927), (6, 0.13425293192267418), (7, 0.13437581062316895), (2, 0.13601024076342583), (3, 0.14835064113140106), (16, 0.16363659501075745), (1, 0.3155199885368347), (18, 0.588582307100296), (36, 0.6213865205645561), (53, 1.2069117575883865)]
computing accuracy for after removing block 38 . block score: 0.04886144446209073
removed block 38 current accuracy 0.8908 loss from initial  0.10919999999999996
since last training loss: 0.07539999999999991 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 33, with score 0.053278. All blocks and scores: [(33, 0.05327825527638197), (11, 0.05374908773228526), (51, 0.05440641054883599), (50, 0.05443875724449754), (30, 0.05505310418084264), (37, 0.056944357231259346), (14, 0.05821374012157321), (48, 0.05968264490365982), (22, 0.061339998152107), (17, 0.06541034672409296), (49, 0.06638110615313053), (24, 0.06946175824850798), (52, 0.07864762004464865), (15, 0.09663797821849585), (12, 0.10107329487800598), (8, 0.11699037533253431), (0, 0.11893756501376629), (4, 0.12095255590975285), (5, 0.12831897847354412), (6, 0.13425293751060963), (7, 0.1343758087605238), (2, 0.13601023890078068), (3, 0.1483506429940462), (16, 0.1636365931481123), (1, 0.315519992262125), (18, 0.5885822996497154), (36, 0.6213865056633949), (53, 1.217376857995987)]
computing accuracy for after removing block 33 . block score: 0.05327825527638197
removed block 33 current accuracy 0.8728 loss from initial  0.12719999999999998
training start
training epoch 0 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 1 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 2 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 3 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 4 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.1]
training epoch 5 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 6 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 7 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 8 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
