start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101632449776), (24, 0.006592476740479469), (25, 0.007601775985676795), (21, 0.008612961508333683), (27, 0.008965069777332246), (5, 0.009674609638750553), (23, 0.011229233350604773), (19, 0.011454987688921392), (35, 0.011519728694111109), (32, 0.013281174818985164), (29, 0.0141788151813671), (20, 0.014508438995108008), (31, 0.014615894062444568), (3, 0.014681299915537238), (26, 0.014724894077517092), (30, 0.014915360137820244), (7, 0.015097478171810508), (28, 0.016234831418842077), (37, 0.018546362407505512), (33, 0.021617854246869683), (39, 0.021876287180930376), (6, 0.02225141739472747), (50, 0.02244598208926618), (34, 0.0225658870767802), (49, 0.02260288712568581), (8, 0.023474456276744604), (38, 0.02385126263834536), (41, 0.024523034458979964), (40, 0.02466197172179818), (1, 0.025388096226379275), (46, 0.026244732085615396), (45, 0.026683186180889606), (48, 0.026970998849719763), (44, 0.028061730787158012), (51, 0.028739838395267725), (42, 0.028769565979018807), (43, 0.030795483849942684), (47, 0.03119555884040892), (0, 0.03271650895476341), (13, 0.03601941978558898), (15, 0.043151280377060175), (14, 0.043412636034190655), (16, 0.04433065978810191), (12, 0.04965688427910209), (4, 0.05115430895239115), (11, 0.05217862129211426), (52, 0.05327532906085253), (2, 0.055183833464980125), (10, 0.0601671002805233), (9, 0.08553026709705591), (17, 0.18986638635396957), (18, 0.2766866162419319), (36, 0.2898172102868557), (53, 0.8816948086023331)]
computing accuracy for after removing block 22 . block score: 0.005787101632449776
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.00694694637786597), (25, 0.007925601676106453), (21, 0.00861296127550304), (27, 0.008884542039595544), (5, 0.009674609871581197), (19, 0.01145498757250607), (23, 0.011499474290758371), (35, 0.011587338638491929), (32, 0.013315335847437382), (29, 0.014122492866590619), (20, 0.014508438762277365), (31, 0.014535366673953831), (3, 0.014681300148367882), (30, 0.014953502104617655), (7, 0.015097478055395186), (26, 0.015386729268357158), (28, 0.01665737177245319), (37, 0.018698561936616898), (33, 0.021836149506270885), (6, 0.022251416463404894), (39, 0.022278543328866363), (50, 0.022396720945835114), (34, 0.022579424548894167), (49, 0.022588349413126707), (8, 0.02347445674240589), (38, 0.02401084848679602), (41, 0.02471063518896699), (40, 0.024832447292283177), (1, 0.02538809459656477), (46, 0.026328841922804713), (45, 0.02651964989490807), (48, 0.026865347987040877), (51, 0.028594729956239462), (44, 0.02869078330695629), (42, 0.028934542555361986), (47, 0.030598991317674518), (43, 0.030889176996424794), (0, 0.03271650895476341), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.04341263743117452), (16, 0.044330659322440624), (12, 0.04965688521042466), (4, 0.05115430802106857), (11, 0.05217862129211426), (52, 0.05274482071399689), (2, 0.055183835327625275), (10, 0.06016709888353944), (9, 0.08553026616573334), (17, 0.18986638449132442), (18, 0.2766866236925125), (36, 0.29418329522013664), (53, 0.8765672743320465)]
computing accuracy for after removing block 24 . block score: 0.00694694637786597
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.00796479161363095), (27, 0.008502036915160716), (21, 0.008612961391918361), (5, 0.009674609522335231), (35, 0.011124448385089636), (19, 0.011454987921752036), (23, 0.01149947417434305), (32, 0.012667875620536506), (29, 0.013618955155834556), (31, 0.01425534300506115), (30, 0.014440408791415393), (20, 0.014508438296616077), (3, 0.014681300497613847), (7, 0.015097478404641151), (26, 0.015341691439971328), (28, 0.016541525023058057), (37, 0.018848977982997894), (34, 0.02149180113337934), (33, 0.021746610291302204), (50, 0.022144785150885582), (6, 0.022251417161896825), (49, 0.022573675960302353), (39, 0.02259462559595704), (8, 0.023474456276744604), (38, 0.023919350700452924), (41, 0.02473141113296151), (40, 0.02521214378066361), (1, 0.025388095062226057), (45, 0.026285273022949696), (46, 0.026299894088879228), (48, 0.026813949458301067), (51, 0.028448979370296), (44, 0.028867241693660617), (42, 0.028876985423266888), (47, 0.030472574988380075), (43, 0.030837932834401727), (0, 0.032716508489102125), (13, 0.03601941931992769), (15, 0.04315127898007631), (14, 0.04341263463720679), (16, 0.04433065978810191), (12, 0.049656886141747236), (4, 0.05115430848672986), (11, 0.05217862408608198), (52, 0.05221219174563885), (2, 0.05518383625894785), (10, 0.060167097952216864), (9, 0.08553026523441076), (17, 0.18986638076603413), (18, 0.2766866162419319), (36, 0.2956240698695183), (53, 0.8761104345321655)]
computing accuracy for after removing block 25 . block score: 0.00796479161363095
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.00820748379919678), (21, 0.008612961391918361), (5, 0.009674609522335231), (35, 0.010663896100595593), (19, 0.011454987805336714), (23, 0.011499473941512406), (32, 0.012014232925139368), (29, 0.01278762926813215), (31, 0.01386567612644285), (30, 0.01396130642388016), (20, 0.014508438180200756), (3, 0.01468130003195256), (26, 0.014919800800271332), (7, 0.015097477822564542), (28, 0.015723921242170036), (37, 0.018793188501149416), (34, 0.020361810689792037), (33, 0.021328614791855216), (50, 0.02163330279290676), (49, 0.022232345305383205), (6, 0.022251417161896825), (39, 0.02252841810695827), (8, 0.02347445604391396), (38, 0.023843124974519014), (41, 0.024403040995821357), (40, 0.025254084262996912), (1, 0.025388095527887344), (45, 0.025693234521895647), (46, 0.025908003794029355), (48, 0.026390638668090105), (51, 0.02774876169860363), (42, 0.028475591214373708), (44, 0.028856614837422967), (47, 0.02979940129444003), (43, 0.030201829271391034), (0, 0.032716508489102125), (13, 0.03601941978558898), (15, 0.0431512794457376), (14, 0.04341263556852937), (16, 0.04433065885677934), (12, 0.04965688567608595), (52, 0.05079668154940009), (4, 0.05115430802106857), (11, 0.05217862082645297), (2, 0.055183833464980125), (10, 0.06016709841787815), (9, 0.08553026430308819), (17, 0.18986638449132442), (18, 0.2766866236925125), (36, 0.29478897526860237), (53, 0.8695808425545692)]
computing accuracy for after removing block 27 . block score: 0.00820748379919678
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.008612961391918361), (5, 0.009674609289504588), (35, 0.010487184976227582), (19, 0.011454987688921392), (23, 0.011499473941512406), (32, 0.011747056851163507), (29, 0.01290004572365433), (31, 0.013738625217229128), (30, 0.0138319858815521), (20, 0.014508438296616077), (3, 0.014681299682706594), (26, 0.01491980068385601), (7, 0.015097478171810508), (28, 0.016265673795714974), (37, 0.018666349351406097), (34, 0.020145454443991184), (50, 0.021326792426407337), (33, 0.021582857705652714), (49, 0.022118565160781145), (6, 0.022251415997743607), (39, 0.022289567394182086), (8, 0.023474456276744604), (38, 0.023616681341081858), (41, 0.02451603813096881), (40, 0.02536682435311377), (45, 0.025367739843204618), (1, 0.02538809599354863), (46, 0.025604828260838985), (48, 0.026125093456357718), (51, 0.02720356686040759), (42, 0.02829334605485201), (44, 0.029326205607503653), (47, 0.02935170428827405), (43, 0.030030405148863792), (0, 0.03271650895476341), (13, 0.036019420716911554), (15, 0.04315127898007631), (14, 0.043412636034190655), (16, 0.04433065978810191), (12, 0.0496568838134408), (52, 0.050038253888487816), (4, 0.05115430895239115), (11, 0.05217862268909812), (2, 0.05518383486196399), (10, 0.060167096089571714), (9, 0.08553026802837849), (17, 0.18986639007925987), (18, 0.2766866236925125), (36, 0.29525746777653694), (53, 0.8683890700340271)]
computing accuracy for after removing block 21 . block score: 0.008612961391918361
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.009674609638750553), (35, 0.01054247235879302), (19, 0.01145498815458268), (23, 0.011545549496077001), (32, 0.011696715140715241), (29, 0.013034458039328456), (30, 0.013541992637328804), (31, 0.013661347213201225), (20, 0.014508438878692687), (26, 0.014561281888745725), (3, 0.014681300148367882), (7, 0.01509747770614922), (28, 0.0162722235545516), (37, 0.018855378264561296), (34, 0.020170693285763264), (50, 0.021195362089201808), (33, 0.021736357593908906), (49, 0.022025790996849537), (6, 0.022251416696235538), (39, 0.022593394853174686), (8, 0.023474456975236535), (38, 0.0237947222776711), (41, 0.02448631403967738), (45, 0.025174085283651948), (1, 0.025388096226379275), (46, 0.025596367893740535), (40, 0.025702924467623234), (48, 0.02593583008274436), (51, 0.02690311148762703), (42, 0.02837103814817965), (47, 0.029131257440894842), (44, 0.02926316251978278), (43, 0.030276520177721977), (0, 0.03271650895476341), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.04341263649985194), (16, 0.04433065978810191), (52, 0.04949298035353422), (12, 0.04965688567608595), (4, 0.05115430895239115), (11, 0.05217862222343683), (2, 0.0551838343963027), (10, 0.060167097486555576), (9, 0.08553026430308819), (17, 0.18986638262867928), (18, 0.2766866236925125), (36, 0.2977275960147381), (53, 0.8672097772359848)]
computing accuracy for after removing block 5 . block score: 0.009674609638750553
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 1 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 2 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 3 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 4 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 5 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.1]
training epoch 6 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 7 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 8 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 9 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 10 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010497. All blocks and scores: [(35, 0.010497342445887625), (19, 0.011364333564415574), (23, 0.011454000952653587), (32, 0.011731750681065023), (29, 0.012978376122191548), (30, 0.013561801402829587), (31, 0.013812810997478664), (20, 0.014028266654349864), (26, 0.014234645059332252), (3, 0.014681300381198525), (28, 0.01640962902456522), (37, 0.01911555021069944), (7, 0.019321492174640298), (34, 0.02049453160725534), (50, 0.021026555448770523), (33, 0.02140929759480059), (49, 0.022096334723755717), (39, 0.022289574146270752), (38, 0.023183460347354412), (41, 0.024258682504296303), (6, 0.025002859067171812), (8, 0.025038712192326784), (45, 0.025084450375288725), (46, 0.02536836452782154), (1, 0.025388095062226057), (48, 0.02579234540462494), (40, 0.026035186601802707), (51, 0.026855435222387314), (42, 0.028462824877351522), (44, 0.028849951457232237), (47, 0.02911300305277109), (43, 0.03023843956179917), (0, 0.03271650895476341), (13, 0.03606124874204397), (15, 0.04305668035522103), (16, 0.04365198966115713), (14, 0.04365939600393176), (52, 0.049376740120351315), (4, 0.05115430848672986), (12, 0.05150972306728363), (11, 0.054063089191913605), (2, 0.0551838343963027), (10, 0.06240202859044075), (9, 0.08971724566072226), (17, 0.18636955507099628), (18, 0.27677176520228386), (36, 0.29570789262652397), (53, 0.8705098628997803)]
computing accuracy for after removing block 35 . block score: 0.010497342445887625
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0012000000000000899 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011364. All blocks and scores: [(19, 0.011364333680830896), (23, 0.0114540004869923), (32, 0.011731750215403736), (29, 0.01297837623860687), (30, 0.013561801169998944), (31, 0.01381281134672463), (20, 0.01402826642151922), (26, 0.014234644593670964), (3, 0.014681300148367882), (28, 0.016409628791734576), (37, 0.018872639862820506), (7, 0.019321493105962873), (34, 0.02049453160725534), (50, 0.021021218737587333), (33, 0.021409297361969948), (49, 0.021970302797853947), (39, 0.022241035709157586), (38, 0.022285724757239223), (41, 0.024062653305009007), (45, 0.024892093148082495), (46, 0.024894545087590814), (6, 0.02500285883434117), (8, 0.02503871195949614), (1, 0.025388096226379275), (48, 0.025495541747659445), (40, 0.025603901594877243), (51, 0.02683849656023085), (42, 0.02830564440228045), (44, 0.028504314366728067), (47, 0.028528794180601835), (43, 0.02959450287744403), (0, 0.032716508489102125), (13, 0.0360612478107214), (15, 0.04305667942389846), (16, 0.04365198826417327), (14, 0.0436593983322382), (52, 0.048602734226733446), (4, 0.05115430895239115), (12, 0.051509720738977194), (11, 0.05406309198588133), (2, 0.05518383253365755), (10, 0.062402029521763325), (9, 0.08971724286675453), (17, 0.18636955134570599), (18, 0.27677176892757416), (36, 0.29528704285621643), (53, 0.8746362999081612)]
computing accuracy for after removing block 19 . block score: 0.011364333680830896
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.011435. All blocks and scores: [(32, 0.01143521792255342), (23, 0.011625512037426233), (29, 0.01301793148741126), (31, 0.013358428375795484), (30, 0.013481264933943748), (26, 0.013551716809161007), (20, 0.01447505911346525), (3, 0.014681300614029169), (28, 0.01649198541417718), (37, 0.01898286771029234), (7, 0.019321492640301585), (34, 0.02042598370462656), (50, 0.020725763635709882), (33, 0.02151042129844427), (49, 0.021559856366366148), (39, 0.021842949790880084), (38, 0.021860384847968817), (41, 0.02357930690050125), (46, 0.024237519362941384), (45, 0.02440538303926587), (48, 0.024966377997770905), (6, 0.025002859067171812), (8, 0.025038712192326784), (1, 0.025388095062226057), (40, 0.0255836327560246), (51, 0.02626500208862126), (44, 0.02777586760930717), (42, 0.027991157956421375), (47, 0.028424983145669103), (43, 0.029187679290771484), (0, 0.032716508489102125), (13, 0.036061248276382685), (15, 0.04305668082088232), (16, 0.043651987332850695), (14, 0.043659396935254335), (52, 0.04771037260070443), (4, 0.05115430895239115), (12, 0.051509722135961056), (11, 0.05406309152022004), (2, 0.055183832067996264), (10, 0.0624020304530859), (9, 0.0897172437980771), (17, 0.18636954575777054), (18, 0.27677176147699356), (36, 0.28799719363451004), (53, 0.8807788416743279)]
computing accuracy for after removing block 32 . block score: 0.01143521792255342
removed block 32 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.011626. All blocks and scores: [(23, 0.011625511921010911), (29, 0.013017931138165295), (31, 0.013358428492210805), (30, 0.013481264701113105), (26, 0.013551716692745686), (20, 0.014475058997049928), (3, 0.014681299682706594), (28, 0.01649198541417718), (37, 0.01881252881139517), (7, 0.01932149287313223), (34, 0.02046133275143802), (50, 0.02082308242097497), (49, 0.02181476610712707), (38, 0.022025864804163575), (39, 0.02239114511758089), (33, 0.022413174621760845), (41, 0.02400040184147656), (46, 0.024349761428311467), (45, 0.02442808379419148), (6, 0.025002859300002456), (8, 0.02503871265798807), (1, 0.025388095062226057), (48, 0.025586010655388236), (51, 0.026234305230900645), (40, 0.026594599010422826), (42, 0.0284015245269984), (47, 0.02876698481850326), (44, 0.0288279817905277), (43, 0.02949392842128873), (0, 0.03271650755777955), (13, 0.036061248276382685), (15, 0.04305668035522103), (16, 0.043651989195495844), (14, 0.04365939646959305), (52, 0.04727818723767996), (4, 0.05115430802106857), (12, 0.051509720738977194), (11, 0.054063091054558754), (2, 0.055183833464980125), (10, 0.062402029521763325), (9, 0.0897172437980771), (17, 0.18636955507099628), (18, 0.27677176520228386), (36, 0.30095571279525757), (53, 0.8827565535902977)]
computing accuracy for after removing block 23 . block score: 0.011625511921010911
removed block 23 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.012718. All blocks and scores: [(26, 0.012718255631625652), (31, 0.01305987813975662), (30, 0.01324597978964448), (29, 0.013515455997548997), (20, 0.014475058997049928), (3, 0.014681299566291273), (28, 0.016541111981496215), (37, 0.01896847365424037), (7, 0.019321492640301585), (50, 0.020513229304924607), (34, 0.02061733021400869), (49, 0.021386134903877974), (38, 0.02212540851905942), (39, 0.022963949013501406), (33, 0.023589920718222857), (41, 0.023973098723217845), (46, 0.024251093389466405), (45, 0.024274635827168822), (6, 0.025002859067171812), (8, 0.02503871126100421), (48, 0.025167004903778434), (1, 0.025388095527887344), (51, 0.025717933429405093), (40, 0.026828007772564888), (47, 0.028098625363782048), (44, 0.028160852612927556), (42, 0.028478232445195317), (43, 0.029657084261998534), (0, 0.03271650895476341), (13, 0.03606124874204397), (15, 0.04305668082088232), (16, 0.043651989195495844), (14, 0.043659398797899485), (52, 0.04578007198870182), (4, 0.05115430848672986), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.055183832067996264), (10, 0.062402026262134314), (9, 0.08971724286675453), (17, 0.18636955507099628), (18, 0.27677175402641296), (36, 0.3048461154103279), (53, 0.8830678537487984)]
computing accuracy for after removing block 26 . block score: 0.012718255631625652
removed block 26 current accuracy 0.9864 loss from initial  0.013599999999999945
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.012818. All blocks and scores: [(31, 0.012817569426260889), (30, 0.013015841715969145), (29, 0.013636851450428367), (20, 0.014475058764219284), (3, 0.014681300264783204), (37, 0.018351267324760556), (28, 0.018360019894316792), (34, 0.019276466220617294), (7, 0.01932149240747094), (50, 0.02007306506857276), (49, 0.02093875897116959), (38, 0.021544620161876082), (39, 0.022596267284825444), (46, 0.023219265276566148), (45, 0.023255801992490888), (41, 0.023414233000949025), (33, 0.02383880433626473), (48, 0.024398322449997067), (51, 0.024742739042267203), (6, 0.025002859067171812), (8, 0.025038711726665497), (1, 0.025388096226379275), (40, 0.02665983489714563), (47, 0.027334758546203375), (42, 0.027953899698331952), (44, 0.028050451073795557), (43, 0.028797091683372855), (0, 0.0327165094204247), (13, 0.036061248276382685), (15, 0.043056681752204895), (52, 0.043582526966929436), (16, 0.04365198872983456), (14, 0.04365939740091562), (4, 0.05115430802106857), (12, 0.05150972306728363), (11, 0.05406309058889747), (2, 0.055183833464980125), (10, 0.06240202719345689), (9, 0.08971724566072226), (17, 0.1863695476204157), (18, 0.27677176147699356), (36, 0.299288522452116), (53, 0.8849738091230392)]
computing accuracy for after removing block 31 . block score: 0.012817569426260889
removed block 31 current accuracy 0.9812 loss from initial  0.01880000000000004
training start
training epoch 0 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best False lr [0.1]
training epoch 1 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 2 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 3 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 4 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 5 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 6 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 7 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 8 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 9 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.1]
training epoch 10 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.981200)
finished training. finished 50 epochs. accuracy 0.9812 topk_dict {'top1': 0.9812}
start iteration 12
[activation diff]: block to remove picked: 30, with score 0.013016. All blocks and scores: [(30, 0.01301584206521511), (29, 0.01363685168325901), (20, 0.014475058880634606), (3, 0.014681299799121916), (37, 0.018212777795270085), (28, 0.018360019894316792), (7, 0.01932149240747094), (34, 0.019669849425554276), (50, 0.02015663986094296), (49, 0.021141210105270147), (38, 0.02177692949771881), (39, 0.023024213733151555), (45, 0.023322134744375944), (46, 0.02372095687314868), (41, 0.023724548518657684), (51, 0.02464952226728201), (48, 0.024757301667705178), (6, 0.02500285883434117), (8, 0.025038711493834853), (1, 0.0253880952950567), (33, 0.02650434523820877), (47, 0.027367587201297283), (40, 0.027465489925816655), (42, 0.02804913488216698), (44, 0.02878746041096747), (43, 0.028967605903744698), (0, 0.032716508489102125), (13, 0.036061248276382685), (15, 0.04305668035522103), (52, 0.04324783897027373), (16, 0.04365199012681842), (14, 0.04365939786657691), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.05406309152022004), (2, 0.0551838343963027), (10, 0.06240202905610204), (9, 0.08971724193543196), (17, 0.18636954948306084), (18, 0.27677176147699356), (36, 0.31426598504185677), (53, 0.8895440027117729)]
computing accuracy for after removing block 30 . block score: 0.01301584206521511
removed block 30 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.013637. All blocks and scores: [(29, 0.013636851450428367), (20, 0.014475059462711215), (3, 0.01468130003195256), (37, 0.017944879364222288), (28, 0.018360019428655505), (7, 0.01932149240747094), (34, 0.019725410034880042), (50, 0.019991705659776926), (49, 0.021314991638064384), (38, 0.022087189834564924), (45, 0.02313902135938406), (39, 0.023474511224776506), (41, 0.02387145278044045), (46, 0.024038308765739202), (51, 0.02453828859142959), (6, 0.025002859765663743), (8, 0.025038712192326784), (48, 0.0251194448210299), (1, 0.0253880952950567), (47, 0.027327916584908962), (42, 0.028182359877973795), (33, 0.028287381632253528), (40, 0.028367724269628525), (43, 0.02904468378983438), (44, 0.029352555284276605), (0, 0.0327165094204247), (13, 0.03606124920770526), (52, 0.042394925840198994), (15, 0.04305667942389846), (16, 0.043651989195495844), (14, 0.043659396935254335), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.05518383393064141), (10, 0.062402027659118176), (9, 0.08971724472939968), (17, 0.18636954203248024), (18, 0.27677176892757416), (36, 0.3271830305457115), (53, 0.8959613963961601)]
computing accuracy for after removing block 29 . block score: 0.013636851450428367
removed block 29 current accuracy 0.958 loss from initial  0.04200000000000004
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.014475. All blocks and scores: [(20, 0.014475058764219284), (3, 0.014681299682706594), (37, 0.01768801361322403), (28, 0.01836001966148615), (7, 0.019321492640301585), (50, 0.019902902888134122), (34, 0.020446072798222303), (49, 0.021449923049658537), (38, 0.022830398520454764), (45, 0.023148912470787764), (41, 0.0237820977345109), (51, 0.023966893553733826), (46, 0.024161773500964046), (39, 0.024319971445947886), (6, 0.02500285836867988), (8, 0.025038712192326784), (48, 0.025131586007773876), (1, 0.025388096226379275), (47, 0.026900453958660364), (42, 0.028658576542511582), (40, 0.02886050776578486), (43, 0.029123116051778197), (44, 0.03017951804213226), (33, 0.030993567779660225), (0, 0.03271650895476341), (13, 0.0360612478107214), (52, 0.04165757540613413), (15, 0.043056679889559746), (16, 0.043651989195495844), (14, 0.043659398797899485), (4, 0.05115430848672986), (12, 0.05150972260162234), (11, 0.05406309012323618), (2, 0.0551838343963027), (10, 0.062402027659118176), (9, 0.0897172437980771), (17, 0.18636954948306084), (18, 0.27677176892757416), (36, 0.3362649716436863), (53, 0.8946184292435646)]
computing accuracy for after removing block 20 . block score: 0.014475058764219284
removed block 20 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 3, with score 0.014681. All blocks and scores: [(3, 0.01468130003195256), (37, 0.017535289516672492), (28, 0.01847903523594141), (7, 0.019321492640301585), (50, 0.019452705746516585), (49, 0.020851466106250882), (34, 0.02089377259835601), (38, 0.02193527645431459), (45, 0.022253918927162886), (46, 0.02280866331420839), (51, 0.023012835066765547), (41, 0.023610252887010574), (39, 0.024020644137635827), (48, 0.024894541827961802), (6, 0.025002859300002456), (8, 0.025038712192326784), (1, 0.025388094363734126), (47, 0.026204762049019337), (42, 0.028308544075116515), (43, 0.028871112735942006), (40, 0.029305312782526016), (44, 0.029724607011303306), (0, 0.03271650895476341), (33, 0.03295760741457343), (13, 0.03606124874204397), (52, 0.03952924394980073), (15, 0.04305668035522103), (16, 0.04365198872983456), (14, 0.0436593983322382), (4, 0.05115430802106857), (12, 0.05150972260162234), (11, 0.054063091054558754), (2, 0.05518383486196399), (10, 0.062402027659118176), (9, 0.08971724193543196), (17, 0.18636954948306084), (18, 0.27677175775170326), (36, 0.3319150507450104), (53, 0.891904816031456)]
computing accuracy for after removing block 3 . block score: 0.01468130003195256
removed block 3 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.041999999999999926 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 28, with score 0.018655. All blocks and scores: [(28, 0.018655424937605858), (37, 0.018990264739841223), (50, 0.01935263490304351), (38, 0.020607826067134738), (34, 0.021370295202359557), (49, 0.02147139864973724), (45, 0.022496371995657682), (7, 0.022563792997971177), (46, 0.023017879808321595), (51, 0.023357108933851123), (39, 0.02375177387148142), (6, 0.024294147733598948), (41, 0.024343543220311403), (48, 0.024988261749967933), (1, 0.025388095760717988), (8, 0.02586706611327827), (47, 0.02625099616125226), (44, 0.028660247568041086), (42, 0.028714660787954926), (43, 0.02956711081787944), (40, 0.03209337452426553), (33, 0.03214729996398091), (0, 0.0327165094204247), (13, 0.033637304324656725), (14, 0.039394027553498745), (52, 0.0399103001691401), (16, 0.04249449400231242), (15, 0.04269892768934369), (12, 0.053635504096746445), (11, 0.054042018949985504), (4, 0.05474466411396861), (2, 0.055183835327625275), (10, 0.06464330479502678), (9, 0.0936116399243474), (17, 0.18750124797224998), (18, 0.27515242993831635), (36, 0.34003007784485817), (53, 0.894256629049778)]
computing accuracy for after removing block 28 . block score: 0.018655424937605858
removed block 28 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.06740000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.018354. All blocks and scores: [(37, 0.018354135332629085), (50, 0.01861108816228807), (38, 0.020466344663873315), (49, 0.02077979384921491), (45, 0.021783864591270685), (34, 0.022262956481426954), (51, 0.022289656335487962), (7, 0.02256379253230989), (39, 0.022737625753507018), (46, 0.022809282643720508), (6, 0.02429414726793766), (48, 0.024323247140273452), (41, 0.024347294587641954), (1, 0.02538809459656477), (47, 0.025682266568765044), (8, 0.02586706494912505), (42, 0.028105771401897073), (44, 0.02821160200983286), (43, 0.029053980484604836), (40, 0.03171226941049099), (0, 0.03271650895476341), (13, 0.03363730479031801), (33, 0.03551091533154249), (52, 0.038430553395301104), (14, 0.039394027553498745), (16, 0.04249449260532856), (15, 0.042698927223682404), (12, 0.05363550269976258), (11, 0.05404201662167907), (4, 0.05474466271698475), (2, 0.055183833464980125), (10, 0.06464330293238163), (9, 0.09361164551228285), (17, 0.18750124610960484), (18, 0.27515243366360664), (36, 0.3470934070646763), (53, 0.9132807850837708)]
computing accuracy for after removing block 37 . block score: 0.018354135332629085
removed block 37 current accuracy 0.8968 loss from initial  0.10319999999999996
training start
training epoch 0 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.1]
training epoch 1 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 2 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 5 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 6 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 7 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 8 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 9 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 10 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.961200)
finished training. finished 50 epochs. accuracy 0.9612 topk_dict {'top1': 0.9612}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.034416. All blocks and scores: [(49, 0.03441587230190635), (51, 0.038595590740442276), (50, 0.03871041815727949), (7, 0.04215975617989898), (41, 0.04659780114889145), (48, 0.048613131046295166), (39, 0.04934253264218569), (52, 0.05176106747239828), (46, 0.05197228118777275), (44, 0.05230369092896581), (45, 0.05264504300430417), (38, 0.05473892018198967), (42, 0.055131945759058), (8, 0.05530072748661041), (40, 0.05606239289045334), (47, 0.05617321701720357), (1, 0.05728859454393387), (43, 0.05882951430976391), (34, 0.064232655800879), (6, 0.06952641252428293), (0, 0.08064921014010906), (13, 0.08796880766749382), (14, 0.09621866699308157), (15, 0.10235762689262629), (16, 0.10576137062162161), (11, 0.10919841099530458), (33, 0.12218913808465004), (12, 0.13365576975047588), (4, 0.1388077214360237), (2, 0.14147120155394077), (10, 0.1602811235934496), (9, 0.1779303401708603), (17, 0.43400200456380844), (18, 0.44228290021419525), (36, 0.6826410740613937), (53, 1.0976107716560364)]
computing accuracy for after removing block 49 . block score: 0.03441587230190635
removed block 49 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 7, with score 0.042160. All blocks and scores: [(7, 0.042159756645560265), (51, 0.042908115312457085), (50, 0.04341377643868327), (41, 0.04659780114889145), (48, 0.048613131046295166), (39, 0.04934253264218569), (46, 0.05197228118777275), (44, 0.05230369046330452), (45, 0.05264504253864288), (38, 0.05473892018198967), (42, 0.055131944827735424), (8, 0.0553007279522717), (52, 0.055694607086479664), (40, 0.05606239382177591), (47, 0.056173216085880995), (1, 0.05728859547525644), (43, 0.05882951384410262), (34, 0.064232655800879), (6, 0.06952641159296036), (0, 0.08064921107143164), (13, 0.08796880673617125), (14, 0.09621866699308157), (15, 0.10235761944204569), (16, 0.10576137062162161), (11, 0.10919840820133686), (33, 0.12218913529068232), (12, 0.13365577161312103), (4, 0.13880772329866886), (2, 0.14147120341658592), (10, 0.16028112918138504), (9, 0.1779303401708603), (17, 0.43400201573967934), (18, 0.44228290766477585), (36, 0.6826410442590714), (53, 1.305934563279152)]
computing accuracy for after removing block 7 . block score: 0.042159756645560265
removed block 7 current accuracy 0.9494 loss from initial  0.05059999999999998
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.041795. All blocks and scores: [(50, 0.04179526213556528), (51, 0.042691838927567005), (41, 0.044701213482767344), (39, 0.04657651763409376), (48, 0.047384554985910654), (44, 0.04756591375917196), (38, 0.04809398390352726), (46, 0.049609698355197906), (45, 0.05133705912157893), (42, 0.05388758145272732), (40, 0.05490993894636631), (47, 0.055115179158747196), (52, 0.05606568558141589), (43, 0.05714608635753393), (1, 0.057288595009595156), (8, 0.058281831443309784), (34, 0.0599057050421834), (6, 0.06952641252428293), (0, 0.08064921107143164), (14, 0.083858503960073), (13, 0.08429241646081209), (15, 0.09585002530366182), (16, 0.10382314305752516), (11, 0.10392044391483068), (33, 0.11402400303632021), (12, 0.12392565328627825), (4, 0.13880772329866886), (2, 0.14147120714187622), (10, 0.16325449384748936), (9, 0.19059040769934654), (17, 0.39156654477119446), (18, 0.4206808768212795), (36, 0.6424408033490181), (53, 1.3327257931232452)]
computing accuracy for after removing block 50 . block score: 0.04179526213556528
removed block 50 current accuracy 0.935 loss from initial  0.06499999999999995
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.044701. All blocks and scores: [(41, 0.04470121394842863), (39, 0.04657651763409376), (48, 0.04738455358892679), (44, 0.04756591282784939), (38, 0.048093982972204685), (51, 0.049286987632513046), (46, 0.049609698355197906), (45, 0.05133705772459507), (42, 0.05388758238404989), (40, 0.05490994127467275), (47, 0.055115179624408484), (43, 0.05714608822017908), (1, 0.05728859780356288), (8, 0.058281832840293646), (34, 0.059905705507844687), (52, 0.060203641187399626), (6, 0.06952641159296036), (0, 0.08064921014010906), (14, 0.083858503960073), (13, 0.08429241646081209), (15, 0.09585002530366182), (16, 0.10382314026355743), (11, 0.10392044577747583), (33, 0.11402400489896536), (12, 0.1239256514236331), (4, 0.1388077214360237), (2, 0.14147120155394077), (10, 0.16325449384748936), (9, 0.1905904058367014), (17, 0.39156653359532356), (18, 0.4206808842718601), (36, 0.6424408182501793), (53, 1.5055013447999954)]
computing accuracy for after removing block 41 . block score: 0.04470121394842863
removed block 41 current accuracy 0.9278 loss from initial  0.07220000000000004
since last training loss: 0.033400000000000096 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.044004. All blocks and scores: [(48, 0.04400425776839256), (44, 0.04644410964101553), (39, 0.04657651809975505), (51, 0.04799248557537794), (38, 0.048093982972204685), (46, 0.04810647992417216), (45, 0.04895859910175204), (47, 0.05381970154121518), (40, 0.05490993848070502), (42, 0.054980693850666285), (43, 0.056962812785059214), (1, 0.05728859826922417), (8, 0.05828183051198721), (34, 0.0599057050421834), (52, 0.05992745514959097), (6, 0.06952640879899263), (0, 0.08064921200275421), (14, 0.08385850116610527), (13, 0.08429241646081209), (15, 0.0958500262349844), (16, 0.10382313746958971), (11, 0.10392044298350811), (33, 0.11402399837970734), (12, 0.1239256514236331), (4, 0.13880772329866886), (2, 0.14147119969129562), (10, 0.16325449757277966), (9, 0.1905904058367014), (17, 0.39156653359532356), (18, 0.42068086937069893), (36, 0.6424408331513405), (53, 1.547004222869873)]
computing accuracy for after removing block 48 . block score: 0.04400425776839256
removed block 48 current accuracy 0.9094 loss from initial  0.09060000000000001
since last training loss: 0.05180000000000007 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.046444. All blocks and scores: [(44, 0.04644410777837038), (39, 0.04657651763409376), (38, 0.048093982972204685), (46, 0.04810648085549474), (45, 0.04895859910175204), (51, 0.05218534218147397), (47, 0.053819701075553894), (40, 0.05490993894636631), (42, 0.05498069431632757), (43, 0.056962812319397926), (1, 0.05728859640657902), (8, 0.058281834702938795), (34, 0.05990570457652211), (52, 0.0641195485368371), (6, 0.06952641252428293), (0, 0.08064921107143164), (14, 0.08385850302875042), (13, 0.08429241646081209), (15, 0.0958500262349844), (16, 0.10382313933223486), (11, 0.10392044205218554), (33, 0.11402400303632021), (12, 0.1239256514236331), (4, 0.13880772329866886), (2, 0.14147120527923107), (10, 0.1632544994354248), (9, 0.19059041142463684), (17, 0.39156654477119446), (18, 0.4206808768212795), (36, 0.6424408107995987), (53, 1.7664068788290024)]
computing accuracy for after removing block 44 . block score: 0.04644410777837038
removed block 44 current accuracy 0.8792 loss from initial  0.12080000000000002
since last training loss: 0.08200000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 39, with score 0.046577. All blocks and scores: [(39, 0.046576517168432474), (38, 0.048093982972204685), (46, 0.05032140528783202), (45, 0.05314606288447976), (51, 0.05318373767659068), (47, 0.05454098805785179), (40, 0.05490994080901146), (42, 0.05498069431632757), (43, 0.05696281185373664), (1, 0.057288595009595156), (8, 0.05828183330595493), (34, 0.05990570643916726), (52, 0.06480304151773453), (6, 0.06952640973031521), (0, 0.08064921014010906), (14, 0.08385850489139557), (13, 0.08429241832345724), (15, 0.0958500262349844), (16, 0.10382314026355743), (11, 0.10392044205218554), (33, 0.11402400396764278), (12, 0.12392564956098795), (4, 0.13880772329866886), (2, 0.14147120341658592), (10, 0.16325449384748936), (9, 0.19059040769934654), (17, 0.39156654104590416), (18, 0.4206808805465698), (36, 0.6424408107995987), (53, 1.814819097518921)]
computing accuracy for after removing block 39 . block score: 0.046576517168432474
removed block 39 current accuracy 0.8716 loss from initial  0.12839999999999996
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.048094. All blocks and scores: [(38, 0.048093982972204685), (46, 0.04870449984446168), (45, 0.05101147014647722), (47, 0.05152605287730694), (51, 0.05193331139162183), (42, 0.0560124795883894), (43, 0.05647849477827549), (1, 0.05728859780356288), (40, 0.057621901854872704), (8, 0.0582818309776485), (34, 0.05990570364519954), (52, 0.06357332598417997), (6, 0.06952641066163778), (0, 0.08064921386539936), (14, 0.08385850582271814), (13, 0.08429241739213467), (15, 0.0958500262349844), (16, 0.10382313746958971), (11, 0.10392044205218554), (33, 0.11402400210499763), (12, 0.12392565049231052), (4, 0.13880772329866886), (2, 0.14147120341658592), (10, 0.16325449757277966), (9, 0.1905904058367014), (17, 0.39156654104590416), (18, 0.4206808768212795), (36, 0.6424408257007599), (53, 1.7747954577207565)]
computing accuracy for after removing block 38 . block score: 0.048093982972204685
removed block 38 current accuracy 0.8548 loss from initial  0.1452
since last training loss: 0.10640000000000005 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.048176. All blocks and scores: [(46, 0.04817649023607373), (47, 0.04819272458553314), (45, 0.04869029484689236), (51, 0.051396709866821766), (42, 0.05605077696964145), (43, 0.05675368523225188), (1, 0.057288596872240305), (8, 0.058281832840293646), (34, 0.0599057050421834), (52, 0.06298717204481363), (40, 0.0641734879463911), (6, 0.06952641159296036), (0, 0.08064921200275421), (14, 0.08385850489139557), (13, 0.08429241739213467), (15, 0.09585002530366182), (16, 0.10382314119488001), (11, 0.10392044391483068), (33, 0.11402400489896536), (12, 0.12392565328627825), (4, 0.13880772329866886), (2, 0.14147120155394077), (10, 0.16325450129806995), (9, 0.1905904058367014), (17, 0.39156654104590416), (18, 0.42068086937069893), (36, 0.6424408182501793), (53, 1.706211894750595)]
computing accuracy for after removing block 46 . block score: 0.04817649023607373
removed block 46 current accuracy 0.8114 loss from initial  0.1886
training start
training epoch 0 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.1]
training epoch 1 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 2 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 3 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 4 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 5 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 7 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 8 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 9 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 10 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
