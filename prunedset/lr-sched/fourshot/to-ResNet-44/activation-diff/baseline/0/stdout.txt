start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806163564324), (30, 0.007531445939093828), (2, 0.007728804834187031), (31, 0.009409212740138173), (34, 0.010633390513248742), (33, 0.010768218897283077), (35, 0.010826651006937027), (32, 0.011131544481031597), (28, 0.012192571186460555), (29, 0.013092639506794512), (26, 0.01327010605018586), (25, 0.014763001818209887), (27, 0.015783544862642884), (24, 0.015805189730599523), (22, 0.015843699919059873), (23, 0.017308010021224618), (39, 0.019983843667432666), (42, 0.020841387566179037), (38, 0.02102866256609559), (14, 0.02151670795865357), (43, 0.021687703439965844), (5, 0.02187711768783629), (41, 0.02212515496648848), (44, 0.022776449797675014), (45, 0.023535518441349268), (40, 0.024229632690548897), (47, 0.02465185266919434), (37, 0.025173959089443088), (49, 0.025184793397784233), (3, 0.025671070907264948), (21, 0.025702943792566657), (50, 0.025765859987586737), (20, 0.027230342384427786), (46, 0.028618558775633574), (17, 0.029949784511700273), (51, 0.031313665676862), (48, 0.03152880142442882), (19, 0.03474585711956024), (16, 0.04510569525882602), (15, 0.046672547701746225), (0, 0.0474615478888154), (6, 0.05039410060271621), (7, 0.05069215735420585), (4, 0.050925972405821085), (10, 0.0632855761796236), (13, 0.0640097251161933), (8, 0.06672555860131979), (52, 0.06828812137246132), (12, 0.07267716713249683), (11, 0.07419469766318798), (9, 0.07928675040602684), (36, 0.3385251760482788), (18, 0.4787600599229336), (53, 0.9074814915657043)]
computing accuracy for after removing block 1 . block score: 0.004111806163564324
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.007558359473478049), (2, 0.007992399448994547), (31, 0.009376695612445474), (34, 0.010569098289124668), (33, 0.010759366559796035), (35, 0.010833792039193213), (32, 0.01109052449464798), (28, 0.01219142519403249), (29, 0.013140873750671744), (26, 0.0133111122995615), (25, 0.014746291330084205), (24, 0.015801147324964404), (22, 0.015853286604397), (27, 0.015870402101427317), (23, 0.01725019607692957), (39, 0.019925506319850683), (42, 0.020839826902374625), (38, 0.02093886467628181), (5, 0.02141003031283617), (14, 0.02147067990154028), (43, 0.02164699067361653), (41, 0.022096743574365973), (44, 0.02283085067756474), (45, 0.02349419007077813), (40, 0.024263028986752033), (47, 0.0246264326851815), (37, 0.025157071882858872), (49, 0.02518477221019566), (21, 0.025624873349443078), (50, 0.025800991570577025), (3, 0.026267621433362365), (20, 0.0271265406627208), (46, 0.028638296062126756), (17, 0.030022145714610815), (51, 0.031291101360693574), (48, 0.03151489095762372), (19, 0.03466663230210543), (16, 0.04479835648089647), (15, 0.04640808328986168), (0, 0.047461549285799265), (4, 0.05093049397692084), (6, 0.05134963057935238), (7, 0.05156157026067376), (10, 0.06291997572407126), (13, 0.06426404230296612), (52, 0.06817463226616383), (8, 0.06839867122471333), (12, 0.07294023409485817), (11, 0.07450826372951269), (9, 0.08042858820408583), (36, 0.3383275642991066), (18, 0.4787031188607216), (53, 0.9076695889234543)]
computing accuracy for after removing block 30 . block score: 0.007558359473478049
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992399390786886), (31, 0.009402871364727616), (34, 0.010204410180449486), (35, 0.01043578318785876), (33, 0.010974526521749794), (32, 0.011320485034957528), (28, 0.012191424961201847), (29, 0.013140873750671744), (26, 0.013311111950315535), (25, 0.014746290748007596), (24, 0.015801147324964404), (22, 0.01585328613873571), (27, 0.015870401868596673), (23, 0.017250196542590857), (39, 0.01986637688241899), (38, 0.020629742881283164), (42, 0.020691831596195698), (5, 0.021410029847174883), (14, 0.02147067990154028), (43, 0.0218390841037035), (41, 0.02201103768311441), (44, 0.02278478746302426), (45, 0.0233374263625592), (47, 0.024608810199424624), (40, 0.024793641874566674), (49, 0.02500508981756866), (21, 0.025624873349443078), (37, 0.025666436878964305), (50, 0.025765019236132503), (3, 0.026267620734870434), (20, 0.027126540429890156), (46, 0.028450446669012308), (17, 0.030022145714610815), (51, 0.030892511131241918), (48, 0.0314550728071481), (19, 0.03466663137078285), (16, 0.04479835694655776), (15, 0.04640808515250683), (0, 0.04746154649183154), (4, 0.050930495373904705), (6, 0.05134963057935238), (7, 0.05156157072633505), (10, 0.06291997758671641), (13, 0.06426404230296612), (52, 0.06774707417935133), (8, 0.06839867122471333), (12, 0.0729402331635356), (11, 0.07450826559215784), (9, 0.08042858820408583), (36, 0.341789361089468), (18, 0.4787031076848507), (53, 0.9106026664376259)]
computing accuracy for after removing block 2 . block score: 0.007992399390786886
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.0093913838500157), (34, 0.010356180369853973), (35, 0.010530833271332085), (33, 0.010978628415614367), (32, 0.011285086278803647), (28, 0.012222225894220173), (29, 0.013395004556514323), (26, 0.013411890249699354), (25, 0.014773015980608761), (24, 0.01589584699831903), (22, 0.01594504527747631), (27, 0.016057066386565566), (23, 0.017187519697472453), (39, 0.019868449307978153), (42, 0.020744004286825657), (38, 0.020750499796122313), (5, 0.021117351250723004), (14, 0.02132761781103909), (43, 0.021792822750285268), (41, 0.021959960460662842), (44, 0.022877607494592667), (45, 0.02328475913964212), (47, 0.024535593576729298), (40, 0.02492265636101365), (49, 0.02497671777382493), (21, 0.025540468050166965), (50, 0.025736608309671283), (37, 0.025740001816302538), (3, 0.026626083767041564), (20, 0.02713091066107154), (46, 0.028354250825941563), (17, 0.030052859103307128), (51, 0.030807055300101638), (48, 0.03136400459334254), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384860083461), (7, 0.05248213419690728), (6, 0.05318683199584484), (10, 0.06307358713820577), (13, 0.06417542789131403), (52, 0.06737186666578054), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.3429318964481354), (18, 0.48187143728137016), (53, 0.9105553030967712)]
computing accuracy for after removing block 31 . block score: 0.0093913838500157
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670540764928), (35, 0.010449821129441261), (33, 0.010985722299665213), (32, 0.011304144747555256), (28, 0.012222225544974208), (29, 0.013395005371421576), (26, 0.013411890715360641), (25, 0.014773015631362796), (24, 0.015895847231149673), (22, 0.01594504527747631), (27, 0.016057066153734922), (23, 0.017187519930303097), (39, 0.019797148182988167), (38, 0.020344304852187634), (42, 0.020588677376508713), (5, 0.02111735171638429), (14, 0.021327617345377803), (43, 0.02176103019155562), (41, 0.021869145333766937), (44, 0.02282825973816216), (45, 0.02339630131609738), (47, 0.024508256698027253), (49, 0.02499568462371826), (40, 0.025056050857529044), (21, 0.02554046781733632), (37, 0.025701352395117283), (50, 0.02590625174343586), (3, 0.02662608353421092), (20, 0.02713091066107154), (46, 0.028551971772685647), (17, 0.030052858870476484), (51, 0.03091105609200895), (48, 0.03148650424554944), (19, 0.034590966533869505), (16, 0.04449417209252715), (15, 0.04618462501093745), (0, 0.04746154835447669), (4, 0.050933849066495895), (7, 0.05248213466256857), (6, 0.05318683199584484), (10, 0.06307358853518963), (13, 0.06417542789131403), (52, 0.06731625739485025), (8, 0.07143167965114117), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.34496788680553436), (18, 0.48187144473195076), (53, 0.9170897379517555)]
computing accuracy for after removing block 34 . block score: 0.010089670540764928
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489317937754095), (33, 0.010985722299665213), (32, 0.011304144863970578), (28, 0.01222222566138953), (29, 0.013395004905760288), (26, 0.013411890482529998), (25, 0.014773016213439405), (24, 0.01589584769681096), (22, 0.015945045044645667), (27, 0.016057065688073635), (23, 0.017187520395964384), (39, 0.019266641000285745), (38, 0.019315700512379408), (42, 0.019673911854624748), (5, 0.021117351250723004), (41, 0.02117479918524623), (43, 0.02118000271730125), (14, 0.021327617578208447), (44, 0.022253611125051975), (45, 0.02322493912652135), (47, 0.024223520187661052), (49, 0.024662332143634558), (40, 0.02475132909603417), (37, 0.02511494536884129), (21, 0.025540467351675034), (50, 0.025639905594289303), (3, 0.026626083068549633), (20, 0.02713091135956347), (46, 0.028075408888980746), (17, 0.03005285980179906), (51, 0.030307045206427574), (48, 0.031094568083062768), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.046184624545276165), (0, 0.04746154695749283), (4, 0.05093384766951203), (7, 0.05248213466256857), (6, 0.05318683013319969), (10, 0.06307358667254448), (13, 0.06417542602866888), (52, 0.06632223632186651), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321378737688), (36, 0.3418983221054077), (18, 0.48187142610549927), (53, 0.9368007704615593)]
computing accuracy for after removing block 35 . block score: 0.010489317937754095
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.010985721834003925), (32, 0.0113041449803859), (28, 0.012222225777804852), (29, 0.01339500502217561), (26, 0.013411890831775963), (25, 0.014773015631362796), (24, 0.01589584769681096), (22, 0.015945045743137598), (27, 0.01605706545524299), (23, 0.017187520395964384), (38, 0.018365239026024938), (39, 0.01873115822672844), (42, 0.018845457350835204), (41, 0.020227218745276332), (43, 0.020478624617680907), (5, 0.02111735171638429), (14, 0.021327618043869734), (44, 0.021796140354126692), (45, 0.022849173983559012), (47, 0.023645549546927214), (40, 0.023893441073596478), (49, 0.024012630805373192), (37, 0.02408060897141695), (50, 0.02511946950107813), (21, 0.02554046781733632), (3, 0.026626083068549633), (20, 0.027130910893902183), (46, 0.02747296099551022), (51, 0.029444650281220675), (17, 0.03005285980179906), (48, 0.030196279287338257), (19, 0.034590966533869505), (16, 0.04449417209252715), (15, 0.046184627804905176), (0, 0.047461549285799265), (4, 0.05093384766951203), (7, 0.052482133731245995), (6, 0.053186831064522266), (10, 0.06307358853518963), (13, 0.06417542416602373), (52, 0.06433123350143433), (8, 0.07143167778849602), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.08192321565002203), (36, 0.3352629393339157), (18, 0.48187142983078957), (53, 0.9589025676250458)]
computing accuracy for after removing block 33 . block score: 0.010985721834003925
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144747555256), (28, 0.012222226127050817), (29, 0.013395004905760288), (26, 0.013411890715360641), (25, 0.014773016097024083), (24, 0.015895847231149673), (22, 0.015945045743137598), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.01785989780910313), (39, 0.01848121383227408), (42, 0.01849468587897718), (41, 0.01970775076188147), (43, 0.019804098643362522), (5, 0.021117351949214935), (14, 0.021327617345377803), (44, 0.021341139217838645), (45, 0.022757312282919884), (47, 0.022884674137458205), (40, 0.022964164381846786), (49, 0.02350937225855887), (37, 0.02359610958956182), (50, 0.02473079040646553), (21, 0.025540468748658895), (3, 0.02662608423270285), (46, 0.02685158746317029), (20, 0.02713091019541025), (51, 0.028670211555436254), (48, 0.02950064931064844), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.044494171161204576), (15, 0.046184626407921314), (0, 0.04746154882013798), (4, 0.05093384860083461), (7, 0.05248213326558471), (6, 0.053186831064522266), (52, 0.062409017235040665), (10, 0.06307358993217349), (13, 0.06417542695999146), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423978764563799), (9, 0.08192321565002203), (36, 0.330499742180109), (18, 0.48187144473195076), (53, 0.9826682582497597)]
computing accuracy for after removing block 32 . block score: 0.011304144747555256
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 1 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 2 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 3 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 4 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 5 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 6 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.1]
training epoch 7 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.1]
training epoch 8 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.1]
training epoch 9 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 10 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012222. All blocks and scores: [(28, 0.012222225428558886), (29, 0.01339500502217561), (26, 0.013411890366114676), (25, 0.014773015747778118), (24, 0.015895847463980317), (22, 0.015945045044645667), (27, 0.016057065688073635), (23, 0.01718751946464181), (38, 0.017423494020476937), (42, 0.01785332732833922), (39, 0.018243111670017242), (41, 0.019577455474063754), (43, 0.019590672105550766), (44, 0.020979802357032895), (5, 0.021117351250723004), (14, 0.021327617578208447), (47, 0.022578312316909432), (45, 0.02269747806712985), (37, 0.02285339101217687), (49, 0.023190516512840986), (40, 0.023227871861308813), (50, 0.02436222229152918), (21, 0.025540468282997608), (46, 0.026505473535507917), (3, 0.02662608353421092), (20, 0.02713091135956347), (51, 0.028193607460707426), (48, 0.029435487929731607), (17, 0.030052859103307128), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.047461547423154116), (4, 0.05093384953215718), (7, 0.05248213326558471), (6, 0.05318683013319969), (52, 0.06163395196199417), (10, 0.06307358667254448), (13, 0.06417542416602373), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423978857696056), (9, 0.0819232128560543), (36, 0.3290293700993061), (18, 0.48187143728137016), (53, 0.9939456880092621)]
computing accuracy for after removing block 28 . block score: 0.012222225428558886
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.013134. All blocks and scores: [(29, 0.01313444715924561), (26, 0.013411890715360641), (25, 0.014773015514947474), (24, 0.015895847463980317), (22, 0.015945045044645667), (27, 0.016057066153734922), (38, 0.01716868462972343), (23, 0.017187519930303097), (42, 0.017377696931362152), (39, 0.01826188643462956), (43, 0.01912656961940229), (41, 0.019421310164034367), (44, 0.020716934697702527), (5, 0.02111735171638429), (14, 0.021327618043869734), (47, 0.022124751238152385), (45, 0.02240564743988216), (37, 0.022597742499783635), (40, 0.022692735539749265), (49, 0.022759286453947425), (50, 0.024160553235560656), (21, 0.025540467584505677), (46, 0.02618824504315853), (3, 0.026626083999872208), (20, 0.027130911126732826), (51, 0.02760661533102393), (48, 0.02895548497326672), (17, 0.030052858171984553), (19, 0.03459096699953079), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.047461545560508966), (4, 0.05093384860083461), (7, 0.05248213279992342), (6, 0.05318683199584484), (52, 0.06071764277294278), (10, 0.06307358806952834), (13, 0.06417542416602373), (8, 0.07143167778849602), (12, 0.07294507697224617), (11, 0.07423978950828314), (9, 0.0819232128560543), (36, 0.3257451504468918), (18, 0.48187142983078957), (53, 1.0072816014289856)]
computing accuracy for after removing block 29 . block score: 0.01313444715924561
removed block 29 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013412. All blocks and scores: [(26, 0.013411890482529998), (25, 0.014773015514947474), (24, 0.01589584769681096), (22, 0.01594504527747631), (27, 0.01605706545524299), (38, 0.016528347274288535), (23, 0.017187519930303097), (42, 0.017526801442727447), (39, 0.01801301073282957), (43, 0.01896902685984969), (41, 0.019220214802771807), (44, 0.020273722242563963), (5, 0.021117351483553648), (14, 0.021327618043869734), (47, 0.02195585472509265), (45, 0.022276045754551888), (49, 0.02234107838012278), (37, 0.02238200604915619), (40, 0.022958484711125493), (50, 0.024057542672380805), (21, 0.02554046781733632), (46, 0.026293946895748377), (3, 0.026626084465533495), (20, 0.02713091135956347), (51, 0.027329839998856187), (48, 0.028983932454138994), (17, 0.03005285863764584), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.0461846268735826), (0, 0.0474615478888154), (4, 0.05093384953215718), (7, 0.05248213326558471), (6, 0.053186831064522266), (52, 0.06034902483224869), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143167685717344), (12, 0.07294507790356874), (11, 0.07423979137092829), (9, 0.08192321378737688), (36, 0.33013899624347687), (18, 0.48187144473195076), (53, 1.014470487833023)]
computing accuracy for after removing block 26 . block score: 0.013411890482529998
removed block 26 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014773. All blocks and scores: [(25, 0.014773016213439405), (24, 0.01589584769681096), (22, 0.015945045044645667), (38, 0.016351457219570875), (27, 0.01641613431274891), (42, 0.016968311043456197), (23, 0.01718752016313374), (39, 0.01759598543867469), (43, 0.018648818600922823), (41, 0.01897320244461298), (44, 0.02003990998491645), (5, 0.02111735171638429), (14, 0.021327618043869734), (47, 0.021771238185465336), (45, 0.02202610159292817), (49, 0.022116392850875854), (37, 0.02216550288721919), (40, 0.022654106840491295), (50, 0.024147539166733623), (21, 0.025540467584505677), (46, 0.0257268650457263), (51, 0.02658225758932531), (3, 0.026626083767041564), (20, 0.027130910893902183), (48, 0.028896388364955783), (17, 0.030052858870476484), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.046184627804905176), (0, 0.04746154835447669), (4, 0.05093384766951203), (7, 0.05248213419690728), (6, 0.05318683199584484), (52, 0.059312851168215275), (10, 0.06307358806952834), (13, 0.06417542416602373), (8, 0.07143167685717344), (12, 0.0729450760409236), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.32769153267145157), (18, 0.48187144845724106), (53, 1.0349864661693573)]
computing accuracy for after removing block 25 . block score: 0.014773016213439405
removed block 25 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.015896. All blocks and scores: [(24, 0.015895847463980317), (22, 0.015945045743137598), (38, 0.0161167464684695), (27, 0.016201819060370326), (42, 0.016800900688394904), (39, 0.017148226033896208), (23, 0.017187519930303097), (43, 0.018563210731372237), (41, 0.018886164762079716), (44, 0.019977419637143612), (5, 0.02111735171638429), (14, 0.021327617578208447), (47, 0.021370713831856847), (49, 0.021683972794562578), (45, 0.02175015676766634), (37, 0.021764446515589952), (40, 0.022557187592610717), (50, 0.024213684257119894), (21, 0.025540467351675034), (46, 0.025579196400940418), (51, 0.02589200669899583), (3, 0.026626083301380277), (20, 0.027130910893902183), (48, 0.02842099592089653), (17, 0.030052858870476484), (19, 0.03459096606820822), (16, 0.04449417209252715), (15, 0.04618462547659874), (0, 0.0474615478888154), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.053186831530183554), (52, 0.058053718879818916), (10, 0.0630735894665122), (13, 0.0641754250973463), (8, 0.07143167778849602), (12, 0.07294508069753647), (11, 0.07423978950828314), (9, 0.08192321565002203), (36, 0.3308594338595867), (18, 0.48187144100666046), (53, 1.0488153100013733)]
computing accuracy for after removing block 24 . block score: 0.015895847463980317
removed block 24 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015644. All blocks and scores: [(27, 0.01564404193777591), (38, 0.015937610063701868), (22, 0.015945045510306954), (42, 0.016610756050795317), (39, 0.017013835487887263), (23, 0.017187519930303097), (43, 0.018406943418085575), (41, 0.018716909689828753), (44, 0.01980676525272429), (47, 0.021023611538112164), (5, 0.021117351949214935), (14, 0.021327618276700377), (49, 0.021376667311415076), (45, 0.021665899315848947), (37, 0.022019794210791588), (40, 0.022359847091138363), (50, 0.0240969096776098), (46, 0.025163474725559354), (51, 0.025269010569900274), (21, 0.025540468050166965), (3, 0.02662608353421092), (20, 0.027130910893902183), (48, 0.02797303651459515), (17, 0.03005285933613777), (19, 0.03459096606820822), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.04746154882013798), (4, 0.05093384860083461), (7, 0.052482133731245995), (6, 0.05318682920187712), (52, 0.0571787441149354), (10, 0.06307358806952834), (13, 0.06417542416602373), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423978857696056), (9, 0.08192321378737688), (36, 0.3319184221327305), (18, 0.48187145218253136), (53, 1.056150808930397)]
computing accuracy for after removing block 27 . block score: 0.01564404193777591
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.015308. All blocks and scores: [(38, 0.015307825640775263), (22, 0.015945045510306954), (42, 0.016510470770299435), (39, 0.016512590693309903), (23, 0.01718752016313374), (43, 0.01780830160714686), (41, 0.018523185746744275), (44, 0.019996799295768142), (47, 0.020540195517241955), (49, 0.021024907706305385), (5, 0.021117351949214935), (14, 0.02132761781103909), (45, 0.021421734942123294), (37, 0.021547694690525532), (40, 0.0219746227376163), (50, 0.024400705005973577), (46, 0.024719235254451632), (51, 0.02475439035333693), (21, 0.025540467351675034), (3, 0.026626083767041564), (20, 0.027130910893902183), (48, 0.02760885050520301), (17, 0.03005285933613777), (19, 0.03459096746519208), (16, 0.04449417255818844), (15, 0.04618462594226003), (0, 0.04746154835447669), (4, 0.05093384953215718), (7, 0.052482133731245995), (6, 0.053186831530183554), (52, 0.05619245767593384), (10, 0.06307358760386705), (13, 0.06417542789131403), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423978857696056), (9, 0.0819232165813446), (36, 0.33047793433070183), (18, 0.48187144473195076), (53, 1.0667929947376251)]
computing accuracy for after removing block 38 . block score: 0.015307825640775263
removed block 38 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.017999999999999905 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.015945. All blocks and scores: [(22, 0.015945045510306954), (42, 0.016701201209798455), (39, 0.01711469143629074), (23, 0.017187519697472453), (43, 0.01719377189874649), (41, 0.018250516150146723), (44, 0.019619957311078906), (47, 0.02009118953719735), (49, 0.02028846275061369), (45, 0.020802826853469014), (5, 0.021117351250723004), (14, 0.021327617345377803), (37, 0.021547694923356175), (40, 0.022401679772883654), (50, 0.02355430368334055), (51, 0.023709413362666965), (46, 0.02471372578293085), (21, 0.025540467351675034), (3, 0.026626083301380277), (48, 0.026906078914180398), (20, 0.02713091066107154), (17, 0.03005285933613777), (19, 0.03459096606820822), (16, 0.044494173023849726), (15, 0.046184626407921314), (0, 0.047461545560508966), (4, 0.05093384860083461), (7, 0.052482133731245995), (6, 0.05318683199584484), (52, 0.054677230305969715), (10, 0.06307358853518963), (13, 0.06417542602866888), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.0819232165813446), (36, 0.33047793433070183), (18, 0.48187142983078957), (53, 1.0992354601621628)]
computing accuracy for after removing block 22 . block score: 0.015945045510306954
removed block 22 current accuracy 0.9742 loss from initial  0.025800000000000045
training start
training epoch 0 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.1]
training epoch 1 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 2 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 3 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 4 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 6 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 7 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 8 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 9 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 10 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.974200)
finished training. finished 50 epochs. accuracy 0.9742 topk_dict {'top1': 0.9742}
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.016116. All blocks and scores: [(42, 0.016115854494273663), (23, 0.016751634422689676), (39, 0.017163580283522606), (43, 0.017340539023280144), (41, 0.018351152539253235), (44, 0.019731603330001235), (47, 0.01974461623467505), (49, 0.01996712014079094), (45, 0.020839692559093237), (5, 0.021117351483553648), (14, 0.021327618043869734), (37, 0.021559265442192554), (40, 0.021836146945133805), (51, 0.023225210839882493), (50, 0.023681905586272478), (46, 0.024719639448449016), (21, 0.025540468282997608), (48, 0.02641315315850079), (3, 0.02662608423270285), (20, 0.027130910893902183), (17, 0.03005285933613777), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.04746154835447669), (4, 0.05093384766951203), (7, 0.05248213326558471), (6, 0.053186831530183554), (52, 0.05412210989743471), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143167778849602), (12, 0.07294508069753647), (11, 0.07423978857696056), (9, 0.08192321565002203), (36, 0.3307998776435852), (18, 0.48187144100666046), (53, 1.110215187072754)]
computing accuracy for after removing block 42 . block score: 0.016115854494273663
removed block 42 current accuracy 0.9696 loss from initial  0.030399999999999983
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016752. All blocks and scores: [(23, 0.016751634189859033), (39, 0.017163580050691962), (41, 0.018351152539253235), (43, 0.018390603829175234), (49, 0.019832697231322527), (47, 0.01992953522130847), (44, 0.020700426306575537), (5, 0.021117351483553648), (14, 0.021327618043869734), (37, 0.02155926520936191), (45, 0.021742521552369), (40, 0.021836146945133805), (51, 0.02259360929019749), (50, 0.02351996279321611), (46, 0.02537697833031416), (21, 0.025540467584505677), (48, 0.026064808247610927), (3, 0.026626083999872208), (20, 0.027130910428240895), (17, 0.03005285933613777), (19, 0.03459096606820822), (16, 0.044494171626865864), (15, 0.04618462594226003), (0, 0.04746154695749283), (4, 0.05093384766951203), (52, 0.05230193678289652), (7, 0.052482135128229856), (6, 0.053186831064522266), (10, 0.06307358667254448), (13, 0.0641754250973463), (8, 0.07143167592585087), (12, 0.07294507697224617), (11, 0.07423979043960571), (9, 0.08192321565002203), (36, 0.3307998813688755), (18, 0.48187144100666046), (53, 1.1384830176830292)]
computing accuracy for after removing block 23 . block score: 0.016751634189859033
removed block 23 current accuracy 0.9584 loss from initial  0.04159999999999997
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 39, with score 0.016881. All blocks and scores: [(39, 0.016880576498806477), (41, 0.018102025613188744), (43, 0.018480214988812804), (49, 0.019399642013013363), (47, 0.019492306979373097), (44, 0.020657918648794293), (37, 0.021091047441586852), (5, 0.02111735171638429), (45, 0.021201944211497903), (14, 0.02132761850953102), (40, 0.02153184567578137), (51, 0.0220535253174603), (50, 0.023360743187367916), (46, 0.02486406033858657), (21, 0.025540468515828252), (48, 0.025762951001524925), (3, 0.026626083301380277), (20, 0.02713091066107154), (17, 0.030052859103307128), (19, 0.03459096606820822), (16, 0.04449417209252715), (15, 0.04618462407961488), (0, 0.047461547423154116), (4, 0.05093384813517332), (52, 0.05140139674767852), (7, 0.05248213419690728), (6, 0.05318683059886098), (10, 0.06307358760386705), (13, 0.06417542602866888), (8, 0.07143167965114117), (12, 0.07294507697224617), (11, 0.07423978857696056), (9, 0.0819232128560543), (36, 0.3335048109292984), (18, 0.48187144473195076), (53, 1.1530401110649109)]
computing accuracy for after removing block 39 . block score: 0.016880576498806477
removed block 39 current accuracy 0.9516 loss from initial  0.0484
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 41, with score 0.018354. All blocks and scores: [(41, 0.01835422753356397), (43, 0.01853087591007352), (49, 0.019299121340736747), (47, 0.019307703711092472), (37, 0.021091047441586852), (5, 0.02111735171638429), (51, 0.021305030677467585), (14, 0.021327617578208447), (44, 0.0213861339725554), (40, 0.021602724213153124), (45, 0.021840070141479373), (50, 0.022813046351075172), (46, 0.02475375938229263), (21, 0.02554046711884439), (48, 0.026043321006000042), (3, 0.026626083999872208), (20, 0.02713091019541025), (17, 0.030052858404815197), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462547659874), (0, 0.047461546026170254), (4, 0.050933849066495895), (52, 0.05102795548737049), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.0630735857412219), (13, 0.06417542602866888), (8, 0.07143167778849602), (12, 0.07294507697224617), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3335048109292984), (18, 0.48187144845724106), (53, 1.203935831785202)]
computing accuracy for after removing block 41 . block score: 0.01835422753356397
removed block 41 current accuracy 0.9472 loss from initial  0.05279999999999996
since last training loss: 0.026999999999999913 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 47, with score 0.018820. All blocks and scores: [(47, 0.018819912802428007), (49, 0.0189357060007751), (43, 0.01949500013142824), (51, 0.020423235604539514), (37, 0.021091047674417496), (5, 0.02111735101789236), (14, 0.021327618276700377), (45, 0.02155023696832359), (40, 0.021602722816169262), (44, 0.021712582791224122), (50, 0.022176147205755115), (46, 0.02473819558508694), (21, 0.02554046711884439), (48, 0.026037547271698713), (3, 0.026626083999872208), (20, 0.02713091066107154), (17, 0.03005285933613777), (19, 0.034590966533869505), (16, 0.04449417209252715), (15, 0.0461846268735826), (0, 0.047461545560508966), (52, 0.050155299715697765), (4, 0.050933849066495895), (7, 0.052482133731245995), (6, 0.05318683199584484), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143168058246374), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3335047885775566), (18, 0.48187143728137016), (53, 1.2834498435258865)]
computing accuracy for after removing block 47 . block score: 0.018819912802428007
removed block 47 current accuracy 0.9228 loss from initial  0.07720000000000005
since last training loss: 0.0514 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.019495. All blocks and scores: [(43, 0.01949500059708953), (49, 0.020387135446071625), (37, 0.021091046975925565), (5, 0.021117351250723004), (14, 0.02132761781103909), (51, 0.021424151258543134), (45, 0.021550237433984876), (40, 0.021602724213153124), (44, 0.02171258209273219), (50, 0.023240457754582167), (46, 0.02473819558508694), (21, 0.02554046711884439), (3, 0.02662608423270285), (20, 0.027130910893902183), (48, 0.027901076478883624), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462733924389), (0, 0.047461547423154116), (4, 0.05093384766951203), (52, 0.05177584942430258), (7, 0.05248213466256857), (6, 0.053186831530183554), (10, 0.06307358853518963), (13, 0.06417542695999146), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423978950828314), (9, 0.08192321378737688), (36, 0.3335048109292984), (18, 0.48187143355607986), (53, 1.4368781745433807)]
computing accuracy for after removing block 43 . block score: 0.01949500059708953
removed block 43 current accuracy 0.9048 loss from initial  0.09519999999999995
since last training loss: 0.0693999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.019984. All blocks and scores: [(49, 0.019984257873147726), (51, 0.020722071174532175), (37, 0.021091046975925565), (5, 0.021117351250723004), (14, 0.021327617345377803), (40, 0.021602723747491837), (45, 0.02195880515500903), (50, 0.022416852414608), (44, 0.022723785135895014), (46, 0.02543480251915753), (21, 0.02554046711884439), (3, 0.02662608353421092), (20, 0.027130911126732826), (48, 0.028048778185620904), (17, 0.030052858870476484), (19, 0.03459096746519208), (16, 0.04449417209252715), (15, 0.046184624545276165), (0, 0.0474615478888154), (4, 0.05093384766951203), (52, 0.0518702776171267), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358806952834), (13, 0.0641754250973463), (8, 0.07143167685717344), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321378737688), (36, 0.3335047997534275), (18, 0.48187144100666046), (53, 1.539286881685257)]
computing accuracy for after removing block 49 . block score: 0.019984257873147726
removed block 49 current accuracy 0.8708 loss from initial  0.12919999999999998
since last training loss: 0.10339999999999994 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 37, with score 0.021091. All blocks and scores: [(37, 0.02109104674309492), (5, 0.021117351949214935), (14, 0.02132761781103909), (40, 0.021602723747491837), (45, 0.021958804922178388), (44, 0.02272378420457244), (51, 0.02371912100352347), (50, 0.024712446378543973), (46, 0.02543480251915753), (21, 0.02554046711884439), (3, 0.02662608423270285), (20, 0.027130910893902183), (48, 0.02804877795279026), (17, 0.03005285933613777), (19, 0.03459096606820822), (16, 0.044494171161204576), (15, 0.04618462407961488), (0, 0.047461547423154116), (4, 0.050933847203850746), (7, 0.052482133731245995), (6, 0.05318683199584484), (52, 0.05496656522154808), (10, 0.06307358620688319), (13, 0.06417542416602373), (8, 0.07143167592585087), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.3335048072040081), (18, 0.48187144473195076), (53, 1.7370875179767609)]
computing accuracy for after removing block 37 . block score: 0.02109104674309492
removed block 37 current accuracy 0.8438 loss from initial  0.1562
training start
training epoch 0 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.1]
training epoch 1 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 2 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 3 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 4 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.1]
training epoch 5 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 6 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 7 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 8 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 9 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.1]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.957 topk_dict {'top1': 0.957} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.958200)
finished training. finished 50 epochs. accuracy 0.9582 topk_dict {'top1': 0.9582}
start iteration 24
[activation diff]: block to remove picked: 14, with score 0.045432. All blocks and scores: [(14, 0.045432476326823235), (50, 0.04660762334242463), (51, 0.047071071807295084), (5, 0.04807795723900199), (3, 0.04902090411633253), (45, 0.05196789978072047), (44, 0.05748322093859315), (48, 0.058574018999934196), (17, 0.059014659374952316), (46, 0.0625382112339139), (52, 0.06461372971534729), (40, 0.06800177320837975), (20, 0.07245535869151354), (19, 0.08283385261893272), (0, 0.08465242106467485), (21, 0.09120825491845608), (16, 0.09425012953579426), (4, 0.09477083664387465), (6, 0.09897876437753439), (15, 0.10167945828288794), (7, 0.10588228050619364), (8, 0.11846190970391035), (10, 0.1250703278928995), (13, 0.13652358390390873), (11, 0.1377975530922413), (9, 0.14088832400739193), (12, 0.15168695710599422), (36, 0.5555930510163307), (18, 0.614348977804184), (53, 1.1467132419347763)]
computing accuracy for after removing block 14 . block score: 0.045432476326823235
removed block 14 current accuracy 0.953 loss from initial  0.04700000000000004
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 50, with score 0.046241. All blocks and scores: [(50, 0.046240676660090685), (51, 0.04678473621606827), (5, 0.0480779567733407), (3, 0.049020903650671244), (45, 0.05474024498835206), (48, 0.05891978368163109), (17, 0.060329207219183445), (44, 0.06107325945049524), (46, 0.06352546298876405), (52, 0.06452590972185135), (40, 0.06801112741231918), (20, 0.07368481624871492), (0, 0.0846524192020297), (21, 0.08803027495741844), (19, 0.08983304910361767), (16, 0.09192448388785124), (4, 0.0947708347812295), (6, 0.09897876717150211), (15, 0.10324071254581213), (7, 0.10588228143751621), (8, 0.1184619152918458), (10, 0.1250703278928995), (13, 0.13652358017861843), (11, 0.13779754750430584), (9, 0.14088832959532738), (12, 0.15168695710599422), (36, 0.5608827918767929), (18, 0.613510936498642), (53, 1.135177731513977)]
computing accuracy for after removing block 50 . block score: 0.046240676660090685
removed block 50 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 5, with score 0.048078. All blocks and scores: [(5, 0.0480779567733407), (3, 0.04902090411633253), (45, 0.05474024452269077), (51, 0.055501274298876524), (48, 0.0589197832159698), (17, 0.06032921001315117), (44, 0.06107325991615653), (46, 0.06352546298876405), (40, 0.06801112554967403), (52, 0.07077786419540644), (20, 0.07368481624871492), (0, 0.0846524192020297), (21, 0.08803027495741844), (19, 0.08983304630964994), (16, 0.09192448575049639), (4, 0.09477083571255207), (6, 0.09897876996546984), (15, 0.1032407134771347), (7, 0.10588227678090334), (8, 0.11846191063523293), (10, 0.12507032603025436), (13, 0.13652358390390873), (11, 0.13779754750430584), (9, 0.14088832773268223), (12, 0.15168695896863937), (36, 0.5608827844262123), (18, 0.6135109290480614), (53, 1.2666554301977158)]
computing accuracy for after removing block 5 . block score: 0.0480779567733407
removed block 5 current accuracy 0.9416 loss from initial  0.05840000000000001
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 3, with score 0.049021. All blocks and scores: [(3, 0.04902090411633253), (45, 0.05440321518108249), (51, 0.05493076844140887), (17, 0.056596881709992886), (48, 0.05933480756357312), (44, 0.06146681820973754), (46, 0.06300475541502237), (52, 0.07031204458326101), (20, 0.07147269230335951), (40, 0.07231709081679583), (0, 0.08465242013335228), (21, 0.08598699048161507), (19, 0.08851124159991741), (16, 0.09011814650148153), (4, 0.09477083384990692), (6, 0.0989570114761591), (15, 0.10249123442918062), (7, 0.10771750472486019), (8, 0.12056893110275269), (10, 0.12462723255157471), (11, 0.12752161733806133), (13, 0.1343812681734562), (9, 0.14064214937388897), (12, 0.14519325271248817), (36, 0.5656730160117149), (18, 0.6107945814728737), (53, 1.2793058454990387)]
computing accuracy for after removing block 3 . block score: 0.04902090411633253
removed block 3 current accuracy 0.9384 loss from initial  0.06159999999999999
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 45, with score 0.053687. All blocks and scores: [(45, 0.053686896339058876), (51, 0.05400546686723828), (17, 0.05533509235829115), (48, 0.0588824232108891), (44, 0.06067701941356063), (46, 0.06225531222298741), (20, 0.06947535183280706), (52, 0.07002254575490952), (40, 0.07192849647253752), (21, 0.08325829543173313), (0, 0.08465242106467485), (16, 0.0849092872813344), (19, 0.08589758072048426), (4, 0.09614553209394217), (6, 0.09929602220654488), (15, 0.10034876223653555), (7, 0.10730915889143944), (8, 0.12208541389554739), (11, 0.123437425121665), (10, 0.13002578355371952), (13, 0.1316440813243389), (9, 0.13834768161177635), (12, 0.14068410359323025), (36, 0.5550204813480377), (18, 0.5955221727490425), (53, 1.2875255346298218)]
computing accuracy for after removing block 45 . block score: 0.053686896339058876
removed block 45 current accuracy 0.9226 loss from initial  0.07740000000000002
since last training loss: 0.035600000000000076 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.052846. All blocks and scores: [(51, 0.052846106700599194), (17, 0.055335092823952436), (48, 0.05881365342065692), (44, 0.06067702313885093), (46, 0.06680634338408709), (52, 0.06909474637359381), (20, 0.06947535276412964), (40, 0.07192849926650524), (21, 0.08325829356908798), (0, 0.08465242013335228), (16, 0.08490928635001183), (19, 0.08589757885783911), (4, 0.09614553395658731), (6, 0.09929602220654488), (15, 0.10034876130521297), (7, 0.10730915796011686), (8, 0.12208541296422482), (11, 0.12343741953372955), (10, 0.13002578541636467), (13, 0.13164408318698406), (9, 0.13834768161177635), (12, 0.14068410731852055), (36, 0.5550204962491989), (18, 0.5955221801996231), (53, 1.287597417831421)]
computing accuracy for after removing block 51 . block score: 0.052846106700599194
removed block 51 current accuracy 0.8964 loss from initial  0.10360000000000003
since last training loss: 0.06180000000000008 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 17, with score 0.055335. All blocks and scores: [(17, 0.0553350942209363), (48, 0.05881365342065692), (44, 0.060677021741867065), (46, 0.06680634338408709), (20, 0.06947535369545221), (40, 0.07192849647253752), (52, 0.07942997850477695), (21, 0.08325829543173313), (0, 0.08465242013335228), (16, 0.08490928821265697), (19, 0.08589758072048426), (4, 0.09614553023129702), (6, 0.0992960212752223), (15, 0.10034875851124525), (7, 0.10730915982276201), (8, 0.12208541575819254), (11, 0.12343742325901985), (10, 0.13002578169107437), (13, 0.13164407946169376), (9, 0.1383476797491312), (12, 0.14068410359323025), (36, 0.5550204962491989), (18, 0.5955221876502037), (53, 1.5925943851470947)]
computing accuracy for after removing block 17 . block score: 0.0553350942209363
removed block 17 current accuracy 0.8858 loss from initial  0.11419999999999997
since last training loss: 0.07240000000000002 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 48, with score 0.058069. All blocks and scores: [(48, 0.058069048915058374), (44, 0.06047054287046194), (46, 0.06429015751928091), (20, 0.06569009367376566), (40, 0.07052568718791008), (52, 0.07717160414904356), (21, 0.07808045577257872), (0, 0.08465242292732), (16, 0.08490928635001183), (19, 0.08588584326207638), (4, 0.09614553395658731), (6, 0.099296017549932), (15, 0.1003487603738904), (7, 0.10730915702879429), (8, 0.12208541296422482), (11, 0.123437425121665), (10, 0.13002578169107437), (13, 0.13164407759904861), (9, 0.1383476871997118), (12, 0.1406841054558754), (36, 0.5395540371537209), (18, 0.5849572271108627), (53, 1.5879012793302536)]
computing accuracy for after removing block 48 . block score: 0.058069048915058374
removed block 48 current accuracy 0.8176 loss from initial  0.1824
since last training loss: 0.14060000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 44, with score 0.060471. All blocks and scores: [(44, 0.06047054147347808), (46, 0.06429015938192606), (20, 0.06569009553641081), (40, 0.07052568718791008), (21, 0.07808045297861099), (52, 0.0815091198310256), (0, 0.08465242292732), (16, 0.0849092872813344), (19, 0.0858858423307538), (4, 0.09614553209394217), (6, 0.0992960212752223), (15, 0.1003487603738904), (7, 0.10730915702879429), (8, 0.12208541482686996), (11, 0.12343742232769728), (10, 0.13002578355371952), (13, 0.1316440813243389), (9, 0.13834768533706665), (12, 0.14068410731852055), (36, 0.5395540371537209), (18, 0.5849572047591209), (53, 1.9129676818847656)]
computing accuracy for after removing block 44 . block score: 0.06047054147347808
removed block 44 current accuracy 0.7456 loss from initial  0.25439999999999996
training start
training epoch 0 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best True lr [0.1]
training epoch 1 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.1]
training epoch 2 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 3 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best True lr [0.1]
training epoch 4 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.1]
training epoch 5 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 6 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 7 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 8 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 9 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
