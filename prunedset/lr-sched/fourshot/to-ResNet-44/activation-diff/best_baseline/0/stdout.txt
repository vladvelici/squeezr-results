start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.00923305086325854), (30, 0.010039400542154908), (31, 0.010361599852330983), (34, 0.013312276219949126), (29, 0.013541154679842293), (35, 0.016018462600186467), (26, 0.01603759080171585), (28, 0.017728674924001098), (27, 0.019127048319205642), (43, 0.0202324572019279), (46, 0.02104454068467021), (25, 0.02197260269895196), (23, 0.022379535483196378), (41, 0.02282664831727743), (44, 0.02339507848955691), (40, 0.02402502507902682), (45, 0.024295410374179482), (21, 0.024924598401412368), (22, 0.025168769527226686), (48, 0.025341259548440576), (24, 0.025899536442011595), (50, 0.026409972924739122), (42, 0.026674100197851658), (20, 0.02685900661163032), (49, 0.027037164429202676), (47, 0.029306468786671758), (39, 0.03157071233727038), (38, 0.03163787117227912), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.04173417296260595), (9, 0.04340188065543771), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.04783663526177406), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980783998966), (1, 0.06676734331995249), (52, 0.06862937286496162), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.43757999688386917), (18, 0.5108213052153587), (53, 0.8211489021778107)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.01036160031799227), (34, 0.013133947039023042), (29, 0.013541154679842293), (26, 0.016037591034546494), (35, 0.016169289126992226), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020072476705536246), (46, 0.020731385564431548), (25, 0.021972602931782603), (41, 0.022347092861309648), (23, 0.022379535948857665), (44, 0.023235687287524343), (40, 0.023841067450121045), (45, 0.023965542670339346), (48, 0.024917915929108858), (21, 0.024924598401412368), (22, 0.025168768363073468), (50, 0.025840812595561147), (24, 0.02589953737333417), (42, 0.026315323309972882), (49, 0.02665567467920482), (20, 0.02685900661163032), (47, 0.028728798497468233), (39, 0.03131764195859432), (38, 0.031380363274365664), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859582901001), (37, 0.03802584297955036), (51, 0.04122393857687712), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.054548467975109816), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.06095684925094247), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06745154783129692), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.43538709729909897), (18, 0.5108212903141975), (53, 0.8222574219107628)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039401007816195), (31, 0.010361599968746305), (34, 0.012765232590027153), (29, 0.01354115444701165), (35, 0.015992750879377127), (26, 0.016037590336054564), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02007513167336583), (46, 0.020841406425461173), (25, 0.02197260269895196), (41, 0.022319767391309142), (23, 0.022379535483196378), (44, 0.023154049878939986), (40, 0.02388568432070315), (45, 0.02407168853096664), (48, 0.024877465795725584), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.02569117839448154), (24, 0.025899537140503526), (42, 0.026123747928068042), (49, 0.026479422114789486), (20, 0.02685900731012225), (47, 0.02869313210248947), (38, 0.031236795708537102), (39, 0.0312952920794487), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628594897687435), (37, 0.03837669128552079), (51, 0.041114033199846745), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368550255895), (14, 0.04783663293346763), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.0630098064430058), (1, 0.06676734238862991), (52, 0.0670045642182231), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.43640002235770226), (18, 0.5108212977647781), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039401007816195
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372250564396), (34, 0.01238783705048263), (29, 0.013541154563426971), (35, 0.01600809581577778), (26, 0.016037590336054564), (28, 0.017728675855323672), (27, 0.019127048319205642), (43, 0.020083633484318852), (46, 0.020704444497823715), (25, 0.021972602466121316), (41, 0.022253197384998202), (23, 0.02237953501753509), (44, 0.02326776133850217), (40, 0.024013879941776395), (45, 0.0240929932333529), (48, 0.02466528071090579), (21, 0.02492459793575108), (22, 0.025168768363073468), (50, 0.02545973379164934), (42, 0.025655712699517608), (24, 0.02589953737333417), (49, 0.026287756860256195), (20, 0.02685900731012225), (47, 0.02836342342197895), (38, 0.031047647586092353), (39, 0.031380771892145276), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03897124528884888), (51, 0.04075620276853442), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663246780634), (2, 0.05454846704378724), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980970263481), (52, 0.0658631632104516), (1, 0.06676734425127506), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4389924667775631), (18, 0.5108213126659393), (53, 0.8391561582684517)]
computing accuracy for after removing block 31 . block score: 0.010375372250564396
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619897678494), (29, 0.013541154330596328), (26, 0.01603759080171585), (35, 0.01605736301280558), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02004934987053275), (46, 0.0205529872328043), (25, 0.021972602466121316), (41, 0.02206748421303928), (23, 0.022379535250365734), (44, 0.022979132598266006), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.024386122822761536), (21, 0.02492459793575108), (50, 0.025042241672053933), (22, 0.025168769527226686), (42, 0.025414508301764727), (49, 0.025842698756605387), (24, 0.025899536907672882), (20, 0.02685900731012225), (47, 0.028050735127180815), (38, 0.031040059868246317), (39, 0.03150080284103751), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.039112848695367575), (51, 0.04024627199396491), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.047836634796112776), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300981109961867), (52, 0.06486208876594901), (1, 0.06676734052598476), (8, 0.07467832509428263), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4381278418004513), (18, 0.5108212977647781), (53, 0.8458427786827087)]
computing accuracy for after removing block 34 . block score: 0.012489619897678494
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154330596328), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020503456005826592), (46, 0.0207253226544708), (25, 0.021972602233290672), (23, 0.022379535250365734), (41, 0.022452628705650568), (44, 0.023364473367109895), (48, 0.02429035445675254), (45, 0.02443871204741299), (40, 0.024470558390021324), (21, 0.024924598401412368), (50, 0.025042172521352768), (22, 0.025168768595904112), (49, 0.02587597048841417), (24, 0.025899536442011595), (42, 0.026205406757071614), (20, 0.02685900661163032), (47, 0.028178583132103086), (15, 0.031923390459269285), (38, 0.03208350110799074), (7, 0.03228544723242521), (39, 0.03233744157478213), (19, 0.0326285962946713), (51, 0.039947257842868567), (37, 0.040739682503044605), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300980737432837), (52, 0.06433630082756281), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.45053431764245033), (18, 0.5108213052153587), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.013541154330596328
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590336054564), (35, 0.016470607835799456), (28, 0.017728674924001098), (27, 0.01912704878486693), (43, 0.02004686719737947), (46, 0.02037699380889535), (41, 0.021723242942243814), (25, 0.021972602466121316), (23, 0.02237953501753509), (44, 0.023028337163850665), (48, 0.02377187623642385), (40, 0.023930813651531935), (45, 0.024178663035854697), (50, 0.024390299571678042), (21, 0.02492459863424301), (22, 0.025168768595904112), (42, 0.025188251165673137), (49, 0.02536152908578515), (24, 0.02589953737333417), (20, 0.026859007077291608), (47, 0.027363279601559043), (38, 0.031365619506686926), (15, 0.03192339139059186), (39, 0.03212768537923694), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03893592394888401), (37, 0.04020634386688471), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.05892290361225605), (11, 0.05924912914633751), (17, 0.06095684925094247), (52, 0.062328551430255175), (0, 0.0630098101682961), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4444201998412609), (18, 0.5108212977647781), (53, 0.853791207075119)]
computing accuracy for after removing block 26 . block score: 0.016037590336054564
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366145811975), (28, 0.017088500317186117), (27, 0.01888244692236185), (43, 0.019595165504142642), (46, 0.020073581021279097), (41, 0.020961584523320198), (25, 0.021972602466121316), (23, 0.022379535483196378), (44, 0.02281495602801442), (48, 0.02312816074118018), (40, 0.023345195688307285), (50, 0.023756146663799882), (42, 0.02384730288758874), (45, 0.02387388050556183), (21, 0.02492459793575108), (49, 0.024960315320640802), (22, 0.025168768130242825), (24, 0.025899537838995457), (47, 0.02685554255731404), (20, 0.026859007077291608), (38, 0.030424014665186405), (39, 0.031514043686911464), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.0378248798660934), (37, 0.03936835192143917), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.05722427647560835), (13, 0.058922901283949614), (11, 0.059249128215014935), (52, 0.060332820285111666), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4360685497522354), (18, 0.5108213052153587), (53, 0.8749377280473709)]
computing accuracy for after removing block 35 . block score: 0.015597366145811975
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 1 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 3 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.1]
training epoch 4 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.1]
training epoch 5 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 6 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 7 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 8 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 9 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.1]
training epoch 10 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555945483967662), (27, 0.018882447388023138), (46, 0.01916008535772562), (41, 0.019424294820055366), (48, 0.021467271959409118), (25, 0.02197260269895196), (44, 0.022026916965842247), (40, 0.022179660387337208), (42, 0.02220643009059131), (50, 0.022256129188463092), (23, 0.022379535250365734), (45, 0.022931481478735805), (49, 0.02370851207524538), (21, 0.024924597702920437), (22, 0.025168768130242825), (47, 0.025829139398410916), (24, 0.025899538304656744), (20, 0.026859006145969033), (38, 0.028956545516848564), (39, 0.029667828232049942), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.036009025294333696), (37, 0.03651238651946187), (9, 0.04340188205242157), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846704378724), (52, 0.0561072863638401), (3, 0.0572242783382535), (13, 0.05892290314659476), (11, 0.059249129611998796), (17, 0.06095684692263603), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034483902156353), (16, 0.08408282604068518), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.41757645457983017), (18, 0.5108212977647781), (53, 0.911714494228363)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102707609534), (41, 0.01884901849552989), (27, 0.01888244692236185), (48, 0.02090373425744474), (42, 0.021432003704831004), (40, 0.021832421654835343), (44, 0.021840531146153808), (50, 0.02186986361630261), (25, 0.02197260269895196), (23, 0.022379535948857665), (45, 0.022492847871035337), (49, 0.023123498307541013), (21, 0.024924597004428506), (47, 0.025067138019949198), (22, 0.02516876789741218), (24, 0.025899537140503526), (20, 0.02685900731012225), (38, 0.02811406902037561), (39, 0.02920690947212279), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.035454337019473314), (37, 0.03597763879224658), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368270859122), (14, 0.04783663293346763), (2, 0.05454846518114209), (52, 0.054696458391845226), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980877131224), (1, 0.06676734052598476), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049571871758), (5, 0.10667386837303638), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 0.9246632605791092)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018029868603), (27, 0.018882446456700563), (46, 0.019302030093967915), (42, 0.021432004403322935), (48, 0.021544843446463346), (40, 0.021832421654835343), (50, 0.02194626978598535), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.02300686971284449), (44, 0.02310851076617837), (45, 0.023535606916993856), (21, 0.024924598168581724), (22, 0.025168768130242825), (47, 0.02582044550217688), (24, 0.025899537140503526), (20, 0.02685900661163032), (38, 0.028114069253206253), (39, 0.02920690947212279), (15, 0.03192339325323701), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.035091488622128963), (37, 0.03597763879224658), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.05332902958616614), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.06095684785395861), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.0803448399528861), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4135979078710079), (18, 0.5108212977647781), (53, 0.9678284227848053)]
computing accuracy for after removing block 41 . block score: 0.018849018029868603
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446456700563), (46, 0.01907008863054216), (48, 0.0206781686283648), (50, 0.021344397449865937), (40, 0.021832421654835343), (25, 0.021972602931782603), (42, 0.02198694017715752), (23, 0.022379535483196378), (49, 0.02253474830649793), (45, 0.023929917253553867), (44, 0.024054003646597266), (21, 0.024924598401412368), (22, 0.025168768130242825), (24, 0.025899537838995457), (47, 0.02604393707588315), (20, 0.02685900661163032), (38, 0.02811406902037561), (39, 0.029206907842308283), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.047836634796112776), (52, 0.050476094242185354), (2, 0.05454846378415823), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.4135979264974594), (18, 0.5108212828636169), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882446456700563
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707740023732), (50, 0.02077506179921329), (40, 0.021085952641442418), (42, 0.0213696479331702), (49, 0.02191002992913127), (25, 0.02197260269895196), (23, 0.022379535948857665), (44, 0.023239311994984746), (45, 0.023585308576002717), (21, 0.024924598168581724), (47, 0.025076948571950197), (22, 0.02516876789741218), (24, 0.025899537606164813), (20, 0.026859006844460964), (38, 0.027183361118659377), (39, 0.028580758022144437), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03281426033936441), (37, 0.035420244093984365), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.048523631412535906), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980737432837), (1, 0.06676734145730734), (8, 0.07467832043766975), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.0384204983711243)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831161877140403), (40, 0.021085953805595636), (42, 0.021369647700339556), (25, 0.021972602931782603), (23, 0.022379535250365734), (49, 0.022536989767104387), (44, 0.02323931152932346), (45, 0.023585308343172073), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.026583049446344376), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580759186297655), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859722599387), (51, 0.0328508117236197), (37, 0.035420244093984365), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.04749368550255895), (14, 0.04783663572743535), (52, 0.04812479903921485), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667386930435896), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952874273062), (42, 0.021369647467508912), (25, 0.02197260269895196), (23, 0.022379535948857665), (50, 0.022470062598586082), (44, 0.023239311762154102), (45, 0.023585309041664004), (21, 0.024924597702920437), (22, 0.025168768828734756), (49, 0.02523410157300532), (24, 0.025899537606164813), (47, 0.02658304898068309), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075895346701), (15, 0.031923392321914434), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.03296921169385314), (37, 0.035420242697000504), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663293346763), (52, 0.05089045129716396), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.05892290361225605), (11, 0.05924912914633751), (17, 0.06095685111358762), (0, 0.06300980877131224), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.266390860080719)]
computing accuracy for after removing block 40 . block score: 0.021085952874273062
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868073567748), (50, 0.02128476556390524), (25, 0.021972602466121316), (23, 0.022379535948857665), (45, 0.023098317440599203), (44, 0.024240857688710093), (49, 0.024500868981704116), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537140503526), (47, 0.026519698556512594), (20, 0.026859007542952895), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339092493057), (51, 0.03222084930166602), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.043401881121098995), (6, 0.04660903010517359), (4, 0.04749368270859122), (14, 0.0478366338647902), (52, 0.04885757248848677), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912774935365), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734052598476), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4065233878791332), (18, 0.5108212977647781), (53, 1.371861606836319)]
computing accuracy for after removing block 42 . block score: 0.02096868073567748
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 1 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 2 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 3 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 4 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 5 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 6 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 7 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 8 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 10 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.966600)
finished training. finished 50 epochs. accuracy 0.9666 topk_dict {'top1': 0.9666}
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.042012. All blocks and scores: [(49, 0.04201170615851879), (50, 0.04271218040958047), (45, 0.04692277777940035), (44, 0.04890225920826197), (25, 0.049430519342422485), (22, 0.05314934207126498), (51, 0.05339022213593125), (7, 0.053777622524648905), (23, 0.05387843074277043), (24, 0.05422542383894324), (21, 0.05422696704044938), (47, 0.05455508967861533), (20, 0.05584676004946232), (38, 0.05814139870926738), (15, 0.05884224642068148), (19, 0.059425100684165955), (52, 0.06010669656097889), (39, 0.06328893126919866), (37, 0.0699869291856885), (4, 0.07423232588917017), (9, 0.07856871839612722), (6, 0.08727952651679516), (2, 0.09208748862147331), (14, 0.09339263942092657), (3, 0.09663757495582104), (17, 0.09678375162184238), (0, 0.10132425464689732), (11, 0.10133958235383034), (13, 0.10624886583536863), (1, 0.11116701830178499), (8, 0.12321211397647858), (12, 0.14313358813524246), (10, 0.15156663581728935), (16, 0.1555308774113655), (5, 0.19048324972391129), (36, 0.6422687917947769), (18, 0.7227042391896248), (53, 0.9866589158773422)]
computing accuracy for after removing block 49 . block score: 0.04201170615851879
removed block 49 current accuracy 0.9564 loss from initial  0.04359999999999997
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.044009. All blocks and scores: [(50, 0.04400947131216526), (45, 0.04692277731373906), (44, 0.04890225874260068), (25, 0.0494305188767612), (22, 0.053149341605603695), (7, 0.05377762345597148), (23, 0.053878432139754295), (24, 0.05422542477026582), (21, 0.05422696517780423), (47, 0.05455509154126048), (20, 0.055846759118139744), (51, 0.05652471538633108), (38, 0.058141397312283516), (15, 0.05884224735200405), (19, 0.05942509928718209), (39, 0.06328893126919866), (52, 0.06398465111851692), (37, 0.06998693197965622), (4, 0.07423232775181532), (9, 0.07856872025877237), (6, 0.08727952744811773), (2, 0.09208749048411846), (14, 0.09339263569563627), (3, 0.09663757774978876), (17, 0.09678375441581011), (0, 0.10132425371557474), (11, 0.10133958142250776), (13, 0.10624886583536863), (1, 0.11116701830178499), (8, 0.12321211211383343), (12, 0.1431335862725973), (10, 0.15156663209199905), (16, 0.1555308774113655), (5, 0.19048324972391129), (36, 0.6422687992453575), (18, 0.7227042391896248), (53, 1.0872347503900528)]
computing accuracy for after removing block 50 . block score: 0.04400947131216526
removed block 50 current accuracy 0.9456 loss from initial  0.054400000000000004
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.046923. All blocks and scores: [(45, 0.04692277638241649), (44, 0.04890225920826197), (25, 0.049430517479777336), (22, 0.05314934067428112), (7, 0.05377762299031019), (23, 0.05387843167409301), (24, 0.05422542383894324), (21, 0.054226966574788094), (47, 0.05455509200692177), (20, 0.055846757255494595), (38, 0.05814139638096094), (15, 0.05884224642068148), (19, 0.05942510161548853), (51, 0.060846499633044004), (39, 0.06328893266618252), (37, 0.06998693011701107), (4, 0.07423232682049274), (52, 0.07743938732892275), (9, 0.07856872025877237), (6, 0.08727952837944031), (2, 0.09208748862147331), (14, 0.09339264128357172), (3, 0.09663757774978876), (17, 0.09678375348448753), (0, 0.10132425650954247), (11, 0.10133958607912064), (13, 0.10624886769801378), (1, 0.11116702109575272), (8, 0.12321211397647858), (12, 0.1431335862725973), (10, 0.1515666265040636), (16, 0.15553087554872036), (5, 0.19048324786126614), (36, 0.6422687917947769), (18, 0.7227042242884636), (53, 1.3136747032403946)]
computing accuracy for after removing block 45 . block score: 0.04692277638241649
removed block 45 current accuracy 0.9352 loss from initial  0.06479999999999997
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.048902. All blocks and scores: [(44, 0.04890225827693939), (25, 0.0494305188767612), (22, 0.05314934113994241), (7, 0.053777622524648905), (23, 0.05387843260541558), (24, 0.05422542430460453), (21, 0.054226964712142944), (20, 0.055846760515123606), (38, 0.058141397312283516), (15, 0.05884224781766534), (47, 0.05927548976615071), (19, 0.05942509975284338), (51, 0.05973763205111027), (39, 0.06328893173485994), (37, 0.06998693104833364), (4, 0.07423233054578304), (52, 0.07797038741409779), (9, 0.07856871653348207), (6, 0.08727952651679516), (2, 0.09208748955279589), (14, 0.09339263569563627), (3, 0.09663757961243391), (17, 0.09678375441581011), (0, 0.10132425744086504), (11, 0.10133958514779806), (13, 0.10624886769801378), (1, 0.11116702109575272), (8, 0.12321211583912373), (12, 0.14313358813524246), (10, 0.1515666339546442), (16, 0.15553087927401066), (5, 0.19048324413597584), (36, 0.6422687992453575), (18, 0.722704254090786), (53, 1.4126952290534973)]
computing accuracy for after removing block 44 . block score: 0.04890225827693939
removed block 44 current accuracy 0.914 loss from initial  0.08599999999999997
since last training loss: 0.05259999999999998 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 25, with score 0.049431. All blocks and scores: [(25, 0.049430517479777336), (22, 0.05314934113994241), (7, 0.05377762392163277), (23, 0.05387843260541558), (24, 0.054225423373281956), (21, 0.05422696424648166), (20, 0.055846759118139744), (51, 0.05743816401809454), (38, 0.05814139870926738), (15, 0.05884224735200405), (19, 0.059425100684165955), (39, 0.06328893406316638), (47, 0.06477764900773764), (37, 0.06998693011701107), (4, 0.07423232682049274), (52, 0.07726351730525494), (9, 0.07856871653348207), (6, 0.08727952465415001), (2, 0.09208749234676361), (14, 0.09339263569563627), (3, 0.09663757868111134), (17, 0.09678375162184238), (0, 0.10132425278425217), (11, 0.10133958514779806), (13, 0.10624886769801378), (1, 0.11116701643913984), (8, 0.12321211490780115), (12, 0.1431335899978876), (10, 0.15156663581728935), (16, 0.1555308774113655), (5, 0.190483245998621), (36, 0.6422687992453575), (18, 0.7227042466402054), (53, 1.5384286493062973)]
computing accuracy for after removing block 25 . block score: 0.049430517479777336
removed block 25 current accuracy 0.9076 loss from initial  0.09240000000000004
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.053149. All blocks and scores: [(22, 0.053149341605603695), (7, 0.053777622524648905), (23, 0.05387843260541558), (24, 0.054225421976298094), (21, 0.054226966574788094), (20, 0.055846760515123606), (51, 0.05704421317204833), (38, 0.05828808480873704), (15, 0.05884224455803633), (19, 0.05942509975284338), (47, 0.06288268882781267), (39, 0.06518637854605913), (4, 0.07423232775181532), (37, 0.07483897171914577), (52, 0.0771416462957859), (9, 0.07856871839612722), (6, 0.08727952558547258), (2, 0.09208748396486044), (14, 0.0933926422148943), (3, 0.09663757588714361), (17, 0.09678375348448753), (0, 0.10132425464689732), (11, 0.10133958328515291), (13, 0.10624886583536863), (1, 0.11116701550781727), (8, 0.123212113045156), (12, 0.14313358813524246), (10, 0.15156663209199905), (16, 0.15553087927401066), (5, 0.1904832422733307), (36, 0.6648543328046799), (18, 0.7227042317390442), (53, 1.5068484246730804)]
computing accuracy for after removing block 22 . block score: 0.053149341605603695
removed block 22 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.07200000000000006 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.050397. All blocks and scores: [(23, 0.05039690528064966), (24, 0.05054325331002474), (7, 0.05377762112766504), (21, 0.05422696517780423), (51, 0.054467327892780304), (20, 0.05584675772115588), (38, 0.05724339792504907), (15, 0.058842245023697615), (47, 0.058963242918252945), (19, 0.05942509975284338), (39, 0.06389105599373579), (52, 0.07165188621729612), (4, 0.0742323249578476), (37, 0.07454640697687864), (9, 0.0785687193274498), (6, 0.08727952744811773), (2, 0.09208749048411846), (14, 0.093392638489604), (3, 0.09663757774978876), (17, 0.09678375348448753), (0, 0.10132425837218761), (11, 0.10133958514779806), (13, 0.10624886583536863), (1, 0.11116702016443014), (8, 0.12321211863309145), (12, 0.1431335862725973), (10, 0.1515666339546442), (16, 0.15553087554872036), (5, 0.19048324413597584), (36, 0.6468732208013535), (18, 0.7227042242884636), (53, 1.4708075523376465)]
computing accuracy for after removing block 23 . block score: 0.05039690528064966
removed block 23 current accuracy 0.8712 loss from initial  0.12880000000000003
since last training loss: 0.09540000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.048095. All blocks and scores: [(24, 0.04809482768177986), (7, 0.05377762299031019), (21, 0.05422696843743324), (51, 0.05434536887332797), (20, 0.05584675958380103), (47, 0.05679377447813749), (38, 0.0568144335411489), (15, 0.0588422454893589), (19, 0.05942510114982724), (39, 0.06506835762411356), (52, 0.07148963119834661), (4, 0.07423232775181532), (9, 0.07856871653348207), (37, 0.07994658593088388), (6, 0.08727952744811773), (2, 0.09208748675882816), (14, 0.09339264128357172), (3, 0.09663757774978876), (17, 0.09678375348448753), (0, 0.10132425371557474), (11, 0.10133958514779806), (13, 0.10624886490404606), (1, 0.11116701643913984), (8, 0.12321211770176888), (12, 0.14313358813524246), (10, 0.15156663581728935), (16, 0.1555308774113655), (5, 0.19048324413597584), (36, 0.6700399145483971), (18, 0.7227042391896248), (53, 1.4411889761686325)]
computing accuracy for after removing block 24 . block score: 0.04809482768177986
removed block 24 current accuracy 0.8336 loss from initial  0.1664
training start
training epoch 0 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 1 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.1]
training epoch 2 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 3 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 6 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 7 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 8 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.1]
training epoch 9 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.953400)
finished training. finished 50 epochs. accuracy 0.9534 topk_dict {'top1': 0.9534}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.064654. All blocks and scores: [(7, 0.06465362198650837), (19, 0.07004330959171057), (15, 0.07170030195266008), (52, 0.07573062181472778), (38, 0.07573609799146652), (20, 0.07580276858061552), (51, 0.07688554003834724), (39, 0.08049214538186789), (47, 0.08203199319541454), (37, 0.0830700471997261), (6, 0.09706785809248686), (21, 0.09813398402184248), (4, 0.10013740975409746), (2, 0.10156649723649025), (14, 0.10614457633346319), (0, 0.11050443910062313), (9, 0.11466190591454506), (11, 0.12162803392857313), (3, 0.12186519149690866), (13, 0.12359825801104307), (17, 0.13035227917134762), (8, 0.13349446468055248), (1, 0.13500050641596317), (16, 0.17226090468466282), (12, 0.1734950989484787), (10, 0.18559989891946316), (5, 0.20055794715881348), (36, 0.6049442812800407), (18, 0.655040942132473), (53, 1.0609564632177353)]
computing accuracy for after removing block 7 . block score: 0.06465362198650837
removed block 7 current accuracy 0.9478 loss from initial  0.052200000000000024
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 19, with score 0.067599. All blocks and scores: [(19, 0.06759851519018412), (15, 0.070050910115242), (20, 0.07282774336636066), (52, 0.0728504965081811), (51, 0.07446311693638563), (38, 0.0760995065793395), (37, 0.07719909679144621), (39, 0.0783787053078413), (47, 0.08078179322183132), (21, 0.09438211563974619), (6, 0.09706785995513201), (14, 0.09983561560511589), (4, 0.10013740602880716), (2, 0.10156649630516768), (13, 0.1074843741953373), (9, 0.11003962997347116), (0, 0.1105044400319457), (11, 0.112569491378963), (17, 0.1137772724032402), (3, 0.12186519056558609), (8, 0.13445995934307575), (1, 0.13500050641596317), (12, 0.15618556179106236), (16, 0.1589660346508026), (10, 0.1829230599105358), (5, 0.20055794902145863), (36, 0.5822471007704735), (18, 0.626885324716568), (53, 1.0750334709882736)]
computing accuracy for after removing block 19 . block score: 0.06759851519018412
removed block 19 current accuracy 0.9406 loss from initial  0.05940000000000001
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.066678. All blocks and scores: [(20, 0.0666784755885601), (52, 0.06782654393464327), (15, 0.07005090825259686), (51, 0.07274000439792871), (38, 0.07285770028829575), (47, 0.07619240321218967), (37, 0.07770012225955725), (39, 0.07821108866482973), (21, 0.0878178896382451), (6, 0.09706786461174488), (14, 0.09983561560511589), (4, 0.10013740602880716), (2, 0.10156649630516768), (13, 0.10748437233269215), (9, 0.11003962717950344), (0, 0.11050443258136511), (11, 0.11256949044764042), (17, 0.11377727054059505), (3, 0.12186519335955381), (8, 0.13445995561778545), (1, 0.13500050641596317), (12, 0.1561855636537075), (16, 0.15896603278815746), (10, 0.18292305618524551), (5, 0.20055794529616833), (36, 0.5648607462644577), (18, 0.6268853321671486), (53, 1.0672404915094376)]
computing accuracy for after removing block 20 . block score: 0.0666784755885601
removed block 20 current accuracy 0.9222 loss from initial  0.07779999999999998
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.065339. All blocks and scores: [(52, 0.065338802523911), (15, 0.070050910115242), (51, 0.0713548082858324), (47, 0.07285099942237139), (38, 0.07299374137073755), (39, 0.08266131207346916), (37, 0.08753101341426373), (21, 0.08885299880057573), (6, 0.09706785809248686), (14, 0.09983561560511589), (4, 0.10013740789145231), (2, 0.10156649351119995), (13, 0.1074843741953373), (9, 0.11003962438553572), (0, 0.11050444096326828), (11, 0.11256949324160814), (17, 0.11377727519720793), (3, 0.12186518963426352), (8, 0.13445995561778545), (1, 0.13500050455331802), (12, 0.1561855673789978), (16, 0.15896603651344776), (10, 0.1829230599105358), (5, 0.20055794343352318), (36, 0.5942810773849487), (18, 0.6268853321671486), (53, 1.0319319665431976)]
computing accuracy for after removing block 52 . block score: 0.065338802523911
removed block 52 current accuracy 0.8832 loss from initial  0.11680000000000001
since last training loss: 0.07020000000000004 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 15, with score 0.070051. All blocks and scores: [(15, 0.07005091104656458), (51, 0.07135481107980013), (47, 0.07285099942237139), (38, 0.07299374230206013), (39, 0.08266131393611431), (37, 0.08753101527690887), (21, 0.08885299693793058), (6, 0.0970678636804223), (14, 0.09983561560511589), (4, 0.10013740602880716), (2, 0.10156649444252253), (13, 0.10748437326401472), (9, 0.11003962997347116), (0, 0.11050443444401026), (11, 0.11256949044764042), (17, 0.11377727054059505), (3, 0.12186519615352154), (8, 0.13445995934307575), (1, 0.13500050455331802), (12, 0.15618556551635265), (16, 0.15896603651344776), (10, 0.1829230599105358), (5, 0.20055793970823288), (36, 0.5942810773849487), (18, 0.6268853470683098), (53, 1.1573105603456497)]
computing accuracy for after removing block 15 . block score: 0.07005091104656458
removed block 15 current accuracy 0.8604 loss from initial  0.13959999999999995
since last training loss: 0.09299999999999997 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.070227. All blocks and scores: [(38, 0.07022678665816784), (47, 0.07058558240532875), (51, 0.0712744239717722), (39, 0.08095064107328653), (21, 0.08261267933994532), (37, 0.08417127374559641), (6, 0.09706786461174488), (14, 0.09983561281114817), (4, 0.10013740789145231), (2, 0.10156649257987738), (13, 0.10748436860740185), (9, 0.11003962904214859), (0, 0.11050443444401026), (11, 0.11256949044764042), (17, 0.11849873419851065), (3, 0.12186519335955381), (8, 0.13445995934307575), (1, 0.13500050641596317), (12, 0.15618556551635265), (16, 0.17570798099040985), (10, 0.18292305804789066), (5, 0.20055794529616833), (36, 0.5745082497596741), (18, 0.6074430122971535), (53, 1.1429692506790161)]
computing accuracy for after removing block 38 . block score: 0.07022678665816784
removed block 38 current accuracy 0.817 loss from initial  0.18300000000000005
since last training loss: 0.13640000000000008 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.068998. All blocks and scores: [(47, 0.06899829395115376), (51, 0.07054991368204355), (21, 0.08261268027126789), (37, 0.08417127374559641), (39, 0.09699447639286518), (6, 0.09706785995513201), (14, 0.09983561560511589), (4, 0.10013740975409746), (2, 0.1015664953738451), (13, 0.10748437605798244), (9, 0.11003962531685829), (0, 0.11050443816930056), (11, 0.1125694876536727), (17, 0.11849873326718807), (3, 0.12186519056558609), (8, 0.1344599537551403), (1, 0.13500050269067287), (12, 0.15618556551635265), (16, 0.17570797353982925), (10, 0.18292305618524551), (5, 0.20055795088410378), (36, 0.5745082497596741), (18, 0.6074430122971535), (53, 1.1686693131923676)]
computing accuracy for after removing block 47 . block score: 0.06899829395115376
removed block 47 current accuracy 0.7586 loss from initial  0.24139999999999995
since last training loss: 0.19479999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.073988. All blocks and scores: [(51, 0.07398768421262503), (21, 0.08261267747730017), (37, 0.08417127188295126), (39, 0.0969944791868329), (6, 0.09706786088645458), (14, 0.09983561560511589), (4, 0.10013740975409746), (2, 0.10156649351119995), (13, 0.10748437326401472), (9, 0.11003962345421314), (0, 0.11050443537533283), (11, 0.11256949231028557), (17, 0.11849873419851065), (3, 0.12186519242823124), (8, 0.13445995189249516), (1, 0.13500050269067287), (12, 0.15618556179106236), (16, 0.1757079791277647), (10, 0.18292305432260036), (5, 0.20055794902145863), (36, 0.5745082423090935), (18, 0.6074429824948311), (53, 1.3705939650535583)]
computing accuracy for after removing block 51 . block score: 0.07398768421262503
removed block 51 current accuracy 0.6584 loss from initial  0.3416
since last training loss: 0.29500000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 21, with score 0.082613. All blocks and scores: [(21, 0.08261267840862274), (37, 0.08417127281427383), (39, 0.09699447732418776), (6, 0.09706786088645458), (14, 0.09983561281114817), (4, 0.10013740975409746), (2, 0.1015664953738451), (13, 0.10748437233269215), (9, 0.11003962717950344), (0, 0.11050443444401026), (11, 0.11256948951631784), (17, 0.1184987323358655), (3, 0.12186519242823124), (8, 0.13445995934307575), (1, 0.13500050455331802), (12, 0.15618556179106236), (16, 0.1757079791277647), (10, 0.18292305804789066), (5, 0.20055793970823288), (36, 0.5745082423090935), (18, 0.6074429973959923), (53, 1.5081413835287094)]
computing accuracy for after removing block 21 . block score: 0.08261267840862274
removed block 21 current accuracy 0.6 loss from initial  0.4
training start
training epoch 0 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best True lr [0.1]
training epoch 1 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 2 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 3 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best True lr [0.1]
training epoch 4 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 5 val accuracy 0.861 topk_dict {'top1': 0.861} is_best True lr [0.1]
training epoch 6 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.1]
training epoch 7 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 8 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best True lr [0.1]
training epoch 9 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 10 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.928800)
finished training. finished 50 epochs. accuracy 0.9288 topk_dict {'top1': 0.9288}
