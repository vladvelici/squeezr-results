start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975077856332), (20, 0.008696247707121074), (27, 0.009198295301757753), (31, 0.009675503824837506), (29, 0.01003042096272111), (22, 0.010588386678136885), (23, 0.010651617660187185), (21, 0.01072535093408078), (28, 0.011828799499198794), (24, 0.012058728374540806), (17, 0.012199450517073274), (19, 0.013177948421798646), (33, 0.013279786915518343), (35, 0.013483816292136908), (25, 0.013839342282153666), (11, 0.013912908965721726), (32, 0.013956584851257503), (16, 0.014766237465664744), (30, 0.015491605387069285), (9, 0.015547690447419882), (40, 0.0159863349981606), (34, 0.01665632240474224), (39, 0.017517176223918796), (44, 0.018641566392034292), (37, 0.01879900391213596), (43, 0.0189350345171988), (42, 0.019514338579028845), (41, 0.019590020878240466), (45, 0.019901464926078916), (38, 0.020000957883894444), (14, 0.020047535188496113), (8, 0.021667920984327793), (7, 0.02180621027946472), (15, 0.02483329689130187), (46, 0.025212791981175542), (10, 0.02590036136098206), (49, 0.027116776211187243), (48, 0.027511440450325608), (47, 0.027820878196507692), (50, 0.02872324618510902), (51, 0.031788797583431005), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968294009566), (4, 0.03804349387064576), (3, 0.043747182469815016), (52, 0.052534045185893774), (13, 0.05450336076319218), (2, 0.06120603485032916), (1, 0.07061250694096088), (0, 0.14636892452836037), (36, 0.2727429270744324), (18, 0.30386047437787056), (53, 0.8891633227467537)]
computing accuracy for after removing block 26 . block score: 0.007451975077856332
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.008696247939951718), (27, 0.009569327463395894), (31, 0.009736894513480365), (29, 0.010370098170824349), (22, 0.010588386561721563), (23, 0.010651617660187185), (21, 0.010725351050496101), (24, 0.01205872802529484), (28, 0.01206758536864072), (17, 0.012199450749903917), (19, 0.013177948771044612), (33, 0.013200338813476264), (35, 0.013297738507390022), (32, 0.01354012603405863), (25, 0.013839342165738344), (11, 0.01391290919855237), (16, 0.014766237698495388), (30, 0.015476006898097694), (9, 0.01554769033100456), (34, 0.016335653606802225), (40, 0.016489707864820957), (39, 0.018151729367673397), (44, 0.018809265922755003), (43, 0.01927204616367817), (37, 0.019370622467249632), (41, 0.019797630375251174), (42, 0.019846386974677444), (14, 0.020047535188496113), (38, 0.02020833152346313), (45, 0.02028216957114637), (8, 0.021667920285835862), (7, 0.02180621027946472), (15, 0.024833297124132514), (46, 0.025710680754855275), (10, 0.025900361826643348), (49, 0.027175756637006998), (48, 0.027807613601908088), (47, 0.02826968301087618), (50, 0.02872340427711606), (51, 0.031959859654307365), (12, 0.03298327000811696), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.03804349433630705), (3, 0.043747182469815016), (52, 0.052661973517388105), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.2777215614914894), (18, 0.30386046692728996), (53, 0.8825649693608284)]
computing accuracy for after removing block 20 . block score: 0.008696247939951718
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.00924707145895809), (31, 0.0094903550343588), (29, 0.010141469538211823), (23, 0.010720769176259637), (21, 0.010873694904148579), (22, 0.010951439617201686), (28, 0.011602518148720264), (17, 0.01219945086631924), (24, 0.012428545043803751), (33, 0.013006685767322779), (32, 0.013030687463469803), (35, 0.013141493080183864), (19, 0.01317794865462929), (11, 0.013912909082137048), (25, 0.014337054803036153), (30, 0.014731099247001112), (16, 0.014766238164156675), (9, 0.015547689981758595), (34, 0.015950741479173303), (40, 0.016676967032253742), (39, 0.018123318441212177), (44, 0.019042733358219266), (43, 0.019525704439729452), (37, 0.019535947125405073), (41, 0.02002391265705228), (42, 0.020024611381813884), (14, 0.020047535421326756), (38, 0.02022995171137154), (45, 0.020495346747338772), (8, 0.021667920518666506), (7, 0.02180621144361794), (15, 0.024833297124132514), (10, 0.02590036136098206), (46, 0.026008821558207273), (49, 0.027358208317309618), (48, 0.02794406423345208), (47, 0.028558713849633932), (50, 0.028874032432213426), (51, 0.03197578387334943), (12, 0.03298327047377825), (5, 0.03333624452352524), (6, 0.03351968340575695), (4, 0.0380434924736619), (3, 0.043747184332460165), (52, 0.053193128667771816), (13, 0.054503361228853464), (2, 0.06120603485032916), (1, 0.07061250694096088), (0, 0.14636891894042492), (36, 0.27894823253154755), (18, 0.30386047437787056), (53, 0.8746765181422234)]
computing accuracy for after removing block 27 . block score: 0.00924707145895809
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703439543955028), (29, 0.010401993873529136), (23, 0.01072076940909028), (21, 0.010873694904148579), (22, 0.01095143985003233), (28, 0.011904270271770656), (17, 0.012199450749903917), (24, 0.012428545043803751), (33, 0.012989282375201583), (35, 0.01303201261907816), (32, 0.013032321585342288), (19, 0.013177948771044612), (11, 0.013912908732891083), (25, 0.014337054453790188), (30, 0.014530949760228395), (16, 0.014766237582080066), (34, 0.015523915993981063), (9, 0.015547689981758595), (40, 0.01742828404530883), (39, 0.01863569999113679), (44, 0.019323375774547458), (43, 0.019895021338015795), (14, 0.020047535886988044), (37, 0.020162817556411028), (38, 0.020197830395773053), (42, 0.020295765018090606), (41, 0.02033131755888462), (45, 0.02073849504813552), (8, 0.021667920518666506), (7, 0.02180621074512601), (15, 0.024833296658471227), (10, 0.02590036066249013), (46, 0.026298311538994312), (49, 0.027372207259759307), (48, 0.028113746317103505), (47, 0.028824042761698365), (50, 0.029082486405968666), (51, 0.03204397205263376), (12, 0.032983269076794386), (5, 0.03333624405786395), (6, 0.033519684337079525), (4, 0.0380434924736619), (3, 0.04374718386679888), (52, 0.05334703531116247), (13, 0.05450336029753089), (2, 0.0612060371786356), (1, 0.07061250787228346), (0, 0.14636891894042492), (36, 0.2865508385002613), (18, 0.30386047065258026), (53, 0.873922660946846)]
computing accuracy for after removing block 31 . block score: 0.009703439543955028
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401993873529136), (23, 0.01072076940909028), (21, 0.010873694904148579), (22, 0.010951440082862973), (28, 0.011904270038940012), (17, 0.01219945086631924), (24, 0.012428545393049717), (33, 0.013075273134745657), (19, 0.01317794865462929), (32, 0.013221941306255758), (35, 0.013311224640347064), (11, 0.01391290919855237), (25, 0.014337054686620831), (30, 0.014530948945321143), (16, 0.014766237698495388), (34, 0.015109014348126948), (9, 0.015547689981758595), (40, 0.01796384761109948), (44, 0.01917275949381292), (39, 0.019229266792535782), (38, 0.019627249101176858), (43, 0.019773422740399837), (42, 0.02001498988829553), (14, 0.020047535886988044), (41, 0.020369441946968436), (45, 0.02045823959633708), (37, 0.02053516125306487), (8, 0.021667920285835862), (7, 0.021806210512295365), (15, 0.02483329689130187), (10, 0.025900361593812704), (46, 0.02643988886848092), (49, 0.027319708140566945), (48, 0.02830672194249928), (47, 0.02865198371000588), (50, 0.029288704274222255), (51, 0.03214396582916379), (12, 0.03298327140510082), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718340113759), (52, 0.05252913711592555), (13, 0.05450336216017604), (2, 0.061206035781651735), (1, 0.07061250507831573), (0, 0.14636892080307007), (36, 0.29571831598877907), (18, 0.30386047437787056), (53, 0.8852703720331192)]
computing accuracy for after removing block 29 . block score: 0.010401993873529136
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.010720769176259637), (21, 0.010873694671317935), (22, 0.01095143985003233), (28, 0.01190426992252469), (17, 0.012199450517073274), (24, 0.012428545276634395), (33, 0.013095533940941095), (19, 0.013177948887459934), (32, 0.013331791036762297), (35, 0.01334268192294985), (11, 0.013912908732891083), (25, 0.01433705526869744), (16, 0.01476623781491071), (34, 0.014780625817365944), (30, 0.014848081162199378), (9, 0.015547690214589238), (40, 0.017947440268471837), (44, 0.01857014838606119), (38, 0.018818872049450874), (39, 0.019284184090793133), (42, 0.01955016702413559), (43, 0.019667528802528977), (41, 0.020019967574626207), (14, 0.0200475356541574), (45, 0.020145077956840396), (37, 0.020778114441782236), (8, 0.021667920984327793), (7, 0.02180621027946472), (15, 0.024833296658471227), (10, 0.025900361128151417), (46, 0.026351965963840485), (49, 0.026999606983736157), (48, 0.027823995798826218), (47, 0.028508093673735857), (50, 0.029334592865779996), (51, 0.032171768601983786), (12, 0.03298327047377825), (5, 0.033336243126541376), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.043747182469815016), (52, 0.0519054657779634), (13, 0.05450335796922445), (2, 0.06120603671297431), (1, 0.07061250600963831), (0, 0.14636892452836037), (36, 0.2995104193687439), (18, 0.30386047437787056), (53, 0.8962140008807182)]
computing accuracy for after removing block 23 . block score: 0.010720769176259637
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.010873695136979222), (22, 0.010951439966447651), (28, 0.01145462435670197), (24, 0.011984123033471406), (17, 0.012199450517073274), (35, 0.013001650921069086), (32, 0.013018106226809323), (33, 0.013115601381286979), (19, 0.013177948887459934), (25, 0.013824696186929941), (11, 0.013912908732891083), (30, 0.014240248245187104), (34, 0.014703377266414464), (16, 0.014766237698495388), (9, 0.015547690098173916), (40, 0.018065203679725528), (44, 0.018300466472283006), (38, 0.01860098447650671), (42, 0.019345170818269253), (43, 0.019551129080355167), (39, 0.019822366070002317), (45, 0.019911037757992744), (41, 0.020028739469125867), (14, 0.0200475356541574), (37, 0.02084772032685578), (8, 0.021667920285835862), (7, 0.021806210046634078), (15, 0.02483329619280994), (10, 0.025900362292304635), (46, 0.026478099869564176), (49, 0.026978092966601253), (48, 0.027518167393282056), (47, 0.02853023912757635), (50, 0.029085059417411685), (51, 0.03238660376518965), (12, 0.03298326954245567), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718386679888), (52, 0.05187077634036541), (13, 0.0545033598318696), (2, 0.06120603624731302), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.3020646683871746), (18, 0.30386048182845116), (53, 0.893830269575119)]
computing accuracy for after removing block 21 . block score: 0.010873695136979222
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718231205828488), (22, 0.01112441555596888), (24, 0.011734541621990502), (17, 0.012199450517073274), (32, 0.01233904401306063), (35, 0.012350355158559978), (33, 0.012773355934768915), (19, 0.013177948538213968), (30, 0.013385720318183303), (25, 0.013581673498265445), (11, 0.01391290919855237), (34, 0.014493828755803406), (16, 0.014766237582080066), (9, 0.015547690563835204), (40, 0.01817885460332036), (44, 0.018340062582865357), (38, 0.018629685742780566), (42, 0.019575109938159585), (43, 0.0197298398707062), (39, 0.019833360332995653), (14, 0.020047535188496113), (45, 0.020094188395887613), (41, 0.02073429198935628), (37, 0.020795797929167747), (8, 0.021667920285835862), (7, 0.021806210046634078), (15, 0.024833297356963158), (10, 0.025900361128151417), (46, 0.027196240611374378), (49, 0.0272921328432858), (48, 0.027600203407928348), (47, 0.028906626626849174), (50, 0.029168642358854413), (51, 0.0327908075414598), (12, 0.03298327140510082), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.05234553525224328), (13, 0.05450335843488574), (2, 0.06120603438466787), (1, 0.07061250694096088), (0, 0.14636892080307007), (18, 0.30386047437787056), (36, 0.3042290173470974), (53, 0.896795280277729)]
computing accuracy for after removing block 28 . block score: 0.010718231205828488
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
training start
training epoch 0 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 1 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 2 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 3 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 4 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 5 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 6 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 7 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.1]
training epoch 8 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 9 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 10 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.990000)
finished training. finished 50 epochs. accuracy 0.99 topk_dict {'top1': 0.99}
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011124. All blocks and scores: [(22, 0.011124415090307593), (24, 0.011734541738405824), (32, 0.012095691403374076), (35, 0.012157875928096473), (17, 0.012199451099149883), (33, 0.013105916790664196), (19, 0.013177948887459934), (30, 0.01332365081179887), (25, 0.013581673731096089), (11, 0.013912909082137048), (34, 0.014369336306117475), (16, 0.014766237698495388), (9, 0.015547690447419882), (38, 0.01792138093151152), (44, 0.01819704077206552), (40, 0.018912273924797773), (42, 0.01936492556706071), (43, 0.019978848984465003), (14, 0.020047535421326756), (45, 0.020337820751592517), (39, 0.02059708791784942), (41, 0.020729141542688012), (37, 0.02132129459641874), (8, 0.021667920984327793), (7, 0.021806210512295365), (15, 0.024833296658471227), (10, 0.025900361593812704), (49, 0.027097659185528755), (48, 0.02719514723867178), (46, 0.02748569822870195), (47, 0.02907437109388411), (50, 0.029169490095227957), (12, 0.03298326954245567), (51, 0.033133427146822214), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.051573602482676506), (13, 0.054503359366208315), (2, 0.06120603857561946), (1, 0.07061250787228346), (0, 0.14636892080307007), (18, 0.30386047437787056), (36, 0.31568818166852), (53, 0.9053315073251724)]
computing accuracy for after removing block 22 . block score: 0.011124415090307593
removed block 22 current accuracy 0.9804 loss from initial  0.01959999999999995
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.010824. All blocks and scores: [(24, 0.010824102559126914), (32, 0.011274677235633135), (35, 0.012037030654028058), (17, 0.012199451099149883), (30, 0.012747167842462659), (33, 0.013064955594018102), (25, 0.01317650976125151), (19, 0.01317794865462929), (11, 0.01391290919855237), (34, 0.01427151181269437), (16, 0.014766237582080066), (9, 0.015547690214589238), (38, 0.017574149882420897), (44, 0.017618532292544842), (42, 0.018865567864850163), (40, 0.018951469101011753), (43, 0.01948712021112442), (45, 0.019938054960221052), (14, 0.020047535886988044), (39, 0.020676982356235385), (41, 0.02079974301159382), (37, 0.02091888920404017), (8, 0.021667920518666506), (7, 0.021806210977956653), (15, 0.024833296658471227), (10, 0.025900360895320773), (49, 0.026988671626895666), (48, 0.02712715440429747), (46, 0.02736985543742776), (50, 0.02874125842936337), (47, 0.029024813324213028), (12, 0.03298326954245567), (51, 0.03313175914809108), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.0380434924736619), (3, 0.04374718386679888), (52, 0.05089538171887398), (13, 0.05450336029753089), (2, 0.06120603624731302), (1, 0.07061250694096088), (0, 0.14636892452836037), (18, 0.30386047810316086), (36, 0.3163903057575226), (53, 0.9149599820375443)]
computing accuracy for after removing block 24 . block score: 0.010824102559126914
removed block 24 current accuracy 0.9664 loss from initial  0.03359999999999996
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.010877. All blocks and scores: [(32, 0.010876586777158082), (35, 0.011955110123381019), (30, 0.012104445369914174), (17, 0.01219945028424263), (25, 0.013075435883365571), (19, 0.013177948421798646), (33, 0.01325787918176502), (11, 0.013912908732891083), (34, 0.01444917032495141), (16, 0.014766237582080066), (9, 0.015547690447419882), (38, 0.01698773936368525), (44, 0.017669430235400796), (42, 0.01874342025257647), (40, 0.019168380880728364), (43, 0.019857255974784493), (45, 0.019892358453944325), (14, 0.0200475356541574), (41, 0.020732014440000057), (37, 0.021041916450485587), (39, 0.021407435415312648), (8, 0.021667921217158437), (7, 0.021806210512295365), (15, 0.024833296658471227), (10, 0.025900361826643348), (49, 0.026679034810513258), (48, 0.026844705920666456), (46, 0.027388096787035465), (50, 0.02831620047800243), (47, 0.028733997605741024), (51, 0.03292590379714966), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.043747184332460165), (52, 0.04968237690627575), (13, 0.0545033598318696), (2, 0.061206035781651735), (1, 0.07061250787228346), (0, 0.14636892452836037), (18, 0.30386047437787056), (36, 0.3254365213215351), (53, 0.9151448756456375)]
computing accuracy for after removing block 32 . block score: 0.010876586777158082
removed block 32 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.012104. All blocks and scores: [(30, 0.012104445835575461), (17, 0.012199450633488595), (35, 0.012797020259313285), (25, 0.013075435534119606), (19, 0.013177948538213968), (33, 0.013797620427794755), (11, 0.01391290919855237), (34, 0.014519993215799332), (16, 0.014766237582080066), (9, 0.015547690214589238), (38, 0.016240306897088885), (44, 0.017033956479281187), (42, 0.01825910108163953), (40, 0.01946928328834474), (45, 0.01950681279413402), (43, 0.019664271036162972), (14, 0.020047535421326756), (41, 0.020211151335388422), (37, 0.020982666173949838), (39, 0.021373851457610726), (8, 0.021667920518666506), (7, 0.021806210977956653), (15, 0.02483329689130187), (10, 0.02590036136098206), (49, 0.026327638188377023), (48, 0.026497263927012682), (46, 0.027324117720127106), (50, 0.028004023944959044), (47, 0.028627989580854774), (51, 0.03261660737916827), (12, 0.032983270939439535), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.048060743138194084), (13, 0.05450336029753089), (2, 0.061206035781651735), (1, 0.07061250787228346), (0, 0.14636892266571522), (18, 0.30386047065258026), (36, 0.33333006501197815), (53, 0.9361404329538345)]
computing accuracy for after removing block 30 . block score: 0.012104445835575461
removed block 30 current accuracy 0.9186 loss from initial  0.08140000000000003
since last training loss: 0.07140000000000002 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 17, with score 0.012199. All blocks and scores: [(17, 0.012199450982734561), (25, 0.013075435534119606), (19, 0.013177949003875256), (35, 0.013523002620786428), (11, 0.013912908965721726), (34, 0.014766030362807214), (16, 0.014766237698495388), (33, 0.015034387819468975), (9, 0.015547690447419882), (38, 0.01585832703858614), (44, 0.016648652032017708), (42, 0.01781687722541392), (45, 0.019354374846443534), (43, 0.019491265760734677), (41, 0.020042051561176777), (14, 0.020047535188496113), (40, 0.020565516082569957), (8, 0.02166792005300522), (7, 0.021806210977956653), (37, 0.022225635824725032), (39, 0.022749603260308504), (15, 0.024833296658471227), (10, 0.025900361826643348), (49, 0.026006161933764815), (48, 0.02639011270366609), (46, 0.02736017433926463), (50, 0.027876119827851653), (47, 0.028576353332027793), (51, 0.0326245347969234), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718526378274), (52, 0.04603598499670625), (13, 0.054503361228853464), (2, 0.061206035781651735), (1, 0.07061250880360603), (0, 0.14636892266571522), (18, 0.30386047065258026), (36, 0.3517293334007263), (53, 0.9536165073513985)]
computing accuracy for after removing block 17 . block score: 0.012199450982734561
removed block 17 current accuracy 0.9074 loss from initial  0.09260000000000002
since last training loss: 0.0826 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.012180. All blocks and scores: [(19, 0.012179647805169225), (25, 0.01227200380526483), (35, 0.013189251767471433), (11, 0.013912908965721726), (33, 0.014486355823464692), (34, 0.014641908695921302), (16, 0.014766237582080066), (9, 0.015547690098173916), (38, 0.015624886262230575), (44, 0.016568857477977872), (42, 0.017387024825438857), (45, 0.018840335309505463), (43, 0.01932032499462366), (14, 0.0200475356541574), (41, 0.020390713354572654), (40, 0.021592806791886687), (8, 0.021667920518666506), (7, 0.021806210977956653), (37, 0.022732951445505023), (39, 0.02422378701157868), (15, 0.024833296425640583), (49, 0.025589684955775738), (10, 0.025900361826643348), (48, 0.026119847549125552), (50, 0.027166033163666725), (46, 0.027381491381675005), (47, 0.02795734000392258), (51, 0.03151704580523074), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968340575695), (4, 0.038043493404984474), (52, 0.04372498253360391), (3, 0.043747184332460165), (13, 0.05450335890054703), (2, 0.06120603624731302), (1, 0.07061250507831573), (0, 0.14636892080307007), (18, 0.31064049899578094), (36, 0.35844870284199715), (53, 0.9435389935970306)]
computing accuracy for after removing block 19 . block score: 0.012179647805169225
removed block 19 current accuracy 0.886 loss from initial  0.11399999999999999
since last training loss: 0.10399999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.011761. All blocks and scores: [(25, 0.011760654393583536), (35, 0.013664751197211444), (11, 0.013912908965721726), (34, 0.014714435441419482), (16, 0.014766238047741354), (9, 0.015547689981758595), (38, 0.015558895422145724), (33, 0.015920345671474934), (44, 0.0165003202855587), (42, 0.017734749475494027), (45, 0.01935424213297665), (14, 0.020047535886988044), (43, 0.02004793775267899), (41, 0.02063838462345302), (8, 0.021667920518666506), (7, 0.021806211210787296), (40, 0.02246462181210518), (37, 0.022927868412807584), (39, 0.02423938037827611), (15, 0.024833296658471227), (49, 0.02560739521868527), (10, 0.025900361593812704), (48, 0.026131258811801672), (50, 0.02728119771927595), (46, 0.02762721967883408), (47, 0.0281282605137676), (51, 0.03160239523276687), (12, 0.03298327000811696), (5, 0.033336244989186525), (6, 0.03351968340575695), (4, 0.03804349293932319), (52, 0.04308580607175827), (3, 0.043747184332460165), (13, 0.05450336029753089), (2, 0.061206037644296885), (1, 0.07061250600963831), (0, 0.14636892452836037), (18, 0.31064049899578094), (36, 0.3724363371729851), (53, 0.9451775476336479)]
computing accuracy for after removing block 25 . block score: 0.011760654393583536
removed block 25 current accuracy 0.851 loss from initial  0.14900000000000002
since last training loss: 0.139 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 35, with score 0.013833. All blocks and scores: [(35, 0.013832747587002814), (11, 0.013912909431383014), (16, 0.014766237349249423), (34, 0.015167495585046709), (9, 0.015547690447419882), (38, 0.015721766161732376), (44, 0.016465769615024328), (33, 0.016804948216304183), (42, 0.01725919940508902), (45, 0.01934929215349257), (43, 0.01996661676093936), (14, 0.02004753635264933), (41, 0.02115498180501163), (8, 0.021667920518666506), (7, 0.021806210512295365), (40, 0.023630635580047965), (37, 0.02430838905274868), (15, 0.024833296658471227), (49, 0.02514790720306337), (10, 0.025900361128151417), (48, 0.02610317151993513), (50, 0.026404579635709524), (39, 0.026513395830988884), (46, 0.027128393296152353), (47, 0.027616398874670267), (51, 0.03103758580982685), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.03804349293932319), (52, 0.04048937279731035), (3, 0.04374718479812145), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250787228346), (0, 0.14636892080307007), (18, 0.31064051017165184), (36, 0.3894701525568962), (53, 0.9491120502352715)]
computing accuracy for after removing block 35 . block score: 0.013832747587002814
removed block 35 current accuracy 0.8452 loss from initial  0.15480000000000005
training start
training epoch 0 val accuracy 0.7982 topk_dict {'top1': 0.7982} is_best False lr [0.1]
training epoch 1 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 3 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 4 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 5 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 6 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.1]
training epoch 7 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 9 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.965000)
finished training. finished 50 epochs. accuracy 0.965 topk_dict {'top1': 0.965}
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.032452. All blocks and scores: [(40, 0.03245226992294192), (44, 0.03298074519261718), (9, 0.036188901867717505), (43, 0.03645619936287403), (39, 0.03818685607984662), (41, 0.038838306441903114), (42, 0.03942267131060362), (38, 0.04013922391459346), (45, 0.04104871116578579), (11, 0.04173080250620842), (16, 0.043357196263968945), (49, 0.04551691934466362), (51, 0.0458740321919322), (50, 0.0468056658282876), (14, 0.04691982688382268), (37, 0.04747267859056592), (48, 0.05024449760094285), (46, 0.051985892467200756), (47, 0.05311367753893137), (7, 0.053206936456263065), (34, 0.058534607756882906), (52, 0.05963421845808625), (8, 0.06156722875311971), (15, 0.06841610372066498), (33, 0.07073553930968046), (5, 0.07725847233086824), (10, 0.0794587479904294), (12, 0.08021300379186869), (6, 0.08580699469894171), (4, 0.10351492837071419), (3, 0.10975950676947832), (2, 0.15486829727888107), (13, 0.15504436008632183), (1, 0.1953007262200117), (0, 0.32484980672597885), (18, 0.5162139907479286), (36, 0.669498398900032), (53, 1.0760361701250076)]
computing accuracy for after removing block 40 . block score: 0.03245226992294192
removed block 40 current accuracy 0.9624 loss from initial  0.03759999999999997
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.033852. All blocks and scores: [(44, 0.033851970452815294), (9, 0.036188901867717505), (39, 0.038186857011169195), (43, 0.03833110723644495), (38, 0.04013922484591603), (42, 0.04166135238483548), (45, 0.04169044969603419), (11, 0.04173080250620842), (41, 0.04184505669400096), (16, 0.04335719533264637), (51, 0.04615573910996318), (49, 0.04640697967261076), (14, 0.04691982548683882), (37, 0.04747267905622721), (50, 0.047502401284873486), (48, 0.04993578512221575), (7, 0.05320693738758564), (46, 0.053639321587979794), (47, 0.053714320063591), (34, 0.058534606359899044), (52, 0.05945600103586912), (8, 0.061567229218780994), (15, 0.0684161027893424), (33, 0.07073553651571274), (5, 0.07725847326219082), (10, 0.07945874519646168), (12, 0.08021300006657839), (6, 0.08580699935555458), (4, 0.10351492557674646), (3, 0.10975950956344604), (2, 0.15486829355359077), (13, 0.15504436194896698), (1, 0.1953007224947214), (0, 0.32484981417655945), (18, 0.5162139981985092), (36, 0.6694983914494514), (53, 1.0899984687566757)]
computing accuracy for after removing block 44 . block score: 0.033851970452815294
removed block 44 current accuracy 0.9596 loss from initial  0.04039999999999999
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 9, with score 0.036189. All blocks and scores: [(9, 0.036188901867717505), (39, 0.03818685654550791), (43, 0.03833110677078366), (38, 0.040139224380254745), (42, 0.04166135238483548), (11, 0.04173080250620842), (41, 0.04184505622833967), (16, 0.043357196263968945), (45, 0.04489037720486522), (51, 0.046613001730293036), (14, 0.04691982641816139), (37, 0.04747267859056592), (49, 0.04750268254429102), (50, 0.04850746178999543), (48, 0.049929603934288025), (7, 0.05320693785324693), (46, 0.05503890058025718), (47, 0.05509124929085374), (34, 0.05853460682556033), (52, 0.05958068976178765), (8, 0.061567229218780994), (15, 0.06841610185801983), (33, 0.07073553558439016), (5, 0.0772584741935134), (10, 0.0794587442651391), (12, 0.08021300658583641), (6, 0.08580699563026428), (4, 0.10351492092013359), (3, 0.10975950863212347), (2, 0.15486829169094563), (13, 0.15504436194896698), (1, 0.19530071690678596), (0, 0.32484981790184975), (18, 0.516213983297348), (36, 0.6694983914494514), (53, 1.1470528841018677)]
computing accuracy for after removing block 9 . block score: 0.036188901867717505
removed block 9 current accuracy 0.9564 loss from initial  0.04359999999999997
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.036881. All blocks and scores: [(39, 0.036881338339298964), (43, 0.03812964865937829), (16, 0.03911148523911834), (38, 0.03972794907167554), (42, 0.040088947396725416), (11, 0.04168114624917507), (14, 0.0424960688687861), (41, 0.04313659528270364), (45, 0.044430024921894073), (37, 0.04571191966533661), (51, 0.04597065318375826), (49, 0.046936171129345894), (50, 0.04800028679892421), (48, 0.04910368425771594), (7, 0.05320693692192435), (46, 0.053958835080266), (47, 0.05409453855827451), (34, 0.05707018496468663), (52, 0.058710381388664246), (8, 0.061567229218780994), (15, 0.0657854899764061), (33, 0.06801511440426111), (10, 0.07313044741749763), (12, 0.07722418755292892), (5, 0.07725847326219082), (6, 0.08580700401216745), (4, 0.10351492557674646), (3, 0.1097595077008009), (13, 0.14180605672299862), (2, 0.15486829727888107), (1, 0.19530071690678596), (0, 0.32484981417655945), (18, 0.49142764136195183), (36, 0.6472650319337845), (53, 1.136590838432312)]
computing accuracy for after removing block 39 . block score: 0.036881338339298964
removed block 39 current accuracy 0.9496 loss from initial  0.0504
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 16, with score 0.039111. All blocks and scores: [(16, 0.039111485704779625), (43, 0.0394524484872818), (38, 0.039727950002998114), (11, 0.0416811453178525), (14, 0.04249606840312481), (42, 0.04271224932745099), (45, 0.04447238706052303), (51, 0.045139848720282316), (41, 0.04556116322055459), (37, 0.04571191966533661), (49, 0.04740322707220912), (50, 0.04770040838047862), (48, 0.04894261760637164), (7, 0.05320693692192435), (47, 0.05450861621648073), (46, 0.054774902295321226), (34, 0.05707018682733178), (52, 0.05883621471002698), (8, 0.06156723201274872), (15, 0.0657854899764061), (33, 0.06801511347293854), (10, 0.07313044834882021), (12, 0.0772241884842515), (5, 0.07725847233086824), (6, 0.085806998424232), (4, 0.10351492464542389), (3, 0.10975950956344604), (13, 0.14180605486035347), (2, 0.15486829355359077), (1, 0.1953007262200117), (0, 0.32484980300068855), (18, 0.4914276488125324), (36, 0.6472650691866875), (53, 1.1286492049694061)]
computing accuracy for after removing block 16 . block score: 0.039111485704779625
removed block 16 current accuracy 0.94 loss from initial  0.06000000000000005
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.039219. All blocks and scores: [(43, 0.03921910701319575), (38, 0.03961715567857027), (11, 0.0416811453178525), (42, 0.04195656720548868), (14, 0.042496069334447384), (45, 0.04377831518650055), (51, 0.04440439119935036), (37, 0.04603520594537258), (41, 0.046582940965890884), (49, 0.046934520825743675), (50, 0.047046022955328226), (48, 0.04831298999488354), (7, 0.05320693692192435), (47, 0.05404666345566511), (46, 0.05416568461805582), (34, 0.05615949211642146), (52, 0.05722434585914016), (8, 0.06156722968444228), (15, 0.06578548904508352), (33, 0.06810808088630438), (10, 0.07313044648617506), (12, 0.0772241884842515), (5, 0.07725847698748112), (6, 0.08580699749290943), (4, 0.10351492557674646), (3, 0.10975951049476862), (13, 0.14180605299770832), (2, 0.15486829541623592), (1, 0.19530072063207626), (0, 0.32484981790184975), (18, 0.4979938454926014), (36, 0.6477988064289093), (53, 1.1385482102632523)]
computing accuracy for after removing block 43 . block score: 0.03921910701319575
removed block 43 current accuracy 0.9312 loss from initial  0.06879999999999997
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 38, with score 0.039617. All blocks and scores: [(38, 0.039617153350263834), (11, 0.041681145783513784), (42, 0.04195656767114997), (14, 0.04249606840312481), (51, 0.04453637171536684), (45, 0.04576036240905523), (37, 0.04603520594537258), (41, 0.046582940965890884), (50, 0.0470691779628396), (49, 0.047506035305559635), (48, 0.047515138518065214), (7, 0.05320693785324693), (47, 0.05467525636777282), (46, 0.055220641661435366), (34, 0.056159491185098886), (52, 0.05690909316763282), (8, 0.06156722875311971), (15, 0.0657854899764061), (33, 0.06810808181762695), (10, 0.07313044462352991), (12, 0.07722418755292892), (5, 0.07725847512483597), (6, 0.085806998424232), (4, 0.10351492464542389), (3, 0.10975950676947832), (13, 0.14180605299770832), (2, 0.15486829727888107), (1, 0.19530072435736656), (0, 0.32484981045126915), (18, 0.4979938082396984), (36, 0.6477988064289093), (53, 1.1897602528333664)]
computing accuracy for after removing block 38 . block score: 0.039617153350263834
removed block 38 current accuracy 0.9172 loss from initial  0.08279999999999998
since last training loss: 0.047799999999999954 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 42, with score 0.041515. All blocks and scores: [(42, 0.04151482507586479), (11, 0.04168114624917507), (14, 0.04249606793746352), (51, 0.043162787333130836), (45, 0.04343590931966901), (48, 0.045066861901432276), (50, 0.045847256667912006), (37, 0.04603520641103387), (49, 0.04695356264710426), (41, 0.0475344960577786), (7, 0.05320693692192435), (47, 0.053284038323909044), (46, 0.05364527367055416), (52, 0.053848059847950935), (34, 0.05615949258208275), (8, 0.06156723154708743), (15, 0.06578548811376095), (33, 0.06810807902365923), (10, 0.07313044834882021), (12, 0.07722418941557407), (5, 0.0772584741935134), (6, 0.08580700028687716), (4, 0.10351492278277874), (3, 0.10975950676947832), (13, 0.14180605486035347), (2, 0.15486829727888107), (1, 0.19530072063207626), (0, 0.32484981045126915), (18, 0.4979938231408596), (36, 0.6477988138794899), (53, 1.1928531378507614)]
computing accuracy for after removing block 42 . block score: 0.04151482507586479
removed block 42 current accuracy 0.892 loss from initial  0.10799999999999998
training start
training epoch 0 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 1 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 2 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 3 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.1]
training epoch 6 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 7 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 8 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 9 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9538 topk_dict {'top1': 0.9538}
start iteration 24
[activation diff]: block to remove picked: 51, with score 0.052680. All blocks and scores: [(51, 0.052679894026368856), (11, 0.05326903611421585), (45, 0.05500823259353638), (49, 0.05521480506286025), (48, 0.056829940527677536), (50, 0.05754555808380246), (14, 0.0593953151255846), (52, 0.0597482668235898), (7, 0.06391040794551373), (47, 0.06500187609344721), (46, 0.06561561487615108), (34, 0.0680897319689393), (8, 0.06974401976913214), (41, 0.07003071717917919), (37, 0.07721545733511448), (10, 0.08645002450793982), (15, 0.08920838870108128), (5, 0.09247830603271723), (33, 0.09372543264180422), (6, 0.0946854967623949), (12, 0.10371395014226437), (4, 0.1141955005005002), (3, 0.118343161419034), (13, 0.1662826258689165), (2, 0.1669808365404606), (1, 0.20959781482815742), (0, 0.3315398618578911), (18, 0.5617010518908501), (36, 0.6350873038172722), (53, 1.1871107816696167)]
computing accuracy for after removing block 51 . block score: 0.052679894026368856
removed block 51 current accuracy 0.9432 loss from initial  0.05679999999999996
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 11, with score 0.053269. All blocks and scores: [(11, 0.05326903657987714), (45, 0.05500823259353638), (49, 0.055214805994182825), (48, 0.05682994099333882), (50, 0.0575455604121089), (14, 0.05939531372860074), (7, 0.06391040794551373), (47, 0.06500187702476978), (46, 0.06561561301350594), (52, 0.06719296146184206), (34, 0.06808973103761673), (8, 0.06974401976913214), (41, 0.07003071624785662), (37, 0.0772154564037919), (10, 0.08645002450793982), (15, 0.0892083877697587), (5, 0.09247830510139465), (33, 0.0937254298478365), (6, 0.09468549955636263), (12, 0.10371395107358694), (4, 0.1141955005005002), (3, 0.11834316048771143), (13, 0.1662826295942068), (2, 0.16698083840310574), (1, 0.20959781482815742), (0, 0.3315398693084717), (18, 0.5617010593414307), (36, 0.635087288916111), (53, 1.3510560989379883)]
computing accuracy for after removing block 11 . block score: 0.05326903657987714
removed block 11 current accuracy 0.9414 loss from initial  0.058599999999999985
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 14, with score 0.054722. All blocks and scores: [(14, 0.05472236732020974), (45, 0.05500664096325636), (49, 0.055112579837441444), (50, 0.056086234748363495), (48, 0.056371068116277456), (7, 0.06391040608286858), (47, 0.06409031990915537), (46, 0.06577392015606165), (34, 0.06584153510630131), (52, 0.06730271875858307), (8, 0.06974402163177729), (41, 0.06994932424277067), (37, 0.0746044646948576), (10, 0.08645002450793982), (15, 0.08772858045995235), (33, 0.09178890381008387), (5, 0.09247830417007208), (6, 0.09468549862504005), (12, 0.09790163021534681), (4, 0.11419549770653248), (3, 0.11834316328167915), (13, 0.15887456573545933), (2, 0.1669808365404606), (1, 0.20959781669080257), (0, 0.3315398655831814), (18, 0.5323366969823837), (36, 0.621638610959053), (53, 1.3606635630130768)]
computing accuracy for after removing block 14 . block score: 0.05472236732020974
removed block 14 current accuracy 0.9318 loss from initial  0.06820000000000004
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 48, with score 0.054599. All blocks and scores: [(48, 0.05459906626492739), (50, 0.05468342872336507), (49, 0.05485137412324548), (45, 0.0552498591132462), (47, 0.06295112427324057), (7, 0.0639104088768363), (34, 0.06413723435252905), (46, 0.06608909647911787), (52, 0.06609317008405924), (41, 0.06798529718071222), (8, 0.06974401883780956), (37, 0.07579646725207567), (10, 0.08645002357661724), (33, 0.09001375548541546), (5, 0.09247830603271723), (15, 0.0933792358264327), (6, 0.09468549862504005), (12, 0.09790163394063711), (4, 0.1141955005005002), (3, 0.11834316048771143), (13, 0.15887456946074963), (2, 0.1669808365404606), (1, 0.20959780551493168), (0, 0.3315398804843426), (18, 0.5430838391184807), (36, 0.6273956149816513), (53, 1.356100633740425)]
computing accuracy for after removing block 48 . block score: 0.05459906626492739
removed block 48 current accuracy 0.9134 loss from initial  0.08660000000000001
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 45, with score 0.055250. All blocks and scores: [(45, 0.05524985957890749), (50, 0.05966561567038298), (47, 0.06295112520456314), (49, 0.06308727618306875), (7, 0.06391040794551373), (34, 0.06413723528385162), (46, 0.06608909647911787), (41, 0.06798529531806707), (8, 0.06974401976913214), (52, 0.07261745724827051), (37, 0.07579646818339825), (10, 0.08645002264529467), (33, 0.09001375548541546), (5, 0.09247830975800753), (15, 0.0933792358264327), (6, 0.0946855004876852), (12, 0.09790163021534681), (4, 0.11419549956917763), (3, 0.11834315955638885), (13, 0.15887456759810448), (2, 0.16698083467781544), (1, 0.20959781296551228), (0, 0.331539873033762), (18, 0.5430838391184807), (36, 0.6273956149816513), (53, 1.5079602301120758)]
computing accuracy for after removing block 45 . block score: 0.05524985957890749
removed block 45 current accuracy 0.8972 loss from initial  0.1028
since last training loss: 0.056599999999999984 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 50, with score 0.060869. All blocks and scores: [(50, 0.06086919875815511), (7, 0.06391040701419115), (34, 0.06413723342120647), (49, 0.06534459814429283), (47, 0.06653924193233252), (41, 0.06798529624938965), (8, 0.06974402163177729), (46, 0.0714900242164731), (52, 0.07435666676610708), (37, 0.0757964700460434), (10, 0.08645002357661724), (33, 0.09001375734806061), (5, 0.09247830417007208), (15, 0.0933792321011424), (6, 0.0946855004876852), (12, 0.09790163021534681), (4, 0.11419549956917763), (3, 0.118343161419034), (13, 0.15887456387281418), (2, 0.1669808365404606), (1, 0.20959781296551228), (0, 0.3315398544073105), (18, 0.5430838465690613), (36, 0.6273956149816513), (53, 1.629953682422638)]
computing accuracy for after removing block 50 . block score: 0.06086919875815511
removed block 50 current accuracy 0.8648 loss from initial  0.1352
since last training loss: 0.08899999999999997 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 7, with score 0.063910. All blocks and scores: [(7, 0.06391040794551373), (34, 0.06413723435252905), (49, 0.06534459814429283), (47, 0.06653924193233252), (41, 0.06798529531806707), (8, 0.06974401976913214), (46, 0.0714900242164731), (37, 0.07579646911472082), (10, 0.08645002357661724), (52, 0.08879935089498758), (33, 0.09001375734806061), (5, 0.09247830603271723), (15, 0.0933792321011424), (6, 0.09468549955636263), (12, 0.09790163207799196), (4, 0.11419550143182278), (3, 0.11834315862506628), (13, 0.15887456387281418), (2, 0.16698083840310574), (1, 0.20959780924022198), (0, 0.3315398655831814), (18, 0.5430838465690613), (36, 0.6273956000804901), (53, 1.8223944455385208)]
computing accuracy for after removing block 7 . block score: 0.06391040794551373
removed block 7 current accuracy 0.858 loss from initial  0.14200000000000002
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 34, with score 0.061985. All blocks and scores: [(34, 0.06198454508557916), (49, 0.06271474529057741), (47, 0.06380537338554859), (46, 0.06749382056295872), (8, 0.06790327001363039), (41, 0.06958011724054813), (37, 0.07137512695044279), (10, 0.0779851395636797), (33, 0.08610027842223644), (52, 0.08816975820809603), (15, 0.08954168111085892), (5, 0.09247830882668495), (6, 0.0946855004876852), (12, 0.09693484473973513), (4, 0.11419549863785505), (3, 0.11834315862506628), (13, 0.15135887637734413), (2, 0.16698083840310574), (1, 0.20959781482815742), (0, 0.3315398544073105), (18, 0.5113072842359543), (36, 0.6009752079844475), (53, 1.8130336254835129)]
computing accuracy for after removing block 34 . block score: 0.06198454508557916
removed block 34 current accuracy 0.8202 loss from initial  0.17979999999999996
since last training loss: 0.13359999999999994 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 49, with score 0.060955. All blocks and scores: [(49, 0.06095513654872775), (47, 0.06190101196989417), (46, 0.06411087792366743), (8, 0.06790327001363039), (41, 0.07100076507776976), (37, 0.07331817876547575), (10, 0.0779851395636797), (52, 0.08465813472867012), (33, 0.08610027935355902), (15, 0.08954168576747179), (5, 0.09247830417007208), (6, 0.09468550141900778), (12, 0.09693484753370285), (4, 0.11419550236314535), (3, 0.11834316048771143), (13, 0.15135888010263443), (2, 0.1669808365404606), (1, 0.20959781296551228), (0, 0.3315398655831814), (18, 0.5113072767853737), (36, 0.6229902282357216), (53, 1.8752411007881165)]
computing accuracy for after removing block 49 . block score: 0.06095513654872775
removed block 49 current accuracy 0.7628 loss from initial  0.23719999999999997
training start
training epoch 0 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.1]
training epoch 1 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.1]
training epoch 2 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 3 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 4 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 5 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 6 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 7 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 8 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 9 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.939400)
finished training. finished 50 epochs. accuracy 0.9394 topk_dict {'top1': 0.9394}
