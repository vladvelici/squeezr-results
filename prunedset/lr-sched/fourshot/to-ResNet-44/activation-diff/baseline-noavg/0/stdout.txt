start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101807072759), (24, 0.006592476507648826), (25, 0.007601776043884456), (21, 0.008612961391918361), (27, 0.008965069660916924), (5, 0.009674609522335231), (23, 0.011229232884943485), (19, 0.011454988387413323), (35, 0.011519728461280465), (32, 0.013281174236908555), (29, 0.014178814948536456), (20, 0.0145084384130314), (31, 0.014615894411690533), (3, 0.014681300148367882), (26, 0.01472489454317838), (30, 0.014915360603481531), (7, 0.01509747828822583), (28, 0.016234831884503365), (37, 0.018546362407505512), (33, 0.021617853548377752), (39, 0.02187628811225295), (6, 0.022251416696235538), (50, 0.02244598139077425), (34, 0.0225658870767802), (49, 0.02260288642719388), (8, 0.023474456509575248), (38, 0.02385126333683729), (41, 0.024523035157471895), (40, 0.024661973118782043), (1, 0.02538809599354863), (46, 0.026244731852784753), (45, 0.02668318711221218), (48, 0.026970998384058475), (44, 0.0280617312528193), (51, 0.028739838860929012), (42, 0.028769566910341382), (43, 0.03079548361711204), (47, 0.03119555884040892), (0, 0.032716508489102125), (13, 0.036019420716911554), (15, 0.04315127898007631), (14, 0.04341263556852937), (16, 0.044330659322440624), (12, 0.049656882882118225), (4, 0.051154307555407286), (11, 0.05217862315475941), (52, 0.053275329526513815), (2, 0.05518383299931884), (10, 0.0601671002805233), (9, 0.08553026523441076), (17, 0.18986638449132442), (18, 0.2766866236925125), (36, 0.2898172177374363), (53, 0.8816948309540749)]
computing accuracy for after removing block 22 . block score: 0.005787101807072759
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.006946946610696614), (25, 0.007925601676106453), (21, 0.008612961624749005), (27, 0.008884541923180223), (5, 0.009674609522335231), (19, 0.011454987921752036), (23, 0.011499474290758371), (35, 0.01158733875490725), (32, 0.013315335963852704), (29, 0.014122492983005941), (20, 0.014508438529446721), (31, 0.01453536655753851), (3, 0.01468130003195256), (30, 0.014953501988202333), (7, 0.015097478870302439), (26, 0.015386729501187801), (28, 0.016657372238114476), (37, 0.018698561936616898), (33, 0.02183614973910153), (6, 0.02225141692906618), (39, 0.022278543561697006), (50, 0.0223967214114964), (34, 0.02257942478172481), (49, 0.022588348481804132), (8, 0.023474456975236535), (38, 0.024010848021134734), (41, 0.02471063518896699), (40, 0.02483244682662189), (1, 0.0253880952950567), (46, 0.026328842621296644), (45, 0.026519648963585496), (48, 0.026865347055718303), (51, 0.028594730654731393), (44, 0.028690783539786935), (42, 0.028934542322531343), (47, 0.03059899271465838), (43, 0.03088917676359415), (0, 0.0327165094204247), (13, 0.03601941978558898), (15, 0.043151278514415026), (14, 0.04341263556852937), (16, 0.04433065978810191), (12, 0.04965688521042466), (4, 0.051154307555407286), (11, 0.05217862408608198), (52, 0.052744821179658175), (2, 0.05518383393064141), (10, 0.06016709981486201), (9, 0.08553026616573334), (17, 0.18986638635396957), (18, 0.2766866236925125), (36, 0.29418330639600754), (53, 0.8765672892332077)]
computing accuracy for after removing block 24 . block score: 0.006946946610696614
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.00796479161363095), (27, 0.00850203714799136), (21, 0.008612961042672396), (5, 0.009674609755165875), (35, 0.011124448501504958), (19, 0.011454987921752036), (23, 0.011499474057927728), (32, 0.012667875736951828), (29, 0.013618955272249877), (31, 0.01425534370355308), (30, 0.014440409024246037), (20, 0.014508438180200756), (3, 0.014681299682706594), (7, 0.015097478055395186), (26, 0.01534169097431004), (28, 0.016541525023058057), (37, 0.01884897775016725), (34, 0.021491801599040627), (33, 0.02174661122262478), (50, 0.02214478445239365), (6, 0.022251416463404894), (49, 0.02257367572747171), (39, 0.02259462559595704), (8, 0.02347445674240589), (38, 0.02391935046762228), (41, 0.024731411831453443), (40, 0.025212144246324897), (1, 0.025388095062226057), (45, 0.026285271858796477), (46, 0.026299893856048584), (48, 0.026813949923962355), (51, 0.02844897983595729), (44, 0.028867240995168686), (42, 0.02887698612175882), (47, 0.03047257475554943), (43, 0.03083793306723237), (0, 0.032716508489102125), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.043412636034190655), (16, 0.0443306602537632), (12, 0.049656886607408524), (4, 0.05115430802106857), (11, 0.052178621757775545), (52, 0.052212192211300135), (2, 0.05518383393064141), (10, 0.060167096089571714), (9, 0.08553026430308819), (17, 0.18986639194190502), (18, 0.2766866236925125), (36, 0.2956240735948086), (53, 0.8761104419827461)]
computing accuracy for after removing block 25 . block score: 0.00796479161363095
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.00820748379919678), (21, 0.00861296127550304), (5, 0.009674609522335231), (35, 0.01066389656625688), (19, 0.011454987805336714), (23, 0.011499473941512406), (32, 0.012014232808724046), (29, 0.012787628802470863), (31, 0.013865676592104137), (30, 0.013961306307464838), (20, 0.014508438762277365), (3, 0.014681299566291273), (26, 0.014919800567440689), (7, 0.015097478404641151), (28, 0.01572392089292407), (37, 0.01879318873398006), (34, 0.02036181022413075), (33, 0.021328614791855216), (50, 0.021633303025737405), (49, 0.022232345072552562), (6, 0.022251416696235538), (39, 0.02252841927111149), (8, 0.023474456975236535), (38, 0.023843125207349658), (41, 0.024403041461482644), (40, 0.025254083797335625), (1, 0.0253880952950567), (45, 0.025693233823403716), (46, 0.025908004259690642), (48, 0.026390638668090105), (51, 0.027748763095587492), (42, 0.02847559191286564), (44, 0.02885661507025361), (47, 0.029799402225762606), (43, 0.03020182834006846), (0, 0.03271650895476341), (13, 0.036019420716911554), (15, 0.04315127898007631), (14, 0.04341263649985194), (16, 0.04433066118508577), (12, 0.04965688427910209), (52, 0.05079668015241623), (4, 0.05115430895239115), (11, 0.05217862082645297), (2, 0.05518383486196399), (10, 0.06016709702089429), (9, 0.08553026430308819), (17, 0.18986638635396957), (18, 0.2766866274178028), (36, 0.29478897899389267), (53, 0.8695808723568916)]
computing accuracy for after removing block 27 . block score: 0.00820748379919678
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.008612961042672396), (5, 0.00967460940591991), (35, 0.010487184743396938), (19, 0.011454987688921392), (23, 0.01149947417434305), (32, 0.011747056734748185), (29, 0.012900045490823686), (31, 0.013738625217229128), (30, 0.013831985997967422), (20, 0.014508438645862043), (3, 0.014681299799121916), (26, 0.014919801033101976), (7, 0.015097477938979864), (28, 0.016265673795714974), (37, 0.018666349118575454), (34, 0.020145454443991184), (50, 0.02132679265923798), (33, 0.021582857938483357), (49, 0.022118565160781145), (6, 0.02225141692906618), (39, 0.0222895669285208), (8, 0.02347445604391396), (38, 0.02361668087542057), (41, 0.024516039062291384), (40, 0.0253668250516057), (45, 0.02536774054169655), (1, 0.025388095760717988), (46, 0.02560482849366963), (48, 0.026125094387680292), (51, 0.027203566394746304), (42, 0.028293345356360078), (44, 0.029326205840334296), (47, 0.02935170498676598), (43, 0.030030404683202505), (0, 0.03271650895476341), (13, 0.03601941978558898), (15, 0.04315127758309245), (14, 0.04341263649985194), (16, 0.0443306602537632), (12, 0.049656882882118225), (52, 0.05003825714811683), (4, 0.05115430848672986), (11, 0.052178623620420694), (2, 0.05518383486196399), (10, 0.060167096555233), (9, 0.08553026430308819), (17, 0.18986638635396957), (18, 0.2766866274178028), (36, 0.29525746777653694), (53, 0.8683891072869301)]
computing accuracy for after removing block 21 . block score: 0.008612961042672396
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.009674609289504588), (35, 0.010542471893131733), (19, 0.011454987688921392), (23, 0.011545549263246357), (32, 0.011696714325807989), (29, 0.013034457922913134), (30, 0.01354199240449816), (31, 0.013661347329616547), (20, 0.014508438645862043), (26, 0.014561282354407012), (3, 0.014681299915537238), (7, 0.015097478404641151), (28, 0.0162722235545516), (37, 0.018855378264561296), (34, 0.02017069305293262), (50, 0.02119536232203245), (33, 0.021736358059570193), (49, 0.022025791462510824), (6, 0.02225141739472747), (39, 0.022593395551666617), (8, 0.02347445674240589), (38, 0.023794721579179168), (41, 0.024486313574016094), (45, 0.02517408551648259), (1, 0.025388095527887344), (46, 0.025596367428079247), (40, 0.02570292539894581), (48, 0.02593583008274436), (51, 0.026903111720457673), (42, 0.028371038381010294), (47, 0.02913125790655613), (44, 0.029263162752613425), (43, 0.030276520177721977), (0, 0.032716508489102125), (13, 0.03601941978558898), (15, 0.043151278514415026), (14, 0.04341263743117452), (16, 0.044330660719424486), (52, 0.04949297895655036), (12, 0.04965688334777951), (4, 0.051154307555407286), (11, 0.052178621757775545), (2, 0.055183833464980125), (10, 0.06016709841787815), (9, 0.08553026616573334), (17, 0.18986638262867928), (18, 0.2766866236925125), (36, 0.2977275885641575), (53, 0.8672097846865654)]
computing accuracy for after removing block 5 . block score: 0.009674609289504588
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010497. All blocks and scores: [(35, 0.010497342329472303), (19, 0.011364333564415574), (23, 0.011454000836238265), (32, 0.01173175044823438), (29, 0.012978376005776227), (30, 0.013561801402829587), (31, 0.013812811579555273), (20, 0.014028266887180507), (26, 0.014234644477255642), (3, 0.01468130003195256), (28, 0.01640962902456522), (37, 0.019115549977868795), (7, 0.019321491941809654), (34, 0.02049453160725534), (50, 0.02102655521593988), (33, 0.02140929689630866), (49, 0.02209633612073958), (39, 0.02228957461193204), (38, 0.02318346011452377), (41, 0.02425868227146566), (6, 0.025002858601510525), (8, 0.025038712425157428), (45, 0.025084450840950012), (46, 0.025368364993482828), (1, 0.025388095062226057), (48, 0.025792345171794295), (40, 0.026035186601802707), (51, 0.02685543615370989), (42, 0.028462824877351522), (44, 0.028849950758740306), (47, 0.029113001422956586), (43, 0.03023843909613788), (0, 0.032716508489102125), (13, 0.036061248276382685), (15, 0.04305667895823717), (16, 0.043651989195495844), (14, 0.043659398797899485), (52, 0.04937674105167389), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.05406309058889747), (2, 0.055183835327625275), (10, 0.062402026262134314), (9, 0.08971724193543196), (17, 0.1863695476204157), (18, 0.27677176147699356), (36, 0.2957078889012337), (53, 0.8705098554491997)]
computing accuracy for after removing block 35 . block score: 0.010497342329472303
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011364. All blocks and scores: [(19, 0.011364334146492183), (23, 0.011454000836238265), (32, 0.011731750098988414), (29, 0.012978376122191548), (30, 0.01356180151924491), (31, 0.013812811230309308), (20, 0.014028266770765185), (26, 0.014234644826501608), (3, 0.014681299682706594), (28, 0.016409628558903933), (37, 0.018872639164328575), (7, 0.01932149240747094), (34, 0.02049453160725534), (50, 0.021021218970417976), (33, 0.02140929689630866), (49, 0.021970302099362016), (39, 0.022241036174818873), (38, 0.02228572452440858), (41, 0.024062653305009007), (45, 0.024892093613743782), (46, 0.024894545786082745), (6, 0.025002858601510525), (8, 0.02503871195949614), (1, 0.025388096692040563), (48, 0.025495541747659445), (40, 0.0256039013620466), (51, 0.02683849702589214), (42, 0.028305644867941737), (44, 0.02850431390106678), (47, 0.028528794879093766), (43, 0.029594503808766603), (0, 0.03271650895476341), (13, 0.03606124920770526), (15, 0.04305668128654361), (16, 0.04365199012681842), (14, 0.04365939740091562), (52, 0.048602734226733446), (4, 0.05115430895239115), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.05518383393064141), (10, 0.062402029521763325), (9, 0.08971724566072226), (17, 0.18636955134570599), (18, 0.27677176520228386), (36, 0.29528704285621643), (53, 0.8746363148093224)]
computing accuracy for after removing block 19 . block score: 0.011364334146492183
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
training start
training epoch 0 val accuracy 0.7386 topk_dict {'top1': 0.7386} is_best False lr [0.1]
training epoch 1 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best False lr [0.1]
training epoch 2 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 3 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 4 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 5 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 6 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 7 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 8 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 9 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 10 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.997800)
finished training. finished 50 epochs. accuracy 0.9978 topk_dict {'top1': 0.9978}
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.011435. All blocks and scores: [(32, 0.011435218388214707), (23, 0.011625511688180268), (29, 0.013017931603826582), (31, 0.013358428375795484), (30, 0.013481264701113105), (26, 0.013551717158406973), (20, 0.014475058880634606), (3, 0.014681299915537238), (28, 0.016491985181346536), (37, 0.018982867943122983), (7, 0.01932149240747094), (34, 0.020425984170287848), (50, 0.020725763402879238), (33, 0.021510421065613627), (49, 0.021559856366366148), (39, 0.02184294955804944), (38, 0.021860384149476886), (41, 0.02357930806465447), (46, 0.024237518897280097), (45, 0.024405382806435227), (48, 0.024966377299278975), (6, 0.02500285883434117), (8, 0.025038712192326784), (1, 0.02538809599354863), (40, 0.025583632057532668), (51, 0.026265001855790615), (44, 0.027775867143645883), (42, 0.027991156559437513), (47, 0.02842498244717717), (43, 0.02918767975643277), (0, 0.0327165094204247), (13, 0.03606124874204397), (15, 0.04305668035522103), (16, 0.04365198872983456), (14, 0.04365939926356077), (52, 0.04771037399768829), (4, 0.05115430895239115), (12, 0.05150972260162234), (11, 0.05406309058889747), (2, 0.05518383393064141), (10, 0.06240202905610204), (9, 0.08971724193543196), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.28799718618392944), (53, 0.8807788193225861)]
computing accuracy for after removing block 32 . block score: 0.011435218388214707
removed block 32 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.011626. All blocks and scores: [(23, 0.011625512037426233), (29, 0.01301793148741126), (31, 0.013358428608626127), (30, 0.013481264817528427), (26, 0.01355171692557633), (20, 0.014475058764219284), (3, 0.01468130003195256), (28, 0.016491985181346536), (37, 0.01881252881139517), (7, 0.019321492640301585), (34, 0.020461332984268665), (50, 0.020823082188144326), (49, 0.02181476610712707), (38, 0.02202586503699422), (39, 0.022391145350411534), (33, 0.0224131743889302), (41, 0.024000402307137847), (46, 0.02434976096265018), (45, 0.02442808309569955), (6, 0.025002859998494387), (8, 0.025038711726665497), (1, 0.025388095527887344), (48, 0.025586012052372098), (51, 0.026234305696561933), (40, 0.026594598777592182), (42, 0.0284015245269984), (47, 0.028766985284164548), (44, 0.028827981324866414), (43, 0.02949392795562744), (0, 0.03271650988608599), (13, 0.03606124874204397), (15, 0.043056679889559746), (16, 0.04365198826417327), (14, 0.04365939786657691), (52, 0.04727818816900253), (4, 0.05115430802106857), (12, 0.05150972120463848), (11, 0.054063089191913605), (2, 0.05518383393064141), (10, 0.062402029521763325), (9, 0.08971724472939968), (17, 0.18636955134570599), (18, 0.27677176520228386), (36, 0.30095571652054787), (53, 0.8827565386891365)]
computing accuracy for after removing block 23 . block score: 0.011625512037426233
removed block 23 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.012718. All blocks and scores: [(26, 0.012718255748040974), (31, 0.013059878023341298), (30, 0.013245979906059802), (29, 0.013515455881133676), (20, 0.014475059229880571), (3, 0.014681299682706594), (28, 0.01654111174866557), (37, 0.018968473887071013), (7, 0.01932149240747094), (50, 0.020513230003416538), (34, 0.02061733091250062), (49, 0.021386135136708617), (38, 0.02212540782056749), (39, 0.022963949013501406), (33, 0.02358992164954543), (41, 0.023973098257556558), (46, 0.02425109432078898), (45, 0.02427463559433818), (6, 0.02500285883434117), (8, 0.02503871195949614), (48, 0.025167004438117146), (1, 0.025388095760717988), (51, 0.02571793389506638), (40, 0.026828006375581026), (47, 0.028098625363782048), (44, 0.02816085214726627), (42, 0.028478232445195317), (43, 0.029657084494829178), (0, 0.03271650895476341), (13, 0.036061248276382685), (15, 0.04305667942389846), (16, 0.04365198872983456), (14, 0.04365939740091562), (52, 0.04578007245436311), (4, 0.05115430848672986), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.05518383393064141), (10, 0.06240202905610204), (9, 0.0897172437980771), (17, 0.18636955320835114), (18, 0.27677176147699356), (36, 0.3048461154103279), (53, 0.8830678388476372)]
computing accuracy for after removing block 26 . block score: 0.012718255748040974
removed block 26 current accuracy 0.9864 loss from initial  0.013599999999999945
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.012818. All blocks and scores: [(31, 0.012817569309845567), (30, 0.01301584206521511), (29, 0.01363685168325901), (20, 0.014475058764219284), (3, 0.014681299682706594), (37, 0.018351267790421844), (28, 0.01836001919582486), (34, 0.019276465056464076), (7, 0.019321493105962873), (50, 0.020073064835742116), (49, 0.020938759204000235), (38, 0.02154461992904544), (39, 0.0225962670519948), (46, 0.023219266207888722), (45, 0.023255801293998957), (41, 0.02341423276811838), (33, 0.02383880433626473), (48, 0.024398323148489), (51, 0.024742738576605916), (6, 0.025002859067171812), (8, 0.025038711726665497), (1, 0.025388095760717988), (40, 0.02665983443148434), (47, 0.02733475947752595), (42, 0.02795389946550131), (44, 0.028050450375303626), (43, 0.02879709075205028), (0, 0.03271650895476341), (13, 0.036061248276382685), (15, 0.04305667942389846), (52, 0.043582526966929436), (16, 0.043651989195495844), (14, 0.04365939740091562), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.05406309152022004), (2, 0.0551838343963027), (10, 0.06240202905610204), (9, 0.0897172437980771), (17, 0.18636954948306084), (18, 0.27677176147699356), (36, 0.2992885150015354), (53, 0.8849737644195557)]
computing accuracy for after removing block 31 . block score: 0.012817569309845567
removed block 31 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 30, with score 0.013016. All blocks and scores: [(30, 0.013015841599553823), (29, 0.013636852148920298), (20, 0.014475058997049928), (3, 0.014681299915537238), (37, 0.018212777795270085), (28, 0.01836001966148615), (7, 0.019321492640301585), (34, 0.019669849425554276), (50, 0.020156640093773603), (49, 0.021141209872439504), (38, 0.021776929730549455), (39, 0.023024213267490268), (45, 0.023322134045884013), (46, 0.023720957338809967), (41, 0.02372454944998026), (51, 0.024649521335959435), (48, 0.024757300736382604), (6, 0.025002859300002456), (8, 0.025038710795342922), (1, 0.025388094829395413), (33, 0.02650434453971684), (47, 0.02736758696846664), (40, 0.027465491089969873), (42, 0.028049134416505694), (44, 0.0287874611094594), (43, 0.028967605670914054), (0, 0.03271650755777955), (13, 0.0360612478107214), (15, 0.043056679889559746), (52, 0.04324783803895116), (16, 0.04365198826417327), (14, 0.043659396935254335), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.054063091054558754), (2, 0.0551838343963027), (10, 0.06240203091874719), (9, 0.08971724100410938), (17, 0.18636954948306084), (18, 0.27677175402641296), (36, 0.31426597759127617), (53, 0.8895440399646759)]
computing accuracy for after removing block 30 . block score: 0.013015841599553823
removed block 30 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.013637. All blocks and scores: [(29, 0.013636851799674332), (20, 0.014475059462711215), (3, 0.014681299915537238), (37, 0.017944879131391644), (28, 0.018360018962994218), (7, 0.019321493105962873), (34, 0.019725409569218755), (50, 0.01999170519411564), (49, 0.02131499140523374), (38, 0.02208719030022621), (45, 0.02313902135938406), (39, 0.02347451145760715), (41, 0.02387145347893238), (46, 0.024038308765739202), (51, 0.02453828905709088), (6, 0.025002859067171812), (8, 0.025038711726665497), (48, 0.025119444355368614), (1, 0.025388095062226057), (47, 0.02732791635207832), (42, 0.028182359877973795), (33, 0.028287380933761597), (40, 0.02836772403679788), (43, 0.029044683324173093), (44, 0.029352556681260467), (0, 0.03271650802344084), (13, 0.0360612478107214), (52, 0.04239492770284414), (15, 0.043056679889559746), (16, 0.04365198779851198), (14, 0.04365939786657691), (4, 0.05115430895239115), (12, 0.05150972167029977), (11, 0.054063091054558754), (2, 0.05518383299931884), (10, 0.06240202812477946), (9, 0.08971724286675453), (17, 0.18636954575777054), (18, 0.27677176892757416), (36, 0.3271830305457115), (53, 0.8959614187479019)]
computing accuracy for after removing block 29 . block score: 0.013636851799674332
removed block 29 current accuracy 0.958 loss from initial  0.04200000000000004
since last training loss: 0.03980000000000006 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.014475. All blocks and scores: [(20, 0.014475058880634606), (3, 0.014681299915537238), (37, 0.017688013147562742), (28, 0.01836001919582486), (7, 0.019321492640301585), (50, 0.019902902888134122), (34, 0.020446072798222303), (49, 0.021449922816827893), (38, 0.02283039828762412), (45, 0.02314891293644905), (41, 0.02378209843300283), (51, 0.023966894019395113), (46, 0.024161773268133402), (39, 0.024319970281794667), (6, 0.025002858601510525), (8, 0.025038712425157428), (48, 0.025131586007773876), (1, 0.025388095062226057), (47, 0.026900453492999077), (42, 0.02865857700817287), (40, 0.028860508231446147), (43, 0.029123116517439485), (44, 0.030179518274962902), (33, 0.03099356801249087), (0, 0.032716508489102125), (13, 0.036061248276382685), (52, 0.041657575871795416), (15, 0.043056679889559746), (16, 0.043651989195495844), (14, 0.04365939786657691), (4, 0.05115430848672986), (12, 0.051509722135961056), (11, 0.05406309152022004), (2, 0.05518383393064141), (10, 0.06240202812477946), (9, 0.08971724659204483), (17, 0.18636954948306084), (18, 0.27677176147699356), (36, 0.3362649790942669), (53, 0.8946184441447258)]
computing accuracy for after removing block 20 . block score: 0.014475058880634606
removed block 20 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.05700000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 3, with score 0.014681. All blocks and scores: [(3, 0.014681299915537238), (37, 0.017535289051011205), (28, 0.01847903523594141), (7, 0.019321492640301585), (50, 0.019452705746516585), (49, 0.02085146587342024), (34, 0.020893772831186652), (38, 0.02193527529016137), (45, 0.02225391985848546), (46, 0.022808663547039032), (51, 0.023012835765257478), (41, 0.023610253119841218), (39, 0.024020643439143896), (48, 0.024894542060792446), (6, 0.025002858601510525), (8, 0.02503871195949614), (1, 0.025388094829395413), (47, 0.026204761816188693), (42, 0.02830854314379394), (43, 0.028871112037450075), (40, 0.029305312084034085), (44, 0.02972460724413395), (0, 0.032716508489102125), (33, 0.03295760788023472), (13, 0.03606124874204397), (52, 0.03952924255281687), (15, 0.043056678492575884), (16, 0.04365198872983456), (14, 0.0436593983322382), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.054063089191913605), (2, 0.05518383299931884), (10, 0.0624020304530859), (9, 0.08971724286675453), (17, 0.18636955320835114), (18, 0.27677176147699356), (36, 0.3319150507450104), (53, 0.8919048309326172)]
computing accuracy for after removing block 3 . block score: 0.014681299915537238
removed block 3 current accuracy 0.9392 loss from initial  0.060799999999999965
training start
training epoch 0 val accuracy 0.7748 topk_dict {'top1': 0.7748} is_best False lr [0.1]
training epoch 1 val accuracy 0.7954 topk_dict {'top1': 0.7954} is_best False lr [0.1]
training epoch 2 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 3 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 4 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 5 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.1]
training epoch 6 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 7 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 8 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 9 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.965000)
finished training. finished 50 epochs. accuracy 0.965 topk_dict {'top1': 0.965}
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.034508. All blocks and scores: [(49, 0.03450787765905261), (50, 0.035692459903657436), (37, 0.0360211287625134), (51, 0.040151049848645926), (7, 0.0408155876211822), (39, 0.04396826680749655), (48, 0.04731661593541503), (38, 0.04738232586532831), (40, 0.048154890071600676), (41, 0.0489279511384666), (0, 0.04978851368650794), (44, 0.050743631552904844), (45, 0.05120868841186166), (46, 0.05213983589783311), (42, 0.05362338526174426), (8, 0.05480942549183965), (52, 0.05748215690255165), (47, 0.05832803109660745), (43, 0.05971808033064008), (1, 0.06092904834076762), (6, 0.0678299656137824), (34, 0.07232033926993608), (33, 0.08085354417562485), (13, 0.08119571674615145), (14, 0.0835202019661665), (16, 0.09734275564551353), (15, 0.09744193963706493), (28, 0.10745225008577108), (11, 0.11394754145294428), (12, 0.12336566764861345), (4, 0.1322412882000208), (2, 0.14520592242479324), (10, 0.14783612824976444), (9, 0.17851928062736988), (17, 0.43086767941713333), (18, 0.4958740212023258), (36, 0.7023996710777283), (53, 1.0942960530519485)]
computing accuracy for after removing block 49 . block score: 0.03450787765905261
removed block 49 current accuracy 0.9564 loss from initial  0.04359999999999997
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.036021. All blocks and scores: [(37, 0.03602112829685211), (7, 0.040815587155520916), (50, 0.04114167811349034), (39, 0.04396826680749655), (51, 0.04463834036141634), (48, 0.04731661593541503), (38, 0.0473823263309896), (40, 0.04815488960593939), (41, 0.0489279511384666), (0, 0.04978851415216923), (44, 0.050743632949888706), (45, 0.051208687014877796), (46, 0.052139836829155684), (42, 0.053623384330421686), (8, 0.05480942456051707), (47, 0.05832803249359131), (43, 0.059718078933656216), (1, 0.06092904740944505), (52, 0.06182352686300874), (6, 0.06782996747642756), (34, 0.07232033833861351), (33, 0.0808535423129797), (13, 0.08119571674615145), (14, 0.08352020289748907), (16, 0.09734275937080383), (15, 0.09744193777441978), (28, 0.10745225381106138), (11, 0.11394753307104111), (12, 0.1233656695112586), (4, 0.1322412882000208), (2, 0.1452059205621481), (10, 0.1478361301124096), (9, 0.17851928621530533), (17, 0.43086767569184303), (18, 0.4958740100264549), (36, 0.7023996636271477), (53, 1.2867869287729263)]
computing accuracy for after removing block 37 . block score: 0.03602112829685211
removed block 37 current accuracy 0.9522 loss from initial  0.047799999999999954
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.039844. All blocks and scores: [(50, 0.039843822829425335), (7, 0.04081558808684349), (51, 0.04345597233623266), (48, 0.044603688176721334), (39, 0.04511357331648469), (44, 0.04815630288794637), (41, 0.04846996022388339), (45, 0.0489129526540637), (40, 0.04895506799221039), (0, 0.0497885150834918), (46, 0.050183241721242666), (38, 0.051125193014740944), (42, 0.051880060229450464), (8, 0.05480942456051707), (47, 0.05652364110574126), (43, 0.05711124837398529), (52, 0.06039394997060299), (1, 0.060929046012461185), (6, 0.0678299656137824), (34, 0.07232033926993608), (33, 0.0808535423129797), (13, 0.0811957186087966), (14, 0.08352020476013422), (16, 0.09734275843948126), (15, 0.09744193777441978), (28, 0.10745224822312593), (11, 0.1139475367963314), (12, 0.12336566671729088), (4, 0.13224129006266594), (2, 0.1452059242874384), (10, 0.1478361338376999), (9, 0.17851928249001503), (17, 0.43086767941713333), (18, 0.4958740212023258), (36, 0.7023996785283089), (53, 1.3044736087322235)]
computing accuracy for after removing block 50 . block score: 0.039843822829425335
removed block 50 current accuracy 0.9404 loss from initial  0.059599999999999986
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 7, with score 0.040816. All blocks and scores: [(7, 0.040815587155520916), (48, 0.044603688176721334), (39, 0.04511357471346855), (44, 0.04815630288794637), (41, 0.04846996022388339), (45, 0.04891295172274113), (40, 0.04895506892353296), (51, 0.049165583215653896), (0, 0.04978851415216923), (46, 0.05018324078992009), (38, 0.05112519487738609), (42, 0.05188006069511175), (8, 0.05480942549183965), (47, 0.05652364157140255), (43, 0.05711124883964658), (1, 0.06092904740944505), (52, 0.0647612102329731), (6, 0.06782996654510498), (34, 0.07232033926993608), (33, 0.08085354138165712), (13, 0.08119571674615145), (14, 0.08352020476013422), (16, 0.09734275471419096), (15, 0.09744194149971008), (28, 0.10745224822312593), (11, 0.11394753772765398), (12, 0.12336566764861345), (4, 0.1322412844747305), (2, 0.1452059205621481), (10, 0.14783612824976444), (9, 0.17851928435266018), (17, 0.43086767941713333), (18, 0.49587399885058403), (36, 0.7023996710777283), (53, 1.495584636926651)]
computing accuracy for after removing block 7 . block score: 0.040815587155520916
removed block 7 current accuracy 0.9366 loss from initial  0.06340000000000001
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.042626. All blocks and scores: [(39, 0.04262567078694701), (44, 0.04406363796442747), (48, 0.04425991512835026), (38, 0.046590200159698725), (41, 0.04698237497359514), (45, 0.048563625663518906), (51, 0.04875937337055802), (46, 0.04900562670081854), (40, 0.049667103216052055), (0, 0.04978851368650794), (42, 0.051600645296275616), (43, 0.0550475032068789), (47, 0.056520671118050814), (1, 0.06092904508113861), (8, 0.06366585241630673), (52, 0.06474779453128576), (6, 0.06782996747642756), (34, 0.06871846877038479), (14, 0.07492645364254713), (33, 0.07661313749849796), (13, 0.07775998022407293), (16, 0.09336499404162169), (15, 0.09349157754331827), (28, 0.10051752347499132), (11, 0.11091079749166965), (12, 0.11786550004035234), (4, 0.13224128633737564), (2, 0.14520592242479324), (10, 0.14935624971985817), (9, 0.1894668973982334), (17, 0.3942718468606472), (18, 0.4770187586545944), (36, 0.676495335996151), (53, 1.5370829850435257)]
computing accuracy for after removing block 39 . block score: 0.04262567078694701
removed block 39 current accuracy 0.9242 loss from initial  0.07579999999999998
since last training loss: 0.04079999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.041331. All blocks and scores: [(48, 0.04133137874305248), (44, 0.041970106307417154), (45, 0.04633791605010629), (38, 0.046590200159698725), (41, 0.04704064130783081), (51, 0.047487030271440744), (46, 0.04887492069974542), (40, 0.04917600518092513), (0, 0.049788514617830515), (42, 0.051035468466579914), (43, 0.053546630311757326), (47, 0.05476565985009074), (1, 0.06092904647812247), (52, 0.06275554141029716), (8, 0.06366585241630673), (6, 0.06782996468245983), (34, 0.06871846877038479), (14, 0.07492645364254713), (33, 0.07661313936114311), (13, 0.07775997743010521), (16, 0.09336499404162169), (15, 0.09349157009273767), (28, 0.10051752161234617), (11, 0.11091079842299223), (12, 0.11786549910902977), (4, 0.1322412882000208), (2, 0.1452059205621481), (10, 0.14935624785721302), (9, 0.18946689367294312), (17, 0.3942718468606472), (18, 0.4770187512040138), (36, 0.6764953210949898), (53, 1.5654512792825699)]
computing accuracy for after removing block 48 . block score: 0.04133137874305248
removed block 48 current accuracy 0.9106 loss from initial  0.08940000000000003
since last training loss: 0.054400000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.041970. All blocks and scores: [(44, 0.04197010584175587), (45, 0.04633791605010629), (38, 0.04659019922837615), (41, 0.047040642239153385), (46, 0.04887491976842284), (40, 0.04917600564658642), (0, 0.04978851415216923), (42, 0.05103546753525734), (51, 0.052529480308294296), (43, 0.05354663077741861), (47, 0.054765657521784306), (1, 0.0609290455467999), (8, 0.06366585195064545), (52, 0.06760702468454838), (6, 0.0678299656137824), (34, 0.06871846877038479), (14, 0.07492645177990198), (33, 0.07661313842982054), (13, 0.07775997743010521), (16, 0.09336499031633139), (15, 0.09349157381802797), (28, 0.10051752347499132), (11, 0.11091079469770193), (12, 0.11786549724638462), (4, 0.1322412807494402), (2, 0.14520592242479324), (10, 0.14935624599456787), (9, 0.1894668973982334), (17, 0.3942718468606472), (18, 0.4770187586545944), (36, 0.6764953136444092), (53, 1.8705040365457535)]
computing accuracy for after removing block 44 . block score: 0.04197010584175587
removed block 44 current accuracy 0.8922 loss from initial  0.1078
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.046590. All blocks and scores: [(38, 0.046590198297053576), (41, 0.04704063991084695), (40, 0.049176004249602556), (0, 0.0497885150834918), (45, 0.04994547227397561), (42, 0.05103546613827348), (46, 0.051777323707938194), (51, 0.05221773684024811), (43, 0.05354662984609604), (47, 0.05694322194904089), (1, 0.06092904740944505), (8, 0.06366585427895188), (52, 0.06732319295406342), (6, 0.06782996468245983), (34, 0.06871846877038479), (14, 0.0749264508485794), (33, 0.07661313749849796), (13, 0.07775997743010521), (16, 0.09336499031633139), (15, 0.09349157102406025), (28, 0.10051752161234617), (11, 0.11091080401092768), (12, 0.1178654944524169), (4, 0.13224128633737564), (2, 0.1452059205621481), (10, 0.14935624971985817), (9, 0.18946689367294312), (17, 0.3942718431353569), (18, 0.4770187847316265), (36, 0.676495335996151), (53, 1.9150926321744919)]
computing accuracy for after removing block 38 . block score: 0.046590198297053576
removed block 38 current accuracy 0.8774 loss from initial  0.12260000000000004
training start
training epoch 0 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 1 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 2 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 3 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 4 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 5 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 6 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 7 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 8 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 9 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.948600)
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 24
[activation diff]: block to remove picked: 0, with score 0.057051. All blocks and scores: [(0, 0.05705102579668164), (41, 0.06372573785483837), (51, 0.06381446775048971), (46, 0.06385379936546087), (45, 0.06774772144854069), (52, 0.06813189946115017), (42, 0.06970262713730335), (47, 0.0740741603076458), (1, 0.07479653134942055), (40, 0.0750289736315608), (43, 0.07656432781368494), (6, 0.07817379012703896), (34, 0.08370271604508162), (33, 0.08699208591133356), (8, 0.08756100479513407), (13, 0.08835304714739323), (14, 0.0938591668382287), (15, 0.09710224624723196), (16, 0.10301143582910299), (28, 0.12351120356470346), (12, 0.1258859895169735), (11, 0.12815834768116474), (2, 0.15846595726907253), (10, 0.1729962695389986), (4, 0.1869946327060461), (9, 0.19709631986916065), (17, 0.5000773333013058), (18, 0.5476785600185394), (36, 0.6443021148443222), (53, 1.1552802920341492)]
computing accuracy for after removing block 0 . block score: 0.05705102579668164
removed block 0 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.061664. All blocks and scores: [(41, 0.06166442623361945), (46, 0.06281674792990088), (51, 0.06438068393617868), (52, 0.06739889550954103), (6, 0.06768448743969202), (45, 0.06796651054173708), (42, 0.06914791651070118), (43, 0.07221890240907669), (47, 0.07394323218613863), (1, 0.07756056170910597), (14, 0.07813365571200848), (40, 0.07818598672747612), (8, 0.07832232024520636), (13, 0.07866373844444752), (33, 0.08246306143701077), (34, 0.08248777408152819), (15, 0.08440431859344244), (16, 0.09467124380171299), (28, 0.11572382785379887), (11, 0.1197902699932456), (12, 0.12399897165596485), (2, 0.17000200226902962), (10, 0.175268879160285), (9, 0.1765249352902174), (4, 0.20962845534086227), (17, 0.45105209201574326), (18, 0.5140292122960091), (36, 0.6312920674681664), (53, 1.120817482471466)]
computing accuracy for after removing block 41 . block score: 0.06166442623361945
removed block 41 current accuracy 0.9296 loss from initial  0.07040000000000002
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.061119. All blocks and scores: [(46, 0.06111932685598731), (51, 0.06235695071518421), (45, 0.06337501388043165), (52, 0.06618603225797415), (6, 0.0676844883710146), (42, 0.07261490542441607), (43, 0.07381283398717642), (47, 0.07425439637154341), (1, 0.07756056357175112), (14, 0.0781336547806859), (40, 0.07818598859012127), (8, 0.0783223221078515), (13, 0.07866373844444752), (33, 0.08246305491775274), (34, 0.08248777315020561), (15, 0.08440431859344244), (16, 0.09467124100774527), (28, 0.11572382785379887), (11, 0.11979026533663273), (12, 0.12399897444993258), (2, 0.17000199481844902), (10, 0.17526887357234955), (9, 0.17652493715286255), (4, 0.20962845161557198), (17, 0.45105208083987236), (18, 0.5140292122960091), (36, 0.6312920674681664), (53, 1.1634616553783417)]
computing accuracy for after removing block 46 . block score: 0.06111932685598731
removed block 46 current accuracy 0.9042 loss from initial  0.0958
since last training loss: 0.044399999999999995 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 45, with score 0.063375. All blocks and scores: [(45, 0.06337501294910908), (6, 0.06768449116498232), (51, 0.06888337060809135), (52, 0.07034710887819529), (42, 0.07261490449309349), (43, 0.07381283491849899), (1, 0.07756056264042854), (14, 0.07813365384936333), (40, 0.07818598486483097), (8, 0.0783223221078515), (13, 0.07866373751312494), (33, 0.08246305771172047), (34, 0.08248777408152819), (15, 0.08440431579947472), (47, 0.09189734701067209), (16, 0.09467124659568071), (28, 0.11572382971644402), (11, 0.11979026906192303), (12, 0.12399897444993258), (2, 0.17000199668109417), (10, 0.17526888102293015), (9, 0.1765249390155077), (4, 0.20962845347821712), (17, 0.45105208829045296), (18, 0.5140292271971703), (36, 0.6312920525670052), (53, 1.3093060851097107)]
computing accuracy for after removing block 45 . block score: 0.06337501294910908
removed block 45 current accuracy 0.8798 loss from initial  0.12019999999999997
since last training loss: 0.06879999999999997 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 6, with score 0.067684. All blocks and scores: [(6, 0.06768448930233717), (52, 0.0717064393684268), (51, 0.07179121859371662), (42, 0.07261490542441607), (43, 0.07381283584982157), (1, 0.07756056450307369), (14, 0.07813365571200848), (40, 0.07818598486483097), (8, 0.07832232117652893), (13, 0.07866373844444752), (33, 0.08246305398643017), (34, 0.08248777408152819), (15, 0.08440431952476501), (16, 0.09467124566435814), (47, 0.10401073098182678), (28, 0.11572383437305689), (11, 0.11979026813060045), (12, 0.12399896886199713), (2, 0.17000200040638447), (10, 0.175268879160285), (9, 0.17652493715286255), (4, 0.20962845720350742), (17, 0.45105209201574326), (18, 0.5140292048454285), (36, 0.6312920823693275), (53, 1.4771928191184998)]
computing accuracy for after removing block 6 . block score: 0.06768448930233717
removed block 6 current accuracy 0.8672 loss from initial  0.13280000000000003
since last training loss: 0.08140000000000003 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 43, with score 0.070709. All blocks and scores: [(43, 0.07070854306221008), (51, 0.07116251718252897), (52, 0.07170253340154886), (42, 0.07190901227295399), (1, 0.07756056264042854), (40, 0.078133306466043), (33, 0.07838990446180105), (34, 0.07950967736542225), (13, 0.07968112360686064), (14, 0.08004062436521053), (15, 0.08855024725198746), (16, 0.09554195683449507), (8, 0.09682981111109257), (47, 0.1045501483604312), (28, 0.11135927494615316), (11, 0.12144376151263714), (12, 0.127889234572649), (2, 0.17000200226902962), (9, 0.18425307236611843), (10, 0.187065739184618), (4, 0.20962845534086227), (17, 0.44037073478102684), (18, 0.5157655254006386), (36, 0.6171490997076035), (53, 1.4595085978507996)]
computing accuracy for after removing block 43 . block score: 0.07070854306221008
removed block 43 current accuracy 0.8044 loss from initial  0.1956
since last training loss: 0.1442 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 51, with score 0.071780. All blocks and scores: [(51, 0.07178010419011116), (42, 0.07190901227295399), (52, 0.07268220651894808), (1, 0.0775605607777834), (40, 0.07813330460339785), (33, 0.07838990539312363), (34, 0.07950967829674482), (13, 0.07968112640082836), (14, 0.08004062250256538), (15, 0.08855024538934231), (16, 0.09554195776581764), (8, 0.09682981576770544), (28, 0.11135926935821772), (47, 0.11619896069169044), (11, 0.12144375778734684), (12, 0.12788923643529415), (2, 0.17000199854373932), (9, 0.18425306491553783), (10, 0.1870657354593277), (4, 0.20962845347821712), (17, 0.44037074223160744), (18, 0.5157655403017998), (36, 0.6171490848064423), (53, 1.591637372970581)]
computing accuracy for after removing block 51 . block score: 0.07178010419011116
removed block 51 current accuracy 0.7398 loss from initial  0.2602
since last training loss: 0.20879999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 42, with score 0.071909. All blocks and scores: [(42, 0.07190901134163141), (1, 0.07756056170910597), (40, 0.07813330739736557), (33, 0.07838990353047848), (34, 0.0795096792280674), (13, 0.07968112360686064), (14, 0.08004062343388796), (15, 0.0885502491146326), (52, 0.09004510380327702), (16, 0.09554196055978537), (8, 0.09682981111109257), (28, 0.11135927215218544), (47, 0.11619896534830332), (11, 0.12144376244395971), (12, 0.1278892382979393), (2, 0.17000199668109417), (9, 0.18425307981669903), (10, 0.18706574104726315), (4, 0.20962845347821712), (17, 0.44037073478102684), (18, 0.5157655328512192), (36, 0.6171490997076035), (53, 2.17869833111763)]
computing accuracy for after removing block 42 . block score: 0.07190901134163141
removed block 42 current accuracy 0.6178 loss from initial  0.3822
since last training loss: 0.3308 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 1, with score 0.077561. All blocks and scores: [(1, 0.07756056264042854), (40, 0.078133306466043), (33, 0.07838990073651075), (34, 0.0795096792280674), (13, 0.07968112453818321), (14, 0.08004062529653311), (52, 0.0871881078928709), (15, 0.0885502491146326), (16, 0.09554195869714022), (8, 0.09682981483638287), (47, 0.110962750390172), (28, 0.11135927494615316), (11, 0.12144376244395971), (12, 0.12788923271000385), (2, 0.17000199854373932), (9, 0.18425307050347328), (10, 0.1870657429099083), (4, 0.20962845161557198), (17, 0.44037072360515594), (18, 0.5157655477523804), (36, 0.617149107158184), (53, 2.2257652580738068)]
computing accuracy for after removing block 1 . block score: 0.07756056264042854
removed block 1 current accuracy 0.5462 loss from initial  0.4538
training start
training epoch 0 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best True lr [0.1]
training epoch 1 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best True lr [0.1]
training epoch 2 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 3 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.1]
training epoch 4 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best False lr [0.1]
training epoch 5 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 6 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 7 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 8 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 9 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 10 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.932200)
finished training. finished 50 epochs. accuracy 0.9322 topk_dict {'top1': 0.9322}
