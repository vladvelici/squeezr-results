start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009340. All blocks and scores: [(35, 0.009340325486846268), (27, 0.011103684199042618), (21, 0.011334074311889708), (31, 0.01160703890491277), (34, 0.011916786432266235), (20, 0.012414053548127413), (10, 0.012957266881130636), (29, 0.013191591599024832), (28, 0.014451422728598118), (25, 0.015047204564325511), (32, 0.015597441350109875), (26, 0.015913886949419975), (9, 0.015947437612339854), (33, 0.01621382776647806), (19, 0.016238084062933922), (30, 0.01653508166782558), (13, 0.017304430715739727), (23, 0.017807669239118695), (24, 0.018264205660670996), (47, 0.018334639258682728), (43, 0.018826094456017017), (22, 0.019027541857212782), (42, 0.01941879210062325), (39, 0.019591449527069926), (11, 0.019892502576112747), (46, 0.019984069745987654), (45, 0.020175756886601448), (40, 0.02033784124068916), (44, 0.02035037102177739), (41, 0.021346833556890488), (17, 0.022294857539236546), (14, 0.02316005458123982), (48, 0.023965090047568083), (38, 0.024251851718872786), (49, 0.025340354768559337), (37, 0.028723529540002346), (50, 0.030707397032529116), (51, 0.03621984971687198), (15, 0.037177728954702616), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.052134628873318434), (5, 0.05241671670228243), (7, 0.05547522474080324), (2, 0.06098463898524642), (16, 0.06157056335359812), (3, 0.06243071798235178), (6, 0.06518651638180017), (52, 0.07758118771016598), (1, 0.1571871768683195), (36, 0.31111687421798706), (18, 0.3824950382113457), (53, 0.8639278039336205)]
computing accuracy for after removing block 35 . block score: 0.009340325486846268
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.011104. All blocks and scores: [(27, 0.011103683500550687), (21, 0.011334074311889708), (31, 0.011607038439251482), (34, 0.011916786315850914), (20, 0.012414053897373378), (10, 0.012957266881130636), (29, 0.013191591599024832), (28, 0.014451422146521509), (25, 0.01504720444791019), (32, 0.015597441582940519), (26, 0.01591388718225062), (9, 0.01594743854366243), (33, 0.016213826835155487), (19, 0.01623808452859521), (30, 0.01653508166782558), (13, 0.01730443025007844), (23, 0.01780766947194934), (47, 0.018221579026430845), (24, 0.018264206126332283), (43, 0.018713121069595218), (22, 0.019027541624382138), (42, 0.019336250377818942), (39, 0.019576827296987176), (11, 0.019892502576112747), (46, 0.01998652284964919), (45, 0.020047926576808095), (40, 0.02029632613994181), (44, 0.020512878661975265), (41, 0.021449611522257328), (17, 0.022294857306405902), (14, 0.023160054814070463), (48, 0.02381129562854767), (38, 0.024050168227404356), (49, 0.025408401852473617), (37, 0.028856528224423528), (50, 0.0306404500734061), (51, 0.03598107350990176), (15, 0.037177728954702616), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213463120162487), (5, 0.05241671670228243), (7, 0.055475225672125816), (2, 0.060984639916568995), (16, 0.061570563819259405), (3, 0.062430717051029205), (6, 0.06518651824444532), (52, 0.07701416499912739), (1, 0.1571871805936098), (36, 0.3119105063378811), (18, 0.3824950307607651), (53, 0.873422771692276)]
computing accuracy for after removing block 27 . block score: 0.011103683500550687
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011334. All blocks and scores: [(21, 0.011334074195474386), (31, 0.011815687525086105), (34, 0.011877579498104751), (20, 0.0124140540137887), (10, 0.01295726653188467), (29, 0.013689620303921402), (28, 0.014708209200762212), (25, 0.015047203633002937), (32, 0.015121230389922857), (26, 0.015913886483758688), (9, 0.015947438310831785), (33, 0.01618849136866629), (19, 0.016238084062933922), (30, 0.016331732971593738), (13, 0.01730443094857037), (47, 0.017806177027523518), (23, 0.017807669239118695), (24, 0.018264206359162927), (43, 0.018580012023448944), (22, 0.01902754232287407), (42, 0.01939117512665689), (46, 0.0196069423109293), (39, 0.019607228692620993), (45, 0.019715042086318135), (40, 0.019747436977922916), (11, 0.019892503274604678), (44, 0.020142703549936414), (41, 0.020753073738887906), (17, 0.022294857306405902), (48, 0.022873760433867574), (14, 0.02316005458123982), (38, 0.0239896010607481), (49, 0.024799507576972246), (37, 0.02869816101156175), (50, 0.030612412141636014), (51, 0.03549663443118334), (15, 0.037177728954702616), (0, 0.04586179321631789), (12, 0.047379821073263884), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.055475224275141954), (2, 0.06098464038223028), (16, 0.06157056475058198), (3, 0.062430717051029205), (6, 0.06518651638180017), (52, 0.07554570864886045), (1, 0.15718718245625496), (36, 0.31206290796399117), (18, 0.3824950307607651), (53, 0.8803881481289864)]
computing accuracy for after removing block 21 . block score: 0.011334074195474386
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011639. All blocks and scores: [(31, 0.01163906091824174), (34, 0.011946187005378306), (20, 0.012414054246619344), (10, 0.01295726653188467), (29, 0.01387479598633945), (28, 0.014550405321642756), (25, 0.014715024968609214), (32, 0.01530939363874495), (26, 0.015426586498506367), (9, 0.01594743807800114), (30, 0.016168840462341905), (19, 0.01623808452859521), (33, 0.01623979490250349), (13, 0.017304430715739727), (23, 0.017435556277632713), (47, 0.01766685605980456), (24, 0.018116667168214917), (43, 0.01840194663964212), (42, 0.018988730618730187), (22, 0.01920809200964868), (45, 0.019360199803486466), (40, 0.01936384430155158), (39, 0.019441344775259495), (46, 0.019487919751554728), (11, 0.019892502343282104), (44, 0.020180195569992065), (41, 0.02058564033359289), (17, 0.022294857539236546), (48, 0.022515942342579365), (14, 0.02316005458123982), (38, 0.024127490585669875), (49, 0.02472286159172654), (37, 0.029028164455667138), (50, 0.03045049775391817), (51, 0.0352638135664165), (15, 0.03717772988602519), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042520567775), (4, 0.05213463073596358), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.060984638053923845), (16, 0.06157056475058198), (3, 0.062430717051029205), (6, 0.0651865154504776), (52, 0.07456282619386911), (1, 0.15718718245625496), (36, 0.3133090250194073), (18, 0.3824950382113457), (53, 0.8804345428943634)]
computing accuracy for after removing block 31 . block score: 0.01163906091824174
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012262. All blocks and scores: [(34, 0.012262115371413529), (20, 0.012414053548127413), (10, 0.012957266997545958), (29, 0.01387479668483138), (28, 0.014550405438058078), (25, 0.014715025201439857), (32, 0.015284727443940938), (26, 0.015426586382091045), (9, 0.01594743807800114), (33, 0.016090110410004854), (30, 0.01616884022951126), (19, 0.016238084295764565), (13, 0.017304430482909083), (47, 0.017389521468430758), (23, 0.017435555811971426), (43, 0.017958790296688676), (24, 0.018116667633876204), (42, 0.01855146512389183), (40, 0.01901159342378378), (45, 0.019096720730885863), (22, 0.019208091776818037), (46, 0.01932260673493147), (39, 0.01943867444060743), (11, 0.019892502343282104), (44, 0.020096177235245705), (41, 0.020399770932272077), (48, 0.022222393192350864), (17, 0.022294856840744615), (14, 0.023160054814070463), (38, 0.023856614949181676), (49, 0.024399894755333662), (37, 0.029221920995041728), (50, 0.03002141392789781), (51, 0.03500615246593952), (15, 0.037177728954702616), (0, 0.045861792750656605), (12, 0.04737982153892517), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.05547522380948067), (2, 0.060984641313552856), (16, 0.06157056475058198), (3, 0.06243071751669049), (6, 0.06518651824444532), (52, 0.07356802467256784), (1, 0.1571871805936098), (36, 0.31360404565930367), (18, 0.38249504193663597), (53, 0.8875407204031944)]
computing accuracy for after removing block 34 . block score: 0.012262115371413529
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012414. All blocks and scores: [(20, 0.012414054130204022), (10, 0.012957266764715314), (29, 0.013874796917662024), (28, 0.0145504055544734), (25, 0.014715025434270501), (32, 0.015284727443940938), (26, 0.015426586149260402), (9, 0.015947437845170498), (33, 0.016090109944343567), (30, 0.016168839996680617), (19, 0.016238084295764565), (47, 0.017113495618104935), (13, 0.017304430715739727), (23, 0.017435555811971426), (43, 0.017444000812247396), (42, 0.01795332203619182), (24, 0.018116667633876204), (40, 0.018627354176715016), (45, 0.018796850461512804), (46, 0.019162563141435385), (22, 0.019208092242479324), (39, 0.019221501192077994), (11, 0.019892502576112747), (44, 0.020024231867864728), (41, 0.020066209603101015), (48, 0.02205545175820589), (17, 0.022294857073575258), (14, 0.02316005458123982), (38, 0.023407893488183618), (49, 0.023943486157804728), (37, 0.028878843178972602), (50, 0.02955093001946807), (51, 0.03471436817198992), (15, 0.03717773035168648), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.048870422411710024), (4, 0.05213462933897972), (5, 0.052416717633605), (7, 0.05547522380948067), (2, 0.06098463758826256), (16, 0.061570560559630394), (3, 0.06243071798235178), (6, 0.0651865154504776), (52, 0.07239074725657701), (1, 0.15718717873096466), (36, 0.313132181763649), (18, 0.3824950307607651), (53, 0.8949520587921143)]
computing accuracy for after removing block 20 . block score: 0.012414054130204022
removed block 20 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012957. All blocks and scores: [(10, 0.012957266764715314), (29, 0.013561785337515175), (28, 0.01402895140927285), (25, 0.014169098110869527), (32, 0.01497860869858414), (26, 0.01498312409967184), (30, 0.015398440300486982), (9, 0.015947438776493073), (33, 0.01612044731155038), (19, 0.016238084062933922), (47, 0.01681544235907495), (43, 0.016843859339132905), (23, 0.01724750827997923), (13, 0.017304431181401014), (42, 0.017349500209093094), (24, 0.017785267904400826), (40, 0.018032792722806334), (45, 0.01834440603852272), (39, 0.018923637690022588), (46, 0.019041894702240825), (22, 0.01921574934385717), (41, 0.0196465568151325), (11, 0.019892502576112747), (44, 0.02013750490732491), (48, 0.021741406759247184), (17, 0.02229485777206719), (14, 0.023160054348409176), (38, 0.023315483005717397), (49, 0.02366255223751068), (37, 0.029045789036899805), (50, 0.029134638141840696), (51, 0.03401449788361788), (15, 0.03717772988602519), (0, 0.04586179228499532), (12, 0.04737982014194131), (8, 0.04887042613700032), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.055475224275141954), (2, 0.06098464038223028), (16, 0.06157056475058198), (3, 0.062430717051029205), (6, 0.06518651731312275), (52, 0.0706823468208313), (1, 0.1571871805936098), (36, 0.31336938217282295), (18, 0.38249505311250687), (53, 0.8989739492535591)]
computing accuracy for after removing block 10 . block score: 0.012957266764715314
removed block 10 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013780. All blocks and scores: [(29, 0.013779842760413885), (28, 0.013976978603750467), (25, 0.014224751968868077), (26, 0.014854759676381946), (32, 0.01509961485862732), (30, 0.015454858192242682), (9, 0.015947437845170498), (33, 0.016266704071313143), (13, 0.01654286589473486), (43, 0.016762647312134504), (47, 0.016782119870185852), (23, 0.01707396819256246), (19, 0.01718146982602775), (42, 0.017427340615540743), (40, 0.017764175310730934), (24, 0.017844600835815072), (45, 0.01806302764452994), (39, 0.01861978298984468), (46, 0.018768534064292908), (22, 0.01894473726861179), (41, 0.019444624660536647), (44, 0.019642784958705306), (11, 0.020282881800085306), (48, 0.02117547346279025), (17, 0.022723610512912273), (14, 0.022779475199058652), (38, 0.023119496880099177), (49, 0.023811477469280362), (37, 0.027783304685726762), (50, 0.02857796847820282), (51, 0.033666453789919615), (15, 0.03736387798562646), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.048870423808693886), (4, 0.05213462980464101), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.060984639916568995), (16, 0.06162197282537818), (3, 0.06243071658536792), (6, 0.0651865154504776), (52, 0.0700069461017847), (1, 0.1571871843189001), (36, 0.30398043990135193), (18, 0.374211173504591), (53, 0.8993167877197266)]
computing accuracy for after removing block 29 . block score: 0.013779842760413885
removed block 29 current accuracy 0.9986 loss from initial  0.0013999999999999568
training start
training epoch 0 val accuracy 0.7752 topk_dict {'top1': 0.7752} is_best False lr [0.1]
training epoch 1 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 2 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 3 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 4 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 5 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 6 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 7 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 8 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 9 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 10 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.013977. All blocks and scores: [(28, 0.013976978603750467), (25, 0.014224751736037433), (26, 0.014854759676381946), (32, 0.015656630625016987), (9, 0.015947438310831785), (33, 0.016093431506305933), (30, 0.016331066377460957), (13, 0.016542865429073572), (47, 0.016583282500505447), (43, 0.016609042417258024), (42, 0.016731814248487353), (23, 0.017073967959731817), (19, 0.01718146982602775), (40, 0.017593795899301767), (45, 0.017683780286461115), (24, 0.017844600370153785), (39, 0.01834291312843561), (46, 0.018452940741553903), (22, 0.018944737501442432), (41, 0.019309210823848844), (44, 0.019369024084880948), (11, 0.020282881101593375), (48, 0.020786920562386513), (17, 0.022723610745742917), (14, 0.02277947450056672), (38, 0.023035791469737887), (49, 0.023334231227636337), (37, 0.027782237390056252), (50, 0.027876751264557242), (51, 0.03319639666005969), (15, 0.03736387798562646), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.04887042613700032), (4, 0.05213462933897972), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.06098463945090771), (16, 0.06162197422236204), (3, 0.06243071751669049), (6, 0.0651865154504776), (52, 0.06813919451087713), (1, 0.1571871843189001), (36, 0.30388377606868744), (18, 0.3742111884057522), (53, 0.9086464643478394)]
computing accuracy for after removing block 28 . block score: 0.013976978603750467
removed block 28 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.014225. All blocks and scores: [(25, 0.01422475150320679), (26, 0.014854760142043233), (32, 0.015713009983301163), (9, 0.01594743807800114), (33, 0.016001067822799087), (47, 0.016190798487514257), (42, 0.01631853962317109), (43, 0.01633123680949211), (13, 0.01654286519624293), (30, 0.016802769619971514), (23, 0.017073968425393105), (19, 0.017181470524519682), (40, 0.017207596451044083), (45, 0.01731860777363181), (24, 0.01784460013732314), (39, 0.01789897633716464), (46, 0.018052106723189354), (22, 0.01894473726861179), (44, 0.019007600843906403), (41, 0.019063473446294665), (48, 0.020253473659977317), (11, 0.020282881800085306), (38, 0.022655860520899296), (17, 0.022723609814420342), (49, 0.022748680086806417), (14, 0.022779475199058652), (50, 0.02703481912612915), (37, 0.027097024954855442), (51, 0.03234624140895903), (15, 0.037363878451287746), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671670228243), (7, 0.05547522520646453), (2, 0.06098464084789157), (16, 0.06162197468802333), (3, 0.06243071658536792), (6, 0.06518651451915503), (52, 0.06599841080605984), (1, 0.15718717873096466), (36, 0.303010955452919), (18, 0.3742111884057522), (53, 0.9200856760144234)]
computing accuracy for after removing block 25 . block score: 0.01422475150320679
removed block 25 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014321. All blocks and scores: [(26, 0.014321206253953278), (32, 0.01572513615246862), (47, 0.01581348234321922), (9, 0.015947438310831785), (33, 0.01617535180412233), (43, 0.016194914001971483), (13, 0.01654286589473486), (42, 0.016636511543765664), (40, 0.016900551039725542), (30, 0.01692401454783976), (45, 0.017010100185871124), (23, 0.017073967959731817), (19, 0.017181470058858395), (24, 0.01784460060298443), (46, 0.017934612231329083), (39, 0.018276612041518092), (41, 0.0189382447861135), (22, 0.018944737734273076), (44, 0.018969443161040545), (48, 0.01987506542354822), (11, 0.020282881567254663), (49, 0.02230100310407579), (17, 0.022723609814420342), (14, 0.022779475431889296), (38, 0.022952501894906163), (50, 0.02660952089354396), (37, 0.02736746333539486), (51, 0.032106865430250764), (15, 0.03736387751996517), (12, 0.04314273316413164), (0, 0.045861792750656605), (8, 0.04887042427435517), (4, 0.05213462980464101), (5, 0.052416717167943716), (7, 0.05547522474080324), (2, 0.060984638053923845), (16, 0.06162197422236204), (3, 0.06243071658536792), (52, 0.0642223646864295), (6, 0.06518651824444532), (1, 0.15718718245625496), (36, 0.30919430777430534), (18, 0.3742111809551716), (53, 0.9223421737551689)]
computing accuracy for after removing block 26 . block score: 0.014321206253953278
removed block 26 current accuracy 0.9856 loss from initial  0.014399999999999968
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 47, with score 0.015591. All blocks and scores: [(47, 0.015591378789395094), (9, 0.015947438776493073), (33, 0.01611968199722469), (43, 0.016470806440338492), (13, 0.01654286589473486), (32, 0.016675117192789912), (45, 0.016848278930410743), (40, 0.01696594594977796), (23, 0.017073967959731817), (19, 0.017181470524519682), (42, 0.01737767760641873), (30, 0.017694465117529035), (46, 0.017731529427692294), (24, 0.01784460013732314), (44, 0.018625708995386958), (22, 0.0189447368029505), (39, 0.01899522077292204), (41, 0.01938954391516745), (48, 0.019601588137447834), (11, 0.020282881567254663), (49, 0.022070482140406966), (17, 0.022723609348759055), (14, 0.022779475897550583), (38, 0.02378577971830964), (50, 0.02612114930525422), (37, 0.028035481460392475), (51, 0.0319701861590147), (15, 0.037363877054303885), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.04887042474001646), (4, 0.05213462794199586), (5, 0.052416719030588865), (7, 0.05547522474080324), (2, 0.06098464038223028), (16, 0.06162197329103947), (3, 0.06243071844801307), (52, 0.06296230759471655), (6, 0.06518651638180017), (1, 0.15718718245625496), (36, 0.31919989362359047), (18, 0.374211173504591), (53, 0.9199746698141098)]
computing accuracy for after removing block 47 . block score: 0.015591378789395094
removed block 47 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.015947. All blocks and scores: [(9, 0.01594743807800114), (33, 0.016119681298732758), (43, 0.01647080690599978), (13, 0.016542866360396147), (32, 0.016675117425620556), (45, 0.016848279163241386), (40, 0.016965946182608604), (23, 0.01707396819256246), (19, 0.01718147029168904), (42, 0.01737767714075744), (30, 0.01769446604885161), (46, 0.01773153035901487), (24, 0.01784460060298443), (44, 0.018625709461048245), (22, 0.018944737501442432), (39, 0.018995220540091395), (41, 0.01938954391516745), (11, 0.02028288133442402), (48, 0.022071628365665674), (17, 0.022723609348759055), (14, 0.022779475199058652), (49, 0.023477207869291306), (38, 0.023785780649632215), (50, 0.027219211915507913), (37, 0.02803548169322312), (51, 0.03351395716890693), (15, 0.03736387938261032), (12, 0.04314273316413164), (0, 0.04586179368197918), (8, 0.04887042520567775), (4, 0.052134630270302296), (5, 0.05241671670228243), (7, 0.055475224275141954), (2, 0.06098464038223028), (16, 0.061621973756700754), (3, 0.06243071751669049), (52, 0.06439626589417458), (6, 0.06518651731312275), (1, 0.1571871805936098), (36, 0.31919989734888077), (18, 0.3742111921310425), (53, 0.9626969993114471)]
computing accuracy for after removing block 9 . block score: 0.01594743807800114
removed block 9 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.016096. All blocks and scores: [(32, 0.01609638729132712), (45, 0.01626696507446468), (43, 0.016269845189526677), (33, 0.016375446692109108), (23, 0.016607446828857064), (40, 0.016879581846296787), (46, 0.017053304240107536), (30, 0.01717839646153152), (19, 0.01734978798776865), (24, 0.01750320033170283), (44, 0.0178118662443012), (42, 0.017975984141230583), (13, 0.018235396360978484), (41, 0.018629115307703614), (22, 0.01906752143986523), (39, 0.019353311974555254), (48, 0.02096651284955442), (11, 0.021229500882327557), (14, 0.02272612787783146), (49, 0.023100799415260553), (17, 0.023560584988445044), (38, 0.02391230990178883), (50, 0.02587041282095015), (37, 0.026413641637191176), (51, 0.032382586039602757), (15, 0.03793497942388058), (12, 0.04165834281593561), (0, 0.045861792750656605), (8, 0.04887042520567775), (4, 0.052134628873318434), (5, 0.052416717167943716), (7, 0.05547522474080324), (2, 0.060984639916568995), (3, 0.06243071798235178), (52, 0.0628032754175365), (16, 0.06422330252826214), (6, 0.06518651731312275), (1, 0.1571871805936098), (36, 0.3088325299322605), (18, 0.3658624030649662), (53, 0.9575238525867462)]
computing accuracy for after removing block 32 . block score: 0.01609638729132712
removed block 32 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.016016. All blocks and scores: [(43, 0.016015663277357817), (45, 0.016113010817207396), (40, 0.01653079898096621), (23, 0.016607446828857064), (46, 0.017001276602968574), (30, 0.01717839646153152), (19, 0.017349787754938006), (24, 0.017503201263025403), (44, 0.017587421229109168), (33, 0.017657325603067875), (13, 0.018235396593809128), (42, 0.01836430188268423), (41, 0.018588943872600794), (22, 0.019067521207034588), (39, 0.019302496453747153), (48, 0.020728602539747953), (11, 0.021229500183835626), (14, 0.02272612787783146), (49, 0.022927335230633616), (17, 0.02356058545410633), (38, 0.0236231938470155), (50, 0.025466856779530644), (37, 0.025660474319010973), (51, 0.03188293590210378), (15, 0.03793498082086444), (12, 0.04165834467858076), (0, 0.045861792750656605), (8, 0.04887042660266161), (4, 0.052134628407657146), (5, 0.05241671623662114), (7, 0.05547522334381938), (2, 0.06098463898524642), (52, 0.061193055007606745), (3, 0.06243071611970663), (16, 0.06422330345958471), (6, 0.06518651638180017), (1, 0.1571871805936098), (36, 0.3131869323551655), (18, 0.3658623956143856), (53, 0.9862026795744896)]
computing accuracy for after removing block 43 . block score: 0.016015663277357817
removed block 43 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.05380000000000007 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.016531. All blocks and scores: [(40, 0.01653079898096621), (23, 0.016607446828857064), (45, 0.016902158269658685), (30, 0.017178396694362164), (19, 0.017349787754938006), (24, 0.017503201263025403), (33, 0.017657326068729162), (13, 0.01823539682663977), (46, 0.018336049281060696), (42, 0.018364302115514874), (44, 0.0185073702596128), (41, 0.018588944105431437), (22, 0.0190675207413733), (39, 0.01930249552242458), (11, 0.021229500882327557), (48, 0.0215134690515697), (14, 0.022726127412170172), (49, 0.02329544979147613), (17, 0.023560585221275687), (38, 0.023623194079846144), (37, 0.025660474319010973), (50, 0.026300599798560143), (51, 0.0323826193343848), (15, 0.03793497895821929), (12, 0.04165834281593561), (0, 0.04586179368197918), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.052416717167943716), (7, 0.05547522334381938), (2, 0.06098464038223028), (52, 0.061220892239362), (3, 0.06243071611970663), (16, 0.06422330159693956), (6, 0.06518651638180017), (1, 0.1571871843189001), (36, 0.3131869360804558), (18, 0.3658623918890953), (53, 1.0472510904073715)]
computing accuracy for after removing block 40 . block score: 0.01653079898096621
removed block 40 current accuracy 0.9298 loss from initial  0.07020000000000004
training start
training epoch 0 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 1 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 2 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 3 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 4 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.1]
training epoch 5 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 6 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 7 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 8 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 9 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 10 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.967 topk_dict {'top1': 0.967} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.967000)
finished training. finished 50 epochs. accuracy 0.967 topk_dict {'top1': 0.967}
start iteration 16
[activation diff]: block to remove picked: 19, with score 0.034465. All blocks and scores: [(19, 0.03446521842852235), (46, 0.03641529520973563), (42, 0.037330275401473045), (45, 0.04063769895583391), (44, 0.040831927210092545), (39, 0.04244134621694684), (41, 0.042757750023156404), (50, 0.04463016241788864), (48, 0.04556639678776264), (24, 0.04582518199458718), (49, 0.04695152072235942), (38, 0.04787817224860191), (13, 0.04803907219320536), (17, 0.04854739457368851), (51, 0.04906752798706293), (11, 0.05215232586488128), (33, 0.05363774253055453), (30, 0.05367746111005545), (23, 0.053795871790498495), (22, 0.0556827038526535), (37, 0.05729132238775492), (14, 0.0649532787501812), (15, 0.07887053489685059), (52, 0.08404595777392387), (12, 0.10864048730581999), (5, 0.11060584429651499), (4, 0.11068115662783384), (8, 0.11205797642469406), (0, 0.11331598367542028), (2, 0.12251570448279381), (16, 0.1258332822471857), (7, 0.13459955900907516), (6, 0.13460533879697323), (3, 0.13600358180701733), (1, 0.335006769746542), (18, 0.617404155433178), (36, 0.6674903705716133), (53, 1.0544427782297134)]
computing accuracy for after removing block 19 . block score: 0.03446521842852235
removed block 19 current accuracy 0.9624 loss from initial  0.03759999999999997
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 46, with score 0.035530. All blocks and scores: [(46, 0.03553023422136903), (42, 0.03685691114515066), (45, 0.04004107555374503), (44, 0.04007868282496929), (39, 0.04223367432132363), (41, 0.04243189934641123), (48, 0.043813707772642374), (50, 0.04388806410133839), (24, 0.04572681011632085), (49, 0.046680519822984934), (51, 0.047264705412089825), (13, 0.04803907219320536), (17, 0.04854739271104336), (38, 0.04867412755265832), (30, 0.051274267956614494), (33, 0.051430603954941034), (23, 0.05198149709030986), (11, 0.05215232539921999), (22, 0.055116045754402876), (37, 0.05763250216841698), (14, 0.06495327968150377), (15, 0.07887053489685059), (52, 0.08251520153135061), (12, 0.10864048544317484), (5, 0.11060584057122469), (4, 0.1106811547651887), (8, 0.11205798014998436), (0, 0.11331598274409771), (2, 0.12251570262014866), (16, 0.1258332785218954), (7, 0.13459956087172031), (6, 0.13460533693432808), (3, 0.13600357808172703), (1, 0.3350067660212517), (18, 0.6174041703343391), (36, 0.6668206378817558), (53, 1.0582066178321838)]
computing accuracy for after removing block 46 . block score: 0.03553023422136903
removed block 46 current accuracy 0.9578 loss from initial  0.042200000000000015
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 42, with score 0.036857. All blocks and scores: [(42, 0.03685691114515066), (45, 0.040041076485067606), (44, 0.040078683756291866), (39, 0.042233675718307495), (41, 0.04243189934641123), (24, 0.045726810581982136), (50, 0.04630297841504216), (48, 0.046948404517024755), (13, 0.04803907219320536), (49, 0.04824788123369217), (17, 0.04854739224538207), (38, 0.048674124758690596), (51, 0.04916360601782799), (30, 0.05127426888793707), (33, 0.05143060302361846), (23, 0.05198149709030986), (11, 0.0521523249335587), (22, 0.055116047617048025), (37, 0.057632502634078264), (14, 0.06495327781885862), (15, 0.07887053396552801), (52, 0.08437891490757465), (12, 0.10864049009978771), (5, 0.11060584243386984), (4, 0.1106811547651887), (8, 0.11205797642469406), (0, 0.11331597995012999), (2, 0.12251570262014866), (16, 0.12583327665925026), (7, 0.13459955900907516), (6, 0.13460534065961838), (3, 0.13600357808172703), (1, 0.3350067771971226), (18, 0.6174041852355003), (36, 0.6668206378817558), (53, 1.1029049307107925)]
computing accuracy for after removing block 42 . block score: 0.03685691114515066
removed block 42 current accuracy 0.9498 loss from initial  0.05020000000000002
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.042234. All blocks and scores: [(39, 0.04223367618396878), (41, 0.04243189888074994), (44, 0.04272611811757088), (45, 0.0432477449066937), (24, 0.04572681151330471), (50, 0.04766880255192518), (13, 0.04803907172754407), (17, 0.04854739410802722), (38, 0.04867412522435188), (48, 0.049740660935640335), (51, 0.05086589651182294), (30, 0.05127427075058222), (33, 0.05143060302361846), (49, 0.05160869425162673), (23, 0.051981497555971146), (11, 0.05215232539921999), (22, 0.05511604668572545), (37, 0.05763250309973955), (14, 0.06495327781885862), (15, 0.07887053396552801), (52, 0.08509683515876532), (12, 0.10864048730581999), (5, 0.11060584336519241), (4, 0.1106811547651887), (8, 0.11205797921866179), (0, 0.11331597995012999), (2, 0.12251570448279381), (16, 0.12583328131586313), (7, 0.13459956087172031), (6, 0.13460534065961838), (3, 0.13600357435643673), (1, 0.3350067734718323), (18, 0.6174041852355003), (36, 0.6668206378817558), (53, 1.1500948518514633)]
computing accuracy for after removing block 39 . block score: 0.04223367618396878
removed block 39 current accuracy 0.9452 loss from initial  0.05479999999999996
since last training loss: 0.02179999999999993 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.043799. All blocks and scores: [(44, 0.04379879916086793), (45, 0.044019965920597315), (41, 0.04547196859493852), (24, 0.04572681011632085), (50, 0.04656053055077791), (13, 0.04803907126188278), (17, 0.04854739224538207), (38, 0.04867412615567446), (48, 0.04968629823997617), (51, 0.05015738354995847), (30, 0.05127426888793707), (33, 0.051430603954941034), (49, 0.05170142790302634), (23, 0.051981497555971146), (11, 0.05215232539921999), (22, 0.055116045754402876), (37, 0.05763250356540084), (14, 0.06495327688753605), (15, 0.07887053303420544), (52, 0.08346390910446644), (12, 0.10864048823714256), (5, 0.11060584150254726), (4, 0.1106811547651887), (8, 0.11205797456204891), (0, 0.11331597901880741), (2, 0.12251570075750351), (16, 0.1258332822471857), (7, 0.13459956087172031), (6, 0.13460534252226353), (3, 0.13600357621908188), (1, 0.3350067734718323), (18, 0.6174041852355003), (36, 0.6668206453323364), (53, 1.1457816064357758)]
computing accuracy for after removing block 44 . block score: 0.04379879916086793
removed block 44 current accuracy 0.9334 loss from initial  0.06659999999999999
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.045472. All blocks and scores: [(41, 0.04547196952626109), (24, 0.04572681011632085), (50, 0.04674494871869683), (45, 0.047488090582191944), (13, 0.048039072658866644), (17, 0.04854739271104336), (38, 0.04867412615567446), (51, 0.0504507371224463), (30, 0.05127426888793707), (33, 0.05143060348927975), (23, 0.05198149709030986), (11, 0.0521523249335587), (48, 0.05299473740160465), (22, 0.05511604622006416), (49, 0.05518392659723759), (37, 0.05763250356540084), (14, 0.06495327781885862), (15, 0.07887053489685059), (52, 0.0806275773793459), (12, 0.10864048730581999), (5, 0.11060584150254726), (4, 0.11068115290254354), (8, 0.11205797456204891), (0, 0.11331598460674286), (2, 0.12251570541411638), (16, 0.12583327945321798), (7, 0.13459956087172031), (6, 0.13460533693432808), (3, 0.13600357249379158), (1, 0.3350067771971226), (18, 0.6174041628837585), (36, 0.6668206602334976), (53, 1.1874982118606567)]
computing accuracy for after removing block 41 . block score: 0.04547196952626109
removed block 41 current accuracy 0.917 loss from initial  0.08299999999999996
since last training loss: 0.04999999999999993 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 50, with score 0.045667. All blocks and scores: [(50, 0.04566661408171058), (24, 0.04572681011632085), (13, 0.04803906939923763), (17, 0.048547393176704645), (38, 0.048674124758690596), (45, 0.05012061586603522), (51, 0.05074930330738425), (30, 0.05127427028492093), (33, 0.05143060488626361), (48, 0.05178612424060702), (23, 0.05198149802163243), (11, 0.052152324467897415), (22, 0.05511604622006416), (37, 0.05763250309973955), (49, 0.05789576470851898), (14, 0.06495327781885862), (15, 0.07887053489685059), (52, 0.07924951612949371), (12, 0.10864048823714256), (5, 0.11060584243386984), (4, 0.1106811547651887), (8, 0.11205798014998436), (0, 0.11331598274409771), (2, 0.12251570075750351), (16, 0.12583328038454056), (7, 0.13459955900907516), (6, 0.13460533507168293), (3, 0.13600357621908188), (1, 0.335006769746542), (18, 0.6174041852355003), (36, 0.6668206602334976), (53, 1.2317960411310196)]
computing accuracy for after removing block 50 . block score: 0.04566661408171058
removed block 50 current accuracy 0.8852 loss from initial  0.11480000000000001
since last training loss: 0.08179999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.045727. All blocks and scores: [(24, 0.04572681104764342), (13, 0.04803907126188278), (17, 0.04854739224538207), (38, 0.04867412615567446), (45, 0.05012061493471265), (30, 0.05127426888793707), (33, 0.05143060442060232), (48, 0.051786127500236034), (23, 0.05198149662464857), (11, 0.0521523249335587), (22, 0.055116044357419014), (37, 0.05763250356540084), (49, 0.05789576377719641), (51, 0.059686570428311825), (14, 0.0649532750248909), (15, 0.07887053582817316), (52, 0.08447279036045074), (12, 0.10864048637449741), (5, 0.11060584429651499), (4, 0.1106811510398984), (8, 0.11205797735601664), (0, 0.11331597995012999), (2, 0.12251569889485836), (16, 0.12583327759057283), (7, 0.13459955900907516), (6, 0.13460533879697323), (3, 0.13600357435643673), (1, 0.3350067622959614), (18, 0.6174041777849197), (36, 0.666820652782917), (53, 1.3561774492263794)]
computing accuracy for after removing block 24 . block score: 0.04572681104764342
removed block 24 current accuracy 0.8822 loss from initial  0.11780000000000002
training start
training epoch 0 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 1 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 2 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 3 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 4 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 5 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 6 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 7 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.951200)
finished training. finished 50 epochs. accuracy 0.9512 topk_dict {'top1': 0.9512}
start iteration 24
[activation diff]: block to remove picked: 17, with score 0.054976. All blocks and scores: [(17, 0.054975890554487705), (13, 0.05919375456869602), (11, 0.06067446246743202), (48, 0.06436068005859852), (49, 0.06533127930015326), (51, 0.06612994987517595), (14, 0.07297875359654427), (38, 0.07327859755605459), (45, 0.07371603883802891), (23, 0.07457255944609642), (33, 0.07878388091921806), (22, 0.07999210432171822), (37, 0.08195928204804659), (30, 0.08338397741317749), (52, 0.08673123363405466), (15, 0.09182070102542639), (0, 0.1213334184139967), (12, 0.1215886790305376), (2, 0.1298743113875389), (8, 0.13221867382526398), (4, 0.13557284884154797), (5, 0.13739514537155628), (6, 0.1389167420566082), (3, 0.15620166435837746), (7, 0.15999074466526508), (16, 0.17906150594353676), (1, 0.3899344764649868), (36, 0.6056484431028366), (18, 0.6414251998066902), (53, 1.0962603241205215)]
computing accuracy for after removing block 17 . block score: 0.054975890554487705
removed block 17 current accuracy 0.9486 loss from initial  0.0514
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 13, with score 0.059194. All blocks and scores: [(13, 0.05919375317171216), (11, 0.06067446293309331), (48, 0.06407229881733656), (49, 0.06509261857718229), (51, 0.0656134495511651), (45, 0.07289887964725494), (14, 0.07297875639051199), (23, 0.07389239873737097), (38, 0.07468890026211739), (33, 0.07726091798394918), (30, 0.07900027185678482), (22, 0.07974923867732286), (37, 0.08138683903962374), (52, 0.08603712543845177), (15, 0.09182069823145866), (0, 0.12133341375738382), (12, 0.1215886753052473), (2, 0.1298743113875389), (8, 0.13221867382526398), (4, 0.13557285256683826), (5, 0.13739514164626598), (6, 0.1389167420566082), (3, 0.1562016736716032), (7, 0.15999074466526508), (16, 0.17906150966882706), (1, 0.3899344801902771), (36, 0.5986181572079659), (18, 0.6446556001901627), (53, 1.0860852599143982)]
computing accuracy for after removing block 13 . block score: 0.05919375317171216
removed block 13 current accuracy 0.9472 loss from initial  0.05279999999999996
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 11, with score 0.060674. All blocks and scores: [(11, 0.060674462001770735), (48, 0.06424356531351805), (49, 0.06473270617425442), (51, 0.06564731989055872), (23, 0.07167754136025906), (45, 0.07222351990640163), (33, 0.07465480547398329), (38, 0.07646820414811373), (14, 0.07688748091459274), (30, 0.07753246743232012), (37, 0.08119653631001711), (22, 0.08126085437834263), (52, 0.08596750255674124), (15, 0.09668456669896841), (0, 0.12133341562002897), (12, 0.12158867716789246), (2, 0.12987431325018406), (8, 0.13221867568790913), (4, 0.1355728544294834), (5, 0.13739514909684658), (6, 0.13891674019396305), (3, 0.15620166808366776), (7, 0.15999074093997478), (16, 0.21169756166636944), (1, 0.3899344801902771), (36, 0.5997314453125), (18, 0.6484307423233986), (53, 1.0661882162094116)]
computing accuracy for after removing block 11 . block score: 0.060674462001770735
removed block 11 current accuracy 0.936 loss from initial  0.06399999999999995
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 48, with score 0.064030. All blocks and scores: [(48, 0.06402968196198344), (51, 0.06533945444971323), (49, 0.06551580037921667), (23, 0.07063547242432833), (45, 0.07221749145537615), (33, 0.07226368971168995), (30, 0.07545951381325722), (37, 0.08041450474411249), (38, 0.08111180458217859), (22, 0.08194219693541527), (52, 0.08426324091851711), (14, 0.08478646911680698), (15, 0.10483745206147432), (0, 0.12133341655135155), (2, 0.12987431325018406), (8, 0.13221867009997368), (12, 0.13379656709730625), (4, 0.13557285256683826), (5, 0.13739515282213688), (6, 0.13891674391925335), (3, 0.1562016699463129), (7, 0.15999075025320053), (16, 0.22281472943723202), (1, 0.3899344764649868), (36, 0.5998615473508835), (18, 0.6470238044857979), (53, 1.0351104140281677)]
computing accuracy for after removing block 48 . block score: 0.06402968196198344
removed block 48 current accuracy 0.927 loss from initial  0.07299999999999995
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 23, with score 0.070635. All blocks and scores: [(23, 0.07063547242432833), (45, 0.07221748866140842), (33, 0.07226368971168995), (49, 0.07519909832626581), (30, 0.07545951474457979), (51, 0.07652660366147757), (37, 0.08041450381278992), (38, 0.08111180458217859), (22, 0.08194219693541527), (14, 0.08478647284209728), (52, 0.08877674955874681), (15, 0.1048374529927969), (0, 0.12133341655135155), (2, 0.1298743113875389), (8, 0.13221867568790913), (12, 0.13379656709730625), (4, 0.1355728544294834), (5, 0.13739514909684658), (6, 0.13891674391925335), (3, 0.1562016699463129), (7, 0.15999074839055538), (16, 0.22281472571194172), (1, 0.3899344839155674), (36, 0.5998615324497223), (18, 0.6470238417387009), (53, 1.1135116815567017)]
computing accuracy for after removing block 23 . block score: 0.07063547242432833
removed block 23 current accuracy 0.9004 loss from initial  0.09960000000000002
since last training loss: 0.05080000000000007 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 33, with score 0.067157. All blocks and scores: [(33, 0.06715711858123541), (45, 0.0695451470091939), (49, 0.07285911776125431), (51, 0.0755689637735486), (30, 0.07605146337300539), (22, 0.0819421960040927), (38, 0.08312252536416054), (52, 0.08448902890086174), (14, 0.08478646818548441), (37, 0.08491093944758177), (15, 0.10483745113015175), (0, 0.1213334146887064), (2, 0.12987431325018406), (8, 0.13221867568790913), (12, 0.1337965652346611), (4, 0.13557285070419312), (5, 0.13739514537155628), (6, 0.1389167420566082), (3, 0.1562016699463129), (7, 0.15999074466526508), (16, 0.22281472757458687), (1, 0.3899344876408577), (36, 0.6067546904087067), (18, 0.6470238044857979), (53, 1.0816579461097717)]
computing accuracy for after removing block 33 . block score: 0.06715711858123541
removed block 33 current accuracy 0.8746 loss from initial  0.12539999999999996
since last training loss: 0.0766 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 45, with score 0.068860. All blocks and scores: [(45, 0.06885953154414892), (49, 0.07429135497659445), (51, 0.07440924737602472), (30, 0.07605146616697311), (22, 0.08194219786673784), (52, 0.08296810276806355), (14, 0.08478646911680698), (38, 0.08552811108529568), (37, 0.08937935810536146), (15, 0.10483745206147432), (0, 0.12133341375738382), (2, 0.12987431325018406), (8, 0.13221867196261883), (12, 0.1337965652346611), (4, 0.13557284884154797), (5, 0.13739514537155628), (6, 0.1389167457818985), (3, 0.15620167180895805), (7, 0.15999074280261993), (16, 0.22281473502516747), (1, 0.3899344801902771), (36, 0.6330881342291832), (18, 0.6470238268375397), (53, 1.0798104852437973)]
computing accuracy for after removing block 45 . block score: 0.06885953154414892
removed block 45 current accuracy 0.8292 loss from initial  0.17079999999999995
since last training loss: 0.122 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 30, with score 0.076051. All blocks and scores: [(30, 0.07605146709829569), (51, 0.07885681372135878), (49, 0.07958838529884815), (22, 0.0819421960040927), (52, 0.08273069001734257), (14, 0.08478646818548441), (38, 0.0855281138792634), (37, 0.08937935810536146), (15, 0.10483745019882917), (0, 0.12133341748267412), (2, 0.12987430952489376), (8, 0.13221867382526398), (12, 0.13379656337201595), (4, 0.13557284884154797), (5, 0.13739514723420143), (6, 0.13891674391925335), (3, 0.15620166808366776), (7, 0.15999074093997478), (16, 0.22281473316252232), (1, 0.3899344801902771), (36, 0.6330881491303444), (18, 0.6470238044857979), (53, 1.1732463985681534)]
computing accuracy for after removing block 30 . block score: 0.07605146709829569
removed block 30 current accuracy 0.7822 loss from initial  0.2178
since last training loss: 0.16900000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 49, with score 0.077188. All blocks and scores: [(49, 0.07718835957348347), (51, 0.0803047614172101), (52, 0.08181286696344614), (22, 0.0819421960040927), (14, 0.08478646911680698), (38, 0.0871362816542387), (37, 0.09328455291688442), (15, 0.10483745019882917), (0, 0.1213334146887064), (2, 0.1298743113875389), (8, 0.13221867009997368), (12, 0.13379656709730625), (4, 0.1355728544294834), (5, 0.13739514537155628), (6, 0.1389167457818985), (3, 0.1562016699463129), (7, 0.15999074466526508), (16, 0.2228147406131029), (1, 0.3899344801902771), (18, 0.6470238193869591), (36, 0.6671282351016998), (53, 1.1793510913848877)]
computing accuracy for after removing block 49 . block score: 0.07718835957348347
removed block 49 current accuracy 0.6788 loss from initial  0.32120000000000004
training start
training epoch 0 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.1]
training epoch 1 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 2 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 3 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.1]
training epoch 5 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 6 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 7 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 8 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best True lr [0.1]
training epoch 10 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
