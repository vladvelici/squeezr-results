start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.008455108851194382), (30, 0.009703245596028864), (33, 0.011115942848846316), (34, 0.011622710153460503), (31, 0.012275203014723957), (28, 0.012290219776332378), (29, 0.01479124859906733), (27, 0.016729247989133), (26, 0.01744490279816091), (1, 0.018259593285620213), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.01964871073141694), (35, 0.01978794764727354), (24, 0.020829483401030302), (22, 0.02102166088297963), (23, 0.021574513288214803), (47, 0.02254638448357582), (44, 0.023842158261686563), (41, 0.024168546544387937), (46, 0.024651075713336468), (6, 0.024668580386787653), (21, 0.025249342899769545), (43, 0.02580355340614915), (10, 0.026363695971667767), (42, 0.02642606943845749), (4, 0.026659545255824924), (45, 0.02682359190657735), (39, 0.026881905272603035), (40, 0.02689355262555182), (49, 0.02785642584785819), (48, 0.02849160390906036), (50, 0.028780476422980428), (11, 0.029002359602600336), (38, 0.029662921326234937), (3, 0.03227203991264105), (13, 0.03333653602749109), (37, 0.035762056708335876), (20, 0.03646321874111891), (12, 0.03799272142350674), (9, 0.03963937098160386), (51, 0.03964210720732808), (19, 0.04421887407079339), (52, 0.04580832691863179), (15, 0.04691674746572971), (14, 0.04904163675382733), (2, 0.05722745647653937), (0, 0.05888257594779134), (16, 0.062252288684248924), (5, 0.09379573818296194), (17, 0.2543222941458225), (36, 0.41727547720074654), (18, 0.4852069281041622), (53, 0.7453346699476242)]
computing accuracy for after removing block 32 . block score: 0.008455108851194382
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.00970324594527483), (33, 0.011199890170246363), (34, 0.011937809525988996), (31, 0.012275203014723957), (28, 0.012290219659917057), (29, 0.01479124859906733), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.01825959305278957), (7, 0.01837918604724109), (8, 0.019532452570274472), (25, 0.019648710498586297), (35, 0.020431342301890254), (24, 0.020829484332352877), (22, 0.021021660650148988), (23, 0.02157451375387609), (47, 0.02226210874505341), (44, 0.023293233010917902), (41, 0.023795815417543054), (46, 0.02404359495267272), (6, 0.024668579921126366), (21, 0.025249343598261476), (43, 0.02552505722269416), (42, 0.026236766250804067), (40, 0.026315772673115134), (10, 0.026363695738837123), (4, 0.026659545954316854), (45, 0.026667138328775764), (39, 0.02688687131740153), (49, 0.0273270255420357), (48, 0.02791151450946927), (50, 0.028208705130964518), (38, 0.02861060807481408), (11, 0.029002359602600336), (3, 0.032272040378302336), (13, 0.03333653602749109), (37, 0.03469931660220027), (20, 0.03646321967244148), (12, 0.03799272142350674), (51, 0.03937024995684624), (9, 0.03963937098160386), (19, 0.04421887593343854), (52, 0.04512502206489444), (15, 0.04691674932837486), (14, 0.04904163721948862), (2, 0.0572274555452168), (0, 0.05888257687911391), (16, 0.06225228775292635), (5, 0.09379573818296194), (17, 0.2543222904205322), (36, 0.4077853001654148), (18, 0.4852069169282913), (53, 0.7581149116158485)]
computing accuracy for after removing block 30 . block score: 0.00970324594527483
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006428726017), (34, 0.011887529050000012), (28, 0.012290219310671091), (31, 0.012499804957769811), (29, 0.01479124859906733), (27, 0.016729247989133), (26, 0.01744490279816091), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.019532452803105116), (25, 0.019648710498586297), (35, 0.02071700361557305), (24, 0.020829484332352877), (22, 0.021021660650148988), (23, 0.021574513521045446), (47, 0.02210709871724248), (44, 0.023113694041967392), (46, 0.023742160527035594), (41, 0.0239292006008327), (6, 0.02466858015395701), (21, 0.025249343132600188), (43, 0.025264927186071873), (40, 0.026247450383380055), (10, 0.026363695971667767), (42, 0.02652742387726903), (4, 0.026659545255824924), (45, 0.026712610851973295), (39, 0.027034528786316514), (49, 0.027338512474671006), (48, 0.02790993871167302), (50, 0.0279565101955086), (38, 0.028708982979878783), (11, 0.02900235867127776), (3, 0.0322720417752862), (13, 0.033336535561829805), (37, 0.03434832626953721), (20, 0.03646322013810277), (12, 0.03799272095784545), (51, 0.03913323301821947), (9, 0.039639370050281286), (19, 0.04421887453645468), (52, 0.04478001827374101), (15, 0.04691675025969744), (14, 0.049041638150811195), (2, 0.05722745833918452), (0, 0.058882574550807476), (16, 0.06225228728726506), (5, 0.09379573725163937), (17, 0.25432227924466133), (36, 0.40603339299559593), (18, 0.4852069206535816), (53, 0.7581836432218552)]
computing accuracy for after removing block 33 . block score: 0.011317006428726017
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.01224008237477392), (28, 0.012290219310671091), (31, 0.012499805423431098), (29, 0.014791248715482652), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532453501597047), (25, 0.01964871073141694), (24, 0.020829484099522233), (22, 0.021021660650148988), (35, 0.02147724572569132), (23, 0.021574513986706734), (47, 0.02193373069167137), (44, 0.022819968406111002), (46, 0.023398497607558966), (41, 0.02404660196043551), (6, 0.024668579921126366), (21, 0.02524934452958405), (43, 0.0254047648049891), (40, 0.026019646786153316), (10, 0.02636369550600648), (4, 0.026659545954316854), (42, 0.026750181335955858), (45, 0.026783812791109085), (49, 0.027069833828136325), (39, 0.027496121358126402), (48, 0.027574571082368493), (50, 0.027946369955316186), (38, 0.02873630286194384), (11, 0.029002358904108405), (3, 0.032272040378302336), (13, 0.033336535561829805), (37, 0.03405904909595847), (20, 0.03646321827545762), (12, 0.03799272095784545), (51, 0.03880898095667362), (9, 0.03963937098160386), (19, 0.04421887453645468), (52, 0.044503950513899326), (15, 0.046916748862713575), (14, 0.04904163861647248), (2, 0.05722745694220066), (0, 0.05888257548213005), (16, 0.062252288684248924), (5, 0.09379573818296194), (17, 0.25432228669524193), (36, 0.40450604259967804), (18, 0.4852069243788719), (53, 0.7641192898154259)]
computing accuracy for after removing block 34 . block score: 0.01224008237477392
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.012290219543501735), (31, 0.012499805656261742), (29, 0.014791248715482652), (27, 0.016729248221963644), (26, 0.017444903030991554), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.019532452570274472), (25, 0.019648710964247584), (24, 0.020829483401030302), (22, 0.021021660650148988), (23, 0.021574512822553515), (35, 0.021708655869588256), (47, 0.021801754599437118), (44, 0.022438113344833255), (46, 0.02333691017702222), (41, 0.023686284199357033), (6, 0.02466858085244894), (21, 0.025249343365430832), (43, 0.025404840474948287), (40, 0.025569377932697535), (10, 0.02636369550600648), (42, 0.026551801478490233), (39, 0.026582872262224555), (49, 0.026649242034181952), (4, 0.026659546187147498), (45, 0.026776784099638462), (48, 0.026865947293117642), (50, 0.027566451113671064), (38, 0.027829119469970465), (11, 0.02900235867127776), (3, 0.03227204084396362), (37, 0.03319812100380659), (13, 0.03333653509616852), (20, 0.03646321874111891), (12, 0.03799272142350674), (51, 0.03805992705747485), (9, 0.03963937098160386), (52, 0.04353108024224639), (19, 0.044218876864761114), (15, 0.046916747000068426), (14, 0.04904163675382733), (2, 0.05722745414823294), (0, 0.058882576413452625), (16, 0.062252290546894073), (5, 0.09379573538899422), (17, 0.25432228296995163), (36, 0.3958275467157364), (18, 0.4852069243788719), (53, 0.7794358432292938)]
computing accuracy for after removing block 28 . block score: 0.012290219543501735
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645366333425), (29, 0.014790621004067361), (27, 0.016729248221963644), (26, 0.017444903263822198), (1, 0.01825959258712828), (7, 0.01837918604724109), (8, 0.019532452803105116), (25, 0.01964871142990887), (24, 0.020829483401030302), (22, 0.02102166088297963), (47, 0.021346518071368337), (23, 0.021574512822553515), (35, 0.02159673278219998), (44, 0.021918716840445995), (46, 0.02273467555642128), (41, 0.023228028090670705), (6, 0.024668579921126366), (40, 0.024839135352522135), (43, 0.024858605582267046), (21, 0.02524934383109212), (39, 0.02596626291051507), (48, 0.02597146457992494), (42, 0.02599131502211094), (49, 0.026064811274409294), (10, 0.026363695971667767), (45, 0.026453920174390078), (4, 0.026659545954316854), (50, 0.026680127950385213), (38, 0.027020083274692297), (11, 0.029002359602600336), (37, 0.032236403319984674), (3, 0.03227204084396362), (13, 0.03333653509616852), (20, 0.03646321780979633), (51, 0.03758792392909527), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.04288490163162351), (19, 0.044218876864761114), (15, 0.046916747931391), (14, 0.049041638150811195), (2, 0.05722745647653937), (0, 0.05888257548213005), (16, 0.062252288684248924), (5, 0.09379573632031679), (17, 0.25432228296995163), (36, 0.3858989290893078), (18, 0.4852069281041622), (53, 0.7881819233298302)]
computing accuracy for after removing block 31 . block score: 0.011874645366333425
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.014790620421990752), (27, 0.016729247756302357), (26, 0.01744490349665284), (1, 0.018259592354297638), (7, 0.018379185115918517), (8, 0.019532452570274472), (25, 0.019648710964247584), (24, 0.020829483633860946), (47, 0.020932046929374337), (22, 0.021021660650148988), (44, 0.021379181183874607), (23, 0.021574513288214803), (46, 0.022063189884647727), (35, 0.022440450033172965), (41, 0.022648891666904092), (40, 0.02413078141398728), (43, 0.02466420759446919), (6, 0.02466857945546508), (21, 0.0252493426669389), (48, 0.02525039715692401), (49, 0.02551580942235887), (42, 0.025626871502026916), (39, 0.025647579692304134), (38, 0.025854781735688448), (50, 0.025972345611080527), (45, 0.026165933581069112), (10, 0.02636369620449841), (4, 0.02665954572148621), (11, 0.029002359602600336), (37, 0.03128928737714887), (3, 0.03227203991264105), (13, 0.03333653602749109), (20, 0.03646321874111891), (51, 0.03728976007550955), (12, 0.03799272142350674), (9, 0.039639370515942574), (52, 0.04199218424037099), (19, 0.04421887546777725), (15, 0.04691674839705229), (14, 0.04904163861647248), (2, 0.0572274555452168), (0, 0.05888257501646876), (16, 0.06225228775292635), (5, 0.09379573725163937), (17, 0.2543222904205322), (36, 0.3760597035288811), (18, 0.4852069243788719), (53, 0.8019541054964066)]
computing accuracy for after removing block 29 . block score: 0.014790620421990752
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729247989133), (26, 0.01744490396231413), (1, 0.01825959258712828), (7, 0.018379185581579804), (8, 0.019532452570274472), (25, 0.019648710498586297), (47, 0.020515700103715062), (24, 0.020829483633860946), (44, 0.020975132007151842), (22, 0.021021661115810275), (23, 0.02157451305538416), (46, 0.021652452182024717), (41, 0.02266181749291718), (35, 0.02272362424992025), (40, 0.023883074754849076), (43, 0.024189722957089543), (6, 0.024668579921126366), (48, 0.024881582241505384), (49, 0.025212351698428392), (42, 0.02522930083796382), (21, 0.02524934383109212), (38, 0.025457143783569336), (50, 0.025512878550216556), (39, 0.025584626942873), (45, 0.026210954878479242), (10, 0.026363695738837123), (4, 0.026659546419978142), (11, 0.029002358205616474), (37, 0.03110239445231855), (3, 0.03227203991264105), (13, 0.03333653509616852), (20, 0.036463219206780195), (51, 0.03752173809334636), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.041576670948415995), (19, 0.04421887453645468), (15, 0.04691675025969744), (14, 0.04904163768514991), (2, 0.057227456010878086), (0, 0.058882576413452625), (16, 0.062252288684248924), (5, 0.09379573818296194), (17, 0.25432227924466133), (36, 0.374427892267704), (18, 0.4852069243788719), (53, 0.8058174252510071)]
computing accuracy for after removing block 27 . block score: 0.016729247989133
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 1 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 2 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 3 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.1]
training epoch 4 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.1]
training epoch 5 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.1]
training epoch 6 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 7 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.1]
training epoch 8 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017445. All blocks and scores: [(26, 0.017444903263822198), (1, 0.018259593285620213), (7, 0.018379185581579804), (8, 0.01953245303593576), (25, 0.019648710498586297), (47, 0.020196364726871252), (44, 0.020198779879137874), (24, 0.020829483633860946), (22, 0.021021660650148988), (46, 0.021314961835741997), (23, 0.021574513986706734), (35, 0.02166120195761323), (41, 0.022262451704591513), (40, 0.023434571223333478), (43, 0.02366974879987538), (48, 0.023870017612352967), (49, 0.024273038376122713), (39, 0.02463195798918605), (6, 0.024668580386787653), (50, 0.024705925956368446), (38, 0.02471397095359862), (42, 0.02476488775573671), (21, 0.025249344063922763), (45, 0.025909220334142447), (10, 0.02636369550600648), (4, 0.026659546187147498), (11, 0.029002359369769692), (37, 0.030295761534944177), (3, 0.032272040378302336), (13, 0.03333653463050723), (20, 0.03646321967244148), (51, 0.03686857596039772), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.04049280658364296), (19, 0.04421887453645468), (15, 0.04691675025969744), (14, 0.049041638150811195), (2, 0.0572274555452168), (0, 0.05888257594779134), (16, 0.06225228775292635), (5, 0.09379573725163937), (17, 0.25432228296995163), (36, 0.3650362640619278), (18, 0.4852069281041622), (53, 0.8347273245453835)]
computing accuracy for after removing block 26 . block score: 0.017444903263822198
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018260. All blocks and scores: [(1, 0.01825959305278957), (7, 0.018379185581579804), (8, 0.01953245233744383), (25, 0.019648710498586297), (44, 0.019705433631315827), (47, 0.01974601368419826), (46, 0.02080916124396026), (24, 0.020829483401030302), (22, 0.021021660650148988), (35, 0.02119597140699625), (23, 0.021574512589722872), (41, 0.022163193440064788), (48, 0.022673571715131402), (40, 0.022844478487968445), (43, 0.023211446590721607), (49, 0.023580189794301987), (38, 0.02393691544421017), (39, 0.02414303575642407), (50, 0.024241250939667225), (42, 0.024461104767397046), (6, 0.02466858015395701), (21, 0.025249343365430832), (45, 0.025508656399324536), (10, 0.026363695738837123), (4, 0.026659545488655567), (11, 0.02900235867127776), (37, 0.029677377548068762), (3, 0.03227204084396362), (13, 0.03333653463050723), (51, 0.03632144629955292), (20, 0.03646321874111891), (12, 0.03799272049218416), (9, 0.039639370050281286), (52, 0.03989553265273571), (19, 0.04421887593343854), (15, 0.04691674979403615), (14, 0.04904163861647248), (2, 0.0572274592705071), (0, 0.058882576413452625), (16, 0.06225228775292635), (5, 0.09379573725163937), (17, 0.25432228296995163), (36, 0.36152271181344986), (18, 0.4852069243788719), (53, 0.8471468612551689)]
computing accuracy for after removing block 1 . block score: 0.01825959305278957
removed block 1 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017854. All blocks and scores: [(7, 0.017853511730208993), (8, 0.01868281955830753), (25, 0.019129085820168257), (44, 0.019602667540311813), (24, 0.019680223194882274), (47, 0.019842988811433315), (22, 0.020383452996611595), (35, 0.020452446537092328), (46, 0.02082586125470698), (23, 0.021086917957291007), (41, 0.0216403363738209), (48, 0.02230572863481939), (40, 0.022332167020067573), (43, 0.022896901238709688), (38, 0.023239595349878073), (39, 0.023386763874441385), (49, 0.023744063917547464), (50, 0.02402120432816446), (6, 0.024041746277362108), (42, 0.02427849150262773), (21, 0.02437790879048407), (45, 0.025495618116110563), (10, 0.025961281266063452), (11, 0.028003806713968515), (4, 0.028626713203266263), (37, 0.029063857393339276), (3, 0.03240096475929022), (13, 0.03324462892487645), (20, 0.03517247596755624), (51, 0.0365655655041337), (12, 0.03718129266053438), (9, 0.038683032151311636), (52, 0.0396947106346488), (19, 0.04354847967624664), (15, 0.04737107688561082), (14, 0.048121773172169924), (2, 0.05715902289375663), (0, 0.058882574550807476), (16, 0.060861749574542046), (5, 0.09224656410515308), (17, 0.2509492505341768), (36, 0.34972938150167465), (18, 0.46861378848552704), (53, 0.8498541191220284)]
computing accuracy for after removing block 7 . block score: 0.017853511730208993
removed block 7 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.018390. All blocks and scores: [(25, 0.018389767035841942), (24, 0.018951865611597896), (35, 0.01924196002073586), (47, 0.019434642978012562), (44, 0.019624897511675954), (23, 0.019739443669095635), (22, 0.01995630143210292), (8, 0.01996665634214878), (46, 0.02043476584367454), (41, 0.02130422624759376), (40, 0.021420422475785017), (48, 0.021825639298185706), (43, 0.02223287569358945), (38, 0.022553730057552457), (39, 0.02290530619211495), (21, 0.02331746951676905), (50, 0.023608924821019173), (49, 0.023631910560652614), (42, 0.024006218882277608), (6, 0.02404174581170082), (45, 0.02504535624757409), (10, 0.026167658856138587), (11, 0.02802672004327178), (37, 0.02840108796954155), (4, 0.028626713436096907), (3, 0.03240096475929022), (13, 0.03292407561093569), (20, 0.034043310675770044), (51, 0.03644962003454566), (12, 0.03690121369436383), (52, 0.03922955924645066), (9, 0.03934459341689944), (19, 0.04198857629671693), (15, 0.046306459698826075), (14, 0.047303912695497274), (2, 0.05715902289375663), (0, 0.05888257594779134), (16, 0.059412579983472824), (5, 0.09224656503647566), (17, 0.2388458512723446), (36, 0.3409247435629368), (18, 0.45438623428344727), (53, 0.8508737534284592)]
computing accuracy for after removing block 25 . block score: 0.018389767035841942
removed block 25 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.018641. All blocks and scores: [(35, 0.018640689784660935), (24, 0.018951865611597896), (47, 0.019162753829732537), (44, 0.019372919341549277), (23, 0.019739443669095635), (22, 0.01995630143210292), (8, 0.019966655410826206), (46, 0.0201800677459687), (41, 0.02079282863996923), (40, 0.020806472981348634), (48, 0.021095545263960958), (38, 0.02166480990126729), (43, 0.022042255382984877), (39, 0.022102958522737026), (50, 0.022921856958419085), (49, 0.02298674383200705), (21, 0.02331746998243034), (42, 0.023690476780757308), (6, 0.024041746277362108), (45, 0.025103285210207105), (10, 0.02616765769198537), (37, 0.027708852430805564), (11, 0.02802672004327178), (4, 0.028626712039113045), (3, 0.032400965224951506), (13, 0.0329240751452744), (20, 0.034043310675770044), (51, 0.035923190880566835), (12, 0.03690121369436383), (52, 0.03849219577386975), (9, 0.03934459341689944), (19, 0.04198857396841049), (15, 0.04630645737051964), (14, 0.047303915489465), (2, 0.05715902103111148), (0, 0.05888257548213005), (16, 0.05941257858648896), (5, 0.09224656503647566), (17, 0.23884584195911884), (36, 0.33257048204541206), (18, 0.4543862156569958), (53, 0.8579950109124184)]
computing accuracy for after removing block 35 . block score: 0.018640689784660935
removed block 35 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.013799999999999923 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.018301. All blocks and scores: [(47, 0.01830139895901084), (44, 0.018879120238125324), (24, 0.01895186514593661), (48, 0.019549657125025988), (46, 0.01955736498348415), (40, 0.019585497211664915), (23, 0.01973944390192628), (22, 0.019956301199272275), (8, 0.01996665564365685), (41, 0.019993557827547193), (38, 0.020276635885238647), (39, 0.02071825321763754), (43, 0.021324648754671216), (50, 0.02192226378247142), (49, 0.022055699257180095), (42, 0.022884832927957177), (21, 0.023317469749599695), (6, 0.024041746044531465), (45, 0.0242677831556648), (10, 0.0261676583904773), (37, 0.026483883149921894), (11, 0.028026720974594355), (4, 0.02862671366892755), (3, 0.032400965224951506), (13, 0.03292407467961311), (20, 0.03404330927878618), (51, 0.03433887893334031), (12, 0.03690121369436383), (52, 0.03733885241672397), (9, 0.039344592951238155), (19, 0.04198857629671693), (15, 0.0463064587675035), (14, 0.047303914558142424), (2, 0.05715902103111148), (0, 0.05888257920742035), (16, 0.05941257951781154), (5, 0.09224656689912081), (17, 0.238845843821764), (36, 0.31887491047382355), (18, 0.45438624545931816), (53, 0.8835926875472069)]
computing accuracy for after removing block 47 . block score: 0.01830139895901084
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.017999999999999905 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.018879. All blocks and scores: [(44, 0.01887912000529468), (24, 0.018951865378767252), (46, 0.019557365449145436), (40, 0.01958549744449556), (23, 0.01973944390192628), (22, 0.019956301199272275), (8, 0.019966655876487494), (41, 0.019993558526039124), (48, 0.020102362846955657), (38, 0.02027663611806929), (39, 0.020718253683298826), (43, 0.021324648754671216), (42, 0.02288483246229589), (50, 0.02293519163504243), (49, 0.023261676775291562), (21, 0.02331746951676905), (6, 0.02404174511320889), (45, 0.024267783854156733), (10, 0.0261676583904773), (37, 0.026483883149921894), (11, 0.028026720508933067), (4, 0.028626712737604976), (3, 0.032400963827967644), (13, 0.03292407467961311), (20, 0.03404331114143133), (51, 0.03476384421810508), (12, 0.03690121416002512), (52, 0.037515231873840094), (9, 0.03934459341689944), (19, 0.041988576762378216), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.057159020099788904), (0, 0.0588825773447752), (16, 0.0594125809147954), (5, 0.09224656503647566), (17, 0.23884584568440914), (36, 0.31887492164969444), (18, 0.45438622683286667), (53, 0.9607554450631142)]
computing accuracy for after removing block 44 . block score: 0.01887912000529468
removed block 44 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.018952. All blocks and scores: [(24, 0.018951865611597896), (40, 0.01958549697883427), (23, 0.019739444134756923), (22, 0.019956301897764206), (8, 0.019966656109318137), (41, 0.019993558060377836), (38, 0.020276636350899935), (48, 0.020389965269714594), (46, 0.02057383698411286), (39, 0.02071825391612947), (43, 0.021324649220332503), (42, 0.02288483246229589), (50, 0.0231245718896389), (21, 0.02331746951676905), (49, 0.023369598435238004), (6, 0.024041746743023396), (45, 0.024384557968005538), (10, 0.02616765908896923), (37, 0.02648388361558318), (11, 0.028026720276102424), (4, 0.028626712737604976), (3, 0.032400963827967644), (13, 0.03292407467961311), (20, 0.034043310675770044), (51, 0.03477862384170294), (12, 0.03690121462568641), (52, 0.03756985114887357), (9, 0.03934459341689944), (19, 0.04198857629671693), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.05715902242809534), (0, 0.05888257548213005), (16, 0.05941257951781154), (5, 0.09224656503647566), (17, 0.23884584568440914), (36, 0.31887492910027504), (18, 0.45438621938228607), (53, 1.0215267166495323)]
computing accuracy for after removing block 24 . block score: 0.018951865611597896
removed block 24 current accuracy 0.9534 loss from initial  0.046599999999999975
training start
training epoch 0 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 1 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 3 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 4 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 5 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 6 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 7 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.1]
training epoch 8 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 10 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.967 topk_dict {'top1': 0.967} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.968 topk_dict {'top1': 0.968} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.972800)
finished training. finished 50 epochs. accuracy 0.9728 topk_dict {'top1': 0.9728}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.037737. All blocks and scores: [(50, 0.0377371096983552), (46, 0.03840478416532278), (41, 0.03865524334833026), (49, 0.03942858474329114), (8, 0.04036961309611797), (43, 0.04209314286708832), (48, 0.042206799145787954), (40, 0.042324003763496876), (4, 0.04372081719338894), (51, 0.04502107808366418), (42, 0.04575537983328104), (52, 0.04579773359000683), (39, 0.04626052547246218), (45, 0.04646327393129468), (6, 0.04701122408732772), (10, 0.049487280659377575), (38, 0.0534485187381506), (11, 0.05361197143793106), (23, 0.05448409169912338), (37, 0.0584458289667964), (22, 0.05855120858177543), (13, 0.06254872865974903), (21, 0.06484491378068924), (3, 0.06846655998378992), (9, 0.06869058404117823), (20, 0.07293087057769299), (19, 0.07670277170836926), (12, 0.08214549627155066), (15, 0.09136157017201185), (2, 0.09991287346929312), (14, 0.10025392286479473), (0, 0.11159023176878691), (16, 0.12420983240008354), (5, 0.18669125996530056), (17, 0.43231241405010223), (18, 0.6339604407548904), (36, 0.7521690726280212), (53, 0.8968735262751579)]
computing accuracy for after removing block 50 . block score: 0.0377371096983552
removed block 50 current accuracy 0.9654 loss from initial  0.034599999999999964
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 46, with score 0.038405. All blocks and scores: [(46, 0.03840478556230664), (41, 0.03865524334833026), (49, 0.03942858520895243), (8, 0.04036961309611797), (43, 0.042093143332749605), (48, 0.04220679868012667), (40, 0.04232400329783559), (4, 0.043720816262066364), (42, 0.04575537983328104), (39, 0.04626052500680089), (45, 0.046463272999972105), (6, 0.04701122222468257), (10, 0.04948728159070015), (52, 0.04991981294006109), (51, 0.05075537133961916), (38, 0.0534485187381506), (11, 0.053611970972269773), (23, 0.05448409263044596), (37, 0.05844582710415125), (22, 0.05855120858177543), (13, 0.06254873005673289), (21, 0.06484491191804409), (3, 0.06846655905246735), (9, 0.0686905849725008), (20, 0.07293086871504784), (19, 0.07670277170836926), (12, 0.08214550092816353), (15, 0.09136157017201185), (2, 0.09991287533193827), (14, 0.10025392472743988), (0, 0.11159022431820631), (16, 0.12420983333140612), (5, 0.1866912581026554), (17, 0.43231241405010223), (18, 0.6339604258537292), (36, 0.7521690651774406), (53, 0.9609695747494698)]
computing accuracy for after removing block 46 . block score: 0.03840478556230664
removed block 46 current accuracy 0.9616 loss from initial  0.03839999999999999
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 41, with score 0.038655. All blocks and scores: [(41, 0.038655244279652834), (8, 0.040369612630456686), (49, 0.04059208370745182), (43, 0.042093145195394754), (40, 0.042324003763496876), (48, 0.04352208552882075), (4, 0.043720817659050226), (42, 0.045755378901958466), (39, 0.04626052500680089), (45, 0.04646327393129468), (6, 0.04701122175902128), (10, 0.0494872834533453), (52, 0.05178068159148097), (51, 0.053067185916006565), (38, 0.0534485187381506), (11, 0.05361197143793106), (23, 0.05448409076780081), (37, 0.05844582663848996), (22, 0.05855120858177543), (13, 0.06254872912541032), (21, 0.06484491005539894), (3, 0.0684665571898222), (9, 0.06869058217853308), (20, 0.07293087057769299), (19, 0.07670277450233698), (12, 0.0821454981341958), (15, 0.0913615683093667), (2, 0.0999128706753254), (14, 0.1002539275214076), (0, 0.11159022990614176), (16, 0.12420983146876097), (5, 0.18669126741588116), (17, 0.43231242150068283), (18, 0.6339604258537292), (36, 0.7521690726280212), (53, 1.0024984180927277)]
computing accuracy for after removing block 41 . block score: 0.038655244279652834
removed block 41 current accuracy 0.9514 loss from initial  0.04859999999999998
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.038316. All blocks and scores: [(49, 0.03831622842699289), (8, 0.04036961356177926), (43, 0.04227219521999359), (40, 0.04232400422915816), (48, 0.042694429866969585), (4, 0.04372081672772765), (42, 0.045651715248823166), (39, 0.0462605245411396), (45, 0.04696215130388737), (6, 0.047011221293359995), (10, 0.04948728159070015), (52, 0.05042446171864867), (51, 0.05232812277972698), (38, 0.05344851780682802), (11, 0.053611969109624624), (23, 0.05448409076780081), (37, 0.05844582850113511), (22, 0.05855120625346899), (13, 0.06254872772842646), (21, 0.06484491191804409), (3, 0.06846655905246735), (9, 0.0686905849725008), (20, 0.07293086871504784), (19, 0.07670277170836926), (12, 0.08214549906551838), (15, 0.09136156924068928), (2, 0.0999128706753254), (14, 0.10025392472743988), (0, 0.11159022990614176), (16, 0.12420982867479324), (5, 0.18669125996530056), (17, 0.43231241405010223), (18, 0.633960410952568), (36, 0.7521690726280212), (53, 1.0472838282585144)]
computing accuracy for after removing block 49 . block score: 0.03831622842699289
removed block 49 current accuracy 0.9412 loss from initial  0.05879999999999996
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 8, with score 0.040370. All blocks and scores: [(8, 0.04036961309611797), (43, 0.04227219661697745), (40, 0.04232400422915816), (48, 0.04269443079829216), (4, 0.043720817659050226), (42, 0.04565171431750059), (39, 0.046260524075478315), (45, 0.04696215270087123), (6, 0.04701122362166643), (10, 0.04948728159070015), (52, 0.05242927372455597), (38, 0.05344851687550545), (11, 0.053611972369253635), (23, 0.05448409169912338), (51, 0.057103721890598536), (37, 0.05844582663848996), (22, 0.05855120858177543), (13, 0.06254873005673289), (21, 0.06484491191804409), (3, 0.06846655998378992), (9, 0.0686905849725008), (20, 0.07293086778372526), (19, 0.07670277170836926), (12, 0.0821454981341958), (15, 0.09136156737804413), (2, 0.09991287346929312), (14, 0.1002539237961173), (0, 0.11159022804349661), (16, 0.12420983146876097), (5, 0.18669126369059086), (17, 0.43231241405010223), (18, 0.6339604035019875), (36, 0.7521691024303436), (53, 1.1509316116571426)]
computing accuracy for after removing block 8 . block score: 0.04036961309611797
removed block 8 current accuracy 0.9384 loss from initial  0.06159999999999999
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.041120. All blocks and scores: [(43, 0.041120244190096855), (40, 0.041418869979679585), (48, 0.041832834016531706), (4, 0.043720818124711514), (39, 0.04550682380795479), (42, 0.04568770807236433), (45, 0.04632179858162999), (6, 0.04701122175902128), (10, 0.05095136724412441), (38, 0.051644327118992805), (52, 0.05189395975321531), (23, 0.052788219414651394), (11, 0.056459960993379354), (51, 0.056813064962625504), (37, 0.057707761880010366), (22, 0.05771422199904919), (21, 0.06323755299672484), (13, 0.063365557231009), (9, 0.06763261463493109), (3, 0.06846655998378992), (20, 0.07180929090827703), (19, 0.07449236139655113), (12, 0.08171510510146618), (15, 0.09145998675376177), (14, 0.09515240602195263), (2, 0.09991287346929312), (0, 0.11159023083746433), (16, 0.12286203447729349), (5, 0.1866912581026554), (17, 0.4177943170070648), (18, 0.6193196177482605), (36, 0.7399577498435974), (53, 1.151360034942627)]
computing accuracy for after removing block 43 . block score: 0.041120244190096855
removed block 43 current accuracy 0.9212 loss from initial  0.07879999999999998
since last training loss: 0.05159999999999998 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 40, with score 0.041419. All blocks and scores: [(40, 0.04141886904835701), (48, 0.04303444176912308), (4, 0.043720817659050226), (39, 0.04550682567059994), (42, 0.04568770667538047), (6, 0.04701122175902128), (45, 0.04812610102817416), (10, 0.05095136724412441), (38, 0.05164432665333152), (52, 0.05249618738889694), (23, 0.05278821988031268), (11, 0.056459960993379354), (37, 0.05770775955170393), (22, 0.0577142215333879), (51, 0.058211463037878275), (21, 0.06323755299672484), (13, 0.06336555909365416), (9, 0.06763261649757624), (3, 0.06846655625849962), (20, 0.07180928811430931), (19, 0.07449236046522856), (12, 0.0817151078954339), (15, 0.09145998861640692), (14, 0.09515240136533976), (2, 0.09991287626326084), (0, 0.11159023083746433), (16, 0.12286203354597092), (5, 0.18669126741588116), (17, 0.4177943058311939), (18, 0.6193196401000023), (36, 0.7399577498435974), (53, 1.221187487244606)]
computing accuracy for after removing block 40 . block score: 0.04141886904835701
removed block 40 current accuracy 0.9 loss from initial  0.09999999999999998
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.042471. All blocks and scores: [(48, 0.042471145279705524), (4, 0.04372081719338894), (39, 0.045506826136261225), (42, 0.046068364288657904), (45, 0.04612067015841603), (6, 0.047011223156005144), (10, 0.05095136724412441), (38, 0.051644325256347656), (52, 0.052424009423702955), (23, 0.05278821988031268), (11, 0.05645995819941163), (37, 0.05770776094868779), (22, 0.057714222464710474), (51, 0.05984540889039636), (21, 0.06323755299672484), (13, 0.06336556002497673), (9, 0.06763261556625366), (3, 0.06846655812114477), (20, 0.07180928904563189), (19, 0.07449236046522856), (12, 0.08171511255204678), (15, 0.09145998861640692), (14, 0.09515240136533976), (2, 0.09991287440061569), (0, 0.11159023363143206), (16, 0.12286203633993864), (5, 0.1866912581026554), (17, 0.4177943244576454), (18, 0.6193196177482605), (36, 0.7399577423930168), (53, 1.2892201989889145)]
computing accuracy for after removing block 48 . block score: 0.042471145279705524
removed block 48 current accuracy 0.864 loss from initial  0.136
training start
training epoch 0 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best True lr [0.1]
training epoch 1 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 2 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 3 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 4 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 7 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.1]
training epoch 8 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 9 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 10 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.960600)
finished training. finished 50 epochs. accuracy 0.9606 topk_dict {'top1': 0.9606}
start iteration 24
[activation diff]: block to remove picked: 6, with score 0.050491. All blocks and scores: [(6, 0.050491110887378454), (4, 0.05267135472968221), (38, 0.06448986288160086), (10, 0.06540414784103632), (52, 0.06577576790004969), (39, 0.0685921935364604), (22, 0.06882865447551012), (3, 0.07045758608728647), (23, 0.07082714326679707), (11, 0.07085103448480368), (37, 0.07105068676173687), (51, 0.0714946947991848), (13, 0.07343682646751404), (42, 0.07632982917129993), (45, 0.07825183682143688), (21, 0.07907000184059143), (19, 0.08335758931934834), (9, 0.0859103687107563), (20, 0.089310048148036), (12, 0.09987433534115553), (15, 0.10788909532129765), (14, 0.1092785270884633), (0, 0.11242786329239607), (2, 0.11839950643479824), (16, 0.13610275462269783), (5, 0.19856526143848896), (17, 0.4491664506494999), (36, 0.6359051391482353), (18, 0.6637285500764847), (53, 1.0024805143475533)]
computing accuracy for after removing block 6 . block score: 0.050491110887378454
removed block 6 current accuracy 0.957 loss from initial  0.04300000000000004
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 4, with score 0.052671. All blocks and scores: [(4, 0.05267135286703706), (38, 0.06346885394304991), (52, 0.06564469635486603), (22, 0.06751167681068182), (23, 0.06754412967711687), (10, 0.06859967485070229), (39, 0.06939779967069626), (3, 0.0704575851559639), (51, 0.07113775797188282), (37, 0.07178392633795738), (42, 0.0756433317437768), (11, 0.07569822389632463), (45, 0.07778116501867771), (21, 0.07829703390598297), (13, 0.08016558922827244), (19, 0.08139426074922085), (20, 0.08749887254089117), (9, 0.09120769426226616), (12, 0.10220551863312721), (14, 0.11078030336648226), (0, 0.1124278623610735), (15, 0.11243436392396688), (2, 0.11839950829744339), (16, 0.14072784408926964), (5, 0.1985652595758438), (17, 0.4688759408891201), (36, 0.6404934898018837), (18, 0.6605959460139275), (53, 0.9931474328041077)]
computing accuracy for after removing block 4 . block score: 0.05267135286703706
removed block 4 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.060379. All blocks and scores: [(38, 0.06037859991192818), (23, 0.06396740768104792), (22, 0.06469967309385538), (52, 0.0647447993978858), (10, 0.06562970858067274), (39, 0.06864824797958136), (37, 0.06901450082659721), (51, 0.07007679250091314), (3, 0.07045758329331875), (11, 0.07236941531300545), (42, 0.07457615528255701), (45, 0.07677786331623793), (21, 0.07797129359096289), (13, 0.0788774797692895), (19, 0.07995771337300539), (20, 0.08349587582051754), (9, 0.08961222413927317), (14, 0.10551713593304157), (12, 0.10654496680945158), (15, 0.10960918199270964), (0, 0.11242785770446062), (2, 0.11839950922876596), (16, 0.1422572247684002), (5, 0.1980842389166355), (17, 0.46143122017383575), (36, 0.6248275861144066), (18, 0.6486243680119514), (53, 1.0075897574424744)]
computing accuracy for after removing block 38 . block score: 0.06037859991192818
removed block 38 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.062255. All blocks and scores: [(52, 0.062254770658910275), (23, 0.06396740954369307), (22, 0.06469967029988766), (10, 0.06562970858067274), (51, 0.06743696052581072), (37, 0.06901449710130692), (3, 0.07045758608728647), (11, 0.0723694171756506), (39, 0.07472742348909378), (45, 0.07522988226264715), (42, 0.07574267033487558), (21, 0.07797129172831774), (13, 0.07887748070061207), (19, 0.07995771430432796), (20, 0.08349587582051754), (9, 0.08961222320795059), (14, 0.10551713779568672), (12, 0.10654496401548386), (15, 0.10960917826741934), (0, 0.1124278586357832), (2, 0.11839950829744339), (16, 0.1422572284936905), (5, 0.19808423332870007), (17, 0.46143120899796486), (36, 0.6248275935649872), (18, 0.6486243605613708), (53, 1.0729639381170273)]
computing accuracy for after removing block 52 . block score: 0.062254770658910275
removed block 52 current accuracy 0.9106 loss from initial  0.08940000000000003
since last training loss: 0.050000000000000044 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 23, with score 0.063967. All blocks and scores: [(23, 0.06396740954369307), (22, 0.0646996721625328), (10, 0.06562970858067274), (51, 0.067436957731843), (37, 0.06901449896395206), (3, 0.0704575888812542), (11, 0.0723694171756506), (39, 0.07472742162644863), (45, 0.07522988319396973), (42, 0.07574267219752073), (21, 0.07797129359096289), (13, 0.07887748256325722), (19, 0.07995771244168282), (20, 0.08349587954580784), (9, 0.08961222507059574), (14, 0.10551713593304157), (12, 0.10654496401548386), (15, 0.10960917547345161), (0, 0.11242786049842834), (2, 0.11839950922876596), (16, 0.1422572284936905), (5, 0.19808423332870007), (17, 0.46143120527267456), (36, 0.6248275935649872), (18, 0.648624375462532), (53, 0.9130447804927826)]
computing accuracy for after removing block 23 . block score: 0.06396740954369307
removed block 23 current accuracy 0.9086 loss from initial  0.09140000000000004
since last training loss: 0.052000000000000046 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 22, with score 0.064700. All blocks and scores: [(22, 0.0646996721625328), (10, 0.06562970764935017), (51, 0.06614307314157486), (37, 0.07012371066957712), (3, 0.0704575851559639), (11, 0.0723694171756506), (39, 0.07315251417458057), (45, 0.07469278387725353), (42, 0.07515298668295145), (21, 0.07797129079699516), (13, 0.07887748256325722), (19, 0.07995771337300539), (20, 0.08349587675184011), (9, 0.08961222227662802), (14, 0.10551713407039642), (12, 0.10654496308416128), (15, 0.10960917919874191), (0, 0.11242786049842834), (2, 0.11839950364083052), (16, 0.14225723035633564), (5, 0.19808423705399036), (17, 0.46143121272325516), (36, 0.622667171061039), (18, 0.6486243903636932), (53, 0.8796501979231834)]
computing accuracy for after removing block 22 . block score: 0.0646996721625328
removed block 22 current accuracy 0.8948 loss from initial  0.10519999999999996
since last training loss: 0.06579999999999997 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 51, with score 0.062634. All blocks and scores: [(51, 0.06263377796858549), (10, 0.06562970858067274), (37, 0.06606541574001312), (39, 0.06820820551365614), (42, 0.07028164435178041), (3, 0.07045758701860905), (45, 0.07130004744976759), (11, 0.07236941438168287), (21, 0.07797129359096289), (13, 0.07887748163193464), (19, 0.07995771337300539), (20, 0.08349587861448526), (9, 0.08961222693324089), (14, 0.10551713313907385), (12, 0.10654496494680643), (15, 0.10960917733609676), (0, 0.11242785956710577), (2, 0.11839950643479824), (16, 0.14225722663104534), (5, 0.19808423705399036), (17, 0.46143120899796486), (36, 0.5939184874296188), (18, 0.6486243903636932), (53, 0.8130722567439079)]
computing accuracy for after removing block 51 . block score: 0.06263377796858549
removed block 51 current accuracy 0.836 loss from initial  0.16400000000000003
since last training loss: 0.12460000000000004 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 10, with score 0.065630. All blocks and scores: [(10, 0.06562970764935017), (37, 0.0660654166713357), (39, 0.06820820551365614), (42, 0.07028164621442556), (3, 0.07045758701860905), (45, 0.07130004931241274), (11, 0.07236941624432802), (21, 0.07797129265964031), (13, 0.07887748256325722), (19, 0.07995771430432796), (20, 0.08349587768316269), (9, 0.08961222693324089), (14, 0.10551713686436415), (12, 0.106544965878129), (15, 0.10960917733609676), (0, 0.1124278623610735), (2, 0.11839950270950794), (16, 0.14225722290575504), (5, 0.19808423519134521), (17, 0.46143121644854546), (36, 0.5939184948801994), (18, 0.6486243829131126), (53, 0.7584577649831772)]
computing accuracy for after removing block 10 . block score: 0.06562970764935017
removed block 10 current accuracy 0.8168 loss from initial  0.18320000000000003
since last training loss: 0.14380000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 37, with score 0.062867. All blocks and scores: [(37, 0.06286662258207798), (39, 0.06661693565547466), (42, 0.06902691628783941), (45, 0.06966757215559483), (11, 0.0699361115694046), (3, 0.07045758422464132), (21, 0.07399674318730831), (19, 0.07502357196062803), (13, 0.07600036356598139), (20, 0.07831215299665928), (9, 0.08961222134530544), (14, 0.09926771558821201), (12, 0.10382155422121286), (15, 0.10801349673420191), (0, 0.11242786142975092), (2, 0.11839950643479824), (16, 0.1388380005955696), (5, 0.19808423705399036), (17, 0.45252225175499916), (36, 0.5712299272418022), (18, 0.6282532140612602), (53, 0.7033544480800629)]
computing accuracy for after removing block 37 . block score: 0.06286662258207798
removed block 37 current accuracy 0.7864 loss from initial  0.2136
training start
training epoch 0 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best True lr [0.1]
training epoch 1 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.1]
training epoch 3 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 4 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.1]
training epoch 5 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 6 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 7 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 8 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.1]
training epoch 9 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 10 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
