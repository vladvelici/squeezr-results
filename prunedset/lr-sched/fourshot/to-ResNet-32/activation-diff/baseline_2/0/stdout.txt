start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975019648671), (20, 0.008696247823536396), (27, 0.00919829506892711), (31, 0.009675503941252828), (29, 0.010030421079136431), (22, 0.010588386561721563), (23, 0.010651617893017828), (21, 0.010725351050496101), (28, 0.011828800081275403), (24, 0.012058728723786771), (17, 0.012199450633488595), (19, 0.013177948421798646), (33, 0.0132797866826877), (35, 0.013483816059306264), (25, 0.013839342165738344), (11, 0.013912909082137048), (32, 0.013956584967672825), (16, 0.014766237698495388), (30, 0.01549160503782332), (9, 0.015547690447419882), (40, 0.0159863349981606), (34, 0.01665632240474224), (39, 0.01751717645674944), (44, 0.018641566624864936), (37, 0.018799004843458533), (43, 0.018935034750029445), (42, 0.019514338579028845), (41, 0.019590020878240466), (45, 0.019901464926078916), (38, 0.020000957883894444), (14, 0.020047535421326756), (8, 0.021667920518666506), (7, 0.021806211909279227), (15, 0.02483329619280994), (46, 0.02521279128268361), (10, 0.025900361826643348), (49, 0.027116776444017887), (48, 0.02751143998466432), (47, 0.027820877730846405), (50, 0.028723244788125157), (51, 0.03178879711776972), (12, 0.03298327000811696), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.05253404285758734), (13, 0.05450335890054703), (2, 0.061206035781651735), (1, 0.07061250694096088), (0, 0.14636892452836037), (36, 0.2727429233491421), (18, 0.30386047437787056), (53, 0.8891633078455925)]
computing accuracy for after removing block 26 . block score: 0.007451975019648671
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.008696247823536396), (27, 0.00956932723056525), (31, 0.009736894397065043), (29, 0.010370098170824349), (22, 0.010588386794552207), (23, 0.010651617776602507), (21, 0.010725351050496101), (24, 0.012058728490956128), (28, 0.01206758536864072), (17, 0.012199450749903917), (19, 0.013177948887459934), (33, 0.013200338813476264), (35, 0.013297739089466631), (32, 0.013540125917643309), (25, 0.013839342049323022), (11, 0.013912909082137048), (16, 0.014766237931326032), (30, 0.015476007480174303), (9, 0.015547690447419882), (34, 0.016335652908310294), (40, 0.016489707631990314), (39, 0.018151729367673397), (44, 0.018809265224263072), (43, 0.019272046396508813), (37, 0.019370622700080276), (41, 0.01979763014242053), (42, 0.0198463867418468), (14, 0.020047536119818687), (38, 0.02020833222195506), (45, 0.020282169338315725), (8, 0.021667920518666506), (7, 0.021806210512295365), (15, 0.02483329689130187), (46, 0.02571068168617785), (10, 0.02590036066249013), (49, 0.027175757568329573), (48, 0.02780761430040002), (47, 0.028269682778045535), (50, 0.028723405208438635), (51, 0.03195985918864608), (12, 0.032983270939439535), (5, 0.03333624405786395), (6, 0.033519682474434376), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.05266197212040424), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.2777215540409088), (18, 0.30386048182845116), (53, 0.882564976811409)]
computing accuracy for after removing block 20 . block score: 0.008696247823536396
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.00924707145895809), (31, 0.0094903550343588), (29, 0.010141469771042466), (23, 0.010720769292674959), (21, 0.010873694671317935), (22, 0.010951440315693617), (28, 0.01160251791588962), (17, 0.012199451215565205), (24, 0.012428545160219073), (33, 0.013006685767322779), (32, 0.013030687463469803), (35, 0.013141493313014507), (19, 0.013177948421798646), (11, 0.013912909082137048), (25, 0.014337054803036153), (30, 0.014731099247001112), (16, 0.014766237698495388), (9, 0.015547689865343273), (34, 0.015950741712003946), (40, 0.01667696749791503), (39, 0.018123319139704108), (44, 0.01904273359104991), (43, 0.019525705371052027), (37, 0.019535947358235717), (41, 0.020023912889882922), (42, 0.02002461114898324), (14, 0.020047535421326756), (38, 0.020229951944202185), (45, 0.020495346747338772), (8, 0.021667920984327793), (7, 0.02180621027946472), (15, 0.024833296425640583), (10, 0.025900361593812704), (46, 0.02600882132537663), (49, 0.027358210179954767), (48, 0.02794406423345208), (47, 0.028558713151142), (50, 0.02887403150089085), (51, 0.03197578387334943), (12, 0.03298327047377825), (5, 0.03333624359220266), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.053193127270787954), (13, 0.0545033598318696), (2, 0.061206037644296885), (1, 0.07061250787228346), (0, 0.14636891894042492), (36, 0.27894822508096695), (18, 0.30386048182845116), (53, 0.8746765330433846)]
computing accuracy for after removing block 27 . block score: 0.00924707145895809
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703439893200994), (29, 0.010401993757113814), (23, 0.010720769292674959), (21, 0.010873694554902613), (22, 0.010951439966447651), (28, 0.011904270155355334), (17, 0.012199450517073274), (24, 0.012428545043803751), (33, 0.012989282724447548), (35, 0.013032012851908803), (32, 0.013032321585342288), (19, 0.013177949003875256), (11, 0.013912908965721726), (25, 0.014337054803036153), (30, 0.014530949993059039), (16, 0.014766238047741354), (34, 0.015523916110396385), (9, 0.015547690447419882), (40, 0.01742828404530883), (39, 0.018635700456798077), (44, 0.01932337530888617), (43, 0.01989502110518515), (14, 0.020047535188496113), (37, 0.020162818022072315), (38, 0.020197829697281122), (42, 0.020295765483751893), (41, 0.020331317791715264), (45, 0.020738494116812944), (8, 0.02166792075149715), (7, 0.02180621074512601), (15, 0.024833296658471227), (10, 0.02590036066249013), (46, 0.026298312935978174), (49, 0.02737220679409802), (48, 0.028113746782764792), (47, 0.02882404252886772), (50, 0.02908248663879931), (51, 0.03204397251829505), (12, 0.03298327000811696), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.043747184332460165), (52, 0.053347036242485046), (13, 0.054503359366208315), (2, 0.06120603624731302), (1, 0.07061250787228346), (0, 0.14636892266571522), (36, 0.2865508496761322), (18, 0.30386047810316086), (53, 0.873922660946846)]
computing accuracy for after removing block 31 . block score: 0.009703439893200994
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401993873529136), (23, 0.010720769176259637), (21, 0.010873695136979222), (22, 0.01095143985003233), (28, 0.01190426992252469), (17, 0.012199450982734561), (24, 0.012428544810973108), (33, 0.013075273483991623), (19, 0.013177948771044612), (32, 0.013221941189840436), (35, 0.013311224873177707), (11, 0.013912908849306405), (25, 0.01433705457020551), (30, 0.01453094941098243), (16, 0.014766237698495388), (34, 0.015109014348126948), (9, 0.015547690447419882), (40, 0.01796384761109948), (44, 0.01917276019230485), (39, 0.019229266326874495), (38, 0.019627249101176858), (43, 0.01977342297323048), (42, 0.020014990121126175), (14, 0.02004753495566547), (41, 0.020369442412629724), (45, 0.020458239363506436), (37, 0.020535161951556802), (8, 0.021667920285835862), (7, 0.021806209348142147), (15, 0.024833296658471227), (10, 0.025900361826643348), (46, 0.026439889799803495), (49, 0.027319708140566945), (48, 0.02830672264099121), (47, 0.028651983942836523), (50, 0.029288704739883542), (51, 0.032143966760486364), (12, 0.032983270939439535), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.0380434924736619), (3, 0.0437471829354763), (52, 0.052529138047248125), (13, 0.0545033598318696), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636892080307007), (36, 0.29571832343935966), (18, 0.30386047437787056), (53, 0.8852703869342804)]
computing accuracy for after removing block 29 . block score: 0.010401993873529136
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.01072076940909028), (21, 0.010873694787733257), (22, 0.01095143985003233), (28, 0.011904270038940012), (17, 0.01219945028424263), (24, 0.012428545160219073), (33, 0.013095533708110452), (19, 0.01317794865462929), (32, 0.01333179126959294), (35, 0.013342681690119207), (11, 0.013912909547798336), (25, 0.014337055152282119), (16, 0.014766238047741354), (34, 0.014780626515857875), (30, 0.014848081395030022), (9, 0.015547690447419882), (40, 0.017947439569979906), (44, 0.018570148153230548), (38, 0.018818871583789587), (39, 0.019284183392301202), (42, 0.019550167489796877), (43, 0.019667528569698334), (41, 0.020019967574626207), (14, 0.020047534722834826), (45, 0.02014507818967104), (37, 0.020778114208951592), (8, 0.021667920984327793), (7, 0.021806211210787296), (15, 0.024833297822624445), (10, 0.025900361826643348), (46, 0.026351966429501772), (49, 0.026999606983736157), (48, 0.027823995100334287), (47, 0.028508094372227788), (50, 0.02933459379710257), (51, 0.032171768601983786), (12, 0.03298326954245567), (5, 0.03333624359220266), (6, 0.033519684337079525), (4, 0.038043494801968336), (3, 0.04374718340113759), (52, 0.05190546624362469), (13, 0.05450336029753089), (2, 0.06120603624731302), (1, 0.07061250880360603), (0, 0.14636891894042492), (36, 0.2995104119181633), (18, 0.30386047065258026), (53, 0.8962139934301376)]
computing accuracy for after removing block 23 . block score: 0.01072076940909028
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.0108736950205639), (22, 0.010951439617201686), (28, 0.011454624705947936), (24, 0.011984123033471406), (17, 0.012199451099149883), (35, 0.01300165115389973), (32, 0.013018106459639966), (33, 0.013115601730532944), (19, 0.01317794865462929), (25, 0.013824696536175907), (11, 0.013912908965721726), (30, 0.014240248361602426), (34, 0.014703377499245107), (16, 0.014766237465664744), (9, 0.015547690447419882), (40, 0.018065203679725528), (44, 0.018300466239452362), (38, 0.01860098447650671), (42, 0.01934517058543861), (43, 0.01955112931318581), (39, 0.019822365837171674), (45, 0.019911037757992744), (41, 0.02002873970195651), (14, 0.020047535886988044), (37, 0.020847720094025135), (8, 0.021667920518666506), (7, 0.021806211210787296), (15, 0.024833296658471227), (10, 0.02590036136098206), (46, 0.026478099171072245), (49, 0.02697809273377061), (48, 0.027518166694790125), (47, 0.028530240058898926), (50, 0.029085059417411685), (51, 0.03238660376518965), (12, 0.03298327000811696), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718340113759), (52, 0.05187077587470412), (13, 0.054503359366208315), (2, 0.061206037644296885), (1, 0.07061250787228346), (0, 0.14636891707777977), (36, 0.3020646646618843), (18, 0.30386048182845116), (53, 0.8938303142786026)]
computing accuracy for after removing block 21 . block score: 0.0108736950205639
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718231089413166), (22, 0.011124414973892272), (24, 0.011734541156329215), (17, 0.012199450633488595), (32, 0.012339043780229986), (35, 0.012350354925729334), (33, 0.012773355818353593), (19, 0.013177948771044612), (30, 0.01338572008535266), (25, 0.013581673265434802), (11, 0.013912908732891083), (34, 0.014493828639388084), (16, 0.014766238164156675), (9, 0.015547690098173916), (40, 0.018178854836151004), (44, 0.018340062350034714), (38, 0.01862968597561121), (42, 0.019575109472498298), (43, 0.019729840103536844), (39, 0.019833359867334366), (14, 0.02004753635264933), (45, 0.020094188395887613), (41, 0.020734292222186923), (37, 0.020795797696337104), (8, 0.02166792075149715), (7, 0.02180621074512601), (15, 0.02483329689130187), (10, 0.025900361128151417), (46, 0.027196241077035666), (49, 0.02729213354177773), (48, 0.02760020410642028), (47, 0.02890662639401853), (50, 0.0291686428245157), (51, 0.03279080847278237), (12, 0.032983270939439535), (5, 0.03333624452352524), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.04374718479812145), (52, 0.052345538046211004), (13, 0.0545033598318696), (2, 0.061206035781651735), (1, 0.07061250787228346), (0, 0.14636891707777977), (18, 0.30386048182845116), (36, 0.3042290136218071), (53, 0.8967952728271484)]
computing accuracy for after removing block 28 . block score: 0.010718231089413166
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011124. All blocks and scores: [(22, 0.011124414508230984), (24, 0.01173454150557518), (32, 0.012095691403374076), (35, 0.012157876044511795), (17, 0.012199450749903917), (33, 0.01310591702349484), (19, 0.01317794865462929), (30, 0.01332365081179887), (25, 0.01358167384751141), (11, 0.013912908732891083), (34, 0.014369336073286831), (16, 0.01476623781491071), (9, 0.015547690214589238), (38, 0.01792138139717281), (44, 0.01819704077206552), (40, 0.018912274856120348), (42, 0.019364925799891353), (43, 0.019978848984465003), (14, 0.020047535188496113), (45, 0.020337821217253804), (39, 0.02059708791784942), (41, 0.02072914084419608), (37, 0.021321294829249382), (8, 0.021667920518666506), (7, 0.021806211210787296), (15, 0.024833297124132514), (10, 0.025900361826643348), (49, 0.027097658719867468), (48, 0.027195147471502423), (46, 0.027485697530210018), (47, 0.02907437109388411), (50, 0.029169491259381175), (12, 0.03298326954245567), (51, 0.033133427146822214), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.05157360201701522), (13, 0.0545033598318696), (2, 0.06120603810995817), (1, 0.07061250880360603), (0, 0.14636892266571522), (18, 0.30386047437787056), (36, 0.31568819656968117), (53, 0.905331552028656)]
computing accuracy for after removing block 22 . block score: 0.011124414508230984
removed block 22 current accuracy 0.9804 loss from initial  0.01959999999999995
training start
training epoch 0 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 1 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 2 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 4 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 6 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 7 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 8 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 9 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 10 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.980400)
finished training. finished 50 epochs. accuracy 0.9804 topk_dict {'top1': 0.9804}
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.010824. All blocks and scores: [(24, 0.010824102559126914), (32, 0.011274677701294422), (35, 0.012037030654028058), (17, 0.01219945086631924), (30, 0.012747167726047337), (33, 0.013064955710433424), (25, 0.013176510110497475), (19, 0.013177949003875256), (11, 0.013912909664213657), (34, 0.014271511696279049), (16, 0.01476623781491071), (9, 0.01554769033100456), (38, 0.017574150348082185), (44, 0.017618532525375485), (42, 0.018865567166358232), (40, 0.018951470032334328), (43, 0.01948712021112442), (45, 0.019938055193051696), (14, 0.020047535421326756), (39, 0.02067698212340474), (41, 0.020799742313101888), (37, 0.020918889436870813), (8, 0.02166792075149715), (7, 0.021806211210787296), (15, 0.024833296658471227), (10, 0.02590036205947399), (49, 0.026988670928403735), (48, 0.027127153938636184), (46, 0.02736985543742776), (50, 0.028741258895024657), (47, 0.02902481402270496), (12, 0.032983269076794386), (51, 0.033131759613752365), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.0437471829354763), (52, 0.05089538358151913), (13, 0.054503359366208315), (2, 0.06120603531599045), (1, 0.07061250973492861), (0, 0.14636892266571522), (18, 0.30386048555374146), (36, 0.3163903057575226), (53, 0.9149599820375443)]
computing accuracy for after removing block 24 . block score: 0.010824102559126914
removed block 24 current accuracy 0.9664 loss from initial  0.03359999999999996
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.010877. All blocks and scores: [(32, 0.010876586777158082), (35, 0.011955109774135053), (30, 0.012104445835575461), (17, 0.012199450517073274), (25, 0.013075435534119606), (19, 0.01317794865462929), (33, 0.013257879531010985), (11, 0.01391290919855237), (34, 0.014449170674197376), (16, 0.01476623781491071), (9, 0.015547689865343273), (38, 0.016987738432362676), (44, 0.017669430235400796), (42, 0.018743420485407114), (40, 0.019168380880728364), (43, 0.019857255974784493), (45, 0.019892358453944325), (14, 0.0200475356541574), (41, 0.0207320146728307), (37, 0.02104191784746945), (39, 0.021407434483990073), (8, 0.02166792005300522), (7, 0.02180621027946472), (15, 0.02483329689130187), (10, 0.025900361593812704), (49, 0.026679034112021327), (48, 0.02684470545500517), (46, 0.027388097485527396), (50, 0.028316201409325004), (47, 0.028733996907249093), (51, 0.032925904262810946), (12, 0.032983270939439535), (5, 0.03333624452352524), (6, 0.03351968340575695), (4, 0.03804349433630705), (3, 0.043747184332460165), (52, 0.04968237690627575), (13, 0.05450336029753089), (2, 0.06120603531599045), (1, 0.07061250694096088), (0, 0.14636892266571522), (18, 0.30386047437787056), (36, 0.3254365250468254), (53, 0.9151448830962181)]
computing accuracy for after removing block 32 . block score: 0.010876586777158082
removed block 32 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.030200000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.012104. All blocks and scores: [(30, 0.012104445602744818), (17, 0.012199451099149883), (35, 0.012797020957805216), (25, 0.013075435534119606), (19, 0.013177948771044612), (33, 0.013797620311379433), (11, 0.01391290919855237), (34, 0.014519992982968688), (16, 0.014766237931326032), (9, 0.015547690563835204), (38, 0.016240306431427598), (44, 0.01703395671211183), (42, 0.018259102012962103), (40, 0.01946928258985281), (45, 0.01950681279413402), (43, 0.01966427033767104), (14, 0.0200475356541574), (41, 0.020211151568219066), (37, 0.020982665475457907), (39, 0.021373851457610726), (8, 0.021667920285835862), (7, 0.021806211676448584), (15, 0.024833297124132514), (10, 0.025900360895320773), (49, 0.026327638421207666), (48, 0.026497263461351395), (46, 0.027324117720127106), (50, 0.028004024643450975), (47, 0.02862798934802413), (51, 0.032616606913506985), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.04374718479812145), (52, 0.04806074220687151), (13, 0.054503359366208315), (2, 0.06120603531599045), (1, 0.07061250694096088), (0, 0.14636892266571522), (18, 0.30386048182845116), (36, 0.33333006873726845), (53, 0.9361404031515121)]
computing accuracy for after removing block 30 . block score: 0.012104445602744818
removed block 30 current accuracy 0.9186 loss from initial  0.08140000000000003
since last training loss: 0.06180000000000008 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 17, with score 0.012199. All blocks and scores: [(17, 0.01219945086631924), (25, 0.013075435650534928), (19, 0.01317794865462929), (35, 0.01352300331927836), (11, 0.01391290919855237), (34, 0.01476603071205318), (16, 0.014766237931326032), (33, 0.015034387819468975), (9, 0.01554769033100456), (38, 0.015858327271416783), (44, 0.016648652032017708), (42, 0.017816877458244562), (45, 0.019354374846443534), (43, 0.01949126529507339), (41, 0.020042051561176777), (14, 0.0200475356541574), (40, 0.020565516548231244), (8, 0.02166792075149715), (7, 0.021806211210787296), (37, 0.022225635359063745), (39, 0.022749602561816573), (15, 0.02483329689130187), (10, 0.025900361128151417), (49, 0.02600616286508739), (48, 0.026390114100649953), (46, 0.02736017433926463), (50, 0.027876119362190366), (47, 0.028576353332027793), (51, 0.0326245347969234), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718340113759), (52, 0.046035982202738523), (13, 0.05450335843488574), (2, 0.06120603624731302), (1, 0.07061250694096088), (0, 0.14636892080307007), (18, 0.30386047437787056), (36, 0.3517293408513069), (53, 0.9536164999008179)]
computing accuracy for after removing block 17 . block score: 0.01219945086631924
removed block 17 current accuracy 0.9074 loss from initial  0.09260000000000002
since last training loss: 0.07300000000000006 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.012180. All blocks and scores: [(19, 0.012179648037999868), (25, 0.012272003921680152), (35, 0.013189252000302076), (11, 0.01391290919855237), (33, 0.014486355590634048), (34, 0.014641908463090658), (16, 0.014766237698495388), (9, 0.01554769033100456), (38, 0.015624886378645897), (44, 0.016568857477977872), (42, 0.0173870250582695), (45, 0.018840335542336106), (43, 0.019320324528962374), (14, 0.020047535886988044), (41, 0.02039071382023394), (40, 0.0215928063262254), (8, 0.021667921217158437), (7, 0.02180621027946472), (37, 0.022732951445505023), (39, 0.024223787244409323), (15, 0.024833296425640583), (49, 0.02558968518860638), (10, 0.025900361593812704), (48, 0.026119847083464265), (50, 0.027166033163666725), (46, 0.027381491847336292), (47, 0.027957340702414513), (51, 0.031517046270892024), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.03804349293932319), (52, 0.04372498160228133), (3, 0.04374718340113759), (13, 0.05450336076319218), (2, 0.06120603485032916), (1, 0.07061250694096088), (0, 0.14636892080307007), (18, 0.31064050644636154), (36, 0.35844869911670685), (53, 0.94353898614645)]
computing accuracy for after removing block 19 . block score: 0.012179648037999868
removed block 19 current accuracy 0.886 loss from initial  0.11399999999999999
since last training loss: 0.09440000000000004 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.011761. All blocks and scores: [(25, 0.011760654277168214), (35, 0.013664751197211444), (11, 0.01391290919855237), (34, 0.014714435441419482), (16, 0.014766238047741354), (9, 0.015547690563835204), (38, 0.015558895422145724), (33, 0.015920345904305577), (44, 0.016500320052728057), (42, 0.017734749475494027), (45, 0.01935424213297665), (14, 0.02004753635264933), (43, 0.02004793845117092), (41, 0.020638384157791734), (8, 0.021667921217158437), (7, 0.021806211210787296), (40, 0.022464620880782604), (37, 0.022927869111299515), (39, 0.024239381309598684), (15, 0.024833297124132514), (49, 0.02560739521868527), (10, 0.02590036136098206), (48, 0.02613125811330974), (50, 0.027281198417767882), (46, 0.027627219911664724), (47, 0.028128260979428887), (51, 0.03160239523276687), (12, 0.03298327000811696), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.038043493404984474), (52, 0.04308580607175827), (3, 0.04374718479812145), (13, 0.05450336029753089), (2, 0.06120603531599045), (1, 0.07061250694096088), (0, 0.14636892266571522), (18, 0.31064050644636154), (36, 0.3724363297224045), (53, 0.9451775550842285)]
computing accuracy for after removing block 25 . block score: 0.011760654277168214
removed block 25 current accuracy 0.851 loss from initial  0.14900000000000002
since last training loss: 0.12940000000000007 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 35, with score 0.013833. All blocks and scores: [(35, 0.013832748169079423), (11, 0.013912909082137048), (16, 0.014766237582080066), (34, 0.015167495235800743), (9, 0.015547690447419882), (38, 0.015721766161732376), (44, 0.01646577031351626), (33, 0.016804947750642896), (42, 0.017259199870750308), (45, 0.019349291920661926), (43, 0.019966616528108716), (14, 0.0200475356541574), (41, 0.021154981339350343), (8, 0.021667920984327793), (7, 0.021806209813803434), (40, 0.023630635580047965), (37, 0.024308389285579324), (15, 0.024833296658471227), (49, 0.02514790720306337), (10, 0.02590036136098206), (48, 0.026103172218427062), (50, 0.026404579635709524), (39, 0.026513394434005022), (46, 0.02712839306332171), (47, 0.027616398874670267), (51, 0.031037586508318782), (12, 0.032983269076794386), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.038043493404984474), (52, 0.040489372331649065), (3, 0.04374718340113759), (13, 0.05450335890054703), (2, 0.06120603624731302), (1, 0.07061250694096088), (0, 0.14636891894042492), (18, 0.31064051389694214), (36, 0.3894701488316059), (53, 0.949112057685852)]
computing accuracy for after removing block 35 . block score: 0.013832748169079423
removed block 35 current accuracy 0.8452 loss from initial  0.15480000000000005
since last training loss: 0.1352000000000001 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 11, with score 0.013913. All blocks and scores: [(11, 0.013912908500060439), (16, 0.014766237698495388), (34, 0.01516749570146203), (38, 0.015244632842950523), (9, 0.015547690447419882), (44, 0.01618287607561797), (33, 0.016804948216304183), (42, 0.017359102610498667), (45, 0.019262385554611683), (43, 0.019361371407285333), (14, 0.020047535421326756), (41, 0.02112998883239925), (8, 0.021667920285835862), (7, 0.021806209813803434), (37, 0.02261869329959154), (40, 0.022659107577055693), (15, 0.024833296658471227), (48, 0.025468709878623486), (10, 0.02590036136098206), (39, 0.026304202154278755), (49, 0.026442063273862004), (50, 0.026654361747205257), (47, 0.02745490986853838), (46, 0.028562052873894572), (51, 0.031898608431220055), (12, 0.03298327047377825), (5, 0.03333624452352524), (6, 0.03351968387141824), (4, 0.03804349387064576), (52, 0.039706327486783266), (3, 0.04374718526378274), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250880360603), (0, 0.14636892080307007), (18, 0.31064050272107124), (36, 0.4019012413918972), (53, 0.9668999761343002)]
computing accuracy for after removing block 11 . block score: 0.013912908500060439
removed block 11 current accuracy 0.8222 loss from initial  0.17779999999999996
since last training loss: 0.1582 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 38, with score 0.014923. All blocks and scores: [(38, 0.014922500355169177), (16, 0.015063714818097651), (34, 0.015295824501663446), (9, 0.015547690563835204), (44, 0.015929904184304178), (33, 0.01713780639693141), (42, 0.01714811776764691), (14, 0.01912930910475552), (43, 0.019260868662968278), (45, 0.019432940520346165), (41, 0.021654096664860845), (8, 0.02166792075149715), (7, 0.021806210977956653), (37, 0.022690806537866592), (40, 0.023237555753439665), (48, 0.024717782624065876), (15, 0.02473648893646896), (10, 0.025900361826643348), (49, 0.02622820809483528), (50, 0.026260598096996546), (39, 0.02650471404194832), (47, 0.02687984425574541), (46, 0.0286984839476645), (12, 0.031113999197259545), (51, 0.03142287442460656), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (52, 0.03841233579441905), (3, 0.043747184332460165), (13, 0.05206864234060049), (2, 0.06120603531599045), (1, 0.07061250694096088), (0, 0.14636892080307007), (18, 0.30379768460989), (36, 0.4071092940866947), (53, 0.9557027071714401)]
computing accuracy for after removing block 38 . block score: 0.014922500355169177
removed block 38 current accuracy 0.806 loss from initial  0.19399999999999995
training start
training epoch 0 val accuracy 0.7956 topk_dict {'top1': 0.7956} is_best False lr [0.1]
training epoch 1 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 2 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 3 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 5 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.1]
training epoch 6 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 7 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 8 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.1]
training epoch 9 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 10 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.961000)
finished training. finished 50 epochs. accuracy 0.961 topk_dict {'top1': 0.961}
start iteration 18
[activation diff]: block to remove picked: 40, with score 0.033458. All blocks and scores: [(40, 0.03345762053504586), (44, 0.0343117481097579), (43, 0.035810932982712984), (41, 0.0386775191873312), (45, 0.039150255266577005), (42, 0.04026272054761648), (37, 0.04188017640262842), (16, 0.04207222443073988), (39, 0.04353801952674985), (14, 0.04375001369044185), (9, 0.044583181384950876), (48, 0.04721241723746061), (51, 0.0485063293017447), (49, 0.049133009277284145), (46, 0.04932227684184909), (50, 0.04988762130960822), (8, 0.051101171877235174), (47, 0.053250743076205254), (7, 0.05654899310320616), (33, 0.05733587685972452), (52, 0.05950270453467965), (15, 0.07021300867199898), (34, 0.0705885486677289), (10, 0.0715191001072526), (12, 0.08236705791205168), (5, 0.0874927481636405), (6, 0.10301277041435242), (4, 0.10688940063118935), (3, 0.12654858268797398), (13, 0.14429055526852608), (2, 0.15025806054472923), (1, 0.17002761363983154), (0, 0.3304699920117855), (18, 0.5069265440106392), (36, 0.6581995785236359), (53, 1.0750077813863754)]
computing accuracy for after removing block 40 . block score: 0.03345762053504586
removed block 40 current accuracy 0.9556 loss from initial  0.044399999999999995
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.035267. All blocks and scores: [(44, 0.03526704292744398), (43, 0.03755313763394952), (45, 0.039963457733392715), (41, 0.04178541852161288), (37, 0.04188017826527357), (16, 0.04207222396507859), (39, 0.04353801999241114), (42, 0.0435785842128098), (14, 0.04375001508742571), (9, 0.04458318091928959), (48, 0.04813095321878791), (51, 0.04876683512702584), (49, 0.050557063426822424), (50, 0.0508804046548903), (46, 0.05101026128977537), (8, 0.051101171877235174), (47, 0.053826896008104086), (7, 0.056548993568867445), (33, 0.05733587592840195), (52, 0.06022860715165734), (15, 0.0702130114659667), (34, 0.0705885523930192), (10, 0.07151909731328487), (12, 0.08236705977469683), (5, 0.0874927481636405), (6, 0.10301277134567499), (4, 0.10688939690589905), (3, 0.12654857896268368), (13, 0.14429055340588093), (2, 0.15025806240737438), (1, 0.1700276043266058), (0, 0.3304699882864952), (18, 0.5069265365600586), (36, 0.6581995561718941), (53, 1.0767241269350052)]
computing accuracy for after removing block 44 . block score: 0.03526704292744398
removed block 44 current accuracy 0.9522 loss from initial  0.047799999999999954
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.037553. All blocks and scores: [(43, 0.03755313716828823), (41, 0.04178541852161288), (37, 0.04188017826527357), (16, 0.04207222443073988), (39, 0.04353801952674985), (42, 0.043578585144132376), (45, 0.04358843760564923), (14, 0.043750014156103134), (9, 0.044583179987967014), (48, 0.048238258343189955), (51, 0.048933794256299734), (8, 0.051101173274219036), (49, 0.051180738024413586), (50, 0.05198170896619558), (46, 0.052221087738871574), (47, 0.05597393540665507), (7, 0.056548991706222296), (33, 0.05733587592840195), (52, 0.059488354716449976), (15, 0.0702130114659667), (34, 0.07058855146169662), (10, 0.0715191001072526), (12, 0.08236705791205168), (5, 0.08749274723231792), (6, 0.10301277227699757), (4, 0.10688939969986677), (3, 0.12654858082532883), (13, 0.14429054968059063), (2, 0.15025806054472923), (1, 0.17002760991454124), (0, 0.3304699771106243), (18, 0.5069265440106392), (36, 0.6581995636224747), (53, 1.105079635977745)]
computing accuracy for after removing block 43 . block score: 0.03755313716828823
removed block 43 current accuracy 0.9478 loss from initial  0.052200000000000024
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.041785. All blocks and scores: [(41, 0.04178541945293546), (37, 0.04188017686828971), (16, 0.04207222303375602), (39, 0.04353801999241114), (42, 0.04357858560979366), (14, 0.04375001462176442), (9, 0.04458317952230573), (45, 0.045993098989129066), (48, 0.04685579100623727), (51, 0.048455416690558195), (8, 0.0511011746712029), (49, 0.0511658382602036), (50, 0.051927735563367605), (46, 0.05218237638473511), (47, 0.05632596230134368), (7, 0.05654899310320616), (33, 0.05733587732538581), (52, 0.0578217888250947), (15, 0.0702130114659667), (34, 0.07058855146169662), (10, 0.07151909824460745), (12, 0.0823670569807291), (5, 0.0874927481636405), (6, 0.10301276668906212), (4, 0.10688939597457647), (3, 0.12654858455061913), (13, 0.14429055340588093), (2, 0.15025806427001953), (1, 0.17002760618925095), (0, 0.3304699808359146), (18, 0.5069265440106392), (36, 0.6581995636224747), (53, 1.116162583231926)]
computing accuracy for after removing block 41 . block score: 0.04178541945293546
removed block 41 current accuracy 0.933 loss from initial  0.06699999999999995
since last training loss: 0.027999999999999914 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 37, with score 0.041880. All blocks and scores: [(37, 0.041880177333950996), (16, 0.042072223499417305), (39, 0.04353801906108856), (14, 0.043750014156103134), (9, 0.04458318091928959), (48, 0.04657042631879449), (45, 0.046778539195656776), (42, 0.04758818633854389), (51, 0.04779524402692914), (8, 0.05110117420554161), (49, 0.05190489534288645), (50, 0.052322615403681993), (46, 0.05299964174628258), (47, 0.056517818477004766), (7, 0.05654899310320616), (52, 0.05674520879983902), (33, 0.057335874531418085), (15, 0.07021300960332155), (34, 0.0705885523930192), (10, 0.07151909731328487), (12, 0.08236705884337425), (5, 0.08749274723231792), (6, 0.10301276948302984), (4, 0.10688939969986677), (3, 0.12654858268797398), (13, 0.14429055154323578), (2, 0.15025806054472923), (1, 0.17002761363983154), (0, 0.3304699882864952), (18, 0.5069265514612198), (36, 0.6581995636224747), (53, 1.1311805248260498)]
computing accuracy for after removing block 37 . block score: 0.041880177333950996
removed block 37 current accuracy 0.9228 loss from initial  0.07720000000000005
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 16, with score 0.042072. All blocks and scores: [(16, 0.04207222396507859), (14, 0.043750014156103134), (48, 0.04389937920495868), (9, 0.044583179987967014), (51, 0.04487175354734063), (39, 0.04578707739710808), (45, 0.046090268064290285), (50, 0.04910094663500786), (42, 0.049549445044249296), (49, 0.05007824441418052), (8, 0.05110117280855775), (46, 0.051262582652270794), (47, 0.052881295792758465), (52, 0.053042493760585785), (7, 0.056548993568867445), (33, 0.05733587546274066), (15, 0.07021300960332155), (34, 0.07058855053037405), (10, 0.07151909917593002), (12, 0.08236705977469683), (5, 0.08749275095760822), (6, 0.10301276575773954), (4, 0.10688939690589905), (3, 0.12654858268797398), (13, 0.14429055340588093), (2, 0.15025806613266468), (1, 0.17002760618925095), (0, 0.3304699920117855), (18, 0.5069265440106392), (36, 0.6581995710730553), (53, 1.1217474341392517)]
computing accuracy for after removing block 16 . block score: 0.04207222396507859
removed block 16 current accuracy 0.9164 loss from initial  0.08360000000000001
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.043623. All blocks and scores: [(48, 0.0436232197098434), (14, 0.04375001322478056), (51, 0.04394945269450545), (9, 0.044583179987967014), (39, 0.04565342189744115), (45, 0.04601356899365783), (50, 0.04831517767161131), (42, 0.04945995984598994), (49, 0.04971184674650431), (8, 0.05110117420554161), (46, 0.05117563949897885), (52, 0.052133865654468536), (47, 0.05225809756666422), (33, 0.056410614401102066), (7, 0.05654899310320616), (34, 0.06906955409795046), (15, 0.07021301239728928), (10, 0.07151909731328487), (12, 0.08236705791205168), (5, 0.0874927444383502), (6, 0.10301277320832014), (4, 0.10688940063118935), (3, 0.12654858268797398), (13, 0.14429055526852608), (2, 0.15025806240737438), (1, 0.17002760991454124), (0, 0.3304699882864952), (18, 0.5147685632109642), (36, 0.6547049507498741), (53, 1.1197220087051392)]
computing accuracy for after removing block 48 . block score: 0.0436232197098434
removed block 48 current accuracy 0.8978 loss from initial  0.10219999999999996
since last training loss: 0.06319999999999992 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 14, with score 0.043750. All blocks and scores: [(14, 0.04375001369044185), (9, 0.04458317952230573), (39, 0.04565342282876372), (45, 0.046013569459319115), (51, 0.04857003828510642), (42, 0.04945995984598994), (8, 0.05110117373988032), (46, 0.051175639033317566), (47, 0.05225809616968036), (50, 0.05270293727517128), (33, 0.05641061533242464), (7, 0.05654899263754487), (49, 0.057920453138649464), (52, 0.05858903098851442), (34, 0.06906955502927303), (15, 0.07021300960332155), (10, 0.0715190963819623), (12, 0.08236705884337425), (5, 0.08749274630099535), (6, 0.10301277041435242), (4, 0.10688939783722162), (3, 0.12654858082532883), (13, 0.14429055340588093), (2, 0.15025806240737438), (1, 0.1700276080518961), (0, 0.3304699882864952), (18, 0.5147685632109642), (36, 0.6547049582004547), (53, 1.221581757068634)]
computing accuracy for after removing block 14 . block score: 0.04375001369044185
removed block 14 current accuracy 0.8838 loss from initial  0.11619999999999997
since last training loss: 0.07719999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.044583. All blocks and scores: [(9, 0.044583181850612164), (45, 0.04512799344956875), (51, 0.04808981157839298), (39, 0.04853777075186372), (42, 0.048691370990127325), (8, 0.051101171877235174), (47, 0.051902266684919596), (50, 0.05198874697089195), (46, 0.05457561602815986), (33, 0.05635170778259635), (7, 0.05654899403452873), (52, 0.05761383846402168), (49, 0.058188669849187136), (34, 0.06745007168501616), (10, 0.07151909824460745), (15, 0.07416071929037571), (12, 0.08236705791205168), (5, 0.08749274630099535), (6, 0.10301276855170727), (4, 0.10688939969986677), (3, 0.12654858268797398), (13, 0.14429055340588093), (2, 0.15025806427001953), (1, 0.1700276117771864), (0, 0.3304699808359146), (18, 0.5322008579969406), (36, 0.6791410371661186), (53, 1.2048789709806442)]
computing accuracy for after removing block 9 . block score: 0.044583181850612164
removed block 9 current accuracy 0.8612 loss from initial  0.13880000000000003
training start
training epoch 0 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.1]
training epoch 1 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.1]
training epoch 2 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 3 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.1]
training epoch 4 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 5 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 6 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.1]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 9 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.053601. All blocks and scores: [(51, 0.05360137578099966), (45, 0.05867272661998868), (50, 0.06244877493008971), (49, 0.062481936533004045), (46, 0.0645096180960536), (52, 0.06587808392941952), (42, 0.06830071099102497), (47, 0.07105829194188118), (7, 0.07138360757380724), (39, 0.07404421269893646), (8, 0.07971833366900682), (10, 0.08255503792315722), (15, 0.08765575475990772), (34, 0.08975333627313375), (33, 0.09088278282433748), (5, 0.09628575760871172), (12, 0.1005458366125822), (6, 0.10183858592063189), (4, 0.12317380402237177), (3, 0.13008803315460682), (2, 0.1692071668803692), (1, 0.17540808022022247), (13, 0.1948545891791582), (0, 0.34708693623542786), (18, 0.5686729177832603), (36, 0.624439537525177), (53, 1.1678573936223984)]
computing accuracy for after removing block 51 . block score: 0.05360137578099966
removed block 51 current accuracy 0.935 loss from initial  0.06499999999999995
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 45, with score 0.058673. All blocks and scores: [(45, 0.05867272615432739), (50, 0.06244877493008971), (49, 0.06248193560168147), (46, 0.06450961716473103), (42, 0.06830071192234755), (47, 0.0710582947358489), (7, 0.07138360850512981), (52, 0.07143031060695648), (39, 0.07404420897364616), (8, 0.0797183346003294), (10, 0.08255503792315722), (15, 0.08765575662255287), (34, 0.08975333254784346), (33, 0.09088278375566006), (5, 0.0962857585400343), (12, 0.10054583102464676), (6, 0.10183858219534159), (4, 0.12317380215972662), (3, 0.13008803874254227), (2, 0.16920716874301434), (1, 0.17540808022022247), (13, 0.19485458359122276), (0, 0.34708693996071815), (18, 0.5686729177832603), (36, 0.6244395300745964), (53, 1.3330778777599335)]
computing accuracy for after removing block 45 . block score: 0.05867272615432739
removed block 45 current accuracy 0.9226 loss from initial  0.07740000000000002
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 50, with score 0.064819. All blocks and scores: [(50, 0.06481928285211325), (49, 0.065409024246037), (42, 0.0683007100597024), (7, 0.07138360477983952), (52, 0.0731613477692008), (46, 0.07335584983229637), (47, 0.07365608587861061), (39, 0.07404421176761389), (8, 0.0797183346003294), (10, 0.08255504071712494), (15, 0.0876557556912303), (34, 0.08975333720445633), (33, 0.09088278282433748), (5, 0.09628575947135687), (12, 0.10054583474993706), (6, 0.10183858312666416), (4, 0.12317379750311375), (3, 0.13008803129196167), (2, 0.1692071594297886), (1, 0.17540807835757732), (13, 0.1948545891791582), (0, 0.34708692878484726), (18, 0.5686729252338409), (36, 0.6244395077228546), (53, 1.3819051086902618)]
computing accuracy for after removing block 50 . block score: 0.06481928285211325
removed block 50 current accuracy 0.8972 loss from initial  0.1028
since last training loss: 0.05059999999999998 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.065409. All blocks and scores: [(49, 0.06540902517735958), (42, 0.06830071099102497), (7, 0.07138361129909754), (46, 0.0733558526262641), (47, 0.07365608774125576), (39, 0.07404421363025904), (8, 0.07971833553165197), (10, 0.08255503885447979), (15, 0.08765575475990772), (34, 0.08975333347916603), (52, 0.09039363451302052), (33, 0.09088278282433748), (5, 0.09628575667738914), (12, 0.10054583474993706), (6, 0.10183858685195446), (4, 0.12317380215972662), (3, 0.13008803687989712), (2, 0.16920716501772404), (1, 0.17540807649493217), (13, 0.1948545891791582), (0, 0.34708693251013756), (18, 0.5686729177832603), (36, 0.6244395226240158), (53, 1.6149885058403015)]
computing accuracy for after removing block 49 . block score: 0.06540902517735958
removed block 49 current accuracy 0.8454 loss from initial  0.15459999999999996
since last training loss: 0.10239999999999994 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 42, with score 0.068301. All blocks and scores: [(42, 0.06830070912837982), (7, 0.07138360850512981), (46, 0.07335585076361895), (47, 0.07365608587861061), (39, 0.07404421083629131), (8, 0.07971833646297455), (10, 0.08255503699183464), (15, 0.0876557556912303), (34, 0.08975333534181118), (33, 0.09088278282433748), (5, 0.0962857585400343), (52, 0.09658659156411886), (12, 0.10054583474993706), (6, 0.10183858405798674), (4, 0.12317380402237177), (3, 0.13008803501725197), (2, 0.1692071631550789), (1, 0.17540807835757732), (13, 0.19485458359122276), (0, 0.34708693623542786), (18, 0.5686729177832603), (36, 0.624439537525177), (53, 1.8168877810239792)]
computing accuracy for after removing block 42 . block score: 0.06830070912837982
removed block 42 current accuracy 0.8034 loss from initial  0.1966
since last training loss: 0.14439999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 7, with score 0.071384. All blocks and scores: [(7, 0.07138360850512981), (39, 0.07404421269893646), (47, 0.07574936375021935), (46, 0.07772033847868443), (8, 0.07971833553165197), (10, 0.08255504071712494), (15, 0.08765575382858515), (34, 0.08975333254784346), (33, 0.09088278654962778), (52, 0.09270528517663479), (5, 0.09628576040267944), (12, 0.1005458366125822), (6, 0.10183858405798674), (4, 0.12317380215972662), (3, 0.13008804060518742), (2, 0.16920717060565948), (1, 0.17540808022022247), (13, 0.1948545929044485), (0, 0.34708693996071815), (18, 0.5686729028820992), (36, 0.6244395226240158), (53, 1.9849854707717896)]
computing accuracy for after removing block 7 . block score: 0.07138360850512981
removed block 7 current accuracy 0.7886 loss from initial  0.21140000000000003
since last training loss: 0.1592 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 10, with score 0.071855. All blocks and scores: [(10, 0.07185474596917629), (39, 0.0722624035552144), (46, 0.0730530433356762), (47, 0.07392948772758245), (8, 0.08087452221661806), (15, 0.08453735150396824), (34, 0.08667329605668783), (33, 0.0872917789965868), (52, 0.09182161279022694), (12, 0.09399294294416904), (5, 0.09628576133400202), (6, 0.10183858405798674), (4, 0.1231738030910492), (3, 0.13008803874254227), (2, 0.1692071631550789), (1, 0.17540808022022247), (13, 0.18688327632844448), (0, 0.34708692878484726), (18, 0.538862369954586), (36, 0.5959979295730591), (53, 1.9696806222200394)]
computing accuracy for after removing block 10 . block score: 0.07185474596917629
removed block 10 current accuracy 0.7796 loss from initial  0.22040000000000004
since last training loss: 0.16820000000000002 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.070801. All blocks and scores: [(39, 0.07080136239528656), (47, 0.07220240496098995), (46, 0.07495720218867064), (8, 0.08087452128529549), (34, 0.0829548966139555), (33, 0.08378421608358622), (15, 0.08687531854957342), (52, 0.09192951023578644), (5, 0.09628575760871172), (6, 0.10183858685195446), (12, 0.10550025384873152), (4, 0.12317380588501692), (3, 0.13008803687989712), (2, 0.16920717060565948), (1, 0.17540807835757732), (13, 0.20342296920716763), (0, 0.34708693623542786), (18, 0.5290812030434608), (36, 0.5916892439126968), (53, 1.962190181016922)]
computing accuracy for after removing block 39 . block score: 0.07080136239528656
removed block 39 current accuracy 0.74 loss from initial  0.26
since last training loss: 0.20779999999999998 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 47, with score 0.074298. All blocks and scores: [(47, 0.07429757807403803), (8, 0.08087452221661806), (46, 0.08151951152831316), (34, 0.08295489754527807), (33, 0.08378421328961849), (15, 0.0868753157556057), (52, 0.09502318128943443), (5, 0.09628575947135687), (6, 0.10183858592063189), (12, 0.10550025198608637), (4, 0.1231738030910492), (3, 0.13008803687989712), (2, 0.16920717060565948), (1, 0.17540808022022247), (13, 0.20342296548187733), (0, 0.34708693996071815), (18, 0.529081217944622), (36, 0.5916892290115356), (53, 2.083674371242523)]
computing accuracy for after removing block 47 . block score: 0.07429757807403803
removed block 47 current accuracy 0.6376 loss from initial  0.36240000000000006
since last training loss: 0.31020000000000003 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 8, with score 0.080875. All blocks and scores: [(8, 0.08087452221661806), (46, 0.08151950966566801), (34, 0.08295489568263292), (33, 0.08378421235829592), (15, 0.086875319480896), (5, 0.0962857585400343), (52, 0.09678334463387728), (6, 0.10183858685195446), (12, 0.10550025198608637), (4, 0.1231738030910492), (3, 0.13008803501725197), (2, 0.16920716501772404), (1, 0.17540808022022247), (13, 0.20342296920716763), (0, 0.34708693251013756), (18, 0.5290812030434608), (36, 0.5916892364621162), (53, 2.2651977837085724)]
computing accuracy for after removing block 8 . block score: 0.08087452221661806
removed block 8 current accuracy 0.6184 loss from initial  0.38160000000000005
since last training loss: 0.3294 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 46, with score 0.080934. All blocks and scores: [(46, 0.0809343121945858), (34, 0.08354430552572012), (33, 0.08561435807496309), (15, 0.08618468139320612), (52, 0.09519129525870085), (5, 0.09628575667738914), (6, 0.10183858498930931), (12, 0.10289084445685148), (4, 0.12317380681633949), (3, 0.13008803687989712), (2, 0.1692071631550789), (1, 0.17540807649493217), (13, 0.20506161078810692), (0, 0.34708693623542786), (18, 0.5164034441113472), (36, 0.5821076259016991), (53, 2.1562501192092896)]
computing accuracy for after removing block 46 . block score: 0.0809343121945858
removed block 46 current accuracy 0.53 loss from initial  0.47
since last training loss: 0.41779999999999995 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 34, with score 0.083544. All blocks and scores: [(34, 0.0835443064570427), (33, 0.08561435900628567), (15, 0.08618468418717384), (5, 0.0962857585400343), (52, 0.0988357625901699), (6, 0.10183858405798674), (12, 0.10289084166288376), (4, 0.12317379843443632), (3, 0.13008803315460682), (2, 0.16920716501772404), (1, 0.17540807463228703), (13, 0.20506161265075207), (0, 0.34708693251013756), (18, 0.516403466463089), (36, 0.5821076259016991), (53, 2.333990842103958)]
computing accuracy for after removing block 34 . block score: 0.0835443064570427
removed block 34 current accuracy 0.4972 loss from initial  0.5028
training start
training epoch 0 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best True lr [0.1]
training epoch 1 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.1]
training epoch 2 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best True lr [0.1]
training epoch 3 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best True lr [0.1]
training epoch 4 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 5 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 6 val accuracy 0.8158 topk_dict {'top1': 0.8158} is_best False lr [0.1]
training epoch 7 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 8 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 9 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 10 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.924000)
finished training. finished 50 epochs. accuracy 0.924 topk_dict {'top1': 0.924}
