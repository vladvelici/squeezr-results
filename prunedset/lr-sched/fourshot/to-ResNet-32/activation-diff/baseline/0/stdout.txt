start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806163564324), (30, 0.007531446171924472), (2, 0.007728804950602353), (31, 0.009409212390892208), (34, 0.010633390629664063), (33, 0.010768218780867755), (35, 0.010826650657691061), (32, 0.011131544597446918), (28, 0.012192570720799267), (29, 0.01309263939037919), (26, 0.013270106166601181), (25, 0.0147630013525486), (27, 0.015783545095473528), (24, 0.01580519019626081), (22, 0.01584369922056794), (23, 0.017308010021224618), (39, 0.01998384390026331), (42, 0.020841387566179037), (38, 0.021028662798926234), (14, 0.021516708424314857), (43, 0.021687703672796488), (5, 0.02187711768783629), (41, 0.022125155199319124), (44, 0.022776450496166945), (45, 0.023535519372671843), (40, 0.02422963408753276), (47, 0.024651851505041122), (37, 0.02517395978793502), (49, 0.025184793630614877), (3, 0.025671070674434304), (21, 0.025702943559736013), (50, 0.02576585952192545), (20, 0.027230343548581004), (46, 0.028618559706956148), (17, 0.029949785443022847), (51, 0.031313665676862), (48, 0.03152880095876753), (19, 0.034745858050882816), (16, 0.04510569479316473), (15, 0.04667254630476236), (0, 0.047461547423154116), (6, 0.05039410013705492), (7, 0.050692159216850996), (4, 0.05092597333714366), (10, 0.06328557664528489), (13, 0.06400972884148359), (8, 0.06672556232661009), (52, 0.06828812137246132), (12, 0.07267716992646456), (11, 0.07419469859451056), (9, 0.07928675040602684), (36, 0.3385251760482788), (18, 0.4787600561976433), (53, 0.9074814692139626)]
computing accuracy for after removing block 1 . block score: 0.004111806163564324
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.007558359357062727), (2, 0.007992399798240513), (31, 0.009376695845276117), (34, 0.01056909782346338), (33, 0.010759366443380713), (35, 0.01083379180636257), (32, 0.011090524378232658), (28, 0.012191424844786525), (29, 0.01314087409991771), (26, 0.0133111122995615), (25, 0.014746290864422917), (24, 0.015801146859303117), (22, 0.015853286604397), (27, 0.015870402101427317), (23, 0.01725019607692957), (39, 0.019925505854189396), (42, 0.020839826902374625), (38, 0.020938864909112453), (5, 0.021410029847174883), (14, 0.021470679668709636), (43, 0.021646990906447172), (41, 0.022096744272857904), (44, 0.02283085067756474), (45, 0.0234941893722862), (40, 0.024263028521090746), (47, 0.02462643221952021), (37, 0.02515707165002823), (49, 0.025184771977365017), (21, 0.025624872650951147), (50, 0.025800991104915738), (3, 0.026267620734870434), (20, 0.027126540895551443), (46, 0.028638296527788043), (17, 0.030022146413102746), (51, 0.031291102059185505), (48, 0.031514890026301146), (19, 0.03466663137078285), (16, 0.04479835694655776), (15, 0.046408085618168116), (0, 0.04746154835447669), (4, 0.050930493511259556), (6, 0.051349631045013666), (7, 0.051561571191996336), (10, 0.06291997712105513), (13, 0.06426404323428869), (52, 0.06817463133484125), (8, 0.0683986684307456), (12, 0.07294023409485817), (11, 0.07450826652348042), (9, 0.08042858820408583), (36, 0.3383275717496872), (18, 0.4787031225860119), (53, 0.9076695889234543)]
computing accuracy for after removing block 30 . block score: 0.007558359357062727
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992399507202208), (31, 0.009402871481142938), (34, 0.010204410296864808), (35, 0.010435783653520048), (33, 0.010974526638165116), (32, 0.011320484918542206), (28, 0.012191425077617168), (29, 0.013140873867087066), (26, 0.013311112532392144), (25, 0.014746291097253561), (24, 0.01580114709213376), (22, 0.015853287070058286), (27, 0.015870402101427317), (23, 0.017250196542590857), (39, 0.01986637688241899), (38, 0.020629742415621877), (42, 0.020691831596195698), (5, 0.021410029847174883), (14, 0.021470680367201567), (43, 0.021839084569364786), (41, 0.022011037450283766), (44, 0.02278478746302426), (45, 0.023337426595389843), (47, 0.024608809733763337), (40, 0.024793642107397318), (49, 0.025005090050399303), (21, 0.025624873349443078), (37, 0.025666437577456236), (50, 0.02576501900330186), (3, 0.02626762166619301), (20, 0.027126540895551443), (46, 0.028450446901842952), (17, 0.03002214664593339), (51, 0.030892509734258056), (48, 0.031455071875825524), (19, 0.03466663137078285), (16, 0.04479835694655776), (15, 0.046408084221184254), (0, 0.047461549285799265), (4, 0.05093049397692084), (6, 0.05134963057935238), (7, 0.05156157165765762), (10, 0.06291997572407126), (13, 0.06426404230296612), (52, 0.06774707417935133), (8, 0.06839867029339075), (12, 0.0729402331635356), (11, 0.07450826652348042), (9, 0.08042858727276325), (36, 0.341789361089468), (18, 0.4787031225860119), (53, 0.9106026589870453)]
computing accuracy for after removing block 2 . block score: 0.007992399507202208
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.009391383733600378), (34, 0.010356180020608008), (35, 0.010530833969824016), (33, 0.010978628182783723), (32, 0.011285086045973003), (28, 0.012222225428558886), (29, 0.01339500502217561), (26, 0.013411890249699354), (25, 0.014773016097024083), (24, 0.015895847463980317), (22, 0.015945045743137598), (27, 0.016057065688073635), (23, 0.017187519697472453), (39, 0.019868449307978153), (42, 0.020744004286825657), (38, 0.020750499330461025), (5, 0.02111735171638429), (14, 0.021327618043869734), (43, 0.02179282298311591), (41, 0.021959960227832198), (44, 0.022877607960253954), (45, 0.023284759372472763), (47, 0.024535594042390585), (40, 0.024922655429691076), (49, 0.024976717540994287), (21, 0.02554046781733632), (50, 0.025736608309671283), (37, 0.02574000204913318), (3, 0.026626083767041564), (20, 0.027130911592394114), (46, 0.028354251757264137), (17, 0.030052858404815197), (51, 0.03080705483444035), (48, 0.03136400459334254), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462547659874), (0, 0.04746154882013798), (4, 0.05093384673818946), (7, 0.05248213466256857), (6, 0.05318682920187712), (10, 0.06307358667254448), (13, 0.06417542695999146), (52, 0.06737186666578054), (8, 0.07143167965114117), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.0819232128560543), (36, 0.342931903898716), (18, 0.48187142238020897), (53, 0.9105552807450294)]
computing accuracy for after removing block 31 . block score: 0.009391383733600378
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670424349606), (35, 0.010449821245856583), (33, 0.01098572218324989), (32, 0.011304144863970578), (28, 0.012222225428558886), (29, 0.013395004789344966), (26, 0.01341189059894532), (25, 0.01477301586419344), (24, 0.01589584769681096), (22, 0.015945045510306954), (27, 0.01605706592090428), (23, 0.01718752016313374), (39, 0.01979714771732688), (38, 0.02034430461935699), (42, 0.020588676910847425), (5, 0.02111735171638429), (14, 0.02132761850953102), (43, 0.021761029725894332), (41, 0.02186914556659758), (44, 0.022828260203823447), (45, 0.023396300617605448), (47, 0.02450825716368854), (49, 0.024995684158056974), (40, 0.025056052021682262), (21, 0.025540468050166965), (37, 0.02570135099813342), (50, 0.02590625174343586), (3, 0.02662608353421092), (20, 0.02713091019541025), (46, 0.02855197270400822), (17, 0.03005285793915391), (51, 0.030911056557670236), (48, 0.031486503314226866), (19, 0.03459096746519208), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.04746154509484768), (4, 0.05093384860083461), (7, 0.05248213466256857), (6, 0.053186831530183554), (10, 0.06307358667254448), (13, 0.06417542602866888), (52, 0.06731625739485025), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.34496788680553436), (18, 0.48187144100666046), (53, 0.9170897379517555)]
computing accuracy for after removing block 34 . block score: 0.010089670424349606
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489318054169416), (33, 0.01098572218324989), (32, 0.011304144747555256), (28, 0.012222225428558886), (29, 0.013395004323683679), (26, 0.013411890366114676), (25, 0.014773016329854727), (24, 0.015895847231149673), (22, 0.01594504527747631), (27, 0.01605706592090428), (23, 0.01718752016313374), (39, 0.019266640534624457), (38, 0.019315700279548764), (42, 0.019673912087455392), (5, 0.02111735101789236), (41, 0.021174800349399447), (43, 0.021180002251639962), (14, 0.021327618276700377), (44, 0.02225361089222133), (45, 0.023224938428029418), (47, 0.024223520420491695), (49, 0.024662331910803914), (40, 0.02475132793188095), (37, 0.02511494606733322), (21, 0.025540468748658895), (50, 0.025639905594289303), (3, 0.02662608353421092), (20, 0.02713091135956347), (46, 0.028075408656150103), (17, 0.030052858870476484), (51, 0.030307046370580792), (48, 0.031094569945707917), (19, 0.03459096699953079), (16, 0.04449417069554329), (15, 0.04618462501093745), (0, 0.0474615478888154), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.05318683199584484), (10, 0.06307358853518963), (13, 0.06417542602866888), (52, 0.06632223539054394), (8, 0.07143167778849602), (12, 0.0729450760409236), (11, 0.07423978857696056), (9, 0.08192321565002203), (36, 0.3418983221054077), (18, 0.48187143728137016), (53, 0.9368007779121399)]
computing accuracy for after removing block 35 . block score: 0.010489318054169416
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.010985722066834569), (32, 0.011304144747555256), (28, 0.01222222566138953), (29, 0.013395005138590932), (26, 0.013411890715360641), (25, 0.014773015398532152), (24, 0.01589584769681096), (22, 0.015945045743137598), (27, 0.016057066153734922), (23, 0.01718751946464181), (38, 0.018365238793194294), (39, 0.01873115892522037), (42, 0.018845457583665848), (41, 0.02022721921093762), (43, 0.020478624384850264), (5, 0.021117351483553648), (14, 0.02132761781103909), (44, 0.021796140121296048), (45, 0.022849174682050943), (47, 0.023645549779757857), (40, 0.02389344177208841), (49, 0.024012630805373192), (37, 0.024080609437078238), (50, 0.025119470665231347), (21, 0.025540467584505677), (3, 0.026626084465533495), (20, 0.02713091135956347), (46, 0.027472961926832795), (51, 0.029444649117067456), (17, 0.030052859103307128), (48, 0.030196279054507613), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462547659874), (0, 0.0474615478888154), (4, 0.05093384813517332), (7, 0.05248213466256857), (6, 0.053186831064522266), (10, 0.06307358853518963), (13, 0.06417542695999146), (52, 0.06433123257011175), (8, 0.07143167685717344), (12, 0.07294507883489132), (11, 0.07423979230225086), (9, 0.08192321471869946), (36, 0.335262943059206), (18, 0.48187142983078957), (53, 0.958902508020401)]
computing accuracy for after removing block 33 . block score: 0.010985722066834569
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144747555256), (28, 0.01222222566138953), (29, 0.013395005138590932), (26, 0.013411890715360641), (25, 0.01477301586419344), (24, 0.015895847231149673), (22, 0.01594504527747631), (27, 0.016057065688073635), (23, 0.017187519697472453), (38, 0.017859897576272488), (39, 0.01848121453076601), (42, 0.018494685646146536), (41, 0.019707750994712114), (43, 0.019804098876193166), (5, 0.021117351949214935), (14, 0.021327618276700377), (44, 0.021341139217838645), (45, 0.02275731274858117), (47, 0.02288467320613563), (40, 0.022964163916185498), (49, 0.023509373189881444), (37, 0.023596108658239245), (50, 0.024730789475142956), (21, 0.02554046781733632), (3, 0.026626083301380277), (46, 0.02685158746317029), (20, 0.027130910893902183), (51, 0.02867021202109754), (48, 0.02950064931064844), (17, 0.030052859568968415), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.0461846268735826), (0, 0.047461546026170254), (4, 0.05093384860083461), (7, 0.05248213419690728), (6, 0.05318683059886098), (52, 0.06240901490673423), (10, 0.06307358853518963), (13, 0.06417542602866888), (8, 0.07143167871981859), (12, 0.07294507697224617), (11, 0.07423979043960571), (9, 0.08192321471869946), (36, 0.33049973100423813), (18, 0.48187142983078957), (53, 0.9826682507991791)]
computing accuracy for after removing block 32 . block score: 0.011304144747555256
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012222. All blocks and scores: [(28, 0.01222222566138953), (29, 0.013395005487836897), (26, 0.01341189059894532), (25, 0.01477301656268537), (24, 0.015895847463980317), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.017423493787646294), (42, 0.01785332732833922), (39, 0.018243112368509173), (41, 0.01957745454274118), (43, 0.01959067233838141), (44, 0.02097980212420225), (5, 0.021117351483553648), (14, 0.021327618043869734), (47, 0.022578312316909432), (45, 0.022697477601468563), (37, 0.022853391245007515), (49, 0.023190515814349055), (40, 0.023227871861308813), (50, 0.024362223455682397), (21, 0.02554046711884439), (46, 0.026505474001169205), (3, 0.026626083767041564), (20, 0.02713091135956347), (51, 0.02819360769353807), (48, 0.02943548862822354), (17, 0.030052858171984553), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.04618462547659874), (0, 0.047461546026170254), (4, 0.05093384999781847), (7, 0.052482131868600845), (6, 0.05318683059886098), (52, 0.06163395056501031), (10, 0.06307358667254448), (13, 0.06417542323470116), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3290293700993061), (18, 0.48187142238020897), (53, 0.9939456731081009)]
computing accuracy for after removing block 28 . block score: 0.01222222566138953
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
training start
training epoch 0 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 3 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 4 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 5 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 6 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 7 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 8 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 9 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 10 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.013134. All blocks and scores: [(29, 0.013134447974152863), (26, 0.01341189059894532), (25, 0.014773016213439405), (24, 0.015895847463980317), (22, 0.015945045510306954), (27, 0.016057065222412348), (38, 0.017168684862554073), (23, 0.01718752016313374), (42, 0.01737769739702344), (39, 0.018261886667460203), (43, 0.01912656961940229), (41, 0.019421309931203723), (44, 0.02071693423204124), (5, 0.021117351483553648), (14, 0.021327618276700377), (47, 0.02212475100532174), (45, 0.022405647207051516), (37, 0.02259774273261428), (40, 0.022692735074087977), (49, 0.02275928622111678), (50, 0.024160553701221943), (21, 0.025540468282997608), (46, 0.02618824504315853), (3, 0.026626083301380277), (20, 0.027130911592394114), (51, 0.027606616262346506), (48, 0.02895548567175865), (17, 0.03005285933613777), (19, 0.03459096699953079), (16, 0.04449417209252715), (15, 0.04618462501093745), (0, 0.04746154649183154), (4, 0.050933849066495895), (7, 0.05248213326558471), (6, 0.05318683246150613), (52, 0.060717643704265356), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143167778849602), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.08192321471869946), (36, 0.3257451541721821), (18, 0.48187142983078957), (53, 1.0072815641760826)]
computing accuracy for after removing block 29 . block score: 0.013134447974152863
removed block 29 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013412. All blocks and scores: [(26, 0.013411890249699354), (25, 0.014773016097024083), (24, 0.01589584769681096), (22, 0.015945045510306954), (27, 0.016057065688073635), (38, 0.016528347739949822), (23, 0.017187519697472453), (42, 0.01752680167555809), (39, 0.018013010499998927), (43, 0.018969026627019048), (41, 0.019220214569941163), (44, 0.020273722242563963), (5, 0.021117351949214935), (14, 0.021327618043869734), (47, 0.02195585542358458), (45, 0.02227604598738253), (49, 0.022341078845784068), (37, 0.022382005816325545), (40, 0.022958485642448068), (50, 0.024057543138042092), (21, 0.02554046781733632), (46, 0.026293946895748377), (3, 0.026626083999872208), (20, 0.027130911126732826), (51, 0.02732984023168683), (48, 0.028983933152630925), (17, 0.03005285933613777), (19, 0.03459096699953079), (16, 0.04449417255818844), (15, 0.04618462594226003), (0, 0.04746154695749283), (4, 0.05093384953215718), (7, 0.05248213326558471), (6, 0.053186831064522266), (52, 0.06034902576357126), (10, 0.06307358760386705), (13, 0.06417542416602373), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321471869946), (36, 0.33013899251818657), (18, 0.48187143728137016), (53, 1.0144704580307007)]
computing accuracy for after removing block 26 . block score: 0.013411890249699354
removed block 26 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014773. All blocks and scores: [(25, 0.014773016329854727), (24, 0.01589584699831903), (22, 0.015945045044645667), (38, 0.016351457219570875), (27, 0.016416134545579553), (42, 0.01696831127628684), (23, 0.017187519930303097), (39, 0.017595985671505332), (43, 0.018648818600922823), (41, 0.018973202677443624), (44, 0.02003990951925516), (5, 0.02111735101789236), (14, 0.021327617345377803), (47, 0.021771238883957267), (45, 0.02202610089443624), (49, 0.022116392385214567), (37, 0.022165502654388547), (40, 0.022654106840491295), (50, 0.02414753893390298), (21, 0.02554046781733632), (46, 0.0257268650457263), (51, 0.026582257822155952), (3, 0.02662608353421092), (20, 0.027130911825224757), (48, 0.028896388597786427), (17, 0.030052859103307128), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.04618462547659874), (0, 0.0474615478888154), (4, 0.05093384860083461), (7, 0.05248213419690728), (6, 0.05318683013319969), (52, 0.05931285209953785), (10, 0.06307358900085092), (13, 0.06417542416602373), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423978857696056), (9, 0.08192321751266718), (36, 0.32769153639674187), (18, 0.48187143728137016), (53, 1.0349864810705185)]
computing accuracy for after removing block 25 . block score: 0.014773016329854727
removed block 25 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.015896. All blocks and scores: [(24, 0.015895847463980317), (22, 0.015945045743137598), (38, 0.016116746235638857), (27, 0.016201818361878395), (42, 0.016800900222733617), (39, 0.017148226033896208), (23, 0.017187519930303097), (43, 0.018563210032880306), (41, 0.018886165227741003), (44, 0.019977419869974256), (5, 0.02111735171638429), (14, 0.021327617345377803), (47, 0.02137071336619556), (49, 0.021683972096070647), (45, 0.021750156302005053), (37, 0.021764446515589952), (40, 0.022557188058272004), (50, 0.024213683791458607), (21, 0.025540467584505677), (46, 0.02557919709943235), (51, 0.025892006931826472), (3, 0.02662608353421092), (20, 0.027130910893902183), (48, 0.028420995455235243), (17, 0.030052859568968415), (19, 0.03459096699953079), (16, 0.044494171161204576), (15, 0.046184624545276165), (0, 0.04746154695749283), (4, 0.05093384813517332), (7, 0.05248213419690728), (6, 0.05318683059886098), (52, 0.05805371981114149), (10, 0.06307358853518963), (13, 0.0641754250973463), (8, 0.07143168058246374), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321565002203), (36, 0.330859437584877), (18, 0.48187144473195076), (53, 1.0488152652978897)]
computing accuracy for after removing block 24 . block score: 0.015895847463980317
removed block 24 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015644. All blocks and scores: [(27, 0.015644042170606554), (38, 0.015937610063701868), (22, 0.015945045044645667), (42, 0.01661075628362596), (39, 0.017013835720717907), (23, 0.017187519930303097), (43, 0.018406943418085575), (41, 0.01871691015549004), (44, 0.01980676525272429), (47, 0.021023611770942807), (5, 0.02111735101789236), (14, 0.021327618276700377), (49, 0.021376667311415076), (45, 0.021665898617357016), (37, 0.022019793977960944), (40, 0.022359848022460938), (50, 0.024096909910440445), (46, 0.025163474027067423), (51, 0.025269009871408343), (21, 0.025540467584505677), (3, 0.026626083767041564), (20, 0.027130910893902183), (48, 0.027973036281764507), (17, 0.03005285933613777), (19, 0.03459096746519208), (16, 0.044494171161204576), (15, 0.046184624545276165), (0, 0.0474615478888154), (4, 0.05093384813517332), (7, 0.05248213466256857), (6, 0.05318683013319969), (52, 0.05717874551191926), (10, 0.06307358480989933), (13, 0.06417542695999146), (8, 0.07143167778849602), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321565002203), (36, 0.3319184221327305), (18, 0.48187142610549927), (53, 1.056150808930397)]
computing accuracy for after removing block 27 . block score: 0.015644042170606554
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.015308. All blocks and scores: [(38, 0.015307825757190585), (22, 0.015945044811815023), (42, 0.01651047053746879), (39, 0.016512590926140547), (23, 0.01718752016313374), (43, 0.017808301141485572), (41, 0.01852318551391363), (44, 0.01999679859727621), (47, 0.020540194818750024), (49, 0.021024908404797316), (5, 0.021117351250723004), (14, 0.021327618276700377), (45, 0.02142173401080072), (37, 0.021547694457694888), (40, 0.021974622504785657), (50, 0.02440070523880422), (46, 0.02471923502162099), (51, 0.024754389887675643), (21, 0.025540468050166965), (3, 0.026626083999872208), (20, 0.027130910893902183), (48, 0.02760885003954172), (17, 0.030052858870476484), (19, 0.034590966533869505), (16, 0.044494171161204576), (15, 0.04618462501093745), (0, 0.047461546026170254), (4, 0.05093384673818946), (7, 0.052482133731245995), (6, 0.05318683059886098), (52, 0.056192458141595125), (10, 0.06307358667254448), (13, 0.06417542323470116), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321378737688), (36, 0.3304779455065727), (18, 0.48187142983078957), (53, 1.0667929649353027)]
computing accuracy for after removing block 38 . block score: 0.015307825757190585
removed block 38 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.015945. All blocks and scores: [(22, 0.015945045743137598), (42, 0.016701200744137168), (39, 0.017114691203460097), (23, 0.017187519930303097), (43, 0.017193771665915847), (41, 0.018250516150146723), (44, 0.019619957311078906), (47, 0.020091190235689282), (49, 0.020288462517783046), (45, 0.020802827551960945), (5, 0.021117351250723004), (14, 0.021327618043869734), (37, 0.02154769515618682), (40, 0.022401680005714297), (50, 0.023554304614663124), (51, 0.02370941312983632), (46, 0.02471372624859214), (21, 0.025540468050166965), (3, 0.02662608353421092), (48, 0.02690607775002718), (20, 0.027130911126732826), (17, 0.030052859103307128), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.047461549285799265), (4, 0.050933847203850746), (7, 0.052482133731245995), (6, 0.05318683059886098), (52, 0.054677230771631), (10, 0.06307358760386705), (13, 0.0641754250973463), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321378737688), (36, 0.33047793433070183), (18, 0.48187143728137016), (53, 1.099235475063324)]
computing accuracy for after removing block 22 . block score: 0.015945045743137598
removed block 22 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.016116. All blocks and scores: [(42, 0.01611585426144302), (23, 0.01675163395702839), (39, 0.01716357981786132), (43, 0.017340539023280144), (41, 0.01835115230642259), (44, 0.01973160309717059), (47, 0.019744616467505693), (49, 0.019967120373621583), (45, 0.02083969349041581), (5, 0.02111735101789236), (14, 0.021327618043869734), (37, 0.021559265907853842), (40, 0.02183614717796445), (51, 0.023225211538374424), (50, 0.023681905819103122), (46, 0.024719639914110303), (21, 0.025540468050166965), (48, 0.02641315315850079), (3, 0.02662608423270285), (20, 0.027130911126732826), (17, 0.030052859103307128), (19, 0.03459096699953079), (16, 0.044494170229882), (15, 0.04618462547659874), (0, 0.04746154649183154), (4, 0.05093384766951203), (7, 0.052482135128229856), (6, 0.05318683246150613), (52, 0.05412210803478956), (10, 0.06307358853518963), (13, 0.06417542695999146), (8, 0.07143168058246374), (12, 0.07294507883489132), (11, 0.07423979043960571), (9, 0.08192321471869946), (36, 0.3307998850941658), (18, 0.48187143728137016), (53, 1.1102152466773987)]
computing accuracy for after removing block 42 . block score: 0.01611585426144302
removed block 42 current accuracy 0.9696 loss from initial  0.030399999999999983
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016752. All blocks and scores: [(23, 0.016751633724197745), (39, 0.017163580283522606), (41, 0.01835115230642259), (43, 0.01839060429483652), (49, 0.019832697696983814), (47, 0.019929534988477826), (44, 0.020700426073744893), (5, 0.02111735218204558), (14, 0.021327617345377803), (37, 0.021559265442192554), (45, 0.021742521552369), (40, 0.021836146945133805), (51, 0.022593609523028135), (50, 0.023519962560385466), (46, 0.025376978795975447), (21, 0.025540468748658895), (48, 0.026064807549118996), (3, 0.026626083999872208), (20, 0.027130910893902183), (17, 0.03005285793915391), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.046184624545276165), (0, 0.04746154649183154), (4, 0.050933849066495895), (52, 0.05230193864554167), (7, 0.05248213419690728), (6, 0.053186831530183554), (10, 0.06307358760386705), (13, 0.06417542695999146), (8, 0.07143167778849602), (12, 0.0729450797662139), (11, 0.07423979043960571), (9, 0.08192321565002203), (36, 0.3307998813688755), (18, 0.48187142983078957), (53, 1.138483002781868)]
computing accuracy for after removing block 23 . block score: 0.016751633724197745
removed block 23 current accuracy 0.9584 loss from initial  0.04159999999999997
training start
training epoch 0 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 1 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 2 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 3 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 4 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 5 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 6 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 7 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.1]
training epoch 8 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 9 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 10 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.968 topk_dict {'top1': 0.968} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.968600)
finished training. finished 50 epochs. accuracy 0.9686 topk_dict {'top1': 0.9686}
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.037316. All blocks and scores: [(50, 0.03731577889993787), (39, 0.03795348247513175), (44, 0.03965462790802121), (47, 0.03991178562864661), (41, 0.03994897333905101), (51, 0.04032830707728863), (49, 0.040669048205018044), (5, 0.040722004137933254), (43, 0.04083235189318657), (40, 0.04207786498591304), (45, 0.04241856187582016), (14, 0.044241777155548334), (46, 0.04736969666555524), (3, 0.04966389015316963), (48, 0.0508522130548954), (37, 0.05718510691076517), (17, 0.06151048792526126), (20, 0.06368491053581238), (52, 0.06791266147047281), (19, 0.07286886218935251), (21, 0.0741168512031436), (0, 0.07762973289936781), (16, 0.08227046579122543), (15, 0.08474480174481869), (6, 0.10334023647010326), (7, 0.10833866149187088), (8, 0.11310490779578686), (4, 0.11374504305422306), (10, 0.12656250968575478), (12, 0.13085077702999115), (11, 0.13882902450859547), (13, 0.13994435034692287), (9, 0.15021407790482044), (18, 0.6265894323587418), (36, 0.6609728038311005), (53, 1.08949376642704)]
computing accuracy for after removing block 50 . block score: 0.03731577889993787
removed block 50 current accuracy 0.9608 loss from initial  0.03920000000000001
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.037953. All blocks and scores: [(39, 0.0379534843377769), (44, 0.039654630701988935), (47, 0.039911787025630474), (41, 0.039948972407728434), (49, 0.040669047739356756), (5, 0.04072200367227197), (43, 0.04083235189318657), (40, 0.04207786452025175), (45, 0.04241856234148145), (14, 0.04424177575856447), (46, 0.04736969666555524), (51, 0.04763591522350907), (3, 0.04966389201581478), (48, 0.050852212123572826), (37, 0.057185107842087746), (17, 0.061510486993938684), (20, 0.06368491239845753), (19, 0.07286885939538479), (52, 0.07369603589177132), (21, 0.0741168512031436), (0, 0.07762973569333553), (16, 0.08227046299725771), (15, 0.08474479895085096), (6, 0.10334023740142584), (7, 0.1083386605605483), (8, 0.11310490313917398), (4, 0.11374504119157791), (10, 0.12656250596046448), (12, 0.13085078075528145), (11, 0.13882902078330517), (13, 0.13994435034692287), (9, 0.1502140797674656), (18, 0.6265894249081612), (36, 0.6609728112816811), (53, 1.1945233047008514)]
computing accuracy for after removing block 39 . block score: 0.0379534843377769
removed block 39 current accuracy 0.9582 loss from initial  0.04179999999999995
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 47, with score 0.039822. All blocks and scores: [(47, 0.0398221667855978), (49, 0.040120367892086506), (44, 0.04048185469582677), (5, 0.04072200320661068), (43, 0.04207339370623231), (41, 0.04212241619825363), (45, 0.04345047799870372), (40, 0.044221535325050354), (14, 0.04424177622422576), (51, 0.04706961568444967), (46, 0.04789863666519523), (3, 0.04966389201581478), (48, 0.05045882146805525), (37, 0.05718510830774903), (17, 0.0615104865282774), (20, 0.06368491146713495), (52, 0.07253355719149113), (19, 0.07286886218935251), (21, 0.0741168512031436), (0, 0.07762973476201296), (16, 0.08227046485990286), (15, 0.08474479988217354), (6, 0.10334023740142584), (7, 0.10833865962922573), (8, 0.11310490500181913), (4, 0.11374504398554564), (10, 0.12656250596046448), (12, 0.1308507826179266), (11, 0.13882902264595032), (13, 0.13994435593485832), (9, 0.1502140797674656), (18, 0.6265894323587418), (36, 0.6609728038311005), (53, 1.216023176908493)]
computing accuracy for after removing block 47 . block score: 0.0398221667855978
removed block 47 current accuracy 0.9498 loss from initial  0.05020000000000002
since last training loss: 0.01880000000000004 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.040482. All blocks and scores: [(44, 0.040481855627149343), (5, 0.040722002275288105), (43, 0.04207339230924845), (41, 0.04212241666391492), (49, 0.04300155118107796), (45, 0.043450478464365005), (40, 0.04422153299674392), (14, 0.044241775292903185), (46, 0.04789863666519523), (51, 0.04914089571684599), (3, 0.049663889687508345), (48, 0.05491891084238887), (37, 0.05718510830774903), (17, 0.061510485131293535), (20, 0.06368491239845753), (19, 0.07286886125802994), (52, 0.07323334366083145), (21, 0.07411685027182102), (0, 0.07762973289936781), (16, 0.08227046579122543), (15, 0.08474479895085096), (6, 0.10334023833274841), (7, 0.10833865962922573), (8, 0.11310490779578686), (4, 0.11374504491686821), (10, 0.12656250782310963), (12, 0.13085078075528145), (11, 0.13882902450859547), (13, 0.13994435220956802), (9, 0.15021407790482044), (18, 0.6265894174575806), (36, 0.6609728112816811), (53, 1.266227275133133)]
computing accuracy for after removing block 44 . block score: 0.040481855627149343
removed block 44 current accuracy 0.9374 loss from initial  0.06259999999999999
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 5, with score 0.040722. All blocks and scores: [(5, 0.04072200320661068), (43, 0.04207339184358716), (41, 0.04212241666391492), (49, 0.04233501944690943), (40, 0.04422153299674392), (14, 0.04424177436158061), (45, 0.04542117239907384), (51, 0.048634057864546776), (46, 0.04920758306980133), (3, 0.049663891550153494), (48, 0.05470050359144807), (37, 0.05718510737642646), (17, 0.06151048606261611), (20, 0.06368491053581238), (52, 0.07283910643309355), (19, 0.07286886218935251), (21, 0.0741168512031436), (0, 0.07762973476201296), (16, 0.08227046765387058), (15, 0.08474480081349611), (6, 0.10334023647010326), (7, 0.10833865776658058), (8, 0.11310490313917398), (4, 0.11374504212290049), (10, 0.12656250409781933), (12, 0.13085077702999115), (11, 0.13882902450859547), (13, 0.13994435407221317), (9, 0.1502140797674656), (18, 0.6265894398093224), (36, 0.6609727963805199), (53, 1.3118401765823364)]
computing accuracy for after removing block 5 . block score: 0.04072200320661068
removed block 5 current accuracy 0.9308 loss from initial  0.06920000000000004
since last training loss: 0.037800000000000056 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 41, with score 0.041705. All blocks and scores: [(41, 0.04170525260269642), (43, 0.04183759540319443), (49, 0.04217493114992976), (14, 0.04245294677093625), (45, 0.04594968166202307), (40, 0.046018270775675774), (51, 0.04893758660182357), (46, 0.04964765952900052), (3, 0.04966389201581478), (48, 0.0547193200327456), (37, 0.05892256135120988), (17, 0.05949553661048412), (20, 0.062626869417727), (21, 0.07257985137403011), (19, 0.07285305205732584), (52, 0.07320153713226318), (0, 0.07762973196804523), (16, 0.07958167605102062), (15, 0.08411997184157372), (6, 0.10928008332848549), (7, 0.11240948177874088), (4, 0.11374503932893276), (8, 0.11594612337648869), (10, 0.1237402930855751), (12, 0.12772840075194836), (11, 0.12863802537322044), (13, 0.13960723765194416), (9, 0.1533209513872862), (18, 0.6291708573698997), (36, 0.6720293387770653), (53, 1.333913579583168)]
computing accuracy for after removing block 41 . block score: 0.04170525260269642
removed block 41 current accuracy 0.9128 loss from initial  0.08720000000000006
since last training loss: 0.05580000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 49, with score 0.041031. All blocks and scores: [(49, 0.04103147750720382), (14, 0.042452945839613676), (43, 0.044109840877354145), (40, 0.046018270775675774), (45, 0.046611497178673744), (51, 0.04762536846101284), (46, 0.0490311267785728), (3, 0.04966389108449221), (48, 0.05394044890999794), (37, 0.05892256135120988), (17, 0.05949553521350026), (20, 0.0626268689520657), (52, 0.072243208065629), (21, 0.07257985323667526), (19, 0.07285305112600327), (0, 0.07762973476201296), (16, 0.07958167884498835), (15, 0.08411996997892857), (6, 0.10928008239716291), (7, 0.1124094845727086), (4, 0.11374504677951336), (8, 0.11594612523913383), (10, 0.12374029215425253), (12, 0.12772840075194836), (11, 0.12863802537322044), (13, 0.139607235789299), (9, 0.1533209513872862), (18, 0.629170835018158), (36, 0.6720293387770653), (53, 1.396102175116539)]
computing accuracy for after removing block 49 . block score: 0.04103147750720382
removed block 49 current accuracy 0.883 loss from initial  0.11699999999999999
since last training loss: 0.08560000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 14, with score 0.042453. All blocks and scores: [(14, 0.04245294537395239), (43, 0.044109840877354145), (40, 0.046018270775675774), (45, 0.04661149764433503), (46, 0.04903112584725022), (3, 0.049663891550153494), (48, 0.0539404503069818), (51, 0.054774200078099966), (37, 0.058922560419887304), (17, 0.059495532885193825), (20, 0.062626869417727), (21, 0.07257985044270754), (19, 0.07285305205732584), (0, 0.07762973289936781), (52, 0.07910412736237049), (16, 0.0795816769823432), (15, 0.08411997184157372), (6, 0.10928008146584034), (7, 0.1124094845727086), (4, 0.11374504305422306), (8, 0.11594612617045641), (10, 0.12374029401689768), (12, 0.12772840075194836), (11, 0.1286380272358656), (13, 0.1396072320640087), (9, 0.1533209476619959), (18, 0.6291708275675774), (36, 0.6720293387770653), (53, 1.505214273929596)]
computing accuracy for after removing block 14 . block score: 0.04245294537395239
removed block 14 current accuracy 0.8842 loss from initial  0.11580000000000001
since last training loss: 0.08440000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 43, with score 0.046779. All blocks and scores: [(43, 0.046779240015894175), (40, 0.04679906973615289), (45, 0.048681114334613085), (46, 0.04919289657846093), (3, 0.04966389061883092), (51, 0.053532800637185574), (48, 0.05475494870916009), (37, 0.059733765199780464), (20, 0.060914451256394386), (17, 0.061064936220645905), (21, 0.06983088329434395), (19, 0.07710447069257498), (0, 0.07762973476201296), (16, 0.07943123951554298), (52, 0.07984349224716425), (15, 0.08674007933586836), (6, 0.10928007774055004), (7, 0.11240948084741831), (4, 0.11374504119157791), (8, 0.11594611965119839), (10, 0.12374029587954283), (12, 0.12772839702665806), (11, 0.12863802537322044), (13, 0.13960723765194416), (9, 0.15332095511257648), (18, 0.6100160554051399), (36, 0.667050190269947), (53, 1.478804588317871)]
computing accuracy for after removing block 43 . block score: 0.046779240015894175
removed block 43 current accuracy 0.8562 loss from initial  0.14380000000000004
training start
training epoch 0 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best True lr [0.1]
training epoch 1 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best True lr [0.1]
training epoch 2 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 3 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.1]
training epoch 4 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 6 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 7 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 9 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.0010000000000000002]
loading model_best from epoch 19 (acc 0.953200)
finished training. finished 50 epochs. accuracy 0.9532 topk_dict {'top1': 0.9532}
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.061782. All blocks and scores: [(51, 0.06178180733695626), (3, 0.06391114555299282), (45, 0.06651586946099997), (46, 0.0689085004851222), (40, 0.07067635003477335), (48, 0.07223221566528082), (17, 0.07259067054837942), (20, 0.07403579354286194), (52, 0.07551854755729437), (37, 0.0762899024412036), (0, 0.08899008389562368), (21, 0.09195499401539564), (19, 0.09308107197284698), (16, 0.09877804107964039), (15, 0.10549956280738115), (6, 0.11238786857575178), (4, 0.12579959630966187), (7, 0.1271974677219987), (8, 0.1324002556502819), (10, 0.14710126258432865), (13, 0.15099880285561085), (9, 0.16229498200118542), (11, 0.16406678967177868), (12, 0.1666099615395069), (36, 0.5797573104500771), (18, 0.6568038165569305), (53, 1.1396266669034958)]
computing accuracy for after removing block 51 . block score: 0.06178180733695626
removed block 51 current accuracy 0.9348 loss from initial  0.06520000000000004
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 3, with score 0.063911. All blocks and scores: [(3, 0.06391114834696054), (45, 0.06651586852967739), (46, 0.06890849862247705), (40, 0.07067634724080563), (48, 0.07223221473395824), (17, 0.0725906677544117), (20, 0.07403579354286194), (37, 0.07628989964723587), (0, 0.08899008296430111), (21, 0.09195499680936337), (19, 0.09308107104152441), (52, 0.0946875074878335), (16, 0.09877804014831781), (15, 0.1054995683953166), (6, 0.1123878676444292), (4, 0.12579959444701672), (7, 0.12719747051596642), (8, 0.13240025751292706), (10, 0.1471012644469738), (13, 0.15099881030619144), (9, 0.16229498013854027), (11, 0.16406679153442383), (12, 0.16660996340215206), (36, 0.5797572880983353), (18, 0.6568038165569305), (53, 1.4078402817249298)]
computing accuracy for after removing block 3 . block score: 0.06391114834696054
removed block 3 current accuracy 0.9312 loss from initial  0.06879999999999997
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 45, with score 0.066139. All blocks and scores: [(45, 0.06613936368376017), (46, 0.06844481453299522), (17, 0.06911820452660322), (40, 0.07079475373029709), (48, 0.07233082503080368), (20, 0.0731711108237505), (37, 0.07665717601776123), (0, 0.08899008296430111), (21, 0.09058383759111166), (19, 0.09139271173626184), (16, 0.09357440657913685), (52, 0.09454598650336266), (15, 0.10256356000900269), (6, 0.11172480322420597), (7, 0.12772571668028831), (4, 0.13224736787378788), (8, 0.13238343596458435), (13, 0.14667744003236294), (10, 0.1533393394201994), (11, 0.15556877478957176), (12, 0.1592273712158203), (9, 0.16619529947638512), (36, 0.5767667219042778), (18, 0.6561117991805077), (53, 1.4181441962718964)]
computing accuracy for after removing block 45 . block score: 0.06613936368376017
removed block 45 current accuracy 0.8982 loss from initial  0.1018
since last training loss: 0.05500000000000005 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 17, with score 0.069118. All blocks and scores: [(17, 0.06911820638924837), (40, 0.07079475279897451), (20, 0.0731711108237505), (48, 0.0750283282250166), (37, 0.07665717788040638), (46, 0.07698499131947756), (0, 0.08899008389562368), (21, 0.09058383572846651), (19, 0.09139271266758442), (16, 0.0935744047164917), (52, 0.09432206768542528), (15, 0.10256355814635754), (6, 0.11172480322420597), (7, 0.1277257204055786), (4, 0.13224737159907818), (8, 0.13238343968987465), (13, 0.1466774344444275), (10, 0.1533393319696188), (11, 0.15556877851486206), (12, 0.15922737307846546), (9, 0.16619529761373997), (36, 0.5767667144536972), (18, 0.6561117917299271), (53, 1.4336329698562622)]
computing accuracy for after removing block 17 . block score: 0.06911820638924837
removed block 17 current accuracy 0.8992 loss from initial  0.1008
since last training loss: 0.05400000000000005 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.068043. All blocks and scores: [(40, 0.06804344151169062), (20, 0.06859482917934656), (37, 0.0721889054402709), (48, 0.07435090001672506), (46, 0.07643087301403284), (21, 0.08338420558720827), (0, 0.08899008110165596), (52, 0.09199099149554968), (19, 0.09246156737208366), (16, 0.09357440657913685), (15, 0.10256355721503496), (6, 0.11172480322420597), (7, 0.12772571947425604), (4, 0.13224737159907818), (8, 0.13238343596458435), (13, 0.1466774344444275), (10, 0.1533393394201994), (11, 0.15556877478957176), (12, 0.1592273712158203), (9, 0.16619530133903027), (36, 0.5518181622028351), (18, 0.6289990916848183), (53, 1.4243429154157639)]
computing accuracy for after removing block 40 . block score: 0.06804344151169062
removed block 40 current accuracy 0.8702 loss from initial  0.12980000000000003
since last training loss: 0.08300000000000007 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 20, with score 0.068595. All blocks and scores: [(20, 0.06859482917934656), (37, 0.07218890450894833), (48, 0.07626629155129194), (46, 0.08309359662234783), (21, 0.08338420651853085), (0, 0.08899008203297853), (19, 0.09246156737208366), (52, 0.09319369681179523), (16, 0.09357440378516912), (15, 0.10256355907768011), (6, 0.1117248022928834), (7, 0.1277257176116109), (4, 0.13224736973643303), (8, 0.1323834378272295), (13, 0.1466774344444275), (10, 0.15333933755755424), (11, 0.1555687803775072), (12, 0.1592273712158203), (9, 0.16619529761373997), (36, 0.5518181696534157), (18, 0.6289990693330765), (53, 1.5314204841852188)]
computing accuracy for after removing block 20 . block score: 0.06859482917934656
removed block 20 current accuracy 0.8538 loss from initial  0.1462
since last training loss: 0.09940000000000004 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.071689. All blocks and scores: [(37, 0.0716887442395091), (48, 0.0736154792830348), (21, 0.07787527982145548), (46, 0.08523690514266491), (0, 0.08899008110165596), (52, 0.08919648360460997), (19, 0.09246156271547079), (16, 0.09357440657913685), (15, 0.10256355907768011), (6, 0.11172480322420597), (7, 0.12772572319954634), (4, 0.13224736787378788), (8, 0.13238343968987465), (13, 0.1466774381697178), (10, 0.1533393356949091), (11, 0.1555687803775072), (12, 0.1592273712158203), (9, 0.16619529575109482), (36, 0.5575919300317764), (18, 0.6289990767836571), (53, 1.478624165058136)]
computing accuracy for after removing block 37 . block score: 0.0716887442395091
removed block 37 current accuracy 0.8242 loss from initial  0.17579999999999996
since last training loss: 0.129 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 48, with score 0.077231. All blocks and scores: [(48, 0.07723098620772362), (21, 0.07787527702748775), (0, 0.08899008296430111), (52, 0.09016168303787708), (19, 0.09246156644076109), (16, 0.09357440564781427), (46, 0.09615807700902224), (15, 0.10256356000900269), (6, 0.11172480322420597), (7, 0.12772571481764317), (4, 0.13224736787378788), (8, 0.13238343596458435), (13, 0.1466774344444275), (10, 0.15333933755755424), (11, 0.15556877851486206), (12, 0.15922737307846546), (9, 0.16619530320167542), (36, 0.557591937482357), (18, 0.6289990767836571), (53, 1.45804463326931)]
computing accuracy for after removing block 48 . block score: 0.07723098620772362
removed block 48 current accuracy 0.7536 loss from initial  0.24639999999999995
since last training loss: 0.1996 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 21, with score 0.077875. All blocks and scores: [(21, 0.0778752788901329), (0, 0.08899008296430111), (19, 0.09246156644076109), (16, 0.09357440285384655), (46, 0.09615807142108679), (15, 0.10256356187164783), (52, 0.10385504644364119), (6, 0.11172480415552855), (7, 0.12772571481764317), (4, 0.13224737159907818), (8, 0.1323834415525198), (13, 0.1466774381697178), (10, 0.1533393356949091), (11, 0.1555687841027975), (12, 0.1592273712158203), (9, 0.16619529947638512), (36, 0.5575919300317764), (18, 0.6289990693330765), (53, 1.6660086512565613)]
computing accuracy for after removing block 21 . block score: 0.0778752788901329
removed block 21 current accuracy 0.6952 loss from initial  0.30479999999999996
since last training loss: 0.258 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.088990. All blocks and scores: [(0, 0.08899008203297853), (19, 0.09246156830340624), (16, 0.09357440285384655), (46, 0.09672535955905914), (15, 0.10256356000900269), (52, 0.10320079512894154), (6, 0.11172480415552855), (7, 0.12772571574896574), (4, 0.13224736787378788), (8, 0.1323834378272295), (13, 0.1466774344444275), (10, 0.1533393356949091), (11, 0.1555687766522169), (12, 0.15922737680375576), (9, 0.16619529947638512), (36, 0.5692242383956909), (18, 0.6289990618824959), (53, 1.6312447786331177)]
computing accuracy for after removing block 0 . block score: 0.08899008203297853
removed block 0 current accuracy 0.6542 loss from initial  0.3458
since last training loss: 0.29900000000000004 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 16, with score 0.087181. All blocks and scores: [(16, 0.08718100562691689), (46, 0.09320133738219738), (19, 0.09545604977756739), (15, 0.09810739289969206), (52, 0.10723547171801329), (6, 0.11490833107382059), (7, 0.1292597223073244), (8, 0.13244879432022572), (13, 0.14313990622758865), (11, 0.14323499239981174), (4, 0.14359508641064167), (10, 0.14421114698052406), (12, 0.15056722611188889), (9, 0.15589516051113605), (36, 0.5468920543789864), (18, 0.6047689691185951), (53, 1.7118554413318634)]
computing accuracy for after removing block 16 . block score: 0.08718100562691689
removed block 16 current accuracy 0.644 loss from initial  0.356
since last training loss: 0.30920000000000003 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 46, with score 0.091792. All blocks and scores: [(46, 0.09179206285625696), (15, 0.09810738451778889), (19, 0.09886673465371132), (52, 0.10305899288505316), (6, 0.11490832921117544), (7, 0.1292597223073244), (8, 0.13244879432022572), (13, 0.14313990622758865), (11, 0.14323499612510204), (4, 0.14359508268535137), (10, 0.14421114698052406), (12, 0.15056722797453403), (9, 0.1558951549232006), (36, 0.529856488108635), (18, 0.5705724507570267), (53, 1.6201934814453125)]
computing accuracy for after removing block 46 . block score: 0.09179206285625696
removed block 46 current accuracy 0.5312 loss from initial  0.4688
training start
training epoch 0 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best True lr [0.1]
training epoch 1 val accuracy 0.862 topk_dict {'top1': 0.862} is_best True lr [0.1]
training epoch 2 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 3 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 4 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 6 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 7 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.1]
training epoch 8 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 9 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.923400)
finished training. finished 50 epochs. accuracy 0.9234 topk_dict {'top1': 0.9234}
