start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101574242115), (24, 0.006592476682271808), (25, 0.007601776218507439), (21, 0.008612961391918361), (27, 0.008965069544501603), (5, 0.009674609289504588), (23, 0.011229233001358807), (19, 0.011454988038167357), (35, 0.011519728461280465), (32, 0.013281174935400486), (29, 0.0141788151813671), (20, 0.01450843911152333), (31, 0.014615894062444568), (3, 0.014681300264783204), (26, 0.014724894892424345), (30, 0.014915360254235566), (7, 0.01509747770614922), (28, 0.01623483165167272), (37, 0.018546362640336156), (33, 0.02161785284988582), (39, 0.02187628741376102), (6, 0.022251417860388756), (50, 0.022445981157943606), (34, 0.022565887309610844), (49, 0.022602886660024524), (8, 0.023474456276744604), (38, 0.02385126263834536), (41, 0.024523034691810608), (40, 0.024661971488967538), (1, 0.02538809599354863), (46, 0.026244731387123466), (45, 0.026683186646550894), (48, 0.02697099861688912), (44, 0.028061730787158012), (51, 0.028739837929606438), (42, 0.028769565979018807), (43, 0.030795484082773328), (47, 0.03119555884040892), (0, 0.03271650895476341), (13, 0.03601941978558898), (15, 0.04315127804875374), (14, 0.04341263649985194), (16, 0.04433066165074706), (12, 0.04965688521042466), (4, 0.051154307555407286), (11, 0.05217862408608198), (52, 0.05327533045783639), (2, 0.05518383486196399), (10, 0.060167096555233), (9, 0.08553026616573334), (17, 0.18986638821661472), (18, 0.2766866199672222), (36, 0.289817214012146), (53, 0.8816948235034943)]
computing accuracy for after removing block 22 . block score: 0.005787101574242115
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.006946946668904275), (25, 0.007925601676106453), (21, 0.008612961508333683), (27, 0.008884541923180223), (5, 0.009674609638750553), (19, 0.011454988038167357), (23, 0.011499473941512406), (35, 0.011587338289245963), (32, 0.013315336313098669), (29, 0.014122492633759975), (20, 0.014508438878692687), (31, 0.014535366673953831), (3, 0.014681300148367882), (30, 0.014953502104617655), (7, 0.01509747828822583), (26, 0.015386729850433767), (28, 0.016657372238114476), (37, 0.018698561703786254), (33, 0.021836149506270885), (6, 0.02225141692906618), (39, 0.02227854309603572), (50, 0.022396721877157688), (34, 0.022579424316063523), (49, 0.02258834894746542), (8, 0.02347445674240589), (38, 0.02401084848679602), (41, 0.024710634956136346), (40, 0.02483244682662189), (1, 0.025388095062226057), (46, 0.026328841922804713), (45, 0.026519648963585496), (48, 0.026865347754210234), (51, 0.028594731353223324), (44, 0.02869078330695629), (42, 0.028934542322531343), (47, 0.030598991317674518), (43, 0.030889176530763507), (0, 0.03271650895476341), (13, 0.03601941931992769), (15, 0.043151278514415026), (14, 0.04341263370588422), (16, 0.04433065978810191), (12, 0.049656886607408524), (4, 0.05115430895239115), (11, 0.05217862315475941), (52, 0.05274482164531946), (2, 0.055183835327625275), (10, 0.06016709841787815), (9, 0.08553026616573334), (17, 0.18986638449132442), (18, 0.2766866199672222), (36, 0.29418330267071724), (53, 0.8765672817826271)]
computing accuracy for after removing block 24 . block score: 0.006946946668904275
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.007964791497215629), (27, 0.008502037031576037), (21, 0.008612961391918361), (5, 0.009674609638750553), (35, 0.011124447803013027), (19, 0.01145498815458268), (23, 0.01149947417434305), (32, 0.012667875154875219), (29, 0.013618955155834556), (31, 0.014255343587137759), (30, 0.01444040925707668), (20, 0.014508438180200756), (3, 0.014681299682706594), (7, 0.015097478171810508), (26, 0.015341691207140684), (28, 0.016541525023058057), (37, 0.018848977982997894), (34, 0.02149180183187127), (33, 0.02174661075696349), (50, 0.02214478445239365), (6, 0.022251417161896825), (49, 0.02257367572747171), (39, 0.02259462559595704), (8, 0.023474456975236535), (38, 0.023919350234791636), (41, 0.024731410900130868), (40, 0.025212144013494253), (1, 0.025388095760717988), (45, 0.026285272790119052), (46, 0.026299893856048584), (48, 0.02681394899263978), (51, 0.028448979370296), (44, 0.028867241460829973), (42, 0.028876987285912037), (47, 0.030472575221210718), (43, 0.03083793236874044), (0, 0.03271650895476341), (13, 0.03601942025125027), (15, 0.04315127898007631), (14, 0.04341263556852937), (16, 0.0443306602537632), (12, 0.049656884744763374), (4, 0.05115430802106857), (11, 0.05217862315475941), (52, 0.052212193608284), (2, 0.05518383393064141), (10, 0.0601671002805233), (9, 0.08553026337176561), (17, 0.18986638821661472), (18, 0.2766866199672222), (36, 0.2956240624189377), (53, 0.8761104717850685)]
computing accuracy for after removing block 25 . block score: 0.007964791497215629
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.008207483915612102), (21, 0.00861296127550304), (5, 0.009674609638750553), (35, 0.010663896333426237), (19, 0.011454987688921392), (23, 0.011499474290758371), (32, 0.012014233390800655), (29, 0.012787629151716828), (31, 0.013865677174180746), (30, 0.013961305958218873), (20, 0.0145084384130314), (3, 0.014681300264783204), (26, 0.014919801382347941), (7, 0.015097478055395186), (28, 0.01572392089292407), (37, 0.018793188268318772), (34, 0.020361811155453324), (33, 0.02132861432619393), (50, 0.021633303025737405), (49, 0.022232345072552562), (6, 0.02225141692906618), (39, 0.022528418572619557), (8, 0.023474456276744604), (38, 0.023843125673010945), (41, 0.02440304053016007), (40, 0.02525408356450498), (1, 0.025388095527887344), (45, 0.02569323405623436), (46, 0.025908003794029355), (48, 0.026390638668090105), (51, 0.027748762629926205), (42, 0.02847559144720435), (44, 0.028856614604592323), (47, 0.029799402225762606), (43, 0.030201828805729747), (0, 0.032716508489102125), (13, 0.03601941978558898), (15, 0.043151278514415026), (14, 0.04341263743117452), (16, 0.04433065885677934), (12, 0.04965688567608595), (52, 0.05079668154940009), (4, 0.05115430895239115), (11, 0.05217862222343683), (2, 0.05518383393064141), (10, 0.060167097486555576), (9, 0.08553026709705591), (17, 0.18986638635396957), (18, 0.2766866199672222), (36, 0.29478897526860237), (53, 0.8695808798074722)]
computing accuracy for after removing block 27 . block score: 0.008207483915612102
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.00861296127550304), (5, 0.009674609522335231), (35, 0.010487184626981616), (19, 0.011454987805336714), (23, 0.01149947417434305), (32, 0.011747056967578828), (29, 0.012900045025162399), (31, 0.013738625915721059), (30, 0.0138319858815521), (20, 0.014508438762277365), (3, 0.014681300381198525), (26, 0.014919801033101976), (7, 0.015097477938979864), (28, 0.016265674028545618), (37, 0.018666349118575454), (34, 0.020145454676821828), (50, 0.021326792193576694), (33, 0.021582857938483357), (49, 0.022118564462289214), (6, 0.022251416463404894), (39, 0.0222895669285208), (8, 0.023474456276744604), (38, 0.023616681108251214), (41, 0.024516039295122027), (40, 0.025366823887452483), (45, 0.025367740308865905), (1, 0.02538809599354863), (46, 0.02560482919216156), (48, 0.026125094387680292), (51, 0.027203567093238235), (42, 0.028293345822021365), (44, 0.02932620607316494), (47, 0.02935170568525791), (43, 0.03003040445037186), (0, 0.032716508489102125), (13, 0.03601941931992769), (15, 0.0431512794457376), (14, 0.04341263743117452), (16, 0.044330659322440624), (12, 0.04965688567608595), (52, 0.050038253888487816), (4, 0.05115430895239115), (11, 0.05217862268909812), (2, 0.05518383393064141), (10, 0.06016709888353944), (9, 0.08553026709705591), (17, 0.18986638262867928), (18, 0.2766866274178028), (36, 0.29525746777653694), (53, 0.8683891147375107)]
computing accuracy for after removing block 21 . block score: 0.00861296127550304
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.009674609755165875), (35, 0.010542471893131733), (19, 0.011454987921752036), (23, 0.011545549263246357), (32, 0.011696714092977345), (29, 0.013034458388574421), (30, 0.01354199240449816), (31, 0.013661347213201225), (20, 0.014508438645862043), (26, 0.014561281772330403), (3, 0.014681300381198525), (7, 0.015097478171810508), (28, 0.01627222285605967), (37, 0.018855378730222583), (34, 0.020170693518593907), (50, 0.02119536232203245), (33, 0.021736358292400837), (49, 0.022025791695341468), (6, 0.022251416463404894), (39, 0.022593394853174686), (8, 0.023474456975236535), (38, 0.023794722044840455), (41, 0.02448631334118545), (45, 0.02517408598214388), (1, 0.025388095062226057), (46, 0.025596367428079247), (40, 0.025702924700453877), (48, 0.025935829151421785), (51, 0.026903111254796386), (42, 0.02837103931233287), (47, 0.029131257440894842), (44, 0.02926316298544407), (43, 0.030276520177721977), (0, 0.0327165094204247), (13, 0.036019420716911554), (15, 0.04315127618610859), (14, 0.04341263556852937), (16, 0.04433065885677934), (52, 0.04949297895655036), (12, 0.0496568838134408), (4, 0.05115430802106857), (11, 0.05217862455174327), (2, 0.05518383253365755), (10, 0.060167097952216864), (9, 0.08553026802837849), (17, 0.18986638449132442), (18, 0.2766866125166416), (36, 0.2977275922894478), (53, 0.8672097623348236)]
computing accuracy for after removing block 5 . block score: 0.009674609755165875
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010497. All blocks and scores: [(35, 0.010497342445887625), (19, 0.011364334030076861), (23, 0.011454000836238265), (32, 0.01173175044823438), (29, 0.012978376005776227), (30, 0.013561801402829587), (31, 0.013812811113893986), (20, 0.014028266887180507), (26, 0.014234644710086286), (3, 0.014681300264783204), (28, 0.016409628791734576), (37, 0.019115549745038152), (7, 0.01932149287313223), (34, 0.020494531374424696), (50, 0.021026555448770523), (33, 0.021409297361969948), (49, 0.022096335655078292), (39, 0.022289574379101396), (38, 0.023183459881693125), (41, 0.02425868296995759), (6, 0.02500285836867988), (8, 0.025038711493834853), (45, 0.025084450375288725), (46, 0.025368365226313472), (1, 0.025388095527887344), (48, 0.02579234493896365), (40, 0.026035186601802707), (51, 0.02685543615370989), (42, 0.028462824411690235), (44, 0.02884995099157095), (47, 0.029113001888617873), (43, 0.030238439328968525), (0, 0.0327165094204247), (13, 0.03606124920770526), (15, 0.04305668082088232), (16, 0.043651987332850695), (14, 0.04365939786657691), (52, 0.0493767405860126), (4, 0.05115430895239115), (12, 0.05150972120463848), (11, 0.054063091054558754), (2, 0.055183835327625275), (10, 0.06240202812477946), (9, 0.0897172437980771), (17, 0.18636955693364143), (18, 0.27677175775170326), (36, 0.2957078889012337), (53, 0.8705098405480385)]
computing accuracy for after removing block 35 . block score: 0.010497342445887625
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011364. All blocks and scores: [(19, 0.01136433391366154), (23, 0.011454000603407621), (32, 0.011731749982573092), (29, 0.012978376122191548), (30, 0.013561801752075553), (31, 0.013812811113893986), (20, 0.01402826712001115), (26, 0.01423464494291693), (3, 0.014681299799121916), (28, 0.01640962902456522), (37, 0.018872639629989862), (7, 0.01932149240747094), (34, 0.020494531840085983), (50, 0.02102121920324862), (33, 0.02140929806046188), (49, 0.02197030163370073), (39, 0.02224103594198823), (38, 0.022285724757239223), (41, 0.024062653072178364), (45, 0.024892093148082495), (46, 0.024894545320421457), (6, 0.025002859067171812), (8, 0.025038711726665497), (1, 0.025388095527887344), (48, 0.02549554198049009), (40, 0.025603901594877243), (51, 0.02683849656023085), (42, 0.028305645566433668), (44, 0.02850431390106678), (47, 0.02852879394777119), (43, 0.029594503110274673), (0, 0.03271650895476341), (13, 0.0360612478107214), (15, 0.04305667942389846), (16, 0.04365198826417327), (14, 0.043659398797899485), (52, 0.04860273469239473), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.05406309058889747), (2, 0.05518383579328656), (10, 0.06240202812477946), (9, 0.08971724286675453), (17, 0.18636954575777054), (18, 0.27677176892757416), (36, 0.29528704285621643), (53, 0.874636285007)]
computing accuracy for after removing block 19 . block score: 0.01136433391366154
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.011435. All blocks and scores: [(32, 0.011435218388214707), (23, 0.01162551180459559), (29, 0.013017931370995939), (31, 0.013358428725041449), (30, 0.013481264817528427), (26, 0.01355171692557633), (20, 0.01447505911346525), (3, 0.014681299799121916), (28, 0.016491985181346536), (37, 0.018982867943122983), (7, 0.01932149240747094), (34, 0.02042598440311849), (50, 0.020725762704387307), (33, 0.021510421065613627), (49, 0.021559856366366148), (39, 0.021842949790880084), (38, 0.021860384149476886), (41, 0.023579307598993182), (46, 0.024237519595772028), (45, 0.024405382573604584), (48, 0.024966377997770905), (6, 0.025002858601510525), (8, 0.02503871195949614), (1, 0.02538809459656477), (40, 0.025583632988855243), (51, 0.02626500162295997), (44, 0.027775867376476526), (42, 0.027991156093776226), (47, 0.028424981981515884), (43, 0.02918767905794084), (0, 0.03271650755777955), (13, 0.0360612478107214), (15, 0.043056679889559746), (16, 0.04365198826417327), (14, 0.043659396935254335), (52, 0.04771037446334958), (4, 0.05115430848672986), (12, 0.05150972353294492), (11, 0.05406309012323618), (2, 0.055183833464980125), (10, 0.062402029521763325), (9, 0.08971724472939968), (17, 0.18636955320835114), (18, 0.27677176520228386), (36, 0.28799719363451004), (53, 0.8807788416743279)]
computing accuracy for after removing block 32 . block score: 0.011435218388214707
removed block 32 current accuracy 0.9952 loss from initial  0.0048000000000000265
training start
training epoch 0 val accuracy 0.7766 topk_dict {'top1': 0.7766} is_best False lr [0.1]
training epoch 1 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 3 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 4 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 5 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 6 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 7 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 8 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 9 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 10 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.995200)
finished training. finished 50 epochs. accuracy 0.9952 topk_dict {'top1': 0.9952}
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.011626. All blocks and scores: [(23, 0.011625511688180268), (29, 0.013017931370995939), (31, 0.013358428375795484), (30, 0.013481264584697783), (26, 0.013551717391237617), (20, 0.01447505911346525), (3, 0.014681300148367882), (28, 0.016491985181346536), (37, 0.018812528578564525), (7, 0.019321492174640298), (34, 0.020461332285776734), (50, 0.020823082653805614), (49, 0.02181476540863514), (38, 0.022025865502655506), (39, 0.022391145350411534), (33, 0.022413173923268914), (41, 0.02400040184147656), (46, 0.02434976096265018), (45, 0.024428083328530192), (6, 0.02500285836867988), (8, 0.02503871126100421), (1, 0.025388095760717988), (48, 0.025586011121049523), (51, 0.02623430546373129), (40, 0.02659459924325347), (42, 0.028401524992659688), (47, 0.02876698481850326), (44, 0.0288279817905277), (43, 0.029493928654119372), (0, 0.03271650895476341), (13, 0.03606124874204397), (15, 0.043056679889559746), (16, 0.04365198966115713), (14, 0.0436593983322382), (52, 0.04727818816900253), (4, 0.05115430895239115), (12, 0.051509722135961056), (11, 0.05406309152022004), (2, 0.05518383486196399), (10, 0.06240202905610204), (9, 0.08971724193543196), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.30095570534467697), (53, 0.8827565684914589)]
computing accuracy for after removing block 23 . block score: 0.011625511688180268
removed block 23 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.012718. All blocks and scores: [(26, 0.012718256446532905), (31, 0.013059877790510654), (30, 0.013245980022475123), (29, 0.013515455764718354), (20, 0.014475058764219284), (3, 0.014681299566291273), (28, 0.016541111981496215), (37, 0.0189684743527323), (7, 0.01932149240747094), (50, 0.020513230236247182), (34, 0.020617330679669976), (49, 0.021386134903877974), (38, 0.02212540851905942), (39, 0.022963948315009475), (33, 0.023589920718222857), (41, 0.023973098024725914), (46, 0.024251093389466405), (45, 0.02427463559433818), (6, 0.025002858601510525), (8, 0.025038711726665497), (48, 0.02516700397245586), (1, 0.025388095527887344), (51, 0.025717934127897024), (40, 0.026828007074072957), (47, 0.028098624665290117), (44, 0.0281608528457582), (42, 0.028478232445195317), (43, 0.029657084494829178), (0, 0.03271650802344084), (13, 0.03606124874204397), (15, 0.04305667942389846), (16, 0.043651989195495844), (14, 0.04365939926356077), (52, 0.04578007198870182), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.054063091054558754), (2, 0.05518383299931884), (10, 0.06240202859044075), (9, 0.08971724286675453), (17, 0.18636955134570599), (18, 0.27677176147699356), (36, 0.3048461154103279), (53, 0.8830678537487984)]
computing accuracy for after removing block 26 . block score: 0.012718256446532905
removed block 26 current accuracy 0.9864 loss from initial  0.013599999999999945
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.012818. All blocks and scores: [(31, 0.01281756954267621), (30, 0.01301584206521511), (29, 0.013636851799674332), (20, 0.014475058764219284), (3, 0.014681300381198525), (37, 0.0183512675575912), (28, 0.018360019428655505), (34, 0.019276466220617294), (7, 0.019321492174640298), (50, 0.02007306437008083), (49, 0.02093875897116959), (38, 0.021544619696214795), (39, 0.022596267517656088), (46, 0.02321926597505808), (45, 0.023255801992490888), (41, 0.023414232302457094), (33, 0.023838804103434086), (48, 0.024398322915658355), (51, 0.024742738576605916), (6, 0.025002859067171812), (8, 0.02503871195949614), (1, 0.025388095527887344), (40, 0.02665983489714563), (47, 0.02733475947752595), (42, 0.02795390016399324), (44, 0.0280504513066262), (43, 0.028797091217711568), (0, 0.032716508489102125), (13, 0.0360612478107214), (15, 0.04305668221786618), (52, 0.043582526966929436), (16, 0.04365198826417327), (14, 0.0436593983322382), (4, 0.05115430848672986), (12, 0.05150972306728363), (11, 0.054063091054558754), (2, 0.0551838343963027), (10, 0.062402027659118176), (9, 0.08971724472939968), (17, 0.18636955134570599), (18, 0.27677176520228386), (36, 0.299288522452116), (53, 0.8849738016724586)]
computing accuracy for after removing block 31 . block score: 0.01281756954267621
removed block 31 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 30, with score 0.013016. All blocks and scores: [(30, 0.013015841948799789), (29, 0.013636851566843688), (20, 0.014475058997049928), (3, 0.014681300497613847), (37, 0.01821277802810073), (28, 0.018360019428655505), (7, 0.01932149287313223), (34, 0.01966984965838492), (50, 0.020156640093773603), (49, 0.021141209173947573), (38, 0.021776929264888167), (39, 0.0230242139659822), (45, 0.02332213381305337), (46, 0.02372095757164061), (41, 0.023724549217149615), (51, 0.024649521335959435), (48, 0.024757301434874535), (6, 0.02500285836867988), (8, 0.025038712192326784), (1, 0.025388095062226057), (33, 0.02650434384122491), (47, 0.02736758766695857), (40, 0.02746549085713923), (42, 0.028049134416505694), (44, 0.02878746041096747), (43, 0.028967605205252767), (0, 0.03271650802344084), (13, 0.036061248276382685), (15, 0.04305667895823717), (52, 0.043247838504612446), (16, 0.043651989195495844), (14, 0.04365939740091562), (4, 0.05115430895239115), (12, 0.05150972260162234), (11, 0.05406309012323618), (2, 0.055183833464980125), (10, 0.06240202859044075), (9, 0.08971724193543196), (17, 0.1863695476204157), (18, 0.27677177265286446), (36, 0.31426598876714706), (53, 0.8895440250635147)]
computing accuracy for after removing block 30 . block score: 0.013015841948799789
removed block 30 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.013637. All blocks and scores: [(29, 0.01363685168325901), (20, 0.014475058647803962), (3, 0.01468130003195256), (37, 0.017944879131391644), (28, 0.01836001919582486), (7, 0.01932149240747094), (34, 0.019725410966202617), (50, 0.019991705426946282), (49, 0.021314991638064384), (38, 0.022087190067395568), (45, 0.023139021592214704), (39, 0.023474511923268437), (41, 0.023871453711763024), (46, 0.024038308998569846), (51, 0.024538288358598948), (6, 0.025002858601510525), (8, 0.025038712192326784), (48, 0.025119444588199258), (1, 0.0253880952950567), (47, 0.027327915420755744), (42, 0.02818235964514315), (33, 0.028287380700930953), (40, 0.02836772450245917), (43, 0.02904468378983438), (44, 0.029352555982768536), (0, 0.03271650802344084), (13, 0.036061248276382685), (52, 0.04239492677152157), (15, 0.043056679889559746), (16, 0.043651989195495844), (14, 0.043659396935254335), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.05406309058889747), (2, 0.05518383253365755), (10, 0.062402027659118176), (9, 0.08971724472939968), (17, 0.18636955320835114), (18, 0.27677175775170326), (36, 0.3271830342710018), (53, 0.8959614112973213)]
computing accuracy for after removing block 29 . block score: 0.01363685168325901
removed block 29 current accuracy 0.958 loss from initial  0.04200000000000004
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.014475. All blocks and scores: [(20, 0.014475058997049928), (3, 0.01468130003195256), (37, 0.017688013380393386), (28, 0.01836001966148615), (7, 0.019321492174640298), (50, 0.019902902655303478), (34, 0.02044607256539166), (49, 0.021449923748150468), (38, 0.022830398520454764), (45, 0.023148912470787764), (41, 0.023782097967341542), (51, 0.02396689192391932), (46, 0.024161773035302758), (39, 0.024319971213117242), (6, 0.025002859067171812), (8, 0.025038712192326784), (48, 0.02513158624060452), (1, 0.025388095760717988), (47, 0.02690045372582972), (42, 0.028658577241003513), (40, 0.028860507532954216), (43, 0.02912311488762498), (44, 0.030179517809301615), (33, 0.030993567081168294), (0, 0.03271650895476341), (13, 0.03606124874204397), (52, 0.0416575763374567), (15, 0.043056679889559746), (16, 0.043651989195495844), (14, 0.04365940019488335), (4, 0.05115430802106857), (12, 0.05150972167029977), (11, 0.05406309012323618), (2, 0.0551838343963027), (10, 0.062402027659118176), (9, 0.08971724566072226), (17, 0.18636954575777054), (18, 0.27677176147699356), (36, 0.3362649753689766), (53, 0.8946184366941452)]
computing accuracy for after removing block 20 . block score: 0.014475058997049928
removed block 20 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.054400000000000004 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 3, with score 0.014681. All blocks and scores: [(3, 0.014681300381198525), (37, 0.017535289516672492), (28, 0.018479035003110766), (7, 0.019321492640301585), (50, 0.019452705280855298), (49, 0.020851465640589595), (34, 0.02089377213269472), (38, 0.021935276221483946), (45, 0.02225391915999353), (46, 0.022808663547039032), (51, 0.023012835765257478), (41, 0.02361025335267186), (39, 0.024020644137635827), (48, 0.02489454229362309), (6, 0.02500285883434117), (8, 0.025038711726665497), (1, 0.025388095527887344), (47, 0.026204761117696762), (42, 0.028308543609455228), (43, 0.028871111571788788), (40, 0.02930531115271151), (44, 0.02972460724413395), (0, 0.032716508489102125), (33, 0.032957608345896006), (13, 0.03606124874204397), (52, 0.03952924348413944), (15, 0.04305667942389846), (16, 0.04365198779851198), (14, 0.04365939740091562), (4, 0.051154309418052435), (12, 0.05150972353294492), (11, 0.05406309198588133), (2, 0.055183833464980125), (10, 0.06240202998742461), (9, 0.08971724286675453), (17, 0.18636955507099628), (18, 0.27677176147699356), (36, 0.3319150507450104), (53, 0.8919048383831978)]
computing accuracy for after removing block 3 . block score: 0.014681300381198525
removed block 3 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 28, with score 0.018655. All blocks and scores: [(28, 0.018655424704775214), (37, 0.018990264739841223), (50, 0.01935263443738222), (38, 0.020607825834304094), (34, 0.021370295202359557), (49, 0.02147139934822917), (45, 0.022496372694149613), (7, 0.022563793463632464), (46, 0.023017879342660308), (51, 0.023357107769697905), (39, 0.02375177387148142), (6, 0.024294147500768304), (41, 0.02434354182332754), (48, 0.024988262681290507), (1, 0.025388095760717988), (8, 0.025867065647616982), (47, 0.026250996626913548), (44, 0.0286602471023798), (42, 0.028714660787954926), (43, 0.029567111283540726), (40, 0.03209337405860424), (33, 0.03214729996398091), (0, 0.032716508489102125), (13, 0.033637304324656725), (14, 0.03939402848482132), (52, 0.039910301100462675), (16, 0.04249449400231242), (15, 0.042698927223682404), (12, 0.05363550456240773), (11, 0.05404201848432422), (4, 0.05474466597661376), (2, 0.05518383486196399), (10, 0.06464330479502678), (9, 0.093611647374928), (17, 0.18750124610960484), (18, 0.27515243738889694), (36, 0.34003007411956787), (53, 0.8942566886544228)]
computing accuracy for after removing block 28 . block score: 0.018655424704775214
removed block 28 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.08140000000000003 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.018354. All blocks and scores: [(37, 0.018354135332629085), (50, 0.018611087696626782), (38, 0.02046634373255074), (49, 0.020779792917892337), (45, 0.021783865289762616), (34, 0.022262955782935023), (51, 0.022289656102657318), (7, 0.02256379323080182), (39, 0.022737625520676374), (46, 0.022809282643720508), (6, 0.024294147500768304), (48, 0.024323247140273452), (41, 0.024347293889150023), (1, 0.0253880952950567), (47, 0.025682266801595688), (8, 0.025867066578939557), (42, 0.028105770703405142), (44, 0.028211602242663503), (43, 0.029053980018943548), (40, 0.031712270341813564), (0, 0.03271650895476341), (13, 0.03363730479031801), (33, 0.03551091579720378), (52, 0.03843055525794625), (14, 0.03939402708783746), (16, 0.04249449307098985), (15, 0.042698927223682404), (12, 0.05363550130277872), (11, 0.05404201848432422), (4, 0.05474466364830732), (2, 0.055183835327625275), (10, 0.06464330479502678), (9, 0.09361164644360542), (17, 0.18750124238431454), (18, 0.27515243366360664), (36, 0.3470933996140957), (53, 0.9132807701826096)]
computing accuracy for after removing block 37 . block score: 0.018354135332629085
removed block 37 current accuracy 0.8968 loss from initial  0.10319999999999996
training start
training epoch 0 val accuracy 0.7834 topk_dict {'top1': 0.7834} is_best False lr [0.1]
training epoch 1 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 2 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 3 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best False lr [0.1]
training epoch 4 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 7 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 9 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 10 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.96 topk_dict {'top1': 0.96} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.963000)
finished training. finished 50 epochs. accuracy 0.963 topk_dict {'top1': 0.963}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.037662. All blocks and scores: [(49, 0.03766204044222832), (51, 0.03855243558064103), (50, 0.03863813169300556), (7, 0.0393957095220685), (1, 0.03977075684815645), (48, 0.04554348811507225), (52, 0.04769676085561514), (44, 0.049602295737713575), (41, 0.050117896404117346), (39, 0.05141907650977373), (46, 0.051435894798487425), (38, 0.05144768534228206), (40, 0.05197902675718069), (45, 0.052250166423618793), (8, 0.05437845131382346), (47, 0.055893009062856436), (42, 0.05706681311130524), (43, 0.06600903440266848), (0, 0.07125084288418293), (6, 0.07144162710756063), (13, 0.0819246368482709), (34, 0.08195641729980707), (15, 0.09991027601063251), (14, 0.10192923992872238), (16, 0.10435009654611349), (33, 0.10601951368153095), (11, 0.1166479466482997), (12, 0.12203252501785755), (2, 0.12552883103489876), (10, 0.13613987900316715), (4, 0.15172828175127506), (9, 0.1796356774866581), (18, 0.43715501949191093), (17, 0.4434269964694977), (36, 0.6680537089705467), (53, 1.0698310434818268)]
computing accuracy for after removing block 49 . block score: 0.03766204044222832
removed block 49 current accuracy 0.9578 loss from initial  0.042200000000000015
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 7, with score 0.039396. All blocks and scores: [(7, 0.03939570998772979), (1, 0.03977075777947903), (51, 0.043750984128564596), (50, 0.044995186384767294), (48, 0.04554348858073354), (44, 0.04960229666903615), (41, 0.050117895007133484), (39, 0.051419077441096306), (46, 0.05143589386716485), (38, 0.05144768487662077), (52, 0.05159254791215062), (40, 0.05197902489453554), (45, 0.05225016735494137), (8, 0.0543784499168396), (47, 0.05589300952851772), (42, 0.057066813576966524), (43, 0.06600903533399105), (0, 0.07125084102153778), (6, 0.07144162710756063), (13, 0.08192464057356119), (34, 0.08195641729980707), (15, 0.09991027601063251), (14, 0.10192923806607723), (16, 0.10435009375214577), (33, 0.10601951461285353), (11, 0.11664794944226742), (12, 0.12203252129256725), (2, 0.12552882730960846), (10, 0.13613988272845745), (4, 0.1517282798886299), (9, 0.1796356774866581), (18, 0.43715502321720123), (17, 0.4434269927442074), (36, 0.6680536940693855), (53, 1.2568340003490448)]
computing accuracy for after removing block 7 . block score: 0.03939570998772979
removed block 7 current accuracy 0.9532 loss from initial  0.04679999999999995
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 1, with score 0.039771. All blocks and scores: [(1, 0.03977075731381774), (50, 0.04391190456226468), (51, 0.044482039753347635), (48, 0.044978389982134104), (44, 0.046120569575577974), (38, 0.046947600319981575), (41, 0.04748765844851732), (39, 0.04770107660442591), (46, 0.049865894950926304), (45, 0.05127424607053399), (40, 0.05160617968067527), (52, 0.05200111819431186), (47, 0.05512059573084116), (42, 0.055901361629366875), (8, 0.05963926296681166), (43, 0.06416172999888659), (0, 0.07125084102153778), (6, 0.07144162897020578), (13, 0.07703903503715992), (34, 0.07753634825348854), (14, 0.09113405551761389), (15, 0.09504233114421368), (33, 0.10095577593892813), (16, 0.10330726206302643), (12, 0.11345254629850388), (11, 0.11450277455151081), (2, 0.1255288291722536), (10, 0.1353256031870842), (4, 0.1517282873392105), (9, 0.18260444328188896), (17, 0.3987995497882366), (18, 0.4171077609062195), (36, 0.6325375884771347), (53, 1.2831655144691467)]
computing accuracy for after removing block 1 . block score: 0.03977075731381774
removed block 1 current accuracy 0.9476 loss from initial  0.0524
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.044105. All blocks and scores: [(50, 0.044104565400630236), (44, 0.04510618466883898), (51, 0.04578909417614341), (38, 0.04624936869367957), (48, 0.0462951622903347), (41, 0.04779289662837982), (39, 0.04915824020281434), (46, 0.050873998552560806), (45, 0.0518334642983973), (52, 0.052432283759117126), (40, 0.05520012928172946), (47, 0.056601461954414845), (42, 0.05704427324235439), (8, 0.060556051786988974), (43, 0.06479744333773851), (6, 0.06685218773782253), (0, 0.07125084102153778), (13, 0.07562779635190964), (34, 0.07829306460916996), (14, 0.08636697009205818), (15, 0.09016871079802513), (33, 0.10033182986080647), (16, 0.10252831038087606), (12, 0.11007741186767817), (11, 0.11582757998257875), (2, 0.1291196271777153), (10, 0.13834847696125507), (4, 0.15426373481750488), (9, 0.17991299368441105), (17, 0.4081035815179348), (18, 0.4189276210963726), (36, 0.644667848944664), (53, 1.2643065750598907)]
computing accuracy for after removing block 50 . block score: 0.044104565400630236
removed block 50 current accuracy 0.9286 loss from initial  0.07140000000000002
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.045106. All blocks and scores: [(44, 0.045106185134500265), (38, 0.04624936869367957), (48, 0.04629516275599599), (41, 0.047792897559702396), (39, 0.04915823834016919), (46, 0.050873999018222094), (45, 0.0518334642983973), (51, 0.05294811027124524), (40, 0.05520012974739075), (47, 0.05660146148875356), (42, 0.05704427324235439), (52, 0.057882634457200766), (8, 0.06055605225265026), (43, 0.06479744240641594), (6, 0.06685218680649996), (0, 0.07125084195286036), (13, 0.07562779542058706), (34, 0.07829306740313768), (14, 0.08636697195470333), (15, 0.09016870893537998), (33, 0.10033183079212904), (16, 0.10252831038087606), (12, 0.11007741186767817), (11, 0.11582757998257875), (2, 0.12911962158977985), (10, 0.13834847696125507), (4, 0.15426373481750488), (9, 0.1799129955470562), (17, 0.4081035479903221), (18, 0.4189276210963726), (36, 0.644667848944664), (53, 1.4488917887210846)]
computing accuracy for after removing block 44 . block score: 0.045106185134500265
removed block 44 current accuracy 0.9134 loss from initial  0.08660000000000001
since last training loss: 0.04959999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.046249. All blocks and scores: [(38, 0.046249369625002146), (48, 0.04749338421970606), (41, 0.047792896162718534), (39, 0.04915823834016919), (51, 0.05298877554014325), (46, 0.05327382776886225), (40, 0.055200131610035896), (45, 0.05576819134876132), (42, 0.057044270914047956), (47, 0.05727997934445739), (52, 0.05749549996107817), (8, 0.06055605039000511), (43, 0.06479744333773851), (6, 0.06685218680649996), (0, 0.07125083915889263), (13, 0.07562779542058706), (34, 0.07829306460916996), (14, 0.08636697102338076), (15, 0.09016870986670256), (33, 0.10033182799816132), (16, 0.10252831131219864), (12, 0.11007741559296846), (11, 0.11582757718861103), (2, 0.1291196197271347), (10, 0.13834847509860992), (4, 0.15426373668015003), (9, 0.1799129955470562), (17, 0.4081035666167736), (18, 0.4189276285469532), (36, 0.6446678563952446), (53, 1.471155896782875)]
computing accuracy for after removing block 38 . block score: 0.046249369625002146
removed block 38 current accuracy 0.901 loss from initial  0.09899999999999998
since last training loss: 0.061999999999999944 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.043666. All blocks and scores: [(48, 0.04366563865914941), (41, 0.04787380527704954), (46, 0.05077732028439641), (51, 0.051048808731138706), (45, 0.052407439798116684), (47, 0.052553939167410135), (39, 0.05399066489189863), (52, 0.05598384840413928), (42, 0.056111167185008526), (40, 0.0570660880766809), (8, 0.060556051786988974), (43, 0.0649100299924612), (6, 0.06685218494385481), (0, 0.07125084102153778), (13, 0.07562779635190964), (34, 0.07829306367784739), (14, 0.08636697102338076), (15, 0.09016870986670256), (33, 0.10033182986080647), (16, 0.10252830944955349), (12, 0.11007741373032331), (11, 0.11582758370786905), (2, 0.12911962158977985), (10, 0.13834847882390022), (4, 0.15426373668015003), (9, 0.1799129992723465), (17, 0.4081035777926445), (18, 0.4189276210963726), (36, 0.6446678712964058), (53, 1.4102854281663895)]
computing accuracy for after removing block 48 . block score: 0.04366563865914941
removed block 48 current accuracy 0.872 loss from initial  0.128
since last training loss: 0.09099999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.047874. All blocks and scores: [(41, 0.04787380434572697), (46, 0.0507773207500577), (45, 0.05240743886679411), (47, 0.05255394009873271), (39, 0.05399066489189863), (42, 0.05611116765066981), (51, 0.05631876643747091), (40, 0.05706608761101961), (8, 0.060556051321327686), (52, 0.06063387496396899), (43, 0.0649100299924612), (6, 0.06685218494385481), (0, 0.0712508400902152), (13, 0.07562779728323221), (34, 0.07829306554049253), (14, 0.08636697102338076), (15, 0.09016870800405741), (33, 0.10033182986080647), (16, 0.10252830665558577), (12, 0.11007741186767817), (11, 0.11582757905125618), (2, 0.1291196271777153), (10, 0.13834847882390022), (4, 0.15426373854279518), (9, 0.17991299740970135), (17, 0.4081035666167736), (18, 0.4189276285469532), (36, 0.6446678563952446), (53, 1.6237045526504517)]
computing accuracy for after removing block 41 . block score: 0.04787380434572697
removed block 41 current accuracy 0.8568 loss from initial  0.1432
since last training loss: 0.10619999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.049143. All blocks and scores: [(46, 0.04914297861978412), (45, 0.049642825964838266), (47, 0.05142336478456855), (39, 0.053990666288882494), (51, 0.05540242372080684), (42, 0.05694689555093646), (40, 0.05706608761101961), (8, 0.06055605271831155), (52, 0.06113287899643183), (43, 0.0655756862834096), (6, 0.06685218680649996), (0, 0.07125084102153778), (13, 0.07562779635190964), (34, 0.07829306554049253), (14, 0.08636697009205818), (15, 0.09016870986670256), (33, 0.10033182892948389), (16, 0.10252830758690834), (12, 0.11007741652429104), (11, 0.1158275818452239), (2, 0.129119623452425), (10, 0.13834847882390022), (4, 0.15426374040544033), (9, 0.17991300113499165), (17, 0.4081035740673542), (18, 0.4189276173710823), (36, 0.6446678787469864), (53, 1.7058468014001846)]
computing accuracy for after removing block 46 . block score: 0.04914297861978412
removed block 46 current accuracy 0.808 loss from initial  0.19199999999999995
training start
training epoch 0 val accuracy 0.843 topk_dict {'top1': 0.843} is_best True lr [0.1]
training epoch 1 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best True lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 3 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 4 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.1]
training epoch 5 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 6 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.1]
training epoch 7 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 8 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 9 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.066383. All blocks and scores: [(52, 0.06638332083821297), (51, 0.07012750208377838), (40, 0.07280862797051668), (45, 0.07498017139732838), (39, 0.07697778660804033), (42, 0.08150158915668726), (8, 0.08312122523784637), (47, 0.08400689717382193), (6, 0.08562350459396839), (43, 0.08789059612900019), (13, 0.09635879565030336), (34, 0.10334808100014925), (0, 0.10721797030419111), (16, 0.11236760951578617), (15, 0.11311968602240086), (14, 0.1154852407053113), (11, 0.11812457721680403), (33, 0.13502268493175507), (12, 0.1399240866303444), (10, 0.15802829526364803), (2, 0.16146285645663738), (9, 0.19328326731920242), (4, 0.20546958781778812), (17, 0.4629388824105263), (18, 0.5007087886333466), (36, 0.6093571707606316), (53, 1.1630521565675735)]
computing accuracy for after removing block 52 . block score: 0.06638332083821297
removed block 52 current accuracy 0.9196 loss from initial  0.08040000000000003
since last training loss: 0.024800000000000044 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.070128. All blocks and scores: [(51, 0.07012750208377838), (40, 0.07280862890183926), (45, 0.07498016953468323), (39, 0.07697778847068548), (42, 0.08150158822536469), (8, 0.0831212243065238), (47, 0.08400689717382193), (6, 0.08562350459396839), (43, 0.08789059706032276), (13, 0.09635879844427109), (34, 0.10334808100014925), (0, 0.10721797030419111), (16, 0.1123676123097539), (15, 0.11311968695372343), (14, 0.11548523511737585), (11, 0.1181245855987072), (33, 0.13502268493175507), (12, 0.13992408476769924), (10, 0.15802829153835773), (2, 0.16146286763250828), (9, 0.19328327290713787), (4, 0.20546958409249783), (17, 0.4629388861358166), (18, 0.500708781182766), (36, 0.6093571707606316), (53, 1.0845505893230438)]
computing accuracy for after removing block 51 . block score: 0.07012750208377838
removed block 51 current accuracy 0.8936 loss from initial  0.10640000000000005
since last training loss: 0.05080000000000007 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 40, with score 0.072809. All blocks and scores: [(40, 0.07280862890183926), (45, 0.07498016860336065), (39, 0.07697778753936291), (42, 0.08150159008800983), (8, 0.0831212280318141), (47, 0.08400689717382193), (6, 0.08562350459396839), (43, 0.08789059892296791), (13, 0.09635879471898079), (34, 0.1033480828627944), (0, 0.10721796657890081), (16, 0.11236761137843132), (15, 0.11311968602240086), (14, 0.11548523977398872), (11, 0.1181245818734169), (33, 0.13502268306910992), (12, 0.1399240903556347), (10, 0.15802829526364803), (2, 0.16146286390721798), (9, 0.19328327476978302), (4, 0.20546958595514297), (17, 0.4629388898611069), (18, 0.5007087960839272), (36, 0.609357163310051), (53, 1.3642746359109879)]
computing accuracy for after removing block 40 . block score: 0.07280862890183926
removed block 40 current accuracy 0.8656 loss from initial  0.13439999999999996
since last training loss: 0.07879999999999998 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 45, with score 0.073239. All blocks and scores: [(45, 0.07323900237679482), (39, 0.07697778940200806), (47, 0.07860942464321852), (8, 0.0831212243065238), (42, 0.083926597610116), (6, 0.08562350086867809), (43, 0.09310796018689871), (13, 0.09635879751294851), (34, 0.1033480828627944), (0, 0.10721796657890081), (16, 0.11236761324107647), (15, 0.1131196841597557), (14, 0.11548524163663387), (11, 0.11812458280473948), (33, 0.13502268679440022), (12, 0.1399240866303444), (10, 0.15802829153835773), (2, 0.16146285831928253), (9, 0.19328326359391212), (4, 0.20546958409249783), (17, 0.4629388861358166), (18, 0.5007087886333466), (36, 0.609357163310051), (53, 1.3323704153299332)]
computing accuracy for after removing block 45 . block score: 0.07323900237679482
removed block 45 current accuracy 0.809 loss from initial  0.19099999999999995
since last training loss: 0.13539999999999996 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 39, with score 0.076978. All blocks and scores: [(39, 0.07697778847068548), (8, 0.08312122523784637), (42, 0.08392659574747086), (6, 0.08562350552529097), (47, 0.088039162568748), (43, 0.09310796298086643), (13, 0.09635880030691624), (34, 0.10334808100014925), (0, 0.10721796844154596), (16, 0.11236761137843132), (15, 0.11311968229711056), (14, 0.11548523604869843), (11, 0.11812457907944918), (33, 0.13502268679440022), (12, 0.1399240829050541), (10, 0.15802829153835773), (2, 0.16146286204457283), (9, 0.19328327104449272), (4, 0.20546958409249783), (17, 0.4629388824105263), (18, 0.5007087960839272), (36, 0.6093571782112122), (53, 1.5411079972982407)]
computing accuracy for after removing block 39 . block score: 0.07697778847068548
removed block 39 current accuracy 0.7702 loss from initial  0.2298
since last training loss: 0.17420000000000002 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 8, with score 0.083121. All blocks and scores: [(8, 0.08312122616916895), (6, 0.08562350366264582), (47, 0.08616149798035622), (42, 0.09033498074859381), (13, 0.09635879844427109), (43, 0.09795538242906332), (34, 0.10334808100014925), (0, 0.10721796564757824), (16, 0.1123676123097539), (15, 0.113119687885046), (14, 0.11548523884266615), (11, 0.11812458001077175), (33, 0.13502268120646477), (12, 0.13992408849298954), (10, 0.15802829340100288), (2, 0.16146286763250828), (9, 0.19328326918184757), (4, 0.20546958409249783), (17, 0.46293889358639717), (18, 0.500708818435669), (36, 0.6093571707606316), (53, 1.5688343942165375)]
computing accuracy for after removing block 8 . block score: 0.08312122616916895
removed block 8 current accuracy 0.6786 loss from initial  0.3214
since last training loss: 0.26580000000000004 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 47, with score 0.077339. All blocks and scores: [(47, 0.07733924966305494), (42, 0.08365436643362045), (6, 0.08562350180000067), (43, 0.09064406901597977), (13, 0.09417388867586851), (34, 0.09600294660776854), (14, 0.10463559348136187), (0, 0.10721796937286854), (11, 0.11276952549815178), (16, 0.11858568247407675), (15, 0.12053028307855129), (12, 0.1208017198368907), (33, 0.128963528200984), (10, 0.1608257181942463), (2, 0.16146286390721798), (4, 0.20546958595514297), (9, 0.22253728099167347), (17, 0.38402046635746956), (18, 0.4592589698731899), (36, 0.5781671777367592), (53, 1.53728748857975)]
computing accuracy for after removing block 47 . block score: 0.07733924966305494
removed block 47 current accuracy 0.5306 loss from initial  0.46940000000000004
since last training loss: 0.41380000000000006 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 42, with score 0.083654. All blocks and scores: [(42, 0.08365436643362045), (6, 0.08562349993735552), (43, 0.09064406994730234), (13, 0.09417388867586851), (34, 0.09600294940173626), (14, 0.10463559068739414), (0, 0.10721797030419111), (11, 0.1127695282921195), (16, 0.11858567781746387), (15, 0.12053028587251902), (12, 0.12080172076821327), (33, 0.1289635244756937), (10, 0.16082572005689144), (2, 0.16146286204457283), (4, 0.20546958036720753), (9, 0.22253728099167347), (17, 0.38402047380805016), (18, 0.4592589773237705), (36, 0.5781671553850174), (53, 1.8823152482509613)]
computing accuracy for after removing block 42 . block score: 0.08365436643362045
removed block 42 current accuracy 0.4838 loss from initial  0.5162
since last training loss: 0.4606 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 6, with score 0.085623. All blocks and scores: [(6, 0.08562349993735552), (13, 0.09417389053851366), (34, 0.09600294660776854), (43, 0.10423041973263025), (14, 0.10463558789342642), (0, 0.10721796564757824), (11, 0.11276952736079693), (16, 0.11858568247407675), (15, 0.12053028400987387), (12, 0.12080171704292297), (33, 0.128963528200984), (10, 0.1608257181942463), (2, 0.16146286390721798), (4, 0.20546958222985268), (9, 0.22253728285431862), (17, 0.38402047008275986), (18, 0.4592589884996414), (36, 0.5781671777367592), (53, 1.8142477720975876)]
computing accuracy for after removing block 6 . block score: 0.08562349993735552
removed block 6 current accuracy 0.4606 loss from initial  0.5394
since last training loss: 0.4838 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 34, with score 0.088116. All blocks and scores: [(34, 0.08811610378324986), (13, 0.09348397050052881), (43, 0.0982144819572568), (14, 0.10246896371245384), (0, 0.10721796937286854), (11, 0.11101157683879137), (12, 0.11712269764393568), (16, 0.11751155462116003), (33, 0.11815245356410742), (15, 0.12742969766259193), (2, 0.16146286018192768), (10, 0.1652760747820139), (4, 0.20546958222985268), (9, 0.2247878648340702), (17, 0.380580086261034), (18, 0.4551882818341255), (36, 0.5405922383069992), (53, 1.7545569092035294)]
computing accuracy for after removing block 34 . block score: 0.08811610378324986
removed block 34 current accuracy 0.3942 loss from initial  0.6058
since last training loss: 0.5502 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 13, with score 0.093484. All blocks and scores: [(13, 0.09348397236317396), (14, 0.10246896464377642), (43, 0.10341138392686844), (0, 0.10721797030419111), (11, 0.1110115759074688), (12, 0.11712269950658083), (16, 0.11751155368983746), (33, 0.11815245915204287), (15, 0.12742970138788223), (2, 0.16146286390721798), (10, 0.1652760747820139), (4, 0.20546957850456238), (9, 0.2247878536581993), (17, 0.3805800937116146), (18, 0.4551882855594158), (36, 0.575109951198101), (53, 1.854774996638298)]
computing accuracy for after removing block 13 . block score: 0.09348397236317396
removed block 13 current accuracy 0.3632 loss from initial  0.6368
since last training loss: 0.5811999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 14, with score 0.093162. All blocks and scores: [(14, 0.09316200390458107), (43, 0.09657959081232548), (0, 0.10721797030419111), (11, 0.1110115759074688), (16, 0.11233233939856291), (33, 0.11582048051059246), (12, 0.11712269857525826), (15, 0.12872780486941338), (2, 0.16146286763250828), (10, 0.16527607291936874), (4, 0.20546957850456238), (9, 0.22478785552084446), (17, 0.3292568549513817), (18, 0.43321443349123), (36, 0.538392037153244), (53, 1.7473642975091934)]
computing accuracy for after removing block 14 . block score: 0.09316200390458107
removed block 14 current accuracy 0.329 loss from initial  0.671
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.1]
training epoch 1 val accuracy 0.833 topk_dict {'top1': 0.833} is_best True lr [0.1]
training epoch 2 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best True lr [0.1]
training epoch 3 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 4 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 5 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.1]
training epoch 6 val accuracy 0.814 topk_dict {'top1': 0.814} is_best False lr [0.1]
training epoch 7 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 8 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 9 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 10 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.915400)
finished training. finished 50 epochs. accuracy 0.9154 topk_dict {'top1': 0.9154}
