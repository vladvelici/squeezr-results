start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009340. All blocks and scores: [(35, 0.009340325254015625), (27, 0.011103683733381331), (21, 0.011334074079059064), (31, 0.011607039254158735), (34, 0.011916786199435592), (20, 0.012414053780958056), (10, 0.012957266997545958), (29, 0.013191591715440154), (28, 0.014451422379352152), (25, 0.015047204098664224), (32, 0.015597440884448588), (26, 0.015913886483758688), (9, 0.015947438310831785), (33, 0.016213827300816774), (19, 0.016238084295764565), (30, 0.016535081434994936), (13, 0.01730443025007844), (23, 0.01780766947194934), (24, 0.018264205427840352), (47, 0.018334639724344015), (43, 0.018826094921678305), (22, 0.01902754232287407), (42, 0.019418791867792606), (39, 0.01959144975990057), (11, 0.019892502576112747), (46, 0.019984069745987654), (45, 0.020175756653770804), (40, 0.020337841473519802), (44, 0.02035037102177739), (41, 0.02134683425538242), (17, 0.022294857306405902), (14, 0.023160054814070463), (48, 0.023965090047568083), (38, 0.024251852184534073), (49, 0.025340354768559337), (37, 0.02872352860867977), (50, 0.030707398429512978), (51, 0.0362198487855494), (15, 0.03717772988602519), (0, 0.04586179181933403), (12, 0.04737982153892517), (8, 0.04887042474001646), (4, 0.05213462933897972), (5, 0.052416717633605), (7, 0.05547522380948067), (2, 0.06098463665693998), (16, 0.06157056335359812), (3, 0.06243071844801307), (6, 0.06518651638180017), (52, 0.07758118864148855), (1, 0.15718718618154526), (36, 0.31111688166856766), (18, 0.38249506056308746), (53, 0.8639277964830399)]
computing accuracy for after removing block 35 . block score: 0.009340325254015625
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.011104. All blocks and scores: [(27, 0.01110368361696601), (21, 0.011334074195474386), (31, 0.011607038788497448), (34, 0.011916786548681557), (20, 0.0124140540137887), (10, 0.01295726653188467), (29, 0.013191591831855476), (28, 0.01445142226293683), (25, 0.015047204215079546), (32, 0.015597441582940519), (26, 0.015913886483758688), (9, 0.015947437845170498), (33, 0.016213827999308705), (19, 0.016238084295764565), (30, 0.016535081434994936), (13, 0.01730443094857037), (23, 0.017807669239118695), (47, 0.0182215787936002), (24, 0.018264205660670996), (43, 0.01871312130242586), (22, 0.019027542555704713), (42, 0.019336249912157655), (39, 0.01957682752981782), (11, 0.019892503041774035), (46, 0.019986523315310478), (45, 0.02004792680963874), (40, 0.020296326372772455), (44, 0.020512877963483334), (41, 0.02144961175508797), (17, 0.022294857306405902), (14, 0.023160054348409176), (48, 0.023811294930055737), (38, 0.024050168693065643), (49, 0.025408401852473617), (37, 0.028856527991592884), (50, 0.03064044937491417), (51, 0.03598107350990176), (15, 0.0371777294203639), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042613700032), (4, 0.052134628873318434), (5, 0.05241671856492758), (7, 0.05547522287815809), (2, 0.06098463712260127), (16, 0.06157056335359812), (3, 0.06243071751669049), (6, 0.06518651824444532), (52, 0.07701416406780481), (1, 0.15718718245625496), (36, 0.3119105063378811), (18, 0.38249505683779716), (53, 0.873422808945179)]
computing accuracy for after removing block 27 . block score: 0.01110368361696601
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011334. All blocks and scores: [(21, 0.011334074195474386), (31, 0.011815687641501427), (34, 0.011877579498104751), (20, 0.012414053664542735), (10, 0.012957266997545958), (29, 0.013689620420336723), (28, 0.014708209433592856), (25, 0.015047204331494868), (32, 0.015121230273507535), (26, 0.01591388671658933), (9, 0.01594743807800114), (33, 0.016188491135835648), (19, 0.016238084295764565), (30, 0.01633173250593245), (13, 0.01730443094857037), (47, 0.017806177493184805), (23, 0.01780766900628805), (24, 0.01826420589350164), (43, 0.018580012256279588), (22, 0.019027542090043426), (42, 0.019391174893826246), (46, 0.01960694300942123), (39, 0.019607228226959705), (45, 0.019715042086318135), (40, 0.01974743651226163), (11, 0.01989250280894339), (44, 0.020142703782767057), (41, 0.02075307280756533), (17, 0.022294856375083327), (48, 0.022873760666698217), (14, 0.023160054814070463), (38, 0.0239896010607481), (49, 0.024799507576972246), (37, 0.028698160778731108), (50, 0.030612411443144083), (51, 0.035496633499860764), (15, 0.03717772988602519), (0, 0.04586179181933403), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213463120162487), (5, 0.05241671670228243), (7, 0.05547522287815809), (2, 0.06098463851958513), (16, 0.06157056335359812), (3, 0.062430717051029205), (6, 0.06518651824444532), (52, 0.07554570958018303), (1, 0.15718718245625496), (36, 0.31206290796399117), (18, 0.3824950382113457), (53, 0.8803881481289864)]
computing accuracy for after removing block 21 . block score: 0.011334074195474386
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011639. All blocks and scores: [(31, 0.011639060452580452), (34, 0.011946186306886375), (20, 0.012414053548127413), (10, 0.012957266648299992), (29, 0.013874796568416059), (28, 0.014550406020134687), (25, 0.014715025201439857), (32, 0.015309393173083663), (26, 0.015426586265675724), (9, 0.015947437845170498), (30, 0.016168840462341905), (19, 0.016238084295764565), (33, 0.01623979490250349), (13, 0.017304430482909083), (23, 0.017435556277632713), (47, 0.01766685605980456), (24, 0.018116667633876204), (43, 0.018401946406811476), (42, 0.018988730618730187), (22, 0.019208092242479324), (45, 0.01936019933782518), (40, 0.019363844534382224), (39, 0.01944134454242885), (46, 0.019487919751554728), (11, 0.019892503041774035), (44, 0.02018019580282271), (41, 0.02058563963510096), (17, 0.022294857539236546), (48, 0.022515942808240652), (14, 0.023160054814070463), (38, 0.024127490585669875), (49, 0.024722861126065254), (37, 0.029028164222836494), (50, 0.03045049775391817), (51, 0.03526381403207779), (15, 0.0371777294203639), (0, 0.04586179368197918), (12, 0.047379820607602596), (8, 0.04887042474001646), (4, 0.05213462980464101), (5, 0.05241671670228243), (7, 0.055475224275141954), (2, 0.06098464038223028), (16, 0.061570563819259405), (3, 0.062430717051029205), (6, 0.06518651731312275), (52, 0.07456282526254654), (1, 0.15718718245625496), (36, 0.3133090250194073), (18, 0.38249505311250687), (53, 0.880434550344944)]
computing accuracy for after removing block 31 . block score: 0.011639060452580452
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012262. All blocks and scores: [(34, 0.012262115138582885), (20, 0.012414054712280631), (10, 0.012957266997545958), (29, 0.013874796917662024), (28, 0.014550405205227435), (25, 0.014715025434270501), (32, 0.015284727793186903), (26, 0.015426586265675724), (9, 0.015947438310831785), (33, 0.01609011017717421), (30, 0.016168840462341905), (19, 0.016238084062933922), (13, 0.017304430482909083), (47, 0.0173895217012614), (23, 0.017435555811971426), (43, 0.017958790296688676), (24, 0.018116666935384274), (42, 0.018551464658230543), (40, 0.01901159342378378), (45, 0.01909672119654715), (22, 0.019208092940971255), (46, 0.01932260673493147), (39, 0.019438674673438072), (11, 0.019892503041774035), (44, 0.02009617746807635), (41, 0.02039977116510272), (48, 0.022222392726689577), (17, 0.022294857539236546), (14, 0.02316005458123982), (38, 0.023856615647673607), (49, 0.024399895453825593), (37, 0.029221920762211084), (50, 0.030021414626389742), (51, 0.03500615246593952), (15, 0.037177727557718754), (0, 0.04586179181933403), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.052134628873318434), (5, 0.05241671856492758), (7, 0.05547522334381938), (2, 0.06098463758826256), (16, 0.06157056102529168), (3, 0.062430717051029205), (6, 0.06518651638180017), (52, 0.07356802467256784), (1, 0.15718718245625496), (36, 0.31360404938459396), (18, 0.38249504566192627), (53, 0.887540690600872)]
computing accuracy for after removing block 34 . block score: 0.012262115138582885
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012414. All blocks and scores: [(20, 0.0124140540137887), (10, 0.012957266764715314), (29, 0.01387479668483138), (28, 0.014550404972396791), (25, 0.014715025667101145), (32, 0.01528472697827965), (26, 0.015426585800014436), (9, 0.015947438776493073), (33, 0.016090110642835498), (30, 0.016168839996680617), (19, 0.016238084761425853), (47, 0.01711349585093558), (13, 0.01730443094857037), (23, 0.01743555604480207), (43, 0.017444000113755465), (42, 0.017953321570530534), (24, 0.018116667633876204), (40, 0.01862735440954566), (45, 0.01879685022868216), (46, 0.019162564305588603), (22, 0.01920809200964868), (39, 0.019221500726416707), (11, 0.019892503041774035), (44, 0.020024231867864728), (41, 0.02006620983593166), (48, 0.02205545175820589), (17, 0.02229485777206719), (14, 0.023160055046901107), (38, 0.023407893488183618), (49, 0.02394348639063537), (37, 0.02887884364463389), (50, 0.02955093001946807), (51, 0.034714368637651205), (15, 0.03717772848904133), (0, 0.045861792750656605), (12, 0.047379819210618734), (8, 0.0488704270683229), (4, 0.05213462980464101), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.060984639916568995), (16, 0.061570563819259405), (3, 0.06243071798235178), (6, 0.06518651824444532), (52, 0.07239074818789959), (1, 0.15718717873096466), (36, 0.3131321780383587), (18, 0.3824950382113457), (53, 0.8949520438909531)]
computing accuracy for after removing block 20 . block score: 0.0124140540137887
removed block 20 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012957. All blocks and scores: [(10, 0.012957266881130636), (29, 0.013561785453930497), (28, 0.01402895210776478), (25, 0.014169098576530814), (32, 0.014978608931414783), (26, 0.014983123284764588), (30, 0.015398439951241016), (9, 0.01594743807800114), (33, 0.016120446380227804), (19, 0.01623808452859521), (47, 0.016815442824736238), (43, 0.016843858873471618), (23, 0.017247507581487298), (13, 0.017304430482909083), (42, 0.017349499743431807), (24, 0.017785267438739538), (40, 0.018032792722806334), (45, 0.018344406271353364), (39, 0.0189236372243613), (46, 0.019041895167902112), (22, 0.01921574934385717), (41, 0.019646556582301855), (11, 0.019892503041774035), (44, 0.02013750490732491), (48, 0.021741406992077827), (17, 0.022294857539236546), (14, 0.023160054814070463), (38, 0.023315483005717397), (49, 0.023662553634494543), (37, 0.02904578926973045), (50, 0.02913463767617941), (51, 0.03401449741795659), (15, 0.03717772988602519), (0, 0.04586179135367274), (12, 0.04737982153892517), (8, 0.048870425671339035), (4, 0.05213462980464101), (5, 0.05241671670228243), (7, 0.05547522334381938), (2, 0.06098463572561741), (16, 0.06157056335359812), (3, 0.06243071658536792), (6, 0.06518651731312275), (52, 0.07068234588950872), (1, 0.15718718618154526), (36, 0.31336938217282295), (18, 0.3824950382113457), (53, 0.8989739492535591)]
computing accuracy for after removing block 10 . block score: 0.012957266881130636
removed block 10 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013780. All blocks and scores: [(29, 0.013779842876829207), (28, 0.013976978603750467), (25, 0.014224751270376146), (26, 0.014854759676381946), (32, 0.01509961485862732), (30, 0.01545485737733543), (9, 0.015947438310831785), (33, 0.0162667038384825), (13, 0.016542865661904216), (43, 0.01676264777779579), (47, 0.01678211963735521), (23, 0.017073968658223748), (19, 0.017181470524519682), (42, 0.017427340848371387), (40, 0.01776417507790029), (24, 0.01784460013732314), (45, 0.018063028110191226), (39, 0.018619783455505967), (46, 0.018768534529954195), (22, 0.018944737734273076), (41, 0.01944462489336729), (44, 0.019642785424366593), (11, 0.020282882265746593), (48, 0.021175473229959607), (17, 0.022723609814420342), (14, 0.022779475431889296), (38, 0.023119496181607246), (49, 0.02381147793494165), (37, 0.027783304685726762), (50, 0.02857796847820282), (51, 0.033666453789919615), (15, 0.03736387751996517), (12, 0.0431427345611155), (0, 0.04586179135367274), (8, 0.04887042660266161), (4, 0.05213462980464101), (5, 0.05241671670228243), (7, 0.05547522287815809), (2, 0.06098463945090771), (16, 0.061621973756700754), (3, 0.06243071937933564), (6, 0.06518651638180017), (52, 0.07000694703310728), (1, 0.1571871805936098), (36, 0.30398043617606163), (18, 0.3742111809551716), (53, 0.899316817522049)]
computing accuracy for after removing block 29 . block score: 0.013779842876829207
removed block 29 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.013977. All blocks and scores: [(28, 0.013976979185827076), (25, 0.01422475220169872), (26, 0.01485475990921259), (32, 0.015656630392186344), (9, 0.015947438310831785), (33, 0.016093432204797864), (30, 0.01633106591179967), (13, 0.016542865429073572), (47, 0.01658328203484416), (43, 0.016609041718766093), (42, 0.016731813549995422), (23, 0.017073968425393105), (19, 0.01718146982602775), (40, 0.01759379543364048), (45, 0.017683780984953046), (24, 0.017844600370153785), (39, 0.018342912895604968), (46, 0.018452940741553903), (22, 0.018944737501442432), (41, 0.019309210125356913), (44, 0.01936902431771159), (11, 0.020282881800085306), (48, 0.020786920795217156), (17, 0.022723609348759055), (14, 0.022779475431889296), (38, 0.023035791236907244), (49, 0.023334230994805694), (37, 0.02778223715722561), (50, 0.027876750798895955), (51, 0.033196397591382265), (15, 0.037363878916949034), (12, 0.043142734095454216), (0, 0.04586179368197918), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671623662114), (7, 0.05547522474080324), (2, 0.060984638053923845), (16, 0.061621975153684616), (3, 0.062430718913674355), (6, 0.0651865191757679), (52, 0.06813919544219971), (1, 0.1571871843189001), (36, 0.30388377606868744), (18, 0.3742111884057522), (53, 0.90864647179842)]
computing accuracy for after removing block 28 . block score: 0.013976979185827076
removed block 28 current accuracy 0.996 loss from initial  0.0040000000000000036
training start
training epoch 0 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best False lr [0.1]
training epoch 1 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 2 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 3 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 4 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 5 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.1]
training epoch 6 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 7 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 8 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 9 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 10 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996000)
finished training. finished 50 epochs. accuracy 0.996 topk_dict {'top1': 0.996}
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.014225. All blocks and scores: [(25, 0.014224751968868077), (26, 0.01485475932713598), (32, 0.015713009983301163), (9, 0.01594743854366243), (33, 0.016001068521291018), (47, 0.016190798487514257), (42, 0.016318539390340447), (43, 0.01633123680949211), (13, 0.016542865661904216), (30, 0.016802769852802157), (23, 0.017073968658223748), (19, 0.017181470058858395), (40, 0.017207595985382795), (45, 0.017318607540801167), (24, 0.01784460060298443), (39, 0.017898976569995284), (46, 0.018052106723189354), (22, 0.018944737501442432), (44, 0.01900760061107576), (41, 0.019063472980633378), (48, 0.02025347389280796), (11, 0.02028288203291595), (38, 0.022655859123915434), (17, 0.022723610047250986), (49, 0.022748680086806417), (14, 0.022779475199058652), (50, 0.027034819358959794), (37, 0.027097023092210293), (51, 0.03234624187462032), (15, 0.037363878451287746), (12, 0.04314273316413164), (0, 0.045861792750656605), (8, 0.048870425671339035), (4, 0.05213462980464101), (5, 0.05241671670228243), (7, 0.05547522148117423), (2, 0.06098464038223028), (16, 0.06162197422236204), (3, 0.062430717051029205), (6, 0.0651865191757679), (52, 0.06599841266870499), (1, 0.1571871805936098), (36, 0.3030109517276287), (18, 0.3742111884057522), (53, 0.9200856983661652)]
computing accuracy for after removing block 25 . block score: 0.014224751968868077
removed block 25 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014321. All blocks and scores: [(26, 0.014321206486783922), (32, 0.015725135570392013), (47, 0.015813482808880508), (9, 0.015947438310831785), (33, 0.01617535250261426), (43, 0.016194913536310196), (13, 0.016542865661904216), (42, 0.016636511776596308), (40, 0.016900550108402967), (30, 0.016924015013501048), (45, 0.01701010065153241), (23, 0.017073967959731817), (19, 0.017181470524519682), (24, 0.017844599904492497), (46, 0.017934611765667796), (39, 0.018276610877364874), (41, 0.018938244320452213), (22, 0.018944737035781145), (44, 0.01896944222971797), (48, 0.01987506588920951), (11, 0.020282881101593375), (49, 0.022301002871245146), (17, 0.022723609814420342), (14, 0.022779475897550583), (38, 0.02295250166207552), (50, 0.026609522057697177), (37, 0.02736746473237872), (51, 0.03210686496458948), (15, 0.037363877054303885), (12, 0.04314273316413164), (0, 0.04586179228499532), (8, 0.048870425671339035), (4, 0.05213462933897972), (5, 0.05241671670228243), (7, 0.055475224275141954), (2, 0.06098464038223028), (16, 0.061621971894055605), (3, 0.062430717051029205), (52, 0.0642223646864295), (6, 0.0651865191757679), (1, 0.1571871805936098), (36, 0.30919430777430534), (18, 0.3742111921310425), (53, 0.9223421737551689)]
computing accuracy for after removing block 26 . block score: 0.014321206486783922
removed block 26 current accuracy 0.9856 loss from initial  0.014399999999999968
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 47, with score 0.015591. All blocks and scores: [(47, 0.015591378672979772), (9, 0.015947438310831785), (33, 0.016119681065902114), (43, 0.016470806440338492), (13, 0.016542865661904216), (32, 0.016675117192789912), (45, 0.01684827939607203), (40, 0.01696594594977796), (23, 0.017073968658223748), (19, 0.017181469593197107), (42, 0.01737767760641873), (30, 0.01769446535035968), (46, 0.01773153035901487), (24, 0.01784460013732314), (44, 0.018625709228217602), (22, 0.018944737035781145), (39, 0.018995221005752683), (41, 0.019389543682336807), (48, 0.019601587671786547), (11, 0.02028288133442402), (49, 0.022070482140406966), (17, 0.02272361097857356), (14, 0.022779475199058652), (38, 0.023785780416801572), (50, 0.026121148839592934), (37, 0.028035480994731188), (51, 0.03197018662467599), (15, 0.03736387798562646), (12, 0.0431427345611155), (0, 0.045861790888011456), (8, 0.04887042520567775), (4, 0.052134628873318434), (5, 0.052416717167943716), (7, 0.05547522520646453), (2, 0.06098464084789157), (16, 0.061621973756700754), (3, 0.06243071984499693), (52, 0.06296230666339397), (6, 0.0651865191757679), (1, 0.15718717873096466), (36, 0.31919990479946136), (18, 0.3742111846804619), (53, 0.919974684715271)]
computing accuracy for after removing block 47 . block score: 0.015591378672979772
removed block 47 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.015947. All blocks and scores: [(9, 0.015947438776493073), (33, 0.016119681764394045), (43, 0.016470807371661067), (13, 0.016542865429073572), (32, 0.016675117192789912), (45, 0.016848279163241386), (40, 0.016965945716947317), (23, 0.017073968891054392), (19, 0.017181470058858395), (42, 0.01737767760641873), (30, 0.01769446535035968), (46, 0.017731530126184225), (24, 0.017844599904492497), (44, 0.018625709461048245), (22, 0.018944737501442432), (39, 0.018995221005752683), (41, 0.01938954391516745), (11, 0.020282881567254663), (48, 0.022071629529818892), (17, 0.022723609348759055), (14, 0.02277947450056672), (49, 0.023477209266275167), (38, 0.023785779252648354), (50, 0.02721921121701598), (37, 0.028035480761900544), (51, 0.03351395670324564), (15, 0.037363878451287746), (12, 0.04314273316413164), (0, 0.04586179135367274), (8, 0.04887042520567775), (4, 0.052134628873318434), (5, 0.052416717633605), (7, 0.055475222412496805), (2, 0.06098463945090771), (16, 0.06162197282537818), (3, 0.06243071658536792), (52, 0.06439626682549715), (6, 0.06518651824444532), (1, 0.1571871843189001), (36, 0.31919990107417107), (18, 0.3742111921310425), (53, 0.9626970216631889)]
computing accuracy for after removing block 9 . block score: 0.015947438776493073
removed block 9 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.016096. All blocks and scores: [(32, 0.01609638729132712), (45, 0.016266965540125966), (43, 0.016269846120849252), (33, 0.01637544692493975), (23, 0.016607446828857064), (40, 0.016879581613466144), (46, 0.01705330447293818), (30, 0.017178396694362164), (19, 0.017349788220599294), (24, 0.017503201495856047), (44, 0.0178118662443012), (42, 0.017975983675569296), (13, 0.018235396360978484), (41, 0.018629116006195545), (22, 0.019067521207034588), (39, 0.019353311974555254), (48, 0.02096651284955442), (11, 0.021229501347988844), (14, 0.022726128110662103), (49, 0.023100799415260553), (17, 0.023560585686936975), (38, 0.02391230990178883), (50, 0.025870412588119507), (37, 0.026413641637191176), (51, 0.032382586505264044), (15, 0.03793497942388058), (12, 0.041658344212919474), (0, 0.04586179181933403), (8, 0.048870425671339035), (4, 0.052134630270302296), (5, 0.052416717167943716), (7, 0.05547522287815809), (2, 0.06098464038223028), (3, 0.06243071844801307), (52, 0.06280327634885907), (16, 0.06422330066561699), (6, 0.06518651638180017), (1, 0.1571871805936098), (36, 0.3088325299322605), (18, 0.3658623918890953), (53, 0.9575238227844238)]
computing accuracy for after removing block 32 . block score: 0.01609638729132712
removed block 32 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.03859999999999997 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.016016. All blocks and scores: [(43, 0.016015663743019104), (45, 0.01611301035154611), (40, 0.016530799446627498), (23, 0.016607446363195777), (46, 0.017001276137307286), (30, 0.01717839646153152), (19, 0.01734978798776865), (24, 0.017503201495856047), (44, 0.017587421694770455), (33, 0.01765732537023723), (13, 0.018235396360978484), (42, 0.018364302115514874), (41, 0.018588943872600794), (22, 0.019067521207034588), (39, 0.019302496453747153), (48, 0.020728602772578597), (11, 0.021229500882327557), (14, 0.022726128110662103), (49, 0.02292733546346426), (17, 0.02356058545410633), (38, 0.02362319454550743), (50, 0.025466856779530644), (37, 0.025660474551841617), (51, 0.03188293636776507), (15, 0.037934978492558), (12, 0.04165834467858076), (0, 0.045861792750656605), (8, 0.04887042660266161), (4, 0.05213462980464101), (5, 0.052416717167943716), (7, 0.05547522380948067), (2, 0.06098463758826256), (52, 0.061193055007606745), (3, 0.06243071611970663), (16, 0.06422330439090729), (6, 0.06518651824444532), (1, 0.1571871843189001), (36, 0.3131869360804558), (18, 0.3658623993396759), (53, 0.9862026497721672)]
computing accuracy for after removing block 43 . block score: 0.016015663743019104
removed block 43 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.05120000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.016531. All blocks and scores: [(40, 0.016530798748135567), (23, 0.01660744659602642), (45, 0.016902157803997397), (30, 0.017178396228700876), (19, 0.017349787754938006), (24, 0.017503201263025403), (33, 0.01765732653439045), (13, 0.018235396593809128), (46, 0.01833605021238327), (42, 0.01836430188268423), (44, 0.01850736979395151), (41, 0.018588944571092725), (22, 0.01906752143986523), (39, 0.01930249622091651), (11, 0.021229501347988844), (48, 0.02151346835307777), (14, 0.022726127645000815), (49, 0.0232954490929842), (17, 0.02356058545410633), (38, 0.02362319454550743), (37, 0.025660474551841617), (50, 0.02630060026422143), (51, 0.03238261886872351), (15, 0.03793497942388058), (12, 0.041658344212919474), (0, 0.04586179228499532), (8, 0.04887042520567775), (4, 0.05213462980464101), (5, 0.052416717633605), (7, 0.05547522334381938), (2, 0.060984638053923845), (52, 0.06122089270502329), (3, 0.062430718913674355), (16, 0.06422330439090729), (6, 0.06518651731312275), (1, 0.1571871805936098), (36, 0.3131869360804558), (18, 0.3658623956143856), (53, 1.047251045703888)]
computing accuracy for after removing block 40 . block score: 0.016530798748135567
removed block 40 current accuracy 0.9298 loss from initial  0.07020000000000004
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.016446. All blocks and scores: [(45, 0.016445676097646356), (23, 0.016607446363195777), (30, 0.01717839646153152), (19, 0.01734978798776865), (24, 0.01750320103019476), (33, 0.017657326068729162), (46, 0.018193190451711416), (13, 0.01823539612814784), (44, 0.01839232468046248), (42, 0.019028427777811885), (22, 0.019067521207034588), (39, 0.01930249622091651), (41, 0.019459924660623074), (48, 0.021121519850566983), (11, 0.021229501580819488), (49, 0.022725160466507077), (14, 0.022726127645000815), (17, 0.02356058545410633), (38, 0.02362319501116872), (50, 0.02518891333602369), (37, 0.025660475250333548), (51, 0.03114904905669391), (15, 0.037934978492558), (12, 0.0416583432815969), (0, 0.045861792750656605), (8, 0.048870425671339035), (4, 0.05213463073596358), (5, 0.05241671623662114), (7, 0.05547522287815809), (52, 0.057828040327876806), (2, 0.06098463525995612), (3, 0.062430718913674355), (16, 0.06422330252826214), (6, 0.0651865191757679), (1, 0.1571871843189001), (36, 0.3131869360804558), (18, 0.3658624030649662), (53, 1.070447251200676)]
computing accuracy for after removing block 45 . block score: 0.016445676097646356
removed block 45 current accuracy 0.9122 loss from initial  0.08779999999999999
since last training loss: 0.08379999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.016607. All blocks and scores: [(23, 0.01660744659602642), (30, 0.017178396228700876), (19, 0.017349788453429937), (24, 0.017503200564533472), (33, 0.01765732583589852), (13, 0.01823539612814784), (44, 0.018392324913293123), (46, 0.018523868871852756), (42, 0.019028428243473172), (22, 0.0190675207413733), (39, 0.01930249622091651), (41, 0.01945992512628436), (11, 0.021229500882327557), (48, 0.021385454339906573), (14, 0.022726127645000815), (49, 0.02349673886783421), (17, 0.023560585221275687), (38, 0.02362319454550743), (37, 0.02566047478467226), (50, 0.02585514564998448), (51, 0.03073749248869717), (15, 0.03793498082086444), (12, 0.041658344212919474), (0, 0.045861792750656605), (8, 0.04887042474001646), (4, 0.052134628407657146), (5, 0.052416717633605), (7, 0.05547522474080324), (52, 0.056449937634170055), (2, 0.060984639916568995), (3, 0.06243071798235178), (16, 0.06422330252826214), (6, 0.06518651638180017), (1, 0.1571871768683195), (36, 0.3131869360804558), (18, 0.3658624067902565), (53, 1.1521297693252563)]
computing accuracy for after removing block 23 . block score: 0.01660744659602642
removed block 23 current accuracy 0.8804 loss from initial  0.11960000000000004
training start
training epoch 0 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best False lr [0.1]
training epoch 1 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 2 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 3 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 4 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 5 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 6 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 7 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 9 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.964400)
finished training. finished 50 epochs. accuracy 0.9644 topk_dict {'top1': 0.9644}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.035704. All blocks and scores: [(19, 0.03570432402193546), (42, 0.04151950869709253), (46, 0.042587774340063334), (44, 0.043354952707886696), (39, 0.0434300503693521), (49, 0.04708958603441715), (50, 0.047442748211324215), (41, 0.04820163827389479), (38, 0.048777295742183924), (48, 0.049651439767330885), (51, 0.049992256332188845), (33, 0.05390279460698366), (37, 0.055567838717252016), (22, 0.0564271486364305), (14, 0.05821241298690438), (17, 0.05834945058450103), (13, 0.06223413674160838), (11, 0.0640855198726058), (30, 0.06641960330307484), (24, 0.06740108504891396), (52, 0.08153021987527609), (15, 0.08526969142258167), (0, 0.10849498677998781), (8, 0.11624127067625523), (4, 0.11859053187072277), (12, 0.11897171102464199), (5, 0.11993300262838602), (7, 0.12781797721982002), (6, 0.1346443071961403), (2, 0.13832827098667622), (16, 0.14786749333143234), (3, 0.1534811519086361), (1, 0.3269793838262558), (18, 0.5976619049906731), (36, 0.6303274109959602), (53, 1.0706505626440048)]
computing accuracy for after removing block 19 . block score: 0.03570432402193546
removed block 19 current accuracy 0.96 loss from initial  0.040000000000000036
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 42, with score 0.040738. All blocks and scores: [(42, 0.040738311130553484), (44, 0.04228636110201478), (46, 0.04249304439872503), (39, 0.04362861532717943), (50, 0.04632688080891967), (49, 0.046394776087254286), (48, 0.047378957737237215), (51, 0.04756056284531951), (41, 0.04775545373558998), (38, 0.05061908485367894), (33, 0.05146255111321807), (22, 0.05480139749124646), (37, 0.05613476177677512), (14, 0.05821241205558181), (17, 0.058349451050162315), (13, 0.06223413906991482), (30, 0.0631294990889728), (11, 0.06408552173525095), (24, 0.06712447479367256), (52, 0.07989097479730844), (15, 0.08526969328522682), (0, 0.10849498305469751), (8, 0.11624127253890038), (4, 0.11859053280204535), (12, 0.11897171195596457), (5, 0.11993300076574087), (7, 0.12781797535717487), (6, 0.1346443071961403), (2, 0.13832827098667622), (16, 0.1478674989193678), (3, 0.15348115004599094), (1, 0.3269793912768364), (18, 0.5976619049906731), (36, 0.627631276845932), (53, 1.0616866946220398)]
computing accuracy for after removing block 42 . block score: 0.040738311130553484
removed block 42 current accuracy 0.9536 loss from initial  0.0464
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.043629. All blocks and scores: [(39, 0.04362861579284072), (46, 0.04512072913348675), (44, 0.04647129029035568), (41, 0.04775545420125127), (50, 0.04872380802407861), (49, 0.0488706873729825), (51, 0.048893583938479424), (48, 0.04964191559702158), (38, 0.05061908485367894), (33, 0.051462552044540644), (22, 0.054801397025585175), (37, 0.056134761311113834), (14, 0.058212412521243095), (17, 0.058349451050162315), (13, 0.06223413906991482), (30, 0.06312950188294053), (11, 0.0640855198726058), (24, 0.06712447199970484), (52, 0.08232763409614563), (15, 0.0852696942165494), (0, 0.10849498305469751), (8, 0.1162412678822875), (4, 0.11859053373336792), (12, 0.11897171381860971), (5, 0.11993300169706345), (7, 0.12781797908246517), (6, 0.1346443071961403), (2, 0.13832827471196651), (16, 0.14786749705672264), (3, 0.1534811481833458), (1, 0.3269793838262558), (18, 0.5976619124412537), (36, 0.627631276845932), (53, 1.1206178814172745)]
computing accuracy for after removing block 39 . block score: 0.04362861579284072
removed block 39 current accuracy 0.9474 loss from initial  0.05259999999999998
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 46, with score 0.045448. All blocks and scores: [(46, 0.04544809879735112), (50, 0.048547230660915375), (44, 0.04864695901051164), (51, 0.049068731255829334), (49, 0.04907944658771157), (48, 0.049587118439376354), (38, 0.05061908531934023), (33, 0.05146255064755678), (41, 0.051608439069241285), (22, 0.054801398422569036), (37, 0.05613476177677512), (14, 0.058212411124259233), (17, 0.05834945198148489), (13, 0.06223413906991482), (30, 0.06312950048595667), (11, 0.06408551894128323), (24, 0.06712447572499514), (52, 0.08146457094699144), (15, 0.0852696942165494), (0, 0.10849498305469751), (8, 0.11624127067625523), (4, 0.11859053373336792), (12, 0.11897171009331942), (5, 0.11993299797177315), (7, 0.12781797721982002), (6, 0.1346443071961403), (2, 0.13832827098667622), (16, 0.14786749333143234), (3, 0.15348115377128124), (1, 0.3269793801009655), (18, 0.5976619124412537), (36, 0.6276312917470932), (53, 1.122149646282196)]
computing accuracy for after removing block 46 . block score: 0.04544809879735112
removed block 46 current accuracy 0.9352 loss from initial  0.06479999999999997
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.048647. All blocks and scores: [(44, 0.04864695854485035), (38, 0.05061908392235637), (33, 0.051462551578879356), (41, 0.05160843441262841), (51, 0.0520493877120316), (49, 0.053183142095804214), (48, 0.05352698406204581), (50, 0.0541332820430398), (22, 0.05480139935389161), (37, 0.056134762708097696), (14, 0.05821241298690438), (17, 0.05834945244714618), (13, 0.062234137672930956), (30, 0.06312950327992439), (11, 0.06408552173525095), (24, 0.06712447665631771), (52, 0.08442391827702522), (15, 0.08526969328522682), (0, 0.10849498584866524), (8, 0.11624127347022295), (4, 0.1185905346646905), (12, 0.11897171381860971), (5, 0.11993300076574087), (7, 0.12781798094511032), (6, 0.1346443071961403), (2, 0.13832826912403107), (16, 0.1478674989193678), (3, 0.1534811519086361), (1, 0.3269793950021267), (18, 0.5976619273424149), (36, 0.6276312842965126), (53, 1.193825289607048)]
computing accuracy for after removing block 44 . block score: 0.04864695854485035
removed block 44 current accuracy 0.919 loss from initial  0.08099999999999996
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.050619. All blocks and scores: [(38, 0.050619084388017654), (33, 0.05146255111321807), (41, 0.051608435809612274), (51, 0.05309349671006203), (22, 0.05480139935389161), (50, 0.05603506742045283), (37, 0.056134761311113834), (49, 0.0570996068418026), (48, 0.0572552434168756), (14, 0.05821241205558181), (17, 0.05834945244714618), (13, 0.06223413674160838), (30, 0.06312950188294053), (11, 0.06408552080392838), (24, 0.06712447293102741), (52, 0.08525391481816769), (15, 0.0852696942165494), (0, 0.10849498491734266), (8, 0.1162412678822875), (4, 0.11859053187072277), (12, 0.11897171102464199), (5, 0.11993300169706345), (7, 0.12781797721982002), (6, 0.13464430533349514), (2, 0.13832827098667622), (16, 0.1478674951940775), (3, 0.1534811519086361), (1, 0.3269793801009655), (18, 0.5976619273424149), (36, 0.6276312917470932), (53, 1.2593012154102325)]
computing accuracy for after removing block 38 . block score: 0.050619084388017654
removed block 38 current accuracy 0.9038 loss from initial  0.09619999999999995
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 33, with score 0.051463. All blocks and scores: [(33, 0.05146255064755678), (51, 0.05301364930346608), (41, 0.05332106724381447), (22, 0.05480139935389161), (50, 0.05511038610711694), (48, 0.055975017603486776), (37, 0.05613476037979126), (49, 0.05725400010123849), (14, 0.05821241019293666), (17, 0.05834944965317845), (13, 0.06223413860425353), (30, 0.06312950002029538), (11, 0.06408552173525095), (24, 0.06712447293102741), (52, 0.0848282566294074), (15, 0.08526969514787197), (0, 0.10849498398602009), (8, 0.11624127067625523), (4, 0.11859053373336792), (12, 0.11897171009331942), (5, 0.11993299704045057), (7, 0.12781797721982002), (6, 0.1346443071961403), (2, 0.13832826726138592), (16, 0.1478674951940775), (3, 0.15348115004599094), (1, 0.3269793838262558), (18, 0.5976619124412537), (36, 0.6276312917470932), (53, 1.271953970193863)]
computing accuracy for after removing block 33 . block score: 0.05146255064755678
removed block 33 current accuracy 0.895 loss from initial  0.10499999999999998
since last training loss: 0.06940000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.052658. All blocks and scores: [(51, 0.052658171858638525), (41, 0.05349642364308238), (48, 0.05443898309022188), (50, 0.05459330463781953), (22, 0.05480139749124646), (49, 0.05569789884611964), (37, 0.05796281574293971), (14, 0.05821241158992052), (17, 0.05834945011883974), (13, 0.062234137672930956), (30, 0.06312950002029538), (11, 0.06408552080392838), (24, 0.06712447386234999), (52, 0.08331075962632895), (15, 0.08526969142258167), (0, 0.10849498305469751), (8, 0.11624126695096493), (4, 0.11859053559601307), (12, 0.11897171009331942), (5, 0.11993299797177315), (7, 0.12781798094511032), (6, 0.13464430533349514), (2, 0.13832826912403107), (16, 0.1478674914687872), (3, 0.1534811481833458), (1, 0.3269793875515461), (18, 0.5976618975400925), (36, 0.645802803337574), (53, 1.3045175671577454)]
computing accuracy for after removing block 51 . block score: 0.052658171858638525
removed block 51 current accuracy 0.8472 loss from initial  0.15280000000000005
since last training loss: 0.11720000000000008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.053496. All blocks and scores: [(41, 0.05349642410874367), (48, 0.05443898309022188), (50, 0.054593305103480816), (22, 0.054801397025585175), (49, 0.05569789884611964), (37, 0.057962814811617136), (14, 0.058212412521243095), (17, 0.05834944965317845), (13, 0.06223413813859224), (30, 0.06312950188294053), (11, 0.0640855198726058), (24, 0.06712447386234999), (15, 0.0852696942165494), (52, 0.09126360062509775), (0, 0.10849498305469751), (8, 0.11624126695096493), (4, 0.11859053373336792), (12, 0.11897171195596457), (5, 0.11993300169706345), (7, 0.12781797908246517), (6, 0.1346443071961403), (2, 0.13832827471196651), (16, 0.1478674951940775), (3, 0.1534811556339264), (1, 0.3269793912768364), (18, 0.5976619198918343), (36, 0.6458028107881546), (53, 1.627961814403534)]
computing accuracy for after removing block 41 . block score: 0.05349642410874367
removed block 41 current accuracy 0.8068 loss from initial  0.19320000000000004
training start
training epoch 0 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 1 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 2 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.1]
training epoch 3 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 6 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 9 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.950000)
finished training. finished 50 epochs. accuracy 0.95 topk_dict {'top1': 0.95}
start iteration 27
[activation diff]: block to remove picked: 17, with score 0.062433. All blocks and scores: [(17, 0.062433321960270405), (13, 0.06734192743897438), (50, 0.07087889593094587), (22, 0.0773950107395649), (49, 0.07768963184207678), (11, 0.07781871408224106), (48, 0.07809673994779587), (14, 0.08531155623495579), (52, 0.0891973003745079), (24, 0.09391903970390558), (30, 0.10551636759191751), (15, 0.10842363815754652), (37, 0.10912463534623384), (8, 0.1252985494211316), (0, 0.12538231909275055), (12, 0.13925300911068916), (4, 0.14345653168857098), (7, 0.14645977690815926), (2, 0.14904748648405075), (5, 0.1497261542826891), (16, 0.1574632115662098), (3, 0.1628943271934986), (6, 0.17640330269932747), (1, 0.37884582206606865), (36, 0.5762260109186172), (18, 0.602318175137043), (53, 1.1769384741783142)]
computing accuracy for after removing block 17 . block score: 0.062433321960270405
removed block 17 current accuracy 0.9458 loss from initial  0.054200000000000026
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 13, with score 0.067342. All blocks and scores: [(13, 0.06734192930161953), (50, 0.07016452308744192), (22, 0.0759566007182002), (11, 0.07781871408224106), (49, 0.07797112315893173), (48, 0.07829409837722778), (14, 0.08531155809760094), (52, 0.08928792830556631), (24, 0.09376552235335112), (30, 0.10232349578291178), (15, 0.10842364002019167), (37, 0.1088482541963458), (8, 0.12529854476451874), (0, 0.12538232374936342), (12, 0.1392530109733343), (4, 0.14345652982592583), (7, 0.14645977318286896), (2, 0.14904749020934105), (5, 0.1497261580079794), (16, 0.1574632115662098), (3, 0.16289433278143406), (6, 0.17640329711139202), (1, 0.37884582951664925), (36, 0.5717523172497749), (18, 0.6020079180598259), (53, 1.178385078907013)]
computing accuracy for after removing block 13 . block score: 0.06734192930161953
removed block 13 current accuracy 0.939 loss from initial  0.061000000000000054
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 50, with score 0.069252. All blocks and scores: [(50, 0.0692518912255764), (22, 0.07483762688934803), (49, 0.0771828182041645), (48, 0.07747352961450815), (11, 0.07781871128827333), (52, 0.08963942620903254), (14, 0.08973143249750137), (24, 0.09166257362812757), (30, 0.10012977942824364), (37, 0.10547894239425659), (15, 0.10657177120447159), (8, 0.12529854476451874), (0, 0.12538231909275055), (12, 0.1392530109733343), (4, 0.14345652982592583), (7, 0.14645978063344955), (2, 0.14904749020934105), (5, 0.1497261542826891), (3, 0.16289432905614376), (6, 0.17640330269932747), (16, 0.17932650074362755), (1, 0.37884582206606865), (36, 0.5631172433495522), (18, 0.6016827449202538), (53, 1.1614174842834473)]
computing accuracy for after removing block 50 . block score: 0.0692518912255764
removed block 50 current accuracy 0.912 loss from initial  0.08799999999999997
since last training loss: 0.03799999999999992 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 22, with score 0.074838. All blocks and scores: [(22, 0.07483762595802546), (49, 0.07718281727284193), (48, 0.07747352961450815), (11, 0.07781871128827333), (14, 0.08973143249750137), (24, 0.09166257735341787), (52, 0.09867628011852503), (30, 0.10012977942824364), (37, 0.10547894425690174), (15, 0.10657177027314901), (8, 0.12529854848980904), (0, 0.12538232281804085), (12, 0.13925301283597946), (4, 0.14345652982592583), (7, 0.1464597787708044), (2, 0.14904749020934105), (5, 0.14972615242004395), (3, 0.1628943234682083), (6, 0.17640330083668232), (16, 0.1793265026062727), (1, 0.37884582951664925), (36, 0.5631172060966492), (18, 0.6016827374696732), (53, 1.2883514016866684)]
computing accuracy for after removing block 22 . block score: 0.07483762595802546
removed block 22 current accuracy 0.8848 loss from initial  0.11519999999999997
since last training loss: 0.06519999999999992 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 49, with score 0.074873. All blocks and scores: [(49, 0.07487298082560301), (48, 0.07729782909154892), (11, 0.07781871221959591), (24, 0.0885610980913043), (14, 0.08973142877221107), (30, 0.0952901067212224), (52, 0.09641137439757586), (15, 0.10657177120447159), (37, 0.11706073023378849), (8, 0.12529854848980904), (0, 0.12538232188671827), (12, 0.13925301283597946), (4, 0.14345653168857098), (7, 0.14645978063344955), (2, 0.1490474846214056), (5, 0.14972615614533424), (3, 0.16289433278143406), (6, 0.17640330269932747), (16, 0.17932649701833725), (1, 0.37884582206606865), (36, 0.5789275169372559), (18, 0.6016827374696732), (53, 1.2800271660089493)]
computing accuracy for after removing block 49 . block score: 0.07487298082560301
removed block 49 current accuracy 0.8304 loss from initial  0.16959999999999997
since last training loss: 0.11959999999999993 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 48, with score 0.077298. All blocks and scores: [(48, 0.07729783095419407), (11, 0.07781871408224106), (24, 0.08856109529733658), (14, 0.08973142877221107), (30, 0.09529010578989983), (52, 0.10539540369063616), (15, 0.10657177027314901), (37, 0.11706073023378849), (8, 0.12529854848980904), (0, 0.12538231909275055), (12, 0.13925300538539886), (4, 0.14345652796328068), (7, 0.1464597787708044), (2, 0.1490474883466959), (5, 0.14972615242004395), (3, 0.16289432533085346), (6, 0.17640329897403717), (16, 0.17932650074362755), (1, 0.37884582951664925), (36, 0.578927531838417), (18, 0.6016827374696732), (53, 1.5397128909826279)]
computing accuracy for after removing block 48 . block score: 0.07729783095419407
removed block 48 current accuracy 0.7404 loss from initial  0.25960000000000005
since last training loss: 0.2096 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 11, with score 0.077819. All blocks and scores: [(11, 0.07781871501356363), (24, 0.08856109622865915), (14, 0.08973143063485622), (30, 0.09529010485857725), (15, 0.10657177306711674), (52, 0.11426794808357954), (37, 0.11706072743982077), (8, 0.1252985494211316), (0, 0.1253823209553957), (12, 0.13925300724804401), (4, 0.14345652610063553), (7, 0.14645977690815926), (2, 0.14904749020934105), (5, 0.1497261580079794), (3, 0.1628943309187889), (6, 0.17640330269932747), (16, 0.1793264951556921), (1, 0.37884583324193954), (36, 0.5789275094866753), (18, 0.6016827374696732), (53, 1.6702736467123032)]
computing accuracy for after removing block 11 . block score: 0.07781871501356363
removed block 11 current accuracy 0.6982 loss from initial  0.30179999999999996
since last training loss: 0.2517999999999999 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 24, with score 0.087004. All blocks and scores: [(24, 0.08700440544635057), (30, 0.09009681735187769), (14, 0.1046878956258297), (15, 0.11176728270947933), (37, 0.11307742353528738), (52, 0.1132841045036912), (8, 0.1252985466271639), (0, 0.12538232281804085), (4, 0.14345652423799038), (7, 0.1464597750455141), (12, 0.14853383414447308), (2, 0.1490474883466959), (5, 0.14972615987062454), (3, 0.16289432533085346), (6, 0.17640329711139202), (16, 0.178662134334445), (1, 0.37884584069252014), (36, 0.5668132826685905), (18, 0.589308999478817), (53, 1.678393542766571)]
computing accuracy for after removing block 24 . block score: 0.08700440544635057
removed block 24 current accuracy 0.5476 loss from initial  0.4524
since last training loss: 0.4024 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 30, with score 0.095735. All blocks and scores: [(30, 0.09573523513972759), (14, 0.10468789376318455), (15, 0.11176728270947933), (52, 0.1164963273331523), (37, 0.12474935874342918), (8, 0.1252985494211316), (0, 0.1253823172301054), (4, 0.14345652423799038), (7, 0.1464597787708044), (12, 0.14853383228182793), (2, 0.14904748648405075), (5, 0.1497261542826891), (3, 0.16289432533085346), (6, 0.17640330456197262), (16, 0.17866214364767075), (1, 0.37884581834077835), (18, 0.5893090069293976), (36, 0.6086833626031876), (53, 1.8191419392824173)]
computing accuracy for after removing block 30 . block score: 0.09573523513972759
removed block 30 current accuracy 0.3796 loss from initial  0.6204000000000001
since last training loss: 0.5704 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 14, with score 0.104688. All blocks and scores: [(14, 0.10468789748847485), (15, 0.11176727991551161), (52, 0.12527102418243885), (8, 0.12529854755848646), (0, 0.12538232002407312), (4, 0.14345652423799038), (7, 0.14645977690815926), (37, 0.1471011284738779), (12, 0.14853383414447308), (2, 0.1490474846214056), (5, 0.14972615614533424), (3, 0.16289432905614376), (6, 0.17640330456197262), (16, 0.1786621380597353), (1, 0.37884582579135895), (18, 0.5893089920282364), (36, 0.6917411759495735), (53, 1.9588551223278046)]
computing accuracy for after removing block 14 . block score: 0.10468789748847485
removed block 14 current accuracy 0.35 loss from initial  0.65
since last training loss: 0.6 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 52, with score 0.124137. All blocks and scores: [(52, 0.12413690984249115), (8, 0.12529854755848646), (0, 0.125382324680686), (15, 0.13318910636007786), (4, 0.14345652796328068), (7, 0.14645977318286896), (12, 0.14853383600711823), (37, 0.14867634139955044), (2, 0.1490474920719862), (5, 0.14972615614533424), (3, 0.16289432905614376), (6, 0.17640330642461777), (16, 0.20430086366832256), (1, 0.37884582579135895), (18, 0.5779034346342087), (36, 0.6916597932577133), (53, 2.0028277337551117)]
computing accuracy for after removing block 52 . block score: 0.12413690984249115
removed block 52 current accuracy 0.2208 loss from initial  0.7792
since last training loss: 0.7292 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 8, with score 0.125299. All blocks and scores: [(8, 0.12529854383319616), (0, 0.125382324680686), (15, 0.133189108222723), (4, 0.14345652982592583), (7, 0.1464597750455141), (12, 0.14853383786976337), (37, 0.1486763432621956), (2, 0.14904748648405075), (5, 0.1497261542826891), (3, 0.16289432533085346), (6, 0.17640330269932747), (16, 0.20430086180567741), (1, 0.37884581461548805), (18, 0.5779034569859505), (36, 0.6916598081588745), (53, 2.3978779017925262)]
computing accuracy for after removing block 8 . block score: 0.12529854383319616
removed block 8 current accuracy 0.198 loss from initial  0.802
training start
training epoch 0 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best True lr [0.1]
training epoch 1 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.1]
training epoch 2 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best False lr [0.1]
training epoch 3 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 4 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 5 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 6 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.1]
training epoch 7 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 8 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 9 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.923600)
finished training. finished 50 epochs. accuracy 0.9236 topk_dict {'top1': 0.9236}
