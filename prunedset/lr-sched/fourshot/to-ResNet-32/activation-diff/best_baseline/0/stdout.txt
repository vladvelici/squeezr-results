start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996264383197), (32, 0.009233050630427897), (30, 0.010039400309324265), (31, 0.010361600085161626), (34, 0.013312276219949126), (29, 0.013541154796257615), (35, 0.016018462600186467), (26, 0.01603759080171585), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020232456969097257), (46, 0.02104453952051699), (25, 0.02197260200046003), (23, 0.02237953571602702), (41, 0.0228266476187855), (44, 0.023395078722387552), (40, 0.024025025311857462), (45, 0.02429541083984077), (21, 0.024924597702920437), (22, 0.025168767431750894), (48, 0.025341259315609932), (24, 0.02589953737333417), (50, 0.026409972924739122), (42, 0.02667409973219037), (20, 0.026859007542952895), (49, 0.027037164429202676), (47, 0.029306469717994332), (39, 0.031570713268592954), (38, 0.03163787070661783), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.032628594897687435), (37, 0.037960261572152376), (51, 0.04173417296260595), (9, 0.04340187879279256), (6, 0.046609030570834875), (4, 0.04749368457123637), (14, 0.04783663526177406), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.05924912681803107), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (52, 0.06862937565892935), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.43758000433444977), (18, 0.5108213201165199), (53, 0.8211489096283913)]
computing accuracy for after removing block 33 . block score: 0.007061996264383197
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.010361599852330983), (34, 0.013133947271853685), (29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.01616928866133094), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020072476472705603), (46, 0.020731384633108974), (25, 0.021972603164613247), (41, 0.02234709309414029), (23, 0.022379535250365734), (44, 0.023235687986016273), (40, 0.023841066984459758), (45, 0.02396554220467806), (48, 0.024917916394770145), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.025840813061222434), (24, 0.025899537140503526), (42, 0.026315323309972882), (49, 0.026655675377696753), (20, 0.02685900731012225), (47, 0.028728798031806946), (39, 0.03131764265708625), (38, 0.031380362808704376), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.038025844376534224), (51, 0.041223939042538404), (9, 0.04340188018977642), (6, 0.04660903010517359), (4, 0.047493684105575085), (14, 0.047836634796112776), (2, 0.05454846564680338), (3, 0.05722427740693092), (13, 0.058922902680933475), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (52, 0.06745154969394207), (8, 0.0746783260256052), (10, 0.0803448436781764), (16, 0.08408282604068518), (12, 0.09042049571871758), (5, 0.10667386930435896), (36, 0.43538709357380867), (18, 0.5108212977647781), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361600085161626), (34, 0.012765232706442475), (29, 0.013541154330596328), (35, 0.01599275111220777), (26, 0.01603759010322392), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020075131906196475), (46, 0.020841406425461173), (25, 0.021972603164613247), (41, 0.022319766925647855), (23, 0.02237953571602702), (44, 0.023154050344601274), (40, 0.02388568501919508), (45, 0.024071689695119858), (48, 0.024877465097233653), (21, 0.02492459863424301), (22, 0.025168767664581537), (50, 0.02569117909297347), (24, 0.025899537140503526), (42, 0.026123748160898685), (49, 0.026479422114789486), (20, 0.026859006844460964), (47, 0.028693131636828184), (38, 0.031236795708537102), (39, 0.03129529138095677), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.03837668988853693), (51, 0.04111403413116932), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.059249130077660084), (17, 0.06095684925094247), (0, 0.0630098064430058), (1, 0.06676734145730734), (52, 0.06700456328690052), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.43640001118183136), (18, 0.5108212903141975), (53, 0.8289348855614662)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371784903109), (34, 0.012387837283313274), (29, 0.013541154330596328), (35, 0.016008096281439066), (26, 0.016037590336054564), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.02008363325148821), (46, 0.02070444426499307), (25, 0.02197260269895196), (41, 0.022253197384998202), (23, 0.022379535483196378), (44, 0.02326776133850217), (40, 0.024013880640268326), (45, 0.024092993000522256), (48, 0.02466528071090579), (21, 0.024924597702920437), (22, 0.02516876976005733), (50, 0.02545973425731063), (42, 0.025655713165178895), (24, 0.02589953737333417), (49, 0.02628775709308684), (20, 0.026859006844460964), (47, 0.028363423887640238), (38, 0.031047647818922997), (39, 0.03138077235780656), (15, 0.03192339139059186), (7, 0.0322854476980865), (19, 0.03262859582901001), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.05454846424981952), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095684878528118), (0, 0.06300980830565095), (52, 0.0658631632104516), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4389924630522728), (18, 0.5108212903141975), (53, 0.8391561433672905)]
computing accuracy for after removing block 31 . block score: 0.010375371784903109
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619897678494), (29, 0.013541155029088259), (26, 0.01603759010322392), (35, 0.01605736301280558), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.020049349637702107), (46, 0.020552986999973655), (25, 0.02197260269895196), (41, 0.022067484678700566), (23, 0.022379535948857665), (44, 0.022979132365435362), (40, 0.023858347442001104), (45, 0.02412470243871212), (48, 0.024386123288422823), (21, 0.024924597702920437), (50, 0.025042241672053933), (22, 0.0251687690615654), (42, 0.025414508767426014), (49, 0.025842698523774743), (24, 0.025899536442011595), (20, 0.026859006844460964), (47, 0.028050734661519527), (38, 0.031040058936923742), (39, 0.031500803772360086), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (37, 0.03911284822970629), (51, 0.040246272925287485), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095685111358762), (0, 0.06300980970263481), (52, 0.06486208736896515), (1, 0.06676734425127506), (8, 0.0746783260256052), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.10667387302964926), (36, 0.438127838075161), (18, 0.5108213126659393), (53, 0.845842756330967)]
computing accuracy for after removing block 34 . block score: 0.012489619897678494
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.01665342040359974), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020503456005826592), (46, 0.0207253226544708), (25, 0.021972602931782603), (23, 0.022379535250365734), (41, 0.022452629171311855), (44, 0.023364473832771182), (48, 0.024290355388075113), (45, 0.024438712978735566), (40, 0.024470558390021324), (21, 0.024924597702920437), (50, 0.02504217205569148), (22, 0.025168767664581537), (49, 0.025875970721244812), (24, 0.0258995380718261), (42, 0.02620540768839419), (20, 0.02685900731012225), (47, 0.028178582666441798), (15, 0.031923390459269285), (38, 0.03208350110799074), (7, 0.03228544630110264), (39, 0.0323374392464757), (19, 0.0326285962946713), (51, 0.03994725923985243), (37, 0.040739682503044605), (9, 0.04340187972411513), (6, 0.04660903010517359), (4, 0.04749368317425251), (14, 0.047836634796112776), (2, 0.054548466112464666), (3, 0.05722427926957607), (13, 0.0589229017496109), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.0630098101682961), (52, 0.06433630408719182), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034483902156353), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.45053430274128914), (18, 0.5108212977647781), (53, 0.8443200439214706)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.01603759080171585), (35, 0.0164706080686301), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020046867430210114), (46, 0.02037699380889535), (41, 0.02172324270941317), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.023028337163850665), (48, 0.023771876702085137), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.024390299106016755), (21, 0.02492459793575108), (22, 0.025168768130242825), (42, 0.025188251165673137), (49, 0.025361528154462576), (24, 0.025899537838995457), (20, 0.02685900661163032), (47, 0.027363279834389687), (38, 0.031365619506686926), (15, 0.031923392321914434), (39, 0.03212768537923694), (7, 0.03228544583544135), (19, 0.03262859582901001), (51, 0.03893592394888401), (37, 0.04020634340122342), (9, 0.04340188018977642), (6, 0.04660903289914131), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846424981952), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095685064792633), (52, 0.06232855003327131), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386837303638), (36, 0.4444201961159706), (18, 0.5108212977647781), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.01603759080171585
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597366262227297), (28, 0.017088500317186117), (27, 0.018882446689531207), (43, 0.01959516596980393), (46, 0.02007358125410974), (41, 0.02096158522181213), (25, 0.02197260269895196), (23, 0.022379535483196378), (44, 0.02281495602801442), (48, 0.02312816074118018), (40, 0.02334519545547664), (50, 0.023756146663799882), (42, 0.02384730288758874), (45, 0.02387388003990054), (21, 0.02492459723725915), (49, 0.024960316019132733), (22, 0.025168767664581537), (24, 0.025899538304656744), (47, 0.026855542324483395), (20, 0.02685900777578354), (38, 0.030424013966694474), (39, 0.03151404391974211), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03782488126307726), (37, 0.039368351455777884), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.047493682242929935), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.059249129611998796), (52, 0.06033282168209553), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4360685497522354), (18, 0.5108213052153587), (53, 0.8749377354979515)]
computing accuracy for after removing block 35 . block score: 0.015597366262227297
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.01855594594962895), (27, 0.018882447388023138), (46, 0.019160085124894977), (41, 0.019424295518547297), (48, 0.021467271959409118), (25, 0.021972602466121316), (44, 0.02202691650018096), (40, 0.02217966062016785), (42, 0.02220643009059131), (50, 0.022256128955632448), (23, 0.022379535250365734), (45, 0.022931481944397092), (49, 0.02370851207524538), (21, 0.024924597470089793), (22, 0.025168768130242825), (47, 0.025829140096902847), (24, 0.025899537140503526), (20, 0.02685900661163032), (38, 0.02895654644817114), (39, 0.02966782753355801), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03600902669131756), (37, 0.03651238698512316), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548466112464666), (52, 0.056107287760823965), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467831950634718), (10, 0.08034484274685383), (16, 0.08408282604068518), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.41757645085453987), (18, 0.5108213126659393), (53, 0.9117145016789436)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
training start
training epoch 0 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 1 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 2 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 3 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 4 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 5 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 6 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 7 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.1]
training epoch 8 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 9 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.1]
training epoch 10 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302505344152), (46, 0.018656102241948247), (41, 0.01884901849552989), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.021432003937661648), (40, 0.021832421654835343), (44, 0.02184053068049252), (50, 0.021869863849133253), (25, 0.021972602233290672), (23, 0.02237953501753509), (45, 0.022492847638204694), (49, 0.023123498540371656), (21, 0.024924597702920437), (47, 0.025067139184102416), (22, 0.025168768130242825), (24, 0.025899537606164813), (20, 0.026859006844460964), (38, 0.02811406971886754), (39, 0.0292069090064615), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03545433608815074), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.05454846704378724), (52, 0.05469645746052265), (3, 0.05722427973523736), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 0.9246632754802704)]
computing accuracy for after removing block 43 . block score: 0.018140302505344152
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882446689531207), (46, 0.019302030093967915), (42, 0.021432003937661648), (48, 0.02154484367929399), (40, 0.0218324214220047), (50, 0.021946269320324063), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.02300686901435256), (44, 0.023108510300517082), (45, 0.0235356071498245), (21, 0.024924597470089793), (22, 0.02516876789741218), (47, 0.025820445735007524), (24, 0.02589953667484224), (20, 0.026859007542952895), (38, 0.02811406971886754), (39, 0.029206908773630857), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.03509148769080639), (37, 0.03597763925790787), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.05332903051748872), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980737432837), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4135979190468788), (18, 0.5108212977647781), (53, 0.9678284078836441)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882447388023138), (46, 0.01907008863054216), (48, 0.020678168162703514), (50, 0.02134439698420465), (40, 0.021832420956343412), (25, 0.021972602931782603), (42, 0.021986939711496234), (23, 0.02237953571602702), (49, 0.02253474877215922), (45, 0.023929917719215155), (44, 0.024054003646597266), (21, 0.024924597702920437), (22, 0.025168768828734756), (24, 0.025899537140503526), (47, 0.026043937308713794), (20, 0.026859007542952895), (38, 0.028114068787544966), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.033794480841606855), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493682242929935), (14, 0.0478366338647902), (52, 0.05047609517350793), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387209832668), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 1.027817964553833)]
computing accuracy for after removing block 27 . block score: 0.018882447388023138
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.019989707740023732), (50, 0.020775062032043934), (40, 0.021085953572764993), (42, 0.021369647467508912), (49, 0.021910030161961913), (25, 0.021972603164613247), (23, 0.02237953571602702), (44, 0.023239312693476677), (45, 0.02358530950732529), (21, 0.024924597470089793), (47, 0.02507694740779698), (22, 0.025168768828734756), (24, 0.025899537838995457), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.0328142608050257), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.047836634796112776), (52, 0.04852362908422947), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922902680933475), (11, 0.05924912868067622), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.406523410230875), (18, 0.5108213052153587), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327561534941196), (50, 0.020831162109971046), (40, 0.021085953107103705), (42, 0.021369648166000843), (25, 0.021972603164613247), (23, 0.022379535250365734), (49, 0.02253698999993503), (44, 0.023239311296492815), (45, 0.023585309041664004), (21, 0.02492459723725915), (22, 0.025168767664581537), (24, 0.02589953737333417), (47, 0.026583050144836307), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339278757572), (7, 0.032285445369780064), (19, 0.03262859582901001), (51, 0.03285081218928099), (37, 0.035420244093984365), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663246780634), (52, 0.04812479671090841), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.05892289895564318), (11, 0.05924912542104721), (17, 0.06095685064792633), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.4065234065055847), (18, 0.5108212903141975), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.020327561534941196
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085952874273062), (42, 0.0213696479331702), (25, 0.021972602466121316), (23, 0.02237953571602702), (50, 0.022470063529908657), (44, 0.023239311994984746), (45, 0.02358530880883336), (21, 0.024924597702920437), (22, 0.0251687690615654), (49, 0.02523410227149725), (24, 0.02589953667484224), (47, 0.02658304898068309), (20, 0.026859007542952895), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339278757572), (7, 0.03228544583544135), (19, 0.03262859722599387), (51, 0.03296921122819185), (37, 0.03542024316266179), (9, 0.04340188158676028), (6, 0.046609032433480024), (4, 0.04749368550255895), (14, 0.04783663246780634), (52, 0.05089045129716396), (2, 0.05454846518114209), (3, 0.05722428113222122), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300981063395739), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387582361698), (36, 0.4065233916044235), (18, 0.5108213201165199), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085952874273062
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868073567748), (50, 0.021284765796735883), (25, 0.021972602931782603), (23, 0.022379535483196378), (45, 0.023098317673429847), (44, 0.024240857223048806), (49, 0.024500868981704116), (21, 0.024924597702920437), (22, 0.025168768828734756), (24, 0.025899536442011595), (47, 0.026519698556512594), (20, 0.02685900661163032), (38, 0.02718336065299809), (39, 0.028580758720636368), (15, 0.03192339185625315), (51, 0.03222084976732731), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03542024316266179), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836634796112776), (52, 0.04885757341980934), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.058922900818288326), (11, 0.059249130077660084), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667386651039124), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.3718615621328354)]
computing accuracy for after removing block 42 . block score: 0.02096868073567748
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.021202658070251346), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.02376196626573801), (49, 0.02460233890451491), (44, 0.024712182115763426), (21, 0.024924597470089793), (22, 0.02516876789741218), (24, 0.0258995380718261), (47, 0.026220474625006318), (20, 0.026859006844460964), (38, 0.027183360885828733), (39, 0.028580758720636368), (51, 0.03127906774170697), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.04340188018977642), (52, 0.046101709362119436), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.04783663293346763), (2, 0.05454846518114209), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448399528861), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.4178233742713928)]
computing accuracy for after removing block 50 . block score: 0.021202658070251346
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.022379535483196378), (45, 0.02376196696422994), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598168581724), (22, 0.025168768363073468), (24, 0.025899537140503526), (47, 0.026220475090667605), (20, 0.026859007077291608), (38, 0.027183360187336802), (39, 0.028580758487805724), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03344302112236619), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.052651793230324984), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.058922901283949614), (11, 0.059249130077660084), (17, 0.06095685111358762), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108213201165199), (53, 1.6287681311368942)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.789 topk_dict {'top1': 0.789} is_best False lr [0.1]
training epoch 1 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 2 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 3 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 4 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 5 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.1]
training epoch 6 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 7 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 8 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 9 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 10 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.962 topk_dict {'top1': 0.962} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9622 topk_dict {'top1': 0.9622} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.965400)
finished training. finished 50 epochs. accuracy 0.9654 topk_dict {'top1': 0.9654}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.044971. All blocks and scores: [(49, 0.04497103113681078), (45, 0.04861539835110307), (44, 0.04908331669867039), (21, 0.05149448523297906), (23, 0.05324602406471968), (7, 0.05442804843187332), (19, 0.05485838558524847), (22, 0.056098447646945715), (20, 0.05623572180047631), (51, 0.057422447483986616), (47, 0.05802766978740692), (38, 0.058286996092647314), (24, 0.061136435717344284), (39, 0.06549300625920296), (15, 0.06560815591365099), (37, 0.06907709408551455), (52, 0.07038871105760336), (4, 0.07296435069292784), (9, 0.07781528402119875), (6, 0.08175343181937933), (2, 0.08560283295810223), (14, 0.09048472996801138), (11, 0.09633495286107063), (17, 0.10145785566419363), (3, 0.10161276534199715), (0, 0.10349199641495943), (13, 0.11351336911320686), (1, 0.1177874207496643), (8, 0.13163519278168678), (10, 0.14194054529070854), (12, 0.14390356838703156), (16, 0.15209484845399857), (5, 0.201439144089818), (36, 0.6199103817343712), (18, 0.6792039051651955), (53, 0.9996111392974854)]
computing accuracy for after removing block 49 . block score: 0.04497103113681078
removed block 49 current accuracy 0.9554 loss from initial  0.04459999999999997
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.048615. All blocks and scores: [(45, 0.048615398816764355), (44, 0.0490833162330091), (21, 0.05149448476731777), (23, 0.053246024530380964), (7, 0.05442805262282491), (19, 0.05485838884487748), (22, 0.056098445784300566), (20, 0.0562357222661376), (47, 0.05802766792476177), (38, 0.058286997489631176), (24, 0.06113643432036042), (51, 0.06251061335206032), (39, 0.06549300625920296), (15, 0.06560815591365099), (37, 0.06907709687948227), (4, 0.07296434976160526), (52, 0.07521024160087109), (9, 0.0778152821585536), (6, 0.08175343088805676), (2, 0.08560283295810223), (14, 0.09048472717404366), (11, 0.09633495192974806), (17, 0.10145785380154848), (3, 0.101612763479352), (0, 0.10349199827760458), (13, 0.11351337376981974), (1, 0.11778741795569658), (8, 0.13163519278168678), (10, 0.14194054529070854), (12, 0.14390357211232185), (16, 0.15209484286606312), (5, 0.2014391403645277), (36, 0.6199103817343712), (18, 0.6792038977146149), (53, 1.0861721187829971)]
computing accuracy for after removing block 45 . block score: 0.048615398816764355
removed block 45 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.049083. All blocks and scores: [(44, 0.0490833162330091), (21, 0.051494485698640347), (23, 0.0532460231333971), (7, 0.05442805076017976), (19, 0.05485838931053877), (22, 0.05609844904392958), (20, 0.056235721334815025), (38, 0.058286994230002165), (24, 0.061136435251683), (51, 0.06424239370971918), (39, 0.06549300719052553), (47, 0.06550903152674437), (15, 0.06560815684497356), (37, 0.0690770959481597), (4, 0.07296434883028269), (9, 0.0778152858838439), (52, 0.07865310646593571), (6, 0.0817534327507019), (2, 0.0856028338894248), (14, 0.09048472996801138), (11, 0.09633495286107063), (17, 0.1014578528702259), (3, 0.10161276906728745), (0, 0.10349199827760458), (13, 0.11351337190717459), (1, 0.11778742168098688), (8, 0.13163519278168678), (10, 0.14194054156541824), (12, 0.1439035665243864), (16, 0.15209484286606312), (5, 0.20143913850188255), (36, 0.6199103891849518), (18, 0.6792039200663567), (53, 1.1772640347480774)]
computing accuracy for after removing block 44 . block score: 0.0490833162330091
removed block 44 current accuracy 0.9302 loss from initial  0.06979999999999997
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.051494. All blocks and scores: [(21, 0.0514944838359952), (23, 0.0532460231333971), (7, 0.05442805076017976), (19, 0.05485838884487748), (22, 0.056098447646945715), (20, 0.05623572273179889), (38, 0.05828699329867959), (24, 0.061136435251683), (51, 0.06267874548211694), (39, 0.06549300625920296), (15, 0.06560815591365099), (37, 0.0690770959481597), (47, 0.07165143825113773), (4, 0.07296435069292784), (9, 0.07781528308987617), (52, 0.08134304732084274), (6, 0.08175343461334705), (2, 0.08560283295810223), (14, 0.09048472996801138), (11, 0.09633495379239321), (17, 0.10145785380154848), (3, 0.1016127672046423), (0, 0.10349199827760458), (13, 0.11351337190717459), (1, 0.11778741981834173), (8, 0.13163519464433193), (10, 0.1419405434280634), (12, 0.1439035702496767), (16, 0.15209484100341797), (5, 0.2014391478151083), (36, 0.61991036683321), (18, 0.6792039126157761), (53, 1.2444821000099182)]
computing accuracy for after removing block 21 . block score: 0.0514944838359952
removed block 21 current accuracy 0.9224 loss from initial  0.0776
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.047943. All blocks and scores: [(23, 0.04794303793460131), (22, 0.04994518542662263), (24, 0.05259821377694607), (38, 0.05369851645082235), (7, 0.054428049363195896), (19, 0.05485838744789362), (20, 0.056235723197460175), (51, 0.05966814560815692), (39, 0.06285470770671964), (37, 0.06471381895244122), (15, 0.06560815684497356), (47, 0.06707592308521271), (52, 0.07061297819018364), (4, 0.07296434883028269), (9, 0.07781528402119875), (6, 0.0817534327507019), (2, 0.08560283482074738), (14, 0.09048472996801138), (11, 0.09633495286107063), (17, 0.10145785100758076), (3, 0.10161276441067457), (0, 0.10349199827760458), (13, 0.11351337283849716), (1, 0.11778742354363203), (8, 0.13163519836962223), (10, 0.1419405434280634), (12, 0.1439035665243864), (16, 0.15209484286606312), (5, 0.2014391403645277), (36, 0.5783031135797501), (18, 0.6792038902640343), (53, 1.311259850859642)]
computing accuracy for after removing block 23 . block score: 0.04794303793460131
removed block 23 current accuracy 0.9014 loss from initial  0.09860000000000002
since last training loss: 0.06400000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.049945. All blocks and scores: [(22, 0.049945186357945204), (24, 0.050203519873321056), (7, 0.05442805076017976), (19, 0.05485838698223233), (38, 0.05513501726090908), (20, 0.05623572273179889), (51, 0.059895559679716825), (39, 0.06387155409902334), (47, 0.06433266028761864), (15, 0.06560815684497356), (52, 0.071078946813941), (37, 0.07247915863990784), (4, 0.07296434976160526), (9, 0.07781528402119875), (6, 0.0817534327507019), (2, 0.08560283575206995), (14, 0.09048472810536623), (11, 0.09633495379239321), (17, 0.10145785380154848), (3, 0.10161276627331972), (0, 0.10349199920892715), (13, 0.11351337283849716), (1, 0.11778741795569658), (8, 0.13163519650697708), (10, 0.1419405434280634), (12, 0.14390356838703156), (16, 0.15209484845399857), (5, 0.2014391478151083), (36, 0.6067196726799011), (18, 0.6792039200663567), (53, 1.3095954805612564)]
computing accuracy for after removing block 22 . block score: 0.049945186357945204
removed block 22 current accuracy 0.874 loss from initial  0.126
since last training loss: 0.09140000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.047380. All blocks and scores: [(24, 0.04738046461716294), (38, 0.05402192194014788), (7, 0.05442804750055075), (19, 0.05485838744789362), (20, 0.05623572273179889), (51, 0.05807960359379649), (47, 0.06097073620185256), (39, 0.06289705820381641), (15, 0.06560815591365099), (52, 0.06658994499593973), (4, 0.07296435069292784), (37, 0.0760558731853962), (9, 0.07781528402119875), (6, 0.08175343461334705), (2, 0.0856028338894248), (14, 0.09048472996801138), (11, 0.09633495192974806), (17, 0.1014578528702259), (3, 0.10161276534199715), (0, 0.103491997346282), (13, 0.11351337563246489), (1, 0.1177874207496643), (8, 0.13163519091904163), (10, 0.1419405397027731), (12, 0.1439035702496767), (16, 0.15209484472870827), (5, 0.201439144089818), (36, 0.613497219979763), (18, 0.6792039051651955), (53, 1.3474775552749634)]
computing accuracy for after removing block 24 . block score: 0.04738046461716294
removed block 24 current accuracy 0.8408 loss from initial  0.1592
since last training loss: 0.12460000000000004 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.050578. All blocks and scores: [(38, 0.050577782560139894), (47, 0.05365712475031614), (51, 0.05406464543193579), (7, 0.05442804982885718), (19, 0.05485839024186134), (20, 0.056235725060105324), (39, 0.05989860184490681), (52, 0.06098861526697874), (15, 0.06560815498232841), (4, 0.07296435162425041), (37, 0.07664468884468079), (9, 0.0778152821585536), (6, 0.08175343181937933), (2, 0.08560283109545708), (14, 0.09048472996801138), (11, 0.09633495192974806), (17, 0.1014578528702259), (3, 0.1016127709299326), (0, 0.10349199827760458), (13, 0.11351337376981974), (1, 0.11778741795569658), (8, 0.13163519464433193), (10, 0.14194054156541824), (12, 0.14390356838703156), (16, 0.15209484100341797), (5, 0.2014391478151083), (36, 0.6028055921196938), (18, 0.6792038977146149), (53, 1.3075456321239471)]
computing accuracy for after removing block 38 . block score: 0.050577782560139894
removed block 38 current accuracy 0.8082 loss from initial  0.19179999999999997
since last training loss: 0.1572 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.052610. All blocks and scores: [(47, 0.0526103600859642), (51, 0.053823040798306465), (7, 0.05442804889753461), (19, 0.054858388379216194), (20, 0.05623572273179889), (52, 0.05904834531247616), (15, 0.06560815591365099), (39, 0.0671817734837532), (4, 0.07296435069292784), (37, 0.07664468791335821), (9, 0.07781528495252132), (6, 0.08175343368202448), (2, 0.08560283668339252), (14, 0.0904847290366888), (11, 0.09633495472371578), (17, 0.10145785007625818), (3, 0.10161276441067457), (0, 0.10349199175834656), (13, 0.11351337097585201), (1, 0.1177874207496643), (8, 0.13163519278168678), (10, 0.14194054529070854), (12, 0.14390357211232185), (16, 0.15209484286606312), (5, 0.20143914222717285), (36, 0.6028055921196938), (18, 0.6792039200663567), (53, 1.3708674013614655)]
computing accuracy for after removing block 47 . block score: 0.0526103600859642
removed block 47 current accuracy 0.726 loss from initial  0.274
training start
training epoch 0 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.1]
training epoch 1 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 2 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 3 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 6 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 8 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 9 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.071687. All blocks and scores: [(7, 0.07168675027787685), (52, 0.08355539198964834), (51, 0.08448090869933367), (4, 0.08491806499660015), (15, 0.08662302419543266), (19, 0.0871594212949276), (6, 0.09702068846672773), (20, 0.09882980026304722), (37, 0.10068163275718689), (2, 0.10592318326234818), (39, 0.10803236439824104), (11, 0.11583949625492096), (9, 0.11936167161911726), (14, 0.12146279029548168), (3, 0.12812750041484833), (0, 0.13085376657545567), (13, 0.1325208805501461), (17, 0.13532593846321106), (1, 0.14378510415554047), (8, 0.17315270565450191), (10, 0.17598922364413738), (12, 0.18512445874512196), (16, 0.19332455843687057), (5, 0.23717398196458817), (36, 0.5585149973630905), (18, 0.6460401639342308), (53, 1.1115642488002777)]
computing accuracy for after removing block 7 . block score: 0.07168675027787685
removed block 7 current accuracy 0.9402 loss from initial  0.059799999999999964
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 19, with score 0.081220. All blocks and scores: [(19, 0.08121955394744873), (52, 0.08190333191305399), (51, 0.08390659000724554), (4, 0.08491806406527758), (15, 0.08584246039390564), (37, 0.09439425077289343), (20, 0.09536733757704496), (6, 0.09702069219201803), (2, 0.10592318698763847), (11, 0.10707946680486202), (39, 0.10803089290857315), (9, 0.1154795391485095), (14, 0.11567505076527596), (13, 0.11612218618392944), (17, 0.12201673723757267), (3, 0.12812749482691288), (0, 0.13085376657545567), (1, 0.14378510415554047), (16, 0.17111423052847385), (8, 0.1713667158037424), (12, 0.17579584568738937), (10, 0.1774328425526619), (5, 0.2371739875525236), (36, 0.5434885919094086), (18, 0.6214548200368881), (53, 1.1001242995262146)]
computing accuracy for after removing block 19 . block score: 0.08121955394744873
removed block 19 current accuracy 0.9238 loss from initial  0.07620000000000005
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 52, with score 0.073340. All blocks and scores: [(52, 0.07334022875875235), (51, 0.08132251910865307), (4, 0.08491806499660015), (15, 0.08584246039390564), (20, 0.08675277791917324), (6, 0.09702069219201803), (37, 0.10527042020112276), (2, 0.10592318698763847), (11, 0.10707946307957172), (39, 0.10849151853471994), (9, 0.11547953821718693), (14, 0.11567504610866308), (13, 0.11612218152731657), (17, 0.1220167363062501), (3, 0.12812749668955803), (0, 0.13085376285016537), (1, 0.14378510601818562), (16, 0.17111423425376415), (8, 0.1713667195290327), (12, 0.17579584568738937), (10, 0.1774328462779522), (5, 0.23717398568987846), (36, 0.5470620766282082), (18, 0.6214548200368881), (53, 1.0880835801362991)]
computing accuracy for after removing block 52 . block score: 0.07334022875875235
removed block 52 current accuracy 0.8768 loss from initial  0.12319999999999998
since last training loss: 0.06799999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 51, with score 0.081323. All blocks and scores: [(51, 0.08132251910865307), (4, 0.08491806406527758), (15, 0.08584246318787336), (20, 0.08675277978181839), (6, 0.09702069126069546), (37, 0.10527042020112276), (2, 0.10592318419367075), (11, 0.10707946214824915), (39, 0.10849151760339737), (9, 0.11547953728586435), (14, 0.11567504703998566), (13, 0.1161221843212843), (17, 0.1220167363062501), (3, 0.12812750414013863), (0, 0.13085376471281052), (1, 0.14378510043025017), (16, 0.17111423052847385), (8, 0.17136672139167786), (12, 0.17579584382474422), (10, 0.17743284069001675), (5, 0.23717398941516876), (36, 0.5470620840787888), (18, 0.6214548051357269), (53, 1.1368981152772903)]
computing accuracy for after removing block 51 . block score: 0.08132251910865307
removed block 51 current accuracy 0.7818 loss from initial  0.21819999999999995
since last training loss: 0.16299999999999992 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 4, with score 0.084918. All blocks and scores: [(4, 0.0849180668592453), (15, 0.08584245946258307), (20, 0.08675277885049582), (6, 0.09702069126069546), (37, 0.10527041926980019), (2, 0.10592318698763847), (11, 0.10707946214824915), (39, 0.10849151853471994), (9, 0.11547954101115465), (14, 0.11567504797130823), (13, 0.11612218245863914), (17, 0.12201673816889524), (3, 0.12812749482691288), (0, 0.13085376843810081), (1, 0.14378510601818562), (16, 0.17111423052847385), (8, 0.1713667269796133), (12, 0.17579584196209908), (10, 0.17743284069001675), (5, 0.2371739912778139), (36, 0.5470620840787888), (18, 0.6214548200368881), (53, 1.2967138141393661)]
computing accuracy for after removing block 4 . block score: 0.0849180668592453
removed block 4 current accuracy 0.7576 loss from initial  0.24239999999999995
since last training loss: 0.18719999999999992 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 15, with score 0.085319. All blocks and scores: [(15, 0.08531870041042566), (20, 0.08641647733747959), (11, 0.10441591404378414), (6, 0.10495852958410978), (2, 0.10592318791896105), (37, 0.1087232856079936), (39, 0.11000026855617762), (14, 0.11484535038471222), (13, 0.11609847750514746), (17, 0.11746999528259039), (9, 0.11868692841380835), (3, 0.12812749668955803), (0, 0.13085376657545567), (1, 0.14378510043025017), (16, 0.15500402636826038), (10, 0.16739012114703655), (8, 0.16883081756532192), (12, 0.1756143905222416), (5, 0.25965920835733414), (36, 0.5518834888935089), (18, 0.62459397315979), (53, 1.265803575515747)]
computing accuracy for after removing block 15 . block score: 0.08531870041042566
removed block 15 current accuracy 0.692 loss from initial  0.30800000000000005
since last training loss: 0.2528 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 20, with score 0.081830. All blocks and scores: [(20, 0.08182971179485321), (11, 0.10441591590642929), (6, 0.10495852679014206), (2, 0.10592318885028362), (37, 0.10604734998196363), (39, 0.10855762474238873), (14, 0.1148453513160348), (13, 0.1160984793677926), (9, 0.11868692375719547), (17, 0.12230414897203445), (3, 0.12812749668955803), (0, 0.13085376657545567), (1, 0.14378510601818562), (16, 0.16710449010133743), (10, 0.16739011742174625), (8, 0.16883081942796707), (12, 0.17561439238488674), (5, 0.25965920463204384), (36, 0.5310907661914825), (18, 0.6115145236253738), (53, 1.24354949593544)]
computing accuracy for after removing block 20 . block score: 0.08182971179485321
removed block 20 current accuracy 0.6298 loss from initial  0.3702
since last training loss: 0.31499999999999995 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 39, with score 0.104025. All blocks and scores: [(39, 0.10402491874992847), (11, 0.10441591497510672), (6, 0.10495853144675493), (2, 0.1059231823310256), (14, 0.11484534945338964), (37, 0.1157733453437686), (13, 0.11609848029911518), (9, 0.11868692375719547), (17, 0.1223041545599699), (3, 0.12812750041484833), (0, 0.13085376843810081), (1, 0.14378509856760502), (16, 0.16710449755191803), (10, 0.1673901155591011), (8, 0.16883082315325737), (12, 0.1756143905222416), (5, 0.25965920463204384), (36, 0.5580150932073593), (18, 0.6115145459771156), (53, 1.111153244972229)]
computing accuracy for after removing block 39 . block score: 0.10402491874992847
removed block 39 current accuracy 0.4824 loss from initial  0.5176000000000001
since last training loss: 0.4624 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 11, with score 0.104416. All blocks and scores: [(11, 0.10441591311246157), (6, 0.10495853144675493), (2, 0.10592318419367075), (14, 0.11484534945338964), (37, 0.11577334627509117), (13, 0.11609847564250231), (9, 0.11868692748248577), (17, 0.12230415269732475), (3, 0.12812750041484833), (0, 0.13085376285016537), (1, 0.14378510229289532), (16, 0.16710449941456318), (10, 0.16739012114703655), (8, 0.16883082129061222), (12, 0.1756143905222416), (5, 0.25965919718146324), (36, 0.5580150857567787), (18, 0.6115145310759544), (53, 1.27077254652977)]
computing accuracy for after removing block 11 . block score: 0.10441591311246157
removed block 11 current accuracy 0.413 loss from initial  0.587
since last training loss: 0.5318 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 6, with score 0.104959. All blocks and scores: [(6, 0.10495852958410978), (2, 0.10592318698763847), (14, 0.1123954402282834), (37, 0.1149547528475523), (17, 0.11688377894461155), (13, 0.11764726229012012), (9, 0.11868692375719547), (16, 0.12702436558902264), (3, 0.12812750041484833), (0, 0.13085376098752022), (1, 0.14378510601818562), (12, 0.16731461882591248), (10, 0.1673901192843914), (8, 0.16883082315325737), (5, 0.25965919718146324), (36, 0.5530390441417694), (18, 0.6172501146793365), (53, 1.2119866013526917)]
computing accuracy for after removing block 6 . block score: 0.10495852958410978
removed block 6 current accuracy 0.3042 loss from initial  0.6958
since last training loss: 0.6406 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 14, with score 0.096892. All blocks and scores: [(14, 0.09689177293330431), (2, 0.10592318791896105), (16, 0.10626222100108862), (17, 0.10806885175406933), (37, 0.10899949166923761), (13, 0.11434101313352585), (9, 0.11880162823945284), (3, 0.12812749668955803), (0, 0.13085376657545567), (1, 0.14378510601818562), (12, 0.15890567749738693), (8, 0.15937948413193226), (10, 0.16771521233022213), (5, 0.25965918973088264), (36, 0.5366586148738861), (18, 0.5969745144248009), (53, 1.2194291651248932)]
computing accuracy for after removing block 14 . block score: 0.09689177293330431
removed block 14 current accuracy 0.227 loss from initial  0.773
since last training loss: 0.7178 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.105050. All blocks and scores: [(17, 0.10505025181919336), (2, 0.1059231860563159), (37, 0.11059960350394249), (13, 0.11434101313352585), (9, 0.11880162358283997), (16, 0.1281021609902382), (3, 0.12812749855220318), (0, 0.13085376657545567), (1, 0.14378510229289532), (12, 0.15890567749738693), (8, 0.15937948040664196), (10, 0.16771520674228668), (5, 0.25965919718146324), (36, 0.5346866101026535), (18, 0.6234005019068718), (53, 1.3142337501049042)]
computing accuracy for after removing block 17 . block score: 0.10505025181919336
removed block 17 current accuracy 0.2186 loss from initial  0.7814
training start
training epoch 0 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.1]
training epoch 1 val accuracy 0.8072 topk_dict {'top1': 0.8072} is_best False lr [0.1]
training epoch 2 val accuracy 0.861 topk_dict {'top1': 0.861} is_best True lr [0.1]
training epoch 3 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best False lr [0.1]
training epoch 4 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best True lr [0.1]
training epoch 5 val accuracy 0.8016 topk_dict {'top1': 0.8016} is_best False lr [0.1]
training epoch 6 val accuracy 0.867 topk_dict {'top1': 0.867} is_best True lr [0.1]
training epoch 7 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 8 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 9 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 10 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.922200)
finished training. finished 50 epochs. accuracy 0.9222 topk_dict {'top1': 0.9222}
