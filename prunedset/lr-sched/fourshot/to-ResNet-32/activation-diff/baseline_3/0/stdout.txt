start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.00845510873477906), (30, 0.009703245596028864), (33, 0.01111594308167696), (34, 0.011622709804214537), (31, 0.012275203014723957), (28, 0.012290219543501735), (29, 0.014791248016990721), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.01953245303593576), (25, 0.019648711197078228), (35, 0.01978794764727354), (24, 0.020829484099522233), (22, 0.021021661115810275), (23, 0.02157451375387609), (47, 0.022546384017914534), (44, 0.023842158261686563), (41, 0.024168547010049224), (46, 0.024651075713336468), (6, 0.024668579688295722), (21, 0.025249344063922763), (43, 0.02580355410464108), (10, 0.026363695971667767), (42, 0.026426069205626845), (4, 0.02665954572148621), (45, 0.026823592372238636), (39, 0.026881905971094966), (40, 0.02689355192705989), (49, 0.027856426313519478), (48, 0.028491602512076497), (50, 0.028780476888641715), (11, 0.029002359369769692), (38, 0.029662921093404293), (3, 0.032272040378302336), (13, 0.03333653463050723), (37, 0.035762056708335876), (20, 0.03646321967244148), (12, 0.037992720026522875), (9, 0.03963937098160386), (51, 0.039642108138650656), (19, 0.04421887639909983), (52, 0.04580832598730922), (15, 0.04691674932837486), (14, 0.04904163721948862), (2, 0.05722745507955551), (0, 0.05888257594779134), (16, 0.062252288684248924), (5, 0.09379573632031679), (17, 0.25432228669524193), (36, 0.41727545484900475), (18, 0.4852069206535816), (53, 0.7453346773982048)]
computing accuracy for after removing block 32 . block score: 0.00845510873477906
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.009703245828859508), (33, 0.01119989005383104), (34, 0.011937809525988996), (31, 0.012275203131139278), (28, 0.012290219427086413), (29, 0.014791248715482652), (27, 0.016729247989133), (26, 0.01744490279816091), (1, 0.018259592819958925), (7, 0.01837918534874916), (8, 0.01953245303593576), (25, 0.019648710498586297), (35, 0.020431341836228967), (24, 0.020829483633860946), (22, 0.02102166088297963), (23, 0.021574513521045446), (47, 0.022262109676375985), (44, 0.023293233942240477), (41, 0.023795815417543054), (46, 0.024043594719842076), (6, 0.02466858015395701), (21, 0.025249343365430832), (43, 0.025525057455524802), (42, 0.026236766017973423), (40, 0.026315772207453847), (10, 0.026363697135820985), (4, 0.026659545954316854), (45, 0.026667137863114476), (39, 0.026886870618909597), (49, 0.027327026007696986), (48, 0.02791151381097734), (50, 0.028208705596625805), (38, 0.02861060854047537), (11, 0.02900235983543098), (3, 0.032272040378302336), (13, 0.03333653463050723), (37, 0.034699315670877695), (20, 0.036463219206780195), (12, 0.037992720026522875), (51, 0.039370250422507524), (9, 0.03963937098160386), (19, 0.04421887407079339), (52, 0.045125022530555725), (15, 0.046916747931391), (14, 0.04904163861647248), (2, 0.057227457873523235), (0, 0.058882576413452625), (16, 0.0622522896155715), (5, 0.09379573911428452), (17, 0.25432228669524193), (36, 0.4077852927148342), (18, 0.4852069243788719), (53, 0.7581149190664291)]
computing accuracy for after removing block 30 . block score: 0.009703245828859508
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006312310696), (34, 0.011887529282830656), (28, 0.01229021919425577), (31, 0.012499805074185133), (29, 0.014791248831897974), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.018259593285620213), (7, 0.01837918534874916), (8, 0.019532452570274472), (25, 0.01964871073141694), (35, 0.02071700361557305), (24, 0.020829483633860946), (22, 0.021021660417318344), (23, 0.021574513288214803), (47, 0.022107098251581192), (44, 0.02311369380913675), (46, 0.023742159130051732), (41, 0.02392919920384884), (6, 0.024668580386787653), (21, 0.025249342899769545), (43, 0.025264927884563804), (40, 0.026247450849041343), (10, 0.026363695971667767), (42, 0.026527423644438386), (4, 0.026659545488655567), (45, 0.02671261061914265), (39, 0.027034528786316514), (49, 0.027338512241840363), (48, 0.027909939642995596), (50, 0.027956509264186025), (38, 0.028708983911201358), (11, 0.029002360068261623), (3, 0.03227204084396362), (13, 0.03333653463050723), (37, 0.03434832580387592), (20, 0.036463219206780195), (12, 0.037992720026522875), (51, 0.039133232086896896), (9, 0.03963937098160386), (19, 0.04421887453645468), (52, 0.04478001641109586), (15, 0.046916747931391), (14, 0.04904163768514991), (2, 0.05722745647653937), (0, 0.058882574550807476), (16, 0.062252288684248924), (5, 0.09379573632031679), (17, 0.2543222885578871), (36, 0.40603340044617653), (18, 0.4852069169282913), (53, 0.758183628320694)]
computing accuracy for after removing block 33 . block score: 0.011317006312310696
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.012240081909112632), (28, 0.012290219077840447), (31, 0.012499805423431098), (29, 0.014791248249821365), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532452803105116), (25, 0.019648710265755653), (24, 0.02082948386669159), (22, 0.021021660417318344), (35, 0.021477245492860675), (23, 0.021574513288214803), (47, 0.021933730226010084), (44, 0.022819968406111002), (46, 0.023398497374728322), (41, 0.024046602426096797), (6, 0.024668579688295722), (21, 0.025249342899769545), (43, 0.025404763873666525), (40, 0.026019647484645247), (10, 0.026363695971667767), (4, 0.026659546187147498), (42, 0.026750181335955858), (45, 0.02678381372243166), (49, 0.027069834293797612), (39, 0.027496120892465115), (48, 0.027574570383876562), (50, 0.0279463694896549), (38, 0.028736303094774485), (11, 0.029002359602600336), (3, 0.032272040378302336), (13, 0.03333653509616852), (37, 0.03405904769897461), (20, 0.03646321967244148), (12, 0.03799272049218416), (51, 0.03880898095667362), (9, 0.03963937098160386), (19, 0.044218875002115965), (52, 0.04450395004823804), (15, 0.04691674746572971), (14, 0.04904163768514991), (2, 0.05722745647653937), (0, 0.058882574550807476), (16, 0.06225228914991021), (5, 0.09379573632031679), (17, 0.2543222736567259), (36, 0.40450604259967804), (18, 0.4852069281041622), (53, 0.7641192972660065)]
computing accuracy for after removing block 34 . block score: 0.012240081909112632
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.012290219427086413), (31, 0.012499805656261742), (29, 0.014791248366236687), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.01825959305278957), (7, 0.018379186280071735), (8, 0.019532452803105116), (25, 0.019648710964247584), (24, 0.020829484099522233), (22, 0.021021661115810275), (23, 0.021574513521045446), (35, 0.0217086561024189), (47, 0.02180175529792905), (44, 0.0224381135776639), (46, 0.023336909245699644), (41, 0.023686284432187676), (6, 0.024668580386787653), (21, 0.025249343365430832), (43, 0.02540483931079507), (40, 0.02556937700137496), (10, 0.026363695971667767), (42, 0.02655180124565959), (39, 0.02658287319354713), (49, 0.026649241102859378), (4, 0.026659546652808785), (45, 0.026776784798130393), (48, 0.026865947525948286), (50, 0.027566451346501708), (38, 0.027829119004309177), (11, 0.029002359369769692), (3, 0.032272040378302336), (37, 0.03319812146946788), (13, 0.03333653509616852), (20, 0.03646321827545762), (12, 0.03799272095784545), (51, 0.03805992612615228), (9, 0.03963937144726515), (52, 0.04353108070790768), (19, 0.04421887639909983), (15, 0.046916747931391), (14, 0.04904163861647248), (2, 0.05722745647653937), (0, 0.05888257594779134), (16, 0.06225228775292635), (5, 0.09379573911428452), (17, 0.25432228296995163), (36, 0.3958275355398655), (18, 0.4852069206535816), (53, 0.7794358879327774)]
computing accuracy for after removing block 28 . block score: 0.012290219427086413
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645482748747), (29, 0.014790621120482683), (27, 0.016729248221963644), (26, 0.017444903030991554), (1, 0.018259593518450856), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.01964871142990887), (24, 0.020829483401030302), (22, 0.0210216601844877), (47, 0.02134651830419898), (23, 0.02157451305538416), (35, 0.021596733247861266), (44, 0.021918716840445995), (46, 0.02273467485792935), (41, 0.023228028556331992), (6, 0.02466858085244894), (40, 0.024839136051014066), (43, 0.024858604883775115), (21, 0.025249343365430832), (39, 0.025966263841837645), (48, 0.025971464347094297), (42, 0.02599131502211094), (49, 0.026064811507239938), (10, 0.026363695971667767), (45, 0.02645392087288201), (4, 0.026659545488655567), (50, 0.026680127950385213), (38, 0.027020083740353584), (11, 0.029002359369769692), (37, 0.032236404716968536), (3, 0.032272040378302336), (13, 0.03333653602749109), (20, 0.036463219206780195), (51, 0.03758792392909527), (12, 0.03799272095784545), (9, 0.039639370050281286), (52, 0.04288490163162351), (19, 0.04421887453645468), (15, 0.046916747931391), (14, 0.04904163861647248), (2, 0.05722745694220066), (0, 0.05888257594779134), (16, 0.06225228914991021), (5, 0.09379573818296194), (17, 0.2543222811073065), (36, 0.3858989179134369), (18, 0.4852069281041622), (53, 0.7881819233298302)]
computing accuracy for after removing block 31 . block score: 0.011874645482748747
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.014790620771236718), (27, 0.016729247989133), (26, 0.01744490396231413), (1, 0.018259593518450856), (7, 0.01837918534874916), (8, 0.019532452803105116), (25, 0.01964871073141694), (24, 0.020829483633860946), (47, 0.020932046696543694), (22, 0.021021661115810275), (44, 0.021379181882366538), (23, 0.02157451375387609), (46, 0.02206318941898644), (35, 0.022440450033172965), (41, 0.02264889213256538), (40, 0.02413078141398728), (43, 0.024664208758622408), (6, 0.024668579688295722), (21, 0.025249343598261476), (48, 0.02525039715692401), (49, 0.025515808956697583), (42, 0.025626870803534985), (39, 0.025647579925134778), (38, 0.025854782667011023), (50, 0.025972345378249884), (45, 0.026165934279561043), (10, 0.026363696437329054), (4, 0.02665954502299428), (11, 0.02900235913693905), (37, 0.031289287842810154), (3, 0.03227204130962491), (13, 0.033336535561829805), (20, 0.03646321967244148), (51, 0.03728976147249341), (12, 0.03799272095784545), (9, 0.03963937098160386), (52, 0.04199218424037099), (19, 0.044218875002115965), (15, 0.04691674932837486), (14, 0.049041638150811195), (2, 0.05722745647653937), (0, 0.058882574550807476), (16, 0.06225228728726506), (5, 0.09379573818296194), (17, 0.2543222736567259), (36, 0.3760596886277199), (18, 0.4852069243788719), (53, 0.8019541054964066)]
computing accuracy for after removing block 29 . block score: 0.014790620771236718
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729248454794288), (26, 0.01744490396231413), (1, 0.01825959305278957), (7, 0.018379185814410448), (8, 0.019532452570274472), (25, 0.019648710498586297), (47, 0.020515700336545706), (24, 0.020829484332352877), (44, 0.02097513130865991), (22, 0.021021660650148988), (23, 0.02157451305538416), (46, 0.021652451250702143), (41, 0.022661818424239755), (35, 0.022723624017089605), (40, 0.02388307498767972), (43, 0.024189722957089543), (6, 0.02466858015395701), (48, 0.024881583405658603), (49, 0.02521235216408968), (42, 0.02522930083796382), (21, 0.025249343132600188), (38, 0.025457143085077405), (50, 0.025512879714369774), (39, 0.025584627175703645), (45, 0.02621095417998731), (10, 0.026363695738837123), (4, 0.026659546187147498), (11, 0.02900235913693905), (37, 0.03110239445231855), (3, 0.0322720417752862), (13, 0.03333653509616852), (20, 0.036463219206780195), (51, 0.037521738559007645), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.04157667187973857), (19, 0.04421887407079339), (15, 0.04691675025969744), (14, 0.049041638150811195), (2, 0.05722745507955551), (0, 0.058882576413452625), (16, 0.06225228821858764), (5, 0.09379573818296194), (17, 0.25432227179408073), (36, 0.3744279034435749), (18, 0.4852069206535816), (53, 0.8058174327015877)]
computing accuracy for after removing block 27 . block score: 0.016729248454794288
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017445. All blocks and scores: [(26, 0.01744490349665284), (1, 0.01825959305278957), (7, 0.01837918534874916), (8, 0.019532452803105116), (25, 0.01964871073141694), (47, 0.02019636449404061), (44, 0.020198780111968517), (24, 0.02082948386669159), (22, 0.021021661115810275), (46, 0.021314961137250066), (23, 0.021574512589722872), (35, 0.021661201724782586), (41, 0.022262451238930225), (40, 0.02343457145616412), (43, 0.02366974879987538), (48, 0.023870018543675542), (49, 0.024273037677630782), (39, 0.02463195752352476), (6, 0.02466858085244894), (50, 0.024705925723537803), (38, 0.024713970720767975), (42, 0.024764888687059283), (21, 0.02524934383109212), (45, 0.025909221963956952), (10, 0.026363695971667767), (4, 0.026659545954316854), (11, 0.02900235913693905), (37, 0.030295762233436108), (3, 0.03227203991264105), (13, 0.033336535561829805), (20, 0.03646321874111891), (51, 0.03686857549473643), (12, 0.03799272142350674), (9, 0.039639370515942574), (52, 0.040492807514965534), (19, 0.044218875002115965), (15, 0.046916747931391), (14, 0.04904163908213377), (2, 0.05722745740786195), (0, 0.058882574550807476), (16, 0.062252288684248924), (5, 0.09379573725163937), (17, 0.2543222811073065), (36, 0.3650362640619278), (18, 0.4852069318294525), (53, 0.8347273096442223)]
computing accuracy for after removing block 26 . block score: 0.01744490349665284
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
training start
training epoch 0 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 1 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 4 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 6 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.1]
training epoch 7 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 8 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 9 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 10 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.994400)
finished training. finished 50 epochs. accuracy 0.9944 topk_dict {'top1': 0.9944}
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018260. All blocks and scores: [(1, 0.01825959305278957), (7, 0.018379185581579804), (8, 0.019532452803105116), (25, 0.019648710265755653), (44, 0.019705433398485184), (47, 0.019746014149859548), (46, 0.020809161011129618), (24, 0.020829484332352877), (22, 0.021021660417318344), (35, 0.021195971174165606), (23, 0.021574514219537377), (41, 0.022163193440064788), (48, 0.02267357218079269), (40, 0.0228444782551378), (43, 0.023211447056382895), (49, 0.02358019002713263), (38, 0.02393691544421017), (39, 0.024143034825101495), (50, 0.024241250939667225), (42, 0.024461105465888977), (6, 0.024668580619618297), (21, 0.025249343365430832), (45, 0.025508656864985824), (10, 0.026363695273175836), (4, 0.02665954572148621), (11, 0.02900235983543098), (37, 0.029677377315238118), (3, 0.03227203991264105), (13, 0.03333653509616852), (51, 0.036321446765214205), (20, 0.03646321967244148), (12, 0.03799272095784545), (9, 0.03963937144726515), (52, 0.039895533584058285), (19, 0.04421887593343854), (15, 0.046916747000068426), (14, 0.04904163768514991), (2, 0.05722745507955551), (0, 0.0588825773447752), (16, 0.06225228821858764), (5, 0.09379573818296194), (17, 0.25432227924466133), (36, 0.36152271926403046), (18, 0.4852069392800331), (53, 0.8471468314528465)]
computing accuracy for after removing block 1 . block score: 0.01825959305278957
removed block 1 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017854. All blocks and scores: [(7, 0.017853511730208993), (8, 0.01868281909264624), (25, 0.019129085121676326), (44, 0.019602667074650526), (24, 0.01968022366054356), (47, 0.01984298788011074), (22, 0.020383453462272882), (35, 0.020452447468414903), (46, 0.020825861487537622), (23, 0.021086917957291007), (41, 0.021640336606651545), (48, 0.0223057281691581), (40, 0.022332167020067573), (43, 0.022896901238709688), (38, 0.02323959581553936), (39, 0.023386763874441385), (49, 0.02374406438320875), (50, 0.024021203396841884), (6, 0.024041746510192752), (42, 0.024278491968289018), (21, 0.024377909721806645), (45, 0.02549561788327992), (10, 0.025961280800402164), (11, 0.028003806015476584), (4, 0.028626713436096907), (37, 0.029063857393339276), (3, 0.03240096429362893), (13, 0.03324462752789259), (20, 0.03517247689887881), (51, 0.03656556457281113), (12, 0.03718129266053438), (9, 0.03868303028866649), (52, 0.039694709703326225), (19, 0.04354848060756922), (15, 0.047371077351272106), (14, 0.048121772706508636), (2, 0.05715902289375663), (0, 0.058882576413452625), (16, 0.060861748177558184), (5, 0.09224656596779823), (17, 0.2509492505341768), (36, 0.34972937777638435), (18, 0.46861379966139793), (53, 0.8498541191220284)]
computing accuracy for after removing block 7 . block score: 0.017853511730208993
removed block 7 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.018390. All blocks and scores: [(25, 0.018389767268672585), (24, 0.018951865378767252), (35, 0.01924195932224393), (47, 0.01943464344367385), (44, 0.019624897511675954), (23, 0.019739443669095635), (22, 0.019956301664933562), (8, 0.01996665564365685), (46, 0.020434766076505184), (41, 0.021304226480424404), (40, 0.02142042270861566), (48, 0.021825639763846993), (43, 0.02223287522792816), (38, 0.0225537302903831), (39, 0.022905307123437524), (21, 0.02331746951676905), (50, 0.02360892412252724), (49, 0.0236319110263139), (42, 0.02400621841661632), (6, 0.02404174581170082), (45, 0.025045356946066022), (10, 0.026167658623307943), (11, 0.028026720974594355), (37, 0.02840108796954155), (4, 0.02862671227194369), (3, 0.03240096475929022), (13, 0.0329240751452744), (20, 0.03404331021010876), (51, 0.036449620965868235), (12, 0.036901213228702545), (52, 0.03922955971211195), (9, 0.03934459248557687), (19, 0.04198857489973307), (15, 0.046306457836180925), (14, 0.04730391362681985), (2, 0.05715902289375663), (0, 0.058882574550807476), (16, 0.0594125771895051), (5, 0.09224656410515308), (17, 0.23884584568440914), (36, 0.3409247472882271), (18, 0.4543862156569958), (53, 0.8508737459778786)]
computing accuracy for after removing block 25 . block score: 0.018389767268672585
removed block 25 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.018641. All blocks and scores: [(35, 0.018640690483152866), (24, 0.018951865611597896), (47, 0.01916275336407125), (44, 0.019372919807210565), (23, 0.01973944390192628), (22, 0.01995630096644163), (8, 0.01996665564365685), (46, 0.0201800677459687), (41, 0.020792829105630517), (40, 0.020806472981348634), (48, 0.021095545263960958), (38, 0.021664810366928577), (43, 0.022042255848646164), (39, 0.022102958289906383), (50, 0.022921856958419085), (49, 0.02298674499616027), (21, 0.02331746951676905), (42, 0.023690476780757308), (6, 0.024041745346039534), (45, 0.02510328497737646), (10, 0.02616765908896923), (37, 0.027708852663636208), (11, 0.028026721207425), (4, 0.028626713203266263), (3, 0.03240096569061279), (13, 0.0329240751452744), (20, 0.034043310675770044), (51, 0.03592318994924426), (12, 0.03690121462568641), (52, 0.03849219670519233), (9, 0.03934459388256073), (19, 0.041988575365394354), (15, 0.046306459698826075), (14, 0.047303912695497274), (2, 0.05715902242809534), (0, 0.058882576413452625), (16, 0.059412581380456686), (5, 0.09224656410515308), (17, 0.23884584568440914), (36, 0.33257047832012177), (18, 0.45438623428344727), (53, 0.8579949960112572)]
computing accuracy for after removing block 35 . block score: 0.018640690483152866
removed block 35 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.018301. All blocks and scores: [(47, 0.018301398726180196), (44, 0.018879120238125324), (24, 0.018951865378767252), (48, 0.019549657125025988), (46, 0.019557364750653505), (40, 0.019585497211664915), (23, 0.01973944390192628), (22, 0.019956301199272275), (8, 0.01996665564365685), (41, 0.019993557827547193), (38, 0.02027663541957736), (39, 0.020718253450468183), (43, 0.021324649220332503), (50, 0.02192226378247142), (49, 0.02205569832585752), (42, 0.02288483246229589), (21, 0.023317469283938408), (6, 0.024041746277362108), (45, 0.024267783854156733), (10, 0.026167658623307943), (37, 0.026483883382752538), (11, 0.02802672074176371), (4, 0.028626713436096907), (3, 0.03240096429362893), (13, 0.03292407561093569), (20, 0.03404331021010876), (51, 0.03433887893334031), (12, 0.036901215091347694), (52, 0.03733885195106268), (9, 0.03934459248557687), (19, 0.04198857583105564), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.05715902103111148), (0, 0.05888257594779134), (16, 0.05941257951781154), (5, 0.09224656596779823), (17, 0.23884584195911884), (36, 0.31887491792440414), (18, 0.4543862119317055), (53, 0.8835926800966263)]
computing accuracy for after removing block 47 . block score: 0.018301398726180196
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.015999999999999903 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.018879. All blocks and scores: [(44, 0.018879120238125324), (24, 0.018951865378767252), (46, 0.019557365914806724), (40, 0.019585496746003628), (23, 0.019739443669095635), (22, 0.019956301199272275), (8, 0.019966655177995563), (41, 0.01999355829320848), (48, 0.020102362614125013), (38, 0.020276635186746716), (39, 0.020718253450468183), (43, 0.02132464898750186), (42, 0.02288483316078782), (50, 0.02293519163504243), (49, 0.02326167724095285), (21, 0.023317469283938408), (6, 0.02404174581170082), (45, 0.024267783854156733), (10, 0.0261676583904773), (37, 0.026483883382752538), (11, 0.028026721207425), (4, 0.028626713436096907), (3, 0.032400965224951506), (13, 0.03292407561093569), (20, 0.03404331021010876), (51, 0.03476384421810508), (12, 0.036901213228702545), (52, 0.03751523280516267), (9, 0.039344592951238155), (19, 0.04198857489973307), (15, 0.04630645830184221), (14, 0.0473039117641747), (2, 0.05715902196243405), (0, 0.058882576413452625), (16, 0.0594125809147954), (5, 0.09224656689912081), (17, 0.2388458512723446), (36, 0.31887492910027504), (18, 0.45438623055815697), (53, 0.9607554376125336)]
computing accuracy for after removing block 44 . block score: 0.018879120238125324
removed block 44 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.018952. All blocks and scores: [(24, 0.018951865611597896), (40, 0.01958549697883427), (23, 0.019739444134756923), (22, 0.019956301199272275), (8, 0.019966656109318137), (41, 0.01999355829320848), (38, 0.02027663611806929), (48, 0.020389965269714594), (46, 0.020573836751282215), (39, 0.020718253450468183), (43, 0.021324649453163147), (42, 0.02288483246229589), (50, 0.023124572122469544), (21, 0.02331746998243034), (49, 0.023369599599391222), (6, 0.024041746510192752), (45, 0.024384557968005538), (10, 0.026167658856138587), (37, 0.02648388291709125), (11, 0.02802672074176371), (4, 0.028626712737604976), (3, 0.03240096429362893), (13, 0.03292407467961311), (20, 0.03404331021010876), (51, 0.03477862337604165), (12, 0.03690121369436383), (52, 0.03756985208019614), (9, 0.03934459155425429), (19, 0.04198857583105564), (15, 0.0463064587675035), (14, 0.04730391362681985), (2, 0.05715902242809534), (0, 0.05888257687911391), (16, 0.059412579983472824), (5, 0.09224656410515308), (17, 0.23884584568440914), (36, 0.31887491419911385), (18, 0.45438622310757637), (53, 1.021526776254177)]
computing accuracy for after removing block 24 . block score: 0.018951865611597896
removed block 24 current accuracy 0.9534 loss from initial  0.046599999999999975
since last training loss: 0.040999999999999925 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.019207. All blocks and scores: [(40, 0.01920685893855989), (48, 0.019635460572317243), (23, 0.019739443669095635), (41, 0.019740517949685454), (22, 0.019956301199272275), (38, 0.019963711267337203), (8, 0.019966656109318137), (39, 0.020108413649722934), (46, 0.02023323532193899), (43, 0.020772278774529696), (50, 0.022506374400109053), (42, 0.022604695986956358), (49, 0.022722699446603656), (21, 0.023317469051107764), (45, 0.02385061956010759), (6, 0.024041745346039534), (37, 0.02599820145405829), (10, 0.026167659554630518), (11, 0.028026720508933067), (4, 0.028626712504774332), (3, 0.03240096615627408), (13, 0.03292407561093569), (20, 0.03404330927878618), (51, 0.034166337456554174), (12, 0.03690121276304126), (52, 0.037114220671355724), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.04630646016448736), (14, 0.04730391362681985), (2, 0.05715902056545019), (0, 0.058882576413452625), (16, 0.05941258044913411), (5, 0.09224656596779823), (17, 0.23884584568440914), (36, 0.31504474207758904), (18, 0.4543862119317055), (53, 1.0337043851613998)]
computing accuracy for after removing block 40 . block score: 0.01920685893855989
removed block 40 current accuracy 0.9372 loss from initial  0.06279999999999997
since last training loss: 0.05719999999999992 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.018811. All blocks and scores: [(48, 0.01881053065881133), (46, 0.019371640868484974), (41, 0.019517680630087852), (43, 0.019623473985120654), (23, 0.01973944390192628), (22, 0.019956301897764206), (38, 0.019963711965829134), (8, 0.01996665494516492), (39, 0.020108413649722934), (50, 0.021321627078577876), (49, 0.021479649003595114), (42, 0.021748679224401712), (45, 0.022593647940084338), (21, 0.023317469283938408), (6, 0.024041746510192752), (37, 0.02599820145405829), (10, 0.02616765908896923), (11, 0.02802672074176371), (4, 0.02862671227194369), (51, 0.03205896238796413), (3, 0.03240096475929022), (13, 0.0329240751452744), (20, 0.034043310675770044), (52, 0.03687903797253966), (12, 0.036901213228702545), (9, 0.039344592951238155), (19, 0.04198857443407178), (15, 0.04630645923316479), (14, 0.047303914558142424), (2, 0.05715902196243405), (0, 0.0588825773447752), (16, 0.05941258044913411), (5, 0.09224656224250793), (17, 0.2388458475470543), (36, 0.31504473835229874), (18, 0.4543862044811249), (53, 1.1355613768100739)]
computing accuracy for after removing block 48 . block score: 0.01881053065881133
removed block 48 current accuracy 0.9258 loss from initial  0.07420000000000004
training start
training epoch 0 val accuracy 0.774 topk_dict {'top1': 0.774} is_best False lr [0.1]
training epoch 1 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 2 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 3 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 4 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 7 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.1]
training epoch 8 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.1]
training epoch 9 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 10 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.969400)
finished training. finished 50 epochs. accuracy 0.9694 topk_dict {'top1': 0.9694}
start iteration 18
[activation diff]: block to remove picked: 8, with score 0.036520. All blocks and scores: [(8, 0.03652040893211961), (50, 0.04044210631400347), (6, 0.04075614456087351), (41, 0.04326394107192755), (46, 0.04421496298164129), (49, 0.0449263877235353), (43, 0.04571018274873495), (42, 0.04830890381708741), (51, 0.04837476974353194), (45, 0.04838899848982692), (52, 0.04860695963725448), (39, 0.05020750081166625), (10, 0.05190028203651309), (4, 0.05201595975086093), (22, 0.05204929271712899), (13, 0.054767875000834465), (38, 0.056016755290329456), (23, 0.057987116277217865), (3, 0.05876645538955927), (11, 0.06070300890132785), (37, 0.06395718920975924), (21, 0.06606834568083286), (19, 0.06910295784473419), (12, 0.06933016050606966), (20, 0.0778527669608593), (9, 0.08113953750580549), (14, 0.0914071761071682), (15, 0.0988371754065156), (2, 0.10092068091034889), (0, 0.10121378675103188), (16, 0.11128688137978315), (5, 0.17853128165006638), (17, 0.4646754153072834), (18, 0.6299317926168442), (36, 0.7015234157443047), (53, 0.9446814954280853)]
computing accuracy for after removing block 8 . block score: 0.03652040893211961
removed block 8 current accuracy 0.9676 loss from initial  0.032399999999999984
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.039808. All blocks and scores: [(50, 0.039808227214962244), (6, 0.040756145026534796), (41, 0.042874724604189396), (46, 0.043871242087334394), (49, 0.044611649587750435), (43, 0.04509500553831458), (45, 0.04771131603047252), (51, 0.04775794502347708), (42, 0.04832415375858545), (52, 0.0483509786427021), (39, 0.049770524725317955), (22, 0.050419384613633156), (4, 0.05201595975086093), (10, 0.05402085045352578), (38, 0.054155390709638596), (23, 0.05578815843909979), (13, 0.0576537367887795), (3, 0.058766456320881844), (11, 0.06294744880869985), (37, 0.06312961596995592), (21, 0.06621770095080137), (19, 0.0668318597599864), (12, 0.068374196998775), (20, 0.07624006643891335), (9, 0.08422007877379656), (14, 0.08935391996055841), (15, 0.09815602749586105), (2, 0.10092068091034889), (0, 0.10121378675103188), (16, 0.11107594333589077), (5, 0.17853128165006638), (17, 0.4496259093284607), (18, 0.6193372085690498), (36, 0.6894373297691345), (53, 0.9351976960897446)]
computing accuracy for after removing block 50 . block score: 0.039808227214962244
removed block 50 current accuracy 0.9596 loss from initial  0.04039999999999999
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 6, with score 0.040756. All blocks and scores: [(6, 0.04075614549219608), (41, 0.042874724604189396), (46, 0.04387124069035053), (49, 0.044611649587750435), (43, 0.04509500414133072), (45, 0.04771131603047252), (42, 0.04832415375858545), (39, 0.04977052565664053), (22, 0.05041938554495573), (4, 0.052015958819538355), (52, 0.05354424798861146), (51, 0.053601608611643314), (10, 0.05402085091918707), (38, 0.054155392572283745), (23, 0.05578815843909979), (13, 0.05765373585745692), (3, 0.05876645678654313), (11, 0.0629474469460547), (37, 0.06312961596995592), (21, 0.0662177000194788), (19, 0.06683185882866383), (12, 0.06837419606745243), (20, 0.07624006923288107), (9, 0.08422007970511913), (14, 0.08935391996055841), (15, 0.09815602842718363), (2, 0.10092068277299404), (0, 0.10121378675103188), (16, 0.11107594054192305), (5, 0.17853127792477608), (17, 0.4496259205043316), (18, 0.6193372309207916), (36, 0.6894373595714569), (53, 1.1053486168384552)]
computing accuracy for after removing block 6 . block score: 0.04075614549219608
removed block 6 current accuracy 0.956 loss from initial  0.04400000000000004
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.042566. All blocks and scores: [(41, 0.04256561817601323), (46, 0.042850101832300425), (49, 0.043432001024484634), (43, 0.0440489137545228), (45, 0.04628009768202901), (42, 0.04748458741232753), (22, 0.047672814689576626), (39, 0.049030565191060305), (23, 0.05164224235340953), (38, 0.05185806239023805), (4, 0.052015960682183504), (51, 0.05209697503596544), (52, 0.053198513109236956), (10, 0.0549119682982564), (3, 0.05876645492389798), (37, 0.061478313989937305), (13, 0.06195042235776782), (19, 0.06329161208122969), (21, 0.06379380635917187), (11, 0.06503026187419891), (12, 0.06820840295404196), (20, 0.07265566941350698), (9, 0.08472934737801552), (14, 0.08926019538193941), (15, 0.10011176113039255), (2, 0.10092068277299404), (0, 0.1012137858197093), (16, 0.11307201068848372), (5, 0.17853128165006638), (17, 0.4505910836160183), (18, 0.6092899814248085), (36, 0.6754626482725143), (53, 1.0931716412305832)]
computing accuracy for after removing block 41 . block score: 0.04256561817601323
removed block 41 current accuracy 0.9496 loss from initial  0.0504
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.041097. All blocks and scores: [(49, 0.04109739372506738), (46, 0.04305412946268916), (43, 0.044950760900974274), (45, 0.04648799216374755), (22, 0.047672813292592764), (42, 0.04826266737654805), (39, 0.04903056658804417), (51, 0.05132155865430832), (23, 0.05164224375039339), (38, 0.05185806006193161), (4, 0.05201596021652222), (52, 0.05277913948521018), (10, 0.05491196922957897), (3, 0.05876645725220442), (37, 0.061478312592953444), (13, 0.061950423289090395), (19, 0.06329161208122969), (21, 0.06379380729049444), (11, 0.06503026373684406), (12, 0.06820840388536453), (20, 0.07265566941350698), (9, 0.08472934551537037), (14, 0.08926019258797169), (15, 0.1001117629930377), (2, 0.10092068091034889), (0, 0.10121378675103188), (16, 0.11307201161980629), (5, 0.17853128351271152), (17, 0.4505911022424698), (18, 0.6092899665236473), (36, 0.6754626557230949), (53, 1.1732040345668793)]
computing accuracy for after removing block 49 . block score: 0.04109739372506738
removed block 49 current accuracy 0.9384 loss from initial  0.06159999999999999
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 46, with score 0.043054. All blocks and scores: [(46, 0.043054128997027874), (43, 0.044950760900974274), (45, 0.046487993095070124), (22, 0.04767281282693148), (42, 0.048262668307870626), (39, 0.04903056658804417), (23, 0.05164224375039339), (38, 0.05185806332156062), (4, 0.05201595928519964), (10, 0.054911968763917685), (52, 0.05667901551350951), (51, 0.05748124094679952), (3, 0.058766456320881844), (37, 0.06147831305861473), (13, 0.06195042375475168), (19, 0.06329161114990711), (21, 0.06379380729049444), (11, 0.06503026280552149), (12, 0.06820840202271938), (20, 0.07265567220747471), (9, 0.08472935110330582), (14, 0.08926019631326199), (15, 0.100111766718328), (2, 0.10092068277299404), (0, 0.10121378488838673), (16, 0.11307201534509659), (5, 0.17853128351271152), (17, 0.4505910836160183), (18, 0.6092899665236473), (36, 0.6754626557230949), (53, 1.3045707643032074)]
computing accuracy for after removing block 46 . block score: 0.043054128997027874
removed block 46 current accuracy 0.9112 loss from initial  0.08879999999999999
since last training loss: 0.05820000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 43, with score 0.044951. All blocks and scores: [(43, 0.04495076136663556), (45, 0.046487992629408836), (22, 0.047672813292592764), (42, 0.04826266644522548), (39, 0.04903056565672159), (23, 0.051642242819070816), (38, 0.0518580605275929), (4, 0.05201595975086093), (10, 0.05491197109222412), (3, 0.058766457717865705), (52, 0.06047125440090895), (37, 0.06147831305861473), (51, 0.06169209908694029), (13, 0.06195042422041297), (19, 0.06329161021858454), (21, 0.06379380822181702), (11, 0.06503026187419891), (12, 0.06820839922875166), (20, 0.07265567127615213), (9, 0.08472934644669294), (14, 0.08926019445061684), (15, 0.10011176206171513), (2, 0.10092067997902632), (0, 0.10121378395706415), (16, 0.11307200882583857), (5, 0.17853128351271152), (17, 0.4505910873413086), (18, 0.6092899888753891), (36, 0.6754626557230949), (53, 1.3818269968032837)]
computing accuracy for after removing block 43 . block score: 0.04495076136663556
removed block 43 current accuracy 0.891 loss from initial  0.10899999999999999
since last training loss: 0.07840000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.047673. All blocks and scores: [(22, 0.04767281282693148), (42, 0.048262666910886765), (39, 0.04903056612238288), (45, 0.04908656561747193), (23, 0.0516422432847321), (38, 0.05185806192457676), (4, 0.052015958819538355), (10, 0.05491196922957897), (3, 0.058766455855220556), (52, 0.06137595046311617), (37, 0.06147831166163087), (13, 0.06195042282342911), (51, 0.06244396464899182), (19, 0.06329161208122969), (21, 0.06379380822181702), (11, 0.06503026373684406), (12, 0.06820840016007423), (20, 0.07265567127615213), (9, 0.08472935017198324), (14, 0.08926019445061684), (15, 0.10011176392436028), (2, 0.10092068091034889), (0, 0.10121378861367702), (16, 0.11307201161980629), (5, 0.17853127978742123), (17, 0.4505911022424698), (18, 0.6092899814248085), (36, 0.6754626408219337), (53, 1.4556703865528107)]
computing accuracy for after removing block 22 . block score: 0.04767281282693148
removed block 22 current accuracy 0.8806 loss from initial  0.11939999999999995
since last training loss: 0.08879999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.045235. All blocks and scores: [(42, 0.04523516446352005), (39, 0.04628500947728753), (45, 0.04805937688797712), (23, 0.04967487696558237), (38, 0.05032109608873725), (4, 0.05201595975086093), (10, 0.05491196922957897), (37, 0.05866092583164573), (3, 0.05876645678654313), (52, 0.060852676164358854), (51, 0.06144280033186078), (13, 0.06195042235776782), (19, 0.06329161208122969), (21, 0.06379380635917187), (11, 0.06503026280552149), (12, 0.06820840295404196), (20, 0.07265567127615213), (9, 0.08472934737801552), (14, 0.08926019724458456), (15, 0.10011176113039255), (2, 0.10092068184167147), (0, 0.10121378675103188), (16, 0.11307201255112886), (5, 0.17853127792477608), (17, 0.4505911096930504), (18, 0.6092899888753891), (36, 0.6480931490659714), (53, 1.4685791283845901)]
computing accuracy for after removing block 42 . block score: 0.04523516446352005
removed block 42 current accuracy 0.8506 loss from initial  0.14939999999999998
training start
training epoch 0 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 1 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.1]
training epoch 2 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 3 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 4 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.1]
training epoch 5 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 6 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 7 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 8 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 9 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 10 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.955400)
finished training. finished 50 epochs. accuracy 0.9554 topk_dict {'top1': 0.9554}
start iteration 27
[activation diff]: block to remove picked: 10, with score 0.061036. All blocks and scores: [(10, 0.061035582795739174), (4, 0.06267448794096708), (52, 0.06677403301000595), (38, 0.07211862318217754), (51, 0.07494756579399109), (13, 0.07613660953938961), (39, 0.07798507157713175), (37, 0.08051312994211912), (23, 0.08089346438646317), (3, 0.08148070145398378), (11, 0.08225770108401775), (45, 0.08526263665407896), (12, 0.08870338182896376), (21, 0.0911538889631629), (20, 0.09488633647561073), (19, 0.09556851536035538), (15, 0.10671140160411596), (0, 0.11577944364398718), (9, 0.11578181479126215), (2, 0.12164847739040852), (14, 0.1225514467805624), (16, 0.13045256957411766), (5, 0.2248254008591175), (17, 0.4590310715138912), (36, 0.6009732484817505), (18, 0.6382589042186737), (53, 1.028091549873352)]
computing accuracy for after removing block 10 . block score: 0.061035582795739174
removed block 10 current accuracy 0.955 loss from initial  0.04500000000000004
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 4, with score 0.062674. All blocks and scores: [(4, 0.06267448840662837), (52, 0.06580198835581541), (38, 0.06737412139773369), (51, 0.07272431533783674), (39, 0.0761158661916852), (23, 0.0764897083863616), (37, 0.07832372188568115), (13, 0.07941778283566236), (3, 0.08148070238530636), (45, 0.08288383949548006), (11, 0.08591207768768072), (21, 0.08807098492980003), (12, 0.08927546720951796), (19, 0.09112513530999422), (20, 0.09204832650721073), (15, 0.10571013111621141), (0, 0.11577943991869688), (9, 0.11578181106597185), (14, 0.12046405114233494), (2, 0.12164848111569881), (16, 0.13144290447235107), (5, 0.22482539899647236), (17, 0.4569951146841049), (36, 0.5832914710044861), (18, 0.6189803779125214), (53, 1.0332807898521423)]
computing accuracy for after removing block 4 . block score: 0.06267448840662837
removed block 4 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.064841. All blocks and scores: [(38, 0.06484086811542511), (52, 0.06497320625931025), (51, 0.07127947360277176), (23, 0.07328212633728981), (37, 0.07535026222467422), (39, 0.07607511710375547), (45, 0.08023694530129433), (3, 0.08148070517927408), (13, 0.08243290614336729), (11, 0.08320477977395058), (19, 0.08782846108078957), (21, 0.08919493574649096), (20, 0.09028510935604572), (12, 0.09175774548202753), (15, 0.10316725168377161), (9, 0.11010348331183195), (14, 0.11419560853391886), (0, 0.11577943805605173), (2, 0.12164847739040852), (16, 0.13068177364766598), (5, 0.23352025263011456), (17, 0.44377388805150986), (36, 0.5683445036411285), (18, 0.6157732829451561), (53, 1.0348691940307617)]
computing accuracy for after removing block 38 . block score: 0.06484086811542511
removed block 38 current accuracy 0.9362 loss from initial  0.06379999999999997
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.064355. All blocks and scores: [(52, 0.06435516756027937), (51, 0.06865696050226688), (23, 0.07328212633728981), (37, 0.07535026036202908), (45, 0.08121760096400976), (3, 0.08148069959133863), (13, 0.08243290707468987), (11, 0.08320478070527315), (19, 0.08782845921814442), (39, 0.08830147888511419), (21, 0.08919493667781353), (20, 0.09028511121869087), (12, 0.0917577464133501), (15, 0.10316725540906191), (9, 0.11010348051786423), (14, 0.11419560573995113), (0, 0.1157794389873743), (2, 0.12164847832173109), (16, 0.13068177737295628), (5, 0.23352025821805), (17, 0.44377389177680016), (36, 0.5683445110917091), (18, 0.6157732978463173), (53, 1.1410919576883316)]
computing accuracy for after removing block 52 . block score: 0.06435516756027937
removed block 52 current accuracy 0.8868 loss from initial  0.11319999999999997
since last training loss: 0.0686 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.068657. All blocks and scores: [(51, 0.06865696050226688), (23, 0.07328212726861238), (37, 0.07535026222467422), (45, 0.08121760282665491), (3, 0.08148070238530636), (13, 0.08243290986865759), (11, 0.08320477791130543), (19, 0.08782846108078957), (39, 0.08830147795379162), (21, 0.08919493574649096), (20, 0.09028510935604572), (12, 0.09175774548202753), (15, 0.10316725447773933), (9, 0.11010348424315453), (14, 0.11419560573995113), (0, 0.11577943805605173), (2, 0.12164848204702139), (16, 0.13068177923560143), (5, 0.23352025635540485), (17, 0.44377388060092926), (36, 0.5683445036411285), (18, 0.6157732680439949), (53, 0.8752784729003906)]
computing accuracy for after removing block 51 . block score: 0.06865696050226688
removed block 51 current accuracy 0.81 loss from initial  0.18999999999999995
since last training loss: 0.14539999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 23, with score 0.073282. All blocks and scores: [(23, 0.07328212633728981), (37, 0.07535026036202908), (45, 0.08121760096400976), (3, 0.08148070517927408), (13, 0.08243290800601244), (11, 0.08320477791130543), (19, 0.08782846201211214), (39, 0.08830147795379162), (21, 0.0891949338838458), (20, 0.09028510842472315), (12, 0.09175774361938238), (15, 0.10316725354641676), (9, 0.11010348331183195), (14, 0.11419560760259628), (0, 0.11577944178134203), (2, 0.12164847739040852), (16, 0.13068178109824657), (5, 0.23352025263011456), (17, 0.44377389177680016), (36, 0.5683445110917091), (18, 0.6157732978463173), (53, 0.8773260712623596)]
computing accuracy for after removing block 23 . block score: 0.07328212633728981
removed block 23 current accuracy 0.796 loss from initial  0.20399999999999996
since last training loss: 0.1594 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.078481. All blocks and scores: [(37, 0.07848098035901785), (3, 0.08148070331662893), (45, 0.08151247072964907), (13, 0.08243290986865759), (11, 0.083204778842628), (19, 0.08782846014946699), (21, 0.08919493481516838), (39, 0.08935535699129105), (20, 0.0902851102873683), (12, 0.09175774175673723), (15, 0.10316725261509418), (9, 0.11010347865521908), (14, 0.11419560667127371), (0, 0.11577943805605173), (2, 0.12164847925305367), (16, 0.13068177923560143), (5, 0.23352025263011456), (17, 0.44377389550209045), (36, 0.5847927778959274), (18, 0.6157732978463173), (53, 0.863411009311676)]
computing accuracy for after removing block 37 . block score: 0.07848098035901785
removed block 37 current accuracy 0.7668 loss from initial  0.23319999999999996
since last training loss: 0.1886 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 45, with score 0.076647. All blocks and scores: [(45, 0.07664746511727571), (3, 0.08148070145398378), (13, 0.08243291079998016), (11, 0.08320477977395058), (19, 0.08782846108078957), (21, 0.08919493667781353), (20, 0.0902851102873683), (12, 0.0917577464133501), (39, 0.10019847005605698), (15, 0.10316725447773933), (9, 0.1101034851744771), (14, 0.11419560853391886), (0, 0.11577944085001945), (2, 0.12164848204702139), (16, 0.13068178109824657), (5, 0.23352025821805), (17, 0.44377387687563896), (36, 0.5847927778959274), (18, 0.6157732978463173), (53, 0.8941016420722008)]
computing accuracy for after removing block 45 . block score: 0.07664746511727571
removed block 45 current accuracy 0.6438 loss from initial  0.35619999999999996
since last training loss: 0.3116 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.081481. All blocks and scores: [(3, 0.08148070331662893), (13, 0.08243291079998016), (11, 0.08320478443056345), (19, 0.08782846108078957), (21, 0.08919493667781353), (20, 0.0902851102873683), (12, 0.09175774455070496), (39, 0.1001984653994441), (15, 0.10316725447773933), (9, 0.11010348331183195), (14, 0.11419560667127371), (0, 0.1157794427126646), (2, 0.12164848297834396), (16, 0.13068177551031113), (5, 0.2335202507674694), (17, 0.44377389550209045), (36, 0.5847927555441856), (18, 0.6157732680439949), (53, 1.0032239630818367)]
computing accuracy for after removing block 3 . block score: 0.08148070331662893
removed block 3 current accuracy 0.5796 loss from initial  0.4204
since last training loss: 0.3758 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 11, with score 0.077874. All blocks and scores: [(11, 0.07787393033504486), (19, 0.08024877868592739), (20, 0.08042073342949152), (13, 0.08365983236581087), (21, 0.08445463981479406), (12, 0.08941565174609423), (39, 0.08948445413261652), (15, 0.0992084238678217), (14, 0.10862300638109446), (9, 0.11208907514810562), (0, 0.11577944178134203), (2, 0.12164848111569881), (16, 0.13201002962887287), (5, 0.24803244695067406), (17, 0.4315670616924763), (36, 0.5322818458080292), (18, 0.5813778415322304), (53, 0.9034941121935844)]
computing accuracy for after removing block 11 . block score: 0.07787393033504486
removed block 11 current accuracy 0.5668 loss from initial  0.43320000000000003
since last training loss: 0.38860000000000006 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 19, with score 0.074853. All blocks and scores: [(19, 0.07485310547053814), (21, 0.07681352272629738), (20, 0.07957747392356396), (39, 0.08394798636436462), (12, 0.09422795753926039), (13, 0.09546231105923653), (15, 0.10235036443918943), (14, 0.10754616744816303), (9, 0.11208906956017017), (0, 0.11577943991869688), (2, 0.12164848018437624), (16, 0.14366042613983154), (5, 0.24803245067596436), (17, 0.3989653214812279), (36, 0.5100159496068954), (18, 0.5592973902821541), (53, 0.8636971339583397)]
computing accuracy for after removing block 19 . block score: 0.07485310547053814
removed block 19 current accuracy 0.5374 loss from initial  0.4626
since last training loss: 0.41800000000000004 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 39, with score 0.077173. All blocks and scores: [(39, 0.07717310078442097), (21, 0.0795974126085639), (20, 0.08963998686522245), (12, 0.09422795753926039), (13, 0.09546231105923653), (15, 0.10235035978257656), (14, 0.10754617024213076), (9, 0.1120890686288476), (0, 0.11577944178134203), (2, 0.12164848297834396), (16, 0.1436604280024767), (5, 0.2480324488133192), (17, 0.3989653140306473), (36, 0.46707432344555855), (18, 0.5592973753809929), (53, 0.7510251253843307)]
computing accuracy for after removing block 39 . block score: 0.07717310078442097
removed block 39 current accuracy 0.439 loss from initial  0.5609999999999999
training start
training epoch 0 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best True lr [0.1]
training epoch 1 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best False lr [0.1]
training epoch 2 val accuracy 0.8166 topk_dict {'top1': 0.8166} is_best False lr [0.1]
training epoch 3 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best True lr [0.1]
training epoch 4 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 5 val accuracy 0.838 topk_dict {'top1': 0.838} is_best True lr [0.1]
training epoch 6 val accuracy 0.844 topk_dict {'top1': 0.844} is_best True lr [0.1]
training epoch 7 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 8 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 9 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 10 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.921000)
finished training. finished 50 epochs. accuracy 0.921 topk_dict {'top1': 0.921}
