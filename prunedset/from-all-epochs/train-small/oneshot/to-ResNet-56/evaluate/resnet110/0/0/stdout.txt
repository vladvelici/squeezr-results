start iteration 0
(cache recomputed) Accuracy log [(0, 0.148, {'top1': 0.148}), (1, 0.17, {'top1': 0.17}), (2, 0.1822, {'top1': 0.1822}), (3, 0.184, {'top1': 0.184}), (4, 0.1842, {'top1': 0.1842}), (5, 0.1834, {'top1': 0.1834}), (6, 0.186, {'top1': 0.186}), (7, 0.1894, {'top1': 0.1894}), (8, 0.1858, {'top1': 0.1858}), (9, 0.1824, {'top1': 0.1824}), (10, 0.1832, {'top1': 0.1832}), (11, 0.1862, {'top1': 0.1862}), (12, 0.1868, {'top1': 0.1868}), (13, 0.187, {'top1': 0.187}), (14, 0.1826, {'top1': 0.1826}), (15, 0.186, {'top1': 0.186}), (16, 0.1824, {'top1': 0.1824}), (17, 0.1824, {'top1': 0.1824}), (18, 0.1804, {'top1': 0.1804}), (19, 0.1798, {'top1': 0.1798}), (20, 0.1902, {'top1': 0.1902}), (21, 0.1878, {'top1': 0.1878}), (22, 0.189, {'top1': 0.189}), (23, 0.1816, {'top1': 0.1816}), (24, 0.1818, {'top1': 0.1818}), (25, 0.1826, {'top1': 0.1826}), (26, 0.1906, {'top1': 0.1906}), (27, 0.1854, {'top1': 0.1854}), (28, 0.186, {'top1': 0.186}), (29, 0.1852, {'top1': 0.1852}), (30, 0.1818, {'top1': 0.1818}), (31, 0.183, {'top1': 0.183}), (32, 0.1866, {'top1': 0.1866}), (33, 0.1868, {'top1': 0.1868}), (34, 0.1928, {'top1': 0.1928}), (35, 0.1834, {'top1': 0.1834}), (36, 0.1782, {'top1': 0.1782}), (37, 0.1822, {'top1': 0.1822}), (38, 0.1858, {'top1': 0.1858}), (39, 0.1848, {'top1': 0.1848}), (40, 0.1842, {'top1': 0.1842}), (41, 0.1826, {'top1': 0.1826}), (42, 0.1822, {'top1': 0.1822}), (43, 0.1838, {'top1': 0.1838}), (44, 0.1822, {'top1': 0.1822}), (45, 0.1838, {'top1': 0.1838}), (46, 0.1866, {'top1': 0.1866}), (47, 0.1796, {'top1': 0.1796}), (48, 0.1856, {'top1': 0.1856}), (49, 0.1838, {'top1': 0.1838}), (50, 0.1854, {'top1': 0.1854}), (51, 0.1846, {'top1': 0.1846}), (52, 0.1848, {'top1': 0.1848}), (53, 0.1388, {'top1': 0.1388})]
just computed impact of block 34 . accuracy after removing:  0.1928
removed block 34 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.1676, {'top1': 0.1676}), (1, 0.1792, {'top1': 0.1792}), (2, 0.1826, {'top1': 0.1826}), (3, 0.1866, {'top1': 0.1866}), (4, 0.1898, {'top1': 0.1898}), (5, 0.189, {'top1': 0.189}), (6, 0.1912, {'top1': 0.1912}), (7, 0.1926, {'top1': 0.1926}), (8, 0.1844, {'top1': 0.1844}), (9, 0.191, {'top1': 0.191}), (10, 0.1878, {'top1': 0.1878}), (11, 0.189, {'top1': 0.189}), (12, 0.1868, {'top1': 0.1868}), (13, 0.1932, {'top1': 0.1932}), (14, 0.19, {'top1': 0.19}), (15, 0.1918, {'top1': 0.1918}), (16, 0.1876, {'top1': 0.1876}), (17, 0.1888, {'top1': 0.1888}), (18, 0.143, {'top1': 0.143}), (19, 0.1868, {'top1': 0.1868}), (20, 0.1836, {'top1': 0.1836}), (21, 0.1826, {'top1': 0.1826}), (22, 0.1836, {'top1': 0.1836}), (23, 0.1862, {'top1': 0.1862}), (24, 0.1846, {'top1': 0.1846}), (25, 0.1904, {'top1': 0.1904}), (26, 0.1674, {'top1': 0.1674}), (27, 0.1922, {'top1': 0.1922}), (28, 0.1884, {'top1': 0.1884}), (29, 0.1912, {'top1': 0.1912}), (30, 0.1888, {'top1': 0.1888}), (31, 0.188, {'top1': 0.188}), (32, 0.1906, {'top1': 0.1906}), (33, 0.1916, {'top1': 0.1916}), (35, 0.1898, {'top1': 0.1898}), (36, 0.18, {'top1': 0.18}), (37, 0.1886, {'top1': 0.1886}), (38, 0.1928, {'top1': 0.1928}), (39, 0.1894, {'top1': 0.1894}), (40, 0.189, {'top1': 0.189}), (41, 0.1872, {'top1': 0.1872}), (42, 0.1864, {'top1': 0.1864}), (43, 0.1902, {'top1': 0.1902}), (44, 0.187, {'top1': 0.187}), (45, 0.187, {'top1': 0.187}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1858, {'top1': 0.1858}), (48, 0.1884, {'top1': 0.1884}), (49, 0.1898, {'top1': 0.1898}), (50, 0.1894, {'top1': 0.1894}), (51, 0.192, {'top1': 0.192}), (52, 0.1926, {'top1': 0.1926}), (53, 0.1362, {'top1': 0.1362})]
just computed impact of block 13 . accuracy after removing:  0.1932
removed block 13 current accuracy 0.1932 loss from initial  -0.008400000000000019
since last training loss: -0.008400000000000019 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.172, {'top1': 0.172}), (1, 0.1788, {'top1': 0.1788}), (2, 0.1828, {'top1': 0.1828}), (3, 0.1828, {'top1': 0.1828}), (4, 0.1876, {'top1': 0.1876}), (5, 0.1906, {'top1': 0.1906}), (6, 0.183, {'top1': 0.183}), (7, 0.1854, {'top1': 0.1854}), (8, 0.1806, {'top1': 0.1806}), (9, 0.1902, {'top1': 0.1902}), (10, 0.1894, {'top1': 0.1894}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1828, {'top1': 0.1828}), (14, 0.1896, {'top1': 0.1896}), (15, 0.1904, {'top1': 0.1904}), (16, 0.19, {'top1': 0.19}), (17, 0.19, {'top1': 0.19}), (18, 0.1396, {'top1': 0.1396}), (19, 0.1828, {'top1': 0.1828}), (20, 0.1812, {'top1': 0.1812}), (21, 0.1764, {'top1': 0.1764}), (22, 0.181, {'top1': 0.181}), (23, 0.1842, {'top1': 0.1842}), (24, 0.1874, {'top1': 0.1874}), (25, 0.1924, {'top1': 0.1924}), (26, 0.1626, {'top1': 0.1626}), (27, 0.1926, {'top1': 0.1926}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1868, {'top1': 0.1868}), (30, 0.1898, {'top1': 0.1898}), (31, 0.1876, {'top1': 0.1876}), (32, 0.1904, {'top1': 0.1904}), (33, 0.1936, {'top1': 0.1936}), (35, 0.1906, {'top1': 0.1906}), (36, 0.1746, {'top1': 0.1746}), (37, 0.185, {'top1': 0.185}), (38, 0.1906, {'top1': 0.1906}), (39, 0.189, {'top1': 0.189}), (40, 0.19, {'top1': 0.19}), (41, 0.1888, {'top1': 0.1888}), (42, 0.1878, {'top1': 0.1878}), (43, 0.1884, {'top1': 0.1884}), (44, 0.1874, {'top1': 0.1874}), (45, 0.1902, {'top1': 0.1902}), (46, 0.1904, {'top1': 0.1904}), (47, 0.1868, {'top1': 0.1868}), (48, 0.1922, {'top1': 0.1922}), (49, 0.1916, {'top1': 0.1916}), (50, 0.191, {'top1': 0.191}), (51, 0.193, {'top1': 0.193}), (52, 0.1912, {'top1': 0.1912}), (53, 0.1364, {'top1': 0.1364})]
just computed impact of block 33 . accuracy after removing:  0.1936
removed block 33 current accuracy 0.1936 loss from initial  -0.008800000000000002
since last training loss: -0.008800000000000002 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.1744, {'top1': 0.1744}), (1, 0.1782, {'top1': 0.1782}), (2, 0.1834, {'top1': 0.1834}), (3, 0.1838, {'top1': 0.1838}), (4, 0.1856, {'top1': 0.1856}), (5, 0.1892, {'top1': 0.1892}), (6, 0.1798, {'top1': 0.1798}), (7, 0.1856, {'top1': 0.1856}), (8, 0.1794, {'top1': 0.1794}), (9, 0.1926, {'top1': 0.1926}), (10, 0.19, {'top1': 0.19}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1822, {'top1': 0.1822}), (14, 0.1916, {'top1': 0.1916}), (15, 0.189, {'top1': 0.189}), (16, 0.1894, {'top1': 0.1894}), (17, 0.1884, {'top1': 0.1884}), (18, 0.1348, {'top1': 0.1348}), (19, 0.179, {'top1': 0.179}), (20, 0.182, {'top1': 0.182}), (21, 0.1744, {'top1': 0.1744}), (22, 0.1796, {'top1': 0.1796}), (23, 0.185, {'top1': 0.185}), (24, 0.1906, {'top1': 0.1906}), (25, 0.1924, {'top1': 0.1924}), (26, 0.1572, {'top1': 0.1572}), (27, 0.192, {'top1': 0.192}), (28, 0.1898, {'top1': 0.1898}), (29, 0.187, {'top1': 0.187}), (30, 0.188, {'top1': 0.188}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1864, {'top1': 0.1864}), (35, 0.1926, {'top1': 0.1926}), (36, 0.1758, {'top1': 0.1758}), (37, 0.1856, {'top1': 0.1856}), (38, 0.19, {'top1': 0.19}), (39, 0.1894, {'top1': 0.1894}), (40, 0.1916, {'top1': 0.1916}), (41, 0.19, {'top1': 0.19}), (42, 0.1894, {'top1': 0.1894}), (43, 0.1878, {'top1': 0.1878}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1904, {'top1': 0.1904}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1878, {'top1': 0.1878}), (48, 0.193, {'top1': 0.193}), (49, 0.1934, {'top1': 0.1934}), (50, 0.1912, {'top1': 0.1912}), (51, 0.1896, {'top1': 0.1896}), (52, 0.1916, {'top1': 0.1916}), (53, 0.1358, {'top1': 0.1358})]
just computed impact of block 49 . accuracy after removing:  0.1934
removed block 49 current accuracy 0.1934 loss from initial  -0.008599999999999997
since last training loss: -0.008599999999999997 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.177, {'top1': 0.177}), (1, 0.1794, {'top1': 0.1794}), (2, 0.1808, {'top1': 0.1808}), (3, 0.1822, {'top1': 0.1822}), (4, 0.1848, {'top1': 0.1848}), (5, 0.1892, {'top1': 0.1892}), (6, 0.182, {'top1': 0.182}), (7, 0.1856, {'top1': 0.1856}), (8, 0.179, {'top1': 0.179}), (9, 0.1938, {'top1': 0.1938}), (10, 0.192, {'top1': 0.192}), (11, 0.1834, {'top1': 0.1834}), (12, 0.1832, {'top1': 0.1832}), (14, 0.193, {'top1': 0.193}), (15, 0.1884, {'top1': 0.1884}), (16, 0.1894, {'top1': 0.1894}), (17, 0.185, {'top1': 0.185}), (18, 0.1294, {'top1': 0.1294}), (19, 0.1792, {'top1': 0.1792}), (20, 0.1764, {'top1': 0.1764}), (21, 0.173, {'top1': 0.173}), (22, 0.1784, {'top1': 0.1784}), (23, 0.1826, {'top1': 0.1826}), (24, 0.1914, {'top1': 0.1914}), (25, 0.1926, {'top1': 0.1926}), (26, 0.1498, {'top1': 0.1498}), (27, 0.1932, {'top1': 0.1932}), (28, 0.1908, {'top1': 0.1908}), (29, 0.1858, {'top1': 0.1858}), (30, 0.1864, {'top1': 0.1864}), (31, 0.189, {'top1': 0.189}), (32, 0.185, {'top1': 0.185}), (35, 0.1926, {'top1': 0.1926}), (36, 0.1752, {'top1': 0.1752}), (37, 0.1828, {'top1': 0.1828}), (38, 0.1894, {'top1': 0.1894}), (39, 0.1884, {'top1': 0.1884}), (40, 0.1924, {'top1': 0.1924}), (41, 0.1912, {'top1': 0.1912}), (42, 0.1896, {'top1': 0.1896}), (43, 0.1868, {'top1': 0.1868}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1904, {'top1': 0.1904}), (46, 0.19, {'top1': 0.19}), (47, 0.1868, {'top1': 0.1868}), (48, 0.1916, {'top1': 0.1916}), (50, 0.1896, {'top1': 0.1896}), (51, 0.1898, {'top1': 0.1898}), (52, 0.192, {'top1': 0.192}), (53, 0.1372, {'top1': 0.1372})]
just computed impact of block 9 . accuracy after removing:  0.1938
removed block 9 current accuracy 0.1938 loss from initial  -0.009000000000000008
since last training loss: -0.009000000000000008 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.171, {'top1': 0.171}), (1, 0.1818, {'top1': 0.1818}), (2, 0.1818, {'top1': 0.1818}), (3, 0.1812, {'top1': 0.1812}), (4, 0.1838, {'top1': 0.1838}), (5, 0.1886, {'top1': 0.1886}), (6, 0.1828, {'top1': 0.1828}), (7, 0.184, {'top1': 0.184}), (8, 0.179, {'top1': 0.179}), (10, 0.1896, {'top1': 0.1896}), (11, 0.184, {'top1': 0.184}), (12, 0.1816, {'top1': 0.1816}), (14, 0.1924, {'top1': 0.1924}), (15, 0.1876, {'top1': 0.1876}), (16, 0.189, {'top1': 0.189}), (17, 0.184, {'top1': 0.184}), (18, 0.126, {'top1': 0.126}), (19, 0.1796, {'top1': 0.1796}), (20, 0.1772, {'top1': 0.1772}), (21, 0.1716, {'top1': 0.1716}), (22, 0.1782, {'top1': 0.1782}), (23, 0.186, {'top1': 0.186}), (24, 0.1894, {'top1': 0.1894}), (25, 0.1922, {'top1': 0.1922}), (26, 0.1484, {'top1': 0.1484}), (27, 0.1938, {'top1': 0.1938}), (28, 0.1902, {'top1': 0.1902}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1868, {'top1': 0.1868}), (31, 0.1898, {'top1': 0.1898}), (32, 0.1866, {'top1': 0.1866}), (35, 0.192, {'top1': 0.192}), (36, 0.177, {'top1': 0.177}), (37, 0.1848, {'top1': 0.1848}), (38, 0.1892, {'top1': 0.1892}), (39, 0.1872, {'top1': 0.1872}), (40, 0.191, {'top1': 0.191}), (41, 0.189, {'top1': 0.189}), (42, 0.1898, {'top1': 0.1898}), (43, 0.1848, {'top1': 0.1848}), (44, 0.189, {'top1': 0.189}), (45, 0.1902, {'top1': 0.1902}), (46, 0.1882, {'top1': 0.1882}), (47, 0.1864, {'top1': 0.1864}), (48, 0.1928, {'top1': 0.1928}), (50, 0.1902, {'top1': 0.1902}), (51, 0.1942, {'top1': 0.1942}), (52, 0.191, {'top1': 0.191}), (53, 0.1344, {'top1': 0.1344})]
just computed impact of block 51 . accuracy after removing:  0.1942
removed block 51 current accuracy 0.1942 loss from initial  -0.00940000000000002
since last training loss: -0.00940000000000002 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.1714, {'top1': 0.1714}), (1, 0.181, {'top1': 0.181}), (2, 0.1818, {'top1': 0.1818}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1838, {'top1': 0.1838}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1804, {'top1': 0.1804}), (7, 0.1842, {'top1': 0.1842}), (8, 0.1802, {'top1': 0.1802}), (10, 0.1892, {'top1': 0.1892}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1824, {'top1': 0.1824}), (14, 0.1932, {'top1': 0.1932}), (15, 0.1874, {'top1': 0.1874}), (16, 0.1896, {'top1': 0.1896}), (17, 0.1848, {'top1': 0.1848}), (18, 0.1228, {'top1': 0.1228}), (19, 0.1792, {'top1': 0.1792}), (20, 0.1742, {'top1': 0.1742}), (21, 0.1698, {'top1': 0.1698}), (22, 0.1752, {'top1': 0.1752}), (23, 0.1874, {'top1': 0.1874}), (24, 0.191, {'top1': 0.191}), (25, 0.1936, {'top1': 0.1936}), (26, 0.1456, {'top1': 0.1456}), (27, 0.195, {'top1': 0.195}), (28, 0.1912, {'top1': 0.1912}), (29, 0.185, {'top1': 0.185}), (30, 0.19, {'top1': 0.19}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1846, {'top1': 0.1846}), (35, 0.1932, {'top1': 0.1932}), (36, 0.1746, {'top1': 0.1746}), (37, 0.1844, {'top1': 0.1844}), (38, 0.1916, {'top1': 0.1916}), (39, 0.1886, {'top1': 0.1886}), (40, 0.1906, {'top1': 0.1906}), (41, 0.1894, {'top1': 0.1894}), (42, 0.189, {'top1': 0.189}), (43, 0.1886, {'top1': 0.1886}), (44, 0.1908, {'top1': 0.1908}), (45, 0.19, {'top1': 0.19}), (46, 0.1902, {'top1': 0.1902}), (47, 0.1902, {'top1': 0.1902}), (48, 0.194, {'top1': 0.194}), (50, 0.19, {'top1': 0.19}), (52, 0.194, {'top1': 0.194}), (53, 0.136, {'top1': 0.136})]
just computed impact of block 27 . accuracy after removing:  0.195
removed block 27 current accuracy 0.195 loss from initial  -0.010200000000000015
since last training loss: -0.010200000000000015 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.169, {'top1': 0.169}), (1, 0.1822, {'top1': 0.1822}), (2, 0.1824, {'top1': 0.1824}), (3, 0.1816, {'top1': 0.1816}), (4, 0.1824, {'top1': 0.1824}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1806, {'top1': 0.1806}), (7, 0.1836, {'top1': 0.1836}), (8, 0.1796, {'top1': 0.1796}), (10, 0.1894, {'top1': 0.1894}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1822, {'top1': 0.1822}), (14, 0.1936, {'top1': 0.1936}), (15, 0.1888, {'top1': 0.1888}), (16, 0.189, {'top1': 0.189}), (17, 0.186, {'top1': 0.186}), (18, 0.121, {'top1': 0.121}), (19, 0.1802, {'top1': 0.1802}), (20, 0.175, {'top1': 0.175}), (21, 0.1722, {'top1': 0.1722}), (22, 0.1772, {'top1': 0.1772}), (23, 0.1858, {'top1': 0.1858}), (24, 0.1908, {'top1': 0.1908}), (25, 0.1934, {'top1': 0.1934}), (26, 0.1408, {'top1': 0.1408}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1862, {'top1': 0.1862}), (30, 0.1884, {'top1': 0.1884}), (31, 0.1926, {'top1': 0.1926}), (32, 0.1868, {'top1': 0.1868}), (35, 0.1924, {'top1': 0.1924}), (36, 0.1724, {'top1': 0.1724}), (37, 0.1846, {'top1': 0.1846}), (38, 0.191, {'top1': 0.191}), (39, 0.1906, {'top1': 0.1906}), (40, 0.1908, {'top1': 0.1908}), (41, 0.1894, {'top1': 0.1894}), (42, 0.1898, {'top1': 0.1898}), (43, 0.1914, {'top1': 0.1914}), (44, 0.191, {'top1': 0.191}), (45, 0.1922, {'top1': 0.1922}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1912, {'top1': 0.1912}), (48, 0.194, {'top1': 0.194}), (50, 0.1914, {'top1': 0.1914}), (52, 0.1936, {'top1': 0.1936}), (53, 0.1364, {'top1': 0.1364})]
just computed impact of block 48 . accuracy after removing:  0.194
removed block 48 current accuracy 0.194 loss from initial  -0.009200000000000014
since last training loss: -0.009200000000000014 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.1724, {'top1': 0.1724}), (1, 0.1792, {'top1': 0.1792}), (2, 0.1802, {'top1': 0.1802}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1816, {'top1': 0.1816}), (5, 0.188, {'top1': 0.188}), (6, 0.1786, {'top1': 0.1786}), (7, 0.183, {'top1': 0.183}), (8, 0.1748, {'top1': 0.1748}), (10, 0.1886, {'top1': 0.1886}), (11, 0.1816, {'top1': 0.1816}), (12, 0.1798, {'top1': 0.1798}), (14, 0.1938, {'top1': 0.1938}), (15, 0.1852, {'top1': 0.1852}), (16, 0.1922, {'top1': 0.1922}), (17, 0.1828, {'top1': 0.1828}), (18, 0.1138, {'top1': 0.1138}), (19, 0.179, {'top1': 0.179}), (20, 0.169, {'top1': 0.169}), (21, 0.1698, {'top1': 0.1698}), (22, 0.1732, {'top1': 0.1732}), (23, 0.1822, {'top1': 0.1822}), (24, 0.1892, {'top1': 0.1892}), (25, 0.1916, {'top1': 0.1916}), (26, 0.1354, {'top1': 0.1354}), (28, 0.1902, {'top1': 0.1902}), (29, 0.181, {'top1': 0.181}), (30, 0.1842, {'top1': 0.1842}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1824, {'top1': 0.1824}), (35, 0.1932, {'top1': 0.1932}), (36, 0.1664, {'top1': 0.1664}), (37, 0.182, {'top1': 0.182}), (38, 0.1862, {'top1': 0.1862}), (39, 0.1848, {'top1': 0.1848}), (40, 0.1948, {'top1': 0.1948}), (41, 0.1944, {'top1': 0.1944}), (42, 0.1938, {'top1': 0.1938}), (43, 0.1864, {'top1': 0.1864}), (44, 0.1924, {'top1': 0.1924}), (45, 0.1896, {'top1': 0.1896}), (46, 0.187, {'top1': 0.187}), (47, 0.1946, {'top1': 0.1946}), (50, 0.1888, {'top1': 0.1888}), (52, 0.188, {'top1': 0.188}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 40 . accuracy after removing:  0.1948
removed block 40 current accuracy 0.1948 loss from initial  -0.010000000000000009
since last training loss: -0.010000000000000009 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.1814, {'top1': 0.1814}), (2, 0.181, {'top1': 0.181}), (3, 0.1824, {'top1': 0.1824}), (4, 0.1818, {'top1': 0.1818}), (5, 0.19, {'top1': 0.19}), (6, 0.18, {'top1': 0.18}), (7, 0.1838, {'top1': 0.1838}), (8, 0.18, {'top1': 0.18}), (10, 0.19, {'top1': 0.19}), (11, 0.1828, {'top1': 0.1828}), (12, 0.1826, {'top1': 0.1826}), (14, 0.194, {'top1': 0.194}), (15, 0.1896, {'top1': 0.1896}), (16, 0.1898, {'top1': 0.1898}), (17, 0.1874, {'top1': 0.1874}), (18, 0.1212, {'top1': 0.1212}), (19, 0.1822, {'top1': 0.1822}), (20, 0.177, {'top1': 0.177}), (21, 0.1706, {'top1': 0.1706}), (22, 0.1766, {'top1': 0.1766}), (23, 0.187, {'top1': 0.187}), (24, 0.1912, {'top1': 0.1912}), (25, 0.1948, {'top1': 0.1948}), (26, 0.1438, {'top1': 0.1438}), (28, 0.1902, {'top1': 0.1902}), (29, 0.1862, {'top1': 0.1862}), (30, 0.189, {'top1': 0.189}), (31, 0.1926, {'top1': 0.1926}), (32, 0.1886, {'top1': 0.1886}), (35, 0.1922, {'top1': 0.1922}), (36, 0.1728, {'top1': 0.1728}), (37, 0.187, {'top1': 0.187}), (38, 0.1906, {'top1': 0.1906}), (39, 0.1882, {'top1': 0.1882}), (41, 0.1908, {'top1': 0.1908}), (42, 0.1906, {'top1': 0.1906}), (43, 0.1904, {'top1': 0.1904}), (44, 0.1904, {'top1': 0.1904}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1912, {'top1': 0.1912}), (47, 0.193, {'top1': 0.193}), (50, 0.191, {'top1': 0.191}), (52, 0.1918, {'top1': 0.1918}), (53, 0.1352, {'top1': 0.1352})]
just computed impact of block 25 . accuracy after removing:  0.1948
removed block 25 current accuracy 0.1948 loss from initial  -0.010000000000000009
since last training loss: -0.010000000000000009 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.1808, {'top1': 0.1808}), (2, 0.181, {'top1': 0.181}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1812, {'top1': 0.1812}), (5, 0.1888, {'top1': 0.1888}), (6, 0.1812, {'top1': 0.1812}), (7, 0.1832, {'top1': 0.1832}), (8, 0.1796, {'top1': 0.1796}), (10, 0.1898, {'top1': 0.1898}), (11, 0.182, {'top1': 0.182}), (12, 0.1812, {'top1': 0.1812}), (14, 0.192, {'top1': 0.192}), (15, 0.1908, {'top1': 0.1908}), (16, 0.188, {'top1': 0.188}), (17, 0.1858, {'top1': 0.1858}), (18, 0.1164, {'top1': 0.1164}), (19, 0.181, {'top1': 0.181}), (20, 0.1712, {'top1': 0.1712}), (21, 0.169, {'top1': 0.169}), (22, 0.1744, {'top1': 0.1744}), (23, 0.184, {'top1': 0.184}), (24, 0.1896, {'top1': 0.1896}), (26, 0.134, {'top1': 0.134}), (28, 0.191, {'top1': 0.191}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1828, {'top1': 0.1828}), (35, 0.194, {'top1': 0.194}), (36, 0.172, {'top1': 0.172}), (37, 0.1852, {'top1': 0.1852}), (38, 0.1888, {'top1': 0.1888}), (39, 0.189, {'top1': 0.189}), (41, 0.1898, {'top1': 0.1898}), (42, 0.1898, {'top1': 0.1898}), (43, 0.19, {'top1': 0.19}), (44, 0.1902, {'top1': 0.1902}), (45, 0.1898, {'top1': 0.1898}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1906, {'top1': 0.1906}), (50, 0.189, {'top1': 0.189}), (52, 0.1906, {'top1': 0.1906}), (53, 0.135, {'top1': 0.135})]
just computed impact of block 35 . accuracy after removing:  0.194
removed block 35 current accuracy 0.194 loss from initial  -0.009200000000000014
since last training loss: -0.009200000000000014 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.1694, {'top1': 0.1694}), (1, 0.1834, {'top1': 0.1834}), (2, 0.1822, {'top1': 0.1822}), (3, 0.1842, {'top1': 0.1842}), (4, 0.1852, {'top1': 0.1852}), (5, 0.1904, {'top1': 0.1904}), (6, 0.1818, {'top1': 0.1818}), (7, 0.1844, {'top1': 0.1844}), (8, 0.1802, {'top1': 0.1802}), (10, 0.1914, {'top1': 0.1914}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1812, {'top1': 0.1812}), (14, 0.1906, {'top1': 0.1906}), (15, 0.1886, {'top1': 0.1886}), (16, 0.1892, {'top1': 0.1892}), (17, 0.1872, {'top1': 0.1872}), (18, 0.1214, {'top1': 0.1214}), (19, 0.1824, {'top1': 0.1824}), (20, 0.1768, {'top1': 0.1768}), (21, 0.1736, {'top1': 0.1736}), (22, 0.1812, {'top1': 0.1812}), (23, 0.1862, {'top1': 0.1862}), (24, 0.1902, {'top1': 0.1902}), (26, 0.14, {'top1': 0.14}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1866, {'top1': 0.1866}), (30, 0.1878, {'top1': 0.1878}), (31, 0.1918, {'top1': 0.1918}), (32, 0.1864, {'top1': 0.1864}), (36, 0.1762, {'top1': 0.1762}), (37, 0.1882, {'top1': 0.1882}), (38, 0.189, {'top1': 0.189}), (39, 0.1886, {'top1': 0.1886}), (41, 0.1916, {'top1': 0.1916}), (42, 0.1918, {'top1': 0.1918}), (43, 0.1894, {'top1': 0.1894}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1914, {'top1': 0.1914}), (47, 0.1896, {'top1': 0.1896}), (50, 0.1926, {'top1': 0.1926}), (52, 0.192, {'top1': 0.192}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 50 . accuracy after removing:  0.1926
removed block 50 current accuracy 0.1926 loss from initial  -0.007800000000000001
since last training loss: -0.007800000000000001 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.17, {'top1': 0.17}), (1, 0.1794, {'top1': 0.1794}), (2, 0.1832, {'top1': 0.1832}), (3, 0.1786, {'top1': 0.1786}), (4, 0.1804, {'top1': 0.1804}), (5, 0.1878, {'top1': 0.1878}), (6, 0.177, {'top1': 0.177}), (7, 0.179, {'top1': 0.179}), (8, 0.172, {'top1': 0.172}), (10, 0.1888, {'top1': 0.1888}), (11, 0.1806, {'top1': 0.1806}), (12, 0.1794, {'top1': 0.1794}), (14, 0.1914, {'top1': 0.1914}), (15, 0.1826, {'top1': 0.1826}), (16, 0.1908, {'top1': 0.1908}), (17, 0.1802, {'top1': 0.1802}), (18, 0.112, {'top1': 0.112}), (19, 0.1796, {'top1': 0.1796}), (20, 0.1644, {'top1': 0.1644}), (21, 0.162, {'top1': 0.162}), (22, 0.1734, {'top1': 0.1734}), (23, 0.179, {'top1': 0.179}), (24, 0.189, {'top1': 0.189}), (26, 0.127, {'top1': 0.127}), (28, 0.186, {'top1': 0.186}), (29, 0.1772, {'top1': 0.1772}), (30, 0.1792, {'top1': 0.1792}), (31, 0.1882, {'top1': 0.1882}), (32, 0.1764, {'top1': 0.1764}), (36, 0.1638, {'top1': 0.1638}), (37, 0.18, {'top1': 0.18}), (38, 0.1834, {'top1': 0.1834}), (39, 0.1844, {'top1': 0.1844}), (41, 0.1936, {'top1': 0.1936}), (42, 0.1938, {'top1': 0.1938}), (43, 0.185, {'top1': 0.185}), (44, 0.193, {'top1': 0.193}), (45, 0.187, {'top1': 0.187}), (46, 0.186, {'top1': 0.186}), (47, 0.193, {'top1': 0.193}), (52, 0.1866, {'top1': 0.1866}), (53, 0.1338, {'top1': 0.1338})]
just computed impact of block 42 . accuracy after removing:  0.1938
removed block 42 current accuracy 0.1938 loss from initial  -0.009000000000000008
since last training loss: -0.009000000000000008 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.1714, {'top1': 0.1714}), (1, 0.1808, {'top1': 0.1808}), (2, 0.1804, {'top1': 0.1804}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1816, {'top1': 0.1816}), (5, 0.19, {'top1': 0.19}), (6, 0.18, {'top1': 0.18}), (7, 0.1826, {'top1': 0.1826}), (8, 0.1786, {'top1': 0.1786}), (10, 0.1896, {'top1': 0.1896}), (11, 0.1804, {'top1': 0.1804}), (12, 0.1794, {'top1': 0.1794}), (14, 0.1928, {'top1': 0.1928}), (15, 0.1848, {'top1': 0.1848}), (16, 0.1892, {'top1': 0.1892}), (17, 0.1824, {'top1': 0.1824}), (18, 0.1156, {'top1': 0.1156}), (19, 0.1812, {'top1': 0.1812}), (20, 0.1728, {'top1': 0.1728}), (21, 0.1692, {'top1': 0.1692}), (22, 0.178, {'top1': 0.178}), (23, 0.1836, {'top1': 0.1836}), (24, 0.1898, {'top1': 0.1898}), (26, 0.1342, {'top1': 0.1342}), (28, 0.1904, {'top1': 0.1904}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1834, {'top1': 0.1834}), (31, 0.191, {'top1': 0.191}), (32, 0.181, {'top1': 0.181}), (36, 0.1706, {'top1': 0.1706}), (37, 0.1866, {'top1': 0.1866}), (38, 0.188, {'top1': 0.188}), (39, 0.1874, {'top1': 0.1874}), (41, 0.1908, {'top1': 0.1908}), (43, 0.1872, {'top1': 0.1872}), (44, 0.1906, {'top1': 0.1906}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1892, {'top1': 0.1892}), (47, 0.1918, {'top1': 0.1918}), (52, 0.189, {'top1': 0.189}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 14 . accuracy after removing:  0.1928
removed block 14 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.1646, {'top1': 0.1646}), (1, 0.184, {'top1': 0.184}), (2, 0.1842, {'top1': 0.1842}), (3, 0.183, {'top1': 0.183}), (4, 0.1854, {'top1': 0.1854}), (5, 0.1902, {'top1': 0.1902}), (6, 0.1822, {'top1': 0.1822}), (7, 0.1828, {'top1': 0.1828}), (8, 0.1798, {'top1': 0.1798}), (10, 0.191, {'top1': 0.191}), (11, 0.186, {'top1': 0.186}), (12, 0.1792, {'top1': 0.1792}), (15, 0.1884, {'top1': 0.1884}), (16, 0.189, {'top1': 0.189}), (17, 0.1874, {'top1': 0.1874}), (18, 0.1128, {'top1': 0.1128}), (19, 0.1824, {'top1': 0.1824}), (20, 0.1718, {'top1': 0.1718}), (21, 0.1714, {'top1': 0.1714}), (22, 0.177, {'top1': 0.177}), (23, 0.1842, {'top1': 0.1842}), (24, 0.1868, {'top1': 0.1868}), (26, 0.1348, {'top1': 0.1348}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1858, {'top1': 0.1858}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1902, {'top1': 0.1902}), (32, 0.1844, {'top1': 0.1844}), (36, 0.1738, {'top1': 0.1738}), (37, 0.1866, {'top1': 0.1866}), (38, 0.187, {'top1': 0.187}), (39, 0.188, {'top1': 0.188}), (41, 0.1898, {'top1': 0.1898}), (43, 0.1878, {'top1': 0.1878}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1908, {'top1': 0.1908}), (46, 0.1904, {'top1': 0.1904}), (47, 0.1906, {'top1': 0.1906}), (52, 0.1912, {'top1': 0.1912}), (53, 0.1354, {'top1': 0.1354})]
just computed impact of block 28 . accuracy after removing:  0.1916
removed block 28 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.167, {'top1': 0.167}), (1, 0.1762, {'top1': 0.1762}), (2, 0.1798, {'top1': 0.1798}), (3, 0.1782, {'top1': 0.1782}), (4, 0.1766, {'top1': 0.1766}), (5, 0.1818, {'top1': 0.1818}), (6, 0.1742, {'top1': 0.1742}), (7, 0.1804, {'top1': 0.1804}), (8, 0.1714, {'top1': 0.1714}), (10, 0.1858, {'top1': 0.1858}), (11, 0.179, {'top1': 0.179}), (12, 0.1732, {'top1': 0.1732}), (15, 0.1828, {'top1': 0.1828}), (16, 0.1886, {'top1': 0.1886}), (17, 0.179, {'top1': 0.179}), (18, 0.1112, {'top1': 0.1112}), (19, 0.174, {'top1': 0.174}), (20, 0.1568, {'top1': 0.1568}), (21, 0.1578, {'top1': 0.1578}), (22, 0.166, {'top1': 0.166}), (23, 0.1772, {'top1': 0.1772}), (24, 0.1908, {'top1': 0.1908}), (26, 0.1222, {'top1': 0.1222}), (29, 0.1772, {'top1': 0.1772}), (30, 0.1764, {'top1': 0.1764}), (31, 0.1868, {'top1': 0.1868}), (32, 0.169, {'top1': 0.169}), (36, 0.1642, {'top1': 0.1642}), (37, 0.177, {'top1': 0.177}), (38, 0.1808, {'top1': 0.1808}), (39, 0.1806, {'top1': 0.1806}), (41, 0.1936, {'top1': 0.1936}), (43, 0.1808, {'top1': 0.1808}), (44, 0.1926, {'top1': 0.1926}), (45, 0.185, {'top1': 0.185}), (46, 0.1828, {'top1': 0.1828}), (47, 0.1922, {'top1': 0.1922}), (52, 0.1878, {'top1': 0.1878}), (53, 0.1342, {'top1': 0.1342})]
just computed impact of block 41 . accuracy after removing:  0.1936
removed block 41 current accuracy 0.1936 loss from initial  -0.008800000000000002
since last training loss: -0.008800000000000002 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.181, {'top1': 0.181}), (2, 0.1806, {'top1': 0.1806}), (3, 0.1796, {'top1': 0.1796}), (4, 0.1804, {'top1': 0.1804}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1772, {'top1': 0.1772}), (7, 0.1814, {'top1': 0.1814}), (8, 0.1762, {'top1': 0.1762}), (10, 0.1876, {'top1': 0.1876}), (11, 0.1818, {'top1': 0.1818}), (12, 0.1764, {'top1': 0.1764}), (15, 0.185, {'top1': 0.185}), (16, 0.189, {'top1': 0.189}), (17, 0.185, {'top1': 0.185}), (18, 0.115, {'top1': 0.115}), (19, 0.1774, {'top1': 0.1774}), (20, 0.165, {'top1': 0.165}), (21, 0.1662, {'top1': 0.1662}), (22, 0.1724, {'top1': 0.1724}), (23, 0.1822, {'top1': 0.1822}), (24, 0.1908, {'top1': 0.1908}), (26, 0.1252, {'top1': 0.1252}), (29, 0.184, {'top1': 0.184}), (30, 0.1798, {'top1': 0.1798}), (31, 0.1914, {'top1': 0.1914}), (32, 0.1776, {'top1': 0.1776}), (36, 0.1742, {'top1': 0.1742}), (37, 0.1838, {'top1': 0.1838}), (38, 0.187, {'top1': 0.187}), (39, 0.1868, {'top1': 0.1868}), (43, 0.1872, {'top1': 0.1872}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1886, {'top1': 0.1886}), (46, 0.1896, {'top1': 0.1896}), (47, 0.1916, {'top1': 0.1916}), (52, 0.1886, {'top1': 0.1886}), (53, 0.135, {'top1': 0.135})]
just computed impact of block 47 . accuracy after removing:  0.1916
removed block 47 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.165, {'top1': 0.165}), (1, 0.18, {'top1': 0.18}), (2, 0.1822, {'top1': 0.1822}), (3, 0.181, {'top1': 0.181}), (4, 0.1822, {'top1': 0.1822}), (5, 0.1868, {'top1': 0.1868}), (6, 0.1778, {'top1': 0.1778}), (7, 0.183, {'top1': 0.183}), (8, 0.1768, {'top1': 0.1768}), (10, 0.189, {'top1': 0.189}), (11, 0.1854, {'top1': 0.1854}), (12, 0.1778, {'top1': 0.1778}), (15, 0.1884, {'top1': 0.1884}), (16, 0.1888, {'top1': 0.1888}), (17, 0.1876, {'top1': 0.1876}), (18, 0.117, {'top1': 0.117}), (19, 0.1808, {'top1': 0.1808}), (20, 0.169, {'top1': 0.169}), (21, 0.1708, {'top1': 0.1708}), (22, 0.1752, {'top1': 0.1752}), (23, 0.1854, {'top1': 0.1854}), (24, 0.1852, {'top1': 0.1852}), (26, 0.1288, {'top1': 0.1288}), (29, 0.186, {'top1': 0.186}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1898, {'top1': 0.1898}), (32, 0.1844, {'top1': 0.1844}), (36, 0.1796, {'top1': 0.1796}), (37, 0.1848, {'top1': 0.1848}), (38, 0.1894, {'top1': 0.1894}), (39, 0.1906, {'top1': 0.1906}), (43, 0.1896, {'top1': 0.1896}), (44, 0.1924, {'top1': 0.1924}), (45, 0.1926, {'top1': 0.1926}), (46, 0.1916, {'top1': 0.1916}), (52, 0.1928, {'top1': 0.1928}), (53, 0.1274, {'top1': 0.1274})]
just computed impact of block 52 . accuracy after removing:  0.1928
removed block 52 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.1674, {'top1': 0.1674}), (1, 0.1796, {'top1': 0.1796}), (2, 0.18, {'top1': 0.18}), (3, 0.18, {'top1': 0.18}), (4, 0.1822, {'top1': 0.1822}), (5, 0.186, {'top1': 0.186}), (6, 0.1756, {'top1': 0.1756}), (7, 0.1806, {'top1': 0.1806}), (8, 0.1736, {'top1': 0.1736}), (10, 0.1888, {'top1': 0.1888}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1768, {'top1': 0.1768}), (15, 0.1848, {'top1': 0.1848}), (16, 0.1916, {'top1': 0.1916}), (17, 0.1816, {'top1': 0.1816}), (18, 0.1138, {'top1': 0.1138}), (19, 0.1778, {'top1': 0.1778}), (20, 0.1596, {'top1': 0.1596}), (21, 0.1618, {'top1': 0.1618}), (22, 0.168, {'top1': 0.168}), (23, 0.1832, {'top1': 0.1832}), (24, 0.1902, {'top1': 0.1902}), (26, 0.1234, {'top1': 0.1234}), (29, 0.1842, {'top1': 0.1842}), (30, 0.1802, {'top1': 0.1802}), (31, 0.1912, {'top1': 0.1912}), (32, 0.1768, {'top1': 0.1768}), (36, 0.169, {'top1': 0.169}), (37, 0.182, {'top1': 0.182}), (38, 0.1842, {'top1': 0.1842}), (39, 0.1856, {'top1': 0.1856}), (43, 0.1858, {'top1': 0.1858}), (44, 0.1916, {'top1': 0.1916}), (45, 0.1876, {'top1': 0.1876}), (46, 0.1868, {'top1': 0.1868}), (53, 0.117, {'top1': 0.117})]
just computed impact of block 16 . accuracy after removing:  0.1916
removed block 16 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.1676, {'top1': 0.1676}), (1, 0.178, {'top1': 0.178}), (2, 0.1778, {'top1': 0.1778}), (3, 0.1804, {'top1': 0.1804}), (4, 0.179, {'top1': 0.179}), (5, 0.1862, {'top1': 0.1862}), (6, 0.1778, {'top1': 0.1778}), (7, 0.1808, {'top1': 0.1808}), (8, 0.1766, {'top1': 0.1766}), (10, 0.1876, {'top1': 0.1876}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1758, {'top1': 0.1758}), (15, 0.1868, {'top1': 0.1868}), (17, 0.1888, {'top1': 0.1888}), (18, 0.112, {'top1': 0.112}), (19, 0.1766, {'top1': 0.1766}), (20, 0.1614, {'top1': 0.1614}), (21, 0.1628, {'top1': 0.1628}), (22, 0.1716, {'top1': 0.1716}), (23, 0.1816, {'top1': 0.1816}), (24, 0.1866, {'top1': 0.1866}), (26, 0.124, {'top1': 0.124}), (29, 0.1832, {'top1': 0.1832}), (30, 0.1826, {'top1': 0.1826}), (31, 0.1892, {'top1': 0.1892}), (32, 0.1766, {'top1': 0.1766}), (36, 0.1742, {'top1': 0.1742}), (37, 0.1828, {'top1': 0.1828}), (38, 0.184, {'top1': 0.184}), (39, 0.1854, {'top1': 0.1854}), (43, 0.1848, {'top1': 0.1848}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1838, {'top1': 0.1838}), (46, 0.1836, {'top1': 0.1836}), (53, 0.1142, {'top1': 0.1142})]
just computed impact of block 31 . accuracy after removing:  0.1892
removed block 31 current accuracy 0.1892 loss from initial  -0.004400000000000015
since last training loss: -0.004400000000000015 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.1662, {'top1': 0.1662}), (1, 0.1802, {'top1': 0.1802}), (2, 0.1808, {'top1': 0.1808}), (3, 0.1788, {'top1': 0.1788}), (4, 0.179, {'top1': 0.179}), (5, 0.1848, {'top1': 0.1848}), (6, 0.1768, {'top1': 0.1768}), (7, 0.1788, {'top1': 0.1788}), (8, 0.1776, {'top1': 0.1776}), (10, 0.1886, {'top1': 0.1886}), (11, 0.1824, {'top1': 0.1824}), (12, 0.1746, {'top1': 0.1746}), (15, 0.184, {'top1': 0.184}), (17, 0.187, {'top1': 0.187}), (18, 0.112, {'top1': 0.112}), (19, 0.1744, {'top1': 0.1744}), (20, 0.1612, {'top1': 0.1612}), (21, 0.1612, {'top1': 0.1612}), (22, 0.1698, {'top1': 0.1698}), (23, 0.1802, {'top1': 0.1802}), (24, 0.1884, {'top1': 0.1884}), (26, 0.123, {'top1': 0.123}), (29, 0.1788, {'top1': 0.1788}), (30, 0.1804, {'top1': 0.1804}), (32, 0.174, {'top1': 0.174}), (36, 0.1682, {'top1': 0.1682}), (37, 0.1798, {'top1': 0.1798}), (38, 0.1824, {'top1': 0.1824}), (39, 0.1832, {'top1': 0.1832}), (43, 0.1816, {'top1': 0.1816}), (44, 0.1906, {'top1': 0.1906}), (45, 0.1846, {'top1': 0.1846}), (46, 0.1832, {'top1': 0.1832}), (53, 0.1136, {'top1': 0.1136})]
just computed impact of block 44 . accuracy after removing:  0.1906
removed block 44 current accuracy 0.1906 loss from initial  -0.0058
since last training loss: -0.0058 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.1674, {'top1': 0.1674}), (1, 0.1776, {'top1': 0.1776}), (2, 0.1784, {'top1': 0.1784}), (3, 0.1808, {'top1': 0.1808}), (4, 0.1794, {'top1': 0.1794}), (5, 0.1894, {'top1': 0.1894}), (6, 0.1818, {'top1': 0.1818}), (7, 0.1804, {'top1': 0.1804}), (8, 0.176, {'top1': 0.176}), (10, 0.1912, {'top1': 0.1912}), (11, 0.1848, {'top1': 0.1848}), (12, 0.1804, {'top1': 0.1804}), (15, 0.1864, {'top1': 0.1864}), (17, 0.1902, {'top1': 0.1902}), (18, 0.1154, {'top1': 0.1154}), (19, 0.1744, {'top1': 0.1744}), (20, 0.1656, {'top1': 0.1656}), (21, 0.1664, {'top1': 0.1664}), (22, 0.1714, {'top1': 0.1714}), (23, 0.1802, {'top1': 0.1802}), (24, 0.1868, {'top1': 0.1868}), (26, 0.1282, {'top1': 0.1282}), (29, 0.182, {'top1': 0.182}), (30, 0.1828, {'top1': 0.1828}), (32, 0.181, {'top1': 0.181}), (36, 0.1746, {'top1': 0.1746}), (37, 0.1778, {'top1': 0.1778}), (38, 0.1838, {'top1': 0.1838}), (39, 0.185, {'top1': 0.185}), (43, 0.185, {'top1': 0.185}), (45, 0.1844, {'top1': 0.1844}), (46, 0.1842, {'top1': 0.1842}), (53, 0.1094, {'top1': 0.1094})]
just computed impact of block 10 . accuracy after removing:  0.1912
removed block 10 current accuracy 0.1912 loss from initial  -0.006400000000000017
since last training loss: -0.006400000000000017 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.1664, {'top1': 0.1664}), (1, 0.1784, {'top1': 0.1784}), (2, 0.178, {'top1': 0.178}), (3, 0.1808, {'top1': 0.1808}), (4, 0.182, {'top1': 0.182}), (5, 0.1846, {'top1': 0.1846}), (6, 0.1762, {'top1': 0.1762}), (7, 0.1804, {'top1': 0.1804}), (8, 0.1714, {'top1': 0.1714}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1752, {'top1': 0.1752}), (15, 0.1866, {'top1': 0.1866}), (17, 0.1886, {'top1': 0.1886}), (18, 0.1128, {'top1': 0.1128}), (19, 0.1762, {'top1': 0.1762}), (20, 0.1598, {'top1': 0.1598}), (21, 0.1622, {'top1': 0.1622}), (22, 0.166, {'top1': 0.166}), (23, 0.1806, {'top1': 0.1806}), (24, 0.1856, {'top1': 0.1856}), (26, 0.1252, {'top1': 0.1252}), (29, 0.1826, {'top1': 0.1826}), (30, 0.1812, {'top1': 0.1812}), (32, 0.1788, {'top1': 0.1788}), (36, 0.1712, {'top1': 0.1712}), (37, 0.1816, {'top1': 0.1816}), (38, 0.1846, {'top1': 0.1846}), (39, 0.1868, {'top1': 0.1868}), (43, 0.1878, {'top1': 0.1878}), (45, 0.1852, {'top1': 0.1852}), (46, 0.1866, {'top1': 0.1866}), (53, 0.1082, {'top1': 0.1082})]
just computed impact of block 17 . accuracy after removing:  0.1886
removed block 17 current accuracy 0.1886 loss from initial  -0.003799999999999998
since last training loss: -0.003799999999999998 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.1698, {'top1': 0.1698}), (1, 0.177, {'top1': 0.177}), (2, 0.1784, {'top1': 0.1784}), (3, 0.1796, {'top1': 0.1796}), (4, 0.1818, {'top1': 0.1818}), (5, 0.1852, {'top1': 0.1852}), (6, 0.1754, {'top1': 0.1754}), (7, 0.1782, {'top1': 0.1782}), (8, 0.1722, {'top1': 0.1722}), (11, 0.178, {'top1': 0.178}), (12, 0.1732, {'top1': 0.1732}), (15, 0.1834, {'top1': 0.1834}), (18, 0.1136, {'top1': 0.1136}), (19, 0.1768, {'top1': 0.1768}), (20, 0.1614, {'top1': 0.1614}), (21, 0.1626, {'top1': 0.1626}), (22, 0.1692, {'top1': 0.1692}), (23, 0.179, {'top1': 0.179}), (24, 0.182, {'top1': 0.182}), (26, 0.1236, {'top1': 0.1236}), (29, 0.1788, {'top1': 0.1788}), (30, 0.1794, {'top1': 0.1794}), (32, 0.1768, {'top1': 0.1768}), (36, 0.172, {'top1': 0.172}), (37, 0.1802, {'top1': 0.1802}), (38, 0.1828, {'top1': 0.1828}), (39, 0.1848, {'top1': 0.1848}), (43, 0.1852, {'top1': 0.1852}), (45, 0.1844, {'top1': 0.1844}), (46, 0.1852, {'top1': 0.1852}), (53, 0.1096, {'top1': 0.1096})]
just computed impact of block 5 . accuracy after removing:  0.1852
removed block 5 current accuracy 0.1852 loss from initial  -0.00040000000000001146
since last training loss: -0.00040000000000001146 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.1684, {'top1': 0.1684}), (1, 0.1782, {'top1': 0.1782}), (2, 0.1786, {'top1': 0.1786}), (3, 0.1758, {'top1': 0.1758}), (4, 0.1792, {'top1': 0.1792}), (6, 0.1734, {'top1': 0.1734}), (7, 0.1736, {'top1': 0.1736}), (8, 0.1722, {'top1': 0.1722}), (11, 0.1798, {'top1': 0.1798}), (12, 0.1738, {'top1': 0.1738}), (15, 0.1828, {'top1': 0.1828}), (18, 0.112, {'top1': 0.112}), (19, 0.1748, {'top1': 0.1748}), (20, 0.1586, {'top1': 0.1586}), (21, 0.1576, {'top1': 0.1576}), (22, 0.1622, {'top1': 0.1622}), (23, 0.1776, {'top1': 0.1776}), (24, 0.1816, {'top1': 0.1816}), (26, 0.1174, {'top1': 0.1174}), (29, 0.1748, {'top1': 0.1748}), (30, 0.1762, {'top1': 0.1762}), (32, 0.1716, {'top1': 0.1716}), (36, 0.1706, {'top1': 0.1706}), (37, 0.1754, {'top1': 0.1754}), (38, 0.18, {'top1': 0.18}), (39, 0.1792, {'top1': 0.1792}), (43, 0.179, {'top1': 0.179}), (45, 0.1786, {'top1': 0.1786}), (46, 0.179, {'top1': 0.179}), (53, 0.108, {'top1': 0.108})]
just computed impact of block 15 . accuracy after removing:  0.1828
removed block 15 current accuracy 0.1828 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.1776, {'top1': 0.1776}), (1, 0.175, {'top1': 0.175}), (2, 0.1772, {'top1': 0.1772}), (3, 0.1748, {'top1': 0.1748}), (4, 0.1762, {'top1': 0.1762}), (6, 0.17, {'top1': 0.17}), (7, 0.1716, {'top1': 0.1716}), (8, 0.1684, {'top1': 0.1684}), (11, 0.1762, {'top1': 0.1762}), (12, 0.172, {'top1': 0.172}), (18, 0.1104, {'top1': 0.1104}), (19, 0.1684, {'top1': 0.1684}), (20, 0.1516, {'top1': 0.1516}), (21, 0.1554, {'top1': 0.1554}), (22, 0.159, {'top1': 0.159}), (23, 0.174, {'top1': 0.174}), (24, 0.1842, {'top1': 0.1842}), (26, 0.113, {'top1': 0.113}), (29, 0.1692, {'top1': 0.1692}), (30, 0.171, {'top1': 0.171}), (32, 0.17, {'top1': 0.17}), (36, 0.1678, {'top1': 0.1678}), (37, 0.1714, {'top1': 0.1714}), (38, 0.1728, {'top1': 0.1728}), (39, 0.1724, {'top1': 0.1724}), (43, 0.1726, {'top1': 0.1726}), (45, 0.1742, {'top1': 0.1742}), (46, 0.174, {'top1': 0.174}), (53, 0.1126, {'top1': 0.1126})]
just computed impact of block 24 . accuracy after removing:  0.1842
removed block 24 current accuracy 0.1842 loss from initial  0.0005999999999999894
since last training loss: 0.0005999999999999894 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.1696, {'top1': 0.1696}), (1, 0.1766, {'top1': 0.1766}), (2, 0.1774, {'top1': 0.1774}), (3, 0.1842, {'top1': 0.1842}), (4, 0.186, {'top1': 0.186}), (6, 0.1778, {'top1': 0.1778}), (7, 0.178, {'top1': 0.178}), (8, 0.1786, {'top1': 0.1786}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1794, {'top1': 0.1794}), (18, 0.1214, {'top1': 0.1214}), (19, 0.1802, {'top1': 0.1802}), (20, 0.1718, {'top1': 0.1718}), (21, 0.1616, {'top1': 0.1616}), (22, 0.169, {'top1': 0.169}), (23, 0.1842, {'top1': 0.1842}), (26, 0.1186, {'top1': 0.1186}), (29, 0.1808, {'top1': 0.1808}), (30, 0.1798, {'top1': 0.1798}), (32, 0.1768, {'top1': 0.1768}), (36, 0.1768, {'top1': 0.1768}), (37, 0.1804, {'top1': 0.1804}), (38, 0.1818, {'top1': 0.1818}), (39, 0.1838, {'top1': 0.1838}), (43, 0.183, {'top1': 0.183}), (45, 0.1872, {'top1': 0.1872}), (46, 0.1844, {'top1': 0.1844}), (53, 0.1052, {'top1': 0.1052})]
just computed impact of block 45 . accuracy after removing:  0.1872
removed block 45 current accuracy 0.1872 loss from initial  -0.0024000000000000132
training start
training epoch 0 val accuracy 0.3272 topk_dict {'top1': 0.3272} is_best True lr [0.1]
training epoch 1 val accuracy 0.4244 topk_dict {'top1': 0.4244} is_best True lr [0.1]
training epoch 2 val accuracy 0.445 topk_dict {'top1': 0.445} is_best True lr [0.1]
training epoch 3 val accuracy 0.5438 topk_dict {'top1': 0.5438} is_best True lr [0.1]
training epoch 4 val accuracy 0.5628 topk_dict {'top1': 0.5628} is_best True lr [0.1]
training epoch 5 val accuracy 0.6734 topk_dict {'top1': 0.6734} is_best True lr [0.1]
training epoch 6 val accuracy 0.6852 topk_dict {'top1': 0.6852} is_best True lr [0.1]
training epoch 7 val accuracy 0.6914 topk_dict {'top1': 0.6914} is_best True lr [0.1]
training epoch 8 val accuracy 0.741 topk_dict {'top1': 0.741} is_best True lr [0.1]
training epoch 9 val accuracy 0.7206 topk_dict {'top1': 0.7206} is_best False lr [0.1]
training epoch 10 val accuracy 0.7306 topk_dict {'top1': 0.7306} is_best False lr [0.1]
training epoch 11 val accuracy 0.7428 topk_dict {'top1': 0.7428} is_best True lr [0.1]
training epoch 12 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.1]
training epoch 13 val accuracy 0.7838 topk_dict {'top1': 0.7838} is_best False lr [0.1]
training epoch 14 val accuracy 0.7628 topk_dict {'top1': 0.7628} is_best False lr [0.1]
training epoch 15 val accuracy 0.8098 topk_dict {'top1': 0.8098} is_best False lr [0.1]
training epoch 16 val accuracy 0.6832 topk_dict {'top1': 0.6832} is_best False lr [0.1]
training epoch 17 val accuracy 0.8178 topk_dict {'top1': 0.8178} is_best False lr [0.1]
training epoch 18 val accuracy 0.784 topk_dict {'top1': 0.784} is_best False lr [0.1]
training epoch 19 val accuracy 0.803 topk_dict {'top1': 0.803} is_best False lr [0.1]
training epoch 20 val accuracy 0.822 topk_dict {'top1': 0.822} is_best False lr [0.1]
training epoch 21 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best True lr [0.1]
training epoch 22 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best True lr [0.1]
training epoch 23 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.1]
training epoch 24 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.1]
training epoch 25 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best False lr [0.1]
training epoch 26 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best False lr [0.1]
training epoch 27 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 28 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.1]
training epoch 29 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 30 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 31 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.1]
training epoch 32 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 33 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 34 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 35 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 36 val accuracy 0.859 topk_dict {'top1': 0.859} is_best True lr [0.1]
training epoch 37 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 38 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 39 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 40 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best False lr [0.1]
training epoch 41 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.1]
training epoch 42 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 43 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 44 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 45 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best False lr [0.1]
training epoch 46 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 47 val accuracy 0.7984 topk_dict {'top1': 0.7984} is_best False lr [0.1]
training epoch 48 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.1]
training epoch 49 val accuracy 0.829 topk_dict {'top1': 0.829} is_best False lr [0.1]
training epoch 50 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best False lr [0.1]
training epoch 51 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 52 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 53 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 54 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.1]
training epoch 55 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 56 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 57 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 58 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 59 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 60 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 61 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 62 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 63 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 64 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 65 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 66 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 67 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 68 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 69 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 70 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 71 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 72 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 73 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 74 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 75 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 76 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 77 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 78 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 79 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 80 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.1]
training epoch 81 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 82 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 83 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 84 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 85 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 86 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.1]
training epoch 87 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 88 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 89 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 90 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 91 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 92 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 93 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 94 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 95 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 96 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 97 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 98 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 99 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 100 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 101 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 102 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 103 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 104 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 105 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 106 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 107 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 108 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 109 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 110 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 111 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 112 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 113 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 114 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 115 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 116 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 117 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 118 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 119 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.1]
training epoch 120 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 121 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 122 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 123 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 124 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 125 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 126 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 127 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 128 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 129 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 130 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 131 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 132 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 133 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.1]
training epoch 134 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 135 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 136 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 137 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 138 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 139 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 140 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 141 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 142 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 143 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 144 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 145 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 146 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 147 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 148 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 149 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 150 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 151 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 152 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 153 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 154 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 155 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 156 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 157 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 158 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 159 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 160 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 161 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 162 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 163 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 164 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 165 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 166 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 167 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 168 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 169 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 170 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 171 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 172 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 173 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 174 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 175 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 176 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 177 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 178 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 179 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 180 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 181 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 182 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 183 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 184 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 185 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 186 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 187 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 188 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 189 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 190 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 191 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 192 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 193 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 194 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 195 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 196 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 197 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 198 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 199 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 200 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 201 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 202 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 203 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 204 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 205 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 206 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 207 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 208 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 209 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 210 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 211 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 212 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 213 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 214 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 215 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 216 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 217 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 218 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 219 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 220 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 221 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 222 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 223 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 224 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 225 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 226 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 227 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 228 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 229 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 230 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 231 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 232 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 233 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 234 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 235 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 236 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 237 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 238 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 239 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 240 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 241 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 242 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 243 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 244 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 245 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.1]
training epoch 246 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.1]
training epoch 247 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 248 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 249 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 250 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 251 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.010000000000000002]
training epoch 253 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 255 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 267 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 274 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 276 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 280 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 288 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 301 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 325 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 329 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 340 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 347 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 367 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 368 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 369 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 370 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 371 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 372 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 373 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 374 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 384 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 481 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 489 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 490 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 491 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 492 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 493 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 494 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 495 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 496 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 497 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 498 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
loading model_best from epoch 434 (acc 0.936800)
finished training. finished 499 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
