start iteration 0
(cache recomputed) Accuracy log [(0, 0.8126, {'top1': 0.8126}), (1, 0.8734, {'top1': 0.8734}), (2, 0.8204, {'top1': 0.8204}), (3, 0.846, {'top1': 0.846}), (4, 0.8438, {'top1': 0.8438}), (5, 0.8136, {'top1': 0.8136}), (6, 0.8416, {'top1': 0.8416}), (7, 0.8256, {'top1': 0.8256}), (8, 0.8202, {'top1': 0.8202}), (9, 0.8314, {'top1': 0.8314}), (10, 0.8258, {'top1': 0.8258}), (11, 0.8446, {'top1': 0.8446}), (12, 0.8292, {'top1': 0.8292}), (13, 0.8404, {'top1': 0.8404}), (14, 0.839, {'top1': 0.839}), (15, 0.8182, {'top1': 0.8182}), (16, 0.8322, {'top1': 0.8322}), (17, 0.861, {'top1': 0.861}), (18, 0.3862, {'top1': 0.3862}), (19, 0.8354, {'top1': 0.8354}), (20, 0.8658, {'top1': 0.8658}), (21, 0.8404, {'top1': 0.8404}), (22, 0.8594, {'top1': 0.8594}), (23, 0.861, {'top1': 0.861}), (24, 0.86, {'top1': 0.86}), (25, 0.8572, {'top1': 0.8572}), (26, 0.8578, {'top1': 0.8578}), (27, 0.8368, {'top1': 0.8368}), (28, 0.8654, {'top1': 0.8654}), (29, 0.8628, {'top1': 0.8628}), (30, 0.8628, {'top1': 0.8628}), (31, 0.8624, {'top1': 0.8624}), (32, 0.8738, {'top1': 0.8738}), (33, 0.86, {'top1': 0.86}), (34, 0.8632, {'top1': 0.8632}), (35, 0.8638, {'top1': 0.8638}), (36, 0.5116, {'top1': 0.5116}), (37, 0.8606, {'top1': 0.8606}), (38, 0.8638, {'top1': 0.8638}), (39, 0.8562, {'top1': 0.8562}), (40, 0.8632, {'top1': 0.8632}), (41, 0.861, {'top1': 0.861}), (42, 0.8698, {'top1': 0.8698}), (43, 0.8646, {'top1': 0.8646}), (44, 0.8622, {'top1': 0.8622}), (45, 0.868, {'top1': 0.868}), (46, 0.8622, {'top1': 0.8622}), (47, 0.8624, {'top1': 0.8624}), (48, 0.862, {'top1': 0.862}), (49, 0.869, {'top1': 0.869}), (50, 0.8464, {'top1': 0.8464}), (51, 0.778, {'top1': 0.778}), (52, 0.7806, {'top1': 0.7806}), (53, 0.3376, {'top1': 0.3376})]
just computed impact of block 32 . accuracy after removing:  0.8738
removed block 32 current accuracy 0.8738 loss from initial  -0.011600000000000055
since last training loss: -0.011600000000000055 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.8232, {'top1': 0.8232}), (1, 0.8802, {'top1': 0.8802}), (2, 0.832, {'top1': 0.832}), (3, 0.8588, {'top1': 0.8588}), (4, 0.8552, {'top1': 0.8552}), (5, 0.83, {'top1': 0.83}), (6, 0.854, {'top1': 0.854}), (7, 0.8414, {'top1': 0.8414}), (8, 0.8338, {'top1': 0.8338}), (9, 0.8452, {'top1': 0.8452}), (10, 0.8362, {'top1': 0.8362}), (11, 0.8568, {'top1': 0.8568}), (12, 0.8388, {'top1': 0.8388}), (13, 0.8514, {'top1': 0.8514}), (14, 0.8508, {'top1': 0.8508}), (15, 0.832, {'top1': 0.832}), (16, 0.8428, {'top1': 0.8428}), (17, 0.873, {'top1': 0.873}), (18, 0.3924, {'top1': 0.3924}), (19, 0.85, {'top1': 0.85}), (20, 0.874, {'top1': 0.874}), (21, 0.8524, {'top1': 0.8524}), (22, 0.8718, {'top1': 0.8718}), (23, 0.8714, {'top1': 0.8714}), (24, 0.8722, {'top1': 0.8722}), (25, 0.8708, {'top1': 0.8708}), (26, 0.8688, {'top1': 0.8688}), (27, 0.849, {'top1': 0.849}), (28, 0.8768, {'top1': 0.8768}), (29, 0.8726, {'top1': 0.8726}), (30, 0.8748, {'top1': 0.8748}), (31, 0.8724, {'top1': 0.8724}), (33, 0.8718, {'top1': 0.8718}), (34, 0.8732, {'top1': 0.8732}), (35, 0.8706, {'top1': 0.8706}), (36, 0.4976, {'top1': 0.4976}), (37, 0.8682, {'top1': 0.8682}), (38, 0.8744, {'top1': 0.8744}), (39, 0.8672, {'top1': 0.8672}), (40, 0.875, {'top1': 0.875}), (41, 0.872, {'top1': 0.872}), (42, 0.876, {'top1': 0.876}), (43, 0.8738, {'top1': 0.8738}), (44, 0.8734, {'top1': 0.8734}), (45, 0.878, {'top1': 0.878}), (46, 0.8746, {'top1': 0.8746}), (47, 0.8742, {'top1': 0.8742}), (48, 0.8728, {'top1': 0.8728}), (49, 0.8766, {'top1': 0.8766}), (50, 0.858, {'top1': 0.858}), (51, 0.7902, {'top1': 0.7902}), (52, 0.7882, {'top1': 0.7882}), (53, 0.3432, {'top1': 0.3432})]
just computed impact of block 1 . accuracy after removing:  0.8802
removed block 1 current accuracy 0.8802 loss from initial  -0.018000000000000016
since last training loss: -0.018000000000000016 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8022, {'top1': 0.8022}), (2, 0.8146, {'top1': 0.8146}), (3, 0.8564, {'top1': 0.8564}), (4, 0.8654, {'top1': 0.8654}), (5, 0.8528, {'top1': 0.8528}), (6, 0.8448, {'top1': 0.8448}), (7, 0.835, {'top1': 0.835}), (8, 0.8358, {'top1': 0.8358}), (9, 0.85, {'top1': 0.85}), (10, 0.8426, {'top1': 0.8426}), (11, 0.853, {'top1': 0.853}), (12, 0.8506, {'top1': 0.8506}), (13, 0.86, {'top1': 0.86}), (14, 0.8568, {'top1': 0.8568}), (15, 0.8396, {'top1': 0.8396}), (16, 0.8474, {'top1': 0.8474}), (17, 0.8714, {'top1': 0.8714}), (18, 0.423, {'top1': 0.423}), (19, 0.8724, {'top1': 0.8724}), (20, 0.8866, {'top1': 0.8866}), (21, 0.8594, {'top1': 0.8594}), (22, 0.882, {'top1': 0.882}), (23, 0.8764, {'top1': 0.8764}), (24, 0.8822, {'top1': 0.8822}), (25, 0.8798, {'top1': 0.8798}), (26, 0.8794, {'top1': 0.8794}), (27, 0.8618, {'top1': 0.8618}), (28, 0.8792, {'top1': 0.8792}), (29, 0.8774, {'top1': 0.8774}), (30, 0.8796, {'top1': 0.8796}), (31, 0.8798, {'top1': 0.8798}), (33, 0.8756, {'top1': 0.8756}), (34, 0.877, {'top1': 0.877}), (35, 0.8798, {'top1': 0.8798}), (36, 0.495, {'top1': 0.495}), (37, 0.8784, {'top1': 0.8784}), (38, 0.878, {'top1': 0.878}), (39, 0.8744, {'top1': 0.8744}), (40, 0.88, {'top1': 0.88}), (41, 0.8786, {'top1': 0.8786}), (42, 0.884, {'top1': 0.884}), (43, 0.8816, {'top1': 0.8816}), (44, 0.8788, {'top1': 0.8788}), (45, 0.8842, {'top1': 0.8842}), (46, 0.8798, {'top1': 0.8798}), (47, 0.8808, {'top1': 0.8808}), (48, 0.8836, {'top1': 0.8836}), (49, 0.8838, {'top1': 0.8838}), (50, 0.8708, {'top1': 0.8708}), (51, 0.8092, {'top1': 0.8092}), (52, 0.7876, {'top1': 0.7876}), (53, 0.3376, {'top1': 0.3376})]
just computed impact of block 20 . accuracy after removing:  0.8866
removed block 20 current accuracy 0.8866 loss from initial  -0.02440000000000009
since last training loss: -0.02440000000000009 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.8096, {'top1': 0.8096}), (2, 0.8222, {'top1': 0.8222}), (3, 0.8638, {'top1': 0.8638}), (4, 0.8728, {'top1': 0.8728}), (5, 0.846, {'top1': 0.846}), (6, 0.8562, {'top1': 0.8562}), (7, 0.8308, {'top1': 0.8308}), (8, 0.8354, {'top1': 0.8354}), (9, 0.8562, {'top1': 0.8562}), (10, 0.8488, {'top1': 0.8488}), (11, 0.8656, {'top1': 0.8656}), (12, 0.8548, {'top1': 0.8548}), (13, 0.87, {'top1': 0.87}), (14, 0.8664, {'top1': 0.8664}), (15, 0.851, {'top1': 0.851}), (16, 0.8668, {'top1': 0.8668}), (17, 0.8818, {'top1': 0.8818}), (18, 0.3926, {'top1': 0.3926}), (19, 0.8614, {'top1': 0.8614}), (21, 0.865, {'top1': 0.865}), (22, 0.8844, {'top1': 0.8844}), (23, 0.8804, {'top1': 0.8804}), (24, 0.8896, {'top1': 0.8896}), (25, 0.887, {'top1': 0.887}), (26, 0.8828, {'top1': 0.8828}), (27, 0.8624, {'top1': 0.8624}), (28, 0.8862, {'top1': 0.8862}), (29, 0.8802, {'top1': 0.8802}), (30, 0.8856, {'top1': 0.8856}), (31, 0.8844, {'top1': 0.8844}), (33, 0.88, {'top1': 0.88}), (34, 0.8826, {'top1': 0.8826}), (35, 0.8858, {'top1': 0.8858}), (36, 0.4588, {'top1': 0.4588}), (37, 0.8848, {'top1': 0.8848}), (38, 0.8812, {'top1': 0.8812}), (39, 0.8772, {'top1': 0.8772}), (40, 0.8886, {'top1': 0.8886}), (41, 0.8866, {'top1': 0.8866}), (42, 0.8898, {'top1': 0.8898}), (43, 0.8862, {'top1': 0.8862}), (44, 0.8868, {'top1': 0.8868}), (45, 0.8914, {'top1': 0.8914}), (46, 0.884, {'top1': 0.884}), (47, 0.8846, {'top1': 0.8846}), (48, 0.8902, {'top1': 0.8902}), (49, 0.8888, {'top1': 0.8888}), (50, 0.87, {'top1': 0.87}), (51, 0.8074, {'top1': 0.8074}), (52, 0.7774, {'top1': 0.7774}), (53, 0.3294, {'top1': 0.3294})]
just computed impact of block 45 . accuracy after removing:  0.8914
removed block 45 current accuracy 0.8914 loss from initial  -0.029200000000000004
since last training loss: -0.029200000000000004 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8158, {'top1': 0.8158}), (2, 0.826, {'top1': 0.826}), (3, 0.8698, {'top1': 0.8698}), (4, 0.8748, {'top1': 0.8748}), (5, 0.8508, {'top1': 0.8508}), (6, 0.8584, {'top1': 0.8584}), (7, 0.836, {'top1': 0.836}), (8, 0.8424, {'top1': 0.8424}), (9, 0.8606, {'top1': 0.8606}), (10, 0.858, {'top1': 0.858}), (11, 0.8732, {'top1': 0.8732}), (12, 0.861, {'top1': 0.861}), (13, 0.8716, {'top1': 0.8716}), (14, 0.8708, {'top1': 0.8708}), (15, 0.8544, {'top1': 0.8544}), (16, 0.8724, {'top1': 0.8724}), (17, 0.8864, {'top1': 0.8864}), (18, 0.388, {'top1': 0.388}), (19, 0.87, {'top1': 0.87}), (21, 0.8682, {'top1': 0.8682}), (22, 0.8864, {'top1': 0.8864}), (23, 0.8812, {'top1': 0.8812}), (24, 0.8932, {'top1': 0.8932}), (25, 0.8908, {'top1': 0.8908}), (26, 0.887, {'top1': 0.887}), (27, 0.8678, {'top1': 0.8678}), (28, 0.8878, {'top1': 0.8878}), (29, 0.8868, {'top1': 0.8868}), (30, 0.8902, {'top1': 0.8902}), (31, 0.89, {'top1': 0.89}), (33, 0.8846, {'top1': 0.8846}), (34, 0.8876, {'top1': 0.8876}), (35, 0.8872, {'top1': 0.8872}), (36, 0.4316, {'top1': 0.4316}), (37, 0.8896, {'top1': 0.8896}), (38, 0.8858, {'top1': 0.8858}), (39, 0.8842, {'top1': 0.8842}), (40, 0.8922, {'top1': 0.8922}), (41, 0.8908, {'top1': 0.8908}), (42, 0.8942, {'top1': 0.8942}), (43, 0.8934, {'top1': 0.8934}), (44, 0.8904, {'top1': 0.8904}), (46, 0.889, {'top1': 0.889}), (47, 0.8902, {'top1': 0.8902}), (48, 0.8942, {'top1': 0.8942}), (49, 0.8926, {'top1': 0.8926}), (50, 0.876, {'top1': 0.876}), (51, 0.8104, {'top1': 0.8104}), (52, 0.7706, {'top1': 0.7706}), (53, 0.3312, {'top1': 0.3312})]
just computed impact of block 42 . accuracy after removing:  0.8942
removed block 42 current accuracy 0.8942 loss from initial  -0.03200000000000003
since last training loss: -0.03200000000000003 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8214, {'top1': 0.8214}), (2, 0.832, {'top1': 0.832}), (3, 0.8746, {'top1': 0.8746}), (4, 0.8806, {'top1': 0.8806}), (5, 0.8546, {'top1': 0.8546}), (6, 0.8648, {'top1': 0.8648}), (7, 0.8458, {'top1': 0.8458}), (8, 0.8468, {'top1': 0.8468}), (9, 0.867, {'top1': 0.867}), (10, 0.8638, {'top1': 0.8638}), (11, 0.8762, {'top1': 0.8762}), (12, 0.8658, {'top1': 0.8658}), (13, 0.8762, {'top1': 0.8762}), (14, 0.8772, {'top1': 0.8772}), (15, 0.86, {'top1': 0.86}), (16, 0.874, {'top1': 0.874}), (17, 0.8864, {'top1': 0.8864}), (18, 0.3968, {'top1': 0.3968}), (19, 0.8726, {'top1': 0.8726}), (21, 0.873, {'top1': 0.873}), (22, 0.8874, {'top1': 0.8874}), (23, 0.8878, {'top1': 0.8878}), (24, 0.896, {'top1': 0.896}), (25, 0.893, {'top1': 0.893}), (26, 0.8928, {'top1': 0.8928}), (27, 0.871, {'top1': 0.871}), (28, 0.892, {'top1': 0.892}), (29, 0.8896, {'top1': 0.8896}), (30, 0.8936, {'top1': 0.8936}), (31, 0.8924, {'top1': 0.8924}), (33, 0.888, {'top1': 0.888}), (34, 0.8908, {'top1': 0.8908}), (35, 0.8912, {'top1': 0.8912}), (36, 0.4676, {'top1': 0.4676}), (37, 0.8938, {'top1': 0.8938}), (38, 0.8916, {'top1': 0.8916}), (39, 0.8886, {'top1': 0.8886}), (40, 0.8948, {'top1': 0.8948}), (41, 0.8938, {'top1': 0.8938}), (43, 0.897, {'top1': 0.897}), (44, 0.8924, {'top1': 0.8924}), (46, 0.8946, {'top1': 0.8946}), (47, 0.8912, {'top1': 0.8912}), (48, 0.8976, {'top1': 0.8976}), (49, 0.8948, {'top1': 0.8948}), (50, 0.8778, {'top1': 0.8778}), (51, 0.8164, {'top1': 0.8164}), (52, 0.7648, {'top1': 0.7648}), (53, 0.3272, {'top1': 0.3272})]
just computed impact of block 48 . accuracy after removing:  0.8976
removed block 48 current accuracy 0.8976 loss from initial  -0.03539999999999999
since last training loss: -0.03539999999999999 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.8208, {'top1': 0.8208}), (2, 0.8334, {'top1': 0.8334}), (3, 0.8764, {'top1': 0.8764}), (4, 0.8826, {'top1': 0.8826}), (5, 0.8538, {'top1': 0.8538}), (6, 0.8642, {'top1': 0.8642}), (7, 0.8458, {'top1': 0.8458}), (8, 0.845, {'top1': 0.845}), (9, 0.8656, {'top1': 0.8656}), (10, 0.867, {'top1': 0.867}), (11, 0.8776, {'top1': 0.8776}), (12, 0.867, {'top1': 0.867}), (13, 0.8746, {'top1': 0.8746}), (14, 0.8756, {'top1': 0.8756}), (15, 0.8586, {'top1': 0.8586}), (16, 0.8718, {'top1': 0.8718}), (17, 0.8862, {'top1': 0.8862}), (18, 0.413, {'top1': 0.413}), (19, 0.8722, {'top1': 0.8722}), (21, 0.8724, {'top1': 0.8724}), (22, 0.8888, {'top1': 0.8888}), (23, 0.8884, {'top1': 0.8884}), (24, 0.8962, {'top1': 0.8962}), (25, 0.8936, {'top1': 0.8936}), (26, 0.8946, {'top1': 0.8946}), (27, 0.8726, {'top1': 0.8726}), (28, 0.8948, {'top1': 0.8948}), (29, 0.8904, {'top1': 0.8904}), (30, 0.8942, {'top1': 0.8942}), (31, 0.8924, {'top1': 0.8924}), (33, 0.89, {'top1': 0.89}), (34, 0.8916, {'top1': 0.8916}), (35, 0.8944, {'top1': 0.8944}), (36, 0.4746, {'top1': 0.4746}), (37, 0.8948, {'top1': 0.8948}), (38, 0.8936, {'top1': 0.8936}), (39, 0.8894, {'top1': 0.8894}), (40, 0.898, {'top1': 0.898}), (41, 0.8964, {'top1': 0.8964}), (43, 0.8966, {'top1': 0.8966}), (44, 0.896, {'top1': 0.896}), (46, 0.8936, {'top1': 0.8936}), (47, 0.892, {'top1': 0.892}), (49, 0.8954, {'top1': 0.8954}), (50, 0.8796, {'top1': 0.8796}), (51, 0.8144, {'top1': 0.8144}), (52, 0.7594, {'top1': 0.7594}), (53, 0.3152, {'top1': 0.3152})]
just computed impact of block 40 . accuracy after removing:  0.898
removed block 40 current accuracy 0.898 loss from initial  -0.035800000000000054
since last training loss: -0.035800000000000054 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.823, {'top1': 0.823}), (2, 0.8352, {'top1': 0.8352}), (3, 0.8752, {'top1': 0.8752}), (4, 0.884, {'top1': 0.884}), (5, 0.8572, {'top1': 0.8572}), (6, 0.868, {'top1': 0.868}), (7, 0.8496, {'top1': 0.8496}), (8, 0.8508, {'top1': 0.8508}), (9, 0.8674, {'top1': 0.8674}), (10, 0.8668, {'top1': 0.8668}), (11, 0.881, {'top1': 0.881}), (12, 0.8656, {'top1': 0.8656}), (13, 0.8726, {'top1': 0.8726}), (14, 0.8776, {'top1': 0.8776}), (15, 0.86, {'top1': 0.86}), (16, 0.871, {'top1': 0.871}), (17, 0.89, {'top1': 0.89}), (18, 0.4096, {'top1': 0.4096}), (19, 0.8714, {'top1': 0.8714}), (21, 0.8732, {'top1': 0.8732}), (22, 0.8896, {'top1': 0.8896}), (23, 0.8888, {'top1': 0.8888}), (24, 0.8978, {'top1': 0.8978}), (25, 0.8942, {'top1': 0.8942}), (26, 0.8934, {'top1': 0.8934}), (27, 0.8758, {'top1': 0.8758}), (28, 0.8954, {'top1': 0.8954}), (29, 0.89, {'top1': 0.89}), (30, 0.8972, {'top1': 0.8972}), (31, 0.8922, {'top1': 0.8922}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8932, {'top1': 0.8932}), (35, 0.8952, {'top1': 0.8952}), (36, 0.4776, {'top1': 0.4776}), (37, 0.898, {'top1': 0.898}), (38, 0.8934, {'top1': 0.8934}), (39, 0.8904, {'top1': 0.8904}), (41, 0.8972, {'top1': 0.8972}), (43, 0.898, {'top1': 0.898}), (44, 0.8958, {'top1': 0.8958}), (46, 0.8958, {'top1': 0.8958}), (47, 0.8932, {'top1': 0.8932}), (49, 0.899, {'top1': 0.899}), (50, 0.879, {'top1': 0.879}), (51, 0.8146, {'top1': 0.8146}), (52, 0.7632, {'top1': 0.7632}), (53, 0.3226, {'top1': 0.3226})]
just computed impact of block 49 . accuracy after removing:  0.899
removed block 49 current accuracy 0.899 loss from initial  -0.036800000000000055
since last training loss: -0.036800000000000055 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.8332, {'top1': 0.8332}), (2, 0.8436, {'top1': 0.8436}), (3, 0.8804, {'top1': 0.8804}), (4, 0.8888, {'top1': 0.8888}), (5, 0.8638, {'top1': 0.8638}), (6, 0.8726, {'top1': 0.8726}), (7, 0.8586, {'top1': 0.8586}), (8, 0.8588, {'top1': 0.8588}), (9, 0.8756, {'top1': 0.8756}), (10, 0.8754, {'top1': 0.8754}), (11, 0.8858, {'top1': 0.8858}), (12, 0.8718, {'top1': 0.8718}), (13, 0.8808, {'top1': 0.8808}), (14, 0.8852, {'top1': 0.8852}), (15, 0.87, {'top1': 0.87}), (16, 0.876, {'top1': 0.876}), (17, 0.8906, {'top1': 0.8906}), (18, 0.414, {'top1': 0.414}), (19, 0.877, {'top1': 0.877}), (21, 0.8756, {'top1': 0.8756}), (22, 0.8948, {'top1': 0.8948}), (23, 0.8918, {'top1': 0.8918}), (24, 0.8968, {'top1': 0.8968}), (25, 0.8958, {'top1': 0.8958}), (26, 0.895, {'top1': 0.895}), (27, 0.882, {'top1': 0.882}), (28, 0.8964, {'top1': 0.8964}), (29, 0.8904, {'top1': 0.8904}), (30, 0.8978, {'top1': 0.8978}), (31, 0.893, {'top1': 0.893}), (33, 0.8912, {'top1': 0.8912}), (34, 0.894, {'top1': 0.894}), (35, 0.8942, {'top1': 0.8942}), (36, 0.4822, {'top1': 0.4822}), (37, 0.898, {'top1': 0.898}), (38, 0.8948, {'top1': 0.8948}), (39, 0.891, {'top1': 0.891}), (41, 0.8942, {'top1': 0.8942}), (43, 0.8978, {'top1': 0.8978}), (44, 0.898, {'top1': 0.898}), (46, 0.8954, {'top1': 0.8954}), (47, 0.8972, {'top1': 0.8972}), (50, 0.881, {'top1': 0.881}), (51, 0.8198, {'top1': 0.8198}), (52, 0.7508, {'top1': 0.7508}), (53, 0.3246, {'top1': 0.3246})]
just computed impact of block 37 . accuracy after removing:  0.898
removed block 37 current accuracy 0.898 loss from initial  -0.035800000000000054
since last training loss: -0.035800000000000054 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8304, {'top1': 0.8304}), (2, 0.843, {'top1': 0.843}), (3, 0.8792, {'top1': 0.8792}), (4, 0.888, {'top1': 0.888}), (5, 0.8628, {'top1': 0.8628}), (6, 0.8734, {'top1': 0.8734}), (7, 0.8584, {'top1': 0.8584}), (8, 0.8588, {'top1': 0.8588}), (9, 0.8756, {'top1': 0.8756}), (10, 0.8704, {'top1': 0.8704}), (11, 0.8814, {'top1': 0.8814}), (12, 0.8722, {'top1': 0.8722}), (13, 0.878, {'top1': 0.878}), (14, 0.8814, {'top1': 0.8814}), (15, 0.8634, {'top1': 0.8634}), (16, 0.8702, {'top1': 0.8702}), (17, 0.8874, {'top1': 0.8874}), (18, 0.4328, {'top1': 0.4328}), (19, 0.878, {'top1': 0.878}), (21, 0.8748, {'top1': 0.8748}), (22, 0.895, {'top1': 0.895}), (23, 0.8906, {'top1': 0.8906}), (24, 0.897, {'top1': 0.897}), (25, 0.8944, {'top1': 0.8944}), (26, 0.894, {'top1': 0.894}), (27, 0.8804, {'top1': 0.8804}), (28, 0.8966, {'top1': 0.8966}), (29, 0.8928, {'top1': 0.8928}), (30, 0.901, {'top1': 0.901}), (31, 0.8954, {'top1': 0.8954}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8926, {'top1': 0.8926}), (35, 0.8958, {'top1': 0.8958}), (36, 0.4206, {'top1': 0.4206}), (38, 0.8934, {'top1': 0.8934}), (39, 0.8906, {'top1': 0.8906}), (41, 0.8936, {'top1': 0.8936}), (43, 0.8978, {'top1': 0.8978}), (44, 0.8998, {'top1': 0.8998}), (46, 0.8956, {'top1': 0.8956}), (47, 0.8972, {'top1': 0.8972}), (50, 0.8804, {'top1': 0.8804}), (51, 0.8194, {'top1': 0.8194}), (52, 0.755, {'top1': 0.755}), (53, 0.3286, {'top1': 0.3286})]
just computed impact of block 30 . accuracy after removing:  0.901
removed block 30 current accuracy 0.901 loss from initial  -0.03880000000000006
since last training loss: -0.03880000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.8276, {'top1': 0.8276}), (2, 0.8462, {'top1': 0.8462}), (3, 0.8798, {'top1': 0.8798}), (4, 0.8896, {'top1': 0.8896}), (5, 0.863, {'top1': 0.863}), (6, 0.8716, {'top1': 0.8716}), (7, 0.856, {'top1': 0.856}), (8, 0.8578, {'top1': 0.8578}), (9, 0.8756, {'top1': 0.8756}), (10, 0.871, {'top1': 0.871}), (11, 0.8838, {'top1': 0.8838}), (12, 0.8746, {'top1': 0.8746}), (13, 0.8794, {'top1': 0.8794}), (14, 0.8834, {'top1': 0.8834}), (15, 0.8656, {'top1': 0.8656}), (16, 0.8722, {'top1': 0.8722}), (17, 0.8864, {'top1': 0.8864}), (18, 0.4376, {'top1': 0.4376}), (19, 0.873, {'top1': 0.873}), (21, 0.8756, {'top1': 0.8756}), (22, 0.8928, {'top1': 0.8928}), (23, 0.8914, {'top1': 0.8914}), (24, 0.8944, {'top1': 0.8944}), (25, 0.8924, {'top1': 0.8924}), (26, 0.8948, {'top1': 0.8948}), (27, 0.8804, {'top1': 0.8804}), (28, 0.896, {'top1': 0.896}), (29, 0.8914, {'top1': 0.8914}), (31, 0.8936, {'top1': 0.8936}), (33, 0.89, {'top1': 0.89}), (34, 0.893, {'top1': 0.893}), (35, 0.8956, {'top1': 0.8956}), (36, 0.394, {'top1': 0.394}), (38, 0.8948, {'top1': 0.8948}), (39, 0.8892, {'top1': 0.8892}), (41, 0.8972, {'top1': 0.8972}), (43, 0.9, {'top1': 0.9}), (44, 0.8996, {'top1': 0.8996}), (46, 0.8962, {'top1': 0.8962}), (47, 0.8974, {'top1': 0.8974}), (50, 0.8778, {'top1': 0.8778}), (51, 0.816, {'top1': 0.816}), (52, 0.7492, {'top1': 0.7492}), (53, 0.3248, {'top1': 0.3248})]
just computed impact of block 43 . accuracy after removing:  0.9
removed block 43 current accuracy 0.9 loss from initial  -0.037800000000000056
since last training loss: -0.037800000000000056 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.8308, {'top1': 0.8308}), (2, 0.8492, {'top1': 0.8492}), (3, 0.8816, {'top1': 0.8816}), (4, 0.8912, {'top1': 0.8912}), (5, 0.861, {'top1': 0.861}), (6, 0.8718, {'top1': 0.8718}), (7, 0.8574, {'top1': 0.8574}), (8, 0.8572, {'top1': 0.8572}), (9, 0.873, {'top1': 0.873}), (10, 0.8712, {'top1': 0.8712}), (11, 0.8858, {'top1': 0.8858}), (12, 0.8766, {'top1': 0.8766}), (13, 0.8822, {'top1': 0.8822}), (14, 0.8844, {'top1': 0.8844}), (15, 0.869, {'top1': 0.869}), (16, 0.8716, {'top1': 0.8716}), (17, 0.8868, {'top1': 0.8868}), (18, 0.4268, {'top1': 0.4268}), (19, 0.8714, {'top1': 0.8714}), (21, 0.8728, {'top1': 0.8728}), (22, 0.8922, {'top1': 0.8922}), (23, 0.8918, {'top1': 0.8918}), (24, 0.8932, {'top1': 0.8932}), (25, 0.8934, {'top1': 0.8934}), (26, 0.8938, {'top1': 0.8938}), (27, 0.8782, {'top1': 0.8782}), (28, 0.8944, {'top1': 0.8944}), (29, 0.892, {'top1': 0.892}), (31, 0.892, {'top1': 0.892}), (33, 0.8922, {'top1': 0.8922}), (34, 0.8934, {'top1': 0.8934}), (35, 0.8952, {'top1': 0.8952}), (36, 0.3978, {'top1': 0.3978}), (38, 0.8948, {'top1': 0.8948}), (39, 0.8874, {'top1': 0.8874}), (41, 0.8954, {'top1': 0.8954}), (44, 0.8998, {'top1': 0.8998}), (46, 0.8964, {'top1': 0.8964}), (47, 0.895, {'top1': 0.895}), (50, 0.8766, {'top1': 0.8766}), (51, 0.8148, {'top1': 0.8148}), (52, 0.7412, {'top1': 0.7412}), (53, 0.324, {'top1': 0.324})]
just computed impact of block 44 . accuracy after removing:  0.8998
removed block 44 current accuracy 0.8998 loss from initial  -0.03760000000000008
since last training loss: -0.03760000000000008 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.8272, {'top1': 0.8272}), (2, 0.8484, {'top1': 0.8484}), (3, 0.8802, {'top1': 0.8802}), (4, 0.8906, {'top1': 0.8906}), (5, 0.8606, {'top1': 0.8606}), (6, 0.8684, {'top1': 0.8684}), (7, 0.8562, {'top1': 0.8562}), (8, 0.855, {'top1': 0.855}), (9, 0.8726, {'top1': 0.8726}), (10, 0.8708, {'top1': 0.8708}), (11, 0.884, {'top1': 0.884}), (12, 0.8766, {'top1': 0.8766}), (13, 0.8828, {'top1': 0.8828}), (14, 0.8846, {'top1': 0.8846}), (15, 0.8666, {'top1': 0.8666}), (16, 0.873, {'top1': 0.873}), (17, 0.8886, {'top1': 0.8886}), (18, 0.4188, {'top1': 0.4188}), (19, 0.8724, {'top1': 0.8724}), (21, 0.8742, {'top1': 0.8742}), (22, 0.8906, {'top1': 0.8906}), (23, 0.8914, {'top1': 0.8914}), (24, 0.8934, {'top1': 0.8934}), (25, 0.893, {'top1': 0.893}), (26, 0.895, {'top1': 0.895}), (27, 0.8802, {'top1': 0.8802}), (28, 0.8952, {'top1': 0.8952}), (29, 0.8902, {'top1': 0.8902}), (31, 0.8934, {'top1': 0.8934}), (33, 0.891, {'top1': 0.891}), (34, 0.8926, {'top1': 0.8926}), (35, 0.8936, {'top1': 0.8936}), (36, 0.3982, {'top1': 0.3982}), (38, 0.8924, {'top1': 0.8924}), (39, 0.886, {'top1': 0.886}), (41, 0.891, {'top1': 0.891}), (46, 0.8926, {'top1': 0.8926}), (47, 0.8968, {'top1': 0.8968}), (50, 0.874, {'top1': 0.874}), (51, 0.812, {'top1': 0.812}), (52, 0.7356, {'top1': 0.7356}), (53, 0.324, {'top1': 0.324})]
just computed impact of block 47 . accuracy after removing:  0.8968
removed block 47 current accuracy 0.8968 loss from initial  -0.034600000000000075
since last training loss: -0.034600000000000075 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.8284, {'top1': 0.8284}), (2, 0.8494, {'top1': 0.8494}), (3, 0.8742, {'top1': 0.8742}), (4, 0.8858, {'top1': 0.8858}), (5, 0.857, {'top1': 0.857}), (6, 0.8668, {'top1': 0.8668}), (7, 0.852, {'top1': 0.852}), (8, 0.855, {'top1': 0.855}), (9, 0.8686, {'top1': 0.8686}), (10, 0.8704, {'top1': 0.8704}), (11, 0.881, {'top1': 0.881}), (12, 0.876, {'top1': 0.876}), (13, 0.8804, {'top1': 0.8804}), (14, 0.8832, {'top1': 0.8832}), (15, 0.8648, {'top1': 0.8648}), (16, 0.869, {'top1': 0.869}), (17, 0.883, {'top1': 0.883}), (18, 0.435, {'top1': 0.435}), (19, 0.871, {'top1': 0.871}), (21, 0.8714, {'top1': 0.8714}), (22, 0.8906, {'top1': 0.8906}), (23, 0.888, {'top1': 0.888}), (24, 0.8936, {'top1': 0.8936}), (25, 0.8872, {'top1': 0.8872}), (26, 0.8944, {'top1': 0.8944}), (27, 0.8782, {'top1': 0.8782}), (28, 0.8938, {'top1': 0.8938}), (29, 0.891, {'top1': 0.891}), (31, 0.8926, {'top1': 0.8926}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8924, {'top1': 0.8924}), (35, 0.8918, {'top1': 0.8918}), (36, 0.4154, {'top1': 0.4154}), (38, 0.889, {'top1': 0.889}), (39, 0.8854, {'top1': 0.8854}), (41, 0.8886, {'top1': 0.8886}), (46, 0.8906, {'top1': 0.8906}), (50, 0.8718, {'top1': 0.8718}), (51, 0.8068, {'top1': 0.8068}), (52, 0.73, {'top1': 0.73}), (53, 0.3176, {'top1': 0.3176})]
just computed impact of block 26 . accuracy after removing:  0.8944
removed block 26 current accuracy 0.8944 loss from initial  -0.032200000000000006
since last training loss: -0.032200000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.8256, {'top1': 0.8256}), (2, 0.8426, {'top1': 0.8426}), (3, 0.8702, {'top1': 0.8702}), (4, 0.8824, {'top1': 0.8824}), (5, 0.8544, {'top1': 0.8544}), (6, 0.8616, {'top1': 0.8616}), (7, 0.848, {'top1': 0.848}), (8, 0.8524, {'top1': 0.8524}), (9, 0.863, {'top1': 0.863}), (10, 0.8692, {'top1': 0.8692}), (11, 0.878, {'top1': 0.878}), (12, 0.871, {'top1': 0.871}), (13, 0.8776, {'top1': 0.8776}), (14, 0.8804, {'top1': 0.8804}), (15, 0.8616, {'top1': 0.8616}), (16, 0.8616, {'top1': 0.8616}), (17, 0.8782, {'top1': 0.8782}), (18, 0.4184, {'top1': 0.4184}), (19, 0.8658, {'top1': 0.8658}), (21, 0.8666, {'top1': 0.8666}), (22, 0.886, {'top1': 0.886}), (23, 0.8834, {'top1': 0.8834}), (24, 0.8866, {'top1': 0.8866}), (25, 0.8828, {'top1': 0.8828}), (27, 0.8716, {'top1': 0.8716}), (28, 0.8912, {'top1': 0.8912}), (29, 0.883, {'top1': 0.883}), (31, 0.8904, {'top1': 0.8904}), (33, 0.8866, {'top1': 0.8866}), (34, 0.8902, {'top1': 0.8902}), (35, 0.8884, {'top1': 0.8884}), (36, 0.3972, {'top1': 0.3972}), (38, 0.8868, {'top1': 0.8868}), (39, 0.883, {'top1': 0.883}), (41, 0.889, {'top1': 0.889}), (46, 0.8906, {'top1': 0.8906}), (50, 0.8616, {'top1': 0.8616}), (51, 0.8, {'top1': 0.8}), (52, 0.7244, {'top1': 0.7244}), (53, 0.3178, {'top1': 0.3178})]
just computed impact of block 28 . accuracy after removing:  0.8912
removed block 28 current accuracy 0.8912 loss from initial  -0.029000000000000026
since last training loss: -0.029000000000000026 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.8186, {'top1': 0.8186}), (2, 0.8412, {'top1': 0.8412}), (3, 0.8706, {'top1': 0.8706}), (4, 0.8784, {'top1': 0.8784}), (5, 0.8568, {'top1': 0.8568}), (6, 0.861, {'top1': 0.861}), (7, 0.85, {'top1': 0.85}), (8, 0.851, {'top1': 0.851}), (9, 0.8668, {'top1': 0.8668}), (10, 0.8628, {'top1': 0.8628}), (11, 0.8756, {'top1': 0.8756}), (12, 0.8688, {'top1': 0.8688}), (13, 0.8754, {'top1': 0.8754}), (14, 0.8758, {'top1': 0.8758}), (15, 0.8612, {'top1': 0.8612}), (16, 0.8624, {'top1': 0.8624}), (17, 0.876, {'top1': 0.876}), (18, 0.451, {'top1': 0.451}), (19, 0.8596, {'top1': 0.8596}), (21, 0.8626, {'top1': 0.8626}), (22, 0.8792, {'top1': 0.8792}), (23, 0.8794, {'top1': 0.8794}), (24, 0.8838, {'top1': 0.8838}), (25, 0.8804, {'top1': 0.8804}), (27, 0.8664, {'top1': 0.8664}), (29, 0.8792, {'top1': 0.8792}), (31, 0.887, {'top1': 0.887}), (33, 0.8848, {'top1': 0.8848}), (34, 0.8844, {'top1': 0.8844}), (35, 0.8846, {'top1': 0.8846}), (36, 0.3752, {'top1': 0.3752}), (38, 0.8858, {'top1': 0.8858}), (39, 0.8792, {'top1': 0.8792}), (41, 0.8838, {'top1': 0.8838}), (46, 0.887, {'top1': 0.887}), (50, 0.8586, {'top1': 0.8586}), (51, 0.7982, {'top1': 0.7982}), (52, 0.7042, {'top1': 0.7042}), (53, 0.3188, {'top1': 0.3188})]
just computed impact of block 31 . accuracy after removing:  0.887
removed block 31 current accuracy 0.887 loss from initial  -0.024800000000000044
since last training loss: -0.024800000000000044 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.8204, {'top1': 0.8204}), (2, 0.8422, {'top1': 0.8422}), (3, 0.8678, {'top1': 0.8678}), (4, 0.8774, {'top1': 0.8774}), (5, 0.855, {'top1': 0.855}), (6, 0.859, {'top1': 0.859}), (7, 0.85, {'top1': 0.85}), (8, 0.848, {'top1': 0.848}), (9, 0.8646, {'top1': 0.8646}), (10, 0.8622, {'top1': 0.8622}), (11, 0.8762, {'top1': 0.8762}), (12, 0.8706, {'top1': 0.8706}), (13, 0.872, {'top1': 0.872}), (14, 0.871, {'top1': 0.871}), (15, 0.8584, {'top1': 0.8584}), (16, 0.856, {'top1': 0.856}), (17, 0.8726, {'top1': 0.8726}), (18, 0.4572, {'top1': 0.4572}), (19, 0.8606, {'top1': 0.8606}), (21, 0.8586, {'top1': 0.8586}), (22, 0.8764, {'top1': 0.8764}), (23, 0.8762, {'top1': 0.8762}), (24, 0.8836, {'top1': 0.8836}), (25, 0.878, {'top1': 0.878}), (27, 0.864, {'top1': 0.864}), (29, 0.878, {'top1': 0.878}), (33, 0.8808, {'top1': 0.8808}), (34, 0.879, {'top1': 0.879}), (35, 0.8808, {'top1': 0.8808}), (36, 0.3454, {'top1': 0.3454}), (38, 0.8804, {'top1': 0.8804}), (39, 0.8762, {'top1': 0.8762}), (41, 0.8812, {'top1': 0.8812}), (46, 0.883, {'top1': 0.883}), (50, 0.8582, {'top1': 0.8582}), (51, 0.796, {'top1': 0.796}), (52, 0.6948, {'top1': 0.6948}), (53, 0.3216, {'top1': 0.3216})]
just computed impact of block 24 . accuracy after removing:  0.8836
removed block 24 current accuracy 0.8836 loss from initial  -0.021400000000000086
since last training loss: -0.021400000000000086 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.8094, {'top1': 0.8094}), (2, 0.8344, {'top1': 0.8344}), (3, 0.8616, {'top1': 0.8616}), (4, 0.8726, {'top1': 0.8726}), (5, 0.8426, {'top1': 0.8426}), (6, 0.852, {'top1': 0.852}), (7, 0.8398, {'top1': 0.8398}), (8, 0.841, {'top1': 0.841}), (9, 0.855, {'top1': 0.855}), (10, 0.8584, {'top1': 0.8584}), (11, 0.8668, {'top1': 0.8668}), (12, 0.8664, {'top1': 0.8664}), (13, 0.8638, {'top1': 0.8638}), (14, 0.865, {'top1': 0.865}), (15, 0.8512, {'top1': 0.8512}), (16, 0.8466, {'top1': 0.8466}), (17, 0.8632, {'top1': 0.8632}), (18, 0.415, {'top1': 0.415}), (19, 0.8494, {'top1': 0.8494}), (21, 0.8508, {'top1': 0.8508}), (22, 0.867, {'top1': 0.867}), (23, 0.8656, {'top1': 0.8656}), (25, 0.8688, {'top1': 0.8688}), (27, 0.857, {'top1': 0.857}), (29, 0.8712, {'top1': 0.8712}), (33, 0.8776, {'top1': 0.8776}), (34, 0.8746, {'top1': 0.8746}), (35, 0.8774, {'top1': 0.8774}), (36, 0.3216, {'top1': 0.3216}), (38, 0.8772, {'top1': 0.8772}), (39, 0.8728, {'top1': 0.8728}), (41, 0.8756, {'top1': 0.8756}), (46, 0.8764, {'top1': 0.8764}), (50, 0.8506, {'top1': 0.8506}), (51, 0.7898, {'top1': 0.7898}), (52, 0.693, {'top1': 0.693}), (53, 0.3082, {'top1': 0.3082})]
just computed impact of block 33 . accuracy after removing:  0.8776
removed block 33 current accuracy 0.8776 loss from initial  -0.01540000000000008
since last training loss: -0.01540000000000008 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.8042, {'top1': 0.8042}), (2, 0.8268, {'top1': 0.8268}), (3, 0.8542, {'top1': 0.8542}), (4, 0.8642, {'top1': 0.8642}), (5, 0.8386, {'top1': 0.8386}), (6, 0.8454, {'top1': 0.8454}), (7, 0.8362, {'top1': 0.8362}), (8, 0.837, {'top1': 0.837}), (9, 0.8534, {'top1': 0.8534}), (10, 0.855, {'top1': 0.855}), (11, 0.8628, {'top1': 0.8628}), (12, 0.8606, {'top1': 0.8606}), (13, 0.862, {'top1': 0.862}), (14, 0.8616, {'top1': 0.8616}), (15, 0.8486, {'top1': 0.8486}), (16, 0.8434, {'top1': 0.8434}), (17, 0.8638, {'top1': 0.8638}), (18, 0.414, {'top1': 0.414}), (19, 0.8462, {'top1': 0.8462}), (21, 0.8428, {'top1': 0.8428}), (22, 0.86, {'top1': 0.86}), (23, 0.8616, {'top1': 0.8616}), (25, 0.8622, {'top1': 0.8622}), (27, 0.8484, {'top1': 0.8484}), (29, 0.8624, {'top1': 0.8624}), (34, 0.8656, {'top1': 0.8656}), (35, 0.8686, {'top1': 0.8686}), (36, 0.292, {'top1': 0.292}), (38, 0.8716, {'top1': 0.8716}), (39, 0.8648, {'top1': 0.8648}), (41, 0.8732, {'top1': 0.8732}), (46, 0.8708, {'top1': 0.8708}), (50, 0.8442, {'top1': 0.8442}), (51, 0.7824, {'top1': 0.7824}), (52, 0.6796, {'top1': 0.6796}), (53, 0.3014, {'top1': 0.3014})]
just computed impact of block 41 . accuracy after removing:  0.8732
removed block 41 current accuracy 0.8732 loss from initial  -0.01100000000000001
since last training loss: -0.01100000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.7992, {'top1': 0.7992}), (2, 0.82, {'top1': 0.82}), (3, 0.8512, {'top1': 0.8512}), (4, 0.8602, {'top1': 0.8602}), (5, 0.8392, {'top1': 0.8392}), (6, 0.8446, {'top1': 0.8446}), (7, 0.8352, {'top1': 0.8352}), (8, 0.834, {'top1': 0.834}), (9, 0.852, {'top1': 0.852}), (10, 0.8498, {'top1': 0.8498}), (11, 0.8602, {'top1': 0.8602}), (12, 0.8564, {'top1': 0.8564}), (13, 0.8578, {'top1': 0.8578}), (14, 0.8602, {'top1': 0.8602}), (15, 0.8488, {'top1': 0.8488}), (16, 0.842, {'top1': 0.842}), (17, 0.859, {'top1': 0.859}), (18, 0.4244, {'top1': 0.4244}), (19, 0.842, {'top1': 0.842}), (21, 0.8364, {'top1': 0.8364}), (22, 0.8504, {'top1': 0.8504}), (23, 0.8526, {'top1': 0.8526}), (25, 0.858, {'top1': 0.858}), (27, 0.8466, {'top1': 0.8466}), (29, 0.859, {'top1': 0.859}), (34, 0.8608, {'top1': 0.8608}), (35, 0.8626, {'top1': 0.8626}), (36, 0.3136, {'top1': 0.3136}), (38, 0.865, {'top1': 0.865}), (39, 0.8596, {'top1': 0.8596}), (46, 0.866, {'top1': 0.866}), (50, 0.836, {'top1': 0.836}), (51, 0.7684, {'top1': 0.7684}), (52, 0.6692, {'top1': 0.6692}), (53, 0.2974, {'top1': 0.2974})]
just computed impact of block 46 . accuracy after removing:  0.866
removed block 46 current accuracy 0.866 loss from initial  -0.0038000000000000256
since last training loss: -0.0038000000000000256 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.7922, {'top1': 0.7922}), (2, 0.8138, {'top1': 0.8138}), (3, 0.8452, {'top1': 0.8452}), (4, 0.8554, {'top1': 0.8554}), (5, 0.8332, {'top1': 0.8332}), (6, 0.8384, {'top1': 0.8384}), (7, 0.8306, {'top1': 0.8306}), (8, 0.828, {'top1': 0.828}), (9, 0.8454, {'top1': 0.8454}), (10, 0.8448, {'top1': 0.8448}), (11, 0.8566, {'top1': 0.8566}), (12, 0.852, {'top1': 0.852}), (13, 0.8516, {'top1': 0.8516}), (14, 0.8546, {'top1': 0.8546}), (15, 0.8444, {'top1': 0.8444}), (16, 0.8342, {'top1': 0.8342}), (17, 0.8534, {'top1': 0.8534}), (18, 0.4304, {'top1': 0.4304}), (19, 0.8362, {'top1': 0.8362}), (21, 0.8298, {'top1': 0.8298}), (22, 0.8464, {'top1': 0.8464}), (23, 0.8452, {'top1': 0.8452}), (25, 0.8512, {'top1': 0.8512}), (27, 0.8404, {'top1': 0.8404}), (29, 0.8524, {'top1': 0.8524}), (34, 0.8522, {'top1': 0.8522}), (35, 0.8584, {'top1': 0.8584}), (36, 0.3226, {'top1': 0.3226}), (38, 0.8602, {'top1': 0.8602}), (39, 0.8552, {'top1': 0.8552}), (50, 0.8278, {'top1': 0.8278}), (51, 0.7576, {'top1': 0.7576}), (52, 0.6596, {'top1': 0.6596}), (53, 0.2994, {'top1': 0.2994})]
just computed impact of block 38 . accuracy after removing:  0.8602
removed block 38 current accuracy 0.8602 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.791, {'top1': 0.791}), (2, 0.81, {'top1': 0.81}), (3, 0.8432, {'top1': 0.8432}), (4, 0.8526, {'top1': 0.8526}), (5, 0.8302, {'top1': 0.8302}), (6, 0.8316, {'top1': 0.8316}), (7, 0.827, {'top1': 0.827}), (8, 0.8252, {'top1': 0.8252}), (9, 0.8468, {'top1': 0.8468}), (10, 0.8396, {'top1': 0.8396}), (11, 0.8504, {'top1': 0.8504}), (12, 0.8484, {'top1': 0.8484}), (13, 0.849, {'top1': 0.849}), (14, 0.85, {'top1': 0.85}), (15, 0.8426, {'top1': 0.8426}), (16, 0.831, {'top1': 0.831}), (17, 0.8458, {'top1': 0.8458}), (18, 0.4214, {'top1': 0.4214}), (19, 0.8318, {'top1': 0.8318}), (21, 0.8258, {'top1': 0.8258}), (22, 0.8446, {'top1': 0.8446}), (23, 0.8418, {'top1': 0.8418}), (25, 0.847, {'top1': 0.847}), (27, 0.8346, {'top1': 0.8346}), (29, 0.8488, {'top1': 0.8488}), (34, 0.8468, {'top1': 0.8468}), (35, 0.8516, {'top1': 0.8516}), (36, 0.3094, {'top1': 0.3094}), (39, 0.8506, {'top1': 0.8506}), (50, 0.8218, {'top1': 0.8218}), (51, 0.7566, {'top1': 0.7566}), (52, 0.6578, {'top1': 0.6578}), (53, 0.297, {'top1': 0.297})]
just computed impact of block 4 . accuracy after removing:  0.8526
removed block 4 current accuracy 0.8526 loss from initial  0.009599999999999942
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7732, {'top1': 0.7732}), (2, 0.792, {'top1': 0.792}), (3, 0.8324, {'top1': 0.8324}), (5, 0.8174, {'top1': 0.8174}), (6, 0.819, {'top1': 0.819}), (7, 0.812, {'top1': 0.812}), (8, 0.813, {'top1': 0.813}), (9, 0.8246, {'top1': 0.8246}), (10, 0.8268, {'top1': 0.8268}), (11, 0.8348, {'top1': 0.8348}), (12, 0.8368, {'top1': 0.8368}), (13, 0.8354, {'top1': 0.8354}), (14, 0.8388, {'top1': 0.8388}), (15, 0.8292, {'top1': 0.8292}), (16, 0.8136, {'top1': 0.8136}), (17, 0.8328, {'top1': 0.8328}), (18, 0.4254, {'top1': 0.4254}), (19, 0.8236, {'top1': 0.8236}), (21, 0.8216, {'top1': 0.8216}), (22, 0.8398, {'top1': 0.8398}), (23, 0.835, {'top1': 0.835}), (25, 0.841, {'top1': 0.841}), (27, 0.8284, {'top1': 0.8284}), (29, 0.842, {'top1': 0.842}), (34, 0.842, {'top1': 0.842}), (35, 0.8474, {'top1': 0.8474}), (36, 0.3064, {'top1': 0.3064}), (39, 0.8428, {'top1': 0.8428}), (50, 0.8112, {'top1': 0.8112}), (51, 0.7446, {'top1': 0.7446}), (52, 0.6528, {'top1': 0.6528}), (53, 0.2936, {'top1': 0.2936})]
just computed impact of block 35 . accuracy after removing:  0.8474
removed block 35 current accuracy 0.8474 loss from initial  0.014799999999999924
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7682, {'top1': 0.7682}), (2, 0.785, {'top1': 0.785}), (3, 0.8238, {'top1': 0.8238}), (5, 0.8194, {'top1': 0.8194}), (6, 0.812, {'top1': 0.812}), (7, 0.8072, {'top1': 0.8072}), (8, 0.8106, {'top1': 0.8106}), (9, 0.8176, {'top1': 0.8176}), (10, 0.8212, {'top1': 0.8212}), (11, 0.8314, {'top1': 0.8314}), (12, 0.8332, {'top1': 0.8332}), (13, 0.8234, {'top1': 0.8234}), (14, 0.8302, {'top1': 0.8302}), (15, 0.8252, {'top1': 0.8252}), (16, 0.8034, {'top1': 0.8034}), (17, 0.8224, {'top1': 0.8224}), (18, 0.4306, {'top1': 0.4306}), (19, 0.8118, {'top1': 0.8118}), (21, 0.8118, {'top1': 0.8118}), (22, 0.8292, {'top1': 0.8292}), (23, 0.822, {'top1': 0.822}), (25, 0.8284, {'top1': 0.8284}), (27, 0.8158, {'top1': 0.8158}), (29, 0.8322, {'top1': 0.8322}), (34, 0.8316, {'top1': 0.8316}), (36, 0.2908, {'top1': 0.2908}), (39, 0.837, {'top1': 0.837}), (50, 0.7992, {'top1': 0.7992}), (51, 0.734, {'top1': 0.734}), (52, 0.6338, {'top1': 0.6338}), (53, 0.2918, {'top1': 0.2918})]
just computed impact of block 39 . accuracy after removing:  0.837
removed block 39 current accuracy 0.837 loss from initial  0.0252
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7566, {'top1': 0.7566}), (2, 0.7726, {'top1': 0.7726}), (3, 0.8116, {'top1': 0.8116}), (5, 0.8074, {'top1': 0.8074}), (6, 0.801, {'top1': 0.801}), (7, 0.7966, {'top1': 0.7966}), (8, 0.7988, {'top1': 0.7988}), (9, 0.8068, {'top1': 0.8068}), (10, 0.8106, {'top1': 0.8106}), (11, 0.8198, {'top1': 0.8198}), (12, 0.817, {'top1': 0.817}), (13, 0.8178, {'top1': 0.8178}), (14, 0.8198, {'top1': 0.8198}), (15, 0.8106, {'top1': 0.8106}), (16, 0.7938, {'top1': 0.7938}), (17, 0.8204, {'top1': 0.8204}), (18, 0.4212, {'top1': 0.4212}), (19, 0.8056, {'top1': 0.8056}), (21, 0.797, {'top1': 0.797}), (22, 0.8198, {'top1': 0.8198}), (23, 0.812, {'top1': 0.812}), (25, 0.8186, {'top1': 0.8186}), (27, 0.8044, {'top1': 0.8044}), (29, 0.821, {'top1': 0.821}), (34, 0.824, {'top1': 0.824}), (36, 0.2706, {'top1': 0.2706}), (50, 0.79, {'top1': 0.79}), (51, 0.7256, {'top1': 0.7256}), (52, 0.6152, {'top1': 0.6152}), (53, 0.2888, {'top1': 0.2888})]
just computed impact of block 34 . accuracy after removing:  0.824
removed block 34 current accuracy 0.824 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.7426, {'top1': 0.7426}), (2, 0.758, {'top1': 0.758}), (3, 0.7968, {'top1': 0.7968}), (5, 0.8004, {'top1': 0.8004}), (6, 0.7878, {'top1': 0.7878}), (7, 0.786, {'top1': 0.786}), (8, 0.788, {'top1': 0.788}), (9, 0.7942, {'top1': 0.7942}), (10, 0.7946, {'top1': 0.7946}), (11, 0.8084, {'top1': 0.8084}), (12, 0.8014, {'top1': 0.8014}), (13, 0.8042, {'top1': 0.8042}), (14, 0.809, {'top1': 0.809}), (15, 0.7954, {'top1': 0.7954}), (16, 0.774, {'top1': 0.774}), (17, 0.8046, {'top1': 0.8046}), (18, 0.421, {'top1': 0.421}), (19, 0.7862, {'top1': 0.7862}), (21, 0.7762, {'top1': 0.7762}), (22, 0.801, {'top1': 0.801}), (23, 0.7958, {'top1': 0.7958}), (25, 0.801, {'top1': 0.801}), (27, 0.7878, {'top1': 0.7878}), (29, 0.8016, {'top1': 0.8016}), (36, 0.2418, {'top1': 0.2418}), (50, 0.77, {'top1': 0.77}), (51, 0.7064, {'top1': 0.7064}), (52, 0.5914, {'top1': 0.5914}), (53, 0.2848, {'top1': 0.2848})]
just computed impact of block 14 . accuracy after removing:  0.809
removed block 14 current accuracy 0.809 loss from initial  0.053199999999999914
since last training loss: 0.053199999999999914 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.7172, {'top1': 0.7172}), (2, 0.726, {'top1': 0.726}), (3, 0.7752, {'top1': 0.7752}), (5, 0.7848, {'top1': 0.7848}), (6, 0.7626, {'top1': 0.7626}), (7, 0.7606, {'top1': 0.7606}), (8, 0.7546, {'top1': 0.7546}), (9, 0.7592, {'top1': 0.7592}), (10, 0.7572, {'top1': 0.7572}), (11, 0.776, {'top1': 0.776}), (12, 0.7862, {'top1': 0.7862}), (13, 0.7484, {'top1': 0.7484}), (15, 0.7452, {'top1': 0.7452}), (16, 0.6948, {'top1': 0.6948}), (17, 0.755, {'top1': 0.755}), (18, 0.4122, {'top1': 0.4122}), (19, 0.7784, {'top1': 0.7784}), (21, 0.7664, {'top1': 0.7664}), (22, 0.79, {'top1': 0.79}), (23, 0.7866, {'top1': 0.7866}), (25, 0.792, {'top1': 0.792}), (27, 0.7722, {'top1': 0.7722}), (29, 0.7918, {'top1': 0.7918}), (36, 0.2358, {'top1': 0.2358}), (50, 0.7566, {'top1': 0.7566}), (51, 0.6958, {'top1': 0.6958}), (52, 0.6046, {'top1': 0.6046}), (53, 0.307, {'top1': 0.307})]
just computed impact of block 25 . accuracy after removing:  0.792
removed block 25 current accuracy 0.792 loss from initial  0.07019999999999993
training start
training epoch 0 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best True lr [0.1]
training epoch 1 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.1]
training epoch 2 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 3 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 4 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 5 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 7 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 8 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 9 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 10 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 11 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 12 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 13 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 14 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 15 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 16 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 17 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 18 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 19 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 20 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 21 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 22 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 23 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 24 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 25 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 26 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 27 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 28 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 29 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 30 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 31 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 32 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 33 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 34 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 35 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 36 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 37 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 38 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 39 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 40 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 41 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 42 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 43 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 44 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best False lr [0.1]
training epoch 45 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 46 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 47 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 48 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 49 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 50 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 51 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 52 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 53 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 54 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 55 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 56 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 57 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 58 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 59 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 60 val accuracy 0.8178 topk_dict {'top1': 0.8178} is_best False lr [0.1]
training epoch 61 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 62 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 63 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 64 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 65 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 66 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 67 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 68 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 69 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 70 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 71 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 72 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 73 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 74 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 75 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 76 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 77 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 78 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 79 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 80 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 81 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 82 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 83 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 84 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 85 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 86 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 87 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 88 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 89 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 90 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 91 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 92 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 93 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 94 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 95 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 96 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 97 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.1]
training epoch 98 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 99 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 100 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 101 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 102 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 103 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 104 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 105 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 106 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 107 val accuracy 0.8346 topk_dict {'top1': 0.8346} is_best False lr [0.1]
training epoch 108 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 109 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 110 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 111 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 112 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 113 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 114 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 115 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 116 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 117 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 118 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 119 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 120 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 121 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 122 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 123 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 124 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 125 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 126 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 127 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 128 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 129 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 130 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 131 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 132 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 133 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 134 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 135 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 136 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 137 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 138 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 139 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 140 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 141 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 142 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 143 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 144 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 145 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 146 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 147 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 148 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 149 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 150 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 151 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 152 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 153 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 154 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 155 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 156 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 157 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 158 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 159 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 160 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 161 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 162 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 163 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 164 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 165 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 166 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 167 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 168 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 169 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 170 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 171 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 172 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 173 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 174 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 175 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 176 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 177 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 178 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 179 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 180 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 181 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 182 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 183 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 184 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 185 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 186 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 187 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 188 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 189 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 190 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 191 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 192 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 193 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 194 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 195 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 196 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 197 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 198 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 199 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 200 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 201 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 202 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 203 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 204 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 205 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 206 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 207 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 208 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 209 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 210 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 211 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 212 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 213 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 214 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 215 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 216 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 217 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 218 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 219 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 220 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 221 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 222 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 223 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 224 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 225 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 226 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 227 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 228 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 229 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 230 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 231 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 232 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 233 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 234 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 235 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 236 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 237 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 238 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 239 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 240 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 241 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 242 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 246 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 250 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 271 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 289 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 300 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 301 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 302 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 303 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 304 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 305 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 306 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 307 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 308 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 309 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 310 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 311 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 312 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 313 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 314 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 315 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 316 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 317 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 318 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 319 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 320 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 321 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 322 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 323 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 324 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 325 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 326 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 327 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 328 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 329 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 330 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 331 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 332 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 333 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 334 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 335 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 336 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 337 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 338 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 339 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 340 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 341 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 342 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 343 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 344 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 345 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 346 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 347 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 348 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 349 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 350 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 351 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 352 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 353 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 354 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 355 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 356 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 357 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 358 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 359 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 366 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 377 (acc 0.942200)
finished training. finished 399 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
