start iteration 0
(cache recomputed) Accuracy log [(0, 0.7908, {'top1': 0.7908}), (1, 0.806, {'top1': 0.806}), (2, 0.8232, {'top1': 0.8232}), (3, 0.8486, {'top1': 0.8486}), (4, 0.839, {'top1': 0.839}), (5, 0.819, {'top1': 0.819}), (6, 0.849, {'top1': 0.849}), (7, 0.8452, {'top1': 0.8452}), (8, 0.8506, {'top1': 0.8506}), (9, 0.8118, {'top1': 0.8118}), (10, 0.8268, {'top1': 0.8268}), (11, 0.8448, {'top1': 0.8448}), (12, 0.855, {'top1': 0.855}), (13, 0.812, {'top1': 0.812}), (14, 0.8468, {'top1': 0.8468}), (15, 0.8422, {'top1': 0.8422}), (16, 0.821, {'top1': 0.821}), (17, 0.8286, {'top1': 0.8286}), (18, 0.4596, {'top1': 0.4596}), (19, 0.7758, {'top1': 0.7758}), (20, 0.834, {'top1': 0.834}), (21, 0.838, {'top1': 0.838}), (22, 0.8114, {'top1': 0.8114}), (23, 0.8396, {'top1': 0.8396}), (24, 0.846, {'top1': 0.846}), (25, 0.8468, {'top1': 0.8468}), (26, 0.8488, {'top1': 0.8488}), (27, 0.8418, {'top1': 0.8418}), (28, 0.8506, {'top1': 0.8506}), (29, 0.85, {'top1': 0.85}), (30, 0.845, {'top1': 0.845}), (31, 0.8514, {'top1': 0.8514}), (32, 0.855, {'top1': 0.855}), (33, 0.856, {'top1': 0.856}), (34, 0.8516, {'top1': 0.8516}), (35, 0.8506, {'top1': 0.8506}), (36, 0.6696, {'top1': 0.6696}), (37, 0.8496, {'top1': 0.8496}), (38, 0.8494, {'top1': 0.8494}), (39, 0.8534, {'top1': 0.8534}), (40, 0.8476, {'top1': 0.8476}), (41, 0.8458, {'top1': 0.8458}), (42, 0.8514, {'top1': 0.8514}), (43, 0.8496, {'top1': 0.8496}), (44, 0.8504, {'top1': 0.8504}), (45, 0.8514, {'top1': 0.8514}), (46, 0.8462, {'top1': 0.8462}), (47, 0.847, {'top1': 0.847}), (48, 0.8448, {'top1': 0.8448}), (49, 0.8456, {'top1': 0.8456}), (50, 0.8492, {'top1': 0.8492}), (51, 0.7848, {'top1': 0.7848}), (52, 0.3998, {'top1': 0.3998}), (53, 0.1776, {'top1': 0.1776})]
just computed impact of block 33 . accuracy after removing:  0.856
removed block 33 current accuracy 0.856 loss from initial  -0.006000000000000005
since last training loss: -0.006000000000000005 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.7962, {'top1': 0.7962}), (1, 0.811, {'top1': 0.811}), (2, 0.8242, {'top1': 0.8242}), (3, 0.8504, {'top1': 0.8504}), (4, 0.8444, {'top1': 0.8444}), (5, 0.818, {'top1': 0.818}), (6, 0.8504, {'top1': 0.8504}), (7, 0.8484, {'top1': 0.8484}), (8, 0.8518, {'top1': 0.8518}), (9, 0.8196, {'top1': 0.8196}), (10, 0.832, {'top1': 0.832}), (11, 0.85, {'top1': 0.85}), (12, 0.8594, {'top1': 0.8594}), (13, 0.8196, {'top1': 0.8196}), (14, 0.8518, {'top1': 0.8518}), (15, 0.8462, {'top1': 0.8462}), (16, 0.829, {'top1': 0.829}), (17, 0.835, {'top1': 0.835}), (18, 0.4828, {'top1': 0.4828}), (19, 0.7822, {'top1': 0.7822}), (20, 0.8376, {'top1': 0.8376}), (21, 0.8408, {'top1': 0.8408}), (22, 0.812, {'top1': 0.812}), (23, 0.8412, {'top1': 0.8412}), (24, 0.8474, {'top1': 0.8474}), (25, 0.8504, {'top1': 0.8504}), (26, 0.8526, {'top1': 0.8526}), (27, 0.841, {'top1': 0.841}), (28, 0.8538, {'top1': 0.8538}), (29, 0.8516, {'top1': 0.8516}), (30, 0.8452, {'top1': 0.8452}), (31, 0.8536, {'top1': 0.8536}), (32, 0.8552, {'top1': 0.8552}), (34, 0.8522, {'top1': 0.8522}), (35, 0.8536, {'top1': 0.8536}), (36, 0.6458, {'top1': 0.6458}), (37, 0.8556, {'top1': 0.8556}), (38, 0.853, {'top1': 0.853}), (39, 0.8564, {'top1': 0.8564}), (40, 0.8524, {'top1': 0.8524}), (41, 0.8528, {'top1': 0.8528}), (42, 0.8558, {'top1': 0.8558}), (43, 0.8548, {'top1': 0.8548}), (44, 0.8536, {'top1': 0.8536}), (45, 0.8564, {'top1': 0.8564}), (46, 0.8516, {'top1': 0.8516}), (47, 0.851, {'top1': 0.851}), (48, 0.8504, {'top1': 0.8504}), (49, 0.8524, {'top1': 0.8524}), (50, 0.8514, {'top1': 0.8514}), (51, 0.7898, {'top1': 0.7898}), (52, 0.3986, {'top1': 0.3986}), (53, 0.175, {'top1': 0.175})]
just computed impact of block 12 . accuracy after removing:  0.8594
removed block 12 current accuracy 0.8594 loss from initial  -0.009400000000000075
since last training loss: -0.009400000000000075 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8006, {'top1': 0.8006}), (1, 0.8198, {'top1': 0.8198}), (2, 0.8234, {'top1': 0.8234}), (3, 0.8534, {'top1': 0.8534}), (4, 0.8448, {'top1': 0.8448}), (5, 0.814, {'top1': 0.814}), (6, 0.8574, {'top1': 0.8574}), (7, 0.8484, {'top1': 0.8484}), (8, 0.8482, {'top1': 0.8482}), (9, 0.8268, {'top1': 0.8268}), (10, 0.8254, {'top1': 0.8254}), (11, 0.8522, {'top1': 0.8522}), (13, 0.8314, {'top1': 0.8314}), (14, 0.8546, {'top1': 0.8546}), (15, 0.847, {'top1': 0.847}), (16, 0.8316, {'top1': 0.8316}), (17, 0.84, {'top1': 0.84}), (18, 0.4944, {'top1': 0.4944}), (19, 0.7926, {'top1': 0.7926}), (20, 0.844, {'top1': 0.844}), (21, 0.84, {'top1': 0.84}), (22, 0.8192, {'top1': 0.8192}), (23, 0.8376, {'top1': 0.8376}), (24, 0.8524, {'top1': 0.8524}), (25, 0.8544, {'top1': 0.8544}), (26, 0.8576, {'top1': 0.8576}), (27, 0.8426, {'top1': 0.8426}), (28, 0.8568, {'top1': 0.8568}), (29, 0.8542, {'top1': 0.8542}), (30, 0.8438, {'top1': 0.8438}), (31, 0.855, {'top1': 0.855}), (32, 0.86, {'top1': 0.86}), (34, 0.8564, {'top1': 0.8564}), (35, 0.857, {'top1': 0.857}), (36, 0.6218, {'top1': 0.6218}), (37, 0.863, {'top1': 0.863}), (38, 0.8586, {'top1': 0.8586}), (39, 0.861, {'top1': 0.861}), (40, 0.8598, {'top1': 0.8598}), (41, 0.8582, {'top1': 0.8582}), (42, 0.862, {'top1': 0.862}), (43, 0.8586, {'top1': 0.8586}), (44, 0.8594, {'top1': 0.8594}), (45, 0.861, {'top1': 0.861}), (46, 0.8558, {'top1': 0.8558}), (47, 0.857, {'top1': 0.857}), (48, 0.8558, {'top1': 0.8558}), (49, 0.8578, {'top1': 0.8578}), (50, 0.8542, {'top1': 0.8542}), (51, 0.7964, {'top1': 0.7964}), (52, 0.4036, {'top1': 0.4036}), (53, 0.1752, {'top1': 0.1752})]
just computed impact of block 37 . accuracy after removing:  0.863
removed block 37 current accuracy 0.863 loss from initial  -0.013000000000000012
since last training loss: -0.013000000000000012 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.802, {'top1': 0.802}), (1, 0.8214, {'top1': 0.8214}), (2, 0.8236, {'top1': 0.8236}), (3, 0.8562, {'top1': 0.8562}), (4, 0.8504, {'top1': 0.8504}), (5, 0.8198, {'top1': 0.8198}), (6, 0.8566, {'top1': 0.8566}), (7, 0.852, {'top1': 0.852}), (8, 0.8502, {'top1': 0.8502}), (9, 0.8258, {'top1': 0.8258}), (10, 0.8306, {'top1': 0.8306}), (11, 0.8552, {'top1': 0.8552}), (13, 0.8314, {'top1': 0.8314}), (14, 0.8602, {'top1': 0.8602}), (15, 0.851, {'top1': 0.851}), (16, 0.8334, {'top1': 0.8334}), (17, 0.84, {'top1': 0.84}), (18, 0.5132, {'top1': 0.5132}), (19, 0.7972, {'top1': 0.7972}), (20, 0.8438, {'top1': 0.8438}), (21, 0.8456, {'top1': 0.8456}), (22, 0.823, {'top1': 0.823}), (23, 0.8442, {'top1': 0.8442}), (24, 0.8556, {'top1': 0.8556}), (25, 0.8566, {'top1': 0.8566}), (26, 0.859, {'top1': 0.859}), (27, 0.8436, {'top1': 0.8436}), (28, 0.861, {'top1': 0.861}), (29, 0.8564, {'top1': 0.8564}), (30, 0.8476, {'top1': 0.8476}), (31, 0.8582, {'top1': 0.8582}), (32, 0.8624, {'top1': 0.8624}), (34, 0.8596, {'top1': 0.8596}), (35, 0.859, {'top1': 0.859}), (36, 0.6184, {'top1': 0.6184}), (38, 0.8618, {'top1': 0.8618}), (39, 0.8634, {'top1': 0.8634}), (40, 0.8624, {'top1': 0.8624}), (41, 0.8612, {'top1': 0.8612}), (42, 0.8648, {'top1': 0.8648}), (43, 0.863, {'top1': 0.863}), (44, 0.8638, {'top1': 0.8638}), (45, 0.862, {'top1': 0.862}), (46, 0.86, {'top1': 0.86}), (47, 0.8584, {'top1': 0.8584}), (48, 0.8598, {'top1': 0.8598}), (49, 0.8604, {'top1': 0.8604}), (50, 0.8554, {'top1': 0.8554}), (51, 0.7952, {'top1': 0.7952}), (52, 0.4106, {'top1': 0.4106}), (53, 0.182, {'top1': 0.182})]
just computed impact of block 42 . accuracy after removing:  0.8648
removed block 42 current accuracy 0.8648 loss from initial  -0.014800000000000035
since last training loss: -0.014800000000000035 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8042, {'top1': 0.8042}), (1, 0.8244, {'top1': 0.8244}), (2, 0.8246, {'top1': 0.8246}), (3, 0.858, {'top1': 0.858}), (4, 0.852, {'top1': 0.852}), (5, 0.8216, {'top1': 0.8216}), (6, 0.8588, {'top1': 0.8588}), (7, 0.8534, {'top1': 0.8534}), (8, 0.8522, {'top1': 0.8522}), (9, 0.8262, {'top1': 0.8262}), (10, 0.8348, {'top1': 0.8348}), (11, 0.8586, {'top1': 0.8586}), (13, 0.8338, {'top1': 0.8338}), (14, 0.8608, {'top1': 0.8608}), (15, 0.8526, {'top1': 0.8526}), (16, 0.8338, {'top1': 0.8338}), (17, 0.8418, {'top1': 0.8418}), (18, 0.5158, {'top1': 0.5158}), (19, 0.7988, {'top1': 0.7988}), (20, 0.8458, {'top1': 0.8458}), (21, 0.8478, {'top1': 0.8478}), (22, 0.825, {'top1': 0.825}), (23, 0.843, {'top1': 0.843}), (24, 0.8562, {'top1': 0.8562}), (25, 0.8576, {'top1': 0.8576}), (26, 0.8604, {'top1': 0.8604}), (27, 0.847, {'top1': 0.847}), (28, 0.8614, {'top1': 0.8614}), (29, 0.8584, {'top1': 0.8584}), (30, 0.8496, {'top1': 0.8496}), (31, 0.8612, {'top1': 0.8612}), (32, 0.8646, {'top1': 0.8646}), (34, 0.8628, {'top1': 0.8628}), (35, 0.8612, {'top1': 0.8612}), (36, 0.618, {'top1': 0.618}), (38, 0.863, {'top1': 0.863}), (39, 0.8642, {'top1': 0.8642}), (40, 0.8642, {'top1': 0.8642}), (41, 0.8624, {'top1': 0.8624}), (43, 0.8646, {'top1': 0.8646}), (44, 0.8638, {'top1': 0.8638}), (45, 0.8646, {'top1': 0.8646}), (46, 0.8612, {'top1': 0.8612}), (47, 0.8608, {'top1': 0.8608}), (48, 0.8602, {'top1': 0.8602}), (49, 0.8606, {'top1': 0.8606}), (50, 0.855, {'top1': 0.855}), (51, 0.7946, {'top1': 0.7946}), (52, 0.4122, {'top1': 0.4122}), (53, 0.1848, {'top1': 0.1848})]
just computed impact of block 32 . accuracy after removing:  0.8646
removed block 32 current accuracy 0.8646 loss from initial  -0.014600000000000057
since last training loss: -0.014600000000000057 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8086, {'top1': 0.8086}), (1, 0.8248, {'top1': 0.8248}), (2, 0.8222, {'top1': 0.8222}), (3, 0.856, {'top1': 0.856}), (4, 0.8496, {'top1': 0.8496}), (5, 0.817, {'top1': 0.817}), (6, 0.8594, {'top1': 0.8594}), (7, 0.8534, {'top1': 0.8534}), (8, 0.8504, {'top1': 0.8504}), (9, 0.8314, {'top1': 0.8314}), (10, 0.8334, {'top1': 0.8334}), (11, 0.8616, {'top1': 0.8616}), (13, 0.8364, {'top1': 0.8364}), (14, 0.8654, {'top1': 0.8654}), (15, 0.854, {'top1': 0.854}), (16, 0.837, {'top1': 0.837}), (17, 0.8456, {'top1': 0.8456}), (18, 0.5566, {'top1': 0.5566}), (19, 0.811, {'top1': 0.811}), (20, 0.8438, {'top1': 0.8438}), (21, 0.8432, {'top1': 0.8432}), (22, 0.8212, {'top1': 0.8212}), (23, 0.8412, {'top1': 0.8412}), (24, 0.8546, {'top1': 0.8546}), (25, 0.8572, {'top1': 0.8572}), (26, 0.8602, {'top1': 0.8602}), (27, 0.8448, {'top1': 0.8448}), (28, 0.861, {'top1': 0.861}), (29, 0.859, {'top1': 0.859}), (30, 0.8458, {'top1': 0.8458}), (31, 0.8582, {'top1': 0.8582}), (34, 0.8594, {'top1': 0.8594}), (35, 0.8586, {'top1': 0.8586}), (36, 0.5932, {'top1': 0.5932}), (38, 0.8604, {'top1': 0.8604}), (39, 0.8626, {'top1': 0.8626}), (40, 0.8602, {'top1': 0.8602}), (41, 0.86, {'top1': 0.86}), (43, 0.8616, {'top1': 0.8616}), (44, 0.864, {'top1': 0.864}), (45, 0.8632, {'top1': 0.8632}), (46, 0.86, {'top1': 0.86}), (47, 0.8586, {'top1': 0.8586}), (48, 0.8594, {'top1': 0.8594}), (49, 0.8594, {'top1': 0.8594}), (50, 0.856, {'top1': 0.856}), (51, 0.7996, {'top1': 0.7996}), (52, 0.4094, {'top1': 0.4094}), (53, 0.1752, {'top1': 0.1752})]
just computed impact of block 14 . accuracy after removing:  0.8654
removed block 14 current accuracy 0.8654 loss from initial  -0.01539999999999997
since last training loss: -0.01539999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.7938, {'top1': 0.7938}), (1, 0.8256, {'top1': 0.8256}), (2, 0.8202, {'top1': 0.8202}), (3, 0.8592, {'top1': 0.8592}), (4, 0.8506, {'top1': 0.8506}), (5, 0.8314, {'top1': 0.8314}), (6, 0.8652, {'top1': 0.8652}), (7, 0.861, {'top1': 0.861}), (8, 0.8572, {'top1': 0.8572}), (9, 0.8114, {'top1': 0.8114}), (10, 0.828, {'top1': 0.828}), (11, 0.851, {'top1': 0.851}), (13, 0.8156, {'top1': 0.8156}), (15, 0.849, {'top1': 0.849}), (16, 0.8084, {'top1': 0.8084}), (17, 0.8294, {'top1': 0.8294}), (18, 0.5428, {'top1': 0.5428}), (19, 0.7902, {'top1': 0.7902}), (20, 0.8474, {'top1': 0.8474}), (21, 0.8452, {'top1': 0.8452}), (22, 0.8182, {'top1': 0.8182}), (23, 0.8444, {'top1': 0.8444}), (24, 0.857, {'top1': 0.857}), (25, 0.8564, {'top1': 0.8564}), (26, 0.8636, {'top1': 0.8636}), (27, 0.8526, {'top1': 0.8526}), (28, 0.8646, {'top1': 0.8646}), (29, 0.8594, {'top1': 0.8594}), (30, 0.8534, {'top1': 0.8534}), (31, 0.8626, {'top1': 0.8626}), (34, 0.8596, {'top1': 0.8596}), (35, 0.8596, {'top1': 0.8596}), (36, 0.601, {'top1': 0.601}), (38, 0.865, {'top1': 0.865}), (39, 0.865, {'top1': 0.865}), (40, 0.8638, {'top1': 0.8638}), (41, 0.864, {'top1': 0.864}), (43, 0.8656, {'top1': 0.8656}), (44, 0.8666, {'top1': 0.8666}), (45, 0.8658, {'top1': 0.8658}), (46, 0.8646, {'top1': 0.8646}), (47, 0.8632, {'top1': 0.8632}), (48, 0.863, {'top1': 0.863}), (49, 0.8622, {'top1': 0.8622}), (50, 0.8604, {'top1': 0.8604}), (51, 0.798, {'top1': 0.798}), (52, 0.404, {'top1': 0.404}), (53, 0.1774, {'top1': 0.1774})]
just computed impact of block 44 . accuracy after removing:  0.8666
removed block 44 current accuracy 0.8666 loss from initial  -0.01660000000000006
since last training loss: -0.01660000000000006 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.7968, {'top1': 0.7968}), (1, 0.8248, {'top1': 0.8248}), (2, 0.8214, {'top1': 0.8214}), (3, 0.8608, {'top1': 0.8608}), (4, 0.8516, {'top1': 0.8516}), (5, 0.8264, {'top1': 0.8264}), (6, 0.8648, {'top1': 0.8648}), (7, 0.8596, {'top1': 0.8596}), (8, 0.8546, {'top1': 0.8546}), (9, 0.8174, {'top1': 0.8174}), (10, 0.8304, {'top1': 0.8304}), (11, 0.8504, {'top1': 0.8504}), (13, 0.8204, {'top1': 0.8204}), (15, 0.8502, {'top1': 0.8502}), (16, 0.8128, {'top1': 0.8128}), (17, 0.8316, {'top1': 0.8316}), (18, 0.5412, {'top1': 0.5412}), (19, 0.7926, {'top1': 0.7926}), (20, 0.8462, {'top1': 0.8462}), (21, 0.8456, {'top1': 0.8456}), (22, 0.8146, {'top1': 0.8146}), (23, 0.8432, {'top1': 0.8432}), (24, 0.8554, {'top1': 0.8554}), (25, 0.8582, {'top1': 0.8582}), (26, 0.8642, {'top1': 0.8642}), (27, 0.85, {'top1': 0.85}), (28, 0.8662, {'top1': 0.8662}), (29, 0.8618, {'top1': 0.8618}), (30, 0.8536, {'top1': 0.8536}), (31, 0.8642, {'top1': 0.8642}), (34, 0.862, {'top1': 0.862}), (35, 0.859, {'top1': 0.859}), (36, 0.61, {'top1': 0.61}), (38, 0.8652, {'top1': 0.8652}), (39, 0.8666, {'top1': 0.8666}), (40, 0.864, {'top1': 0.864}), (41, 0.8624, {'top1': 0.8624}), (43, 0.8662, {'top1': 0.8662}), (45, 0.8684, {'top1': 0.8684}), (46, 0.8646, {'top1': 0.8646}), (47, 0.8626, {'top1': 0.8626}), (48, 0.862, {'top1': 0.862}), (49, 0.8648, {'top1': 0.8648}), (50, 0.8594, {'top1': 0.8594}), (51, 0.8036, {'top1': 0.8036}), (52, 0.398, {'top1': 0.398}), (53, 0.1856, {'top1': 0.1856})]
just computed impact of block 45 . accuracy after removing:  0.8684
removed block 45 current accuracy 0.8684 loss from initial  -0.018399999999999972
since last training loss: -0.018399999999999972 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.8008, {'top1': 0.8008}), (1, 0.8256, {'top1': 0.8256}), (2, 0.822, {'top1': 0.822}), (3, 0.8606, {'top1': 0.8606}), (4, 0.8562, {'top1': 0.8562}), (5, 0.8268, {'top1': 0.8268}), (6, 0.8668, {'top1': 0.8668}), (7, 0.8594, {'top1': 0.8594}), (8, 0.8538, {'top1': 0.8538}), (9, 0.8228, {'top1': 0.8228}), (10, 0.8364, {'top1': 0.8364}), (11, 0.8538, {'top1': 0.8538}), (13, 0.8236, {'top1': 0.8236}), (15, 0.8526, {'top1': 0.8526}), (16, 0.8166, {'top1': 0.8166}), (17, 0.837, {'top1': 0.837}), (18, 0.5534, {'top1': 0.5534}), (19, 0.797, {'top1': 0.797}), (20, 0.8464, {'top1': 0.8464}), (21, 0.847, {'top1': 0.847}), (22, 0.811, {'top1': 0.811}), (23, 0.842, {'top1': 0.842}), (24, 0.8576, {'top1': 0.8576}), (25, 0.8578, {'top1': 0.8578}), (26, 0.8642, {'top1': 0.8642}), (27, 0.8502, {'top1': 0.8502}), (28, 0.8642, {'top1': 0.8642}), (29, 0.8614, {'top1': 0.8614}), (30, 0.851, {'top1': 0.851}), (31, 0.865, {'top1': 0.865}), (34, 0.8616, {'top1': 0.8616}), (35, 0.8612, {'top1': 0.8612}), (36, 0.592, {'top1': 0.592}), (38, 0.8658, {'top1': 0.8658}), (39, 0.8664, {'top1': 0.8664}), (40, 0.865, {'top1': 0.865}), (41, 0.8652, {'top1': 0.8652}), (43, 0.8658, {'top1': 0.8658}), (46, 0.8638, {'top1': 0.8638}), (47, 0.8646, {'top1': 0.8646}), (48, 0.8644, {'top1': 0.8644}), (49, 0.8652, {'top1': 0.8652}), (50, 0.859, {'top1': 0.859}), (51, 0.8076, {'top1': 0.8076}), (52, 0.4014, {'top1': 0.4014}), (53, 0.1884, {'top1': 0.1884})]
just computed impact of block 6 . accuracy after removing:  0.8668
removed block 6 current accuracy 0.8668 loss from initial  -0.016800000000000037
since last training loss: -0.016800000000000037 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8, {'top1': 0.8}), (1, 0.8186, {'top1': 0.8186}), (2, 0.8114, {'top1': 0.8114}), (3, 0.852, {'top1': 0.852}), (4, 0.8534, {'top1': 0.8534}), (5, 0.8114, {'top1': 0.8114}), (7, 0.8444, {'top1': 0.8444}), (8, 0.8468, {'top1': 0.8468}), (9, 0.8096, {'top1': 0.8096}), (10, 0.8244, {'top1': 0.8244}), (11, 0.855, {'top1': 0.855}), (13, 0.8202, {'top1': 0.8202}), (15, 0.854, {'top1': 0.854}), (16, 0.8094, {'top1': 0.8094}), (17, 0.8324, {'top1': 0.8324}), (18, 0.5424, {'top1': 0.5424}), (19, 0.7928, {'top1': 0.7928}), (20, 0.8448, {'top1': 0.8448}), (21, 0.8374, {'top1': 0.8374}), (22, 0.7978, {'top1': 0.7978}), (23, 0.834, {'top1': 0.834}), (24, 0.854, {'top1': 0.854}), (25, 0.8558, {'top1': 0.8558}), (26, 0.8598, {'top1': 0.8598}), (27, 0.8456, {'top1': 0.8456}), (28, 0.8606, {'top1': 0.8606}), (29, 0.8574, {'top1': 0.8574}), (30, 0.8522, {'top1': 0.8522}), (31, 0.8616, {'top1': 0.8616}), (34, 0.8596, {'top1': 0.8596}), (35, 0.8608, {'top1': 0.8608}), (36, 0.57, {'top1': 0.57}), (38, 0.8626, {'top1': 0.8626}), (39, 0.8666, {'top1': 0.8666}), (40, 0.8648, {'top1': 0.8648}), (41, 0.8634, {'top1': 0.8634}), (43, 0.8676, {'top1': 0.8676}), (46, 0.8646, {'top1': 0.8646}), (47, 0.864, {'top1': 0.864}), (48, 0.8642, {'top1': 0.8642}), (49, 0.864, {'top1': 0.864}), (50, 0.854, {'top1': 0.854}), (51, 0.8038, {'top1': 0.8038}), (52, 0.3854, {'top1': 0.3854}), (53, 0.192, {'top1': 0.192})]
just computed impact of block 43 . accuracy after removing:  0.8676
removed block 43 current accuracy 0.8676 loss from initial  -0.01760000000000006
since last training loss: -0.01760000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.8022, {'top1': 0.8022}), (1, 0.8178, {'top1': 0.8178}), (2, 0.8128, {'top1': 0.8128}), (3, 0.8514, {'top1': 0.8514}), (4, 0.854, {'top1': 0.854}), (5, 0.808, {'top1': 0.808}), (7, 0.8442, {'top1': 0.8442}), (8, 0.845, {'top1': 0.845}), (9, 0.816, {'top1': 0.816}), (10, 0.8278, {'top1': 0.8278}), (11, 0.86, {'top1': 0.86}), (13, 0.8232, {'top1': 0.8232}), (15, 0.856, {'top1': 0.856}), (16, 0.8108, {'top1': 0.8108}), (17, 0.8346, {'top1': 0.8346}), (18, 0.5486, {'top1': 0.5486}), (19, 0.7954, {'top1': 0.7954}), (20, 0.8444, {'top1': 0.8444}), (21, 0.837, {'top1': 0.837}), (22, 0.7986, {'top1': 0.7986}), (23, 0.8342, {'top1': 0.8342}), (24, 0.8536, {'top1': 0.8536}), (25, 0.8562, {'top1': 0.8562}), (26, 0.859, {'top1': 0.859}), (27, 0.8452, {'top1': 0.8452}), (28, 0.8624, {'top1': 0.8624}), (29, 0.855, {'top1': 0.855}), (30, 0.85, {'top1': 0.85}), (31, 0.8608, {'top1': 0.8608}), (34, 0.8598, {'top1': 0.8598}), (35, 0.8612, {'top1': 0.8612}), (36, 0.568, {'top1': 0.568}), (38, 0.8654, {'top1': 0.8654}), (39, 0.8668, {'top1': 0.8668}), (40, 0.867, {'top1': 0.867}), (41, 0.8646, {'top1': 0.8646}), (46, 0.8658, {'top1': 0.8658}), (47, 0.8662, {'top1': 0.8662}), (48, 0.865, {'top1': 0.865}), (49, 0.8646, {'top1': 0.8646}), (50, 0.8504, {'top1': 0.8504}), (51, 0.8028, {'top1': 0.8028}), (52, 0.3868, {'top1': 0.3868}), (53, 0.1926, {'top1': 0.1926})]
just computed impact of block 40 . accuracy after removing:  0.867
removed block 40 current accuracy 0.867 loss from initial  -0.017000000000000015
since last training loss: -0.017000000000000015 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.803, {'top1': 0.803}), (1, 0.8166, {'top1': 0.8166}), (2, 0.8142, {'top1': 0.8142}), (3, 0.8522, {'top1': 0.8522}), (4, 0.8524, {'top1': 0.8524}), (5, 0.8078, {'top1': 0.8078}), (7, 0.841, {'top1': 0.841}), (8, 0.844, {'top1': 0.844}), (9, 0.8152, {'top1': 0.8152}), (10, 0.8304, {'top1': 0.8304}), (11, 0.8598, {'top1': 0.8598}), (13, 0.823, {'top1': 0.823}), (15, 0.8566, {'top1': 0.8566}), (16, 0.8106, {'top1': 0.8106}), (17, 0.8372, {'top1': 0.8372}), (18, 0.5446, {'top1': 0.5446}), (19, 0.7938, {'top1': 0.7938}), (20, 0.8414, {'top1': 0.8414}), (21, 0.8354, {'top1': 0.8354}), (22, 0.798, {'top1': 0.798}), (23, 0.8338, {'top1': 0.8338}), (24, 0.8512, {'top1': 0.8512}), (25, 0.855, {'top1': 0.855}), (26, 0.859, {'top1': 0.859}), (27, 0.8438, {'top1': 0.8438}), (28, 0.8612, {'top1': 0.8612}), (29, 0.8538, {'top1': 0.8538}), (30, 0.8494, {'top1': 0.8494}), (31, 0.861, {'top1': 0.861}), (34, 0.8584, {'top1': 0.8584}), (35, 0.8612, {'top1': 0.8612}), (36, 0.5794, {'top1': 0.5794}), (38, 0.8652, {'top1': 0.8652}), (39, 0.866, {'top1': 0.866}), (41, 0.8638, {'top1': 0.8638}), (46, 0.8624, {'top1': 0.8624}), (47, 0.8642, {'top1': 0.8642}), (48, 0.8612, {'top1': 0.8612}), (49, 0.8632, {'top1': 0.8632}), (50, 0.846, {'top1': 0.846}), (51, 0.7996, {'top1': 0.7996}), (52, 0.3826, {'top1': 0.3826}), (53, 0.1914, {'top1': 0.1914})]
just computed impact of block 39 . accuracy after removing:  0.866
removed block 39 current accuracy 0.866 loss from initial  -0.016000000000000014
since last training loss: -0.016000000000000014 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.805, {'top1': 0.805}), (1, 0.8172, {'top1': 0.8172}), (2, 0.8144, {'top1': 0.8144}), (3, 0.8526, {'top1': 0.8526}), (4, 0.854, {'top1': 0.854}), (5, 0.7988, {'top1': 0.7988}), (7, 0.842, {'top1': 0.842}), (8, 0.8428, {'top1': 0.8428}), (9, 0.82, {'top1': 0.82}), (10, 0.829, {'top1': 0.829}), (11, 0.8608, {'top1': 0.8608}), (13, 0.8296, {'top1': 0.8296}), (15, 0.857, {'top1': 0.857}), (16, 0.8104, {'top1': 0.8104}), (17, 0.8444, {'top1': 0.8444}), (18, 0.5546, {'top1': 0.5546}), (19, 0.7998, {'top1': 0.7998}), (20, 0.841, {'top1': 0.841}), (21, 0.8308, {'top1': 0.8308}), (22, 0.7922, {'top1': 0.7922}), (23, 0.8306, {'top1': 0.8306}), (24, 0.8536, {'top1': 0.8536}), (25, 0.853, {'top1': 0.853}), (26, 0.8596, {'top1': 0.8596}), (27, 0.8416, {'top1': 0.8416}), (28, 0.8586, {'top1': 0.8586}), (29, 0.8532, {'top1': 0.8532}), (30, 0.8482, {'top1': 0.8482}), (31, 0.8582, {'top1': 0.8582}), (34, 0.8576, {'top1': 0.8576}), (35, 0.8614, {'top1': 0.8614}), (36, 0.557, {'top1': 0.557}), (38, 0.8636, {'top1': 0.8636}), (41, 0.8646, {'top1': 0.8646}), (46, 0.8626, {'top1': 0.8626}), (47, 0.8632, {'top1': 0.8632}), (48, 0.863, {'top1': 0.863}), (49, 0.8662, {'top1': 0.8662}), (50, 0.8394, {'top1': 0.8394}), (51, 0.7944, {'top1': 0.7944}), (52, 0.3808, {'top1': 0.3808}), (53, 0.196, {'top1': 0.196})]
just computed impact of block 49 . accuracy after removing:  0.8662
removed block 49 current accuracy 0.8662 loss from initial  -0.016199999999999992
since last training loss: -0.016199999999999992 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.8012, {'top1': 0.8012}), (1, 0.814, {'top1': 0.814}), (2, 0.8122, {'top1': 0.8122}), (3, 0.8508, {'top1': 0.8508}), (4, 0.8524, {'top1': 0.8524}), (5, 0.79, {'top1': 0.79}), (7, 0.8374, {'top1': 0.8374}), (8, 0.8372, {'top1': 0.8372}), (9, 0.822, {'top1': 0.822}), (10, 0.8254, {'top1': 0.8254}), (11, 0.8606, {'top1': 0.8606}), (13, 0.8276, {'top1': 0.8276}), (15, 0.8564, {'top1': 0.8564}), (16, 0.81, {'top1': 0.81}), (17, 0.843, {'top1': 0.843}), (18, 0.5508, {'top1': 0.5508}), (19, 0.7996, {'top1': 0.7996}), (20, 0.836, {'top1': 0.836}), (21, 0.8274, {'top1': 0.8274}), (22, 0.7832, {'top1': 0.7832}), (23, 0.8278, {'top1': 0.8278}), (24, 0.8508, {'top1': 0.8508}), (25, 0.8498, {'top1': 0.8498}), (26, 0.8558, {'top1': 0.8558}), (27, 0.839, {'top1': 0.839}), (28, 0.8572, {'top1': 0.8572}), (29, 0.8492, {'top1': 0.8492}), (30, 0.845, {'top1': 0.845}), (31, 0.857, {'top1': 0.857}), (34, 0.8562, {'top1': 0.8562}), (35, 0.8598, {'top1': 0.8598}), (36, 0.5534, {'top1': 0.5534}), (38, 0.862, {'top1': 0.862}), (41, 0.862, {'top1': 0.862}), (46, 0.8606, {'top1': 0.8606}), (47, 0.8612, {'top1': 0.8612}), (48, 0.8596, {'top1': 0.8596}), (50, 0.8356, {'top1': 0.8356}), (51, 0.7908, {'top1': 0.7908}), (52, 0.3832, {'top1': 0.3832}), (53, 0.1928, {'top1': 0.1928})]
just computed impact of block 38 . accuracy after removing:  0.862
removed block 38 current accuracy 0.862 loss from initial  -0.01200000000000001
since last training loss: -0.01200000000000001 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.7964, {'top1': 0.7964}), (1, 0.8082, {'top1': 0.8082}), (2, 0.8098, {'top1': 0.8098}), (3, 0.8504, {'top1': 0.8504}), (4, 0.8508, {'top1': 0.8508}), (5, 0.7878, {'top1': 0.7878}), (7, 0.8328, {'top1': 0.8328}), (8, 0.8366, {'top1': 0.8366}), (9, 0.818, {'top1': 0.818}), (10, 0.8226, {'top1': 0.8226}), (11, 0.8562, {'top1': 0.8562}), (13, 0.8234, {'top1': 0.8234}), (15, 0.8536, {'top1': 0.8536}), (16, 0.8094, {'top1': 0.8094}), (17, 0.8394, {'top1': 0.8394}), (18, 0.5348, {'top1': 0.5348}), (19, 0.7932, {'top1': 0.7932}), (20, 0.8326, {'top1': 0.8326}), (21, 0.824, {'top1': 0.824}), (22, 0.7802, {'top1': 0.7802}), (23, 0.8246, {'top1': 0.8246}), (24, 0.8494, {'top1': 0.8494}), (25, 0.8488, {'top1': 0.8488}), (26, 0.8542, {'top1': 0.8542}), (27, 0.8374, {'top1': 0.8374}), (28, 0.855, {'top1': 0.855}), (29, 0.8484, {'top1': 0.8484}), (30, 0.8442, {'top1': 0.8442}), (31, 0.8552, {'top1': 0.8552}), (34, 0.855, {'top1': 0.855}), (35, 0.8566, {'top1': 0.8566}), (36, 0.555, {'top1': 0.555}), (41, 0.8606, {'top1': 0.8606}), (46, 0.8584, {'top1': 0.8584}), (47, 0.8578, {'top1': 0.8578}), (48, 0.8578, {'top1': 0.8578}), (50, 0.8314, {'top1': 0.8314}), (51, 0.7866, {'top1': 0.7866}), (52, 0.377, {'top1': 0.377}), (53, 0.1954, {'top1': 0.1954})]
just computed impact of block 41 . accuracy after removing:  0.8606
removed block 41 current accuracy 0.8606 loss from initial  -0.010600000000000054
since last training loss: -0.010600000000000054 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.7904, {'top1': 0.7904}), (1, 0.8048, {'top1': 0.8048}), (2, 0.8096, {'top1': 0.8096}), (3, 0.846, {'top1': 0.846}), (4, 0.8464, {'top1': 0.8464}), (5, 0.7832, {'top1': 0.7832}), (7, 0.828, {'top1': 0.828}), (8, 0.8362, {'top1': 0.8362}), (9, 0.8138, {'top1': 0.8138}), (10, 0.8214, {'top1': 0.8214}), (11, 0.8526, {'top1': 0.8526}), (13, 0.8198, {'top1': 0.8198}), (15, 0.8506, {'top1': 0.8506}), (16, 0.8068, {'top1': 0.8068}), (17, 0.8358, {'top1': 0.8358}), (18, 0.525, {'top1': 0.525}), (19, 0.7912, {'top1': 0.7912}), (20, 0.8276, {'top1': 0.8276}), (21, 0.8222, {'top1': 0.8222}), (22, 0.7728, {'top1': 0.7728}), (23, 0.819, {'top1': 0.819}), (24, 0.8434, {'top1': 0.8434}), (25, 0.8446, {'top1': 0.8446}), (26, 0.8528, {'top1': 0.8528}), (27, 0.8338, {'top1': 0.8338}), (28, 0.8532, {'top1': 0.8532}), (29, 0.8462, {'top1': 0.8462}), (30, 0.843, {'top1': 0.843}), (31, 0.8542, {'top1': 0.8542}), (34, 0.8536, {'top1': 0.8536}), (35, 0.855, {'top1': 0.855}), (36, 0.5668, {'top1': 0.5668}), (46, 0.8548, {'top1': 0.8548}), (47, 0.854, {'top1': 0.854}), (48, 0.8532, {'top1': 0.8532}), (50, 0.8296, {'top1': 0.8296}), (51, 0.7874, {'top1': 0.7874}), (52, 0.3748, {'top1': 0.3748}), (53, 0.1958, {'top1': 0.1958})]
just computed impact of block 35 . accuracy after removing:  0.855
removed block 35 current accuracy 0.855 loss from initial  -0.0050000000000000044
since last training loss: -0.0050000000000000044 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.7906, {'top1': 0.7906}), (1, 0.802, {'top1': 0.802}), (2, 0.8068, {'top1': 0.8068}), (3, 0.8432, {'top1': 0.8432}), (4, 0.8432, {'top1': 0.8432}), (5, 0.7874, {'top1': 0.7874}), (7, 0.8308, {'top1': 0.8308}), (8, 0.8354, {'top1': 0.8354}), (9, 0.81, {'top1': 0.81}), (10, 0.817, {'top1': 0.817}), (11, 0.8486, {'top1': 0.8486}), (13, 0.8178, {'top1': 0.8178}), (15, 0.8474, {'top1': 0.8474}), (16, 0.804, {'top1': 0.804}), (17, 0.8296, {'top1': 0.8296}), (18, 0.5198, {'top1': 0.5198}), (19, 0.789, {'top1': 0.789}), (20, 0.8268, {'top1': 0.8268}), (21, 0.8202, {'top1': 0.8202}), (22, 0.7764, {'top1': 0.7764}), (23, 0.8194, {'top1': 0.8194}), (24, 0.8398, {'top1': 0.8398}), (25, 0.843, {'top1': 0.843}), (26, 0.849, {'top1': 0.849}), (27, 0.8326, {'top1': 0.8326}), (28, 0.8474, {'top1': 0.8474}), (29, 0.8422, {'top1': 0.8422}), (30, 0.8392, {'top1': 0.8392}), (31, 0.8512, {'top1': 0.8512}), (34, 0.8496, {'top1': 0.8496}), (36, 0.548, {'top1': 0.548}), (46, 0.8512, {'top1': 0.8512}), (47, 0.8516, {'top1': 0.8516}), (48, 0.8502, {'top1': 0.8502}), (50, 0.829, {'top1': 0.829}), (51, 0.7814, {'top1': 0.7814}), (52, 0.3704, {'top1': 0.3704}), (53, 0.1874, {'top1': 0.1874})]
just computed impact of block 47 . accuracy after removing:  0.8516
removed block 47 current accuracy 0.8516 loss from initial  -0.0016000000000000458
since last training loss: -0.0016000000000000458 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.7886, {'top1': 0.7886}), (1, 0.798, {'top1': 0.798}), (2, 0.8044, {'top1': 0.8044}), (3, 0.8382, {'top1': 0.8382}), (4, 0.8388, {'top1': 0.8388}), (5, 0.7748, {'top1': 0.7748}), (7, 0.825, {'top1': 0.825}), (8, 0.831, {'top1': 0.831}), (9, 0.8112, {'top1': 0.8112}), (10, 0.8124, {'top1': 0.8124}), (11, 0.8464, {'top1': 0.8464}), (13, 0.816, {'top1': 0.816}), (15, 0.8446, {'top1': 0.8446}), (16, 0.8016, {'top1': 0.8016}), (17, 0.8276, {'top1': 0.8276}), (18, 0.5178, {'top1': 0.5178}), (19, 0.783, {'top1': 0.783}), (20, 0.8206, {'top1': 0.8206}), (21, 0.814, {'top1': 0.814}), (22, 0.769, {'top1': 0.769}), (23, 0.813, {'top1': 0.813}), (24, 0.8358, {'top1': 0.8358}), (25, 0.8362, {'top1': 0.8362}), (26, 0.8436, {'top1': 0.8436}), (27, 0.8274, {'top1': 0.8274}), (28, 0.846, {'top1': 0.846}), (29, 0.8366, {'top1': 0.8366}), (30, 0.8334, {'top1': 0.8334}), (31, 0.8474, {'top1': 0.8474}), (34, 0.8464, {'top1': 0.8464}), (36, 0.5538, {'top1': 0.5538}), (46, 0.8456, {'top1': 0.8456}), (48, 0.845, {'top1': 0.845}), (50, 0.8248, {'top1': 0.8248}), (51, 0.7776, {'top1': 0.7776}), (52, 0.3614, {'top1': 0.3614}), (53, 0.1866, {'top1': 0.1866})]
just computed impact of block 31 . accuracy after removing:  0.8474
removed block 31 current accuracy 0.8474 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.7912, {'top1': 0.7912}), (1, 0.7972, {'top1': 0.7972}), (2, 0.7916, {'top1': 0.7916}), (3, 0.8304, {'top1': 0.8304}), (4, 0.8354, {'top1': 0.8354}), (5, 0.7634, {'top1': 0.7634}), (7, 0.8152, {'top1': 0.8152}), (8, 0.8176, {'top1': 0.8176}), (9, 0.811, {'top1': 0.811}), (10, 0.8072, {'top1': 0.8072}), (11, 0.8446, {'top1': 0.8446}), (13, 0.816, {'top1': 0.816}), (15, 0.8412, {'top1': 0.8412}), (16, 0.798, {'top1': 0.798}), (17, 0.8258, {'top1': 0.8258}), (18, 0.525, {'top1': 0.525}), (19, 0.7892, {'top1': 0.7892}), (20, 0.8156, {'top1': 0.8156}), (21, 0.801, {'top1': 0.801}), (22, 0.7532, {'top1': 0.7532}), (23, 0.8004, {'top1': 0.8004}), (24, 0.8292, {'top1': 0.8292}), (25, 0.8286, {'top1': 0.8286}), (26, 0.8316, {'top1': 0.8316}), (27, 0.8148, {'top1': 0.8148}), (28, 0.833, {'top1': 0.833}), (29, 0.8262, {'top1': 0.8262}), (30, 0.8186, {'top1': 0.8186}), (34, 0.839, {'top1': 0.839}), (36, 0.516, {'top1': 0.516}), (46, 0.839, {'top1': 0.839}), (48, 0.8406, {'top1': 0.8406}), (50, 0.8132, {'top1': 0.8132}), (51, 0.7696, {'top1': 0.7696}), (52, 0.3598, {'top1': 0.3598}), (53, 0.1866, {'top1': 0.1866})]
just computed impact of block 11 . accuracy after removing:  0.8446
removed block 11 current accuracy 0.8446 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.7828, {'top1': 0.7828}), (1, 0.7964, {'top1': 0.7964}), (2, 0.7838, {'top1': 0.7838}), (3, 0.8272, {'top1': 0.8272}), (4, 0.833, {'top1': 0.833}), (5, 0.7776, {'top1': 0.7776}), (7, 0.8188, {'top1': 0.8188}), (8, 0.8206, {'top1': 0.8206}), (9, 0.7756, {'top1': 0.7756}), (10, 0.794, {'top1': 0.794}), (13, 0.7928, {'top1': 0.7928}), (15, 0.8326, {'top1': 0.8326}), (16, 0.7702, {'top1': 0.7702}), (17, 0.8006, {'top1': 0.8006}), (18, 0.4918, {'top1': 0.4918}), (19, 0.7554, {'top1': 0.7554}), (20, 0.8108, {'top1': 0.8108}), (21, 0.8092, {'top1': 0.8092}), (22, 0.7514, {'top1': 0.7514}), (23, 0.8084, {'top1': 0.8084}), (24, 0.8282, {'top1': 0.8282}), (25, 0.8314, {'top1': 0.8314}), (26, 0.8326, {'top1': 0.8326}), (27, 0.8184, {'top1': 0.8184}), (28, 0.8348, {'top1': 0.8348}), (29, 0.8292, {'top1': 0.8292}), (30, 0.8222, {'top1': 0.8222}), (34, 0.8328, {'top1': 0.8328}), (36, 0.5116, {'top1': 0.5116}), (46, 0.8408, {'top1': 0.8408}), (48, 0.8386, {'top1': 0.8386}), (50, 0.8194, {'top1': 0.8194}), (51, 0.771, {'top1': 0.771}), (52, 0.336, {'top1': 0.336}), (53, 0.1836, {'top1': 0.1836})]
just computed impact of block 46 . accuracy after removing:  0.8408
removed block 46 current accuracy 0.8408 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.781, {'top1': 0.781}), (1, 0.7954, {'top1': 0.7954}), (2, 0.7818, {'top1': 0.7818}), (3, 0.8246, {'top1': 0.8246}), (4, 0.8312, {'top1': 0.8312}), (5, 0.7616, {'top1': 0.7616}), (7, 0.8162, {'top1': 0.8162}), (8, 0.815, {'top1': 0.815}), (9, 0.7758, {'top1': 0.7758}), (10, 0.7902, {'top1': 0.7902}), (13, 0.7908, {'top1': 0.7908}), (15, 0.8276, {'top1': 0.8276}), (16, 0.7682, {'top1': 0.7682}), (17, 0.7942, {'top1': 0.7942}), (18, 0.4948, {'top1': 0.4948}), (19, 0.7518, {'top1': 0.7518}), (20, 0.8048, {'top1': 0.8048}), (21, 0.8008, {'top1': 0.8008}), (22, 0.7434, {'top1': 0.7434}), (23, 0.7996, {'top1': 0.7996}), (24, 0.824, {'top1': 0.824}), (25, 0.8254, {'top1': 0.8254}), (26, 0.8284, {'top1': 0.8284}), (27, 0.8098, {'top1': 0.8098}), (28, 0.829, {'top1': 0.829}), (29, 0.827, {'top1': 0.827}), (30, 0.8158, {'top1': 0.8158}), (34, 0.831, {'top1': 0.831}), (36, 0.5072, {'top1': 0.5072}), (48, 0.8268, {'top1': 0.8268}), (50, 0.8118, {'top1': 0.8118}), (51, 0.7618, {'top1': 0.7618}), (52, 0.3402, {'top1': 0.3402}), (53, 0.182, {'top1': 0.182})]
just computed impact of block 4 . accuracy after removing:  0.8312
removed block 4 current accuracy 0.8312 loss from initial  0.018799999999999928
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.7608, {'top1': 0.7608}), (1, 0.781, {'top1': 0.781}), (2, 0.7566, {'top1': 0.7566}), (3, 0.8116, {'top1': 0.8116}), (5, 0.7658, {'top1': 0.7658}), (7, 0.803, {'top1': 0.803}), (8, 0.8056, {'top1': 0.8056}), (9, 0.7434, {'top1': 0.7434}), (10, 0.7678, {'top1': 0.7678}), (13, 0.7802, {'top1': 0.7802}), (15, 0.8188, {'top1': 0.8188}), (16, 0.759, {'top1': 0.759}), (17, 0.7884, {'top1': 0.7884}), (18, 0.4858, {'top1': 0.4858}), (19, 0.7546, {'top1': 0.7546}), (20, 0.8046, {'top1': 0.8046}), (21, 0.7912, {'top1': 0.7912}), (22, 0.7374, {'top1': 0.7374}), (23, 0.793, {'top1': 0.793}), (24, 0.8168, {'top1': 0.8168}), (25, 0.8144, {'top1': 0.8144}), (26, 0.819, {'top1': 0.819}), (27, 0.8022, {'top1': 0.8022}), (28, 0.8198, {'top1': 0.8198}), (29, 0.8152, {'top1': 0.8152}), (30, 0.8054, {'top1': 0.8054}), (34, 0.8218, {'top1': 0.8218}), (36, 0.496, {'top1': 0.496}), (48, 0.8222, {'top1': 0.8222}), (50, 0.8108, {'top1': 0.8108}), (51, 0.7606, {'top1': 0.7606}), (52, 0.3466, {'top1': 0.3466}), (53, 0.1828, {'top1': 0.1828})]
just computed impact of block 48 . accuracy after removing:  0.8222
removed block 48 current accuracy 0.8222 loss from initial  0.027799999999999936
since last training loss: 0.027799999999999936 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7458, {'top1': 0.7458}), (1, 0.765, {'top1': 0.765}), (2, 0.7522, {'top1': 0.7522}), (3, 0.8062, {'top1': 0.8062}), (5, 0.759, {'top1': 0.759}), (7, 0.8004, {'top1': 0.8004}), (8, 0.8004, {'top1': 0.8004}), (9, 0.7278, {'top1': 0.7278}), (10, 0.762, {'top1': 0.762}), (13, 0.7636, {'top1': 0.7636}), (15, 0.8092, {'top1': 0.8092}), (16, 0.7458, {'top1': 0.7458}), (17, 0.7722, {'top1': 0.7722}), (18, 0.48, {'top1': 0.48}), (19, 0.744, {'top1': 0.744}), (20, 0.7956, {'top1': 0.7956}), (21, 0.791, {'top1': 0.791}), (22, 0.7324, {'top1': 0.7324}), (23, 0.7902, {'top1': 0.7902}), (24, 0.8092, {'top1': 0.8092}), (25, 0.8134, {'top1': 0.8134}), (26, 0.814, {'top1': 0.814}), (27, 0.7966, {'top1': 0.7966}), (28, 0.8142, {'top1': 0.8142}), (29, 0.8108, {'top1': 0.8108}), (30, 0.8018, {'top1': 0.8018}), (34, 0.814, {'top1': 0.814}), (36, 0.4968, {'top1': 0.4968}), (50, 0.8092, {'top1': 0.8092}), (51, 0.7476, {'top1': 0.7476}), (52, 0.356, {'top1': 0.356}), (53, 0.1786, {'top1': 0.1786})]
just computed impact of block 28 . accuracy after removing:  0.8142
removed block 28 current accuracy 0.8142 loss from initial  0.03579999999999994
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7432, {'top1': 0.7432}), (1, 0.7594, {'top1': 0.7594}), (2, 0.736, {'top1': 0.736}), (3, 0.7934, {'top1': 0.7934}), (5, 0.7362, {'top1': 0.7362}), (7, 0.785, {'top1': 0.785}), (8, 0.7878, {'top1': 0.7878}), (9, 0.7266, {'top1': 0.7266}), (10, 0.7522, {'top1': 0.7522}), (13, 0.7652, {'top1': 0.7652}), (15, 0.8032, {'top1': 0.8032}), (16, 0.7378, {'top1': 0.7378}), (17, 0.7662, {'top1': 0.7662}), (18, 0.4574, {'top1': 0.4574}), (19, 0.7402, {'top1': 0.7402}), (20, 0.785, {'top1': 0.785}), (21, 0.7672, {'top1': 0.7672}), (22, 0.712, {'top1': 0.712}), (23, 0.7698, {'top1': 0.7698}), (24, 0.7984, {'top1': 0.7984}), (25, 0.7982, {'top1': 0.7982}), (26, 0.7994, {'top1': 0.7994}), (27, 0.7826, {'top1': 0.7826}), (29, 0.795, {'top1': 0.795}), (30, 0.7848, {'top1': 0.7848}), (34, 0.804, {'top1': 0.804}), (36, 0.4594, {'top1': 0.4594}), (50, 0.7936, {'top1': 0.7936}), (51, 0.739, {'top1': 0.739}), (52, 0.3504, {'top1': 0.3504}), (53, 0.1796, {'top1': 0.1796})]
just computed impact of block 34 . accuracy after removing:  0.804
removed block 34 current accuracy 0.804 loss from initial  0.04599999999999993
since last training loss: 0.04599999999999993 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7328, {'top1': 0.7328}), (1, 0.7534, {'top1': 0.7534}), (2, 0.7218, {'top1': 0.7218}), (3, 0.781, {'top1': 0.781}), (5, 0.7244, {'top1': 0.7244}), (7, 0.7732, {'top1': 0.7732}), (8, 0.7712, {'top1': 0.7712}), (9, 0.706, {'top1': 0.706}), (10, 0.7362, {'top1': 0.7362}), (13, 0.743, {'top1': 0.743}), (15, 0.7936, {'top1': 0.7936}), (16, 0.72, {'top1': 0.72}), (17, 0.748, {'top1': 0.748}), (18, 0.4238, {'top1': 0.4238}), (19, 0.7174, {'top1': 0.7174}), (20, 0.7714, {'top1': 0.7714}), (21, 0.7572, {'top1': 0.7572}), (22, 0.6956, {'top1': 0.6956}), (23, 0.7544, {'top1': 0.7544}), (24, 0.7868, {'top1': 0.7868}), (25, 0.7842, {'top1': 0.7842}), (26, 0.7842, {'top1': 0.7842}), (27, 0.768, {'top1': 0.768}), (29, 0.7816, {'top1': 0.7816}), (30, 0.766, {'top1': 0.766}), (36, 0.4316, {'top1': 0.4316}), (50, 0.7794, {'top1': 0.7794}), (51, 0.7298, {'top1': 0.7298}), (52, 0.3328, {'top1': 0.3328}), (53, 0.1718, {'top1': 0.1718})]
just computed impact of block 15 . accuracy after removing:  0.7936
removed block 15 current accuracy 0.7936 loss from initial  0.056400000000000006
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.7166, {'top1': 0.7166}), (1, 0.7378, {'top1': 0.7378}), (2, 0.7134, {'top1': 0.7134}), (3, 0.7732, {'top1': 0.7732}), (5, 0.727, {'top1': 0.727}), (7, 0.7626, {'top1': 0.7626}), (8, 0.7592, {'top1': 0.7592}), (9, 0.697, {'top1': 0.697}), (10, 0.7212, {'top1': 0.7212}), (13, 0.7116, {'top1': 0.7116}), (16, 0.6662, {'top1': 0.6662}), (17, 0.7004, {'top1': 0.7004}), (18, 0.4154, {'top1': 0.4154}), (19, 0.6954, {'top1': 0.6954}), (20, 0.764, {'top1': 0.764}), (21, 0.743, {'top1': 0.743}), (22, 0.6838, {'top1': 0.6838}), (23, 0.7434, {'top1': 0.7434}), (24, 0.7708, {'top1': 0.7708}), (25, 0.773, {'top1': 0.773}), (26, 0.778, {'top1': 0.778}), (27, 0.7632, {'top1': 0.7632}), (29, 0.7722, {'top1': 0.7722}), (30, 0.7602, {'top1': 0.7602}), (36, 0.4226, {'top1': 0.4226}), (50, 0.7726, {'top1': 0.7726}), (51, 0.7138, {'top1': 0.7138}), (52, 0.3142, {'top1': 0.3142}), (53, 0.1646, {'top1': 0.1646})]
just computed impact of block 26 . accuracy after removing:  0.778
removed block 26 current accuracy 0.778 loss from initial  0.07199999999999995
since last training loss: 0.07199999999999995 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.7056, {'top1': 0.7056}), (1, 0.7234, {'top1': 0.7234}), (2, 0.666, {'top1': 0.666}), (3, 0.738, {'top1': 0.738}), (5, 0.6822, {'top1': 0.6822}), (7, 0.728, {'top1': 0.728}), (8, 0.7192, {'top1': 0.7192}), (9, 0.6802, {'top1': 0.6802}), (10, 0.6866, {'top1': 0.6866}), (13, 0.7046, {'top1': 0.7046}), (16, 0.6436, {'top1': 0.6436}), (17, 0.6856, {'top1': 0.6856}), (18, 0.3682, {'top1': 0.3682}), (19, 0.6862, {'top1': 0.6862}), (20, 0.7464, {'top1': 0.7464}), (21, 0.7148, {'top1': 0.7148}), (22, 0.6436, {'top1': 0.6436}), (23, 0.7004, {'top1': 0.7004}), (24, 0.7436, {'top1': 0.7436}), (25, 0.7432, {'top1': 0.7432}), (27, 0.725, {'top1': 0.725}), (29, 0.7362, {'top1': 0.7362}), (30, 0.7238, {'top1': 0.7238}), (36, 0.353, {'top1': 0.353}), (50, 0.7422, {'top1': 0.7422}), (51, 0.6992, {'top1': 0.6992}), (52, 0.3402, {'top1': 0.3402}), (53, 0.1716, {'top1': 0.1716})]
just computed impact of block 20 . accuracy after removing:  0.7464
removed block 20 current accuracy 0.7464 loss from initial  0.10360000000000003
training start
training epoch 0 val accuracy 0.7796 topk_dict {'top1': 0.7796} is_best True lr [0.1]
training epoch 1 val accuracy 0.769 topk_dict {'top1': 0.769} is_best False lr [0.1]
training epoch 2 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best True lr [0.1]
training epoch 3 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 4 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.1]
training epoch 5 val accuracy 0.8046 topk_dict {'top1': 0.8046} is_best False lr [0.1]
training epoch 6 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best True lr [0.1]
training epoch 7 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 8 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 9 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 10 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 11 val accuracy 0.829 topk_dict {'top1': 0.829} is_best False lr [0.1]
training epoch 12 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.1]
training epoch 13 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 14 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best True lr [0.1]
training epoch 15 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 16 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 17 val accuracy 0.8112 topk_dict {'top1': 0.8112} is_best False lr [0.1]
training epoch 18 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.1]
training epoch 19 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 20 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 21 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 22 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 23 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 24 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 25 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 26 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 27 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 28 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best True lr [0.1]
training epoch 29 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 30 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.1]
training epoch 31 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 32 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 33 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 34 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 35 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 36 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 37 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 38 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 39 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.1]
training epoch 40 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 41 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 42 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 43 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 44 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 45 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 46 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 47 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 48 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 49 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 50 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 51 val accuracy 0.814 topk_dict {'top1': 0.814} is_best False lr [0.1]
training epoch 52 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 53 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.1]
training epoch 54 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 55 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 56 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 57 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 58 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 59 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 60 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best False lr [0.1]
training epoch 61 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 62 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 63 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 64 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 65 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 66 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 67 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 68 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 69 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 70 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 71 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 72 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 73 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 74 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 75 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 76 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 77 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 78 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 79 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 80 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 81 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 82 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 83 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 84 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 85 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 86 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 87 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 88 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 89 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 90 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 91 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 92 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 93 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 94 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 95 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 96 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 97 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 98 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 99 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 100 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 101 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 102 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 103 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 104 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 105 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 106 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 107 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 108 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 109 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 110 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 111 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 112 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 113 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 114 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 115 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 116 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 117 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 118 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 119 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 120 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 121 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 122 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 123 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 124 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 125 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 126 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 127 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 128 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 129 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 130 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 131 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 132 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 133 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 134 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 135 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 136 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 137 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 138 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 139 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 140 val accuracy 0.8198 topk_dict {'top1': 0.8198} is_best False lr [0.1]
training epoch 141 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 142 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 143 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 144 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 145 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 146 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 147 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 148 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 149 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 150 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 151 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 152 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 153 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 154 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 155 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 156 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 157 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 158 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 159 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 160 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 161 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 162 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 163 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 164 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 165 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 166 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 167 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 168 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 169 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 170 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 171 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 172 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 173 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 174 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 175 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 176 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 177 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 178 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 179 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 180 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 181 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 182 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 183 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 184 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 185 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 186 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 187 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 188 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 189 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 190 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 191 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 192 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 193 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 194 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 195 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 196 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 197 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 198 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 199 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 200 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 201 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 202 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 203 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 204 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 205 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 206 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 207 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 208 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 209 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 210 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 211 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.1]
training epoch 212 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 213 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 214 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 215 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 216 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 217 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.1]
training epoch 218 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 219 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 220 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 221 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 222 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 223 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 224 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 225 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 226 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 227 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 228 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 229 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 230 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 231 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 232 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 233 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 234 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.010000000000000002]
training epoch 235 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.010000000000000002]
training epoch 236 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 237 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.010000000000000002]
training epoch 238 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 239 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 240 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 241 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 242 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 246 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 250 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 261 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 269 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 280 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 306 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 307 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 308 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 352 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 353 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 354 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 355 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 356 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 357 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 358 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 359 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 366 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 445 (acc 0.938400)
finished training. finished 469 epochs. accuracy 0.9384 topk_dict {'top1': 0.9384}
