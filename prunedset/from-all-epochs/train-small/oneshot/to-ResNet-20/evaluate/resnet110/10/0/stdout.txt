start iteration 0
(cache recomputed) Accuracy log [(0, 0.668, {'top1': 0.668}), (1, 0.6752, {'top1': 0.6752}), (2, 0.469, {'top1': 0.469}), (3, 0.6292, {'top1': 0.6292}), (4, 0.6986, {'top1': 0.6986}), (5, 0.6274, {'top1': 0.6274}), (6, 0.689, {'top1': 0.689}), (7, 0.6666, {'top1': 0.6666}), (8, 0.6414, {'top1': 0.6414}), (9, 0.6536, {'top1': 0.6536}), (10, 0.6684, {'top1': 0.6684}), (11, 0.6784, {'top1': 0.6784}), (12, 0.6506, {'top1': 0.6506}), (13, 0.681, {'top1': 0.681}), (14, 0.6638, {'top1': 0.6638}), (15, 0.6588, {'top1': 0.6588}), (16, 0.661, {'top1': 0.661}), (17, 0.6748, {'top1': 0.6748}), (18, 0.52, {'top1': 0.52}), (19, 0.6502, {'top1': 0.6502}), (20, 0.6778, {'top1': 0.6778}), (21, 0.6672, {'top1': 0.6672}), (22, 0.6004, {'top1': 0.6004}), (23, 0.666, {'top1': 0.666}), (24, 0.6838, {'top1': 0.6838}), (25, 0.688, {'top1': 0.688}), (26, 0.6732, {'top1': 0.6732}), (27, 0.6608, {'top1': 0.6608}), (28, 0.6828, {'top1': 0.6828}), (29, 0.6638, {'top1': 0.6638}), (30, 0.6664, {'top1': 0.6664}), (31, 0.6768, {'top1': 0.6768}), (32, 0.6802, {'top1': 0.6802}), (33, 0.6848, {'top1': 0.6848}), (34, 0.6788, {'top1': 0.6788}), (35, 0.6802, {'top1': 0.6802}), (36, 0.3382, {'top1': 0.3382}), (37, 0.6902, {'top1': 0.6902}), (38, 0.6966, {'top1': 0.6966}), (39, 0.6958, {'top1': 0.6958}), (40, 0.7016, {'top1': 0.7016}), (41, 0.6992, {'top1': 0.6992}), (42, 0.6956, {'top1': 0.6956}), (43, 0.7022, {'top1': 0.7022}), (44, 0.703, {'top1': 0.703}), (45, 0.7064, {'top1': 0.7064}), (46, 0.7012, {'top1': 0.7012}), (47, 0.7, {'top1': 0.7}), (48, 0.7046, {'top1': 0.7046}), (49, 0.6992, {'top1': 0.6992}), (50, 0.6942, {'top1': 0.6942}), (51, 0.5898, {'top1': 0.5898}), (52, 0.3362, {'top1': 0.3362}), (53, 0.1758, {'top1': 0.1758})]
just computed impact of block 45 . accuracy after removing:  0.7064
removed block 45 current accuracy 0.7064 loss from initial  -0.018199999999999994
since last training loss: -0.018199999999999994 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.6828, {'top1': 0.6828}), (1, 0.6894, {'top1': 0.6894}), (2, 0.4816, {'top1': 0.4816}), (3, 0.6522, {'top1': 0.6522}), (4, 0.718, {'top1': 0.718}), (5, 0.6502, {'top1': 0.6502}), (6, 0.7082, {'top1': 0.7082}), (7, 0.691, {'top1': 0.691}), (8, 0.6652, {'top1': 0.6652}), (9, 0.6728, {'top1': 0.6728}), (10, 0.6888, {'top1': 0.6888}), (11, 0.6994, {'top1': 0.6994}), (12, 0.6774, {'top1': 0.6774}), (13, 0.69, {'top1': 0.69}), (14, 0.6872, {'top1': 0.6872}), (15, 0.6832, {'top1': 0.6832}), (16, 0.6862, {'top1': 0.6862}), (17, 0.6934, {'top1': 0.6934}), (18, 0.5554, {'top1': 0.5554}), (19, 0.6564, {'top1': 0.6564}), (20, 0.6906, {'top1': 0.6906}), (21, 0.6876, {'top1': 0.6876}), (22, 0.629, {'top1': 0.629}), (23, 0.6864, {'top1': 0.6864}), (24, 0.705, {'top1': 0.705}), (25, 0.7034, {'top1': 0.7034}), (26, 0.6932, {'top1': 0.6932}), (27, 0.6862, {'top1': 0.6862}), (28, 0.7006, {'top1': 0.7006}), (29, 0.687, {'top1': 0.687}), (30, 0.6882, {'top1': 0.6882}), (31, 0.6944, {'top1': 0.6944}), (32, 0.701, {'top1': 0.701}), (33, 0.703, {'top1': 0.703}), (34, 0.6974, {'top1': 0.6974}), (35, 0.6994, {'top1': 0.6994}), (36, 0.3482, {'top1': 0.3482}), (37, 0.7084, {'top1': 0.7084}), (38, 0.7132, {'top1': 0.7132}), (39, 0.7112, {'top1': 0.7112}), (40, 0.7176, {'top1': 0.7176}), (41, 0.717, {'top1': 0.717}), (42, 0.7116, {'top1': 0.7116}), (43, 0.7188, {'top1': 0.7188}), (44, 0.7192, {'top1': 0.7192}), (46, 0.7152, {'top1': 0.7152}), (47, 0.7162, {'top1': 0.7162}), (48, 0.7162, {'top1': 0.7162}), (49, 0.7134, {'top1': 0.7134}), (50, 0.708, {'top1': 0.708}), (51, 0.5952, {'top1': 0.5952}), (52, 0.331, {'top1': 0.331}), (53, 0.1686, {'top1': 0.1686})]
just computed impact of block 44 . accuracy after removing:  0.7192
removed block 44 current accuracy 0.7192 loss from initial  -0.030999999999999917
since last training loss: -0.030999999999999917 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.6896, {'top1': 0.6896}), (1, 0.7002, {'top1': 0.7002}), (2, 0.4962, {'top1': 0.4962}), (3, 0.667, {'top1': 0.667}), (4, 0.7312, {'top1': 0.7312}), (5, 0.6646, {'top1': 0.6646}), (6, 0.7224, {'top1': 0.7224}), (7, 0.7034, {'top1': 0.7034}), (8, 0.6794, {'top1': 0.6794}), (9, 0.6872, {'top1': 0.6872}), (10, 0.7026, {'top1': 0.7026}), (11, 0.7114, {'top1': 0.7114}), (12, 0.6924, {'top1': 0.6924}), (13, 0.7012, {'top1': 0.7012}), (14, 0.7026, {'top1': 0.7026}), (15, 0.6946, {'top1': 0.6946}), (16, 0.7034, {'top1': 0.7034}), (17, 0.7056, {'top1': 0.7056}), (18, 0.5662, {'top1': 0.5662}), (19, 0.6554, {'top1': 0.6554}), (20, 0.6988, {'top1': 0.6988}), (21, 0.7008, {'top1': 0.7008}), (22, 0.6488, {'top1': 0.6488}), (23, 0.6978, {'top1': 0.6978}), (24, 0.7202, {'top1': 0.7202}), (25, 0.7142, {'top1': 0.7142}), (26, 0.707, {'top1': 0.707}), (27, 0.7018, {'top1': 0.7018}), (28, 0.7156, {'top1': 0.7156}), (29, 0.7004, {'top1': 0.7004}), (30, 0.7054, {'top1': 0.7054}), (31, 0.7098, {'top1': 0.7098}), (32, 0.7166, {'top1': 0.7166}), (33, 0.7178, {'top1': 0.7178}), (34, 0.7124, {'top1': 0.7124}), (35, 0.7106, {'top1': 0.7106}), (36, 0.3576, {'top1': 0.3576}), (37, 0.7208, {'top1': 0.7208}), (38, 0.724, {'top1': 0.724}), (39, 0.7198, {'top1': 0.7198}), (40, 0.7264, {'top1': 0.7264}), (41, 0.725, {'top1': 0.725}), (42, 0.7206, {'top1': 0.7206}), (43, 0.7272, {'top1': 0.7272}), (46, 0.727, {'top1': 0.727}), (47, 0.7248, {'top1': 0.7248}), (48, 0.7266, {'top1': 0.7266}), (49, 0.7238, {'top1': 0.7238}), (50, 0.7202, {'top1': 0.7202}), (51, 0.6024, {'top1': 0.6024}), (52, 0.3356, {'top1': 0.3356}), (53, 0.1636, {'top1': 0.1636})]
just computed impact of block 4 . accuracy after removing:  0.7312
removed block 4 current accuracy 0.7312 loss from initial  -0.04299999999999993
since last training loss: -0.04299999999999993 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.6934, {'top1': 0.6934}), (1, 0.7038, {'top1': 0.7038}), (2, 0.4936, {'top1': 0.4936}), (3, 0.6634, {'top1': 0.6634}), (5, 0.6676, {'top1': 0.6676}), (6, 0.7212, {'top1': 0.7212}), (7, 0.7132, {'top1': 0.7132}), (8, 0.6826, {'top1': 0.6826}), (9, 0.6674, {'top1': 0.6674}), (10, 0.718, {'top1': 0.718}), (11, 0.7222, {'top1': 0.7222}), (12, 0.7054, {'top1': 0.7054}), (13, 0.697, {'top1': 0.697}), (14, 0.7204, {'top1': 0.7204}), (15, 0.7126, {'top1': 0.7126}), (16, 0.7132, {'top1': 0.7132}), (17, 0.7118, {'top1': 0.7118}), (18, 0.5412, {'top1': 0.5412}), (19, 0.6552, {'top1': 0.6552}), (20, 0.7082, {'top1': 0.7082}), (21, 0.7174, {'top1': 0.7174}), (22, 0.6688, {'top1': 0.6688}), (23, 0.7178, {'top1': 0.7178}), (24, 0.73, {'top1': 0.73}), (25, 0.729, {'top1': 0.729}), (26, 0.7194, {'top1': 0.7194}), (27, 0.7096, {'top1': 0.7096}), (28, 0.7242, {'top1': 0.7242}), (29, 0.71, {'top1': 0.71}), (30, 0.7124, {'top1': 0.7124}), (31, 0.7184, {'top1': 0.7184}), (32, 0.724, {'top1': 0.724}), (33, 0.7306, {'top1': 0.7306}), (34, 0.7228, {'top1': 0.7228}), (35, 0.7222, {'top1': 0.7222}), (36, 0.3602, {'top1': 0.3602}), (37, 0.729, {'top1': 0.729}), (38, 0.7334, {'top1': 0.7334}), (39, 0.7312, {'top1': 0.7312}), (40, 0.7374, {'top1': 0.7374}), (41, 0.7362, {'top1': 0.7362}), (42, 0.7324, {'top1': 0.7324}), (43, 0.7364, {'top1': 0.7364}), (46, 0.735, {'top1': 0.735}), (47, 0.732, {'top1': 0.732}), (48, 0.7356, {'top1': 0.7356}), (49, 0.7322, {'top1': 0.7322}), (50, 0.7332, {'top1': 0.7332}), (51, 0.6116, {'top1': 0.6116}), (52, 0.3458, {'top1': 0.3458}), (53, 0.1656, {'top1': 0.1656})]
just computed impact of block 40 . accuracy after removing:  0.7374
removed block 40 current accuracy 0.7374 loss from initial  -0.04920000000000002
since last training loss: -0.04920000000000002 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.7, {'top1': 0.7}), (1, 0.713, {'top1': 0.713}), (2, 0.511, {'top1': 0.511}), (3, 0.6776, {'top1': 0.6776}), (5, 0.6814, {'top1': 0.6814}), (6, 0.732, {'top1': 0.732}), (7, 0.7274, {'top1': 0.7274}), (8, 0.6958, {'top1': 0.6958}), (9, 0.6812, {'top1': 0.6812}), (10, 0.7284, {'top1': 0.7284}), (11, 0.7336, {'top1': 0.7336}), (12, 0.718, {'top1': 0.718}), (13, 0.7054, {'top1': 0.7054}), (14, 0.7306, {'top1': 0.7306}), (15, 0.7232, {'top1': 0.7232}), (16, 0.7234, {'top1': 0.7234}), (17, 0.7224, {'top1': 0.7224}), (18, 0.553, {'top1': 0.553}), (19, 0.6548, {'top1': 0.6548}), (20, 0.71, {'top1': 0.71}), (21, 0.7284, {'top1': 0.7284}), (22, 0.6844, {'top1': 0.6844}), (23, 0.7268, {'top1': 0.7268}), (24, 0.7384, {'top1': 0.7384}), (25, 0.736, {'top1': 0.736}), (26, 0.731, {'top1': 0.731}), (27, 0.7214, {'top1': 0.7214}), (28, 0.7334, {'top1': 0.7334}), (29, 0.7214, {'top1': 0.7214}), (30, 0.7244, {'top1': 0.7244}), (31, 0.7294, {'top1': 0.7294}), (32, 0.7366, {'top1': 0.7366}), (33, 0.7392, {'top1': 0.7392}), (34, 0.7334, {'top1': 0.7334}), (35, 0.733, {'top1': 0.733}), (36, 0.3716, {'top1': 0.3716}), (37, 0.7382, {'top1': 0.7382}), (38, 0.7398, {'top1': 0.7398}), (39, 0.739, {'top1': 0.739}), (41, 0.7434, {'top1': 0.7434}), (42, 0.7384, {'top1': 0.7384}), (43, 0.744, {'top1': 0.744}), (46, 0.7414, {'top1': 0.7414}), (47, 0.7394, {'top1': 0.7394}), (48, 0.7406, {'top1': 0.7406}), (49, 0.7396, {'top1': 0.7396}), (50, 0.739, {'top1': 0.739}), (51, 0.6162, {'top1': 0.6162}), (52, 0.3474, {'top1': 0.3474}), (53, 0.1586, {'top1': 0.1586})]
just computed impact of block 43 . accuracy after removing:  0.744
removed block 43 current accuracy 0.744 loss from initial  -0.05579999999999996
since last training loss: -0.05579999999999996 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.7046, {'top1': 0.7046}), (1, 0.7184, {'top1': 0.7184}), (2, 0.5254, {'top1': 0.5254}), (3, 0.6936, {'top1': 0.6936}), (5, 0.697, {'top1': 0.697}), (6, 0.739, {'top1': 0.739}), (7, 0.7318, {'top1': 0.7318}), (8, 0.708, {'top1': 0.708}), (9, 0.6914, {'top1': 0.6914}), (10, 0.7358, {'top1': 0.7358}), (11, 0.7374, {'top1': 0.7374}), (12, 0.727, {'top1': 0.727}), (13, 0.7132, {'top1': 0.7132}), (14, 0.7368, {'top1': 0.7368}), (15, 0.7348, {'top1': 0.7348}), (16, 0.7314, {'top1': 0.7314}), (17, 0.7316, {'top1': 0.7316}), (18, 0.5612, {'top1': 0.5612}), (19, 0.6598, {'top1': 0.6598}), (20, 0.7082, {'top1': 0.7082}), (21, 0.7358, {'top1': 0.7358}), (22, 0.6918, {'top1': 0.6918}), (23, 0.7312, {'top1': 0.7312}), (24, 0.7432, {'top1': 0.7432}), (25, 0.7428, {'top1': 0.7428}), (26, 0.7392, {'top1': 0.7392}), (27, 0.7332, {'top1': 0.7332}), (28, 0.742, {'top1': 0.742}), (29, 0.73, {'top1': 0.73}), (30, 0.7336, {'top1': 0.7336}), (31, 0.7386, {'top1': 0.7386}), (32, 0.7436, {'top1': 0.7436}), (33, 0.7452, {'top1': 0.7452}), (34, 0.7418, {'top1': 0.7418}), (35, 0.7406, {'top1': 0.7406}), (36, 0.3738, {'top1': 0.3738}), (37, 0.7448, {'top1': 0.7448}), (38, 0.7446, {'top1': 0.7446}), (39, 0.7448, {'top1': 0.7448}), (41, 0.7476, {'top1': 0.7476}), (42, 0.745, {'top1': 0.745}), (46, 0.747, {'top1': 0.747}), (47, 0.7458, {'top1': 0.7458}), (48, 0.7448, {'top1': 0.7448}), (49, 0.7458, {'top1': 0.7458}), (50, 0.7434, {'top1': 0.7434}), (51, 0.6224, {'top1': 0.6224}), (52, 0.3466, {'top1': 0.3466}), (53, 0.1574, {'top1': 0.1574})]
just computed impact of block 41 . accuracy after removing:  0.7476
removed block 41 current accuracy 0.7476 loss from initial  -0.05940000000000001
since last training loss: -0.05940000000000001 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.7046, {'top1': 0.7046}), (1, 0.7244, {'top1': 0.7244}), (2, 0.5394, {'top1': 0.5394}), (3, 0.7032, {'top1': 0.7032}), (5, 0.7054, {'top1': 0.7054}), (6, 0.7436, {'top1': 0.7436}), (7, 0.735, {'top1': 0.735}), (8, 0.7186, {'top1': 0.7186}), (9, 0.7002, {'top1': 0.7002}), (10, 0.741, {'top1': 0.741}), (11, 0.7418, {'top1': 0.7418}), (12, 0.7344, {'top1': 0.7344}), (13, 0.716, {'top1': 0.716}), (14, 0.7424, {'top1': 0.7424}), (15, 0.7384, {'top1': 0.7384}), (16, 0.7378, {'top1': 0.7378}), (17, 0.7346, {'top1': 0.7346}), (18, 0.5622, {'top1': 0.5622}), (19, 0.6474, {'top1': 0.6474}), (20, 0.706, {'top1': 0.706}), (21, 0.7418, {'top1': 0.7418}), (22, 0.6998, {'top1': 0.6998}), (23, 0.735, {'top1': 0.735}), (24, 0.7476, {'top1': 0.7476}), (25, 0.749, {'top1': 0.749}), (26, 0.743, {'top1': 0.743}), (27, 0.7412, {'top1': 0.7412}), (28, 0.7474, {'top1': 0.7474}), (29, 0.7384, {'top1': 0.7384}), (30, 0.743, {'top1': 0.743}), (31, 0.7448, {'top1': 0.7448}), (32, 0.7484, {'top1': 0.7484}), (33, 0.7508, {'top1': 0.7508}), (34, 0.746, {'top1': 0.746}), (35, 0.7464, {'top1': 0.7464}), (36, 0.3848, {'top1': 0.3848}), (37, 0.7516, {'top1': 0.7516}), (38, 0.7472, {'top1': 0.7472}), (39, 0.7486, {'top1': 0.7486}), (42, 0.7472, {'top1': 0.7472}), (46, 0.7514, {'top1': 0.7514}), (47, 0.747, {'top1': 0.747}), (48, 0.7484, {'top1': 0.7484}), (49, 0.7484, {'top1': 0.7484}), (50, 0.7434, {'top1': 0.7434}), (51, 0.6232, {'top1': 0.6232}), (52, 0.339, {'top1': 0.339}), (53, 0.1516, {'top1': 0.1516})]
just computed impact of block 37 . accuracy after removing:  0.7516
removed block 37 current accuracy 0.7516 loss from initial  -0.06340000000000001
since last training loss: -0.06340000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.7108, {'top1': 0.7108}), (1, 0.7244, {'top1': 0.7244}), (2, 0.5378, {'top1': 0.5378}), (3, 0.7, {'top1': 0.7}), (5, 0.7106, {'top1': 0.7106}), (6, 0.748, {'top1': 0.748}), (7, 0.7394, {'top1': 0.7394}), (8, 0.7198, {'top1': 0.7198}), (9, 0.6952, {'top1': 0.6952}), (10, 0.7444, {'top1': 0.7444}), (11, 0.7444, {'top1': 0.7444}), (12, 0.7334, {'top1': 0.7334}), (13, 0.7156, {'top1': 0.7156}), (14, 0.745, {'top1': 0.745}), (15, 0.741, {'top1': 0.741}), (16, 0.741, {'top1': 0.741}), (17, 0.7364, {'top1': 0.7364}), (18, 0.561, {'top1': 0.561}), (19, 0.6558, {'top1': 0.6558}), (20, 0.7156, {'top1': 0.7156}), (21, 0.7454, {'top1': 0.7454}), (22, 0.6992, {'top1': 0.6992}), (23, 0.7412, {'top1': 0.7412}), (24, 0.7514, {'top1': 0.7514}), (25, 0.7508, {'top1': 0.7508}), (26, 0.7462, {'top1': 0.7462}), (27, 0.7408, {'top1': 0.7408}), (28, 0.748, {'top1': 0.748}), (29, 0.7388, {'top1': 0.7388}), (30, 0.7442, {'top1': 0.7442}), (31, 0.7444, {'top1': 0.7444}), (32, 0.75, {'top1': 0.75}), (33, 0.7528, {'top1': 0.7528}), (34, 0.7488, {'top1': 0.7488}), (35, 0.748, {'top1': 0.748}), (36, 0.3778, {'top1': 0.3778}), (38, 0.7528, {'top1': 0.7528}), (39, 0.7526, {'top1': 0.7526}), (42, 0.7528, {'top1': 0.7528}), (46, 0.7522, {'top1': 0.7522}), (47, 0.7492, {'top1': 0.7492}), (48, 0.7512, {'top1': 0.7512}), (49, 0.7522, {'top1': 0.7522}), (50, 0.7514, {'top1': 0.7514}), (51, 0.632, {'top1': 0.632}), (52, 0.3574, {'top1': 0.3574}), (53, 0.1508, {'top1': 0.1508})]
just computed impact of block 33 . accuracy after removing:  0.7528
removed block 33 current accuracy 0.7528 loss from initial  -0.06459999999999999
since last training loss: -0.06459999999999999 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.7086, {'top1': 0.7086}), (1, 0.7238, {'top1': 0.7238}), (2, 0.5374, {'top1': 0.5374}), (3, 0.6974, {'top1': 0.6974}), (5, 0.7132, {'top1': 0.7132}), (6, 0.7462, {'top1': 0.7462}), (7, 0.7418, {'top1': 0.7418}), (8, 0.7214, {'top1': 0.7214}), (9, 0.7038, {'top1': 0.7038}), (10, 0.744, {'top1': 0.744}), (11, 0.7444, {'top1': 0.7444}), (12, 0.737, {'top1': 0.737}), (13, 0.7194, {'top1': 0.7194}), (14, 0.7426, {'top1': 0.7426}), (15, 0.74, {'top1': 0.74}), (16, 0.7394, {'top1': 0.7394}), (17, 0.7382, {'top1': 0.7382}), (18, 0.5552, {'top1': 0.5552}), (19, 0.6612, {'top1': 0.6612}), (20, 0.711, {'top1': 0.711}), (21, 0.7438, {'top1': 0.7438}), (22, 0.7032, {'top1': 0.7032}), (23, 0.7394, {'top1': 0.7394}), (24, 0.7498, {'top1': 0.7498}), (25, 0.7478, {'top1': 0.7478}), (26, 0.7474, {'top1': 0.7474}), (27, 0.7396, {'top1': 0.7396}), (28, 0.7476, {'top1': 0.7476}), (29, 0.7372, {'top1': 0.7372}), (30, 0.7442, {'top1': 0.7442}), (31, 0.745, {'top1': 0.745}), (32, 0.752, {'top1': 0.752}), (34, 0.747, {'top1': 0.747}), (35, 0.7494, {'top1': 0.7494}), (36, 0.3584, {'top1': 0.3584}), (38, 0.7536, {'top1': 0.7536}), (39, 0.7514, {'top1': 0.7514}), (42, 0.7528, {'top1': 0.7528}), (46, 0.7538, {'top1': 0.7538}), (47, 0.7496, {'top1': 0.7496}), (48, 0.7544, {'top1': 0.7544}), (49, 0.7552, {'top1': 0.7552}), (50, 0.752, {'top1': 0.752}), (51, 0.6318, {'top1': 0.6318}), (52, 0.3556, {'top1': 0.3556}), (53, 0.1514, {'top1': 0.1514})]
just computed impact of block 49 . accuracy after removing:  0.7552
removed block 49 current accuracy 0.7552 loss from initial  -0.06699999999999995
since last training loss: -0.06699999999999995 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.7128, {'top1': 0.7128}), (1, 0.7286, {'top1': 0.7286}), (2, 0.5452, {'top1': 0.5452}), (3, 0.7028, {'top1': 0.7028}), (5, 0.7232, {'top1': 0.7232}), (6, 0.7502, {'top1': 0.7502}), (7, 0.747, {'top1': 0.747}), (8, 0.7288, {'top1': 0.7288}), (9, 0.7076, {'top1': 0.7076}), (10, 0.745, {'top1': 0.745}), (11, 0.7478, {'top1': 0.7478}), (12, 0.7402, {'top1': 0.7402}), (13, 0.7178, {'top1': 0.7178}), (14, 0.7476, {'top1': 0.7476}), (15, 0.7438, {'top1': 0.7438}), (16, 0.7452, {'top1': 0.7452}), (17, 0.7404, {'top1': 0.7404}), (18, 0.5584, {'top1': 0.5584}), (19, 0.6526, {'top1': 0.6526}), (20, 0.7088, {'top1': 0.7088}), (21, 0.7462, {'top1': 0.7462}), (22, 0.7182, {'top1': 0.7182}), (23, 0.7468, {'top1': 0.7468}), (24, 0.7544, {'top1': 0.7544}), (25, 0.7532, {'top1': 0.7532}), (26, 0.7508, {'top1': 0.7508}), (27, 0.7446, {'top1': 0.7446}), (28, 0.753, {'top1': 0.753}), (29, 0.7432, {'top1': 0.7432}), (30, 0.7448, {'top1': 0.7448}), (31, 0.7482, {'top1': 0.7482}), (32, 0.754, {'top1': 0.754}), (34, 0.7516, {'top1': 0.7516}), (35, 0.7494, {'top1': 0.7494}), (36, 0.37, {'top1': 0.37}), (38, 0.7546, {'top1': 0.7546}), (39, 0.756, {'top1': 0.756}), (42, 0.7524, {'top1': 0.7524}), (46, 0.7538, {'top1': 0.7538}), (47, 0.7518, {'top1': 0.7518}), (48, 0.755, {'top1': 0.755}), (50, 0.7514, {'top1': 0.7514}), (51, 0.6244, {'top1': 0.6244}), (52, 0.3522, {'top1': 0.3522}), (53, 0.149, {'top1': 0.149})]
just computed impact of block 39 . accuracy after removing:  0.756
removed block 39 current accuracy 0.756 loss from initial  -0.06779999999999997
since last training loss: -0.06779999999999997 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.7122, {'top1': 0.7122}), (1, 0.7294, {'top1': 0.7294}), (2, 0.5464, {'top1': 0.5464}), (3, 0.7036, {'top1': 0.7036}), (5, 0.7232, {'top1': 0.7232}), (6, 0.7508, {'top1': 0.7508}), (7, 0.7484, {'top1': 0.7484}), (8, 0.7338, {'top1': 0.7338}), (9, 0.709, {'top1': 0.709}), (10, 0.7464, {'top1': 0.7464}), (11, 0.748, {'top1': 0.748}), (12, 0.7408, {'top1': 0.7408}), (13, 0.718, {'top1': 0.718}), (14, 0.748, {'top1': 0.748}), (15, 0.7456, {'top1': 0.7456}), (16, 0.7456, {'top1': 0.7456}), (17, 0.7444, {'top1': 0.7444}), (18, 0.5572, {'top1': 0.5572}), (19, 0.6546, {'top1': 0.6546}), (20, 0.7082, {'top1': 0.7082}), (21, 0.7458, {'top1': 0.7458}), (22, 0.714, {'top1': 0.714}), (23, 0.7468, {'top1': 0.7468}), (24, 0.7548, {'top1': 0.7548}), (25, 0.7536, {'top1': 0.7536}), (26, 0.7502, {'top1': 0.7502}), (27, 0.7454, {'top1': 0.7454}), (28, 0.7536, {'top1': 0.7536}), (29, 0.7438, {'top1': 0.7438}), (30, 0.7444, {'top1': 0.7444}), (31, 0.7468, {'top1': 0.7468}), (32, 0.756, {'top1': 0.756}), (34, 0.7536, {'top1': 0.7536}), (35, 0.7504, {'top1': 0.7504}), (36, 0.3734, {'top1': 0.3734}), (38, 0.7552, {'top1': 0.7552}), (42, 0.7524, {'top1': 0.7524}), (46, 0.753, {'top1': 0.753}), (47, 0.7496, {'top1': 0.7496}), (48, 0.754, {'top1': 0.754}), (50, 0.753, {'top1': 0.753}), (51, 0.626, {'top1': 0.626}), (52, 0.3562, {'top1': 0.3562}), (53, 0.148, {'top1': 0.148})]
just computed impact of block 32 . accuracy after removing:  0.756
removed block 32 current accuracy 0.756 loss from initial  -0.06779999999999997
since last training loss: -0.06779999999999997 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.708, {'top1': 0.708}), (1, 0.729, {'top1': 0.729}), (2, 0.5432, {'top1': 0.5432}), (3, 0.7044, {'top1': 0.7044}), (5, 0.7202, {'top1': 0.7202}), (6, 0.749, {'top1': 0.749}), (7, 0.744, {'top1': 0.744}), (8, 0.7318, {'top1': 0.7318}), (9, 0.7092, {'top1': 0.7092}), (10, 0.748, {'top1': 0.748}), (11, 0.7456, {'top1': 0.7456}), (12, 0.7404, {'top1': 0.7404}), (13, 0.724, {'top1': 0.724}), (14, 0.7486, {'top1': 0.7486}), (15, 0.7476, {'top1': 0.7476}), (16, 0.7466, {'top1': 0.7466}), (17, 0.7468, {'top1': 0.7468}), (18, 0.5124, {'top1': 0.5124}), (19, 0.6704, {'top1': 0.6704}), (20, 0.708, {'top1': 0.708}), (21, 0.736, {'top1': 0.736}), (22, 0.6996, {'top1': 0.6996}), (23, 0.7414, {'top1': 0.7414}), (24, 0.7532, {'top1': 0.7532}), (25, 0.7504, {'top1': 0.7504}), (26, 0.75, {'top1': 0.75}), (27, 0.744, {'top1': 0.744}), (28, 0.752, {'top1': 0.752}), (29, 0.7414, {'top1': 0.7414}), (30, 0.7444, {'top1': 0.7444}), (31, 0.7498, {'top1': 0.7498}), (34, 0.7518, {'top1': 0.7518}), (35, 0.7502, {'top1': 0.7502}), (36, 0.3526, {'top1': 0.3526}), (38, 0.7594, {'top1': 0.7594}), (42, 0.7552, {'top1': 0.7552}), (46, 0.7558, {'top1': 0.7558}), (47, 0.7556, {'top1': 0.7556}), (48, 0.7562, {'top1': 0.7562}), (50, 0.7576, {'top1': 0.7576}), (51, 0.6324, {'top1': 0.6324}), (52, 0.353, {'top1': 0.353}), (53, 0.149, {'top1': 0.149})]
just computed impact of block 38 . accuracy after removing:  0.7594
removed block 38 current accuracy 0.7594 loss from initial  -0.07119999999999993
since last training loss: -0.07119999999999993 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.7102, {'top1': 0.7102}), (1, 0.7346, {'top1': 0.7346}), (2, 0.5474, {'top1': 0.5474}), (3, 0.7096, {'top1': 0.7096}), (5, 0.7278, {'top1': 0.7278}), (6, 0.751, {'top1': 0.751}), (7, 0.7494, {'top1': 0.7494}), (8, 0.7374, {'top1': 0.7374}), (9, 0.7098, {'top1': 0.7098}), (10, 0.7494, {'top1': 0.7494}), (11, 0.7494, {'top1': 0.7494}), (12, 0.7452, {'top1': 0.7452}), (13, 0.7236, {'top1': 0.7236}), (14, 0.7526, {'top1': 0.7526}), (15, 0.7538, {'top1': 0.7538}), (16, 0.7516, {'top1': 0.7516}), (17, 0.748, {'top1': 0.748}), (18, 0.5148, {'top1': 0.5148}), (19, 0.6632, {'top1': 0.6632}), (20, 0.7122, {'top1': 0.7122}), (21, 0.7426, {'top1': 0.7426}), (22, 0.7068, {'top1': 0.7068}), (23, 0.7454, {'top1': 0.7454}), (24, 0.7562, {'top1': 0.7562}), (25, 0.7542, {'top1': 0.7542}), (26, 0.7514, {'top1': 0.7514}), (27, 0.7494, {'top1': 0.7494}), (28, 0.756, {'top1': 0.756}), (29, 0.7448, {'top1': 0.7448}), (30, 0.75, {'top1': 0.75}), (31, 0.7528, {'top1': 0.7528}), (34, 0.7556, {'top1': 0.7556}), (35, 0.7562, {'top1': 0.7562}), (36, 0.363, {'top1': 0.363}), (42, 0.7588, {'top1': 0.7588}), (46, 0.7586, {'top1': 0.7586}), (47, 0.7558, {'top1': 0.7558}), (48, 0.757, {'top1': 0.757}), (50, 0.7582, {'top1': 0.7582}), (51, 0.6312, {'top1': 0.6312}), (52, 0.3508, {'top1': 0.3508}), (53, 0.1462, {'top1': 0.1462})]
just computed impact of block 42 . accuracy after removing:  0.7588
removed block 42 current accuracy 0.7588 loss from initial  -0.0706
since last training loss: -0.0706 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.711, {'top1': 0.711}), (1, 0.7334, {'top1': 0.7334}), (2, 0.5562, {'top1': 0.5562}), (3, 0.7132, {'top1': 0.7132}), (5, 0.731, {'top1': 0.731}), (6, 0.7506, {'top1': 0.7506}), (7, 0.752, {'top1': 0.752}), (8, 0.742, {'top1': 0.742}), (9, 0.7128, {'top1': 0.7128}), (10, 0.7474, {'top1': 0.7474}), (11, 0.7482, {'top1': 0.7482}), (12, 0.7462, {'top1': 0.7462}), (13, 0.7218, {'top1': 0.7218}), (14, 0.7516, {'top1': 0.7516}), (15, 0.7502, {'top1': 0.7502}), (16, 0.753, {'top1': 0.753}), (17, 0.748, {'top1': 0.748}), (18, 0.5186, {'top1': 0.5186}), (19, 0.6654, {'top1': 0.6654}), (20, 0.7052, {'top1': 0.7052}), (21, 0.7418, {'top1': 0.7418}), (22, 0.7132, {'top1': 0.7132}), (23, 0.7494, {'top1': 0.7494}), (24, 0.7586, {'top1': 0.7586}), (25, 0.7558, {'top1': 0.7558}), (26, 0.751, {'top1': 0.751}), (27, 0.7508, {'top1': 0.7508}), (28, 0.7562, {'top1': 0.7562}), (29, 0.747, {'top1': 0.747}), (30, 0.7506, {'top1': 0.7506}), (31, 0.7518, {'top1': 0.7518}), (34, 0.7562, {'top1': 0.7562}), (35, 0.7538, {'top1': 0.7538}), (36, 0.3594, {'top1': 0.3594}), (46, 0.7596, {'top1': 0.7596}), (47, 0.753, {'top1': 0.753}), (48, 0.7544, {'top1': 0.7544}), (50, 0.755, {'top1': 0.755}), (51, 0.627, {'top1': 0.627}), (52, 0.3416, {'top1': 0.3416}), (53, 0.1442, {'top1': 0.1442})]
just computed impact of block 46 . accuracy after removing:  0.7596
removed block 46 current accuracy 0.7596 loss from initial  -0.07140000000000002
since last training loss: -0.07140000000000002 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.7106, {'top1': 0.7106}), (1, 0.7368, {'top1': 0.7368}), (2, 0.5658, {'top1': 0.5658}), (3, 0.716, {'top1': 0.716}), (5, 0.7394, {'top1': 0.7394}), (6, 0.7508, {'top1': 0.7508}), (7, 0.7564, {'top1': 0.7564}), (8, 0.745, {'top1': 0.745}), (9, 0.7082, {'top1': 0.7082}), (10, 0.7482, {'top1': 0.7482}), (11, 0.7528, {'top1': 0.7528}), (12, 0.7498, {'top1': 0.7498}), (13, 0.7138, {'top1': 0.7138}), (14, 0.7522, {'top1': 0.7522}), (15, 0.7518, {'top1': 0.7518}), (16, 0.7524, {'top1': 0.7524}), (17, 0.7492, {'top1': 0.7492}), (18, 0.531, {'top1': 0.531}), (19, 0.6448, {'top1': 0.6448}), (20, 0.703, {'top1': 0.703}), (21, 0.7498, {'top1': 0.7498}), (22, 0.7234, {'top1': 0.7234}), (23, 0.7522, {'top1': 0.7522}), (24, 0.757, {'top1': 0.757}), (25, 0.7548, {'top1': 0.7548}), (26, 0.7546, {'top1': 0.7546}), (27, 0.7518, {'top1': 0.7518}), (28, 0.7598, {'top1': 0.7598}), (29, 0.7556, {'top1': 0.7556}), (30, 0.7522, {'top1': 0.7522}), (31, 0.7546, {'top1': 0.7546}), (34, 0.7584, {'top1': 0.7584}), (35, 0.7552, {'top1': 0.7552}), (36, 0.3712, {'top1': 0.3712}), (47, 0.7502, {'top1': 0.7502}), (48, 0.7556, {'top1': 0.7556}), (50, 0.7486, {'top1': 0.7486}), (51, 0.6294, {'top1': 0.6294}), (52, 0.352, {'top1': 0.352}), (53, 0.1344, {'top1': 0.1344})]
just computed impact of block 28 . accuracy after removing:  0.7598
removed block 28 current accuracy 0.7598 loss from initial  -0.0716
since last training loss: -0.0716 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.7098, {'top1': 0.7098}), (1, 0.7356, {'top1': 0.7356}), (2, 0.559, {'top1': 0.559}), (3, 0.7162, {'top1': 0.7162}), (5, 0.737, {'top1': 0.737}), (6, 0.748, {'top1': 0.748}), (7, 0.7514, {'top1': 0.7514}), (8, 0.7452, {'top1': 0.7452}), (9, 0.71, {'top1': 0.71}), (10, 0.7492, {'top1': 0.7492}), (11, 0.7478, {'top1': 0.7478}), (12, 0.7502, {'top1': 0.7502}), (13, 0.7214, {'top1': 0.7214}), (14, 0.7524, {'top1': 0.7524}), (15, 0.7524, {'top1': 0.7524}), (16, 0.7524, {'top1': 0.7524}), (17, 0.7506, {'top1': 0.7506}), (18, 0.4986, {'top1': 0.4986}), (19, 0.6438, {'top1': 0.6438}), (20, 0.7062, {'top1': 0.7062}), (21, 0.7412, {'top1': 0.7412}), (22, 0.7102, {'top1': 0.7102}), (23, 0.7436, {'top1': 0.7436}), (24, 0.7516, {'top1': 0.7516}), (25, 0.7538, {'top1': 0.7538}), (26, 0.7522, {'top1': 0.7522}), (27, 0.7504, {'top1': 0.7504}), (29, 0.7476, {'top1': 0.7476}), (30, 0.7516, {'top1': 0.7516}), (31, 0.7528, {'top1': 0.7528}), (34, 0.7584, {'top1': 0.7584}), (35, 0.7558, {'top1': 0.7558}), (36, 0.3586, {'top1': 0.3586}), (47, 0.7504, {'top1': 0.7504}), (48, 0.7558, {'top1': 0.7558}), (50, 0.7508, {'top1': 0.7508}), (51, 0.6322, {'top1': 0.6322}), (52, 0.3438, {'top1': 0.3438}), (53, 0.1382, {'top1': 0.1382})]
just computed impact of block 34 . accuracy after removing:  0.7584
removed block 34 current accuracy 0.7584 loss from initial  -0.07019999999999993
since last training loss: -0.07019999999999993 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.7038, {'top1': 0.7038}), (1, 0.7296, {'top1': 0.7296}), (2, 0.5456, {'top1': 0.5456}), (3, 0.7144, {'top1': 0.7144}), (5, 0.725, {'top1': 0.725}), (6, 0.7486, {'top1': 0.7486}), (7, 0.7468, {'top1': 0.7468}), (8, 0.7412, {'top1': 0.7412}), (9, 0.7088, {'top1': 0.7088}), (10, 0.7454, {'top1': 0.7454}), (11, 0.7496, {'top1': 0.7496}), (12, 0.7468, {'top1': 0.7468}), (13, 0.7178, {'top1': 0.7178}), (14, 0.754, {'top1': 0.754}), (15, 0.7526, {'top1': 0.7526}), (16, 0.7514, {'top1': 0.7514}), (17, 0.7506, {'top1': 0.7506}), (18, 0.4578, {'top1': 0.4578}), (19, 0.6362, {'top1': 0.6362}), (20, 0.7086, {'top1': 0.7086}), (21, 0.7374, {'top1': 0.7374}), (22, 0.6926, {'top1': 0.6926}), (23, 0.7382, {'top1': 0.7382}), (24, 0.7504, {'top1': 0.7504}), (25, 0.7502, {'top1': 0.7502}), (26, 0.747, {'top1': 0.747}), (27, 0.7464, {'top1': 0.7464}), (29, 0.746, {'top1': 0.746}), (30, 0.7482, {'top1': 0.7482}), (31, 0.7514, {'top1': 0.7514}), (35, 0.7536, {'top1': 0.7536}), (36, 0.341, {'top1': 0.341}), (47, 0.752, {'top1': 0.752}), (48, 0.757, {'top1': 0.757}), (50, 0.7504, {'top1': 0.7504}), (51, 0.6356, {'top1': 0.6356}), (52, 0.324, {'top1': 0.324}), (53, 0.1344, {'top1': 0.1344})]
just computed impact of block 48 . accuracy after removing:  0.757
removed block 48 current accuracy 0.757 loss from initial  -0.06879999999999997
since last training loss: -0.06879999999999997 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.7012, {'top1': 0.7012}), (1, 0.7326, {'top1': 0.7326}), (2, 0.5622, {'top1': 0.5622}), (3, 0.7174, {'top1': 0.7174}), (5, 0.739, {'top1': 0.739}), (6, 0.7454, {'top1': 0.7454}), (7, 0.7536, {'top1': 0.7536}), (8, 0.7442, {'top1': 0.7442}), (9, 0.704, {'top1': 0.704}), (10, 0.7456, {'top1': 0.7456}), (11, 0.7468, {'top1': 0.7468}), (12, 0.7484, {'top1': 0.7484}), (13, 0.7108, {'top1': 0.7108}), (14, 0.7516, {'top1': 0.7516}), (15, 0.7532, {'top1': 0.7532}), (16, 0.7546, {'top1': 0.7546}), (17, 0.7494, {'top1': 0.7494}), (18, 0.475, {'top1': 0.475}), (19, 0.6308, {'top1': 0.6308}), (20, 0.7038, {'top1': 0.7038}), (21, 0.7418, {'top1': 0.7418}), (22, 0.7084, {'top1': 0.7084}), (23, 0.7438, {'top1': 0.7438}), (24, 0.7536, {'top1': 0.7536}), (25, 0.752, {'top1': 0.752}), (26, 0.754, {'top1': 0.754}), (27, 0.7532, {'top1': 0.7532}), (29, 0.7476, {'top1': 0.7476}), (30, 0.75, {'top1': 0.75}), (31, 0.7542, {'top1': 0.7542}), (35, 0.7506, {'top1': 0.7506}), (36, 0.3538, {'top1': 0.3538}), (47, 0.7498, {'top1': 0.7498}), (50, 0.7382, {'top1': 0.7382}), (51, 0.6252, {'top1': 0.6252}), (52, 0.3222, {'top1': 0.3222}), (53, 0.1276, {'top1': 0.1276})]
just computed impact of block 16 . accuracy after removing:  0.7546
removed block 16 current accuracy 0.7546 loss from initial  -0.06640000000000001
since last training loss: -0.06640000000000001 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.7022, {'top1': 0.7022}), (1, 0.7234, {'top1': 0.7234}), (2, 0.541, {'top1': 0.541}), (3, 0.704, {'top1': 0.704}), (5, 0.7212, {'top1': 0.7212}), (6, 0.7386, {'top1': 0.7386}), (7, 0.7374, {'top1': 0.7374}), (8, 0.7306, {'top1': 0.7306}), (9, 0.687, {'top1': 0.687}), (10, 0.739, {'top1': 0.739}), (11, 0.739, {'top1': 0.739}), (12, 0.7392, {'top1': 0.7392}), (13, 0.7068, {'top1': 0.7068}), (14, 0.7438, {'top1': 0.7438}), (15, 0.7412, {'top1': 0.7412}), (17, 0.745, {'top1': 0.745}), (18, 0.4864, {'top1': 0.4864}), (19, 0.6374, {'top1': 0.6374}), (20, 0.7052, {'top1': 0.7052}), (21, 0.7304, {'top1': 0.7304}), (22, 0.6842, {'top1': 0.6842}), (23, 0.7316, {'top1': 0.7316}), (24, 0.7424, {'top1': 0.7424}), (25, 0.7418, {'top1': 0.7418}), (26, 0.7434, {'top1': 0.7434}), (27, 0.7436, {'top1': 0.7436}), (29, 0.743, {'top1': 0.743}), (30, 0.7448, {'top1': 0.7448}), (31, 0.7474, {'top1': 0.7474}), (35, 0.7488, {'top1': 0.7488}), (36, 0.3464, {'top1': 0.3464}), (47, 0.7448, {'top1': 0.7448}), (50, 0.7408, {'top1': 0.7408}), (51, 0.6304, {'top1': 0.6304}), (52, 0.3548, {'top1': 0.3548}), (53, 0.1288, {'top1': 0.1288})]
just computed impact of block 35 . accuracy after removing:  0.7488
removed block 35 current accuracy 0.7488 loss from initial  -0.06059999999999999
since last training loss: -0.06059999999999999 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.6992, {'top1': 0.6992}), (1, 0.7196, {'top1': 0.7196}), (2, 0.5418, {'top1': 0.5418}), (3, 0.6982, {'top1': 0.6982}), (5, 0.7202, {'top1': 0.7202}), (6, 0.7346, {'top1': 0.7346}), (7, 0.7358, {'top1': 0.7358}), (8, 0.7298, {'top1': 0.7298}), (9, 0.6892, {'top1': 0.6892}), (10, 0.7356, {'top1': 0.7356}), (11, 0.7336, {'top1': 0.7336}), (12, 0.737, {'top1': 0.737}), (13, 0.709, {'top1': 0.709}), (14, 0.739, {'top1': 0.739}), (15, 0.7418, {'top1': 0.7418}), (17, 0.7424, {'top1': 0.7424}), (18, 0.477, {'top1': 0.477}), (19, 0.6386, {'top1': 0.6386}), (20, 0.6966, {'top1': 0.6966}), (21, 0.7298, {'top1': 0.7298}), (22, 0.6874, {'top1': 0.6874}), (23, 0.7332, {'top1': 0.7332}), (24, 0.7422, {'top1': 0.7422}), (25, 0.739, {'top1': 0.739}), (26, 0.7418, {'top1': 0.7418}), (27, 0.7406, {'top1': 0.7406}), (29, 0.7378, {'top1': 0.7378}), (30, 0.7392, {'top1': 0.7392}), (31, 0.7416, {'top1': 0.7416}), (36, 0.3332, {'top1': 0.3332}), (47, 0.7418, {'top1': 0.7418}), (50, 0.7396, {'top1': 0.7396}), (51, 0.623, {'top1': 0.623}), (52, 0.3392, {'top1': 0.3392}), (53, 0.128, {'top1': 0.128})]
just computed impact of block 17 . accuracy after removing:  0.7424
removed block 17 current accuracy 0.7424 loss from initial  -0.054199999999999915
since last training loss: -0.054199999999999915 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.6852, {'top1': 0.6852}), (1, 0.7124, {'top1': 0.7124}), (2, 0.5198, {'top1': 0.5198}), (3, 0.6884, {'top1': 0.6884}), (5, 0.707, {'top1': 0.707}), (6, 0.731, {'top1': 0.731}), (7, 0.7232, {'top1': 0.7232}), (8, 0.7156, {'top1': 0.7156}), (9, 0.6744, {'top1': 0.6744}), (10, 0.7312, {'top1': 0.7312}), (11, 0.7314, {'top1': 0.7314}), (12, 0.7242, {'top1': 0.7242}), (13, 0.701, {'top1': 0.701}), (14, 0.7358, {'top1': 0.7358}), (15, 0.7296, {'top1': 0.7296}), (18, 0.5018, {'top1': 0.5018}), (19, 0.6384, {'top1': 0.6384}), (20, 0.6962, {'top1': 0.6962}), (21, 0.7246, {'top1': 0.7246}), (22, 0.6842, {'top1': 0.6842}), (23, 0.7286, {'top1': 0.7286}), (24, 0.7382, {'top1': 0.7382}), (25, 0.7332, {'top1': 0.7332}), (26, 0.7342, {'top1': 0.7342}), (27, 0.733, {'top1': 0.733}), (29, 0.733, {'top1': 0.733}), (30, 0.7304, {'top1': 0.7304}), (31, 0.7314, {'top1': 0.7314}), (36, 0.3356, {'top1': 0.3356}), (47, 0.7336, {'top1': 0.7336}), (50, 0.728, {'top1': 0.728}), (51, 0.6024, {'top1': 0.6024}), (52, 0.34, {'top1': 0.34}), (53, 0.1306, {'top1': 0.1306})]
just computed impact of block 24 . accuracy after removing:  0.7382
removed block 24 current accuracy 0.7382 loss from initial  -0.04999999999999993
since last training loss: -0.04999999999999993 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.6788, {'top1': 0.6788}), (1, 0.7018, {'top1': 0.7018}), (2, 0.505, {'top1': 0.505}), (3, 0.678, {'top1': 0.678}), (5, 0.692, {'top1': 0.692}), (6, 0.7234, {'top1': 0.7234}), (7, 0.7088, {'top1': 0.7088}), (8, 0.7082, {'top1': 0.7082}), (9, 0.6686, {'top1': 0.6686}), (10, 0.7188, {'top1': 0.7188}), (11, 0.7216, {'top1': 0.7216}), (12, 0.7148, {'top1': 0.7148}), (13, 0.6978, {'top1': 0.6978}), (14, 0.7286, {'top1': 0.7286}), (15, 0.7258, {'top1': 0.7258}), (18, 0.463, {'top1': 0.463}), (19, 0.6024, {'top1': 0.6024}), (20, 0.6942, {'top1': 0.6942}), (21, 0.7092, {'top1': 0.7092}), (22, 0.6528, {'top1': 0.6528}), (23, 0.7094, {'top1': 0.7094}), (25, 0.721, {'top1': 0.721}), (26, 0.7248, {'top1': 0.7248}), (27, 0.7166, {'top1': 0.7166}), (29, 0.7186, {'top1': 0.7186}), (30, 0.7246, {'top1': 0.7246}), (31, 0.7282, {'top1': 0.7282}), (36, 0.3176, {'top1': 0.3176}), (47, 0.733, {'top1': 0.733}), (50, 0.7304, {'top1': 0.7304}), (51, 0.6198, {'top1': 0.6198}), (52, 0.337, {'top1': 0.337}), (53, 0.1284, {'top1': 0.1284})]
just computed impact of block 47 . accuracy after removing:  0.733
removed block 47 current accuracy 0.733 loss from initial  -0.04479999999999995
since last training loss: -0.04479999999999995 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.6836, {'top1': 0.6836}), (1, 0.699, {'top1': 0.699}), (2, 0.5134, {'top1': 0.5134}), (3, 0.6748, {'top1': 0.6748}), (5, 0.6952, {'top1': 0.6952}), (6, 0.7196, {'top1': 0.7196}), (7, 0.7118, {'top1': 0.7118}), (8, 0.707, {'top1': 0.707}), (9, 0.666, {'top1': 0.666}), (10, 0.711, {'top1': 0.711}), (11, 0.7124, {'top1': 0.7124}), (12, 0.7106, {'top1': 0.7106}), (13, 0.6912, {'top1': 0.6912}), (14, 0.7224, {'top1': 0.7224}), (15, 0.7198, {'top1': 0.7198}), (18, 0.4518, {'top1': 0.4518}), (19, 0.5928, {'top1': 0.5928}), (20, 0.6882, {'top1': 0.6882}), (21, 0.7102, {'top1': 0.7102}), (22, 0.6616, {'top1': 0.6616}), (23, 0.7108, {'top1': 0.7108}), (25, 0.7176, {'top1': 0.7176}), (26, 0.7272, {'top1': 0.7272}), (27, 0.7178, {'top1': 0.7178}), (29, 0.7202, {'top1': 0.7202}), (30, 0.721, {'top1': 0.721}), (31, 0.7238, {'top1': 0.7238}), (36, 0.3194, {'top1': 0.3194}), (50, 0.715, {'top1': 0.715}), (51, 0.6166, {'top1': 0.6166}), (52, 0.3444, {'top1': 0.3444}), (53, 0.13, {'top1': 0.13})]
just computed impact of block 26 . accuracy after removing:  0.7272
removed block 26 current accuracy 0.7272 loss from initial  -0.038999999999999924
since last training loss: -0.038999999999999924 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.6662, {'top1': 0.6662}), (1, 0.6888, {'top1': 0.6888}), (2, 0.4902, {'top1': 0.4902}), (3, 0.6658, {'top1': 0.6658}), (5, 0.6666, {'top1': 0.6666}), (6, 0.7128, {'top1': 0.7128}), (7, 0.6938, {'top1': 0.6938}), (8, 0.69, {'top1': 0.69}), (9, 0.6684, {'top1': 0.6684}), (10, 0.708, {'top1': 0.708}), (11, 0.707, {'top1': 0.707}), (12, 0.7044, {'top1': 0.7044}), (13, 0.6896, {'top1': 0.6896}), (14, 0.7152, {'top1': 0.7152}), (15, 0.7116, {'top1': 0.7116}), (18, 0.401, {'top1': 0.401}), (19, 0.5704, {'top1': 0.5704}), (20, 0.6838, {'top1': 0.6838}), (21, 0.6902, {'top1': 0.6902}), (22, 0.6194, {'top1': 0.6194}), (23, 0.683, {'top1': 0.683}), (25, 0.6954, {'top1': 0.6954}), (27, 0.6954, {'top1': 0.6954}), (29, 0.699, {'top1': 0.699}), (30, 0.7102, {'top1': 0.7102}), (31, 0.7142, {'top1': 0.7142}), (36, 0.3136, {'top1': 0.3136}), (50, 0.7176, {'top1': 0.7176}), (51, 0.6288, {'top1': 0.6288}), (52, 0.325, {'top1': 0.325}), (53, 0.126, {'top1': 0.126})]
just computed impact of block 50 . accuracy after removing:  0.7176
removed block 50 current accuracy 0.7176 loss from initial  -0.02939999999999998
since last training loss: -0.02939999999999998 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.61, {'top1': 0.61}), (1, 0.6906, {'top1': 0.6906}), (2, 0.4982, {'top1': 0.4982}), (3, 0.6892, {'top1': 0.6892}), (5, 0.6754, {'top1': 0.6754}), (6, 0.705, {'top1': 0.705}), (7, 0.6974, {'top1': 0.6974}), (8, 0.6986, {'top1': 0.6986}), (9, 0.654, {'top1': 0.654}), (10, 0.7118, {'top1': 0.7118}), (11, 0.699, {'top1': 0.699}), (12, 0.7112, {'top1': 0.7112}), (13, 0.6624, {'top1': 0.6624}), (14, 0.71, {'top1': 0.71}), (15, 0.713, {'top1': 0.713}), (18, 0.4168, {'top1': 0.4168}), (19, 0.5514, {'top1': 0.5514}), (20, 0.6392, {'top1': 0.6392}), (21, 0.689, {'top1': 0.689}), (22, 0.6526, {'top1': 0.6526}), (23, 0.679, {'top1': 0.679}), (25, 0.693, {'top1': 0.693}), (27, 0.7048, {'top1': 0.7048}), (29, 0.7066, {'top1': 0.7066}), (30, 0.7126, {'top1': 0.7126}), (31, 0.7054, {'top1': 0.7054}), (36, 0.3186, {'top1': 0.3186}), (51, 0.5762, {'top1': 0.5762}), (52, 0.1922, {'top1': 0.1922}), (53, 0.127, {'top1': 0.127})]
just computed impact of block 15 . accuracy after removing:  0.713
removed block 15 current accuracy 0.713 loss from initial  -0.024799999999999933
since last training loss: -0.024799999999999933 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.6088, {'top1': 0.6088}), (1, 0.6908, {'top1': 0.6908}), (2, 0.479, {'top1': 0.479}), (3, 0.6862, {'top1': 0.6862}), (5, 0.6598, {'top1': 0.6598}), (6, 0.7034, {'top1': 0.7034}), (7, 0.6824, {'top1': 0.6824}), (8, 0.6842, {'top1': 0.6842}), (9, 0.6442, {'top1': 0.6442}), (10, 0.7022, {'top1': 0.7022}), (11, 0.6898, {'top1': 0.6898}), (12, 0.7, {'top1': 0.7}), (13, 0.6656, {'top1': 0.6656}), (14, 0.7014, {'top1': 0.7014}), (18, 0.4312, {'top1': 0.4312}), (19, 0.5644, {'top1': 0.5644}), (20, 0.6456, {'top1': 0.6456}), (21, 0.6864, {'top1': 0.6864}), (22, 0.6366, {'top1': 0.6366}), (23, 0.6766, {'top1': 0.6766}), (25, 0.6904, {'top1': 0.6904}), (27, 0.7002, {'top1': 0.7002}), (29, 0.7036, {'top1': 0.7036}), (30, 0.7134, {'top1': 0.7134}), (31, 0.7048, {'top1': 0.7048}), (36, 0.3112, {'top1': 0.3112}), (51, 0.5766, {'top1': 0.5766}), (52, 0.2118, {'top1': 0.2118}), (53, 0.1302, {'top1': 0.1302})]
just computed impact of block 30 . accuracy after removing:  0.7134
removed block 30 current accuracy 0.7134 loss from initial  -0.0252
since last training loss: -0.0252 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.6112, {'top1': 0.6112}), (1, 0.6792, {'top1': 0.6792}), (2, 0.4728, {'top1': 0.4728}), (3, 0.6736, {'top1': 0.6736}), (5, 0.6474, {'top1': 0.6474}), (6, 0.7004, {'top1': 0.7004}), (7, 0.681, {'top1': 0.681}), (8, 0.6768, {'top1': 0.6768}), (9, 0.6476, {'top1': 0.6476}), (10, 0.6992, {'top1': 0.6992}), (11, 0.6896, {'top1': 0.6896}), (12, 0.6948, {'top1': 0.6948}), (13, 0.665, {'top1': 0.665}), (14, 0.7008, {'top1': 0.7008}), (18, 0.4016, {'top1': 0.4016}), (19, 0.5534, {'top1': 0.5534}), (20, 0.6506, {'top1': 0.6506}), (21, 0.6768, {'top1': 0.6768}), (22, 0.6218, {'top1': 0.6218}), (23, 0.6728, {'top1': 0.6728}), (25, 0.6802, {'top1': 0.6802}), (27, 0.6878, {'top1': 0.6878}), (29, 0.6872, {'top1': 0.6872}), (31, 0.6994, {'top1': 0.6994}), (36, 0.298, {'top1': 0.298}), (51, 0.572, {'top1': 0.572}), (52, 0.2096, {'top1': 0.2096}), (53, 0.1236, {'top1': 0.1236})]
just computed impact of block 14 . accuracy after removing:  0.7008
removed block 14 current accuracy 0.7008 loss from initial  -0.012599999999999945
since last training loss: -0.012599999999999945 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.6002, {'top1': 0.6002}), (1, 0.6684, {'top1': 0.6684}), (2, 0.4692, {'top1': 0.4692}), (3, 0.6678, {'top1': 0.6678}), (5, 0.6298, {'top1': 0.6298}), (6, 0.6896, {'top1': 0.6896}), (7, 0.6578, {'top1': 0.6578}), (8, 0.651, {'top1': 0.651}), (9, 0.6162, {'top1': 0.6162}), (10, 0.6768, {'top1': 0.6768}), (11, 0.665, {'top1': 0.665}), (12, 0.667, {'top1': 0.667}), (13, 0.6488, {'top1': 0.6488}), (18, 0.4136, {'top1': 0.4136}), (19, 0.5524, {'top1': 0.5524}), (20, 0.646, {'top1': 0.646}), (21, 0.6618, {'top1': 0.6618}), (22, 0.6004, {'top1': 0.6004}), (23, 0.6504, {'top1': 0.6504}), (25, 0.666, {'top1': 0.666}), (27, 0.6772, {'top1': 0.6772}), (29, 0.6728, {'top1': 0.6728}), (31, 0.6868, {'top1': 0.6868}), (36, 0.2928, {'top1': 0.2928}), (51, 0.5704, {'top1': 0.5704}), (52, 0.2148, {'top1': 0.2148}), (53, 0.1266, {'top1': 0.1266})]
just computed impact of block 6 . accuracy after removing:  0.6896
removed block 6 current accuracy 0.6896 loss from initial  -0.0013999999999999568
since last training loss: -0.0013999999999999568 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.5708, {'top1': 0.5708}), (1, 0.6532, {'top1': 0.6532}), (2, 0.4466, {'top1': 0.4466}), (3, 0.6436, {'top1': 0.6436}), (5, 0.6148, {'top1': 0.6148}), (7, 0.6408, {'top1': 0.6408}), (8, 0.6274, {'top1': 0.6274}), (9, 0.587, {'top1': 0.587}), (10, 0.659, {'top1': 0.659}), (11, 0.6466, {'top1': 0.6466}), (12, 0.6478, {'top1': 0.6478}), (13, 0.6338, {'top1': 0.6338}), (18, 0.4048, {'top1': 0.4048}), (19, 0.5362, {'top1': 0.5362}), (20, 0.633, {'top1': 0.633}), (21, 0.6466, {'top1': 0.6466}), (22, 0.5758, {'top1': 0.5758}), (23, 0.6382, {'top1': 0.6382}), (25, 0.6524, {'top1': 0.6524}), (27, 0.6592, {'top1': 0.6592}), (29, 0.6562, {'top1': 0.6562}), (31, 0.6728, {'top1': 0.6728}), (36, 0.2922, {'top1': 0.2922}), (51, 0.5714, {'top1': 0.5714}), (52, 0.2264, {'top1': 0.2264}), (53, 0.1268, {'top1': 0.1268})]
just computed impact of block 31 . accuracy after removing:  0.6728
removed block 31 current accuracy 0.6728 loss from initial  0.01540000000000008
since last training loss: 0.01540000000000008 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.5572, {'top1': 0.5572}), (1, 0.6352, {'top1': 0.6352}), (2, 0.4302, {'top1': 0.4302}), (3, 0.6292, {'top1': 0.6292}), (5, 0.5986, {'top1': 0.5986}), (7, 0.6236, {'top1': 0.6236}), (8, 0.6076, {'top1': 0.6076}), (9, 0.5836, {'top1': 0.5836}), (10, 0.6452, {'top1': 0.6452}), (11, 0.6328, {'top1': 0.6328}), (12, 0.6334, {'top1': 0.6334}), (13, 0.6248, {'top1': 0.6248}), (18, 0.3476, {'top1': 0.3476}), (19, 0.4912, {'top1': 0.4912}), (20, 0.6138, {'top1': 0.6138}), (21, 0.6296, {'top1': 0.6296}), (22, 0.5494, {'top1': 0.5494}), (23, 0.6176, {'top1': 0.6176}), (25, 0.632, {'top1': 0.632}), (27, 0.6376, {'top1': 0.6376}), (29, 0.6346, {'top1': 0.6346}), (36, 0.2818, {'top1': 0.2818}), (51, 0.5576, {'top1': 0.5576}), (52, 0.2276, {'top1': 0.2276}), (53, 0.124, {'top1': 0.124})]
just computed impact of block 10 . accuracy after removing:  0.6452
removed block 10 current accuracy 0.6452 loss from initial  0.04300000000000004
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.5446, {'top1': 0.5446}), (1, 0.6046, {'top1': 0.6046}), (2, 0.4218, {'top1': 0.4218}), (3, 0.6066, {'top1': 0.6066}), (5, 0.5672, {'top1': 0.5672}), (7, 0.5956, {'top1': 0.5956}), (8, 0.5802, {'top1': 0.5802}), (9, 0.5482, {'top1': 0.5482}), (11, 0.5978, {'top1': 0.5978}), (12, 0.5996, {'top1': 0.5996}), (13, 0.5956, {'top1': 0.5956}), (18, 0.344, {'top1': 0.344}), (19, 0.4846, {'top1': 0.4846}), (20, 0.5918, {'top1': 0.5918}), (21, 0.6002, {'top1': 0.6002}), (22, 0.523, {'top1': 0.523}), (23, 0.5892, {'top1': 0.5892}), (25, 0.605, {'top1': 0.605}), (27, 0.6106, {'top1': 0.6106}), (29, 0.6026, {'top1': 0.6026}), (36, 0.2722, {'top1': 0.2722}), (51, 0.555, {'top1': 0.555}), (52, 0.2504, {'top1': 0.2504}), (53, 0.126, {'top1': 0.126})]
just computed impact of block 27 . accuracy after removing:  0.6106
removed block 27 current accuracy 0.6106 loss from initial  0.0776
since last training loss: 0.0776 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.522, {'top1': 0.522}), (1, 0.562, {'top1': 0.562}), (2, 0.3924, {'top1': 0.3924}), (3, 0.5568, {'top1': 0.5568}), (5, 0.5132, {'top1': 0.5132}), (7, 0.5398, {'top1': 0.5398}), (8, 0.5238, {'top1': 0.5238}), (9, 0.5126, {'top1': 0.5126}), (11, 0.5488, {'top1': 0.5488}), (12, 0.5486, {'top1': 0.5486}), (13, 0.5564, {'top1': 0.5564}), (18, 0.2548, {'top1': 0.2548}), (19, 0.3842, {'top1': 0.3842}), (20, 0.5308, {'top1': 0.5308}), (21, 0.5306, {'top1': 0.5306}), (22, 0.4648, {'top1': 0.4648}), (23, 0.517, {'top1': 0.517}), (25, 0.5342, {'top1': 0.5342}), (29, 0.523, {'top1': 0.523}), (36, 0.2598, {'top1': 0.2598}), (51, 0.5356, {'top1': 0.5356}), (52, 0.2452, {'top1': 0.2452}), (53, 0.1164, {'top1': 0.1164})]
just computed impact of block 1 . accuracy after removing:  0.562
removed block 1 current accuracy 0.562 loss from initial  0.12619999999999998
since last training loss: 0.12619999999999998 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.4592, {'top1': 0.4592}), (2, 0.3086, {'top1': 0.3086}), (3, 0.4874, {'top1': 0.4874}), (5, 0.4646, {'top1': 0.4646}), (7, 0.4938, {'top1': 0.4938}), (8, 0.4786, {'top1': 0.4786}), (9, 0.4798, {'top1': 0.4798}), (11, 0.5072, {'top1': 0.5072}), (12, 0.5078, {'top1': 0.5078}), (13, 0.4992, {'top1': 0.4992}), (18, 0.233, {'top1': 0.233}), (19, 0.3432, {'top1': 0.3432}), (20, 0.4736, {'top1': 0.4736}), (21, 0.4836, {'top1': 0.4836}), (22, 0.421, {'top1': 0.421}), (23, 0.4692, {'top1': 0.4692}), (25, 0.4812, {'top1': 0.4812}), (29, 0.4774, {'top1': 0.4774}), (36, 0.2358, {'top1': 0.2358}), (51, 0.4938, {'top1': 0.4938}), (52, 0.2558, {'top1': 0.2558}), (53, 0.1246, {'top1': 0.1246})]
just computed impact of block 12 . accuracy after removing:  0.5078
removed block 12 current accuracy 0.5078 loss from initial  0.1804
since last training loss: 0.1804 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.4314, {'top1': 0.4314}), (2, 0.268, {'top1': 0.268}), (3, 0.4314, {'top1': 0.4314}), (5, 0.4062, {'top1': 0.4062}), (7, 0.4394, {'top1': 0.4394}), (8, 0.4186, {'top1': 0.4186}), (9, 0.4206, {'top1': 0.4206}), (11, 0.4422, {'top1': 0.4422}), (13, 0.449, {'top1': 0.449}), (18, 0.238, {'top1': 0.238}), (19, 0.3154, {'top1': 0.3154}), (20, 0.4368, {'top1': 0.4368}), (21, 0.4484, {'top1': 0.4484}), (22, 0.3834, {'top1': 0.3834}), (23, 0.4324, {'top1': 0.4324}), (25, 0.4416, {'top1': 0.4416}), (29, 0.4302, {'top1': 0.4302}), (36, 0.2186, {'top1': 0.2186}), (51, 0.4488, {'top1': 0.4488}), (52, 0.2848, {'top1': 0.2848}), (53, 0.1284, {'top1': 0.1284})]
just computed impact of block 13 . accuracy after removing:  0.449
removed block 13 current accuracy 0.449 loss from initial  0.23920000000000002
since last training loss: 0.23920000000000002 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.3718, {'top1': 0.3718}), (2, 0.2238, {'top1': 0.2238}), (3, 0.3894, {'top1': 0.3894}), (5, 0.3606, {'top1': 0.3606}), (7, 0.382, {'top1': 0.382}), (8, 0.3694, {'top1': 0.3694}), (9, 0.3324, {'top1': 0.3324}), (11, 0.375, {'top1': 0.375}), (18, 0.2454, {'top1': 0.2454}), (19, 0.285, {'top1': 0.285}), (20, 0.4016, {'top1': 0.4016}), (21, 0.3842, {'top1': 0.3842}), (22, 0.3214, {'top1': 0.3214}), (23, 0.3686, {'top1': 0.3686}), (25, 0.3836, {'top1': 0.3836}), (29, 0.3802, {'top1': 0.3802}), (36, 0.1632, {'top1': 0.1632}), (51, 0.393, {'top1': 0.393}), (52, 0.236, {'top1': 0.236}), (53, 0.1192, {'top1': 0.1192})]
just computed impact of block 20 . accuracy after removing:  0.4016
removed block 20 current accuracy 0.4016 loss from initial  0.2866
since last training loss: 0.2866 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.3264, {'top1': 0.3264}), (2, 0.2122, {'top1': 0.2122}), (3, 0.3336, {'top1': 0.3336}), (5, 0.3366, {'top1': 0.3366}), (7, 0.3494, {'top1': 0.3494}), (8, 0.3486, {'top1': 0.3486}), (9, 0.3208, {'top1': 0.3208}), (11, 0.3554, {'top1': 0.3554}), (18, 0.2046, {'top1': 0.2046}), (19, 0.2314, {'top1': 0.2314}), (21, 0.3268, {'top1': 0.3268}), (22, 0.267, {'top1': 0.267}), (23, 0.3038, {'top1': 0.3038}), (25, 0.3236, {'top1': 0.3236}), (29, 0.3222, {'top1': 0.3222}), (36, 0.1392, {'top1': 0.1392}), (51, 0.359, {'top1': 0.359}), (52, 0.1944, {'top1': 0.1944}), (53, 0.12, {'top1': 0.12})]
just computed impact of block 51 . accuracy after removing:  0.359
removed block 51 current accuracy 0.359 loss from initial  0.32920000000000005
since last training loss: 0.32920000000000005 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.275, {'top1': 0.275}), (2, 0.1728, {'top1': 0.1728}), (3, 0.2936, {'top1': 0.2936}), (5, 0.3068, {'top1': 0.3068}), (7, 0.3178, {'top1': 0.3178}), (8, 0.307, {'top1': 0.307}), (9, 0.2786, {'top1': 0.2786}), (11, 0.3172, {'top1': 0.3172}), (18, 0.1908, {'top1': 0.1908}), (19, 0.262, {'top1': 0.262}), (21, 0.2868, {'top1': 0.2868}), (22, 0.2516, {'top1': 0.2516}), (23, 0.2978, {'top1': 0.2978}), (25, 0.2956, {'top1': 0.2956}), (29, 0.2974, {'top1': 0.2974}), (36, 0.159, {'top1': 0.159}), (52, 0.1552, {'top1': 0.1552}), (53, 0.1334, {'top1': 0.1334})]
just computed impact of block 7 . accuracy after removing:  0.3178
removed block 7 current accuracy 0.3178 loss from initial  0.3704
since last training loss: 0.3704 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.2528, {'top1': 0.2528}), (2, 0.1646, {'top1': 0.1646}), (3, 0.255, {'top1': 0.255}), (5, 0.2622, {'top1': 0.2622}), (8, 0.252, {'top1': 0.252}), (9, 0.255, {'top1': 0.255}), (11, 0.2826, {'top1': 0.2826}), (18, 0.1736, {'top1': 0.1736}), (19, 0.2324, {'top1': 0.2324}), (21, 0.258, {'top1': 0.258}), (22, 0.2232, {'top1': 0.2232}), (23, 0.267, {'top1': 0.267}), (25, 0.26, {'top1': 0.26}), (29, 0.2634, {'top1': 0.2634}), (36, 0.1674, {'top1': 0.1674}), (52, 0.1606, {'top1': 0.1606}), (53, 0.138, {'top1': 0.138})]
just computed impact of block 11 . accuracy after removing:  0.2826
removed block 11 current accuracy 0.2826 loss from initial  0.4056
since last training loss: 0.4056 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.2394, {'top1': 0.2394}), (2, 0.1628, {'top1': 0.1628}), (3, 0.2266, {'top1': 0.2266}), (5, 0.2452, {'top1': 0.2452}), (8, 0.2318, {'top1': 0.2318}), (9, 0.2398, {'top1': 0.2398}), (18, 0.177, {'top1': 0.177}), (19, 0.219, {'top1': 0.219}), (21, 0.2462, {'top1': 0.2462}), (22, 0.209, {'top1': 0.209}), (23, 0.2482, {'top1': 0.2482}), (25, 0.2376, {'top1': 0.2376}), (29, 0.2396, {'top1': 0.2396}), (36, 0.1614, {'top1': 0.1614}), (52, 0.1666, {'top1': 0.1666}), (53, 0.139, {'top1': 0.139})]
just computed impact of block 23 . accuracy after removing:  0.2482
removed block 23 current accuracy 0.2482 loss from initial  0.44000000000000006
since last training loss: 0.44000000000000006 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.2116, {'top1': 0.2116}), (2, 0.177, {'top1': 0.177}), (3, 0.226, {'top1': 0.226}), (5, 0.1992, {'top1': 0.1992}), (8, 0.1952, {'top1': 0.1952}), (9, 0.2338, {'top1': 0.2338}), (18, 0.1404, {'top1': 0.1404}), (19, 0.1646, {'top1': 0.1646}), (21, 0.219, {'top1': 0.219}), (22, 0.1578, {'top1': 0.1578}), (25, 0.2266, {'top1': 0.2266}), (29, 0.2106, {'top1': 0.2106}), (36, 0.1438, {'top1': 0.1438}), (52, 0.1552, {'top1': 0.1552}), (53, 0.1284, {'top1': 0.1284})]
just computed impact of block 9 . accuracy after removing:  0.2338
removed block 9 current accuracy 0.2338 loss from initial  0.4544
since last training loss: 0.4544 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.212, {'top1': 0.212}), (2, 0.156, {'top1': 0.156}), (3, 0.2062, {'top1': 0.2062}), (5, 0.2216, {'top1': 0.2216}), (8, 0.2078, {'top1': 0.2078}), (18, 0.159, {'top1': 0.159}), (19, 0.188, {'top1': 0.188}), (21, 0.2106, {'top1': 0.2106}), (22, 0.1668, {'top1': 0.1668}), (25, 0.2122, {'top1': 0.2122}), (29, 0.209, {'top1': 0.209}), (36, 0.12, {'top1': 0.12}), (52, 0.154, {'top1': 0.154}), (53, 0.1204, {'top1': 0.1204})]
just computed impact of block 5 . accuracy after removing:  0.2216
removed block 5 current accuracy 0.2216 loss from initial  0.4666
since last training loss: 0.4666 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.2052, {'top1': 0.2052}), (2, 0.141, {'top1': 0.141}), (3, 0.1868, {'top1': 0.1868}), (8, 0.1956, {'top1': 0.1956}), (18, 0.1634, {'top1': 0.1634}), (19, 0.1774, {'top1': 0.1774}), (21, 0.1976, {'top1': 0.1976}), (22, 0.1726, {'top1': 0.1726}), (25, 0.2026, {'top1': 0.2026}), (29, 0.1942, {'top1': 0.1942}), (36, 0.1158, {'top1': 0.1158}), (52, 0.1638, {'top1': 0.1638}), (53, 0.126, {'top1': 0.126})]
just computed impact of block 0 . accuracy after removing:  0.2052
removed block 0 current accuracy 0.2052 loss from initial  0.48300000000000004
since last training loss: 0.48300000000000004 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(2, 0.1148, {'top1': 0.1148}), (3, 0.16, {'top1': 0.16}), (8, 0.176, {'top1': 0.176}), (18, 0.1504, {'top1': 0.1504}), (19, 0.1714, {'top1': 0.1714}), (21, 0.1808, {'top1': 0.1808}), (22, 0.1508, {'top1': 0.1508}), (25, 0.184, {'top1': 0.184}), (29, 0.1724, {'top1': 0.1724}), (36, 0.1234, {'top1': 0.1234}), (52, 0.1476, {'top1': 0.1476}), (53, 0.122, {'top1': 0.122})]
just computed impact of block 25 . accuracy after removing:  0.184
removed block 25 current accuracy 0.184 loss from initial  0.5042
since last training loss: 0.5042 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(2, 0.109, {'top1': 0.109}), (3, 0.138, {'top1': 0.138}), (8, 0.1726, {'top1': 0.1726}), (18, 0.1542, {'top1': 0.1542}), (19, 0.1514, {'top1': 0.1514}), (21, 0.1442, {'top1': 0.1442}), (22, 0.1578, {'top1': 0.1578}), (29, 0.154, {'top1': 0.154}), (36, 0.1188, {'top1': 0.1188}), (52, 0.1652, {'top1': 0.1652}), (53, 0.1382, {'top1': 0.1382})]
just computed impact of block 8 . accuracy after removing:  0.1726
removed block 8 current accuracy 0.1726 loss from initial  0.5156000000000001
since last training loss: 0.5156000000000001 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(2, 0.1394, {'top1': 0.1394}), (3, 0.1448, {'top1': 0.1448}), (18, 0.1608, {'top1': 0.1608}), (19, 0.122, {'top1': 0.122}), (21, 0.1338, {'top1': 0.1338}), (22, 0.1692, {'top1': 0.1692}), (29, 0.1474, {'top1': 0.1474}), (36, 0.1044, {'top1': 0.1044}), (52, 0.1706, {'top1': 0.1706}), (53, 0.1478, {'top1': 0.1478})]
just computed impact of block 52 . accuracy after removing:  0.1706
removed block 52 current accuracy 0.1706 loss from initial  0.5176000000000001
training start
training epoch 0 val accuracy 0.6062 topk_dict {'top1': 0.6062} is_best True lr [0.1]
training epoch 1 val accuracy 0.7134 topk_dict {'top1': 0.7134} is_best True lr [0.1]
training epoch 2 val accuracy 0.7404 topk_dict {'top1': 0.7404} is_best True lr [0.1]
training epoch 3 val accuracy 0.7612 topk_dict {'top1': 0.7612} is_best True lr [0.1]
training epoch 4 val accuracy 0.7436 topk_dict {'top1': 0.7436} is_best False lr [0.1]
training epoch 5 val accuracy 0.77 topk_dict {'top1': 0.77} is_best True lr [0.1]
training epoch 6 val accuracy 0.79 topk_dict {'top1': 0.79} is_best True lr [0.1]
training epoch 7 val accuracy 0.7804 topk_dict {'top1': 0.7804} is_best False lr [0.1]
training epoch 8 val accuracy 0.8008 topk_dict {'top1': 0.8008} is_best True lr [0.1]
training epoch 9 val accuracy 0.783 topk_dict {'top1': 0.783} is_best False lr [0.1]
training epoch 10 val accuracy 0.8052 topk_dict {'top1': 0.8052} is_best True lr [0.1]
training epoch 11 val accuracy 0.8054 topk_dict {'top1': 0.8054} is_best True lr [0.1]
training epoch 12 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best True lr [0.1]
training epoch 13 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best False lr [0.1]
training epoch 14 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.1]
training epoch 15 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best False lr [0.1]
training epoch 16 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best False lr [0.1]
training epoch 17 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.1]
training epoch 18 val accuracy 0.7962 topk_dict {'top1': 0.7962} is_best False lr [0.1]
training epoch 19 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best True lr [0.1]
training epoch 20 val accuracy 0.8102 topk_dict {'top1': 0.8102} is_best False lr [0.1]
training epoch 21 val accuracy 0.848 topk_dict {'top1': 0.848} is_best True lr [0.1]
training epoch 22 val accuracy 0.83 topk_dict {'top1': 0.83} is_best False lr [0.1]
training epoch 23 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best False lr [0.1]
training epoch 24 val accuracy 0.8082 topk_dict {'top1': 0.8082} is_best False lr [0.1]
training epoch 25 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best False lr [0.1]
training epoch 26 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.1]
training epoch 27 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best False lr [0.1]
training epoch 28 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 29 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best False lr [0.1]
training epoch 30 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 31 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best False lr [0.1]
training epoch 32 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 33 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best False lr [0.1]
training epoch 34 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best True lr [0.1]
training epoch 35 val accuracy 0.838 topk_dict {'top1': 0.838} is_best False lr [0.1]
training epoch 36 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best True lr [0.1]
training epoch 37 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.1]
training epoch 38 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 39 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best False lr [0.1]
training epoch 40 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 41 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 42 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 43 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.1]
training epoch 44 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 45 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 46 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 47 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 48 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 49 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 50 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 51 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 52 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 53 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best False lr [0.1]
training epoch 54 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 55 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 56 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 57 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 58 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 59 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 60 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 61 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 62 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 63 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 64 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 65 val accuracy 0.87 topk_dict {'top1': 0.87} is_best True lr [0.1]
training epoch 66 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best False lr [0.1]
training epoch 67 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 68 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 69 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 70 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 71 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best False lr [0.1]
training epoch 72 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 73 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 74 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 75 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 76 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.1]
training epoch 77 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 78 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best False lr [0.1]
training epoch 79 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 80 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 81 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 82 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 83 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 84 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best False lr [0.1]
training epoch 85 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 86 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 87 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.1]
training epoch 88 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 89 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 90 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 91 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 92 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 93 val accuracy 0.835 topk_dict {'top1': 0.835} is_best False lr [0.1]
training epoch 94 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 95 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 96 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best False lr [0.1]
training epoch 97 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 98 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 99 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 100 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 101 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 102 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 103 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 104 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 105 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 106 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best False lr [0.1]
training epoch 107 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 108 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 109 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 110 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 111 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 112 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 113 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 114 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 115 val accuracy 0.796 topk_dict {'top1': 0.796} is_best False lr [0.1]
training epoch 116 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 117 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 118 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 119 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 120 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best False lr [0.1]
training epoch 121 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 122 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best False lr [0.1]
training epoch 123 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.1]
training epoch 124 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 125 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 126 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 127 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 128 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 129 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 130 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 131 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 132 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 133 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 134 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 135 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 136 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best False lr [0.1]
training epoch 137 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 138 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 139 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 140 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 141 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 142 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 143 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 144 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 145 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 146 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 147 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 148 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 149 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 150 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 151 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 152 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 153 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 154 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 155 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 156 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best False lr [0.1]
training epoch 157 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 158 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 159 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 160 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 161 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 162 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 163 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best False lr [0.1]
training epoch 164 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 165 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 166 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 167 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 168 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 169 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 170 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 171 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 172 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 173 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 174 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 175 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 176 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 177 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 178 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 179 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 180 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 181 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 182 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 183 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 184 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 185 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 186 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 187 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.1]
training epoch 188 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 189 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 190 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 191 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.1]
training epoch 192 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 193 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 194 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 195 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 196 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 197 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 198 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 199 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 200 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 201 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.1]
training epoch 202 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 203 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 204 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 205 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 206 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 207 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 208 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 209 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 210 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 211 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 212 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 213 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 214 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 215 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 216 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 217 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 218 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 219 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 220 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 221 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 222 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 223 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 224 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 225 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 226 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 227 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 228 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 229 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 230 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 231 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 232 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 233 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 234 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 235 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 236 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 237 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 238 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 239 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 240 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 241 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 242 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 243 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 244 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.010000000000000002]
training epoch 245 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.010000000000000002]
training epoch 246 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.010000000000000002]
training epoch 247 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.010000000000000002]
training epoch 248 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.010000000000000002]
training epoch 249 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.010000000000000002]
training epoch 250 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.010000000000000002]
training epoch 254 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.010000000000000002]
training epoch 255 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.010000000000000002]
training epoch 259 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.010000000000000002]
training epoch 269 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.010000000000000002]
training epoch 276 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.0010000000000000002]
training epoch 481 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
loading model_best from epoch 480 (acc 0.920200)
finished training. finished 489 epochs. accuracy 0.9202 topk_dict {'top1': 0.9202}
