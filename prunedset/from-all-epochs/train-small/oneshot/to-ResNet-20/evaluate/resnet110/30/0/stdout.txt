start iteration 0
(cache recomputed) Accuracy log [(0, 0.7908, {'top1': 0.7908}), (1, 0.806, {'top1': 0.806}), (2, 0.8232, {'top1': 0.8232}), (3, 0.8486, {'top1': 0.8486}), (4, 0.839, {'top1': 0.839}), (5, 0.819, {'top1': 0.819}), (6, 0.849, {'top1': 0.849}), (7, 0.8452, {'top1': 0.8452}), (8, 0.8506, {'top1': 0.8506}), (9, 0.8118, {'top1': 0.8118}), (10, 0.8268, {'top1': 0.8268}), (11, 0.8448, {'top1': 0.8448}), (12, 0.855, {'top1': 0.855}), (13, 0.812, {'top1': 0.812}), (14, 0.8468, {'top1': 0.8468}), (15, 0.8422, {'top1': 0.8422}), (16, 0.821, {'top1': 0.821}), (17, 0.8286, {'top1': 0.8286}), (18, 0.4596, {'top1': 0.4596}), (19, 0.7758, {'top1': 0.7758}), (20, 0.834, {'top1': 0.834}), (21, 0.838, {'top1': 0.838}), (22, 0.8114, {'top1': 0.8114}), (23, 0.8396, {'top1': 0.8396}), (24, 0.846, {'top1': 0.846}), (25, 0.8468, {'top1': 0.8468}), (26, 0.8488, {'top1': 0.8488}), (27, 0.8418, {'top1': 0.8418}), (28, 0.8506, {'top1': 0.8506}), (29, 0.85, {'top1': 0.85}), (30, 0.845, {'top1': 0.845}), (31, 0.8514, {'top1': 0.8514}), (32, 0.855, {'top1': 0.855}), (33, 0.856, {'top1': 0.856}), (34, 0.8516, {'top1': 0.8516}), (35, 0.8506, {'top1': 0.8506}), (36, 0.6696, {'top1': 0.6696}), (37, 0.8496, {'top1': 0.8496}), (38, 0.8494, {'top1': 0.8494}), (39, 0.8534, {'top1': 0.8534}), (40, 0.8476, {'top1': 0.8476}), (41, 0.8458, {'top1': 0.8458}), (42, 0.8514, {'top1': 0.8514}), (43, 0.8496, {'top1': 0.8496}), (44, 0.8504, {'top1': 0.8504}), (45, 0.8514, {'top1': 0.8514}), (46, 0.8462, {'top1': 0.8462}), (47, 0.847, {'top1': 0.847}), (48, 0.8448, {'top1': 0.8448}), (49, 0.8456, {'top1': 0.8456}), (50, 0.8492, {'top1': 0.8492}), (51, 0.7848, {'top1': 0.7848}), (52, 0.3998, {'top1': 0.3998}), (53, 0.1776, {'top1': 0.1776})]
just computed impact of block 33 . accuracy after removing:  0.856
removed block 33 current accuracy 0.856 loss from initial  -0.006000000000000005
since last training loss: -0.006000000000000005 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.7962, {'top1': 0.7962}), (1, 0.811, {'top1': 0.811}), (2, 0.8242, {'top1': 0.8242}), (3, 0.8504, {'top1': 0.8504}), (4, 0.8444, {'top1': 0.8444}), (5, 0.818, {'top1': 0.818}), (6, 0.8504, {'top1': 0.8504}), (7, 0.8484, {'top1': 0.8484}), (8, 0.8518, {'top1': 0.8518}), (9, 0.8196, {'top1': 0.8196}), (10, 0.832, {'top1': 0.832}), (11, 0.85, {'top1': 0.85}), (12, 0.8594, {'top1': 0.8594}), (13, 0.8196, {'top1': 0.8196}), (14, 0.8518, {'top1': 0.8518}), (15, 0.8462, {'top1': 0.8462}), (16, 0.829, {'top1': 0.829}), (17, 0.835, {'top1': 0.835}), (18, 0.4828, {'top1': 0.4828}), (19, 0.7822, {'top1': 0.7822}), (20, 0.8376, {'top1': 0.8376}), (21, 0.8408, {'top1': 0.8408}), (22, 0.812, {'top1': 0.812}), (23, 0.8412, {'top1': 0.8412}), (24, 0.8474, {'top1': 0.8474}), (25, 0.8504, {'top1': 0.8504}), (26, 0.8526, {'top1': 0.8526}), (27, 0.841, {'top1': 0.841}), (28, 0.8538, {'top1': 0.8538}), (29, 0.8516, {'top1': 0.8516}), (30, 0.8452, {'top1': 0.8452}), (31, 0.8536, {'top1': 0.8536}), (32, 0.8552, {'top1': 0.8552}), (34, 0.8522, {'top1': 0.8522}), (35, 0.8536, {'top1': 0.8536}), (36, 0.6458, {'top1': 0.6458}), (37, 0.8556, {'top1': 0.8556}), (38, 0.853, {'top1': 0.853}), (39, 0.8564, {'top1': 0.8564}), (40, 0.8524, {'top1': 0.8524}), (41, 0.8528, {'top1': 0.8528}), (42, 0.8558, {'top1': 0.8558}), (43, 0.8548, {'top1': 0.8548}), (44, 0.8536, {'top1': 0.8536}), (45, 0.8564, {'top1': 0.8564}), (46, 0.8516, {'top1': 0.8516}), (47, 0.851, {'top1': 0.851}), (48, 0.8504, {'top1': 0.8504}), (49, 0.8524, {'top1': 0.8524}), (50, 0.8514, {'top1': 0.8514}), (51, 0.7898, {'top1': 0.7898}), (52, 0.3986, {'top1': 0.3986}), (53, 0.175, {'top1': 0.175})]
just computed impact of block 12 . accuracy after removing:  0.8594
removed block 12 current accuracy 0.8594 loss from initial  -0.009400000000000075
since last training loss: -0.009400000000000075 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8006, {'top1': 0.8006}), (1, 0.8198, {'top1': 0.8198}), (2, 0.8234, {'top1': 0.8234}), (3, 0.8534, {'top1': 0.8534}), (4, 0.8448, {'top1': 0.8448}), (5, 0.814, {'top1': 0.814}), (6, 0.8574, {'top1': 0.8574}), (7, 0.8484, {'top1': 0.8484}), (8, 0.8482, {'top1': 0.8482}), (9, 0.8268, {'top1': 0.8268}), (10, 0.8254, {'top1': 0.8254}), (11, 0.8522, {'top1': 0.8522}), (13, 0.8314, {'top1': 0.8314}), (14, 0.8546, {'top1': 0.8546}), (15, 0.847, {'top1': 0.847}), (16, 0.8316, {'top1': 0.8316}), (17, 0.84, {'top1': 0.84}), (18, 0.4944, {'top1': 0.4944}), (19, 0.7926, {'top1': 0.7926}), (20, 0.844, {'top1': 0.844}), (21, 0.84, {'top1': 0.84}), (22, 0.8192, {'top1': 0.8192}), (23, 0.8376, {'top1': 0.8376}), (24, 0.8524, {'top1': 0.8524}), (25, 0.8544, {'top1': 0.8544}), (26, 0.8576, {'top1': 0.8576}), (27, 0.8426, {'top1': 0.8426}), (28, 0.8568, {'top1': 0.8568}), (29, 0.8542, {'top1': 0.8542}), (30, 0.8438, {'top1': 0.8438}), (31, 0.855, {'top1': 0.855}), (32, 0.86, {'top1': 0.86}), (34, 0.8564, {'top1': 0.8564}), (35, 0.857, {'top1': 0.857}), (36, 0.6218, {'top1': 0.6218}), (37, 0.863, {'top1': 0.863}), (38, 0.8586, {'top1': 0.8586}), (39, 0.861, {'top1': 0.861}), (40, 0.8598, {'top1': 0.8598}), (41, 0.8582, {'top1': 0.8582}), (42, 0.862, {'top1': 0.862}), (43, 0.8586, {'top1': 0.8586}), (44, 0.8594, {'top1': 0.8594}), (45, 0.861, {'top1': 0.861}), (46, 0.8558, {'top1': 0.8558}), (47, 0.857, {'top1': 0.857}), (48, 0.8558, {'top1': 0.8558}), (49, 0.8578, {'top1': 0.8578}), (50, 0.8542, {'top1': 0.8542}), (51, 0.7964, {'top1': 0.7964}), (52, 0.4036, {'top1': 0.4036}), (53, 0.1752, {'top1': 0.1752})]
just computed impact of block 37 . accuracy after removing:  0.863
removed block 37 current accuracy 0.863 loss from initial  -0.013000000000000012
since last training loss: -0.013000000000000012 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.802, {'top1': 0.802}), (1, 0.8214, {'top1': 0.8214}), (2, 0.8236, {'top1': 0.8236}), (3, 0.8562, {'top1': 0.8562}), (4, 0.8504, {'top1': 0.8504}), (5, 0.8198, {'top1': 0.8198}), (6, 0.8566, {'top1': 0.8566}), (7, 0.852, {'top1': 0.852}), (8, 0.8502, {'top1': 0.8502}), (9, 0.8258, {'top1': 0.8258}), (10, 0.8306, {'top1': 0.8306}), (11, 0.8552, {'top1': 0.8552}), (13, 0.8314, {'top1': 0.8314}), (14, 0.8602, {'top1': 0.8602}), (15, 0.851, {'top1': 0.851}), (16, 0.8334, {'top1': 0.8334}), (17, 0.84, {'top1': 0.84}), (18, 0.5132, {'top1': 0.5132}), (19, 0.7972, {'top1': 0.7972}), (20, 0.8438, {'top1': 0.8438}), (21, 0.8456, {'top1': 0.8456}), (22, 0.823, {'top1': 0.823}), (23, 0.8442, {'top1': 0.8442}), (24, 0.8556, {'top1': 0.8556}), (25, 0.8566, {'top1': 0.8566}), (26, 0.859, {'top1': 0.859}), (27, 0.8436, {'top1': 0.8436}), (28, 0.861, {'top1': 0.861}), (29, 0.8564, {'top1': 0.8564}), (30, 0.8476, {'top1': 0.8476}), (31, 0.8582, {'top1': 0.8582}), (32, 0.8624, {'top1': 0.8624}), (34, 0.8596, {'top1': 0.8596}), (35, 0.859, {'top1': 0.859}), (36, 0.6184, {'top1': 0.6184}), (38, 0.8618, {'top1': 0.8618}), (39, 0.8634, {'top1': 0.8634}), (40, 0.8624, {'top1': 0.8624}), (41, 0.8612, {'top1': 0.8612}), (42, 0.8648, {'top1': 0.8648}), (43, 0.863, {'top1': 0.863}), (44, 0.8638, {'top1': 0.8638}), (45, 0.862, {'top1': 0.862}), (46, 0.86, {'top1': 0.86}), (47, 0.8584, {'top1': 0.8584}), (48, 0.8598, {'top1': 0.8598}), (49, 0.8604, {'top1': 0.8604}), (50, 0.8554, {'top1': 0.8554}), (51, 0.7952, {'top1': 0.7952}), (52, 0.4106, {'top1': 0.4106}), (53, 0.182, {'top1': 0.182})]
just computed impact of block 42 . accuracy after removing:  0.8648
removed block 42 current accuracy 0.8648 loss from initial  -0.014800000000000035
since last training loss: -0.014800000000000035 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8042, {'top1': 0.8042}), (1, 0.8244, {'top1': 0.8244}), (2, 0.8246, {'top1': 0.8246}), (3, 0.858, {'top1': 0.858}), (4, 0.852, {'top1': 0.852}), (5, 0.8216, {'top1': 0.8216}), (6, 0.8588, {'top1': 0.8588}), (7, 0.8534, {'top1': 0.8534}), (8, 0.8522, {'top1': 0.8522}), (9, 0.8262, {'top1': 0.8262}), (10, 0.8348, {'top1': 0.8348}), (11, 0.8586, {'top1': 0.8586}), (13, 0.8338, {'top1': 0.8338}), (14, 0.8608, {'top1': 0.8608}), (15, 0.8526, {'top1': 0.8526}), (16, 0.8338, {'top1': 0.8338}), (17, 0.8418, {'top1': 0.8418}), (18, 0.5158, {'top1': 0.5158}), (19, 0.7988, {'top1': 0.7988}), (20, 0.8458, {'top1': 0.8458}), (21, 0.8478, {'top1': 0.8478}), (22, 0.825, {'top1': 0.825}), (23, 0.843, {'top1': 0.843}), (24, 0.8562, {'top1': 0.8562}), (25, 0.8576, {'top1': 0.8576}), (26, 0.8604, {'top1': 0.8604}), (27, 0.847, {'top1': 0.847}), (28, 0.8614, {'top1': 0.8614}), (29, 0.8584, {'top1': 0.8584}), (30, 0.8496, {'top1': 0.8496}), (31, 0.8612, {'top1': 0.8612}), (32, 0.8646, {'top1': 0.8646}), (34, 0.8628, {'top1': 0.8628}), (35, 0.8612, {'top1': 0.8612}), (36, 0.618, {'top1': 0.618}), (38, 0.863, {'top1': 0.863}), (39, 0.8642, {'top1': 0.8642}), (40, 0.8642, {'top1': 0.8642}), (41, 0.8624, {'top1': 0.8624}), (43, 0.8646, {'top1': 0.8646}), (44, 0.8638, {'top1': 0.8638}), (45, 0.8646, {'top1': 0.8646}), (46, 0.8612, {'top1': 0.8612}), (47, 0.8608, {'top1': 0.8608}), (48, 0.8602, {'top1': 0.8602}), (49, 0.8606, {'top1': 0.8606}), (50, 0.855, {'top1': 0.855}), (51, 0.7946, {'top1': 0.7946}), (52, 0.4122, {'top1': 0.4122}), (53, 0.1848, {'top1': 0.1848})]
just computed impact of block 32 . accuracy after removing:  0.8646
removed block 32 current accuracy 0.8646 loss from initial  -0.014600000000000057
since last training loss: -0.014600000000000057 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8086, {'top1': 0.8086}), (1, 0.8248, {'top1': 0.8248}), (2, 0.8222, {'top1': 0.8222}), (3, 0.856, {'top1': 0.856}), (4, 0.8496, {'top1': 0.8496}), (5, 0.817, {'top1': 0.817}), (6, 0.8594, {'top1': 0.8594}), (7, 0.8534, {'top1': 0.8534}), (8, 0.8504, {'top1': 0.8504}), (9, 0.8314, {'top1': 0.8314}), (10, 0.8334, {'top1': 0.8334}), (11, 0.8616, {'top1': 0.8616}), (13, 0.8364, {'top1': 0.8364}), (14, 0.8654, {'top1': 0.8654}), (15, 0.854, {'top1': 0.854}), (16, 0.837, {'top1': 0.837}), (17, 0.8456, {'top1': 0.8456}), (18, 0.5566, {'top1': 0.5566}), (19, 0.811, {'top1': 0.811}), (20, 0.8438, {'top1': 0.8438}), (21, 0.8432, {'top1': 0.8432}), (22, 0.8212, {'top1': 0.8212}), (23, 0.8412, {'top1': 0.8412}), (24, 0.8546, {'top1': 0.8546}), (25, 0.8572, {'top1': 0.8572}), (26, 0.8602, {'top1': 0.8602}), (27, 0.8448, {'top1': 0.8448}), (28, 0.861, {'top1': 0.861}), (29, 0.859, {'top1': 0.859}), (30, 0.8458, {'top1': 0.8458}), (31, 0.8582, {'top1': 0.8582}), (34, 0.8594, {'top1': 0.8594}), (35, 0.8586, {'top1': 0.8586}), (36, 0.5932, {'top1': 0.5932}), (38, 0.8604, {'top1': 0.8604}), (39, 0.8626, {'top1': 0.8626}), (40, 0.8602, {'top1': 0.8602}), (41, 0.86, {'top1': 0.86}), (43, 0.8616, {'top1': 0.8616}), (44, 0.864, {'top1': 0.864}), (45, 0.8632, {'top1': 0.8632}), (46, 0.86, {'top1': 0.86}), (47, 0.8586, {'top1': 0.8586}), (48, 0.8594, {'top1': 0.8594}), (49, 0.8594, {'top1': 0.8594}), (50, 0.856, {'top1': 0.856}), (51, 0.7996, {'top1': 0.7996}), (52, 0.4094, {'top1': 0.4094}), (53, 0.1752, {'top1': 0.1752})]
just computed impact of block 14 . accuracy after removing:  0.8654
removed block 14 current accuracy 0.8654 loss from initial  -0.01539999999999997
since last training loss: -0.01539999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.7938, {'top1': 0.7938}), (1, 0.8256, {'top1': 0.8256}), (2, 0.8202, {'top1': 0.8202}), (3, 0.8592, {'top1': 0.8592}), (4, 0.8506, {'top1': 0.8506}), (5, 0.8314, {'top1': 0.8314}), (6, 0.8652, {'top1': 0.8652}), (7, 0.861, {'top1': 0.861}), (8, 0.8572, {'top1': 0.8572}), (9, 0.8114, {'top1': 0.8114}), (10, 0.828, {'top1': 0.828}), (11, 0.851, {'top1': 0.851}), (13, 0.8156, {'top1': 0.8156}), (15, 0.849, {'top1': 0.849}), (16, 0.8084, {'top1': 0.8084}), (17, 0.8294, {'top1': 0.8294}), (18, 0.5428, {'top1': 0.5428}), (19, 0.7902, {'top1': 0.7902}), (20, 0.8474, {'top1': 0.8474}), (21, 0.8452, {'top1': 0.8452}), (22, 0.8182, {'top1': 0.8182}), (23, 0.8444, {'top1': 0.8444}), (24, 0.857, {'top1': 0.857}), (25, 0.8564, {'top1': 0.8564}), (26, 0.8636, {'top1': 0.8636}), (27, 0.8526, {'top1': 0.8526}), (28, 0.8646, {'top1': 0.8646}), (29, 0.8594, {'top1': 0.8594}), (30, 0.8534, {'top1': 0.8534}), (31, 0.8626, {'top1': 0.8626}), (34, 0.8596, {'top1': 0.8596}), (35, 0.8596, {'top1': 0.8596}), (36, 0.601, {'top1': 0.601}), (38, 0.865, {'top1': 0.865}), (39, 0.865, {'top1': 0.865}), (40, 0.8638, {'top1': 0.8638}), (41, 0.864, {'top1': 0.864}), (43, 0.8656, {'top1': 0.8656}), (44, 0.8666, {'top1': 0.8666}), (45, 0.8658, {'top1': 0.8658}), (46, 0.8646, {'top1': 0.8646}), (47, 0.8632, {'top1': 0.8632}), (48, 0.863, {'top1': 0.863}), (49, 0.8622, {'top1': 0.8622}), (50, 0.8604, {'top1': 0.8604}), (51, 0.798, {'top1': 0.798}), (52, 0.404, {'top1': 0.404}), (53, 0.1774, {'top1': 0.1774})]
just computed impact of block 44 . accuracy after removing:  0.8666
removed block 44 current accuracy 0.8666 loss from initial  -0.01660000000000006
since last training loss: -0.01660000000000006 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.7968, {'top1': 0.7968}), (1, 0.8248, {'top1': 0.8248}), (2, 0.8214, {'top1': 0.8214}), (3, 0.8608, {'top1': 0.8608}), (4, 0.8516, {'top1': 0.8516}), (5, 0.8264, {'top1': 0.8264}), (6, 0.8648, {'top1': 0.8648}), (7, 0.8596, {'top1': 0.8596}), (8, 0.8546, {'top1': 0.8546}), (9, 0.8174, {'top1': 0.8174}), (10, 0.8304, {'top1': 0.8304}), (11, 0.8504, {'top1': 0.8504}), (13, 0.8204, {'top1': 0.8204}), (15, 0.8502, {'top1': 0.8502}), (16, 0.8128, {'top1': 0.8128}), (17, 0.8316, {'top1': 0.8316}), (18, 0.5412, {'top1': 0.5412}), (19, 0.7926, {'top1': 0.7926}), (20, 0.8462, {'top1': 0.8462}), (21, 0.8456, {'top1': 0.8456}), (22, 0.8146, {'top1': 0.8146}), (23, 0.8432, {'top1': 0.8432}), (24, 0.8554, {'top1': 0.8554}), (25, 0.8582, {'top1': 0.8582}), (26, 0.8642, {'top1': 0.8642}), (27, 0.85, {'top1': 0.85}), (28, 0.8662, {'top1': 0.8662}), (29, 0.8618, {'top1': 0.8618}), (30, 0.8536, {'top1': 0.8536}), (31, 0.8642, {'top1': 0.8642}), (34, 0.862, {'top1': 0.862}), (35, 0.859, {'top1': 0.859}), (36, 0.61, {'top1': 0.61}), (38, 0.8652, {'top1': 0.8652}), (39, 0.8666, {'top1': 0.8666}), (40, 0.864, {'top1': 0.864}), (41, 0.8624, {'top1': 0.8624}), (43, 0.8662, {'top1': 0.8662}), (45, 0.8684, {'top1': 0.8684}), (46, 0.8646, {'top1': 0.8646}), (47, 0.8626, {'top1': 0.8626}), (48, 0.862, {'top1': 0.862}), (49, 0.8648, {'top1': 0.8648}), (50, 0.8594, {'top1': 0.8594}), (51, 0.8036, {'top1': 0.8036}), (52, 0.398, {'top1': 0.398}), (53, 0.1856, {'top1': 0.1856})]
just computed impact of block 45 . accuracy after removing:  0.8684
removed block 45 current accuracy 0.8684 loss from initial  -0.018399999999999972
since last training loss: -0.018399999999999972 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.8008, {'top1': 0.8008}), (1, 0.8256, {'top1': 0.8256}), (2, 0.822, {'top1': 0.822}), (3, 0.8606, {'top1': 0.8606}), (4, 0.8562, {'top1': 0.8562}), (5, 0.8268, {'top1': 0.8268}), (6, 0.8668, {'top1': 0.8668}), (7, 0.8594, {'top1': 0.8594}), (8, 0.8538, {'top1': 0.8538}), (9, 0.8228, {'top1': 0.8228}), (10, 0.8364, {'top1': 0.8364}), (11, 0.8538, {'top1': 0.8538}), (13, 0.8236, {'top1': 0.8236}), (15, 0.8526, {'top1': 0.8526}), (16, 0.8166, {'top1': 0.8166}), (17, 0.837, {'top1': 0.837}), (18, 0.5534, {'top1': 0.5534}), (19, 0.797, {'top1': 0.797}), (20, 0.8464, {'top1': 0.8464}), (21, 0.847, {'top1': 0.847}), (22, 0.811, {'top1': 0.811}), (23, 0.842, {'top1': 0.842}), (24, 0.8576, {'top1': 0.8576}), (25, 0.8578, {'top1': 0.8578}), (26, 0.8642, {'top1': 0.8642}), (27, 0.8502, {'top1': 0.8502}), (28, 0.8642, {'top1': 0.8642}), (29, 0.8614, {'top1': 0.8614}), (30, 0.851, {'top1': 0.851}), (31, 0.865, {'top1': 0.865}), (34, 0.8616, {'top1': 0.8616}), (35, 0.8612, {'top1': 0.8612}), (36, 0.592, {'top1': 0.592}), (38, 0.8658, {'top1': 0.8658}), (39, 0.8664, {'top1': 0.8664}), (40, 0.865, {'top1': 0.865}), (41, 0.8652, {'top1': 0.8652}), (43, 0.8658, {'top1': 0.8658}), (46, 0.8638, {'top1': 0.8638}), (47, 0.8646, {'top1': 0.8646}), (48, 0.8644, {'top1': 0.8644}), (49, 0.8652, {'top1': 0.8652}), (50, 0.859, {'top1': 0.859}), (51, 0.8076, {'top1': 0.8076}), (52, 0.4014, {'top1': 0.4014}), (53, 0.1884, {'top1': 0.1884})]
just computed impact of block 6 . accuracy after removing:  0.8668
removed block 6 current accuracy 0.8668 loss from initial  -0.016800000000000037
since last training loss: -0.016800000000000037 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8, {'top1': 0.8}), (1, 0.8186, {'top1': 0.8186}), (2, 0.8114, {'top1': 0.8114}), (3, 0.852, {'top1': 0.852}), (4, 0.8534, {'top1': 0.8534}), (5, 0.8114, {'top1': 0.8114}), (7, 0.8444, {'top1': 0.8444}), (8, 0.8468, {'top1': 0.8468}), (9, 0.8096, {'top1': 0.8096}), (10, 0.8244, {'top1': 0.8244}), (11, 0.855, {'top1': 0.855}), (13, 0.8202, {'top1': 0.8202}), (15, 0.854, {'top1': 0.854}), (16, 0.8094, {'top1': 0.8094}), (17, 0.8324, {'top1': 0.8324}), (18, 0.5424, {'top1': 0.5424}), (19, 0.7928, {'top1': 0.7928}), (20, 0.8448, {'top1': 0.8448}), (21, 0.8374, {'top1': 0.8374}), (22, 0.7978, {'top1': 0.7978}), (23, 0.834, {'top1': 0.834}), (24, 0.854, {'top1': 0.854}), (25, 0.8558, {'top1': 0.8558}), (26, 0.8598, {'top1': 0.8598}), (27, 0.8456, {'top1': 0.8456}), (28, 0.8606, {'top1': 0.8606}), (29, 0.8574, {'top1': 0.8574}), (30, 0.8522, {'top1': 0.8522}), (31, 0.8616, {'top1': 0.8616}), (34, 0.8596, {'top1': 0.8596}), (35, 0.8608, {'top1': 0.8608}), (36, 0.57, {'top1': 0.57}), (38, 0.8626, {'top1': 0.8626}), (39, 0.8666, {'top1': 0.8666}), (40, 0.8648, {'top1': 0.8648}), (41, 0.8634, {'top1': 0.8634}), (43, 0.8676, {'top1': 0.8676}), (46, 0.8646, {'top1': 0.8646}), (47, 0.864, {'top1': 0.864}), (48, 0.8642, {'top1': 0.8642}), (49, 0.864, {'top1': 0.864}), (50, 0.854, {'top1': 0.854}), (51, 0.8038, {'top1': 0.8038}), (52, 0.3854, {'top1': 0.3854}), (53, 0.192, {'top1': 0.192})]
just computed impact of block 43 . accuracy after removing:  0.8676
removed block 43 current accuracy 0.8676 loss from initial  -0.01760000000000006
since last training loss: -0.01760000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.8022, {'top1': 0.8022}), (1, 0.8178, {'top1': 0.8178}), (2, 0.8128, {'top1': 0.8128}), (3, 0.8514, {'top1': 0.8514}), (4, 0.854, {'top1': 0.854}), (5, 0.808, {'top1': 0.808}), (7, 0.8442, {'top1': 0.8442}), (8, 0.845, {'top1': 0.845}), (9, 0.816, {'top1': 0.816}), (10, 0.8278, {'top1': 0.8278}), (11, 0.86, {'top1': 0.86}), (13, 0.8232, {'top1': 0.8232}), (15, 0.856, {'top1': 0.856}), (16, 0.8108, {'top1': 0.8108}), (17, 0.8346, {'top1': 0.8346}), (18, 0.5486, {'top1': 0.5486}), (19, 0.7954, {'top1': 0.7954}), (20, 0.8444, {'top1': 0.8444}), (21, 0.837, {'top1': 0.837}), (22, 0.7986, {'top1': 0.7986}), (23, 0.8342, {'top1': 0.8342}), (24, 0.8536, {'top1': 0.8536}), (25, 0.8562, {'top1': 0.8562}), (26, 0.859, {'top1': 0.859}), (27, 0.8452, {'top1': 0.8452}), (28, 0.8624, {'top1': 0.8624}), (29, 0.855, {'top1': 0.855}), (30, 0.85, {'top1': 0.85}), (31, 0.8608, {'top1': 0.8608}), (34, 0.8598, {'top1': 0.8598}), (35, 0.8612, {'top1': 0.8612}), (36, 0.568, {'top1': 0.568}), (38, 0.8654, {'top1': 0.8654}), (39, 0.8668, {'top1': 0.8668}), (40, 0.867, {'top1': 0.867}), (41, 0.8646, {'top1': 0.8646}), (46, 0.8658, {'top1': 0.8658}), (47, 0.8662, {'top1': 0.8662}), (48, 0.865, {'top1': 0.865}), (49, 0.8646, {'top1': 0.8646}), (50, 0.8504, {'top1': 0.8504}), (51, 0.8028, {'top1': 0.8028}), (52, 0.3868, {'top1': 0.3868}), (53, 0.1926, {'top1': 0.1926})]
just computed impact of block 40 . accuracy after removing:  0.867
removed block 40 current accuracy 0.867 loss from initial  -0.017000000000000015
since last training loss: -0.017000000000000015 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.803, {'top1': 0.803}), (1, 0.8166, {'top1': 0.8166}), (2, 0.8142, {'top1': 0.8142}), (3, 0.8522, {'top1': 0.8522}), (4, 0.8524, {'top1': 0.8524}), (5, 0.8078, {'top1': 0.8078}), (7, 0.841, {'top1': 0.841}), (8, 0.844, {'top1': 0.844}), (9, 0.8152, {'top1': 0.8152}), (10, 0.8304, {'top1': 0.8304}), (11, 0.8598, {'top1': 0.8598}), (13, 0.823, {'top1': 0.823}), (15, 0.8566, {'top1': 0.8566}), (16, 0.8106, {'top1': 0.8106}), (17, 0.8372, {'top1': 0.8372}), (18, 0.5446, {'top1': 0.5446}), (19, 0.7938, {'top1': 0.7938}), (20, 0.8414, {'top1': 0.8414}), (21, 0.8354, {'top1': 0.8354}), (22, 0.798, {'top1': 0.798}), (23, 0.8338, {'top1': 0.8338}), (24, 0.8512, {'top1': 0.8512}), (25, 0.855, {'top1': 0.855}), (26, 0.859, {'top1': 0.859}), (27, 0.8438, {'top1': 0.8438}), (28, 0.8612, {'top1': 0.8612}), (29, 0.8538, {'top1': 0.8538}), (30, 0.8494, {'top1': 0.8494}), (31, 0.861, {'top1': 0.861}), (34, 0.8584, {'top1': 0.8584}), (35, 0.8612, {'top1': 0.8612}), (36, 0.5794, {'top1': 0.5794}), (38, 0.8652, {'top1': 0.8652}), (39, 0.866, {'top1': 0.866}), (41, 0.8638, {'top1': 0.8638}), (46, 0.8624, {'top1': 0.8624}), (47, 0.8642, {'top1': 0.8642}), (48, 0.8612, {'top1': 0.8612}), (49, 0.8632, {'top1': 0.8632}), (50, 0.846, {'top1': 0.846}), (51, 0.7996, {'top1': 0.7996}), (52, 0.3826, {'top1': 0.3826}), (53, 0.1914, {'top1': 0.1914})]
just computed impact of block 39 . accuracy after removing:  0.866
removed block 39 current accuracy 0.866 loss from initial  -0.016000000000000014
since last training loss: -0.016000000000000014 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.805, {'top1': 0.805}), (1, 0.8172, {'top1': 0.8172}), (2, 0.8144, {'top1': 0.8144}), (3, 0.8526, {'top1': 0.8526}), (4, 0.854, {'top1': 0.854}), (5, 0.7988, {'top1': 0.7988}), (7, 0.842, {'top1': 0.842}), (8, 0.8428, {'top1': 0.8428}), (9, 0.82, {'top1': 0.82}), (10, 0.829, {'top1': 0.829}), (11, 0.8608, {'top1': 0.8608}), (13, 0.8296, {'top1': 0.8296}), (15, 0.857, {'top1': 0.857}), (16, 0.8104, {'top1': 0.8104}), (17, 0.8444, {'top1': 0.8444}), (18, 0.5546, {'top1': 0.5546}), (19, 0.7998, {'top1': 0.7998}), (20, 0.841, {'top1': 0.841}), (21, 0.8308, {'top1': 0.8308}), (22, 0.7922, {'top1': 0.7922}), (23, 0.8306, {'top1': 0.8306}), (24, 0.8536, {'top1': 0.8536}), (25, 0.853, {'top1': 0.853}), (26, 0.8596, {'top1': 0.8596}), (27, 0.8416, {'top1': 0.8416}), (28, 0.8586, {'top1': 0.8586}), (29, 0.8532, {'top1': 0.8532}), (30, 0.8482, {'top1': 0.8482}), (31, 0.8582, {'top1': 0.8582}), (34, 0.8576, {'top1': 0.8576}), (35, 0.8614, {'top1': 0.8614}), (36, 0.557, {'top1': 0.557}), (38, 0.8636, {'top1': 0.8636}), (41, 0.8646, {'top1': 0.8646}), (46, 0.8626, {'top1': 0.8626}), (47, 0.8632, {'top1': 0.8632}), (48, 0.863, {'top1': 0.863}), (49, 0.8662, {'top1': 0.8662}), (50, 0.8394, {'top1': 0.8394}), (51, 0.7944, {'top1': 0.7944}), (52, 0.3808, {'top1': 0.3808}), (53, 0.196, {'top1': 0.196})]
just computed impact of block 49 . accuracy after removing:  0.8662
removed block 49 current accuracy 0.8662 loss from initial  -0.016199999999999992
since last training loss: -0.016199999999999992 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.8012, {'top1': 0.8012}), (1, 0.814, {'top1': 0.814}), (2, 0.8122, {'top1': 0.8122}), (3, 0.8508, {'top1': 0.8508}), (4, 0.8524, {'top1': 0.8524}), (5, 0.79, {'top1': 0.79}), (7, 0.8374, {'top1': 0.8374}), (8, 0.8372, {'top1': 0.8372}), (9, 0.822, {'top1': 0.822}), (10, 0.8254, {'top1': 0.8254}), (11, 0.8606, {'top1': 0.8606}), (13, 0.8276, {'top1': 0.8276}), (15, 0.8564, {'top1': 0.8564}), (16, 0.81, {'top1': 0.81}), (17, 0.843, {'top1': 0.843}), (18, 0.5508, {'top1': 0.5508}), (19, 0.7996, {'top1': 0.7996}), (20, 0.836, {'top1': 0.836}), (21, 0.8274, {'top1': 0.8274}), (22, 0.7832, {'top1': 0.7832}), (23, 0.8278, {'top1': 0.8278}), (24, 0.8508, {'top1': 0.8508}), (25, 0.8498, {'top1': 0.8498}), (26, 0.8558, {'top1': 0.8558}), (27, 0.839, {'top1': 0.839}), (28, 0.8572, {'top1': 0.8572}), (29, 0.8492, {'top1': 0.8492}), (30, 0.845, {'top1': 0.845}), (31, 0.857, {'top1': 0.857}), (34, 0.8562, {'top1': 0.8562}), (35, 0.8598, {'top1': 0.8598}), (36, 0.5534, {'top1': 0.5534}), (38, 0.862, {'top1': 0.862}), (41, 0.862, {'top1': 0.862}), (46, 0.8606, {'top1': 0.8606}), (47, 0.8612, {'top1': 0.8612}), (48, 0.8596, {'top1': 0.8596}), (50, 0.8356, {'top1': 0.8356}), (51, 0.7908, {'top1': 0.7908}), (52, 0.3832, {'top1': 0.3832}), (53, 0.1928, {'top1': 0.1928})]
just computed impact of block 38 . accuracy after removing:  0.862
removed block 38 current accuracy 0.862 loss from initial  -0.01200000000000001
since last training loss: -0.01200000000000001 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.7964, {'top1': 0.7964}), (1, 0.8082, {'top1': 0.8082}), (2, 0.8098, {'top1': 0.8098}), (3, 0.8504, {'top1': 0.8504}), (4, 0.8508, {'top1': 0.8508}), (5, 0.7878, {'top1': 0.7878}), (7, 0.8328, {'top1': 0.8328}), (8, 0.8366, {'top1': 0.8366}), (9, 0.818, {'top1': 0.818}), (10, 0.8226, {'top1': 0.8226}), (11, 0.8562, {'top1': 0.8562}), (13, 0.8234, {'top1': 0.8234}), (15, 0.8536, {'top1': 0.8536}), (16, 0.8094, {'top1': 0.8094}), (17, 0.8394, {'top1': 0.8394}), (18, 0.5348, {'top1': 0.5348}), (19, 0.7932, {'top1': 0.7932}), (20, 0.8326, {'top1': 0.8326}), (21, 0.824, {'top1': 0.824}), (22, 0.7802, {'top1': 0.7802}), (23, 0.8246, {'top1': 0.8246}), (24, 0.8494, {'top1': 0.8494}), (25, 0.8488, {'top1': 0.8488}), (26, 0.8542, {'top1': 0.8542}), (27, 0.8374, {'top1': 0.8374}), (28, 0.855, {'top1': 0.855}), (29, 0.8484, {'top1': 0.8484}), (30, 0.8442, {'top1': 0.8442}), (31, 0.8552, {'top1': 0.8552}), (34, 0.855, {'top1': 0.855}), (35, 0.8566, {'top1': 0.8566}), (36, 0.555, {'top1': 0.555}), (41, 0.8606, {'top1': 0.8606}), (46, 0.8584, {'top1': 0.8584}), (47, 0.8578, {'top1': 0.8578}), (48, 0.8578, {'top1': 0.8578}), (50, 0.8314, {'top1': 0.8314}), (51, 0.7866, {'top1': 0.7866}), (52, 0.377, {'top1': 0.377}), (53, 0.1954, {'top1': 0.1954})]
just computed impact of block 41 . accuracy after removing:  0.8606
removed block 41 current accuracy 0.8606 loss from initial  -0.010600000000000054
since last training loss: -0.010600000000000054 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.7904, {'top1': 0.7904}), (1, 0.8048, {'top1': 0.8048}), (2, 0.8096, {'top1': 0.8096}), (3, 0.846, {'top1': 0.846}), (4, 0.8464, {'top1': 0.8464}), (5, 0.7832, {'top1': 0.7832}), (7, 0.828, {'top1': 0.828}), (8, 0.8362, {'top1': 0.8362}), (9, 0.8138, {'top1': 0.8138}), (10, 0.8214, {'top1': 0.8214}), (11, 0.8526, {'top1': 0.8526}), (13, 0.8198, {'top1': 0.8198}), (15, 0.8506, {'top1': 0.8506}), (16, 0.8068, {'top1': 0.8068}), (17, 0.8358, {'top1': 0.8358}), (18, 0.525, {'top1': 0.525}), (19, 0.7912, {'top1': 0.7912}), (20, 0.8276, {'top1': 0.8276}), (21, 0.8222, {'top1': 0.8222}), (22, 0.7728, {'top1': 0.7728}), (23, 0.819, {'top1': 0.819}), (24, 0.8434, {'top1': 0.8434}), (25, 0.8446, {'top1': 0.8446}), (26, 0.8528, {'top1': 0.8528}), (27, 0.8338, {'top1': 0.8338}), (28, 0.8532, {'top1': 0.8532}), (29, 0.8462, {'top1': 0.8462}), (30, 0.843, {'top1': 0.843}), (31, 0.8542, {'top1': 0.8542}), (34, 0.8536, {'top1': 0.8536}), (35, 0.855, {'top1': 0.855}), (36, 0.5668, {'top1': 0.5668}), (46, 0.8548, {'top1': 0.8548}), (47, 0.854, {'top1': 0.854}), (48, 0.8532, {'top1': 0.8532}), (50, 0.8296, {'top1': 0.8296}), (51, 0.7874, {'top1': 0.7874}), (52, 0.3748, {'top1': 0.3748}), (53, 0.1958, {'top1': 0.1958})]
just computed impact of block 35 . accuracy after removing:  0.855
removed block 35 current accuracy 0.855 loss from initial  -0.0050000000000000044
since last training loss: -0.0050000000000000044 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.7906, {'top1': 0.7906}), (1, 0.802, {'top1': 0.802}), (2, 0.8068, {'top1': 0.8068}), (3, 0.8432, {'top1': 0.8432}), (4, 0.8432, {'top1': 0.8432}), (5, 0.7874, {'top1': 0.7874}), (7, 0.8308, {'top1': 0.8308}), (8, 0.8354, {'top1': 0.8354}), (9, 0.81, {'top1': 0.81}), (10, 0.817, {'top1': 0.817}), (11, 0.8486, {'top1': 0.8486}), (13, 0.8178, {'top1': 0.8178}), (15, 0.8474, {'top1': 0.8474}), (16, 0.804, {'top1': 0.804}), (17, 0.8296, {'top1': 0.8296}), (18, 0.5198, {'top1': 0.5198}), (19, 0.789, {'top1': 0.789}), (20, 0.8268, {'top1': 0.8268}), (21, 0.8202, {'top1': 0.8202}), (22, 0.7764, {'top1': 0.7764}), (23, 0.8194, {'top1': 0.8194}), (24, 0.8398, {'top1': 0.8398}), (25, 0.843, {'top1': 0.843}), (26, 0.849, {'top1': 0.849}), (27, 0.8326, {'top1': 0.8326}), (28, 0.8474, {'top1': 0.8474}), (29, 0.8422, {'top1': 0.8422}), (30, 0.8392, {'top1': 0.8392}), (31, 0.8512, {'top1': 0.8512}), (34, 0.8496, {'top1': 0.8496}), (36, 0.548, {'top1': 0.548}), (46, 0.8512, {'top1': 0.8512}), (47, 0.8516, {'top1': 0.8516}), (48, 0.8502, {'top1': 0.8502}), (50, 0.829, {'top1': 0.829}), (51, 0.7814, {'top1': 0.7814}), (52, 0.3704, {'top1': 0.3704}), (53, 0.1874, {'top1': 0.1874})]
just computed impact of block 47 . accuracy after removing:  0.8516
removed block 47 current accuracy 0.8516 loss from initial  -0.0016000000000000458
since last training loss: -0.0016000000000000458 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.7886, {'top1': 0.7886}), (1, 0.798, {'top1': 0.798}), (2, 0.8044, {'top1': 0.8044}), (3, 0.8382, {'top1': 0.8382}), (4, 0.8388, {'top1': 0.8388}), (5, 0.7748, {'top1': 0.7748}), (7, 0.825, {'top1': 0.825}), (8, 0.831, {'top1': 0.831}), (9, 0.8112, {'top1': 0.8112}), (10, 0.8124, {'top1': 0.8124}), (11, 0.8464, {'top1': 0.8464}), (13, 0.816, {'top1': 0.816}), (15, 0.8446, {'top1': 0.8446}), (16, 0.8016, {'top1': 0.8016}), (17, 0.8276, {'top1': 0.8276}), (18, 0.5178, {'top1': 0.5178}), (19, 0.783, {'top1': 0.783}), (20, 0.8206, {'top1': 0.8206}), (21, 0.814, {'top1': 0.814}), (22, 0.769, {'top1': 0.769}), (23, 0.813, {'top1': 0.813}), (24, 0.8358, {'top1': 0.8358}), (25, 0.8362, {'top1': 0.8362}), (26, 0.8436, {'top1': 0.8436}), (27, 0.8274, {'top1': 0.8274}), (28, 0.846, {'top1': 0.846}), (29, 0.8366, {'top1': 0.8366}), (30, 0.8334, {'top1': 0.8334}), (31, 0.8474, {'top1': 0.8474}), (34, 0.8464, {'top1': 0.8464}), (36, 0.5538, {'top1': 0.5538}), (46, 0.8456, {'top1': 0.8456}), (48, 0.845, {'top1': 0.845}), (50, 0.8248, {'top1': 0.8248}), (51, 0.7776, {'top1': 0.7776}), (52, 0.3614, {'top1': 0.3614}), (53, 0.1866, {'top1': 0.1866})]
just computed impact of block 31 . accuracy after removing:  0.8474
removed block 31 current accuracy 0.8474 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.7912, {'top1': 0.7912}), (1, 0.7972, {'top1': 0.7972}), (2, 0.7916, {'top1': 0.7916}), (3, 0.8304, {'top1': 0.8304}), (4, 0.8354, {'top1': 0.8354}), (5, 0.7634, {'top1': 0.7634}), (7, 0.8152, {'top1': 0.8152}), (8, 0.8176, {'top1': 0.8176}), (9, 0.811, {'top1': 0.811}), (10, 0.8072, {'top1': 0.8072}), (11, 0.8446, {'top1': 0.8446}), (13, 0.816, {'top1': 0.816}), (15, 0.8412, {'top1': 0.8412}), (16, 0.798, {'top1': 0.798}), (17, 0.8258, {'top1': 0.8258}), (18, 0.525, {'top1': 0.525}), (19, 0.7892, {'top1': 0.7892}), (20, 0.8156, {'top1': 0.8156}), (21, 0.801, {'top1': 0.801}), (22, 0.7532, {'top1': 0.7532}), (23, 0.8004, {'top1': 0.8004}), (24, 0.8292, {'top1': 0.8292}), (25, 0.8286, {'top1': 0.8286}), (26, 0.8316, {'top1': 0.8316}), (27, 0.8148, {'top1': 0.8148}), (28, 0.833, {'top1': 0.833}), (29, 0.8262, {'top1': 0.8262}), (30, 0.8186, {'top1': 0.8186}), (34, 0.839, {'top1': 0.839}), (36, 0.516, {'top1': 0.516}), (46, 0.839, {'top1': 0.839}), (48, 0.8406, {'top1': 0.8406}), (50, 0.8132, {'top1': 0.8132}), (51, 0.7696, {'top1': 0.7696}), (52, 0.3598, {'top1': 0.3598}), (53, 0.1866, {'top1': 0.1866})]
just computed impact of block 11 . accuracy after removing:  0.8446
removed block 11 current accuracy 0.8446 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.7828, {'top1': 0.7828}), (1, 0.7964, {'top1': 0.7964}), (2, 0.7838, {'top1': 0.7838}), (3, 0.8272, {'top1': 0.8272}), (4, 0.833, {'top1': 0.833}), (5, 0.7776, {'top1': 0.7776}), (7, 0.8188, {'top1': 0.8188}), (8, 0.8206, {'top1': 0.8206}), (9, 0.7756, {'top1': 0.7756}), (10, 0.794, {'top1': 0.794}), (13, 0.7928, {'top1': 0.7928}), (15, 0.8326, {'top1': 0.8326}), (16, 0.7702, {'top1': 0.7702}), (17, 0.8006, {'top1': 0.8006}), (18, 0.4918, {'top1': 0.4918}), (19, 0.7554, {'top1': 0.7554}), (20, 0.8108, {'top1': 0.8108}), (21, 0.8092, {'top1': 0.8092}), (22, 0.7514, {'top1': 0.7514}), (23, 0.8084, {'top1': 0.8084}), (24, 0.8282, {'top1': 0.8282}), (25, 0.8314, {'top1': 0.8314}), (26, 0.8326, {'top1': 0.8326}), (27, 0.8184, {'top1': 0.8184}), (28, 0.8348, {'top1': 0.8348}), (29, 0.8292, {'top1': 0.8292}), (30, 0.8222, {'top1': 0.8222}), (34, 0.8328, {'top1': 0.8328}), (36, 0.5116, {'top1': 0.5116}), (46, 0.8408, {'top1': 0.8408}), (48, 0.8386, {'top1': 0.8386}), (50, 0.8194, {'top1': 0.8194}), (51, 0.771, {'top1': 0.771}), (52, 0.336, {'top1': 0.336}), (53, 0.1836, {'top1': 0.1836})]
just computed impact of block 46 . accuracy after removing:  0.8408
removed block 46 current accuracy 0.8408 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.781, {'top1': 0.781}), (1, 0.7954, {'top1': 0.7954}), (2, 0.7818, {'top1': 0.7818}), (3, 0.8246, {'top1': 0.8246}), (4, 0.8312, {'top1': 0.8312}), (5, 0.7616, {'top1': 0.7616}), (7, 0.8162, {'top1': 0.8162}), (8, 0.815, {'top1': 0.815}), (9, 0.7758, {'top1': 0.7758}), (10, 0.7902, {'top1': 0.7902}), (13, 0.7908, {'top1': 0.7908}), (15, 0.8276, {'top1': 0.8276}), (16, 0.7682, {'top1': 0.7682}), (17, 0.7942, {'top1': 0.7942}), (18, 0.4948, {'top1': 0.4948}), (19, 0.7518, {'top1': 0.7518}), (20, 0.8048, {'top1': 0.8048}), (21, 0.8008, {'top1': 0.8008}), (22, 0.7434, {'top1': 0.7434}), (23, 0.7996, {'top1': 0.7996}), (24, 0.824, {'top1': 0.824}), (25, 0.8254, {'top1': 0.8254}), (26, 0.8284, {'top1': 0.8284}), (27, 0.8098, {'top1': 0.8098}), (28, 0.829, {'top1': 0.829}), (29, 0.827, {'top1': 0.827}), (30, 0.8158, {'top1': 0.8158}), (34, 0.831, {'top1': 0.831}), (36, 0.5072, {'top1': 0.5072}), (48, 0.8268, {'top1': 0.8268}), (50, 0.8118, {'top1': 0.8118}), (51, 0.7618, {'top1': 0.7618}), (52, 0.3402, {'top1': 0.3402}), (53, 0.182, {'top1': 0.182})]
just computed impact of block 4 . accuracy after removing:  0.8312
removed block 4 current accuracy 0.8312 loss from initial  0.018799999999999928
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.7608, {'top1': 0.7608}), (1, 0.781, {'top1': 0.781}), (2, 0.7566, {'top1': 0.7566}), (3, 0.8116, {'top1': 0.8116}), (5, 0.7658, {'top1': 0.7658}), (7, 0.803, {'top1': 0.803}), (8, 0.8056, {'top1': 0.8056}), (9, 0.7434, {'top1': 0.7434}), (10, 0.7678, {'top1': 0.7678}), (13, 0.7802, {'top1': 0.7802}), (15, 0.8188, {'top1': 0.8188}), (16, 0.759, {'top1': 0.759}), (17, 0.7884, {'top1': 0.7884}), (18, 0.4858, {'top1': 0.4858}), (19, 0.7546, {'top1': 0.7546}), (20, 0.8046, {'top1': 0.8046}), (21, 0.7912, {'top1': 0.7912}), (22, 0.7374, {'top1': 0.7374}), (23, 0.793, {'top1': 0.793}), (24, 0.8168, {'top1': 0.8168}), (25, 0.8144, {'top1': 0.8144}), (26, 0.819, {'top1': 0.819}), (27, 0.8022, {'top1': 0.8022}), (28, 0.8198, {'top1': 0.8198}), (29, 0.8152, {'top1': 0.8152}), (30, 0.8054, {'top1': 0.8054}), (34, 0.8218, {'top1': 0.8218}), (36, 0.496, {'top1': 0.496}), (48, 0.8222, {'top1': 0.8222}), (50, 0.8108, {'top1': 0.8108}), (51, 0.7606, {'top1': 0.7606}), (52, 0.3466, {'top1': 0.3466}), (53, 0.1828, {'top1': 0.1828})]
just computed impact of block 48 . accuracy after removing:  0.8222
removed block 48 current accuracy 0.8222 loss from initial  0.027799999999999936
since last training loss: 0.027799999999999936 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7458, {'top1': 0.7458}), (1, 0.765, {'top1': 0.765}), (2, 0.7522, {'top1': 0.7522}), (3, 0.8062, {'top1': 0.8062}), (5, 0.759, {'top1': 0.759}), (7, 0.8004, {'top1': 0.8004}), (8, 0.8004, {'top1': 0.8004}), (9, 0.7278, {'top1': 0.7278}), (10, 0.762, {'top1': 0.762}), (13, 0.7636, {'top1': 0.7636}), (15, 0.8092, {'top1': 0.8092}), (16, 0.7458, {'top1': 0.7458}), (17, 0.7722, {'top1': 0.7722}), (18, 0.48, {'top1': 0.48}), (19, 0.744, {'top1': 0.744}), (20, 0.7956, {'top1': 0.7956}), (21, 0.791, {'top1': 0.791}), (22, 0.7324, {'top1': 0.7324}), (23, 0.7902, {'top1': 0.7902}), (24, 0.8092, {'top1': 0.8092}), (25, 0.8134, {'top1': 0.8134}), (26, 0.814, {'top1': 0.814}), (27, 0.7966, {'top1': 0.7966}), (28, 0.8142, {'top1': 0.8142}), (29, 0.8108, {'top1': 0.8108}), (30, 0.8018, {'top1': 0.8018}), (34, 0.814, {'top1': 0.814}), (36, 0.4968, {'top1': 0.4968}), (50, 0.8092, {'top1': 0.8092}), (51, 0.7476, {'top1': 0.7476}), (52, 0.356, {'top1': 0.356}), (53, 0.1786, {'top1': 0.1786})]
just computed impact of block 28 . accuracy after removing:  0.8142
removed block 28 current accuracy 0.8142 loss from initial  0.03579999999999994
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7432, {'top1': 0.7432}), (1, 0.7594, {'top1': 0.7594}), (2, 0.736, {'top1': 0.736}), (3, 0.7934, {'top1': 0.7934}), (5, 0.7362, {'top1': 0.7362}), (7, 0.785, {'top1': 0.785}), (8, 0.7878, {'top1': 0.7878}), (9, 0.7266, {'top1': 0.7266}), (10, 0.7522, {'top1': 0.7522}), (13, 0.7652, {'top1': 0.7652}), (15, 0.8032, {'top1': 0.8032}), (16, 0.7378, {'top1': 0.7378}), (17, 0.7662, {'top1': 0.7662}), (18, 0.4574, {'top1': 0.4574}), (19, 0.7402, {'top1': 0.7402}), (20, 0.785, {'top1': 0.785}), (21, 0.7672, {'top1': 0.7672}), (22, 0.712, {'top1': 0.712}), (23, 0.7698, {'top1': 0.7698}), (24, 0.7984, {'top1': 0.7984}), (25, 0.7982, {'top1': 0.7982}), (26, 0.7994, {'top1': 0.7994}), (27, 0.7826, {'top1': 0.7826}), (29, 0.795, {'top1': 0.795}), (30, 0.7848, {'top1': 0.7848}), (34, 0.804, {'top1': 0.804}), (36, 0.4594, {'top1': 0.4594}), (50, 0.7936, {'top1': 0.7936}), (51, 0.739, {'top1': 0.739}), (52, 0.3504, {'top1': 0.3504}), (53, 0.1796, {'top1': 0.1796})]
just computed impact of block 34 . accuracy after removing:  0.804
removed block 34 current accuracy 0.804 loss from initial  0.04599999999999993
since last training loss: 0.04599999999999993 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7328, {'top1': 0.7328}), (1, 0.7534, {'top1': 0.7534}), (2, 0.7218, {'top1': 0.7218}), (3, 0.781, {'top1': 0.781}), (5, 0.7244, {'top1': 0.7244}), (7, 0.7732, {'top1': 0.7732}), (8, 0.7712, {'top1': 0.7712}), (9, 0.706, {'top1': 0.706}), (10, 0.7362, {'top1': 0.7362}), (13, 0.743, {'top1': 0.743}), (15, 0.7936, {'top1': 0.7936}), (16, 0.72, {'top1': 0.72}), (17, 0.748, {'top1': 0.748}), (18, 0.4238, {'top1': 0.4238}), (19, 0.7174, {'top1': 0.7174}), (20, 0.7714, {'top1': 0.7714}), (21, 0.7572, {'top1': 0.7572}), (22, 0.6956, {'top1': 0.6956}), (23, 0.7544, {'top1': 0.7544}), (24, 0.7868, {'top1': 0.7868}), (25, 0.7842, {'top1': 0.7842}), (26, 0.7842, {'top1': 0.7842}), (27, 0.768, {'top1': 0.768}), (29, 0.7816, {'top1': 0.7816}), (30, 0.766, {'top1': 0.766}), (36, 0.4316, {'top1': 0.4316}), (50, 0.7794, {'top1': 0.7794}), (51, 0.7298, {'top1': 0.7298}), (52, 0.3328, {'top1': 0.3328}), (53, 0.1718, {'top1': 0.1718})]
just computed impact of block 15 . accuracy after removing:  0.7936
removed block 15 current accuracy 0.7936 loss from initial  0.056400000000000006
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.7166, {'top1': 0.7166}), (1, 0.7378, {'top1': 0.7378}), (2, 0.7134, {'top1': 0.7134}), (3, 0.7732, {'top1': 0.7732}), (5, 0.727, {'top1': 0.727}), (7, 0.7626, {'top1': 0.7626}), (8, 0.7592, {'top1': 0.7592}), (9, 0.697, {'top1': 0.697}), (10, 0.7212, {'top1': 0.7212}), (13, 0.7116, {'top1': 0.7116}), (16, 0.6662, {'top1': 0.6662}), (17, 0.7004, {'top1': 0.7004}), (18, 0.4154, {'top1': 0.4154}), (19, 0.6954, {'top1': 0.6954}), (20, 0.764, {'top1': 0.764}), (21, 0.743, {'top1': 0.743}), (22, 0.6838, {'top1': 0.6838}), (23, 0.7434, {'top1': 0.7434}), (24, 0.7708, {'top1': 0.7708}), (25, 0.773, {'top1': 0.773}), (26, 0.778, {'top1': 0.778}), (27, 0.7632, {'top1': 0.7632}), (29, 0.7722, {'top1': 0.7722}), (30, 0.7602, {'top1': 0.7602}), (36, 0.4226, {'top1': 0.4226}), (50, 0.7726, {'top1': 0.7726}), (51, 0.7138, {'top1': 0.7138}), (52, 0.3142, {'top1': 0.3142}), (53, 0.1646, {'top1': 0.1646})]
just computed impact of block 26 . accuracy after removing:  0.778
removed block 26 current accuracy 0.778 loss from initial  0.07199999999999995
since last training loss: 0.07199999999999995 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.7056, {'top1': 0.7056}), (1, 0.7234, {'top1': 0.7234}), (2, 0.666, {'top1': 0.666}), (3, 0.738, {'top1': 0.738}), (5, 0.6822, {'top1': 0.6822}), (7, 0.728, {'top1': 0.728}), (8, 0.7192, {'top1': 0.7192}), (9, 0.6802, {'top1': 0.6802}), (10, 0.6866, {'top1': 0.6866}), (13, 0.7046, {'top1': 0.7046}), (16, 0.6436, {'top1': 0.6436}), (17, 0.6856, {'top1': 0.6856}), (18, 0.3682, {'top1': 0.3682}), (19, 0.6862, {'top1': 0.6862}), (20, 0.7464, {'top1': 0.7464}), (21, 0.7148, {'top1': 0.7148}), (22, 0.6436, {'top1': 0.6436}), (23, 0.7004, {'top1': 0.7004}), (24, 0.7436, {'top1': 0.7436}), (25, 0.7432, {'top1': 0.7432}), (27, 0.725, {'top1': 0.725}), (29, 0.7362, {'top1': 0.7362}), (30, 0.7238, {'top1': 0.7238}), (36, 0.353, {'top1': 0.353}), (50, 0.7422, {'top1': 0.7422}), (51, 0.6992, {'top1': 0.6992}), (52, 0.3402, {'top1': 0.3402}), (53, 0.1716, {'top1': 0.1716})]
just computed impact of block 20 . accuracy after removing:  0.7464
removed block 20 current accuracy 0.7464 loss from initial  0.10360000000000003
since last training loss: 0.10360000000000003 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.6868, {'top1': 0.6868}), (1, 0.6926, {'top1': 0.6926}), (2, 0.6448, {'top1': 0.6448}), (3, 0.7112, {'top1': 0.7112}), (5, 0.6264, {'top1': 0.6264}), (7, 0.6856, {'top1': 0.6856}), (8, 0.6892, {'top1': 0.6892}), (9, 0.6784, {'top1': 0.6784}), (10, 0.6742, {'top1': 0.6742}), (13, 0.6898, {'top1': 0.6898}), (16, 0.6312, {'top1': 0.6312}), (17, 0.6734, {'top1': 0.6734}), (18, 0.3302, {'top1': 0.3302}), (19, 0.644, {'top1': 0.644}), (21, 0.6756, {'top1': 0.6756}), (22, 0.6122, {'top1': 0.6122}), (23, 0.6688, {'top1': 0.6688}), (24, 0.7122, {'top1': 0.7122}), (25, 0.72, {'top1': 0.72}), (27, 0.6994, {'top1': 0.6994}), (29, 0.7038, {'top1': 0.7038}), (30, 0.6864, {'top1': 0.6864}), (36, 0.342, {'top1': 0.342}), (50, 0.7014, {'top1': 0.7014}), (51, 0.6716, {'top1': 0.6716}), (52, 0.2894, {'top1': 0.2894}), (53, 0.1646, {'top1': 0.1646})]
just computed impact of block 25 . accuracy after removing:  0.72
removed block 25 current accuracy 0.72 loss from initial  0.13
since last training loss: 0.13 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.656, {'top1': 0.656}), (1, 0.6684, {'top1': 0.6684}), (2, 0.5912, {'top1': 0.5912}), (3, 0.6678, {'top1': 0.6678}), (5, 0.585, {'top1': 0.585}), (7, 0.6522, {'top1': 0.6522}), (8, 0.6488, {'top1': 0.6488}), (9, 0.6348, {'top1': 0.6348}), (10, 0.632, {'top1': 0.632}), (13, 0.6552, {'top1': 0.6552}), (16, 0.5574, {'top1': 0.5574}), (17, 0.6304, {'top1': 0.6304}), (18, 0.3032, {'top1': 0.3032}), (19, 0.6244, {'top1': 0.6244}), (21, 0.6334, {'top1': 0.6334}), (22, 0.5568, {'top1': 0.5568}), (23, 0.621, {'top1': 0.621}), (24, 0.6654, {'top1': 0.6654}), (27, 0.651, {'top1': 0.651}), (29, 0.6592, {'top1': 0.6592}), (30, 0.6428, {'top1': 0.6428}), (36, 0.297, {'top1': 0.297}), (50, 0.6578, {'top1': 0.6578}), (51, 0.6416, {'top1': 0.6416}), (52, 0.2928, {'top1': 0.2928}), (53, 0.145, {'top1': 0.145})]
just computed impact of block 1 . accuracy after removing:  0.6684
removed block 1 current accuracy 0.6684 loss from initial  0.18159999999999998
since last training loss: 0.18159999999999998 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.5578, {'top1': 0.5578}), (2, 0.4726, {'top1': 0.4726}), (3, 0.633, {'top1': 0.633}), (5, 0.5376, {'top1': 0.5376}), (7, 0.583, {'top1': 0.583}), (8, 0.6, {'top1': 0.6}), (9, 0.5654, {'top1': 0.5654}), (10, 0.5874, {'top1': 0.5874}), (13, 0.5862, {'top1': 0.5862}), (16, 0.5298, {'top1': 0.5298}), (17, 0.5832, {'top1': 0.5832}), (18, 0.2774, {'top1': 0.2774}), (19, 0.5796, {'top1': 0.5796}), (21, 0.6052, {'top1': 0.6052}), (22, 0.5092, {'top1': 0.5092}), (23, 0.5774, {'top1': 0.5774}), (24, 0.6322, {'top1': 0.6322}), (27, 0.6224, {'top1': 0.6224}), (29, 0.6222, {'top1': 0.6222}), (30, 0.616, {'top1': 0.616}), (36, 0.2826, {'top1': 0.2826}), (50, 0.6178, {'top1': 0.6178}), (51, 0.5904, {'top1': 0.5904}), (52, 0.234, {'top1': 0.234}), (53, 0.1374, {'top1': 0.1374})]
just computed impact of block 3 . accuracy after removing:  0.633
removed block 3 current accuracy 0.633 loss from initial  0.21699999999999997
since last training loss: 0.21699999999999997 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.5054, {'top1': 0.5054}), (2, 0.403, {'top1': 0.403}), (5, 0.457, {'top1': 0.457}), (7, 0.5124, {'top1': 0.5124}), (8, 0.5276, {'top1': 0.5276}), (9, 0.517, {'top1': 0.517}), (10, 0.5254, {'top1': 0.5254}), (13, 0.5522, {'top1': 0.5522}), (16, 0.4778, {'top1': 0.4778}), (17, 0.5384, {'top1': 0.5384}), (18, 0.2336, {'top1': 0.2336}), (19, 0.5526, {'top1': 0.5526}), (21, 0.5598, {'top1': 0.5598}), (22, 0.4524, {'top1': 0.4524}), (23, 0.515, {'top1': 0.515}), (24, 0.5858, {'top1': 0.5858}), (27, 0.5692, {'top1': 0.5692}), (29, 0.5598, {'top1': 0.5598}), (30, 0.561, {'top1': 0.561}), (36, 0.24, {'top1': 0.24}), (50, 0.5636, {'top1': 0.5636}), (51, 0.5532, {'top1': 0.5532}), (52, 0.2542, {'top1': 0.2542}), (53, 0.1346, {'top1': 0.1346})]
just computed impact of block 24 . accuracy after removing:  0.5858
removed block 24 current accuracy 0.5858 loss from initial  0.2642
since last training loss: 0.2642 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.48, {'top1': 0.48}), (2, 0.4044, {'top1': 0.4044}), (5, 0.4304, {'top1': 0.4304}), (7, 0.4872, {'top1': 0.4872}), (8, 0.492, {'top1': 0.492}), (9, 0.4628, {'top1': 0.4628}), (10, 0.495, {'top1': 0.495}), (13, 0.4976, {'top1': 0.4976}), (16, 0.4422, {'top1': 0.4422}), (17, 0.4948, {'top1': 0.4948}), (18, 0.2406, {'top1': 0.2406}), (19, 0.4982, {'top1': 0.4982}), (21, 0.5152, {'top1': 0.5152}), (22, 0.4274, {'top1': 0.4274}), (23, 0.485, {'top1': 0.485}), (27, 0.5238, {'top1': 0.5238}), (29, 0.5132, {'top1': 0.5132}), (30, 0.5182, {'top1': 0.5182}), (36, 0.223, {'top1': 0.223}), (50, 0.5196, {'top1': 0.5196}), (51, 0.5344, {'top1': 0.5344}), (52, 0.2544, {'top1': 0.2544}), (53, 0.1294, {'top1': 0.1294})]
just computed impact of block 51 . accuracy after removing:  0.5344
removed block 51 current accuracy 0.5344 loss from initial  0.3156
since last training loss: 0.3156 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.416, {'top1': 0.416}), (2, 0.3626, {'top1': 0.3626}), (5, 0.3356, {'top1': 0.3356}), (7, 0.4144, {'top1': 0.4144}), (8, 0.4348, {'top1': 0.4348}), (9, 0.408, {'top1': 0.408}), (10, 0.428, {'top1': 0.428}), (13, 0.4336, {'top1': 0.4336}), (16, 0.375, {'top1': 0.375}), (17, 0.4216, {'top1': 0.4216}), (18, 0.2292, {'top1': 0.2292}), (19, 0.4706, {'top1': 0.4706}), (21, 0.4548, {'top1': 0.4548}), (22, 0.3342, {'top1': 0.3342}), (23, 0.402, {'top1': 0.402}), (27, 0.4618, {'top1': 0.4618}), (29, 0.4678, {'top1': 0.4678}), (30, 0.4708, {'top1': 0.4708}), (36, 0.22, {'top1': 0.22}), (50, 0.4408, {'top1': 0.4408}), (52, 0.1574, {'top1': 0.1574}), (53, 0.1146, {'top1': 0.1146})]
just computed impact of block 30 . accuracy after removing:  0.4708
removed block 30 current accuracy 0.4708 loss from initial  0.3792
since last training loss: 0.3792 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.3656, {'top1': 0.3656}), (2, 0.322, {'top1': 0.322}), (5, 0.2756, {'top1': 0.2756}), (7, 0.3498, {'top1': 0.3498}), (8, 0.37, {'top1': 0.37}), (9, 0.383, {'top1': 0.383}), (10, 0.3776, {'top1': 0.3776}), (13, 0.4022, {'top1': 0.4022}), (16, 0.3494, {'top1': 0.3494}), (17, 0.3822, {'top1': 0.3822}), (18, 0.2174, {'top1': 0.2174}), (19, 0.4286, {'top1': 0.4286}), (21, 0.3892, {'top1': 0.3892}), (22, 0.2906, {'top1': 0.2906}), (23, 0.3406, {'top1': 0.3406}), (27, 0.3976, {'top1': 0.3976}), (29, 0.3968, {'top1': 0.3968}), (36, 0.1932, {'top1': 0.1932}), (50, 0.3676, {'top1': 0.3676}), (52, 0.1548, {'top1': 0.1548}), (53, 0.117, {'top1': 0.117})]
just computed impact of block 19 . accuracy after removing:  0.4286
removed block 19 current accuracy 0.4286 loss from initial  0.4214
since last training loss: 0.4214 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.328, {'top1': 0.328}), (2, 0.2844, {'top1': 0.2844}), (5, 0.247, {'top1': 0.247}), (7, 0.3182, {'top1': 0.3182}), (8, 0.3448, {'top1': 0.3448}), (9, 0.3752, {'top1': 0.3752}), (10, 0.3736, {'top1': 0.3736}), (13, 0.3876, {'top1': 0.3876}), (16, 0.3424, {'top1': 0.3424}), (17, 0.368, {'top1': 0.368}), (18, 0.1688, {'top1': 0.1688}), (21, 0.393, {'top1': 0.393}), (22, 0.2726, {'top1': 0.2726}), (23, 0.3164, {'top1': 0.3164}), (27, 0.3808, {'top1': 0.3808}), (29, 0.3732, {'top1': 0.3732}), (36, 0.2162, {'top1': 0.2162}), (50, 0.3548, {'top1': 0.3548}), (52, 0.1346, {'top1': 0.1346}), (53, 0.1072, {'top1': 0.1072})]
just computed impact of block 21 . accuracy after removing:  0.393
removed block 21 current accuracy 0.393 loss from initial  0.45699999999999996
since last training loss: 0.45699999999999996 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.3168, {'top1': 0.3168}), (2, 0.2694, {'top1': 0.2694}), (5, 0.2352, {'top1': 0.2352}), (7, 0.2984, {'top1': 0.2984}), (8, 0.3078, {'top1': 0.3078}), (9, 0.3494, {'top1': 0.3494}), (10, 0.3246, {'top1': 0.3246}), (13, 0.3614, {'top1': 0.3614}), (16, 0.3272, {'top1': 0.3272}), (17, 0.3344, {'top1': 0.3344}), (18, 0.1624, {'top1': 0.1624}), (22, 0.2524, {'top1': 0.2524}), (23, 0.2826, {'top1': 0.2826}), (27, 0.3512, {'top1': 0.3512}), (29, 0.3364, {'top1': 0.3364}), (36, 0.1954, {'top1': 0.1954}), (50, 0.3082, {'top1': 0.3082}), (52, 0.1356, {'top1': 0.1356}), (53, 0.1084, {'top1': 0.1084})]
just computed impact of block 13 . accuracy after removing:  0.3614
removed block 13 current accuracy 0.3614 loss from initial  0.4886
since last training loss: 0.4886 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.2994, {'top1': 0.2994}), (2, 0.2626, {'top1': 0.2626}), (5, 0.2836, {'top1': 0.2836}), (7, 0.3312, {'top1': 0.3312}), (8, 0.309, {'top1': 0.309}), (9, 0.258, {'top1': 0.258}), (10, 0.2752, {'top1': 0.2752}), (16, 0.2714, {'top1': 0.2714}), (17, 0.2828, {'top1': 0.2828}), (18, 0.1306, {'top1': 0.1306}), (22, 0.277, {'top1': 0.277}), (23, 0.2966, {'top1': 0.2966}), (27, 0.3206, {'top1': 0.3206}), (29, 0.3148, {'top1': 0.3148}), (36, 0.2466, {'top1': 0.2466}), (50, 0.3358, {'top1': 0.3358}), (52, 0.1256, {'top1': 0.1256}), (53, 0.1086, {'top1': 0.1086})]
just computed impact of block 50 . accuracy after removing:  0.3358
removed block 50 current accuracy 0.3358 loss from initial  0.5142
since last training loss: 0.5142 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.2564, {'top1': 0.2564}), (2, 0.2046, {'top1': 0.2046}), (5, 0.2146, {'top1': 0.2146}), (7, 0.2782, {'top1': 0.2782}), (8, 0.2782, {'top1': 0.2782}), (9, 0.275, {'top1': 0.275}), (10, 0.2612, {'top1': 0.2612}), (16, 0.2476, {'top1': 0.2476}), (17, 0.2604, {'top1': 0.2604}), (18, 0.1444, {'top1': 0.1444}), (22, 0.2154, {'top1': 0.2154}), (23, 0.2416, {'top1': 0.2416}), (27, 0.2786, {'top1': 0.2786}), (29, 0.259, {'top1': 0.259}), (36, 0.2464, {'top1': 0.2464}), (52, 0.113, {'top1': 0.113}), (53, 0.1038, {'top1': 0.1038})]
just computed impact of block 27 . accuracy after removing:  0.2786
removed block 27 current accuracy 0.2786 loss from initial  0.5713999999999999
since last training loss: 0.5713999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.2292, {'top1': 0.2292}), (2, 0.1828, {'top1': 0.1828}), (5, 0.1914, {'top1': 0.1914}), (7, 0.2296, {'top1': 0.2296}), (8, 0.2358, {'top1': 0.2358}), (9, 0.252, {'top1': 0.252}), (10, 0.23, {'top1': 0.23}), (16, 0.2342, {'top1': 0.2342}), (17, 0.2252, {'top1': 0.2252}), (18, 0.1322, {'top1': 0.1322}), (22, 0.1956, {'top1': 0.1956}), (23, 0.214, {'top1': 0.214}), (29, 0.218, {'top1': 0.218}), (36, 0.2368, {'top1': 0.2368}), (52, 0.1086, {'top1': 0.1086}), (53, 0.1002, {'top1': 0.1002})]
just computed impact of block 9 . accuracy after removing:  0.252
removed block 9 current accuracy 0.252 loss from initial  0.598
since last training loss: 0.598 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.1988, {'top1': 0.1988}), (2, 0.2016, {'top1': 0.2016}), (5, 0.2338, {'top1': 0.2338}), (7, 0.2388, {'top1': 0.2388}), (8, 0.2272, {'top1': 0.2272}), (10, 0.209, {'top1': 0.209}), (16, 0.2036, {'top1': 0.2036}), (17, 0.196, {'top1': 0.196}), (18, 0.1392, {'top1': 0.1392}), (22, 0.196, {'top1': 0.196}), (23, 0.2136, {'top1': 0.2136}), (29, 0.2118, {'top1': 0.2118}), (36, 0.209, {'top1': 0.209}), (52, 0.1048, {'top1': 0.1048}), (53, 0.0926, {'top1': 0.0926})]
just computed impact of block 7 . accuracy after removing:  0.2388
removed block 7 current accuracy 0.2388 loss from initial  0.6112
since last training loss: 0.6112 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.1748, {'top1': 0.1748}), (2, 0.181, {'top1': 0.181}), (5, 0.205, {'top1': 0.205}), (8, 0.2, {'top1': 0.2}), (10, 0.1968, {'top1': 0.1968}), (16, 0.1916, {'top1': 0.1916}), (17, 0.1756, {'top1': 0.1756}), (18, 0.1322, {'top1': 0.1322}), (22, 0.1544, {'top1': 0.1544}), (23, 0.189, {'top1': 0.189}), (29, 0.1912, {'top1': 0.1912}), (36, 0.1884, {'top1': 0.1884}), (52, 0.1014, {'top1': 0.1014}), (53, 0.0864, {'top1': 0.0864})]
just computed impact of block 5 . accuracy after removing:  0.205
removed block 5 current accuracy 0.205 loss from initial  0.645
since last training loss: 0.645 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.1598, {'top1': 0.1598}), (2, 0.1504, {'top1': 0.1504}), (8, 0.1636, {'top1': 0.1636}), (10, 0.17, {'top1': 0.17}), (16, 0.1652, {'top1': 0.1652}), (17, 0.1414, {'top1': 0.1414}), (18, 0.1222, {'top1': 0.1222}), (22, 0.111, {'top1': 0.111}), (23, 0.1616, {'top1': 0.1616}), (29, 0.1594, {'top1': 0.1594}), (36, 0.1584, {'top1': 0.1584}), (52, 0.099, {'top1': 0.099}), (53, 0.084, {'top1': 0.084})]
just computed impact of block 10 . accuracy after removing:  0.17
removed block 10 current accuracy 0.17 loss from initial  0.6799999999999999
since last training loss: 0.6799999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(0, 0.136, {'top1': 0.136}), (2, 0.1388, {'top1': 0.1388}), (8, 0.135, {'top1': 0.135}), (16, 0.153, {'top1': 0.153}), (17, 0.128, {'top1': 0.128}), (18, 0.1288, {'top1': 0.1288}), (22, 0.1204, {'top1': 0.1204}), (23, 0.1452, {'top1': 0.1452}), (29, 0.1412, {'top1': 0.1412}), (36, 0.1354, {'top1': 0.1354}), (52, 0.1086, {'top1': 0.1086}), (53, 0.075, {'top1': 0.075})]
just computed impact of block 16 . accuracy after removing:  0.153
removed block 16 current accuracy 0.153 loss from initial  0.697
since last training loss: 0.697 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(0, 0.1394, {'top1': 0.1394}), (2, 0.1294, {'top1': 0.1294}), (8, 0.1438, {'top1': 0.1438}), (17, 0.1234, {'top1': 0.1234}), (18, 0.1082, {'top1': 0.1082}), (22, 0.1192, {'top1': 0.1192}), (23, 0.1458, {'top1': 0.1458}), (29, 0.1282, {'top1': 0.1282}), (36, 0.0998, {'top1': 0.0998}), (52, 0.148, {'top1': 0.148}), (53, 0.0862, {'top1': 0.0862})]
just computed impact of block 52 . accuracy after removing:  0.148
removed block 52 current accuracy 0.148 loss from initial  0.702
since last training loss: 0.702 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(0, 0.149, {'top1': 0.149}), (2, 0.1176, {'top1': 0.1176}), (8, 0.1718, {'top1': 0.1718}), (17, 0.1594, {'top1': 0.1594}), (18, 0.106, {'top1': 0.106}), (22, 0.143, {'top1': 0.143}), (23, 0.1572, {'top1': 0.1572}), (29, 0.16, {'top1': 0.16}), (36, 0.1018, {'top1': 0.1018}), (53, 0.0962, {'top1': 0.0962})]
just computed impact of block 8 . accuracy after removing:  0.1718
removed block 8 current accuracy 0.1718 loss from initial  0.6781999999999999
training start
training epoch 0 val accuracy 0.7378 topk_dict {'top1': 0.7378} is_best True lr [0.1]
training epoch 1 val accuracy 0.7188 topk_dict {'top1': 0.7188} is_best False lr [0.1]
training epoch 2 val accuracy 0.7518 topk_dict {'top1': 0.7518} is_best True lr [0.1]
training epoch 3 val accuracy 0.7598 topk_dict {'top1': 0.7598} is_best True lr [0.1]
training epoch 4 val accuracy 0.7726 topk_dict {'top1': 0.7726} is_best True lr [0.1]
training epoch 5 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best False lr [0.1]
training epoch 6 val accuracy 0.7784 topk_dict {'top1': 0.7784} is_best True lr [0.1]
training epoch 7 val accuracy 0.812 topk_dict {'top1': 0.812} is_best True lr [0.1]
training epoch 8 val accuracy 0.8016 topk_dict {'top1': 0.8016} is_best False lr [0.1]
training epoch 9 val accuracy 0.807 topk_dict {'top1': 0.807} is_best False lr [0.1]
training epoch 10 val accuracy 0.83 topk_dict {'top1': 0.83} is_best True lr [0.1]
training epoch 11 val accuracy 0.8014 topk_dict {'top1': 0.8014} is_best False lr [0.1]
training epoch 12 val accuracy 0.804 topk_dict {'top1': 0.804} is_best False lr [0.1]
training epoch 13 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.1]
training epoch 14 val accuracy 0.7818 topk_dict {'top1': 0.7818} is_best False lr [0.1]
training epoch 15 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best True lr [0.1]
training epoch 16 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 17 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 18 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best False lr [0.1]
training epoch 19 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best True lr [0.1]
training epoch 20 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best False lr [0.1]
training epoch 21 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best False lr [0.1]
training epoch 22 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 23 val accuracy 0.824 topk_dict {'top1': 0.824} is_best False lr [0.1]
training epoch 24 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best False lr [0.1]
training epoch 25 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 26 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best True lr [0.1]
training epoch 27 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best False lr [0.1]
training epoch 28 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 29 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 30 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.1]
training epoch 31 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 32 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 33 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best True lr [0.1]
training epoch 34 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 35 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 36 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best False lr [0.1]
training epoch 37 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 38 val accuracy 0.8096 topk_dict {'top1': 0.8096} is_best False lr [0.1]
training epoch 39 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 40 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 41 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 42 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 43 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 44 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 45 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 46 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 47 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 48 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.1]
training epoch 49 val accuracy 0.87 topk_dict {'top1': 0.87} is_best True lr [0.1]
training epoch 50 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 51 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 52 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 53 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 54 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 55 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 56 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 57 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 58 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 59 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 60 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 61 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 62 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 63 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 64 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.1]
training epoch 65 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 66 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 67 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 68 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 69 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 70 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 71 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 72 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 73 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 74 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 75 val accuracy 0.817 topk_dict {'top1': 0.817} is_best False lr [0.1]
training epoch 76 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 77 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best False lr [0.1]
training epoch 78 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 79 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 80 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 81 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 82 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 83 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 84 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 85 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 86 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 87 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 88 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.1]
training epoch 89 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 90 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 91 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 92 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best False lr [0.1]
training epoch 93 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 94 val accuracy 0.8086 topk_dict {'top1': 0.8086} is_best False lr [0.1]
training epoch 95 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 96 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 97 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 98 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 99 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 100 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 101 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 102 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 103 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 104 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 105 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 106 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 107 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 108 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 109 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 110 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 111 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 112 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 113 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 114 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 115 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 116 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 117 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.1]
training epoch 118 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 119 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 120 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 121 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 122 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 123 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 124 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 125 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best False lr [0.1]
training epoch 126 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 127 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 128 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 129 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 130 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 131 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 132 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 133 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 134 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 135 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 136 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 137 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 138 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 139 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 140 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 141 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 142 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 143 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 144 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 145 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 146 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 147 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 148 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 149 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 150 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 151 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 152 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 153 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 154 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 155 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 156 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 157 val accuracy 0.8242 topk_dict {'top1': 0.8242} is_best False lr [0.1]
training epoch 158 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 159 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 160 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 161 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 162 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 163 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 164 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 165 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 166 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 167 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 168 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 169 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 170 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 171 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best False lr [0.1]
training epoch 172 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 173 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 174 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best False lr [0.1]
training epoch 175 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 176 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 177 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 178 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 179 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best False lr [0.1]
training epoch 180 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 181 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 182 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 183 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 184 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 185 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 186 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 187 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 188 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 189 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 190 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 191 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 192 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 193 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 194 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 195 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 196 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 197 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 198 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 199 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 200 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 201 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 202 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 203 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 204 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 205 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 206 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 207 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 208 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 209 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 210 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 211 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 212 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 213 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 214 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 215 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 216 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 217 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 218 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 219 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 220 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 221 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 222 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 223 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 224 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 225 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 226 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 227 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 228 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 229 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 230 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 231 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 232 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 233 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 234 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.010000000000000002]
training epoch 235 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.010000000000000002]
training epoch 236 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.010000000000000002]
training epoch 237 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 238 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.010000000000000002]
training epoch 239 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.010000000000000002]
training epoch 240 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 241 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.010000000000000002]
training epoch 242 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 246 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 250 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.010000000000000002]
training epoch 258 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.010000000000000002]
training epoch 263 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.010000000000000002]
training epoch 317 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 352 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 353 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 354 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 355 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 356 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 357 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 358 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 359 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 366 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
loading model_best from epoch 316 (acc 0.919800)
finished training. finished 469 epochs. accuracy 0.9198 topk_dict {'top1': 0.9198}
