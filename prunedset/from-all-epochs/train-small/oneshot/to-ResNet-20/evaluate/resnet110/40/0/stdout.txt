start iteration 0
(cache recomputed) Accuracy log [(0, 0.8872, {'top1': 0.8872}), (1, 0.893, {'top1': 0.893}), (2, 0.8784, {'top1': 0.8784}), (3, 0.9112, {'top1': 0.9112}), (4, 0.9138, {'top1': 0.9138}), (5, 0.8746, {'top1': 0.8746}), (6, 0.911, {'top1': 0.911}), (7, 0.8936, {'top1': 0.8936}), (8, 0.8916, {'top1': 0.8916}), (9, 0.899, {'top1': 0.899}), (10, 0.904, {'top1': 0.904}), (11, 0.8996, {'top1': 0.8996}), (12, 0.9044, {'top1': 0.9044}), (13, 0.8974, {'top1': 0.8974}), (14, 0.9054, {'top1': 0.9054}), (15, 0.9042, {'top1': 0.9042}), (16, 0.9034, {'top1': 0.9034}), (17, 0.9008, {'top1': 0.9008}), (18, 0.396, {'top1': 0.396}), (19, 0.8728, {'top1': 0.8728}), (20, 0.894, {'top1': 0.894}), (21, 0.9124, {'top1': 0.9124}), (22, 0.9008, {'top1': 0.9008}), (23, 0.9082, {'top1': 0.9082}), (24, 0.9124, {'top1': 0.9124}), (25, 0.9088, {'top1': 0.9088}), (26, 0.9132, {'top1': 0.9132}), (27, 0.9174, {'top1': 0.9174}), (28, 0.9128, {'top1': 0.9128}), (29, 0.9128, {'top1': 0.9128}), (30, 0.913, {'top1': 0.913}), (31, 0.9124, {'top1': 0.9124}), (32, 0.9132, {'top1': 0.9132}), (33, 0.9154, {'top1': 0.9154}), (34, 0.9136, {'top1': 0.9136}), (35, 0.9174, {'top1': 0.9174}), (36, 0.6028, {'top1': 0.6028}), (37, 0.9164, {'top1': 0.9164}), (38, 0.9124, {'top1': 0.9124}), (39, 0.9158, {'top1': 0.9158}), (40, 0.915, {'top1': 0.915}), (41, 0.9142, {'top1': 0.9142}), (42, 0.9146, {'top1': 0.9146}), (43, 0.9146, {'top1': 0.9146}), (44, 0.9096, {'top1': 0.9096}), (45, 0.912, {'top1': 0.912}), (46, 0.9108, {'top1': 0.9108}), (47, 0.9116, {'top1': 0.9116}), (48, 0.9092, {'top1': 0.9092}), (49, 0.91, {'top1': 0.91}), (50, 0.8894, {'top1': 0.8894}), (51, 0.8088, {'top1': 0.8088}), (52, 0.4032, {'top1': 0.4032}), (53, 0.2948, {'top1': 0.2948})]
just computed impact of block 27 . accuracy after removing:  0.9174
removed block 27 current accuracy 0.9174 loss from initial  -0.0041999999999999815
since last training loss: -0.0041999999999999815 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.8694, {'top1': 0.8694}), (1, 0.881, {'top1': 0.881}), (2, 0.8544, {'top1': 0.8544}), (3, 0.9044, {'top1': 0.9044}), (4, 0.9114, {'top1': 0.9114}), (5, 0.8756, {'top1': 0.8756}), (6, 0.9028, {'top1': 0.9028}), (7, 0.8888, {'top1': 0.8888}), (8, 0.8912, {'top1': 0.8912}), (9, 0.895, {'top1': 0.895}), (10, 0.9042, {'top1': 0.9042}), (11, 0.9012, {'top1': 0.9012}), (12, 0.898, {'top1': 0.898}), (13, 0.9054, {'top1': 0.9054}), (14, 0.908, {'top1': 0.908}), (15, 0.9104, {'top1': 0.9104}), (16, 0.9022, {'top1': 0.9022}), (17, 0.9082, {'top1': 0.9082}), (18, 0.3832, {'top1': 0.3832}), (19, 0.883, {'top1': 0.883}), (20, 0.9016, {'top1': 0.9016}), (21, 0.9032, {'top1': 0.9032}), (22, 0.8844, {'top1': 0.8844}), (23, 0.9022, {'top1': 0.9022}), (24, 0.9114, {'top1': 0.9114}), (25, 0.9126, {'top1': 0.9126}), (26, 0.9078, {'top1': 0.9078}), (28, 0.9114, {'top1': 0.9114}), (29, 0.9084, {'top1': 0.9084}), (30, 0.9064, {'top1': 0.9064}), (31, 0.9096, {'top1': 0.9096}), (32, 0.9146, {'top1': 0.9146}), (33, 0.9128, {'top1': 0.9128}), (34, 0.9142, {'top1': 0.9142}), (35, 0.9138, {'top1': 0.9138}), (36, 0.503, {'top1': 0.503}), (37, 0.9142, {'top1': 0.9142}), (38, 0.9148, {'top1': 0.9148}), (39, 0.9176, {'top1': 0.9176}), (40, 0.9192, {'top1': 0.9192}), (41, 0.917, {'top1': 0.917}), (42, 0.9178, {'top1': 0.9178}), (43, 0.9172, {'top1': 0.9172}), (44, 0.9162, {'top1': 0.9162}), (45, 0.915, {'top1': 0.915}), (46, 0.9178, {'top1': 0.9178}), (47, 0.9162, {'top1': 0.9162}), (48, 0.9164, {'top1': 0.9164}), (49, 0.9142, {'top1': 0.9142}), (50, 0.8838, {'top1': 0.8838}), (51, 0.8016, {'top1': 0.8016}), (52, 0.4006, {'top1': 0.4006}), (53, 0.2806, {'top1': 0.2806})]
just computed impact of block 40 . accuracy after removing:  0.9192
removed block 40 current accuracy 0.9192 loss from initial  -0.006000000000000005
since last training loss: -0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8722, {'top1': 0.8722}), (1, 0.8842, {'top1': 0.8842}), (2, 0.8596, {'top1': 0.8596}), (3, 0.907, {'top1': 0.907}), (4, 0.913, {'top1': 0.913}), (5, 0.8806, {'top1': 0.8806}), (6, 0.908, {'top1': 0.908}), (7, 0.896, {'top1': 0.896}), (8, 0.897, {'top1': 0.897}), (9, 0.8982, {'top1': 0.8982}), (10, 0.904, {'top1': 0.904}), (11, 0.9032, {'top1': 0.9032}), (12, 0.9014, {'top1': 0.9014}), (13, 0.9054, {'top1': 0.9054}), (14, 0.9082, {'top1': 0.9082}), (15, 0.9118, {'top1': 0.9118}), (16, 0.904, {'top1': 0.904}), (17, 0.9078, {'top1': 0.9078}), (18, 0.3878, {'top1': 0.3878}), (19, 0.887, {'top1': 0.887}), (20, 0.9018, {'top1': 0.9018}), (21, 0.904, {'top1': 0.904}), (22, 0.8874, {'top1': 0.8874}), (23, 0.9042, {'top1': 0.9042}), (24, 0.9128, {'top1': 0.9128}), (25, 0.914, {'top1': 0.914}), (26, 0.9094, {'top1': 0.9094}), (28, 0.9132, {'top1': 0.9132}), (29, 0.9148, {'top1': 0.9148}), (30, 0.9084, {'top1': 0.9084}), (31, 0.9126, {'top1': 0.9126}), (32, 0.9178, {'top1': 0.9178}), (33, 0.9158, {'top1': 0.9158}), (34, 0.9156, {'top1': 0.9156}), (35, 0.9154, {'top1': 0.9154}), (36, 0.5156, {'top1': 0.5156}), (37, 0.9158, {'top1': 0.9158}), (38, 0.9174, {'top1': 0.9174}), (39, 0.9192, {'top1': 0.9192}), (41, 0.9186, {'top1': 0.9186}), (42, 0.92, {'top1': 0.92}), (43, 0.921, {'top1': 0.921}), (44, 0.9188, {'top1': 0.9188}), (45, 0.918, {'top1': 0.918}), (46, 0.9182, {'top1': 0.9182}), (47, 0.92, {'top1': 0.92}), (48, 0.919, {'top1': 0.919}), (49, 0.9164, {'top1': 0.9164}), (50, 0.8874, {'top1': 0.8874}), (51, 0.8062, {'top1': 0.8062}), (52, 0.415, {'top1': 0.415}), (53, 0.2826, {'top1': 0.2826})]
just computed impact of block 43 . accuracy after removing:  0.921
removed block 43 current accuracy 0.921 loss from initial  -0.007800000000000029
since last training loss: -0.007800000000000029 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.8734, {'top1': 0.8734}), (1, 0.8858, {'top1': 0.8858}), (2, 0.8604, {'top1': 0.8604}), (3, 0.9068, {'top1': 0.9068}), (4, 0.9144, {'top1': 0.9144}), (5, 0.884, {'top1': 0.884}), (6, 0.9096, {'top1': 0.9096}), (7, 0.8966, {'top1': 0.8966}), (8, 0.9002, {'top1': 0.9002}), (9, 0.8986, {'top1': 0.8986}), (10, 0.9042, {'top1': 0.9042}), (11, 0.9054, {'top1': 0.9054}), (12, 0.9016, {'top1': 0.9016}), (13, 0.9078, {'top1': 0.9078}), (14, 0.9108, {'top1': 0.9108}), (15, 0.9122, {'top1': 0.9122}), (16, 0.9048, {'top1': 0.9048}), (17, 0.9098, {'top1': 0.9098}), (18, 0.3978, {'top1': 0.3978}), (19, 0.8888, {'top1': 0.8888}), (20, 0.8978, {'top1': 0.8978}), (21, 0.9032, {'top1': 0.9032}), (22, 0.8904, {'top1': 0.8904}), (23, 0.9048, {'top1': 0.9048}), (24, 0.9116, {'top1': 0.9116}), (25, 0.912, {'top1': 0.912}), (26, 0.9108, {'top1': 0.9108}), (28, 0.9122, {'top1': 0.9122}), (29, 0.916, {'top1': 0.916}), (30, 0.9084, {'top1': 0.9084}), (31, 0.9128, {'top1': 0.9128}), (32, 0.9178, {'top1': 0.9178}), (33, 0.9146, {'top1': 0.9146}), (34, 0.916, {'top1': 0.916}), (35, 0.917, {'top1': 0.917}), (36, 0.5168, {'top1': 0.5168}), (37, 0.9164, {'top1': 0.9164}), (38, 0.9188, {'top1': 0.9188}), (39, 0.9202, {'top1': 0.9202}), (41, 0.9186, {'top1': 0.9186}), (42, 0.9184, {'top1': 0.9184}), (44, 0.919, {'top1': 0.919}), (45, 0.9178, {'top1': 0.9178}), (46, 0.9182, {'top1': 0.9182}), (47, 0.92, {'top1': 0.92}), (48, 0.9186, {'top1': 0.9186}), (49, 0.9162, {'top1': 0.9162}), (50, 0.8886, {'top1': 0.8886}), (51, 0.8094, {'top1': 0.8094}), (52, 0.4232, {'top1': 0.4232}), (53, 0.2856, {'top1': 0.2856})]
just computed impact of block 39 . accuracy after removing:  0.9202
removed block 39 current accuracy 0.9202 loss from initial  -0.007000000000000006
since last training loss: -0.007000000000000006 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8732, {'top1': 0.8732}), (1, 0.884, {'top1': 0.884}), (2, 0.8598, {'top1': 0.8598}), (3, 0.9062, {'top1': 0.9062}), (4, 0.9124, {'top1': 0.9124}), (5, 0.8844, {'top1': 0.8844}), (6, 0.9078, {'top1': 0.9078}), (7, 0.898, {'top1': 0.898}), (8, 0.8984, {'top1': 0.8984}), (9, 0.8984, {'top1': 0.8984}), (10, 0.9052, {'top1': 0.9052}), (11, 0.9054, {'top1': 0.9054}), (12, 0.9018, {'top1': 0.9018}), (13, 0.9058, {'top1': 0.9058}), (14, 0.9088, {'top1': 0.9088}), (15, 0.9116, {'top1': 0.9116}), (16, 0.9032, {'top1': 0.9032}), (17, 0.9074, {'top1': 0.9074}), (18, 0.395, {'top1': 0.395}), (19, 0.8926, {'top1': 0.8926}), (20, 0.8988, {'top1': 0.8988}), (21, 0.9002, {'top1': 0.9002}), (22, 0.8852, {'top1': 0.8852}), (23, 0.9042, {'top1': 0.9042}), (24, 0.9112, {'top1': 0.9112}), (25, 0.9126, {'top1': 0.9126}), (26, 0.9098, {'top1': 0.9098}), (28, 0.91, {'top1': 0.91}), (29, 0.9144, {'top1': 0.9144}), (30, 0.9076, {'top1': 0.9076}), (31, 0.9114, {'top1': 0.9114}), (32, 0.9168, {'top1': 0.9168}), (33, 0.9146, {'top1': 0.9146}), (34, 0.9152, {'top1': 0.9152}), (35, 0.9158, {'top1': 0.9158}), (36, 0.5124, {'top1': 0.5124}), (37, 0.9152, {'top1': 0.9152}), (38, 0.9184, {'top1': 0.9184}), (41, 0.9192, {'top1': 0.9192}), (42, 0.9172, {'top1': 0.9172}), (44, 0.918, {'top1': 0.918}), (45, 0.918, {'top1': 0.918}), (46, 0.9176, {'top1': 0.9176}), (47, 0.9186, {'top1': 0.9186}), (48, 0.92, {'top1': 0.92}), (49, 0.9182, {'top1': 0.9182}), (50, 0.8886, {'top1': 0.8886}), (51, 0.8096, {'top1': 0.8096}), (52, 0.423, {'top1': 0.423}), (53, 0.289, {'top1': 0.289})]
just computed impact of block 48 . accuracy after removing:  0.92
removed block 48 current accuracy 0.92 loss from initial  -0.006800000000000028
since last training loss: -0.006800000000000028 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8754, {'top1': 0.8754}), (1, 0.887, {'top1': 0.887}), (2, 0.8618, {'top1': 0.8618}), (3, 0.9084, {'top1': 0.9084}), (4, 0.9158, {'top1': 0.9158}), (5, 0.884, {'top1': 0.884}), (6, 0.9106, {'top1': 0.9106}), (7, 0.898, {'top1': 0.898}), (8, 0.898, {'top1': 0.898}), (9, 0.8976, {'top1': 0.8976}), (10, 0.9046, {'top1': 0.9046}), (11, 0.9032, {'top1': 0.9032}), (12, 0.904, {'top1': 0.904}), (13, 0.9048, {'top1': 0.9048}), (14, 0.907, {'top1': 0.907}), (15, 0.9102, {'top1': 0.9102}), (16, 0.902, {'top1': 0.902}), (17, 0.907, {'top1': 0.907}), (18, 0.397, {'top1': 0.397}), (19, 0.8866, {'top1': 0.8866}), (20, 0.8958, {'top1': 0.8958}), (21, 0.904, {'top1': 0.904}), (22, 0.8922, {'top1': 0.8922}), (23, 0.9046, {'top1': 0.9046}), (24, 0.9126, {'top1': 0.9126}), (25, 0.9142, {'top1': 0.9142}), (26, 0.9112, {'top1': 0.9112}), (28, 0.9094, {'top1': 0.9094}), (29, 0.915, {'top1': 0.915}), (30, 0.909, {'top1': 0.909}), (31, 0.912, {'top1': 0.912}), (32, 0.9178, {'top1': 0.9178}), (33, 0.9156, {'top1': 0.9156}), (34, 0.9164, {'top1': 0.9164}), (35, 0.9164, {'top1': 0.9164}), (36, 0.5106, {'top1': 0.5106}), (37, 0.9164, {'top1': 0.9164}), (38, 0.919, {'top1': 0.919}), (41, 0.9194, {'top1': 0.9194}), (42, 0.9194, {'top1': 0.9194}), (44, 0.9176, {'top1': 0.9176}), (45, 0.9166, {'top1': 0.9166}), (46, 0.9162, {'top1': 0.9162}), (47, 0.9174, {'top1': 0.9174}), (49, 0.9184, {'top1': 0.9184}), (50, 0.8914, {'top1': 0.8914}), (51, 0.8044, {'top1': 0.8044}), (52, 0.4124, {'top1': 0.4124}), (53, 0.2838, {'top1': 0.2838})]
just computed impact of block 41 . accuracy after removing:  0.9194
removed block 41 current accuracy 0.9194 loss from initial  -0.006199999999999983
since last training loss: -0.006199999999999983 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.8758, {'top1': 0.8758}), (1, 0.8876, {'top1': 0.8876}), (2, 0.8606, {'top1': 0.8606}), (3, 0.9064, {'top1': 0.9064}), (4, 0.9138, {'top1': 0.9138}), (5, 0.8858, {'top1': 0.8858}), (6, 0.9096, {'top1': 0.9096}), (7, 0.8974, {'top1': 0.8974}), (8, 0.8996, {'top1': 0.8996}), (9, 0.8944, {'top1': 0.8944}), (10, 0.9038, {'top1': 0.9038}), (11, 0.9042, {'top1': 0.9042}), (12, 0.9014, {'top1': 0.9014}), (13, 0.9044, {'top1': 0.9044}), (14, 0.907, {'top1': 0.907}), (15, 0.9094, {'top1': 0.9094}), (16, 0.9008, {'top1': 0.9008}), (17, 0.9074, {'top1': 0.9074}), (18, 0.395, {'top1': 0.395}), (19, 0.8868, {'top1': 0.8868}), (20, 0.8972, {'top1': 0.8972}), (21, 0.902, {'top1': 0.902}), (22, 0.8892, {'top1': 0.8892}), (23, 0.9032, {'top1': 0.9032}), (24, 0.9136, {'top1': 0.9136}), (25, 0.9144, {'top1': 0.9144}), (26, 0.9108, {'top1': 0.9108}), (28, 0.91, {'top1': 0.91}), (29, 0.9158, {'top1': 0.9158}), (30, 0.9078, {'top1': 0.9078}), (31, 0.9126, {'top1': 0.9126}), (32, 0.9184, {'top1': 0.9184}), (33, 0.9156, {'top1': 0.9156}), (34, 0.9178, {'top1': 0.9178}), (35, 0.9162, {'top1': 0.9162}), (36, 0.5208, {'top1': 0.5208}), (37, 0.9164, {'top1': 0.9164}), (38, 0.9176, {'top1': 0.9176}), (42, 0.9178, {'top1': 0.9178}), (44, 0.9184, {'top1': 0.9184}), (45, 0.918, {'top1': 0.918}), (46, 0.9174, {'top1': 0.9174}), (47, 0.9182, {'top1': 0.9182}), (49, 0.9188, {'top1': 0.9188}), (50, 0.8934, {'top1': 0.8934}), (51, 0.8074, {'top1': 0.8074}), (52, 0.4228, {'top1': 0.4228}), (53, 0.2882, {'top1': 0.2882})]
just computed impact of block 49 . accuracy after removing:  0.9188
removed block 49 current accuracy 0.9188 loss from initial  -0.005599999999999938
since last training loss: -0.005599999999999938 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.8762, {'top1': 0.8762}), (1, 0.8872, {'top1': 0.8872}), (2, 0.8638, {'top1': 0.8638}), (3, 0.909, {'top1': 0.909}), (4, 0.9128, {'top1': 0.9128}), (5, 0.8804, {'top1': 0.8804}), (6, 0.9076, {'top1': 0.9076}), (7, 0.8978, {'top1': 0.8978}), (8, 0.8982, {'top1': 0.8982}), (9, 0.8944, {'top1': 0.8944}), (10, 0.902, {'top1': 0.902}), (11, 0.9038, {'top1': 0.9038}), (12, 0.902, {'top1': 0.902}), (13, 0.9024, {'top1': 0.9024}), (14, 0.9078, {'top1': 0.9078}), (15, 0.9082, {'top1': 0.9082}), (16, 0.9024, {'top1': 0.9024}), (17, 0.9082, {'top1': 0.9082}), (18, 0.3984, {'top1': 0.3984}), (19, 0.8822, {'top1': 0.8822}), (20, 0.893, {'top1': 0.893}), (21, 0.9018, {'top1': 0.9018}), (22, 0.895, {'top1': 0.895}), (23, 0.9046, {'top1': 0.9046}), (24, 0.909, {'top1': 0.909}), (25, 0.914, {'top1': 0.914}), (26, 0.9092, {'top1': 0.9092}), (28, 0.9094, {'top1': 0.9094}), (29, 0.9132, {'top1': 0.9132}), (30, 0.9076, {'top1': 0.9076}), (31, 0.9118, {'top1': 0.9118}), (32, 0.916, {'top1': 0.916}), (33, 0.9164, {'top1': 0.9164}), (34, 0.9156, {'top1': 0.9156}), (35, 0.9138, {'top1': 0.9138}), (36, 0.5286, {'top1': 0.5286}), (37, 0.9172, {'top1': 0.9172}), (38, 0.9176, {'top1': 0.9176}), (42, 0.9178, {'top1': 0.9178}), (44, 0.9162, {'top1': 0.9162}), (45, 0.9136, {'top1': 0.9136}), (46, 0.9136, {'top1': 0.9136}), (47, 0.9184, {'top1': 0.9184}), (50, 0.8888, {'top1': 0.8888}), (51, 0.7998, {'top1': 0.7998}), (52, 0.408, {'top1': 0.408}), (53, 0.2838, {'top1': 0.2838})]
just computed impact of block 47 . accuracy after removing:  0.9184
removed block 47 current accuracy 0.9184 loss from initial  -0.005199999999999982
since last training loss: -0.005199999999999982 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.8728, {'top1': 0.8728}), (1, 0.8884, {'top1': 0.8884}), (2, 0.8622, {'top1': 0.8622}), (3, 0.9082, {'top1': 0.9082}), (4, 0.9128, {'top1': 0.9128}), (5, 0.8798, {'top1': 0.8798}), (6, 0.9062, {'top1': 0.9062}), (7, 0.8968, {'top1': 0.8968}), (8, 0.9004, {'top1': 0.9004}), (9, 0.8912, {'top1': 0.8912}), (10, 0.8994, {'top1': 0.8994}), (11, 0.9024, {'top1': 0.9024}), (12, 0.9016, {'top1': 0.9016}), (13, 0.9006, {'top1': 0.9006}), (14, 0.9048, {'top1': 0.9048}), (15, 0.9078, {'top1': 0.9078}), (16, 0.8966, {'top1': 0.8966}), (17, 0.904, {'top1': 0.904}), (18, 0.3812, {'top1': 0.3812}), (19, 0.8782, {'top1': 0.8782}), (20, 0.8912, {'top1': 0.8912}), (21, 0.899, {'top1': 0.899}), (22, 0.8936, {'top1': 0.8936}), (23, 0.9036, {'top1': 0.9036}), (24, 0.9088, {'top1': 0.9088}), (25, 0.9106, {'top1': 0.9106}), (26, 0.9088, {'top1': 0.9088}), (28, 0.9106, {'top1': 0.9106}), (29, 0.912, {'top1': 0.912}), (30, 0.9052, {'top1': 0.9052}), (31, 0.9104, {'top1': 0.9104}), (32, 0.9146, {'top1': 0.9146}), (33, 0.915, {'top1': 0.915}), (34, 0.9144, {'top1': 0.9144}), (35, 0.9142, {'top1': 0.9142}), (36, 0.54, {'top1': 0.54}), (37, 0.9146, {'top1': 0.9146}), (38, 0.9158, {'top1': 0.9158}), (42, 0.9152, {'top1': 0.9152}), (44, 0.9164, {'top1': 0.9164}), (45, 0.9144, {'top1': 0.9144}), (46, 0.9122, {'top1': 0.9122}), (50, 0.8898, {'top1': 0.8898}), (51, 0.8028, {'top1': 0.8028}), (52, 0.4102, {'top1': 0.4102}), (53, 0.2768, {'top1': 0.2768})]
just computed impact of block 44 . accuracy after removing:  0.9164
removed block 44 current accuracy 0.9164 loss from initial  -0.0031999999999999806
since last training loss: -0.0031999999999999806 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8748, {'top1': 0.8748}), (1, 0.8874, {'top1': 0.8874}), (2, 0.863, {'top1': 0.863}), (3, 0.908, {'top1': 0.908}), (4, 0.9084, {'top1': 0.9084}), (5, 0.8764, {'top1': 0.8764}), (6, 0.9046, {'top1': 0.9046}), (7, 0.8966, {'top1': 0.8966}), (8, 0.898, {'top1': 0.898}), (9, 0.8906, {'top1': 0.8906}), (10, 0.898, {'top1': 0.898}), (11, 0.9004, {'top1': 0.9004}), (12, 0.9012, {'top1': 0.9012}), (13, 0.898, {'top1': 0.898}), (14, 0.905, {'top1': 0.905}), (15, 0.907, {'top1': 0.907}), (16, 0.8974, {'top1': 0.8974}), (17, 0.901, {'top1': 0.901}), (18, 0.372, {'top1': 0.372}), (19, 0.8778, {'top1': 0.8778}), (20, 0.8886, {'top1': 0.8886}), (21, 0.899, {'top1': 0.899}), (22, 0.8952, {'top1': 0.8952}), (23, 0.903, {'top1': 0.903}), (24, 0.9076, {'top1': 0.9076}), (25, 0.9102, {'top1': 0.9102}), (26, 0.9078, {'top1': 0.9078}), (28, 0.908, {'top1': 0.908}), (29, 0.9098, {'top1': 0.9098}), (30, 0.9046, {'top1': 0.9046}), (31, 0.9082, {'top1': 0.9082}), (32, 0.9114, {'top1': 0.9114}), (33, 0.9136, {'top1': 0.9136}), (34, 0.912, {'top1': 0.912}), (35, 0.9128, {'top1': 0.9128}), (36, 0.553, {'top1': 0.553}), (37, 0.9134, {'top1': 0.9134}), (38, 0.9136, {'top1': 0.9136}), (42, 0.9138, {'top1': 0.9138}), (45, 0.912, {'top1': 0.912}), (46, 0.9106, {'top1': 0.9106}), (50, 0.8856, {'top1': 0.8856}), (51, 0.7972, {'top1': 0.7972}), (52, 0.4096, {'top1': 0.4096}), (53, 0.279, {'top1': 0.279})]
just computed impact of block 42 . accuracy after removing:  0.9138
removed block 42 current accuracy 0.9138 loss from initial  -0.0005999999999999339
since last training loss: -0.0005999999999999339 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.8702, {'top1': 0.8702}), (1, 0.8828, {'top1': 0.8828}), (2, 0.8582, {'top1': 0.8582}), (3, 0.903, {'top1': 0.903}), (4, 0.9064, {'top1': 0.9064}), (5, 0.879, {'top1': 0.879}), (6, 0.9034, {'top1': 0.9034}), (7, 0.8962, {'top1': 0.8962}), (8, 0.8964, {'top1': 0.8964}), (9, 0.8902, {'top1': 0.8902}), (10, 0.8982, {'top1': 0.8982}), (11, 0.8986, {'top1': 0.8986}), (12, 0.8974, {'top1': 0.8974}), (13, 0.896, {'top1': 0.896}), (14, 0.903, {'top1': 0.903}), (15, 0.9064, {'top1': 0.9064}), (16, 0.8934, {'top1': 0.8934}), (17, 0.9012, {'top1': 0.9012}), (18, 0.3692, {'top1': 0.3692}), (19, 0.8754, {'top1': 0.8754}), (20, 0.888, {'top1': 0.888}), (21, 0.896, {'top1': 0.896}), (22, 0.891, {'top1': 0.891}), (23, 0.8982, {'top1': 0.8982}), (24, 0.9056, {'top1': 0.9056}), (25, 0.908, {'top1': 0.908}), (26, 0.9036, {'top1': 0.9036}), (28, 0.9046, {'top1': 0.9046}), (29, 0.9066, {'top1': 0.9066}), (30, 0.9002, {'top1': 0.9002}), (31, 0.9044, {'top1': 0.9044}), (32, 0.908, {'top1': 0.908}), (33, 0.9092, {'top1': 0.9092}), (34, 0.908, {'top1': 0.908}), (35, 0.9084, {'top1': 0.9084}), (36, 0.5526, {'top1': 0.5526}), (37, 0.9094, {'top1': 0.9094}), (38, 0.9074, {'top1': 0.9074}), (45, 0.9096, {'top1': 0.9096}), (46, 0.9082, {'top1': 0.9082}), (50, 0.886, {'top1': 0.886}), (51, 0.7978, {'top1': 0.7978}), (52, 0.4266, {'top1': 0.4266}), (53, 0.2812, {'top1': 0.2812})]
just computed impact of block 45 . accuracy after removing:  0.9096
removed block 45 current accuracy 0.9096 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.8682, {'top1': 0.8682}), (1, 0.8812, {'top1': 0.8812}), (2, 0.8538, {'top1': 0.8538}), (3, 0.9006, {'top1': 0.9006}), (4, 0.9036, {'top1': 0.9036}), (5, 0.876, {'top1': 0.876}), (6, 0.9014, {'top1': 0.9014}), (7, 0.8922, {'top1': 0.8922}), (8, 0.8924, {'top1': 0.8924}), (9, 0.8826, {'top1': 0.8826}), (10, 0.8942, {'top1': 0.8942}), (11, 0.897, {'top1': 0.897}), (12, 0.8944, {'top1': 0.8944}), (13, 0.8932, {'top1': 0.8932}), (14, 0.9002, {'top1': 0.9002}), (15, 0.9008, {'top1': 0.9008}), (16, 0.8926, {'top1': 0.8926}), (17, 0.8958, {'top1': 0.8958}), (18, 0.3574, {'top1': 0.3574}), (19, 0.8716, {'top1': 0.8716}), (20, 0.8808, {'top1': 0.8808}), (21, 0.8958, {'top1': 0.8958}), (22, 0.8934, {'top1': 0.8934}), (23, 0.8988, {'top1': 0.8988}), (24, 0.903, {'top1': 0.903}), (25, 0.9032, {'top1': 0.9032}), (26, 0.9034, {'top1': 0.9034}), (28, 0.9028, {'top1': 0.9028}), (29, 0.9014, {'top1': 0.9014}), (30, 0.896, {'top1': 0.896}), (31, 0.9016, {'top1': 0.9016}), (32, 0.9074, {'top1': 0.9074}), (33, 0.9066, {'top1': 0.9066}), (34, 0.9056, {'top1': 0.9056}), (35, 0.9058, {'top1': 0.9058}), (36, 0.542, {'top1': 0.542}), (37, 0.9084, {'top1': 0.9084}), (38, 0.9056, {'top1': 0.9056}), (46, 0.9016, {'top1': 0.9016}), (50, 0.8848, {'top1': 0.8848}), (51, 0.7924, {'top1': 0.7924}), (52, 0.4172, {'top1': 0.4172}), (53, 0.2788, {'top1': 0.2788})]
just computed impact of block 37 . accuracy after removing:  0.9084
removed block 37 current accuracy 0.9084 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.8616, {'top1': 0.8616}), (1, 0.8776, {'top1': 0.8776}), (2, 0.847, {'top1': 0.847}), (3, 0.8964, {'top1': 0.8964}), (4, 0.8994, {'top1': 0.8994}), (5, 0.8768, {'top1': 0.8768}), (6, 0.897, {'top1': 0.897}), (7, 0.8904, {'top1': 0.8904}), (8, 0.893, {'top1': 0.893}), (9, 0.8854, {'top1': 0.8854}), (10, 0.8932, {'top1': 0.8932}), (11, 0.8978, {'top1': 0.8978}), (12, 0.8938, {'top1': 0.8938}), (13, 0.8944, {'top1': 0.8944}), (14, 0.8984, {'top1': 0.8984}), (15, 0.8984, {'top1': 0.8984}), (16, 0.8902, {'top1': 0.8902}), (17, 0.9006, {'top1': 0.9006}), (18, 0.3764, {'top1': 0.3764}), (19, 0.8744, {'top1': 0.8744}), (20, 0.8806, {'top1': 0.8806}), (21, 0.8918, {'top1': 0.8918}), (22, 0.8824, {'top1': 0.8824}), (23, 0.8948, {'top1': 0.8948}), (24, 0.8988, {'top1': 0.8988}), (25, 0.9022, {'top1': 0.9022}), (26, 0.8968, {'top1': 0.8968}), (28, 0.901, {'top1': 0.901}), (29, 0.9008, {'top1': 0.9008}), (30, 0.8958, {'top1': 0.8958}), (31, 0.8986, {'top1': 0.8986}), (32, 0.9036, {'top1': 0.9036}), (33, 0.9026, {'top1': 0.9026}), (34, 0.9052, {'top1': 0.9052}), (35, 0.903, {'top1': 0.903}), (36, 0.5102, {'top1': 0.5102}), (38, 0.9028, {'top1': 0.9028}), (46, 0.9018, {'top1': 0.9018}), (50, 0.8828, {'top1': 0.8828}), (51, 0.7934, {'top1': 0.7934}), (52, 0.443, {'top1': 0.443}), (53, 0.282, {'top1': 0.282})]
just computed impact of block 34 . accuracy after removing:  0.9052
removed block 34 current accuracy 0.9052 loss from initial  0.008000000000000007
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.86, {'top1': 0.86}), (1, 0.8758, {'top1': 0.8758}), (2, 0.8416, {'top1': 0.8416}), (3, 0.8904, {'top1': 0.8904}), (4, 0.895, {'top1': 0.895}), (5, 0.8736, {'top1': 0.8736}), (6, 0.891, {'top1': 0.891}), (7, 0.8826, {'top1': 0.8826}), (8, 0.8854, {'top1': 0.8854}), (9, 0.8796, {'top1': 0.8796}), (10, 0.8884, {'top1': 0.8884}), (11, 0.8956, {'top1': 0.8956}), (12, 0.8858, {'top1': 0.8858}), (13, 0.8928, {'top1': 0.8928}), (14, 0.8962, {'top1': 0.8962}), (15, 0.897, {'top1': 0.897}), (16, 0.887, {'top1': 0.887}), (17, 0.8958, {'top1': 0.8958}), (18, 0.358, {'top1': 0.358}), (19, 0.869, {'top1': 0.869}), (20, 0.8788, {'top1': 0.8788}), (21, 0.888, {'top1': 0.888}), (22, 0.8752, {'top1': 0.8752}), (23, 0.8902, {'top1': 0.8902}), (24, 0.8946, {'top1': 0.8946}), (25, 0.8974, {'top1': 0.8974}), (26, 0.8924, {'top1': 0.8924}), (28, 0.8954, {'top1': 0.8954}), (29, 0.8982, {'top1': 0.8982}), (30, 0.8878, {'top1': 0.8878}), (31, 0.896, {'top1': 0.896}), (32, 0.9006, {'top1': 0.9006}), (33, 0.8992, {'top1': 0.8992}), (35, 0.8984, {'top1': 0.8984}), (36, 0.481, {'top1': 0.481}), (38, 0.8958, {'top1': 0.8958}), (46, 0.9002, {'top1': 0.9002}), (50, 0.8832, {'top1': 0.8832}), (51, 0.784, {'top1': 0.784}), (52, 0.438, {'top1': 0.438}), (53, 0.2844, {'top1': 0.2844})]
just computed impact of block 32 . accuracy after removing:  0.9006
removed block 32 current accuracy 0.9006 loss from initial  0.012600000000000056
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.856, {'top1': 0.856}), (1, 0.8712, {'top1': 0.8712}), (2, 0.8346, {'top1': 0.8346}), (3, 0.8864, {'top1': 0.8864}), (4, 0.8928, {'top1': 0.8928}), (5, 0.8684, {'top1': 0.8684}), (6, 0.8882, {'top1': 0.8882}), (7, 0.8822, {'top1': 0.8822}), (8, 0.882, {'top1': 0.882}), (9, 0.8766, {'top1': 0.8766}), (10, 0.8876, {'top1': 0.8876}), (11, 0.8918, {'top1': 0.8918}), (12, 0.8842, {'top1': 0.8842}), (13, 0.8932, {'top1': 0.8932}), (14, 0.8928, {'top1': 0.8928}), (15, 0.8956, {'top1': 0.8956}), (16, 0.8846, {'top1': 0.8846}), (17, 0.8956, {'top1': 0.8956}), (18, 0.3552, {'top1': 0.3552}), (19, 0.8678, {'top1': 0.8678}), (20, 0.8758, {'top1': 0.8758}), (21, 0.8816, {'top1': 0.8816}), (22, 0.8712, {'top1': 0.8712}), (23, 0.886, {'top1': 0.886}), (24, 0.8916, {'top1': 0.8916}), (25, 0.8934, {'top1': 0.8934}), (26, 0.889, {'top1': 0.889}), (28, 0.889, {'top1': 0.889}), (29, 0.8934, {'top1': 0.8934}), (30, 0.8824, {'top1': 0.8824}), (31, 0.8934, {'top1': 0.8934}), (33, 0.8962, {'top1': 0.8962}), (35, 0.8956, {'top1': 0.8956}), (36, 0.4432, {'top1': 0.4432}), (38, 0.8954, {'top1': 0.8954}), (46, 0.8966, {'top1': 0.8966}), (50, 0.8798, {'top1': 0.8798}), (51, 0.779, {'top1': 0.779}), (52, 0.425, {'top1': 0.425}), (53, 0.2804, {'top1': 0.2804})]
just computed impact of block 46 . accuracy after removing:  0.8966
removed block 46 current accuracy 0.8966 loss from initial  0.01660000000000006
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.854, {'top1': 0.854}), (1, 0.8706, {'top1': 0.8706}), (2, 0.8308, {'top1': 0.8308}), (3, 0.8852, {'top1': 0.8852}), (4, 0.8896, {'top1': 0.8896}), (5, 0.8658, {'top1': 0.8658}), (6, 0.886, {'top1': 0.886}), (7, 0.8788, {'top1': 0.8788}), (8, 0.8818, {'top1': 0.8818}), (9, 0.8718, {'top1': 0.8718}), (10, 0.884, {'top1': 0.884}), (11, 0.888, {'top1': 0.888}), (12, 0.8826, {'top1': 0.8826}), (13, 0.887, {'top1': 0.887}), (14, 0.8882, {'top1': 0.8882}), (15, 0.8918, {'top1': 0.8918}), (16, 0.8792, {'top1': 0.8792}), (17, 0.8922, {'top1': 0.8922}), (18, 0.3502, {'top1': 0.3502}), (19, 0.8578, {'top1': 0.8578}), (20, 0.8692, {'top1': 0.8692}), (21, 0.8768, {'top1': 0.8768}), (22, 0.869, {'top1': 0.869}), (23, 0.8844, {'top1': 0.8844}), (24, 0.8882, {'top1': 0.8882}), (25, 0.8898, {'top1': 0.8898}), (26, 0.8856, {'top1': 0.8856}), (28, 0.8856, {'top1': 0.8856}), (29, 0.8902, {'top1': 0.8902}), (30, 0.8774, {'top1': 0.8774}), (31, 0.8896, {'top1': 0.8896}), (33, 0.8922, {'top1': 0.8922}), (35, 0.889, {'top1': 0.889}), (36, 0.438, {'top1': 0.438}), (38, 0.891, {'top1': 0.891}), (50, 0.8734, {'top1': 0.8734}), (51, 0.7732, {'top1': 0.7732}), (52, 0.4248, {'top1': 0.4248}), (53, 0.2724, {'top1': 0.2724})]
just computed impact of block 17 . accuracy after removing:  0.8922
removed block 17 current accuracy 0.8922 loss from initial  0.02100000000000002
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.8482, {'top1': 0.8482}), (1, 0.8608, {'top1': 0.8608}), (2, 0.8236, {'top1': 0.8236}), (3, 0.8844, {'top1': 0.8844}), (4, 0.8834, {'top1': 0.8834}), (5, 0.864, {'top1': 0.864}), (6, 0.8804, {'top1': 0.8804}), (7, 0.8684, {'top1': 0.8684}), (8, 0.876, {'top1': 0.876}), (9, 0.848, {'top1': 0.848}), (10, 0.862, {'top1': 0.862}), (11, 0.8636, {'top1': 0.8636}), (12, 0.874, {'top1': 0.874}), (13, 0.8544, {'top1': 0.8544}), (14, 0.8662, {'top1': 0.8662}), (15, 0.876, {'top1': 0.876}), (16, 0.8556, {'top1': 0.8556}), (18, 0.3324, {'top1': 0.3324}), (19, 0.8418, {'top1': 0.8418}), (20, 0.8668, {'top1': 0.8668}), (21, 0.8744, {'top1': 0.8744}), (22, 0.8616, {'top1': 0.8616}), (23, 0.875, {'top1': 0.875}), (24, 0.8812, {'top1': 0.8812}), (25, 0.88, {'top1': 0.88}), (26, 0.8822, {'top1': 0.8822}), (28, 0.8864, {'top1': 0.8864}), (29, 0.8836, {'top1': 0.8836}), (30, 0.8712, {'top1': 0.8712}), (31, 0.887, {'top1': 0.887}), (33, 0.8912, {'top1': 0.8912}), (35, 0.8862, {'top1': 0.8862}), (36, 0.4652, {'top1': 0.4652}), (38, 0.8862, {'top1': 0.8862}), (50, 0.8736, {'top1': 0.8736}), (51, 0.7834, {'top1': 0.7834}), (52, 0.419, {'top1': 0.419}), (53, 0.2598, {'top1': 0.2598})]
just computed impact of block 33 . accuracy after removing:  0.8912
removed block 33 current accuracy 0.8912 loss from initial  0.02200000000000002
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.841, {'top1': 0.841}), (1, 0.857, {'top1': 0.857}), (2, 0.818, {'top1': 0.818}), (3, 0.8776, {'top1': 0.8776}), (4, 0.883, {'top1': 0.883}), (5, 0.8606, {'top1': 0.8606}), (6, 0.877, {'top1': 0.877}), (7, 0.8642, {'top1': 0.8642}), (8, 0.8696, {'top1': 0.8696}), (9, 0.8482, {'top1': 0.8482}), (10, 0.8604, {'top1': 0.8604}), (11, 0.8626, {'top1': 0.8626}), (12, 0.867, {'top1': 0.867}), (13, 0.8532, {'top1': 0.8532}), (14, 0.8652, {'top1': 0.8652}), (15, 0.8738, {'top1': 0.8738}), (16, 0.8558, {'top1': 0.8558}), (18, 0.3324, {'top1': 0.3324}), (19, 0.844, {'top1': 0.844}), (20, 0.866, {'top1': 0.866}), (21, 0.8696, {'top1': 0.8696}), (22, 0.8532, {'top1': 0.8532}), (23, 0.8698, {'top1': 0.8698}), (24, 0.8804, {'top1': 0.8804}), (25, 0.8778, {'top1': 0.8778}), (26, 0.877, {'top1': 0.877}), (28, 0.88, {'top1': 0.88}), (29, 0.8792, {'top1': 0.8792}), (30, 0.867, {'top1': 0.867}), (31, 0.8816, {'top1': 0.8816}), (35, 0.8854, {'top1': 0.8854}), (36, 0.43, {'top1': 0.43}), (38, 0.8868, {'top1': 0.8868}), (50, 0.8714, {'top1': 0.8714}), (51, 0.778, {'top1': 0.778}), (52, 0.414, {'top1': 0.414}), (53, 0.2562, {'top1': 0.2562})]
just computed impact of block 38 . accuracy after removing:  0.8868
removed block 38 current accuracy 0.8868 loss from initial  0.02639999999999998
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.8318, {'top1': 0.8318}), (1, 0.8526, {'top1': 0.8526}), (2, 0.8118, {'top1': 0.8118}), (3, 0.8722, {'top1': 0.8722}), (4, 0.8774, {'top1': 0.8774}), (5, 0.86, {'top1': 0.86}), (6, 0.8724, {'top1': 0.8724}), (7, 0.862, {'top1': 0.862}), (8, 0.867, {'top1': 0.867}), (9, 0.8418, {'top1': 0.8418}), (10, 0.8534, {'top1': 0.8534}), (11, 0.8586, {'top1': 0.8586}), (12, 0.8646, {'top1': 0.8646}), (13, 0.8494, {'top1': 0.8494}), (14, 0.859, {'top1': 0.859}), (15, 0.8702, {'top1': 0.8702}), (16, 0.8492, {'top1': 0.8492}), (18, 0.3266, {'top1': 0.3266}), (19, 0.8364, {'top1': 0.8364}), (20, 0.8642, {'top1': 0.8642}), (21, 0.863, {'top1': 0.863}), (22, 0.845, {'top1': 0.845}), (23, 0.864, {'top1': 0.864}), (24, 0.8734, {'top1': 0.8734}), (25, 0.8728, {'top1': 0.8728}), (26, 0.8704, {'top1': 0.8704}), (28, 0.874, {'top1': 0.874}), (29, 0.874, {'top1': 0.874}), (30, 0.8642, {'top1': 0.8642}), (31, 0.876, {'top1': 0.876}), (35, 0.8786, {'top1': 0.8786}), (36, 0.4252, {'top1': 0.4252}), (50, 0.8642, {'top1': 0.8642}), (51, 0.7736, {'top1': 0.7736}), (52, 0.4242, {'top1': 0.4242}), (53, 0.2616, {'top1': 0.2616})]
just computed impact of block 35 . accuracy after removing:  0.8786
removed block 35 current accuracy 0.8786 loss from initial  0.034599999999999964
since last training loss: 0.034599999999999964 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.8268, {'top1': 0.8268}), (1, 0.8424, {'top1': 0.8424}), (2, 0.799, {'top1': 0.799}), (3, 0.865, {'top1': 0.865}), (4, 0.8676, {'top1': 0.8676}), (5, 0.8526, {'top1': 0.8526}), (6, 0.8644, {'top1': 0.8644}), (7, 0.8556, {'top1': 0.8556}), (8, 0.8634, {'top1': 0.8634}), (9, 0.829, {'top1': 0.829}), (10, 0.8442, {'top1': 0.8442}), (11, 0.8528, {'top1': 0.8528}), (12, 0.859, {'top1': 0.859}), (13, 0.8408, {'top1': 0.8408}), (14, 0.8494, {'top1': 0.8494}), (15, 0.8622, {'top1': 0.8622}), (16, 0.8388, {'top1': 0.8388}), (18, 0.31, {'top1': 0.31}), (19, 0.83, {'top1': 0.83}), (20, 0.8578, {'top1': 0.8578}), (21, 0.8542, {'top1': 0.8542}), (22, 0.8344, {'top1': 0.8344}), (23, 0.8548, {'top1': 0.8548}), (24, 0.8682, {'top1': 0.8682}), (25, 0.8664, {'top1': 0.8664}), (26, 0.8602, {'top1': 0.8602}), (28, 0.866, {'top1': 0.866}), (29, 0.8658, {'top1': 0.8658}), (30, 0.853, {'top1': 0.853}), (31, 0.8676, {'top1': 0.8676}), (36, 0.3966, {'top1': 0.3966}), (50, 0.8546, {'top1': 0.8546}), (51, 0.7646, {'top1': 0.7646}), (52, 0.4136, {'top1': 0.4136}), (53, 0.252, {'top1': 0.252})]
just computed impact of block 24 . accuracy after removing:  0.8682
removed block 24 current accuracy 0.8682 loss from initial  0.04500000000000004
since last training loss: 0.04500000000000004 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.8102, {'top1': 0.8102}), (1, 0.8254, {'top1': 0.8254}), (2, 0.7902, {'top1': 0.7902}), (3, 0.85, {'top1': 0.85}), (4, 0.8558, {'top1': 0.8558}), (5, 0.8354, {'top1': 0.8354}), (6, 0.8474, {'top1': 0.8474}), (7, 0.8408, {'top1': 0.8408}), (8, 0.8438, {'top1': 0.8438}), (9, 0.8148, {'top1': 0.8148}), (10, 0.8302, {'top1': 0.8302}), (11, 0.843, {'top1': 0.843}), (12, 0.84, {'top1': 0.84}), (13, 0.8318, {'top1': 0.8318}), (14, 0.84, {'top1': 0.84}), (15, 0.8492, {'top1': 0.8492}), (16, 0.8244, {'top1': 0.8244}), (18, 0.277, {'top1': 0.277}), (19, 0.8072, {'top1': 0.8072}), (20, 0.8414, {'top1': 0.8414}), (21, 0.8364, {'top1': 0.8364}), (22, 0.8062, {'top1': 0.8062}), (23, 0.8384, {'top1': 0.8384}), (25, 0.8492, {'top1': 0.8492}), (26, 0.8432, {'top1': 0.8432}), (28, 0.85, {'top1': 0.85}), (29, 0.8496, {'top1': 0.8496}), (30, 0.8362, {'top1': 0.8362}), (31, 0.8524, {'top1': 0.8524}), (36, 0.3596, {'top1': 0.3596}), (50, 0.8402, {'top1': 0.8402}), (51, 0.7456, {'top1': 0.7456}), (52, 0.4108, {'top1': 0.4108}), (53, 0.2534, {'top1': 0.2534})]
just computed impact of block 4 . accuracy after removing:  0.8558
removed block 4 current accuracy 0.8558 loss from initial  0.05740000000000001
since last training loss: 0.05740000000000001 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.7872, {'top1': 0.7872}), (1, 0.8038, {'top1': 0.8038}), (2, 0.7666, {'top1': 0.7666}), (3, 0.8344, {'top1': 0.8344}), (5, 0.811, {'top1': 0.811}), (6, 0.8282, {'top1': 0.8282}), (7, 0.8224, {'top1': 0.8224}), (8, 0.8266, {'top1': 0.8266}), (9, 0.7904, {'top1': 0.7904}), (10, 0.812, {'top1': 0.812}), (11, 0.8298, {'top1': 0.8298}), (12, 0.8298, {'top1': 0.8298}), (13, 0.8206, {'top1': 0.8206}), (14, 0.8286, {'top1': 0.8286}), (15, 0.8412, {'top1': 0.8412}), (16, 0.8174, {'top1': 0.8174}), (18, 0.2682, {'top1': 0.2682}), (19, 0.793, {'top1': 0.793}), (20, 0.8332, {'top1': 0.8332}), (21, 0.8256, {'top1': 0.8256}), (22, 0.7942, {'top1': 0.7942}), (23, 0.8274, {'top1': 0.8274}), (25, 0.8372, {'top1': 0.8372}), (26, 0.8282, {'top1': 0.8282}), (28, 0.836, {'top1': 0.836}), (29, 0.8362, {'top1': 0.8362}), (30, 0.8232, {'top1': 0.8232}), (31, 0.8404, {'top1': 0.8404}), (36, 0.3474, {'top1': 0.3474}), (50, 0.8328, {'top1': 0.8328}), (51, 0.729, {'top1': 0.729}), (52, 0.423, {'top1': 0.423}), (53, 0.2582, {'top1': 0.2582})]
just computed impact of block 15 . accuracy after removing:  0.8412
removed block 15 current accuracy 0.8412 loss from initial  0.07200000000000006
since last training loss: 0.07200000000000006 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7692, {'top1': 0.7692}), (1, 0.7932, {'top1': 0.7932}), (2, 0.7522, {'top1': 0.7522}), (3, 0.82, {'top1': 0.82}), (5, 0.8094, {'top1': 0.8094}), (6, 0.82, {'top1': 0.82}), (7, 0.804, {'top1': 0.804}), (8, 0.8072, {'top1': 0.8072}), (9, 0.7714, {'top1': 0.7714}), (10, 0.7974, {'top1': 0.7974}), (11, 0.8022, {'top1': 0.8022}), (12, 0.8048, {'top1': 0.8048}), (13, 0.7898, {'top1': 0.7898}), (14, 0.795, {'top1': 0.795}), (16, 0.7544, {'top1': 0.7544}), (18, 0.2546, {'top1': 0.2546}), (19, 0.7832, {'top1': 0.7832}), (20, 0.8276, {'top1': 0.8276}), (21, 0.8126, {'top1': 0.8126}), (22, 0.7708, {'top1': 0.7708}), (23, 0.814, {'top1': 0.814}), (25, 0.8266, {'top1': 0.8266}), (26, 0.8154, {'top1': 0.8154}), (28, 0.8238, {'top1': 0.8238}), (29, 0.8236, {'top1': 0.8236}), (30, 0.8112, {'top1': 0.8112}), (31, 0.826, {'top1': 0.826}), (36, 0.3386, {'top1': 0.3386}), (50, 0.821, {'top1': 0.821}), (51, 0.729, {'top1': 0.729}), (52, 0.4378, {'top1': 0.4378}), (53, 0.2442, {'top1': 0.2442})]
just computed impact of block 20 . accuracy after removing:  0.8276
removed block 20 current accuracy 0.8276 loss from initial  0.08560000000000001
since last training loss: 0.08560000000000001 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7606, {'top1': 0.7606}), (1, 0.776, {'top1': 0.776}), (2, 0.743, {'top1': 0.743}), (3, 0.8116, {'top1': 0.8116}), (5, 0.7864, {'top1': 0.7864}), (6, 0.8116, {'top1': 0.8116}), (7, 0.8022, {'top1': 0.8022}), (8, 0.7956, {'top1': 0.7956}), (9, 0.7688, {'top1': 0.7688}), (10, 0.7892, {'top1': 0.7892}), (11, 0.7904, {'top1': 0.7904}), (12, 0.8018, {'top1': 0.8018}), (13, 0.7744, {'top1': 0.7744}), (14, 0.7894, {'top1': 0.7894}), (16, 0.7308, {'top1': 0.7308}), (18, 0.3278, {'top1': 0.3278}), (19, 0.7578, {'top1': 0.7578}), (21, 0.7902, {'top1': 0.7902}), (22, 0.7604, {'top1': 0.7604}), (23, 0.8088, {'top1': 0.8088}), (25, 0.8032, {'top1': 0.8032}), (26, 0.8098, {'top1': 0.8098}), (28, 0.813, {'top1': 0.813}), (29, 0.8168, {'top1': 0.8168}), (30, 0.7954, {'top1': 0.7954}), (31, 0.8198, {'top1': 0.8198}), (36, 0.3434, {'top1': 0.3434}), (50, 0.7862, {'top1': 0.7862}), (51, 0.6936, {'top1': 0.6936}), (52, 0.389, {'top1': 0.389}), (53, 0.2382, {'top1': 0.2382})]
just computed impact of block 31 . accuracy after removing:  0.8198
removed block 31 current accuracy 0.8198 loss from initial  0.09340000000000004
since last training loss: 0.09340000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7422, {'top1': 0.7422}), (1, 0.7622, {'top1': 0.7622}), (2, 0.7104, {'top1': 0.7104}), (3, 0.7868, {'top1': 0.7868}), (5, 0.7614, {'top1': 0.7614}), (6, 0.7904, {'top1': 0.7904}), (7, 0.781, {'top1': 0.781}), (8, 0.7736, {'top1': 0.7736}), (9, 0.7582, {'top1': 0.7582}), (10, 0.7742, {'top1': 0.7742}), (11, 0.7848, {'top1': 0.7848}), (12, 0.7792, {'top1': 0.7792}), (13, 0.768, {'top1': 0.768}), (14, 0.7812, {'top1': 0.7812}), (16, 0.7222, {'top1': 0.7222}), (18, 0.289, {'top1': 0.289}), (19, 0.7474, {'top1': 0.7474}), (21, 0.7684, {'top1': 0.7684}), (22, 0.733, {'top1': 0.733}), (23, 0.7906, {'top1': 0.7906}), (25, 0.789, {'top1': 0.789}), (26, 0.7848, {'top1': 0.7848}), (28, 0.7922, {'top1': 0.7922}), (29, 0.7878, {'top1': 0.7878}), (30, 0.769, {'top1': 0.769}), (36, 0.3086, {'top1': 0.3086}), (50, 0.7714, {'top1': 0.7714}), (51, 0.6748, {'top1': 0.6748}), (52, 0.382, {'top1': 0.382}), (53, 0.2346, {'top1': 0.2346})]
just computed impact of block 28 . accuracy after removing:  0.7922
removed block 28 current accuracy 0.7922 loss from initial  0.121
since last training loss: 0.121 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.715, {'top1': 0.715}), (1, 0.73, {'top1': 0.73}), (2, 0.6594, {'top1': 0.6594}), (3, 0.748, {'top1': 0.748}), (5, 0.7176, {'top1': 0.7176}), (6, 0.7512, {'top1': 0.7512}), (7, 0.7346, {'top1': 0.7346}), (8, 0.732, {'top1': 0.732}), (9, 0.728, {'top1': 0.728}), (10, 0.7362, {'top1': 0.7362}), (11, 0.758, {'top1': 0.758}), (12, 0.7374, {'top1': 0.7374}), (13, 0.744, {'top1': 0.744}), (14, 0.7554, {'top1': 0.7554}), (16, 0.7002, {'top1': 0.7002}), (18, 0.2538, {'top1': 0.2538}), (19, 0.7098, {'top1': 0.7098}), (21, 0.7272, {'top1': 0.7272}), (22, 0.689, {'top1': 0.689}), (23, 0.75, {'top1': 0.75}), (25, 0.7556, {'top1': 0.7556}), (26, 0.7414, {'top1': 0.7414}), (29, 0.7512, {'top1': 0.7512}), (30, 0.7236, {'top1': 0.7236}), (36, 0.2606, {'top1': 0.2606}), (50, 0.7342, {'top1': 0.7342}), (51, 0.6488, {'top1': 0.6488}), (52, 0.387, {'top1': 0.387}), (53, 0.2288, {'top1': 0.2288})]
just computed impact of block 11 . accuracy after removing:  0.758
removed block 11 current accuracy 0.758 loss from initial  0.1552
since last training loss: 0.1552 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.68, {'top1': 0.68}), (1, 0.6942, {'top1': 0.6942}), (2, 0.6344, {'top1': 0.6344}), (3, 0.7218, {'top1': 0.7218}), (5, 0.71, {'top1': 0.71}), (6, 0.7212, {'top1': 0.7212}), (7, 0.7114, {'top1': 0.7114}), (8, 0.702, {'top1': 0.702}), (9, 0.6682, {'top1': 0.6682}), (10, 0.6974, {'top1': 0.6974}), (12, 0.7058, {'top1': 0.7058}), (13, 0.6666, {'top1': 0.6666}), (14, 0.7024, {'top1': 0.7024}), (16, 0.6272, {'top1': 0.6272}), (18, 0.241, {'top1': 0.241}), (19, 0.6824, {'top1': 0.6824}), (21, 0.7014, {'top1': 0.7014}), (22, 0.654, {'top1': 0.654}), (23, 0.7234, {'top1': 0.7234}), (25, 0.724, {'top1': 0.724}), (26, 0.7144, {'top1': 0.7144}), (29, 0.7254, {'top1': 0.7254}), (30, 0.7032, {'top1': 0.7032}), (36, 0.2566, {'top1': 0.2566}), (50, 0.7072, {'top1': 0.7072}), (51, 0.6378, {'top1': 0.6378}), (52, 0.3834, {'top1': 0.3834}), (53, 0.211, {'top1': 0.211})]
just computed impact of block 29 . accuracy after removing:  0.7254
removed block 29 current accuracy 0.7254 loss from initial  0.18779999999999997
since last training loss: 0.18779999999999997 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.6368, {'top1': 0.6368}), (1, 0.6598, {'top1': 0.6598}), (2, 0.5598, {'top1': 0.5598}), (3, 0.6748, {'top1': 0.6748}), (5, 0.6614, {'top1': 0.6614}), (6, 0.673, {'top1': 0.673}), (7, 0.6728, {'top1': 0.6728}), (8, 0.6646, {'top1': 0.6646}), (9, 0.6314, {'top1': 0.6314}), (10, 0.6526, {'top1': 0.6526}), (12, 0.6558, {'top1': 0.6558}), (13, 0.6466, {'top1': 0.6466}), (14, 0.677, {'top1': 0.677}), (16, 0.6094, {'top1': 0.6094}), (18, 0.2062, {'top1': 0.2062}), (19, 0.635, {'top1': 0.635}), (21, 0.6506, {'top1': 0.6506}), (22, 0.5924, {'top1': 0.5924}), (23, 0.6878, {'top1': 0.6878}), (25, 0.6828, {'top1': 0.6828}), (26, 0.6546, {'top1': 0.6546}), (30, 0.631, {'top1': 0.631}), (36, 0.2324, {'top1': 0.2324}), (50, 0.656, {'top1': 0.656}), (51, 0.6214, {'top1': 0.6214}), (52, 0.3704, {'top1': 0.3704}), (53, 0.197, {'top1': 0.197})]
just computed impact of block 23 . accuracy after removing:  0.6878
removed block 23 current accuracy 0.6878 loss from initial  0.22540000000000004
since last training loss: 0.22540000000000004 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.5812, {'top1': 0.5812}), (1, 0.611, {'top1': 0.611}), (2, 0.5126, {'top1': 0.5126}), (3, 0.6234, {'top1': 0.6234}), (5, 0.6132, {'top1': 0.6132}), (6, 0.6208, {'top1': 0.6208}), (7, 0.6316, {'top1': 0.6316}), (8, 0.6232, {'top1': 0.6232}), (9, 0.584, {'top1': 0.584}), (10, 0.6106, {'top1': 0.6106}), (12, 0.6148, {'top1': 0.6148}), (13, 0.6036, {'top1': 0.6036}), (14, 0.6428, {'top1': 0.6428}), (16, 0.585, {'top1': 0.585}), (18, 0.2042, {'top1': 0.2042}), (19, 0.5788, {'top1': 0.5788}), (21, 0.5884, {'top1': 0.5884}), (22, 0.5124, {'top1': 0.5124}), (25, 0.6336, {'top1': 0.6336}), (26, 0.598, {'top1': 0.598}), (30, 0.5872, {'top1': 0.5872}), (36, 0.1568, {'top1': 0.1568}), (50, 0.6094, {'top1': 0.6094}), (51, 0.6022, {'top1': 0.6022}), (52, 0.3512, {'top1': 0.3512}), (53, 0.1798, {'top1': 0.1798})]
just computed impact of block 14 . accuracy after removing:  0.6428
removed block 14 current accuracy 0.6428 loss from initial  0.2704
since last training loss: 0.2704 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.5416, {'top1': 0.5416}), (1, 0.5648, {'top1': 0.5648}), (2, 0.4822, {'top1': 0.4822}), (3, 0.5824, {'top1': 0.5824}), (5, 0.5822, {'top1': 0.5822}), (6, 0.5812, {'top1': 0.5812}), (7, 0.5858, {'top1': 0.5858}), (8, 0.573, {'top1': 0.573}), (9, 0.5308, {'top1': 0.5308}), (10, 0.569, {'top1': 0.569}), (12, 0.5734, {'top1': 0.5734}), (13, 0.5286, {'top1': 0.5286}), (16, 0.5038, {'top1': 0.5038}), (18, 0.2096, {'top1': 0.2096}), (19, 0.5384, {'top1': 0.5384}), (21, 0.5458, {'top1': 0.5458}), (22, 0.477, {'top1': 0.477}), (25, 0.6006, {'top1': 0.6006}), (26, 0.5496, {'top1': 0.5496}), (30, 0.5508, {'top1': 0.5508}), (36, 0.1446, {'top1': 0.1446}), (50, 0.573, {'top1': 0.573}), (51, 0.5714, {'top1': 0.5714}), (52, 0.3378, {'top1': 0.3378}), (53, 0.1666, {'top1': 0.1666})]
just computed impact of block 25 . accuracy after removing:  0.6006
removed block 25 current accuracy 0.6006 loss from initial  0.3126
since last training loss: 0.3126 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.515, {'top1': 0.515}), (1, 0.535, {'top1': 0.535}), (2, 0.4428, {'top1': 0.4428}), (3, 0.54, {'top1': 0.54}), (5, 0.5244, {'top1': 0.5244}), (6, 0.54, {'top1': 0.54}), (7, 0.5356, {'top1': 0.5356}), (8, 0.527, {'top1': 0.527}), (9, 0.4984, {'top1': 0.4984}), (10, 0.5234, {'top1': 0.5234}), (12, 0.5306, {'top1': 0.5306}), (13, 0.5074, {'top1': 0.5074}), (16, 0.4842, {'top1': 0.4842}), (18, 0.2078, {'top1': 0.2078}), (19, 0.5024, {'top1': 0.5024}), (21, 0.5038, {'top1': 0.5038}), (22, 0.4374, {'top1': 0.4374}), (26, 0.5042, {'top1': 0.5042}), (30, 0.4812, {'top1': 0.4812}), (36, 0.1236, {'top1': 0.1236}), (50, 0.5154, {'top1': 0.5154}), (51, 0.541, {'top1': 0.541}), (52, 0.331, {'top1': 0.331}), (53, 0.1596, {'top1': 0.1596})]
just computed impact of block 51 . accuracy after removing:  0.541
removed block 51 current accuracy 0.541 loss from initial  0.3722
since last training loss: 0.3722 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.4764, {'top1': 0.4764}), (1, 0.4844, {'top1': 0.4844}), (2, 0.424, {'top1': 0.424}), (3, 0.5018, {'top1': 0.5018}), (5, 0.507, {'top1': 0.507}), (6, 0.495, {'top1': 0.495}), (7, 0.5082, {'top1': 0.5082}), (8, 0.5002, {'top1': 0.5002}), (9, 0.4494, {'top1': 0.4494}), (10, 0.4868, {'top1': 0.4868}), (12, 0.4888, {'top1': 0.4888}), (13, 0.4786, {'top1': 0.4786}), (16, 0.44, {'top1': 0.44}), (18, 0.2072, {'top1': 0.2072}), (19, 0.4848, {'top1': 0.4848}), (21, 0.4772, {'top1': 0.4772}), (22, 0.4112, {'top1': 0.4112}), (26, 0.4764, {'top1': 0.4764}), (30, 0.4652, {'top1': 0.4652}), (36, 0.1412, {'top1': 0.1412}), (50, 0.4792, {'top1': 0.4792}), (52, 0.2424, {'top1': 0.2424}), (53, 0.179, {'top1': 0.179})]
just computed impact of block 7 . accuracy after removing:  0.5082
removed block 7 current accuracy 0.5082 loss from initial  0.405
since last training loss: 0.405 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.4028, {'top1': 0.4028}), (1, 0.4252, {'top1': 0.4252}), (2, 0.3848, {'top1': 0.3848}), (3, 0.4684, {'top1': 0.4684}), (5, 0.4174, {'top1': 0.4174}), (6, 0.4444, {'top1': 0.4444}), (8, 0.4284, {'top1': 0.4284}), (9, 0.3816, {'top1': 0.3816}), (10, 0.4544, {'top1': 0.4544}), (12, 0.4362, {'top1': 0.4362}), (13, 0.4282, {'top1': 0.4282}), (16, 0.395, {'top1': 0.395}), (18, 0.1938, {'top1': 0.1938}), (19, 0.4292, {'top1': 0.4292}), (21, 0.4302, {'top1': 0.4302}), (22, 0.3562, {'top1': 0.3562}), (26, 0.4376, {'top1': 0.4376}), (30, 0.4324, {'top1': 0.4324}), (36, 0.122, {'top1': 0.122}), (50, 0.44, {'top1': 0.44}), (52, 0.211, {'top1': 0.211}), (53, 0.1744, {'top1': 0.1744})]
just computed impact of block 3 . accuracy after removing:  0.4684
removed block 3 current accuracy 0.4684 loss from initial  0.44480000000000003
since last training loss: 0.44480000000000003 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.3538, {'top1': 0.3538}), (1, 0.3816, {'top1': 0.3816}), (2, 0.3314, {'top1': 0.3314}), (5, 0.3668, {'top1': 0.3668}), (6, 0.3886, {'top1': 0.3886}), (8, 0.3788, {'top1': 0.3788}), (9, 0.3476, {'top1': 0.3476}), (10, 0.41, {'top1': 0.41}), (12, 0.3806, {'top1': 0.3806}), (13, 0.4038, {'top1': 0.4038}), (16, 0.3662, {'top1': 0.3662}), (18, 0.1866, {'top1': 0.1866}), (19, 0.3874, {'top1': 0.3874}), (21, 0.3748, {'top1': 0.3748}), (22, 0.3128, {'top1': 0.3128}), (26, 0.3832, {'top1': 0.3832}), (30, 0.3974, {'top1': 0.3974}), (36, 0.1144, {'top1': 0.1144}), (50, 0.3978, {'top1': 0.3978}), (52, 0.212, {'top1': 0.212}), (53, 0.1724, {'top1': 0.1724})]
just computed impact of block 10 . accuracy after removing:  0.41
removed block 10 current accuracy 0.41 loss from initial  0.5032000000000001
since last training loss: 0.5032000000000001 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.2992, {'top1': 0.2992}), (1, 0.3282, {'top1': 0.3282}), (2, 0.2834, {'top1': 0.2834}), (5, 0.318, {'top1': 0.318}), (6, 0.337, {'top1': 0.337}), (8, 0.3232, {'top1': 0.3232}), (9, 0.2858, {'top1': 0.2858}), (12, 0.3298, {'top1': 0.3298}), (13, 0.3252, {'top1': 0.3252}), (16, 0.32, {'top1': 0.32}), (18, 0.1914, {'top1': 0.1914}), (19, 0.3392, {'top1': 0.3392}), (21, 0.3228, {'top1': 0.3228}), (22, 0.261, {'top1': 0.261}), (26, 0.3366, {'top1': 0.3366}), (30, 0.3546, {'top1': 0.3546}), (36, 0.1074, {'top1': 0.1074}), (50, 0.3568, {'top1': 0.3568}), (52, 0.2034, {'top1': 0.2034}), (53, 0.1778, {'top1': 0.1778})]
just computed impact of block 50 . accuracy after removing:  0.3568
removed block 50 current accuracy 0.3568 loss from initial  0.5564
since last training loss: 0.5564 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.264, {'top1': 0.264}), (1, 0.2936, {'top1': 0.2936}), (2, 0.2346, {'top1': 0.2346}), (5, 0.2776, {'top1': 0.2776}), (6, 0.2932, {'top1': 0.2932}), (8, 0.2854, {'top1': 0.2854}), (9, 0.2674, {'top1': 0.2674}), (12, 0.2912, {'top1': 0.2912}), (13, 0.2986, {'top1': 0.2986}), (16, 0.2934, {'top1': 0.2934}), (18, 0.1338, {'top1': 0.1338}), (19, 0.2904, {'top1': 0.2904}), (21, 0.2782, {'top1': 0.2782}), (22, 0.2344, {'top1': 0.2344}), (26, 0.2854, {'top1': 0.2854}), (30, 0.2922, {'top1': 0.2922}), (36, 0.1418, {'top1': 0.1418}), (52, 0.201, {'top1': 0.201}), (53, 0.138, {'top1': 0.138})]
just computed impact of block 13 . accuracy after removing:  0.2986
removed block 13 current accuracy 0.2986 loss from initial  0.6146
since last training loss: 0.6146 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.2274, {'top1': 0.2274}), (1, 0.2432, {'top1': 0.2432}), (2, 0.1988, {'top1': 0.1988}), (5, 0.2564, {'top1': 0.2564}), (6, 0.2434, {'top1': 0.2434}), (8, 0.2506, {'top1': 0.2506}), (9, 0.2356, {'top1': 0.2356}), (12, 0.2518, {'top1': 0.2518}), (16, 0.241, {'top1': 0.241}), (18, 0.1912, {'top1': 0.1912}), (19, 0.268, {'top1': 0.268}), (21, 0.2444, {'top1': 0.2444}), (22, 0.2076, {'top1': 0.2076}), (26, 0.2548, {'top1': 0.2548}), (30, 0.25, {'top1': 0.25}), (36, 0.123, {'top1': 0.123}), (52, 0.153, {'top1': 0.153}), (53, 0.1388, {'top1': 0.1388})]
just computed impact of block 19 . accuracy after removing:  0.268
removed block 19 current accuracy 0.268 loss from initial  0.6452
since last training loss: 0.6452 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.2032, {'top1': 0.2032}), (1, 0.2196, {'top1': 0.2196}), (2, 0.175, {'top1': 0.175}), (5, 0.216, {'top1': 0.216}), (6, 0.2174, {'top1': 0.2174}), (8, 0.2172, {'top1': 0.2172}), (9, 0.2246, {'top1': 0.2246}), (12, 0.2152, {'top1': 0.2152}), (16, 0.216, {'top1': 0.216}), (18, 0.1544, {'top1': 0.1544}), (21, 0.2032, {'top1': 0.2032}), (22, 0.1684, {'top1': 0.1684}), (26, 0.215, {'top1': 0.215}), (30, 0.2102, {'top1': 0.2102}), (36, 0.1222, {'top1': 0.1222}), (52, 0.1522, {'top1': 0.1522}), (53, 0.1254, {'top1': 0.1254})]
just computed impact of block 9 . accuracy after removing:  0.2246
removed block 9 current accuracy 0.2246 loss from initial  0.6886
since last training loss: 0.6886 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.1926, {'top1': 0.1926}), (1, 0.1906, {'top1': 0.1906}), (2, 0.1548, {'top1': 0.1548}), (5, 0.1962, {'top1': 0.1962}), (6, 0.195, {'top1': 0.195}), (8, 0.212, {'top1': 0.212}), (12, 0.1998, {'top1': 0.1998}), (16, 0.1966, {'top1': 0.1966}), (18, 0.182, {'top1': 0.182}), (21, 0.1674, {'top1': 0.1674}), (22, 0.148, {'top1': 0.148}), (26, 0.1786, {'top1': 0.1786}), (30, 0.1804, {'top1': 0.1804}), (36, 0.1084, {'top1': 0.1084}), (52, 0.1248, {'top1': 0.1248}), (53, 0.1396, {'top1': 0.1396})]
just computed impact of block 8 . accuracy after removing:  0.212
removed block 8 current accuracy 0.212 loss from initial  0.7012
since last training loss: 0.7012 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.1948, {'top1': 0.1948}), (1, 0.1806, {'top1': 0.1806}), (2, 0.1488, {'top1': 0.1488}), (5, 0.1934, {'top1': 0.1934}), (6, 0.1844, {'top1': 0.1844}), (12, 0.1834, {'top1': 0.1834}), (16, 0.1884, {'top1': 0.1884}), (18, 0.2, {'top1': 0.2}), (21, 0.1526, {'top1': 0.1526}), (22, 0.139, {'top1': 0.139}), (26, 0.1572, {'top1': 0.1572}), (30, 0.1748, {'top1': 0.1748}), (36, 0.1034, {'top1': 0.1034}), (52, 0.1204, {'top1': 0.1204}), (53, 0.1256, {'top1': 0.1256})]
just computed impact of block 18 . accuracy after removing:  0.2
removed block 18 current accuracy 0.2 loss from initial  0.7132000000000001
since last training loss: 0.7132000000000001 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.1776, {'top1': 0.1776}), (1, 0.2034, {'top1': 0.2034}), (2, 0.1638, {'top1': 0.1638}), (5, 0.1954, {'top1': 0.1954}), (6, 0.1904, {'top1': 0.1904}), (12, 0.1796, {'top1': 0.1796}), (16, 0.1886, {'top1': 0.1886}), (21, 0.1406, {'top1': 0.1406}), (22, 0.1044, {'top1': 0.1044}), (26, 0.1524, {'top1': 0.1524}), (30, 0.1388, {'top1': 0.1388}), (36, 0.1016, {'top1': 0.1016}), (52, 0.106, {'top1': 0.106}), (53, 0.1056, {'top1': 0.1056})]
just computed impact of block 1 . accuracy after removing:  0.2034
removed block 1 current accuracy 0.2034 loss from initial  0.7098
since last training loss: 0.7098 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.1592, {'top1': 0.1592}), (2, 0.1696, {'top1': 0.1696}), (5, 0.194, {'top1': 0.194}), (6, 0.1992, {'top1': 0.1992}), (12, 0.2006, {'top1': 0.2006}), (16, 0.1764, {'top1': 0.1764}), (21, 0.1424, {'top1': 0.1424}), (22, 0.1152, {'top1': 0.1152}), (26, 0.1652, {'top1': 0.1652}), (30, 0.1512, {'top1': 0.1512}), (36, 0.109, {'top1': 0.109}), (52, 0.1102, {'top1': 0.1102}), (53, 0.1144, {'top1': 0.1144})]
just computed impact of block 12 . accuracy after removing:  0.2006
removed block 12 current accuracy 0.2006 loss from initial  0.7126
since last training loss: 0.7126 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(0, 0.1594, {'top1': 0.1594}), (2, 0.1568, {'top1': 0.1568}), (5, 0.1914, {'top1': 0.1914}), (6, 0.1896, {'top1': 0.1896}), (16, 0.1678, {'top1': 0.1678}), (21, 0.1228, {'top1': 0.1228}), (22, 0.1096, {'top1': 0.1096}), (26, 0.1422, {'top1': 0.1422}), (30, 0.138, {'top1': 0.138}), (36, 0.1038, {'top1': 0.1038}), (52, 0.1068, {'top1': 0.1068}), (53, 0.11, {'top1': 0.11})]
just computed impact of block 5 . accuracy after removing:  0.1914
removed block 5 current accuracy 0.1914 loss from initial  0.7218
since last training loss: 0.7218 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(0, 0.1596, {'top1': 0.1596}), (2, 0.1444, {'top1': 0.1444}), (6, 0.1768, {'top1': 0.1768}), (16, 0.1642, {'top1': 0.1642}), (21, 0.1196, {'top1': 0.1196}), (22, 0.112, {'top1': 0.112}), (26, 0.133, {'top1': 0.133}), (30, 0.1342, {'top1': 0.1342}), (36, 0.1042, {'top1': 0.1042}), (52, 0.1072, {'top1': 0.1072}), (53, 0.107, {'top1': 0.107})]
just computed impact of block 6 . accuracy after removing:  0.1768
removed block 6 current accuracy 0.1768 loss from initial  0.7363999999999999
since last training loss: 0.7363999999999999 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(0, 0.1562, {'top1': 0.1562}), (2, 0.1368, {'top1': 0.1368}), (16, 0.158, {'top1': 0.158}), (21, 0.1106, {'top1': 0.1106}), (22, 0.111, {'top1': 0.111}), (26, 0.1172, {'top1': 0.1172}), (30, 0.1216, {'top1': 0.1216}), (36, 0.1014, {'top1': 0.1014}), (52, 0.1064, {'top1': 0.1064}), (53, 0.1076, {'top1': 0.1076})]
just computed impact of block 16 . accuracy after removing:  0.158
removed block 16 current accuracy 0.158 loss from initial  0.7552
training start
training epoch 0 val accuracy 0.7186 topk_dict {'top1': 0.7186} is_best True lr [0.1]
training epoch 1 val accuracy 0.7626 topk_dict {'top1': 0.7626} is_best True lr [0.1]
training epoch 2 val accuracy 0.804 topk_dict {'top1': 0.804} is_best True lr [0.1]
training epoch 3 val accuracy 0.8118 topk_dict {'top1': 0.8118} is_best True lr [0.1]
training epoch 4 val accuracy 0.8066 topk_dict {'top1': 0.8066} is_best False lr [0.1]
training epoch 5 val accuracy 0.8106 topk_dict {'top1': 0.8106} is_best False lr [0.1]
training epoch 6 val accuracy 0.8166 topk_dict {'top1': 0.8166} is_best True lr [0.1]
training epoch 7 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best True lr [0.1]
training epoch 8 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best False lr [0.1]
training epoch 9 val accuracy 0.8228 topk_dict {'top1': 0.8228} is_best False lr [0.1]
training epoch 10 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best False lr [0.1]
training epoch 11 val accuracy 0.8114 topk_dict {'top1': 0.8114} is_best False lr [0.1]
training epoch 12 val accuracy 0.8072 topk_dict {'top1': 0.8072} is_best False lr [0.1]
training epoch 13 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 14 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 15 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.1]
training epoch 16 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 17 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 18 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 19 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 20 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 21 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 22 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best True lr [0.1]
training epoch 23 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.1]
training epoch 24 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 25 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 26 val accuracy 0.7906 topk_dict {'top1': 0.7906} is_best False lr [0.1]
training epoch 27 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 28 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 29 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 30 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 31 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 32 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 33 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 34 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 35 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.1]
training epoch 36 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 37 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 38 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 39 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.1]
training epoch 40 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 41 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.1]
training epoch 42 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 43 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 44 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 45 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 46 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 47 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 48 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 49 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 50 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 51 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 52 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 53 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 54 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 55 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 56 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 57 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 58 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 59 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 60 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 61 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 62 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 63 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 64 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 65 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 66 val accuracy 0.828 topk_dict {'top1': 0.828} is_best False lr [0.1]
training epoch 67 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 68 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 69 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 70 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 71 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 72 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 73 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 74 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 75 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 76 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 77 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 78 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 79 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 80 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 81 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 82 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 83 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 84 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 85 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 86 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 87 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 88 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.1]
training epoch 89 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 90 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 91 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 92 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 93 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 94 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 95 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 96 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 97 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 98 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 99 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 100 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 101 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 102 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.1]
training epoch 103 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 104 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 105 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 106 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 107 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 108 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 109 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.1]
training epoch 110 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 111 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 112 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 113 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 114 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 115 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 116 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 117 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 118 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 119 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 120 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 121 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 122 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 123 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 124 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 125 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 126 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 127 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 128 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 129 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 130 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 131 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 132 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 133 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 134 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 135 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 136 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 137 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 138 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 139 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 140 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 141 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 142 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 143 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 144 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 145 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 146 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 147 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 148 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 149 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 150 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 151 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 152 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 153 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 154 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 155 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 156 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 157 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 158 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 159 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 160 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 161 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 162 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 163 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 164 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 165 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 166 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 167 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 168 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 169 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 170 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 171 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 172 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 173 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 174 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 175 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 176 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 177 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 178 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 179 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 180 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 181 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 182 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 183 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 184 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 185 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 186 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 187 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 188 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 189 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 190 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 191 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 192 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 193 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 194 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 195 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 196 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 197 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 198 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 199 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 200 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 201 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.1]
training epoch 202 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 203 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 204 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 205 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 206 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 207 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 208 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 209 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 210 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 211 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 212 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 213 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 214 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 215 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 216 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 217 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 218 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 219 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 220 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 221 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 222 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 223 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 224 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 225 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 226 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 227 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 228 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 229 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.010000000000000002]
training epoch 230 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.010000000000000002]
training epoch 231 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.010000000000000002]
training epoch 232 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 233 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 234 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.010000000000000002]
training epoch 235 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 236 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.010000000000000002]
training epoch 237 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 238 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.010000000000000002]
training epoch 239 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 240 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 241 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 242 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 246 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 250 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 261 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 262 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 311 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 345 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 346 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 347 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 348 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 349 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 350 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 351 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 352 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 353 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 354 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 355 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 356 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 357 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 358 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 359 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.0010000000000000002]
training epoch 366 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
loading model_best from epoch 411 (acc 0.923600)
finished training. finished 459 epochs. accuracy 0.9236 topk_dict {'top1': 0.9236}
