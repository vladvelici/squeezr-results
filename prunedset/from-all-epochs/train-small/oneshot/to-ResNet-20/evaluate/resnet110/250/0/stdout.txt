start iteration 0
(cache recomputed) Accuracy log [(0, 0.9836, {'top1': 0.9836}), (1, 0.9848, {'top1': 0.9848}), (2, 0.9898, {'top1': 0.9898}), (3, 0.9908, {'top1': 0.9908}), (4, 0.9914, {'top1': 0.9914}), (5, 0.9812, {'top1': 0.9812}), (6, 0.9896, {'top1': 0.9896}), (7, 0.9834, {'top1': 0.9834}), (8, 0.9922, {'top1': 0.9922}), (9, 0.9912, {'top1': 0.9912}), (10, 0.9908, {'top1': 0.9908}), (11, 0.9906, {'top1': 0.9906}), (12, 0.9896, {'top1': 0.9896}), (13, 0.9878, {'top1': 0.9878}), (14, 0.988, {'top1': 0.988}), (15, 0.9868, {'top1': 0.9868}), (16, 0.987, {'top1': 0.987}), (17, 0.9922, {'top1': 0.9922}), (18, 0.6116, {'top1': 0.6116}), (19, 0.989, {'top1': 0.989}), (20, 0.9926, {'top1': 0.9926}), (21, 0.991, {'top1': 0.991}), (22, 0.9906, {'top1': 0.9906}), (23, 0.9918, {'top1': 0.9918}), (24, 0.9928, {'top1': 0.9928}), (25, 0.9928, {'top1': 0.9928}), (26, 0.9926, {'top1': 0.9926}), (27, 0.9914, {'top1': 0.9914}), (28, 0.9922, {'top1': 0.9922}), (29, 0.9928, {'top1': 0.9928}), (30, 0.9926, {'top1': 0.9926}), (31, 0.993, {'top1': 0.993}), (32, 0.9918, {'top1': 0.9918}), (33, 0.9926, {'top1': 0.9926}), (34, 0.9918, {'top1': 0.9918}), (35, 0.9916, {'top1': 0.9916}), (36, 0.728, {'top1': 0.728}), (37, 0.9926, {'top1': 0.9926}), (38, 0.9928, {'top1': 0.9928}), (39, 0.9904, {'top1': 0.9904}), (40, 0.9922, {'top1': 0.9922}), (41, 0.9932, {'top1': 0.9932}), (42, 0.9912, {'top1': 0.9912}), (43, 0.9914, {'top1': 0.9914}), (44, 0.9918, {'top1': 0.9918}), (45, 0.993, {'top1': 0.993}), (46, 0.992, {'top1': 0.992}), (47, 0.9918, {'top1': 0.9918}), (48, 0.992, {'top1': 0.992}), (49, 0.9908, {'top1': 0.9908}), (50, 0.9876, {'top1': 0.9876}), (51, 0.9768, {'top1': 0.9768}), (52, 0.965, {'top1': 0.965}), (53, 0.7368, {'top1': 0.7368})]
just computed impact of block 41 . accuracy after removing:  0.9932
removed block 41 current accuracy 0.9932 loss from initial  -0.00039999999999995595
since last training loss: -0.00039999999999995595 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.982, {'top1': 0.982}), (1, 0.9814, {'top1': 0.9814}), (2, 0.9884, {'top1': 0.9884}), (3, 0.9892, {'top1': 0.9892}), (4, 0.9912, {'top1': 0.9912}), (5, 0.9792, {'top1': 0.9792}), (6, 0.9884, {'top1': 0.9884}), (7, 0.9832, {'top1': 0.9832}), (8, 0.991, {'top1': 0.991}), (9, 0.9904, {'top1': 0.9904}), (10, 0.9914, {'top1': 0.9914}), (11, 0.9896, {'top1': 0.9896}), (12, 0.987, {'top1': 0.987}), (13, 0.988, {'top1': 0.988}), (14, 0.9872, {'top1': 0.9872}), (15, 0.987, {'top1': 0.987}), (16, 0.9848, {'top1': 0.9848}), (17, 0.9896, {'top1': 0.9896}), (18, 0.597, {'top1': 0.597}), (19, 0.9906, {'top1': 0.9906}), (20, 0.9914, {'top1': 0.9914}), (21, 0.9908, {'top1': 0.9908}), (22, 0.9912, {'top1': 0.9912}), (23, 0.9902, {'top1': 0.9902}), (24, 0.992, {'top1': 0.992}), (25, 0.9922, {'top1': 0.9922}), (26, 0.9912, {'top1': 0.9912}), (27, 0.99, {'top1': 0.99}), (28, 0.992, {'top1': 0.992}), (29, 0.9912, {'top1': 0.9912}), (30, 0.9918, {'top1': 0.9918}), (31, 0.9904, {'top1': 0.9904}), (32, 0.9916, {'top1': 0.9916}), (33, 0.991, {'top1': 0.991}), (34, 0.992, {'top1': 0.992}), (35, 0.9916, {'top1': 0.9916}), (36, 0.7256, {'top1': 0.7256}), (37, 0.9902, {'top1': 0.9902}), (38, 0.9912, {'top1': 0.9912}), (39, 0.99, {'top1': 0.99}), (40, 0.9916, {'top1': 0.9916}), (42, 0.9908, {'top1': 0.9908}), (43, 0.9912, {'top1': 0.9912}), (44, 0.9918, {'top1': 0.9918}), (45, 0.992, {'top1': 0.992}), (46, 0.9904, {'top1': 0.9904}), (47, 0.9908, {'top1': 0.9908}), (48, 0.991, {'top1': 0.991}), (49, 0.9896, {'top1': 0.9896}), (50, 0.9868, {'top1': 0.9868}), (51, 0.974, {'top1': 0.974}), (52, 0.961, {'top1': 0.961}), (53, 0.7378, {'top1': 0.7378})]
just computed impact of block 25 . accuracy after removing:  0.9922
removed block 25 current accuracy 0.9922 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.981, {'top1': 0.981}), (1, 0.979, {'top1': 0.979}), (2, 0.9862, {'top1': 0.9862}), (3, 0.9872, {'top1': 0.9872}), (4, 0.9898, {'top1': 0.9898}), (5, 0.9742, {'top1': 0.9742}), (6, 0.9866, {'top1': 0.9866}), (7, 0.9776, {'top1': 0.9776}), (8, 0.9894, {'top1': 0.9894}), (9, 0.9892, {'top1': 0.9892}), (10, 0.99, {'top1': 0.99}), (11, 0.9882, {'top1': 0.9882}), (12, 0.9856, {'top1': 0.9856}), (13, 0.9864, {'top1': 0.9864}), (14, 0.9848, {'top1': 0.9848}), (15, 0.985, {'top1': 0.985}), (16, 0.9826, {'top1': 0.9826}), (17, 0.9884, {'top1': 0.9884}), (18, 0.5994, {'top1': 0.5994}), (19, 0.987, {'top1': 0.987}), (20, 0.9906, {'top1': 0.9906}), (21, 0.9884, {'top1': 0.9884}), (22, 0.9876, {'top1': 0.9876}), (23, 0.9888, {'top1': 0.9888}), (24, 0.9904, {'top1': 0.9904}), (26, 0.9902, {'top1': 0.9902}), (27, 0.9874, {'top1': 0.9874}), (28, 0.9912, {'top1': 0.9912}), (29, 0.9882, {'top1': 0.9882}), (30, 0.9908, {'top1': 0.9908}), (31, 0.9902, {'top1': 0.9902}), (32, 0.99, {'top1': 0.99}), (33, 0.9894, {'top1': 0.9894}), (34, 0.9902, {'top1': 0.9902}), (35, 0.9902, {'top1': 0.9902}), (36, 0.6862, {'top1': 0.6862}), (37, 0.9898, {'top1': 0.9898}), (38, 0.9894, {'top1': 0.9894}), (39, 0.9882, {'top1': 0.9882}), (40, 0.9886, {'top1': 0.9886}), (42, 0.991, {'top1': 0.991}), (43, 0.9902, {'top1': 0.9902}), (44, 0.9902, {'top1': 0.9902}), (45, 0.9904, {'top1': 0.9904}), (46, 0.9896, {'top1': 0.9896}), (47, 0.9902, {'top1': 0.9902}), (48, 0.9902, {'top1': 0.9902}), (49, 0.989, {'top1': 0.989}), (50, 0.9864, {'top1': 0.9864}), (51, 0.9722, {'top1': 0.9722}), (52, 0.9632, {'top1': 0.9632}), (53, 0.735, {'top1': 0.735})]
just computed impact of block 28 . accuracy after removing:  0.9912
removed block 28 current accuracy 0.9912 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.9774, {'top1': 0.9774}), (1, 0.9772, {'top1': 0.9772}), (2, 0.9838, {'top1': 0.9838}), (3, 0.9866, {'top1': 0.9866}), (4, 0.9892, {'top1': 0.9892}), (5, 0.971, {'top1': 0.971}), (6, 0.9842, {'top1': 0.9842}), (7, 0.976, {'top1': 0.976}), (8, 0.9886, {'top1': 0.9886}), (9, 0.9884, {'top1': 0.9884}), (10, 0.9888, {'top1': 0.9888}), (11, 0.9866, {'top1': 0.9866}), (12, 0.9854, {'top1': 0.9854}), (13, 0.9858, {'top1': 0.9858}), (14, 0.984, {'top1': 0.984}), (15, 0.981, {'top1': 0.981}), (16, 0.9808, {'top1': 0.9808}), (17, 0.9872, {'top1': 0.9872}), (18, 0.596, {'top1': 0.596}), (19, 0.983, {'top1': 0.983}), (20, 0.9886, {'top1': 0.9886}), (21, 0.987, {'top1': 0.987}), (22, 0.9878, {'top1': 0.9878}), (23, 0.9886, {'top1': 0.9886}), (24, 0.9888, {'top1': 0.9888}), (26, 0.9882, {'top1': 0.9882}), (27, 0.9862, {'top1': 0.9862}), (29, 0.9876, {'top1': 0.9876}), (30, 0.989, {'top1': 0.989}), (31, 0.9888, {'top1': 0.9888}), (32, 0.9888, {'top1': 0.9888}), (33, 0.9886, {'top1': 0.9886}), (34, 0.9884, {'top1': 0.9884}), (35, 0.9878, {'top1': 0.9878}), (36, 0.6702, {'top1': 0.6702}), (37, 0.9886, {'top1': 0.9886}), (38, 0.9888, {'top1': 0.9888}), (39, 0.9862, {'top1': 0.9862}), (40, 0.9878, {'top1': 0.9878}), (42, 0.9894, {'top1': 0.9894}), (43, 0.9886, {'top1': 0.9886}), (44, 0.9882, {'top1': 0.9882}), (45, 0.9898, {'top1': 0.9898}), (46, 0.9878, {'top1': 0.9878}), (47, 0.9896, {'top1': 0.9896}), (48, 0.9896, {'top1': 0.9896}), (49, 0.9876, {'top1': 0.9876}), (50, 0.9842, {'top1': 0.9842}), (51, 0.9702, {'top1': 0.9702}), (52, 0.9628, {'top1': 0.9628}), (53, 0.7304, {'top1': 0.7304})]
just computed impact of block 45 . accuracy after removing:  0.9898
removed block 45 current accuracy 0.9898 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.9766, {'top1': 0.9766}), (1, 0.9758, {'top1': 0.9758}), (2, 0.9828, {'top1': 0.9828}), (3, 0.9856, {'top1': 0.9856}), (4, 0.9862, {'top1': 0.9862}), (5, 0.9698, {'top1': 0.9698}), (6, 0.9842, {'top1': 0.9842}), (7, 0.9768, {'top1': 0.9768}), (8, 0.9878, {'top1': 0.9878}), (9, 0.9872, {'top1': 0.9872}), (10, 0.9874, {'top1': 0.9874}), (11, 0.9858, {'top1': 0.9858}), (12, 0.9822, {'top1': 0.9822}), (13, 0.9834, {'top1': 0.9834}), (14, 0.9836, {'top1': 0.9836}), (15, 0.9802, {'top1': 0.9802}), (16, 0.979, {'top1': 0.979}), (17, 0.9836, {'top1': 0.9836}), (18, 0.5998, {'top1': 0.5998}), (19, 0.9808, {'top1': 0.9808}), (20, 0.986, {'top1': 0.986}), (21, 0.9848, {'top1': 0.9848}), (22, 0.9868, {'top1': 0.9868}), (23, 0.9884, {'top1': 0.9884}), (24, 0.9862, {'top1': 0.9862}), (26, 0.9884, {'top1': 0.9884}), (27, 0.9842, {'top1': 0.9842}), (29, 0.987, {'top1': 0.987}), (30, 0.9884, {'top1': 0.9884}), (31, 0.9878, {'top1': 0.9878}), (32, 0.9866, {'top1': 0.9866}), (33, 0.987, {'top1': 0.987}), (34, 0.9858, {'top1': 0.9858}), (35, 0.9866, {'top1': 0.9866}), (36, 0.681, {'top1': 0.681}), (37, 0.9874, {'top1': 0.9874}), (38, 0.9878, {'top1': 0.9878}), (39, 0.9858, {'top1': 0.9858}), (40, 0.9868, {'top1': 0.9868}), (42, 0.987, {'top1': 0.987}), (43, 0.9866, {'top1': 0.9866}), (44, 0.9878, {'top1': 0.9878}), (46, 0.9846, {'top1': 0.9846}), (47, 0.986, {'top1': 0.986}), (48, 0.9872, {'top1': 0.9872}), (49, 0.9854, {'top1': 0.9854}), (50, 0.9814, {'top1': 0.9814}), (51, 0.9668, {'top1': 0.9668}), (52, 0.9572, {'top1': 0.9572}), (53, 0.7312, {'top1': 0.7312})]
just computed impact of block 23 . accuracy after removing:  0.9884
removed block 23 current accuracy 0.9884 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.9696, {'top1': 0.9696}), (1, 0.9706, {'top1': 0.9706}), (2, 0.9804, {'top1': 0.9804}), (3, 0.9822, {'top1': 0.9822}), (4, 0.9842, {'top1': 0.9842}), (5, 0.9652, {'top1': 0.9652}), (6, 0.9786, {'top1': 0.9786}), (7, 0.9724, {'top1': 0.9724}), (8, 0.9848, {'top1': 0.9848}), (9, 0.9826, {'top1': 0.9826}), (10, 0.9862, {'top1': 0.9862}), (11, 0.9828, {'top1': 0.9828}), (12, 0.9794, {'top1': 0.9794}), (13, 0.9774, {'top1': 0.9774}), (14, 0.979, {'top1': 0.979}), (15, 0.9778, {'top1': 0.9778}), (16, 0.9708, {'top1': 0.9708}), (17, 0.9784, {'top1': 0.9784}), (18, 0.5758, {'top1': 0.5758}), (19, 0.9752, {'top1': 0.9752}), (20, 0.9826, {'top1': 0.9826}), (21, 0.982, {'top1': 0.982}), (22, 0.9818, {'top1': 0.9818}), (24, 0.9842, {'top1': 0.9842}), (26, 0.9846, {'top1': 0.9846}), (27, 0.9816, {'top1': 0.9816}), (29, 0.9844, {'top1': 0.9844}), (30, 0.985, {'top1': 0.985}), (31, 0.9856, {'top1': 0.9856}), (32, 0.9844, {'top1': 0.9844}), (33, 0.983, {'top1': 0.983}), (34, 0.9842, {'top1': 0.9842}), (35, 0.9836, {'top1': 0.9836}), (36, 0.6534, {'top1': 0.6534}), (37, 0.9862, {'top1': 0.9862}), (38, 0.9834, {'top1': 0.9834}), (39, 0.9826, {'top1': 0.9826}), (40, 0.9844, {'top1': 0.9844}), (42, 0.9846, {'top1': 0.9846}), (43, 0.9842, {'top1': 0.9842}), (44, 0.9846, {'top1': 0.9846}), (46, 0.982, {'top1': 0.982}), (47, 0.9834, {'top1': 0.9834}), (48, 0.9828, {'top1': 0.9828}), (49, 0.9826, {'top1': 0.9826}), (50, 0.9782, {'top1': 0.9782}), (51, 0.961, {'top1': 0.961}), (52, 0.9526, {'top1': 0.9526}), (53, 0.7214, {'top1': 0.7214})]
just computed impact of block 10 . accuracy after removing:  0.9862
removed block 10 current accuracy 0.9862 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.9672, {'top1': 0.9672}), (1, 0.9642, {'top1': 0.9642}), (2, 0.9704, {'top1': 0.9704}), (3, 0.9764, {'top1': 0.9764}), (4, 0.982, {'top1': 0.982}), (5, 0.9622, {'top1': 0.9622}), (6, 0.9776, {'top1': 0.9776}), (7, 0.9586, {'top1': 0.9586}), (8, 0.9776, {'top1': 0.9776}), (9, 0.9722, {'top1': 0.9722}), (11, 0.9738, {'top1': 0.9738}), (12, 0.9774, {'top1': 0.9774}), (13, 0.9608, {'top1': 0.9608}), (14, 0.9656, {'top1': 0.9656}), (15, 0.9688, {'top1': 0.9688}), (16, 0.9478, {'top1': 0.9478}), (17, 0.9702, {'top1': 0.9702}), (18, 0.5234, {'top1': 0.5234}), (19, 0.9738, {'top1': 0.9738}), (20, 0.9816, {'top1': 0.9816}), (21, 0.979, {'top1': 0.979}), (22, 0.9776, {'top1': 0.9776}), (24, 0.9818, {'top1': 0.9818}), (26, 0.9828, {'top1': 0.9828}), (27, 0.979, {'top1': 0.979}), (29, 0.9802, {'top1': 0.9802}), (30, 0.9822, {'top1': 0.9822}), (31, 0.9812, {'top1': 0.9812}), (32, 0.9818, {'top1': 0.9818}), (33, 0.9808, {'top1': 0.9808}), (34, 0.981, {'top1': 0.981}), (35, 0.9812, {'top1': 0.9812}), (36, 0.6392, {'top1': 0.6392}), (37, 0.98, {'top1': 0.98}), (38, 0.9794, {'top1': 0.9794}), (39, 0.9812, {'top1': 0.9812}), (40, 0.9828, {'top1': 0.9828}), (42, 0.9828, {'top1': 0.9828}), (43, 0.983, {'top1': 0.983}), (44, 0.9818, {'top1': 0.9818}), (46, 0.9806, {'top1': 0.9806}), (47, 0.9802, {'top1': 0.9802}), (48, 0.981, {'top1': 0.981}), (49, 0.9818, {'top1': 0.9818}), (50, 0.9802, {'top1': 0.9802}), (51, 0.9592, {'top1': 0.9592}), (52, 0.9548, {'top1': 0.9548}), (53, 0.7248, {'top1': 0.7248})]
just computed impact of block 43 . accuracy after removing:  0.983
removed block 43 current accuracy 0.983 loss from initial  0.009800000000000031
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.961, {'top1': 0.961}), (1, 0.9616, {'top1': 0.9616}), (2, 0.9682, {'top1': 0.9682}), (3, 0.9738, {'top1': 0.9738}), (4, 0.9798, {'top1': 0.9798}), (5, 0.9566, {'top1': 0.9566}), (6, 0.9734, {'top1': 0.9734}), (7, 0.9536, {'top1': 0.9536}), (8, 0.9742, {'top1': 0.9742}), (9, 0.9682, {'top1': 0.9682}), (11, 0.9708, {'top1': 0.9708}), (12, 0.977, {'top1': 0.977}), (13, 0.958, {'top1': 0.958}), (14, 0.9634, {'top1': 0.9634}), (15, 0.9664, {'top1': 0.9664}), (16, 0.9454, {'top1': 0.9454}), (17, 0.9676, {'top1': 0.9676}), (18, 0.542, {'top1': 0.542}), (19, 0.9716, {'top1': 0.9716}), (20, 0.9792, {'top1': 0.9792}), (21, 0.9768, {'top1': 0.9768}), (22, 0.9752, {'top1': 0.9752}), (24, 0.9792, {'top1': 0.9792}), (26, 0.9814, {'top1': 0.9814}), (27, 0.9756, {'top1': 0.9756}), (29, 0.979, {'top1': 0.979}), (30, 0.9806, {'top1': 0.9806}), (31, 0.9806, {'top1': 0.9806}), (32, 0.98, {'top1': 0.98}), (33, 0.9788, {'top1': 0.9788}), (34, 0.98, {'top1': 0.98}), (35, 0.9794, {'top1': 0.9794}), (36, 0.6696, {'top1': 0.6696}), (37, 0.9804, {'top1': 0.9804}), (38, 0.9772, {'top1': 0.9772}), (39, 0.9784, {'top1': 0.9784}), (40, 0.9786, {'top1': 0.9786}), (42, 0.979, {'top1': 0.979}), (44, 0.98, {'top1': 0.98}), (46, 0.977, {'top1': 0.977}), (47, 0.9784, {'top1': 0.9784}), (48, 0.9778, {'top1': 0.9778}), (49, 0.98, {'top1': 0.98}), (50, 0.975, {'top1': 0.975}), (51, 0.9538, {'top1': 0.9538}), (52, 0.9482, {'top1': 0.9482}), (53, 0.72, {'top1': 0.72})]
just computed impact of block 26 . accuracy after removing:  0.9814
removed block 26 current accuracy 0.9814 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.9576, {'top1': 0.9576}), (1, 0.9584, {'top1': 0.9584}), (2, 0.9626, {'top1': 0.9626}), (3, 0.9692, {'top1': 0.9692}), (4, 0.9744, {'top1': 0.9744}), (5, 0.952, {'top1': 0.952}), (6, 0.9686, {'top1': 0.9686}), (7, 0.9432, {'top1': 0.9432}), (8, 0.9698, {'top1': 0.9698}), (9, 0.9666, {'top1': 0.9666}), (11, 0.9672, {'top1': 0.9672}), (12, 0.9716, {'top1': 0.9716}), (13, 0.9528, {'top1': 0.9528}), (14, 0.9586, {'top1': 0.9586}), (15, 0.9596, {'top1': 0.9596}), (16, 0.9404, {'top1': 0.9404}), (17, 0.963, {'top1': 0.963}), (18, 0.503, {'top1': 0.503}), (19, 0.964, {'top1': 0.964}), (20, 0.9752, {'top1': 0.9752}), (21, 0.9712, {'top1': 0.9712}), (22, 0.9712, {'top1': 0.9712}), (24, 0.975, {'top1': 0.975}), (27, 0.969, {'top1': 0.969}), (29, 0.974, {'top1': 0.974}), (30, 0.9756, {'top1': 0.9756}), (31, 0.9766, {'top1': 0.9766}), (32, 0.9778, {'top1': 0.9778}), (33, 0.9754, {'top1': 0.9754}), (34, 0.9752, {'top1': 0.9752}), (35, 0.9762, {'top1': 0.9762}), (36, 0.6508, {'top1': 0.6508}), (37, 0.9744, {'top1': 0.9744}), (38, 0.9732, {'top1': 0.9732}), (39, 0.973, {'top1': 0.973}), (40, 0.975, {'top1': 0.975}), (42, 0.975, {'top1': 0.975}), (44, 0.9758, {'top1': 0.9758}), (46, 0.9732, {'top1': 0.9732}), (47, 0.9748, {'top1': 0.9748}), (48, 0.9746, {'top1': 0.9746}), (49, 0.976, {'top1': 0.976}), (50, 0.9704, {'top1': 0.9704}), (51, 0.9456, {'top1': 0.9456}), (52, 0.9428, {'top1': 0.9428}), (53, 0.7144, {'top1': 0.7144})]
just computed impact of block 32 . accuracy after removing:  0.9778
removed block 32 current accuracy 0.9778 loss from initial  0.015000000000000013
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.953, {'top1': 0.953}), (1, 0.9534, {'top1': 0.9534}), (2, 0.9572, {'top1': 0.9572}), (3, 0.9636, {'top1': 0.9636}), (4, 0.9716, {'top1': 0.9716}), (5, 0.9464, {'top1': 0.9464}), (6, 0.9628, {'top1': 0.9628}), (7, 0.946, {'top1': 0.946}), (8, 0.9676, {'top1': 0.9676}), (9, 0.962, {'top1': 0.962}), (11, 0.9626, {'top1': 0.9626}), (12, 0.968, {'top1': 0.968}), (13, 0.949, {'top1': 0.949}), (14, 0.956, {'top1': 0.956}), (15, 0.9592, {'top1': 0.9592}), (16, 0.9344, {'top1': 0.9344}), (17, 0.9572, {'top1': 0.9572}), (18, 0.5326, {'top1': 0.5326}), (19, 0.9584, {'top1': 0.9584}), (20, 0.9714, {'top1': 0.9714}), (21, 0.9656, {'top1': 0.9656}), (22, 0.9674, {'top1': 0.9674}), (24, 0.9686, {'top1': 0.9686}), (27, 0.966, {'top1': 0.966}), (29, 0.9688, {'top1': 0.9688}), (30, 0.9718, {'top1': 0.9718}), (31, 0.9724, {'top1': 0.9724}), (33, 0.9684, {'top1': 0.9684}), (34, 0.9698, {'top1': 0.9698}), (35, 0.971, {'top1': 0.971}), (36, 0.6326, {'top1': 0.6326}), (37, 0.9728, {'top1': 0.9728}), (38, 0.971, {'top1': 0.971}), (39, 0.9698, {'top1': 0.9698}), (40, 0.9714, {'top1': 0.9714}), (42, 0.97, {'top1': 0.97}), (44, 0.9718, {'top1': 0.9718}), (46, 0.971, {'top1': 0.971}), (47, 0.9704, {'top1': 0.9704}), (48, 0.9694, {'top1': 0.9694}), (49, 0.9706, {'top1': 0.9706}), (50, 0.9672, {'top1': 0.9672}), (51, 0.9412, {'top1': 0.9412}), (52, 0.94, {'top1': 0.94}), (53, 0.7152, {'top1': 0.7152})]
just computed impact of block 37 . accuracy after removing:  0.9728
removed block 37 current accuracy 0.9728 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.9488, {'top1': 0.9488}), (1, 0.947, {'top1': 0.947}), (2, 0.952, {'top1': 0.952}), (3, 0.9616, {'top1': 0.9616}), (4, 0.9684, {'top1': 0.9684}), (5, 0.9396, {'top1': 0.9396}), (6, 0.9592, {'top1': 0.9592}), (7, 0.9452, {'top1': 0.9452}), (8, 0.9642, {'top1': 0.9642}), (9, 0.9562, {'top1': 0.9562}), (11, 0.9636, {'top1': 0.9636}), (12, 0.9662, {'top1': 0.9662}), (13, 0.943, {'top1': 0.943}), (14, 0.9528, {'top1': 0.9528}), (15, 0.956, {'top1': 0.956}), (16, 0.9246, {'top1': 0.9246}), (17, 0.9534, {'top1': 0.9534}), (18, 0.4612, {'top1': 0.4612}), (19, 0.9554, {'top1': 0.9554}), (20, 0.9666, {'top1': 0.9666}), (21, 0.9632, {'top1': 0.9632}), (22, 0.963, {'top1': 0.963}), (24, 0.9654, {'top1': 0.9654}), (27, 0.9636, {'top1': 0.9636}), (29, 0.963, {'top1': 0.963}), (30, 0.968, {'top1': 0.968}), (31, 0.968, {'top1': 0.968}), (33, 0.965, {'top1': 0.965}), (34, 0.9644, {'top1': 0.9644}), (35, 0.9684, {'top1': 0.9684}), (36, 0.4766, {'top1': 0.4766}), (38, 0.9642, {'top1': 0.9642}), (39, 0.9634, {'top1': 0.9634}), (40, 0.965, {'top1': 0.965}), (42, 0.9688, {'top1': 0.9688}), (44, 0.968, {'top1': 0.968}), (46, 0.9654, {'top1': 0.9654}), (47, 0.9644, {'top1': 0.9644}), (48, 0.9646, {'top1': 0.9646}), (49, 0.966, {'top1': 0.966}), (50, 0.9606, {'top1': 0.9606}), (51, 0.938, {'top1': 0.938}), (52, 0.9326, {'top1': 0.9326}), (53, 0.7, {'top1': 0.7})]
just computed impact of block 42 . accuracy after removing:  0.9688
removed block 42 current accuracy 0.9688 loss from initial  0.02400000000000002
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.9424, {'top1': 0.9424}), (1, 0.9392, {'top1': 0.9392}), (2, 0.9438, {'top1': 0.9438}), (3, 0.954, {'top1': 0.954}), (4, 0.9638, {'top1': 0.9638}), (5, 0.933, {'top1': 0.933}), (6, 0.9534, {'top1': 0.9534}), (7, 0.94, {'top1': 0.94}), (8, 0.957, {'top1': 0.957}), (9, 0.9518, {'top1': 0.9518}), (11, 0.9566, {'top1': 0.9566}), (12, 0.96, {'top1': 0.96}), (13, 0.9404, {'top1': 0.9404}), (14, 0.95, {'top1': 0.95}), (15, 0.9496, {'top1': 0.9496}), (16, 0.9164, {'top1': 0.9164}), (17, 0.9462, {'top1': 0.9462}), (18, 0.4756, {'top1': 0.4756}), (19, 0.9518, {'top1': 0.9518}), (20, 0.9596, {'top1': 0.9596}), (21, 0.956, {'top1': 0.956}), (22, 0.9566, {'top1': 0.9566}), (24, 0.96, {'top1': 0.96}), (27, 0.9576, {'top1': 0.9576}), (29, 0.959, {'top1': 0.959}), (30, 0.9622, {'top1': 0.9622}), (31, 0.9618, {'top1': 0.9618}), (33, 0.9582, {'top1': 0.9582}), (34, 0.9588, {'top1': 0.9588}), (35, 0.9622, {'top1': 0.9622}), (36, 0.4982, {'top1': 0.4982}), (38, 0.9584, {'top1': 0.9584}), (39, 0.9574, {'top1': 0.9574}), (40, 0.961, {'top1': 0.961}), (44, 0.962, {'top1': 0.962}), (46, 0.9596, {'top1': 0.9596}), (47, 0.9602, {'top1': 0.9602}), (48, 0.9596, {'top1': 0.9596}), (49, 0.96, {'top1': 0.96}), (50, 0.9566, {'top1': 0.9566}), (51, 0.9292, {'top1': 0.9292}), (52, 0.9208, {'top1': 0.9208}), (53, 0.6732, {'top1': 0.6732})]
just computed impact of block 4 . accuracy after removing:  0.9638
removed block 4 current accuracy 0.9638 loss from initial  0.029000000000000026
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.9364, {'top1': 0.9364}), (1, 0.9344, {'top1': 0.9344}), (2, 0.9412, {'top1': 0.9412}), (3, 0.9498, {'top1': 0.9498}), (5, 0.924, {'top1': 0.924}), (6, 0.948, {'top1': 0.948}), (7, 0.9258, {'top1': 0.9258}), (8, 0.9498, {'top1': 0.9498}), (9, 0.9496, {'top1': 0.9496}), (11, 0.9512, {'top1': 0.9512}), (12, 0.9546, {'top1': 0.9546}), (13, 0.9404, {'top1': 0.9404}), (14, 0.9442, {'top1': 0.9442}), (15, 0.9454, {'top1': 0.9454}), (16, 0.9228, {'top1': 0.9228}), (17, 0.9472, {'top1': 0.9472}), (18, 0.4908, {'top1': 0.4908}), (19, 0.9454, {'top1': 0.9454}), (20, 0.9542, {'top1': 0.9542}), (21, 0.953, {'top1': 0.953}), (22, 0.9544, {'top1': 0.9544}), (24, 0.9564, {'top1': 0.9564}), (27, 0.9504, {'top1': 0.9504}), (29, 0.9536, {'top1': 0.9536}), (30, 0.9594, {'top1': 0.9594}), (31, 0.9584, {'top1': 0.9584}), (33, 0.9542, {'top1': 0.9542}), (34, 0.956, {'top1': 0.956}), (35, 0.9572, {'top1': 0.9572}), (36, 0.5198, {'top1': 0.5198}), (38, 0.955, {'top1': 0.955}), (39, 0.9552, {'top1': 0.9552}), (40, 0.9566, {'top1': 0.9566}), (44, 0.958, {'top1': 0.958}), (46, 0.9568, {'top1': 0.9568}), (47, 0.9564, {'top1': 0.9564}), (48, 0.9558, {'top1': 0.9558}), (49, 0.9572, {'top1': 0.9572}), (50, 0.957, {'top1': 0.957}), (51, 0.9234, {'top1': 0.9234}), (52, 0.916, {'top1': 0.916}), (53, 0.6806, {'top1': 0.6806})]
just computed impact of block 30 . accuracy after removing:  0.9594
removed block 30 current accuracy 0.9594 loss from initial  0.033399999999999985
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.9322, {'top1': 0.9322}), (1, 0.9284, {'top1': 0.9284}), (2, 0.938, {'top1': 0.938}), (3, 0.9462, {'top1': 0.9462}), (5, 0.9172, {'top1': 0.9172}), (6, 0.9416, {'top1': 0.9416}), (7, 0.9216, {'top1': 0.9216}), (8, 0.9438, {'top1': 0.9438}), (9, 0.9434, {'top1': 0.9434}), (11, 0.9482, {'top1': 0.9482}), (12, 0.95, {'top1': 0.95}), (13, 0.9348, {'top1': 0.9348}), (14, 0.937, {'top1': 0.937}), (15, 0.9416, {'top1': 0.9416}), (16, 0.9146, {'top1': 0.9146}), (17, 0.9412, {'top1': 0.9412}), (18, 0.5248, {'top1': 0.5248}), (19, 0.9378, {'top1': 0.9378}), (20, 0.9512, {'top1': 0.9512}), (21, 0.9446, {'top1': 0.9446}), (22, 0.9484, {'top1': 0.9484}), (24, 0.9516, {'top1': 0.9516}), (27, 0.9474, {'top1': 0.9474}), (29, 0.9492, {'top1': 0.9492}), (31, 0.9546, {'top1': 0.9546}), (33, 0.9494, {'top1': 0.9494}), (34, 0.9492, {'top1': 0.9492}), (35, 0.9538, {'top1': 0.9538}), (36, 0.4954, {'top1': 0.4954}), (38, 0.9506, {'top1': 0.9506}), (39, 0.95, {'top1': 0.95}), (40, 0.953, {'top1': 0.953}), (44, 0.9552, {'top1': 0.9552}), (46, 0.9512, {'top1': 0.9512}), (47, 0.9518, {'top1': 0.9518}), (48, 0.9518, {'top1': 0.9518}), (49, 0.9502, {'top1': 0.9502}), (50, 0.9494, {'top1': 0.9494}), (51, 0.9184, {'top1': 0.9184}), (52, 0.9114, {'top1': 0.9114}), (53, 0.6766, {'top1': 0.6766})]
just computed impact of block 44 . accuracy after removing:  0.9552
removed block 44 current accuracy 0.9552 loss from initial  0.03759999999999997
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.9292, {'top1': 0.9292}), (1, 0.926, {'top1': 0.926}), (2, 0.9362, {'top1': 0.9362}), (3, 0.943, {'top1': 0.943}), (5, 0.9068, {'top1': 0.9068}), (6, 0.937, {'top1': 0.937}), (7, 0.917, {'top1': 0.917}), (8, 0.9374, {'top1': 0.9374}), (9, 0.937, {'top1': 0.937}), (11, 0.9412, {'top1': 0.9412}), (12, 0.9432, {'top1': 0.9432}), (13, 0.9318, {'top1': 0.9318}), (14, 0.9362, {'top1': 0.9362}), (15, 0.94, {'top1': 0.94}), (16, 0.9082, {'top1': 0.9082}), (17, 0.9362, {'top1': 0.9362}), (18, 0.543, {'top1': 0.543}), (19, 0.9312, {'top1': 0.9312}), (20, 0.9428, {'top1': 0.9428}), (21, 0.9404, {'top1': 0.9404}), (22, 0.94, {'top1': 0.94}), (24, 0.9466, {'top1': 0.9466}), (27, 0.9414, {'top1': 0.9414}), (29, 0.9432, {'top1': 0.9432}), (31, 0.9468, {'top1': 0.9468}), (33, 0.94, {'top1': 0.94}), (34, 0.943, {'top1': 0.943}), (35, 0.9474, {'top1': 0.9474}), (36, 0.5274, {'top1': 0.5274}), (38, 0.9468, {'top1': 0.9468}), (39, 0.9422, {'top1': 0.9422}), (40, 0.9464, {'top1': 0.9464}), (46, 0.9438, {'top1': 0.9438}), (47, 0.9434, {'top1': 0.9434}), (48, 0.9468, {'top1': 0.9468}), (49, 0.9434, {'top1': 0.9434}), (50, 0.9414, {'top1': 0.9414}), (51, 0.9112, {'top1': 0.9112}), (52, 0.8976, {'top1': 0.8976}), (53, 0.6688, {'top1': 0.6688})]
just computed impact of block 35 . accuracy after removing:  0.9474
removed block 35 current accuracy 0.9474 loss from initial  0.045399999999999996
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.9156, {'top1': 0.9156}), (1, 0.9128, {'top1': 0.9128}), (2, 0.926, {'top1': 0.926}), (3, 0.9308, {'top1': 0.9308}), (5, 0.8962, {'top1': 0.8962}), (6, 0.9228, {'top1': 0.9228}), (7, 0.9082, {'top1': 0.9082}), (8, 0.9272, {'top1': 0.9272}), (9, 0.9296, {'top1': 0.9296}), (11, 0.9324, {'top1': 0.9324}), (12, 0.931, {'top1': 0.931}), (13, 0.92, {'top1': 0.92}), (14, 0.9298, {'top1': 0.9298}), (15, 0.931, {'top1': 0.931}), (16, 0.8988, {'top1': 0.8988}), (17, 0.9266, {'top1': 0.9266}), (18, 0.5378, {'top1': 0.5378}), (19, 0.9172, {'top1': 0.9172}), (20, 0.9338, {'top1': 0.9338}), (21, 0.9306, {'top1': 0.9306}), (22, 0.9322, {'top1': 0.9322}), (24, 0.9376, {'top1': 0.9376}), (27, 0.9284, {'top1': 0.9284}), (29, 0.9338, {'top1': 0.9338}), (31, 0.939, {'top1': 0.939}), (33, 0.9308, {'top1': 0.9308}), (34, 0.9338, {'top1': 0.9338}), (36, 0.5168, {'top1': 0.5168}), (38, 0.9404, {'top1': 0.9404}), (39, 0.9334, {'top1': 0.9334}), (40, 0.9398, {'top1': 0.9398}), (46, 0.9358, {'top1': 0.9358}), (47, 0.9336, {'top1': 0.9336}), (48, 0.938, {'top1': 0.938}), (49, 0.9352, {'top1': 0.9352}), (50, 0.9304, {'top1': 0.9304}), (51, 0.8954, {'top1': 0.8954}), (52, 0.8828, {'top1': 0.8828}), (53, 0.6686, {'top1': 0.6686})]
just computed impact of block 38 . accuracy after removing:  0.9404
removed block 38 current accuracy 0.9404 loss from initial  0.0524
since last training loss: 0.0524 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.9078, {'top1': 0.9078}), (1, 0.9052, {'top1': 0.9052}), (2, 0.9126, {'top1': 0.9126}), (3, 0.923, {'top1': 0.923}), (5, 0.8886, {'top1': 0.8886}), (6, 0.914, {'top1': 0.914}), (7, 0.898, {'top1': 0.898}), (8, 0.9212, {'top1': 0.9212}), (9, 0.9188, {'top1': 0.9188}), (11, 0.9232, {'top1': 0.9232}), (12, 0.9238, {'top1': 0.9238}), (13, 0.911, {'top1': 0.911}), (14, 0.9182, {'top1': 0.9182}), (15, 0.9228, {'top1': 0.9228}), (16, 0.8894, {'top1': 0.8894}), (17, 0.9196, {'top1': 0.9196}), (18, 0.5162, {'top1': 0.5162}), (19, 0.9094, {'top1': 0.9094}), (20, 0.9286, {'top1': 0.9286}), (21, 0.9224, {'top1': 0.9224}), (22, 0.9254, {'top1': 0.9254}), (24, 0.9288, {'top1': 0.9288}), (27, 0.9236, {'top1': 0.9236}), (29, 0.9276, {'top1': 0.9276}), (31, 0.9326, {'top1': 0.9326}), (33, 0.9236, {'top1': 0.9236}), (34, 0.9284, {'top1': 0.9284}), (36, 0.4328, {'top1': 0.4328}), (39, 0.9224, {'top1': 0.9224}), (40, 0.9286, {'top1': 0.9286}), (46, 0.9302, {'top1': 0.9302}), (47, 0.9244, {'top1': 0.9244}), (48, 0.9308, {'top1': 0.9308}), (49, 0.9242, {'top1': 0.9242}), (50, 0.9168, {'top1': 0.9168}), (51, 0.8898, {'top1': 0.8898}), (52, 0.8698, {'top1': 0.8698}), (53, 0.6546, {'top1': 0.6546})]
just computed impact of block 31 . accuracy after removing:  0.9326
removed block 31 current accuracy 0.9326 loss from initial  0.06020000000000003
since last training loss: 0.06020000000000003 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.902, {'top1': 0.902}), (1, 0.8996, {'top1': 0.8996}), (2, 0.9054, {'top1': 0.9054}), (3, 0.9158, {'top1': 0.9158}), (5, 0.8794, {'top1': 0.8794}), (6, 0.9044, {'top1': 0.9044}), (7, 0.892, {'top1': 0.892}), (8, 0.9098, {'top1': 0.9098}), (9, 0.9138, {'top1': 0.9138}), (11, 0.9168, {'top1': 0.9168}), (12, 0.9156, {'top1': 0.9156}), (13, 0.9044, {'top1': 0.9044}), (14, 0.9108, {'top1': 0.9108}), (15, 0.9154, {'top1': 0.9154}), (16, 0.8782, {'top1': 0.8782}), (17, 0.9112, {'top1': 0.9112}), (18, 0.5378, {'top1': 0.5378}), (19, 0.8976, {'top1': 0.8976}), (20, 0.9204, {'top1': 0.9204}), (21, 0.9138, {'top1': 0.9138}), (22, 0.9154, {'top1': 0.9154}), (24, 0.9196, {'top1': 0.9196}), (27, 0.9132, {'top1': 0.9132}), (29, 0.9192, {'top1': 0.9192}), (33, 0.9134, {'top1': 0.9134}), (34, 0.9182, {'top1': 0.9182}), (36, 0.4006, {'top1': 0.4006}), (39, 0.9166, {'top1': 0.9166}), (40, 0.9234, {'top1': 0.9234}), (46, 0.9224, {'top1': 0.9224}), (47, 0.9184, {'top1': 0.9184}), (48, 0.924, {'top1': 0.924}), (49, 0.9152, {'top1': 0.9152}), (50, 0.914, {'top1': 0.914}), (51, 0.8796, {'top1': 0.8796}), (52, 0.8538, {'top1': 0.8538}), (53, 0.6498, {'top1': 0.6498})]
just computed impact of block 48 . accuracy after removing:  0.924
removed block 48 current accuracy 0.924 loss from initial  0.06879999999999997
since last training loss: 0.06879999999999997 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.8896, {'top1': 0.8896}), (1, 0.8816, {'top1': 0.8816}), (2, 0.8956, {'top1': 0.8956}), (3, 0.9046, {'top1': 0.9046}), (5, 0.8656, {'top1': 0.8656}), (6, 0.895, {'top1': 0.895}), (7, 0.885, {'top1': 0.885}), (8, 0.902, {'top1': 0.902}), (9, 0.9034, {'top1': 0.9034}), (11, 0.9056, {'top1': 0.9056}), (12, 0.9062, {'top1': 0.9062}), (13, 0.896, {'top1': 0.896}), (14, 0.9054, {'top1': 0.9054}), (15, 0.9074, {'top1': 0.9074}), (16, 0.8686, {'top1': 0.8686}), (17, 0.9004, {'top1': 0.9004}), (18, 0.5562, {'top1': 0.5562}), (19, 0.8856, {'top1': 0.8856}), (20, 0.91, {'top1': 0.91}), (21, 0.9036, {'top1': 0.9036}), (22, 0.9028, {'top1': 0.9028}), (24, 0.9108, {'top1': 0.9108}), (27, 0.9038, {'top1': 0.9038}), (29, 0.9076, {'top1': 0.9076}), (33, 0.9034, {'top1': 0.9034}), (34, 0.907, {'top1': 0.907}), (36, 0.4854, {'top1': 0.4854}), (39, 0.9022, {'top1': 0.9022}), (40, 0.9124, {'top1': 0.9124}), (46, 0.9116, {'top1': 0.9116}), (47, 0.9068, {'top1': 0.9068}), (49, 0.9066, {'top1': 0.9066}), (50, 0.9042, {'top1': 0.9042}), (51, 0.86, {'top1': 0.86}), (52, 0.8406, {'top1': 0.8406}), (53, 0.6322, {'top1': 0.6322})]
just computed impact of block 40 . accuracy after removing:  0.9124
removed block 40 current accuracy 0.9124 loss from initial  0.08040000000000003
since last training loss: 0.08040000000000003 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.8762, {'top1': 0.8762}), (1, 0.8652, {'top1': 0.8652}), (2, 0.8846, {'top1': 0.8846}), (3, 0.896, {'top1': 0.896}), (5, 0.854, {'top1': 0.854}), (6, 0.8856, {'top1': 0.8856}), (7, 0.8726, {'top1': 0.8726}), (8, 0.8918, {'top1': 0.8918}), (9, 0.8954, {'top1': 0.8954}), (11, 0.8956, {'top1': 0.8956}), (12, 0.896, {'top1': 0.896}), (13, 0.8852, {'top1': 0.8852}), (14, 0.8954, {'top1': 0.8954}), (15, 0.9004, {'top1': 0.9004}), (16, 0.8598, {'top1': 0.8598}), (17, 0.8878, {'top1': 0.8878}), (18, 0.533, {'top1': 0.533}), (19, 0.8762, {'top1': 0.8762}), (20, 0.8978, {'top1': 0.8978}), (21, 0.8918, {'top1': 0.8918}), (22, 0.8916, {'top1': 0.8916}), (24, 0.8998, {'top1': 0.8998}), (27, 0.8908, {'top1': 0.8908}), (29, 0.895, {'top1': 0.895}), (33, 0.893, {'top1': 0.893}), (34, 0.8968, {'top1': 0.8968}), (36, 0.4194, {'top1': 0.4194}), (39, 0.8854, {'top1': 0.8854}), (46, 0.8962, {'top1': 0.8962}), (47, 0.894, {'top1': 0.894}), (49, 0.8946, {'top1': 0.8946}), (50, 0.8882, {'top1': 0.8882}), (51, 0.8474, {'top1': 0.8474}), (52, 0.8162, {'top1': 0.8162}), (53, 0.619, {'top1': 0.619})]
just computed impact of block 15 . accuracy after removing:  0.9004
removed block 15 current accuracy 0.9004 loss from initial  0.09240000000000004
since last training loss: 0.09240000000000004 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.8672, {'top1': 0.8672}), (1, 0.8696, {'top1': 0.8696}), (2, 0.856, {'top1': 0.856}), (3, 0.875, {'top1': 0.875}), (5, 0.8546, {'top1': 0.8546}), (6, 0.8782, {'top1': 0.8782}), (7, 0.862, {'top1': 0.862}), (8, 0.8862, {'top1': 0.8862}), (9, 0.8638, {'top1': 0.8638}), (11, 0.8814, {'top1': 0.8814}), (12, 0.8894, {'top1': 0.8894}), (13, 0.8308, {'top1': 0.8308}), (14, 0.8418, {'top1': 0.8418}), (16, 0.7788, {'top1': 0.7788}), (17, 0.847, {'top1': 0.847}), (18, 0.4558, {'top1': 0.4558}), (19, 0.8608, {'top1': 0.8608}), (20, 0.8852, {'top1': 0.8852}), (21, 0.8772, {'top1': 0.8772}), (22, 0.8836, {'top1': 0.8836}), (24, 0.8886, {'top1': 0.8886}), (27, 0.876, {'top1': 0.876}), (29, 0.8838, {'top1': 0.8838}), (33, 0.8818, {'top1': 0.8818}), (34, 0.8852, {'top1': 0.8852}), (36, 0.3538, {'top1': 0.3538}), (39, 0.8834, {'top1': 0.8834}), (46, 0.8834, {'top1': 0.8834}), (47, 0.8836, {'top1': 0.8836}), (49, 0.8844, {'top1': 0.8844}), (50, 0.8862, {'top1': 0.8862}), (51, 0.8462, {'top1': 0.8462}), (52, 0.8234, {'top1': 0.8234}), (53, 0.5884, {'top1': 0.5884})]
just computed impact of block 12 . accuracy after removing:  0.8894
removed block 12 current accuracy 0.8894 loss from initial  0.10340000000000005
since last training loss: 0.10340000000000005 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.8572, {'top1': 0.8572}), (1, 0.8622, {'top1': 0.8622}), (2, 0.8514, {'top1': 0.8514}), (3, 0.8604, {'top1': 0.8604}), (5, 0.8336, {'top1': 0.8336}), (6, 0.8642, {'top1': 0.8642}), (7, 0.834, {'top1': 0.834}), (8, 0.8664, {'top1': 0.8664}), (9, 0.8474, {'top1': 0.8474}), (11, 0.8718, {'top1': 0.8718}), (13, 0.8214, {'top1': 0.8214}), (14, 0.8308, {'top1': 0.8308}), (16, 0.7656, {'top1': 0.7656}), (17, 0.8428, {'top1': 0.8428}), (18, 0.4622, {'top1': 0.4622}), (19, 0.853, {'top1': 0.853}), (20, 0.8742, {'top1': 0.8742}), (21, 0.8666, {'top1': 0.8666}), (22, 0.8748, {'top1': 0.8748}), (24, 0.8742, {'top1': 0.8742}), (27, 0.8606, {'top1': 0.8606}), (29, 0.8696, {'top1': 0.8696}), (33, 0.8684, {'top1': 0.8684}), (34, 0.8724, {'top1': 0.8724}), (36, 0.3638, {'top1': 0.3638}), (39, 0.8692, {'top1': 0.8692}), (46, 0.8712, {'top1': 0.8712}), (47, 0.8746, {'top1': 0.8746}), (49, 0.875, {'top1': 0.875}), (50, 0.8734, {'top1': 0.8734}), (51, 0.8304, {'top1': 0.8304}), (52, 0.806, {'top1': 0.806}), (53, 0.5898, {'top1': 0.5898})]
just computed impact of block 49 . accuracy after removing:  0.875
removed block 49 current accuracy 0.875 loss from initial  0.11780000000000002
since last training loss: 0.11780000000000002 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.843, {'top1': 0.843}), (1, 0.8492, {'top1': 0.8492}), (2, 0.8374, {'top1': 0.8374}), (3, 0.848, {'top1': 0.848}), (5, 0.8184, {'top1': 0.8184}), (6, 0.8448, {'top1': 0.8448}), (7, 0.828, {'top1': 0.828}), (8, 0.8492, {'top1': 0.8492}), (9, 0.8308, {'top1': 0.8308}), (11, 0.856, {'top1': 0.856}), (13, 0.8128, {'top1': 0.8128}), (14, 0.826, {'top1': 0.826}), (16, 0.744, {'top1': 0.744}), (17, 0.8274, {'top1': 0.8274}), (18, 0.4878, {'top1': 0.4878}), (19, 0.8316, {'top1': 0.8316}), (20, 0.852, {'top1': 0.852}), (21, 0.844, {'top1': 0.844}), (22, 0.8566, {'top1': 0.8566}), (24, 0.8568, {'top1': 0.8568}), (27, 0.8428, {'top1': 0.8428}), (29, 0.8544, {'top1': 0.8544}), (33, 0.8512, {'top1': 0.8512}), (34, 0.8562, {'top1': 0.8562}), (36, 0.433, {'top1': 0.433}), (39, 0.8508, {'top1': 0.8508}), (46, 0.857, {'top1': 0.857}), (47, 0.8564, {'top1': 0.8564}), (50, 0.8548, {'top1': 0.8548}), (51, 0.8192, {'top1': 0.8192}), (52, 0.7806, {'top1': 0.7806}), (53, 0.559, {'top1': 0.559})]
just computed impact of block 46 . accuracy after removing:  0.857
removed block 46 current accuracy 0.857 loss from initial  0.13580000000000003
since last training loss: 0.13580000000000003 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.8256, {'top1': 0.8256}), (1, 0.8328, {'top1': 0.8328}), (2, 0.8112, {'top1': 0.8112}), (3, 0.8252, {'top1': 0.8252}), (5, 0.7996, {'top1': 0.7996}), (6, 0.8266, {'top1': 0.8266}), (7, 0.8114, {'top1': 0.8114}), (8, 0.8336, {'top1': 0.8336}), (9, 0.809, {'top1': 0.809}), (11, 0.8396, {'top1': 0.8396}), (13, 0.7884, {'top1': 0.7884}), (14, 0.7996, {'top1': 0.7996}), (16, 0.7132, {'top1': 0.7132}), (17, 0.8072, {'top1': 0.8072}), (18, 0.491, {'top1': 0.491}), (19, 0.813, {'top1': 0.813}), (20, 0.8334, {'top1': 0.8334}), (21, 0.8258, {'top1': 0.8258}), (22, 0.8404, {'top1': 0.8404}), (24, 0.8374, {'top1': 0.8374}), (27, 0.8256, {'top1': 0.8256}), (29, 0.8334, {'top1': 0.8334}), (33, 0.8298, {'top1': 0.8298}), (34, 0.8318, {'top1': 0.8318}), (36, 0.4824, {'top1': 0.4824}), (39, 0.8284, {'top1': 0.8284}), (47, 0.8364, {'top1': 0.8364}), (50, 0.8362, {'top1': 0.8362}), (51, 0.7954, {'top1': 0.7954}), (52, 0.763, {'top1': 0.763}), (53, 0.541, {'top1': 0.541})]
just computed impact of block 22 . accuracy after removing:  0.8404
removed block 22 current accuracy 0.8404 loss from initial  0.15239999999999998
since last training loss: 0.15239999999999998 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.8068, {'top1': 0.8068}), (1, 0.8158, {'top1': 0.8158}), (2, 0.7926, {'top1': 0.7926}), (3, 0.8076, {'top1': 0.8076}), (5, 0.7828, {'top1': 0.7828}), (6, 0.8062, {'top1': 0.8062}), (7, 0.7866, {'top1': 0.7866}), (8, 0.8132, {'top1': 0.8132}), (9, 0.7952, {'top1': 0.7952}), (11, 0.8214, {'top1': 0.8214}), (13, 0.7698, {'top1': 0.7698}), (14, 0.7816, {'top1': 0.7816}), (16, 0.6816, {'top1': 0.6816}), (17, 0.7776, {'top1': 0.7776}), (18, 0.4986, {'top1': 0.4986}), (19, 0.7886, {'top1': 0.7886}), (20, 0.8144, {'top1': 0.8144}), (21, 0.8036, {'top1': 0.8036}), (24, 0.815, {'top1': 0.815}), (27, 0.8026, {'top1': 0.8026}), (29, 0.812, {'top1': 0.812}), (33, 0.8086, {'top1': 0.8086}), (34, 0.809, {'top1': 0.809}), (36, 0.4506, {'top1': 0.4506}), (39, 0.8094, {'top1': 0.8094}), (47, 0.8124, {'top1': 0.8124}), (50, 0.8162, {'top1': 0.8162}), (51, 0.7718, {'top1': 0.7718}), (52, 0.7348, {'top1': 0.7348}), (53, 0.5304, {'top1': 0.5304})]
just computed impact of block 11 . accuracy after removing:  0.8214
removed block 11 current accuracy 0.8214 loss from initial  0.1714
since last training loss: 0.1714 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.771, {'top1': 0.771}), (1, 0.7776, {'top1': 0.7776}), (2, 0.753, {'top1': 0.753}), (3, 0.7728, {'top1': 0.7728}), (5, 0.7614, {'top1': 0.7614}), (6, 0.782, {'top1': 0.782}), (7, 0.7486, {'top1': 0.7486}), (8, 0.779, {'top1': 0.779}), (9, 0.7204, {'top1': 0.7204}), (13, 0.7018, {'top1': 0.7018}), (14, 0.7148, {'top1': 0.7148}), (16, 0.6098, {'top1': 0.6098}), (17, 0.7302, {'top1': 0.7302}), (18, 0.4318, {'top1': 0.4318}), (19, 0.7604, {'top1': 0.7604}), (20, 0.802, {'top1': 0.802}), (21, 0.7814, {'top1': 0.7814}), (24, 0.8008, {'top1': 0.8008}), (27, 0.7922, {'top1': 0.7922}), (29, 0.8, {'top1': 0.8}), (33, 0.7942, {'top1': 0.7942}), (34, 0.7904, {'top1': 0.7904}), (36, 0.4086, {'top1': 0.4086}), (39, 0.7966, {'top1': 0.7966}), (47, 0.7918, {'top1': 0.7918}), (50, 0.7992, {'top1': 0.7992}), (51, 0.752, {'top1': 0.752}), (52, 0.7308, {'top1': 0.7308}), (53, 0.5214, {'top1': 0.5214})]
just computed impact of block 20 . accuracy after removing:  0.802
removed block 20 current accuracy 0.802 loss from initial  0.19079999999999997
since last training loss: 0.19079999999999997 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.758, {'top1': 0.758}), (1, 0.7604, {'top1': 0.7604}), (2, 0.7362, {'top1': 0.7362}), (3, 0.7582, {'top1': 0.7582}), (5, 0.7396, {'top1': 0.7396}), (6, 0.759, {'top1': 0.759}), (7, 0.7216, {'top1': 0.7216}), (8, 0.767, {'top1': 0.767}), (9, 0.7116, {'top1': 0.7116}), (13, 0.6882, {'top1': 0.6882}), (14, 0.6956, {'top1': 0.6956}), (16, 0.5938, {'top1': 0.5938}), (17, 0.7098, {'top1': 0.7098}), (18, 0.4742, {'top1': 0.4742}), (19, 0.7268, {'top1': 0.7268}), (21, 0.7548, {'top1': 0.7548}), (24, 0.7772, {'top1': 0.7772}), (27, 0.7694, {'top1': 0.7694}), (29, 0.7692, {'top1': 0.7692}), (33, 0.7686, {'top1': 0.7686}), (34, 0.7652, {'top1': 0.7652}), (36, 0.373, {'top1': 0.373}), (39, 0.7744, {'top1': 0.7744}), (47, 0.7702, {'top1': 0.7702}), (50, 0.7732, {'top1': 0.7732}), (51, 0.739, {'top1': 0.739}), (52, 0.7114, {'top1': 0.7114}), (53, 0.5166, {'top1': 0.5166})]
just computed impact of block 24 . accuracy after removing:  0.7772
removed block 24 current accuracy 0.7772 loss from initial  0.2156
since last training loss: 0.2156 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.7338, {'top1': 0.7338}), (1, 0.7368, {'top1': 0.7368}), (2, 0.7108, {'top1': 0.7108}), (3, 0.7386, {'top1': 0.7386}), (5, 0.6998, {'top1': 0.6998}), (6, 0.7332, {'top1': 0.7332}), (7, 0.692, {'top1': 0.692}), (8, 0.7358, {'top1': 0.7358}), (9, 0.6906, {'top1': 0.6906}), (13, 0.6744, {'top1': 0.6744}), (14, 0.6784, {'top1': 0.6784}), (16, 0.5724, {'top1': 0.5724}), (17, 0.6874, {'top1': 0.6874}), (18, 0.46, {'top1': 0.46}), (19, 0.7, {'top1': 0.7}), (21, 0.729, {'top1': 0.729}), (27, 0.7392, {'top1': 0.7392}), (29, 0.7442, {'top1': 0.7442}), (33, 0.7452, {'top1': 0.7452}), (34, 0.7394, {'top1': 0.7394}), (36, 0.3652, {'top1': 0.3652}), (39, 0.7468, {'top1': 0.7468}), (47, 0.7436, {'top1': 0.7436}), (50, 0.747, {'top1': 0.747}), (51, 0.7144, {'top1': 0.7144}), (52, 0.6806, {'top1': 0.6806}), (53, 0.5036, {'top1': 0.5036})]
just computed impact of block 50 . accuracy after removing:  0.747
removed block 50 current accuracy 0.747 loss from initial  0.24580000000000002
since last training loss: 0.24580000000000002 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.7002, {'top1': 0.7002}), (1, 0.7042, {'top1': 0.7042}), (2, 0.692, {'top1': 0.692}), (3, 0.7156, {'top1': 0.7156}), (5, 0.6546, {'top1': 0.6546}), (6, 0.6962, {'top1': 0.6962}), (7, 0.6548, {'top1': 0.6548}), (8, 0.707, {'top1': 0.707}), (9, 0.6734, {'top1': 0.6734}), (13, 0.66, {'top1': 0.66}), (14, 0.671, {'top1': 0.671}), (16, 0.5666, {'top1': 0.5666}), (17, 0.6824, {'top1': 0.6824}), (18, 0.3736, {'top1': 0.3736}), (19, 0.6674, {'top1': 0.6674}), (21, 0.696, {'top1': 0.696}), (27, 0.7016, {'top1': 0.7016}), (29, 0.7126, {'top1': 0.7126}), (33, 0.7076, {'top1': 0.7076}), (34, 0.7086, {'top1': 0.7086}), (36, 0.3458, {'top1': 0.3458}), (39, 0.7092, {'top1': 0.7092}), (47, 0.713, {'top1': 0.713}), (51, 0.678, {'top1': 0.678}), (52, 0.6358, {'top1': 0.6358}), (53, 0.457, {'top1': 0.457})]
just computed impact of block 3 . accuracy after removing:  0.7156
removed block 3 current accuracy 0.7156 loss from initial  0.2772
since last training loss: 0.2772 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.6542, {'top1': 0.6542}), (1, 0.6558, {'top1': 0.6558}), (2, 0.6186, {'top1': 0.6186}), (5, 0.6238, {'top1': 0.6238}), (6, 0.6334, {'top1': 0.6334}), (7, 0.5958, {'top1': 0.5958}), (8, 0.6736, {'top1': 0.6736}), (9, 0.6062, {'top1': 0.6062}), (13, 0.6034, {'top1': 0.6034}), (14, 0.5992, {'top1': 0.5992}), (16, 0.4954, {'top1': 0.4954}), (17, 0.6274, {'top1': 0.6274}), (18, 0.3686, {'top1': 0.3686}), (19, 0.6302, {'top1': 0.6302}), (21, 0.6572, {'top1': 0.6572}), (27, 0.668, {'top1': 0.668}), (29, 0.6854, {'top1': 0.6854}), (33, 0.6788, {'top1': 0.6788}), (34, 0.6792, {'top1': 0.6792}), (36, 0.3366, {'top1': 0.3366}), (39, 0.678, {'top1': 0.678}), (47, 0.6774, {'top1': 0.6774}), (51, 0.6422, {'top1': 0.6422}), (52, 0.6192, {'top1': 0.6192}), (53, 0.444, {'top1': 0.444})]
just computed impact of block 29 . accuracy after removing:  0.6854
removed block 29 current accuracy 0.6854 loss from initial  0.3074
since last training loss: 0.3074 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.6214, {'top1': 0.6214}), (1, 0.6266, {'top1': 0.6266}), (2, 0.587, {'top1': 0.587}), (5, 0.5906, {'top1': 0.5906}), (6, 0.6028, {'top1': 0.6028}), (7, 0.5624, {'top1': 0.5624}), (8, 0.644, {'top1': 0.644}), (9, 0.5722, {'top1': 0.5722}), (13, 0.577, {'top1': 0.577}), (14, 0.568, {'top1': 0.568}), (16, 0.4666, {'top1': 0.4666}), (17, 0.591, {'top1': 0.591}), (18, 0.3454, {'top1': 0.3454}), (19, 0.5974, {'top1': 0.5974}), (21, 0.6166, {'top1': 0.6166}), (27, 0.6358, {'top1': 0.6358}), (33, 0.6458, {'top1': 0.6458}), (34, 0.6418, {'top1': 0.6418}), (36, 0.3204, {'top1': 0.3204}), (39, 0.6508, {'top1': 0.6508}), (47, 0.6458, {'top1': 0.6458}), (51, 0.5996, {'top1': 0.5996}), (52, 0.5862, {'top1': 0.5862}), (53, 0.4386, {'top1': 0.4386})]
just computed impact of block 39 . accuracy after removing:  0.6508
removed block 39 current accuracy 0.6508 loss from initial  0.34199999999999997
since last training loss: 0.34199999999999997 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.5968, {'top1': 0.5968}), (1, 0.6012, {'top1': 0.6012}), (2, 0.5674, {'top1': 0.5674}), (5, 0.5458, {'top1': 0.5458}), (6, 0.5714, {'top1': 0.5714}), (7, 0.5498, {'top1': 0.5498}), (8, 0.6094, {'top1': 0.6094}), (9, 0.5574, {'top1': 0.5574}), (13, 0.5548, {'top1': 0.5548}), (14, 0.5486, {'top1': 0.5486}), (16, 0.4518, {'top1': 0.4518}), (17, 0.5606, {'top1': 0.5606}), (18, 0.3356, {'top1': 0.3356}), (19, 0.5668, {'top1': 0.5668}), (21, 0.5834, {'top1': 0.5834}), (27, 0.5994, {'top1': 0.5994}), (33, 0.6054, {'top1': 0.6054}), (34, 0.6062, {'top1': 0.6062}), (36, 0.2844, {'top1': 0.2844}), (47, 0.612, {'top1': 0.612}), (51, 0.5506, {'top1': 0.5506}), (52, 0.5336, {'top1': 0.5336}), (53, 0.4158, {'top1': 0.4158})]
just computed impact of block 47 . accuracy after removing:  0.612
removed block 47 current accuracy 0.612 loss from initial  0.3808
since last training loss: 0.3808 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.5586, {'top1': 0.5586}), (1, 0.5574, {'top1': 0.5574}), (2, 0.5308, {'top1': 0.5308}), (5, 0.5106, {'top1': 0.5106}), (6, 0.5366, {'top1': 0.5366}), (7, 0.53, {'top1': 0.53}), (8, 0.5666, {'top1': 0.5666}), (9, 0.512, {'top1': 0.512}), (13, 0.5148, {'top1': 0.5148}), (14, 0.5096, {'top1': 0.5096}), (16, 0.4198, {'top1': 0.4198}), (17, 0.516, {'top1': 0.516}), (18, 0.3472, {'top1': 0.3472}), (19, 0.5302, {'top1': 0.5302}), (21, 0.5462, {'top1': 0.5462}), (27, 0.5486, {'top1': 0.5486}), (33, 0.5608, {'top1': 0.5608}), (34, 0.5574, {'top1': 0.5574}), (36, 0.2964, {'top1': 0.2964}), (51, 0.5056, {'top1': 0.5056}), (52, 0.503, {'top1': 0.503}), (53, 0.3982, {'top1': 0.3982})]
just computed impact of block 8 . accuracy after removing:  0.5666
removed block 8 current accuracy 0.5666 loss from initial  0.4262
since last training loss: 0.4262 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.5078, {'top1': 0.5078}), (1, 0.4942, {'top1': 0.4942}), (2, 0.4982, {'top1': 0.4982}), (5, 0.4488, {'top1': 0.4488}), (6, 0.48, {'top1': 0.48}), (7, 0.452, {'top1': 0.452}), (9, 0.4552, {'top1': 0.4552}), (13, 0.4838, {'top1': 0.4838}), (14, 0.453, {'top1': 0.453}), (16, 0.3802, {'top1': 0.3802}), (17, 0.484, {'top1': 0.484}), (18, 0.325, {'top1': 0.325}), (19, 0.4844, {'top1': 0.4844}), (21, 0.5108, {'top1': 0.5108}), (27, 0.514, {'top1': 0.514}), (33, 0.5264, {'top1': 0.5264}), (34, 0.5168, {'top1': 0.5168}), (36, 0.259, {'top1': 0.259}), (51, 0.4604, {'top1': 0.4604}), (52, 0.4632, {'top1': 0.4632}), (53, 0.3618, {'top1': 0.3618})]
just computed impact of block 33 . accuracy after removing:  0.5264
removed block 33 current accuracy 0.5264 loss from initial  0.46640000000000004
since last training loss: 0.46640000000000004 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.471, {'top1': 0.471}), (1, 0.4628, {'top1': 0.4628}), (2, 0.4628, {'top1': 0.4628}), (5, 0.416, {'top1': 0.416}), (6, 0.4414, {'top1': 0.4414}), (7, 0.4142, {'top1': 0.4142}), (9, 0.4238, {'top1': 0.4238}), (13, 0.4598, {'top1': 0.4598}), (14, 0.4184, {'top1': 0.4184}), (16, 0.3542, {'top1': 0.3542}), (17, 0.45, {'top1': 0.45}), (18, 0.325, {'top1': 0.325}), (19, 0.4472, {'top1': 0.4472}), (21, 0.4726, {'top1': 0.4726}), (27, 0.474, {'top1': 0.474}), (34, 0.4836, {'top1': 0.4836}), (36, 0.2566, {'top1': 0.2566}), (51, 0.4206, {'top1': 0.4206}), (52, 0.4326, {'top1': 0.4326}), (53, 0.3538, {'top1': 0.3538})]
just computed impact of block 34 . accuracy after removing:  0.4836
removed block 34 current accuracy 0.4836 loss from initial  0.5092000000000001
since last training loss: 0.5092000000000001 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.4346, {'top1': 0.4346}), (1, 0.4172, {'top1': 0.4172}), (2, 0.4276, {'top1': 0.4276}), (5, 0.3856, {'top1': 0.3856}), (6, 0.4188, {'top1': 0.4188}), (7, 0.3924, {'top1': 0.3924}), (9, 0.3884, {'top1': 0.3884}), (13, 0.4168, {'top1': 0.4168}), (14, 0.3902, {'top1': 0.3902}), (16, 0.3294, {'top1': 0.3294}), (17, 0.4136, {'top1': 0.4136}), (18, 0.3302, {'top1': 0.3302}), (19, 0.4174, {'top1': 0.4174}), (21, 0.4388, {'top1': 0.4388}), (27, 0.4322, {'top1': 0.4322}), (36, 0.2488, {'top1': 0.2488}), (51, 0.3744, {'top1': 0.3744}), (52, 0.3894, {'top1': 0.3894}), (53, 0.347, {'top1': 0.347})]
just computed impact of block 21 . accuracy after removing:  0.4388
removed block 21 current accuracy 0.4388 loss from initial  0.554
since last training loss: 0.554 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.4042, {'top1': 0.4042}), (1, 0.3944, {'top1': 0.3944}), (2, 0.3822, {'top1': 0.3822}), (5, 0.3622, {'top1': 0.3622}), (6, 0.3724, {'top1': 0.3724}), (7, 0.342, {'top1': 0.342}), (9, 0.348, {'top1': 0.348}), (13, 0.3836, {'top1': 0.3836}), (14, 0.3346, {'top1': 0.3346}), (16, 0.2932, {'top1': 0.2932}), (17, 0.3744, {'top1': 0.3744}), (18, 0.322, {'top1': 0.322}), (19, 0.388, {'top1': 0.388}), (27, 0.3908, {'top1': 0.3908}), (36, 0.2496, {'top1': 0.2496}), (51, 0.3346, {'top1': 0.3346}), (52, 0.3626, {'top1': 0.3626}), (53, 0.3196, {'top1': 0.3196})]
just computed impact of block 0 . accuracy after removing:  0.4042
removed block 0 current accuracy 0.4042 loss from initial  0.5886
since last training loss: 0.5886 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(1, 0.2636, {'top1': 0.2636}), (2, 0.3428, {'top1': 0.3428}), (5, 0.2958, {'top1': 0.2958}), (6, 0.354, {'top1': 0.354}), (7, 0.342, {'top1': 0.342}), (9, 0.3406, {'top1': 0.3406}), (13, 0.3618, {'top1': 0.3618}), (14, 0.3244, {'top1': 0.3244}), (16, 0.3056, {'top1': 0.3056}), (17, 0.3638, {'top1': 0.3638}), (18, 0.3206, {'top1': 0.3206}), (19, 0.3586, {'top1': 0.3586}), (27, 0.3738, {'top1': 0.3738}), (36, 0.2302, {'top1': 0.2302}), (51, 0.309, {'top1': 0.309}), (52, 0.3184, {'top1': 0.3184}), (53, 0.2938, {'top1': 0.2938})]
just computed impact of block 27 . accuracy after removing:  0.3738
removed block 27 current accuracy 0.3738 loss from initial  0.619
since last training loss: 0.619 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(1, 0.2618, {'top1': 0.2618}), (2, 0.325, {'top1': 0.325}), (5, 0.283, {'top1': 0.283}), (6, 0.3258, {'top1': 0.3258}), (7, 0.3048, {'top1': 0.3048}), (9, 0.3302, {'top1': 0.3302}), (13, 0.3498, {'top1': 0.3498}), (14, 0.3016, {'top1': 0.3016}), (16, 0.2928, {'top1': 0.2928}), (17, 0.3476, {'top1': 0.3476}), (18, 0.3166, {'top1': 0.3166}), (19, 0.3352, {'top1': 0.3352}), (36, 0.237, {'top1': 0.237}), (51, 0.2826, {'top1': 0.2826}), (52, 0.298, {'top1': 0.298}), (53, 0.2738, {'top1': 0.2738})]
just computed impact of block 13 . accuracy after removing:  0.3498
removed block 13 current accuracy 0.3498 loss from initial  0.643
since last training loss: 0.643 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(1, 0.2342, {'top1': 0.2342}), (2, 0.2818, {'top1': 0.2818}), (5, 0.2672, {'top1': 0.2672}), (6, 0.3192, {'top1': 0.3192}), (7, 0.3182, {'top1': 0.3182}), (9, 0.261, {'top1': 0.261}), (14, 0.2542, {'top1': 0.2542}), (16, 0.2292, {'top1': 0.2292}), (17, 0.2832, {'top1': 0.2832}), (18, 0.2784, {'top1': 0.2784}), (19, 0.3056, {'top1': 0.3056}), (36, 0.1786, {'top1': 0.1786}), (51, 0.3178, {'top1': 0.3178}), (52, 0.2896, {'top1': 0.2896}), (53, 0.2614, {'top1': 0.2614})]
just computed impact of block 6 . accuracy after removing:  0.3192
removed block 6 current accuracy 0.3192 loss from initial  0.6736
since last training loss: 0.6736 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(1, 0.2364, {'top1': 0.2364}), (2, 0.2526, {'top1': 0.2526}), (5, 0.2646, {'top1': 0.2646}), (7, 0.2386, {'top1': 0.2386}), (9, 0.2536, {'top1': 0.2536}), (14, 0.23, {'top1': 0.23}), (16, 0.222, {'top1': 0.222}), (17, 0.276, {'top1': 0.276}), (18, 0.241, {'top1': 0.241}), (19, 0.2872, {'top1': 0.2872}), (36, 0.1908, {'top1': 0.1908}), (51, 0.3102, {'top1': 0.3102}), (52, 0.2916, {'top1': 0.2916}), (53, 0.2154, {'top1': 0.2154})]
just computed impact of block 51 . accuracy after removing:  0.3102
removed block 51 current accuracy 0.3102 loss from initial  0.6826000000000001
since last training loss: 0.6826000000000001 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(1, 0.2088, {'top1': 0.2088}), (2, 0.2484, {'top1': 0.2484}), (5, 0.2392, {'top1': 0.2392}), (7, 0.2424, {'top1': 0.2424}), (9, 0.2532, {'top1': 0.2532}), (14, 0.245, {'top1': 0.245}), (16, 0.2466, {'top1': 0.2466}), (17, 0.2802, {'top1': 0.2802}), (18, 0.1994, {'top1': 0.1994}), (19, 0.2704, {'top1': 0.2704}), (36, 0.2794, {'top1': 0.2794}), (52, 0.2336, {'top1': 0.2336}), (53, 0.1956, {'top1': 0.1956})]
just computed impact of block 17 . accuracy after removing:  0.2802
removed block 17 current accuracy 0.2802 loss from initial  0.7126
since last training loss: 0.7126 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(1, 0.2102, {'top1': 0.2102}), (2, 0.2258, {'top1': 0.2258}), (5, 0.256, {'top1': 0.256}), (7, 0.234, {'top1': 0.234}), (9, 0.223, {'top1': 0.223}), (14, 0.2212, {'top1': 0.2212}), (16, 0.225, {'top1': 0.225}), (18, 0.2222, {'top1': 0.2222}), (19, 0.2726, {'top1': 0.2726}), (36, 0.2702, {'top1': 0.2702}), (52, 0.2374, {'top1': 0.2374}), (53, 0.1908, {'top1': 0.1908})]
just computed impact of block 19 . accuracy after removing:  0.2726
removed block 19 current accuracy 0.2726 loss from initial  0.7202
since last training loss: 0.7202 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(1, 0.1788, {'top1': 0.1788}), (2, 0.2314, {'top1': 0.2314}), (5, 0.2284, {'top1': 0.2284}), (7, 0.2216, {'top1': 0.2216}), (9, 0.2284, {'top1': 0.2284}), (14, 0.2232, {'top1': 0.2232}), (16, 0.2188, {'top1': 0.2188}), (18, 0.185, {'top1': 0.185}), (36, 0.2976, {'top1': 0.2976}), (52, 0.2288, {'top1': 0.2288}), (53, 0.1754, {'top1': 0.1754})]
just computed impact of block 36 . accuracy after removing:  0.2976
removed block 36 current accuracy 0.2976 loss from initial  0.6952
since last training loss: 0.6952 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(1, 0.265, {'top1': 0.265}), (2, 0.2252, {'top1': 0.2252}), (5, 0.279, {'top1': 0.279}), (7, 0.2348, {'top1': 0.2348}), (9, 0.2512, {'top1': 0.2512}), (14, 0.2034, {'top1': 0.2034}), (16, 0.2032, {'top1': 0.2032}), (18, 0.1076, {'top1': 0.1076}), (52, 0.2096, {'top1': 0.2096}), (53, 0.1832, {'top1': 0.1832})]
just computed impact of block 5 . accuracy after removing:  0.279
removed block 5 current accuracy 0.279 loss from initial  0.7138
training start
training epoch 0 val accuracy 0.7164 topk_dict {'top1': 0.7164} is_best True lr [0.1]
training epoch 1 val accuracy 0.7482 topk_dict {'top1': 0.7482} is_best True lr [0.1]
training epoch 2 val accuracy 0.7744 topk_dict {'top1': 0.7744} is_best True lr [0.1]
training epoch 3 val accuracy 0.8054 topk_dict {'top1': 0.8054} is_best True lr [0.1]
training epoch 4 val accuracy 0.792 topk_dict {'top1': 0.792} is_best False lr [0.1]
training epoch 5 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.1]
training epoch 6 val accuracy 0.835 topk_dict {'top1': 0.835} is_best False lr [0.1]
training epoch 7 val accuracy 0.799 topk_dict {'top1': 0.799} is_best False lr [0.1]
training epoch 8 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 9 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best False lr [0.1]
training epoch 10 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best False lr [0.1]
training epoch 11 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best True lr [0.1]
training epoch 12 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.1]
training epoch 13 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best True lr [0.1]
training epoch 14 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 15 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 16 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best False lr [0.1]
training epoch 17 val accuracy 0.8126 topk_dict {'top1': 0.8126} is_best False lr [0.1]
training epoch 18 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 19 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 20 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best False lr [0.1]
training epoch 21 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 22 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best False lr [0.1]
training epoch 23 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 24 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 25 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 26 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 27 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 28 val accuracy 0.821 topk_dict {'top1': 0.821} is_best False lr [0.1]
training epoch 29 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 30 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 31 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 32 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 33 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 34 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 35 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 36 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 37 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.1]
training epoch 38 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 39 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 40 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 41 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best False lr [0.1]
training epoch 42 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 43 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 44 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 45 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 46 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best False lr [0.1]
training epoch 47 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 48 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 49 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.1]
training epoch 50 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 51 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 52 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 53 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 54 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best False lr [0.1]
training epoch 55 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 56 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 57 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 58 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 59 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 60 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best False lr [0.1]
training epoch 61 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 62 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 63 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 64 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 65 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 66 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.1]
training epoch 67 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 68 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best False lr [0.1]
training epoch 69 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 70 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 71 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 72 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 73 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 74 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 75 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 76 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 77 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 78 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 79 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 80 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 81 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.1]
training epoch 82 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 83 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 84 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 85 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 86 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 87 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 88 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 89 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 90 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 91 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 92 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 93 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 94 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 95 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 96 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 97 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 98 val accuracy 0.8246 topk_dict {'top1': 0.8246} is_best False lr [0.1]
training epoch 99 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 100 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 101 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best True lr [0.1]
training epoch 102 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 103 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 104 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 105 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.1]
training epoch 106 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 107 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 108 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 109 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 110 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 111 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 112 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 113 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 114 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 115 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 116 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 117 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 118 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 119 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 120 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 121 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 122 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 123 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 124 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.010000000000000002]
training epoch 125 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.010000000000000002]
training epoch 126 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.010000000000000002]
training epoch 127 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.010000000000000002]
training epoch 128 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.010000000000000002]
training epoch 129 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 130 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 131 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 132 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.010000000000000002]
training epoch 133 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.010000000000000002]
training epoch 134 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.010000000000000002]
training epoch 135 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.010000000000000002]
training epoch 136 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.010000000000000002]
training epoch 137 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.010000000000000002]
training epoch 138 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 139 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.010000000000000002]
training epoch 140 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.010000000000000002]
training epoch 141 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.010000000000000002]
training epoch 142 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.010000000000000002]
training epoch 143 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.010000000000000002]
training epoch 144 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 145 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.010000000000000002]
training epoch 146 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.010000000000000002]
training epoch 147 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 148 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.010000000000000002]
training epoch 149 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 150 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 151 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.010000000000000002]
training epoch 152 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 153 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 154 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.010000000000000002]
training epoch 155 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.010000000000000002]
training epoch 156 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 157 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.010000000000000002]
training epoch 158 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 159 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.010000000000000002]
training epoch 160 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.010000000000000002]
training epoch 161 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 162 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.010000000000000002]
training epoch 163 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 164 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.010000000000000002]
training epoch 165 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.010000000000000002]
training epoch 166 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 167 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.010000000000000002]
training epoch 168 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.010000000000000002]
training epoch 169 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.010000000000000002]
training epoch 170 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.010000000000000002]
training epoch 171 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 172 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.010000000000000002]
training epoch 173 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 174 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 175 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.010000000000000002]
training epoch 176 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 177 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 178 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.010000000000000002]
training epoch 179 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.010000000000000002]
training epoch 180 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.010000000000000002]
training epoch 181 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.010000000000000002]
training epoch 182 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 183 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 184 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.010000000000000002]
training epoch 185 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.010000000000000002]
training epoch 186 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 187 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 188 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 189 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 190 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 191 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 192 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 193 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 194 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 195 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 196 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 197 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 198 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 199 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 200 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 201 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 202 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 203 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 204 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 205 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 206 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 207 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 208 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 209 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 210 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 211 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 212 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.0010000000000000002]
training epoch 213 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 214 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 215 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 216 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 217 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 218 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.0010000000000000002]
training epoch 219 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 220 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 221 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 222 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 223 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.0010000000000000002]
training epoch 224 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 225 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 226 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 227 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.0010000000000000002]
training epoch 228 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 229 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 230 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 231 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 232 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 233 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 234 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 235 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 236 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 237 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 238 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 239 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 240 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 241 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 242 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 243 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 244 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 245 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 246 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 247 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.0010000000000000002]
training epoch 248 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
loading model_best from epoch 142 (acc 0.912000)
finished training. finished 249 epochs. accuracy 0.912 topk_dict {'top1': 0.912}
