start iteration 0
(cache recomputed) Accuracy log [(0, 0.148, {'top1': 0.148}), (1, 0.17, {'top1': 0.17}), (2, 0.1822, {'top1': 0.1822}), (3, 0.184, {'top1': 0.184}), (4, 0.1842, {'top1': 0.1842}), (5, 0.1834, {'top1': 0.1834}), (6, 0.186, {'top1': 0.186}), (7, 0.1894, {'top1': 0.1894}), (8, 0.1858, {'top1': 0.1858}), (9, 0.1824, {'top1': 0.1824}), (10, 0.1832, {'top1': 0.1832}), (11, 0.1862, {'top1': 0.1862}), (12, 0.1868, {'top1': 0.1868}), (13, 0.187, {'top1': 0.187}), (14, 0.1826, {'top1': 0.1826}), (15, 0.186, {'top1': 0.186}), (16, 0.1824, {'top1': 0.1824}), (17, 0.1824, {'top1': 0.1824}), (18, 0.1804, {'top1': 0.1804}), (19, 0.1798, {'top1': 0.1798}), (20, 0.1902, {'top1': 0.1902}), (21, 0.1878, {'top1': 0.1878}), (22, 0.189, {'top1': 0.189}), (23, 0.1816, {'top1': 0.1816}), (24, 0.1818, {'top1': 0.1818}), (25, 0.1826, {'top1': 0.1826}), (26, 0.1906, {'top1': 0.1906}), (27, 0.1854, {'top1': 0.1854}), (28, 0.186, {'top1': 0.186}), (29, 0.1852, {'top1': 0.1852}), (30, 0.1818, {'top1': 0.1818}), (31, 0.183, {'top1': 0.183}), (32, 0.1866, {'top1': 0.1866}), (33, 0.1868, {'top1': 0.1868}), (34, 0.1928, {'top1': 0.1928}), (35, 0.1834, {'top1': 0.1834}), (36, 0.1782, {'top1': 0.1782}), (37, 0.1822, {'top1': 0.1822}), (38, 0.1858, {'top1': 0.1858}), (39, 0.1848, {'top1': 0.1848}), (40, 0.1842, {'top1': 0.1842}), (41, 0.1826, {'top1': 0.1826}), (42, 0.1822, {'top1': 0.1822}), (43, 0.1838, {'top1': 0.1838}), (44, 0.1822, {'top1': 0.1822}), (45, 0.1838, {'top1': 0.1838}), (46, 0.1866, {'top1': 0.1866}), (47, 0.1796, {'top1': 0.1796}), (48, 0.1856, {'top1': 0.1856}), (49, 0.1838, {'top1': 0.1838}), (50, 0.1854, {'top1': 0.1854}), (51, 0.1846, {'top1': 0.1846}), (52, 0.1848, {'top1': 0.1848}), (53, 0.1388, {'top1': 0.1388})]
just computed impact of block 34 . accuracy after removing:  0.1928
removed block 34 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.1676, {'top1': 0.1676}), (1, 0.1792, {'top1': 0.1792}), (2, 0.1826, {'top1': 0.1826}), (3, 0.1866, {'top1': 0.1866}), (4, 0.1898, {'top1': 0.1898}), (5, 0.189, {'top1': 0.189}), (6, 0.1912, {'top1': 0.1912}), (7, 0.1926, {'top1': 0.1926}), (8, 0.1844, {'top1': 0.1844}), (9, 0.191, {'top1': 0.191}), (10, 0.1878, {'top1': 0.1878}), (11, 0.189, {'top1': 0.189}), (12, 0.1868, {'top1': 0.1868}), (13, 0.1932, {'top1': 0.1932}), (14, 0.19, {'top1': 0.19}), (15, 0.1918, {'top1': 0.1918}), (16, 0.1876, {'top1': 0.1876}), (17, 0.1888, {'top1': 0.1888}), (18, 0.143, {'top1': 0.143}), (19, 0.1868, {'top1': 0.1868}), (20, 0.1836, {'top1': 0.1836}), (21, 0.1826, {'top1': 0.1826}), (22, 0.1836, {'top1': 0.1836}), (23, 0.1862, {'top1': 0.1862}), (24, 0.1846, {'top1': 0.1846}), (25, 0.1904, {'top1': 0.1904}), (26, 0.1674, {'top1': 0.1674}), (27, 0.1922, {'top1': 0.1922}), (28, 0.1884, {'top1': 0.1884}), (29, 0.1912, {'top1': 0.1912}), (30, 0.1888, {'top1': 0.1888}), (31, 0.188, {'top1': 0.188}), (32, 0.1906, {'top1': 0.1906}), (33, 0.1916, {'top1': 0.1916}), (35, 0.1898, {'top1': 0.1898}), (36, 0.18, {'top1': 0.18}), (37, 0.1886, {'top1': 0.1886}), (38, 0.1928, {'top1': 0.1928}), (39, 0.1894, {'top1': 0.1894}), (40, 0.189, {'top1': 0.189}), (41, 0.1872, {'top1': 0.1872}), (42, 0.1864, {'top1': 0.1864}), (43, 0.1902, {'top1': 0.1902}), (44, 0.187, {'top1': 0.187}), (45, 0.187, {'top1': 0.187}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1858, {'top1': 0.1858}), (48, 0.1884, {'top1': 0.1884}), (49, 0.1898, {'top1': 0.1898}), (50, 0.1894, {'top1': 0.1894}), (51, 0.192, {'top1': 0.192}), (52, 0.1926, {'top1': 0.1926}), (53, 0.1362, {'top1': 0.1362})]
just computed impact of block 13 . accuracy after removing:  0.1932
removed block 13 current accuracy 0.1932 loss from initial  -0.008400000000000019
since last training loss: -0.008400000000000019 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.172, {'top1': 0.172}), (1, 0.1788, {'top1': 0.1788}), (2, 0.1828, {'top1': 0.1828}), (3, 0.1828, {'top1': 0.1828}), (4, 0.1876, {'top1': 0.1876}), (5, 0.1906, {'top1': 0.1906}), (6, 0.183, {'top1': 0.183}), (7, 0.1854, {'top1': 0.1854}), (8, 0.1806, {'top1': 0.1806}), (9, 0.1902, {'top1': 0.1902}), (10, 0.1894, {'top1': 0.1894}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1828, {'top1': 0.1828}), (14, 0.1896, {'top1': 0.1896}), (15, 0.1904, {'top1': 0.1904}), (16, 0.19, {'top1': 0.19}), (17, 0.19, {'top1': 0.19}), (18, 0.1396, {'top1': 0.1396}), (19, 0.1828, {'top1': 0.1828}), (20, 0.1812, {'top1': 0.1812}), (21, 0.1764, {'top1': 0.1764}), (22, 0.181, {'top1': 0.181}), (23, 0.1842, {'top1': 0.1842}), (24, 0.1874, {'top1': 0.1874}), (25, 0.1924, {'top1': 0.1924}), (26, 0.1626, {'top1': 0.1626}), (27, 0.1926, {'top1': 0.1926}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1868, {'top1': 0.1868}), (30, 0.1898, {'top1': 0.1898}), (31, 0.1876, {'top1': 0.1876}), (32, 0.1904, {'top1': 0.1904}), (33, 0.1936, {'top1': 0.1936}), (35, 0.1906, {'top1': 0.1906}), (36, 0.1746, {'top1': 0.1746}), (37, 0.185, {'top1': 0.185}), (38, 0.1906, {'top1': 0.1906}), (39, 0.189, {'top1': 0.189}), (40, 0.19, {'top1': 0.19}), (41, 0.1888, {'top1': 0.1888}), (42, 0.1878, {'top1': 0.1878}), (43, 0.1884, {'top1': 0.1884}), (44, 0.1874, {'top1': 0.1874}), (45, 0.1902, {'top1': 0.1902}), (46, 0.1904, {'top1': 0.1904}), (47, 0.1868, {'top1': 0.1868}), (48, 0.1922, {'top1': 0.1922}), (49, 0.1916, {'top1': 0.1916}), (50, 0.191, {'top1': 0.191}), (51, 0.193, {'top1': 0.193}), (52, 0.1912, {'top1': 0.1912}), (53, 0.1364, {'top1': 0.1364})]
just computed impact of block 33 . accuracy after removing:  0.1936
removed block 33 current accuracy 0.1936 loss from initial  -0.008800000000000002
since last training loss: -0.008800000000000002 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.1744, {'top1': 0.1744}), (1, 0.1782, {'top1': 0.1782}), (2, 0.1834, {'top1': 0.1834}), (3, 0.1838, {'top1': 0.1838}), (4, 0.1856, {'top1': 0.1856}), (5, 0.1892, {'top1': 0.1892}), (6, 0.1798, {'top1': 0.1798}), (7, 0.1856, {'top1': 0.1856}), (8, 0.1794, {'top1': 0.1794}), (9, 0.1926, {'top1': 0.1926}), (10, 0.19, {'top1': 0.19}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1822, {'top1': 0.1822}), (14, 0.1916, {'top1': 0.1916}), (15, 0.189, {'top1': 0.189}), (16, 0.1894, {'top1': 0.1894}), (17, 0.1884, {'top1': 0.1884}), (18, 0.1348, {'top1': 0.1348}), (19, 0.179, {'top1': 0.179}), (20, 0.182, {'top1': 0.182}), (21, 0.1744, {'top1': 0.1744}), (22, 0.1796, {'top1': 0.1796}), (23, 0.185, {'top1': 0.185}), (24, 0.1906, {'top1': 0.1906}), (25, 0.1924, {'top1': 0.1924}), (26, 0.1572, {'top1': 0.1572}), (27, 0.192, {'top1': 0.192}), (28, 0.1898, {'top1': 0.1898}), (29, 0.187, {'top1': 0.187}), (30, 0.188, {'top1': 0.188}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1864, {'top1': 0.1864}), (35, 0.1926, {'top1': 0.1926}), (36, 0.1758, {'top1': 0.1758}), (37, 0.1856, {'top1': 0.1856}), (38, 0.19, {'top1': 0.19}), (39, 0.1894, {'top1': 0.1894}), (40, 0.1916, {'top1': 0.1916}), (41, 0.19, {'top1': 0.19}), (42, 0.1894, {'top1': 0.1894}), (43, 0.1878, {'top1': 0.1878}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1904, {'top1': 0.1904}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1878, {'top1': 0.1878}), (48, 0.193, {'top1': 0.193}), (49, 0.1934, {'top1': 0.1934}), (50, 0.1912, {'top1': 0.1912}), (51, 0.1896, {'top1': 0.1896}), (52, 0.1916, {'top1': 0.1916}), (53, 0.1358, {'top1': 0.1358})]
just computed impact of block 49 . accuracy after removing:  0.1934
removed block 49 current accuracy 0.1934 loss from initial  -0.008599999999999997
since last training loss: -0.008599999999999997 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.177, {'top1': 0.177}), (1, 0.1794, {'top1': 0.1794}), (2, 0.1808, {'top1': 0.1808}), (3, 0.1822, {'top1': 0.1822}), (4, 0.1848, {'top1': 0.1848}), (5, 0.1892, {'top1': 0.1892}), (6, 0.182, {'top1': 0.182}), (7, 0.1856, {'top1': 0.1856}), (8, 0.179, {'top1': 0.179}), (9, 0.1938, {'top1': 0.1938}), (10, 0.192, {'top1': 0.192}), (11, 0.1834, {'top1': 0.1834}), (12, 0.1832, {'top1': 0.1832}), (14, 0.193, {'top1': 0.193}), (15, 0.1884, {'top1': 0.1884}), (16, 0.1894, {'top1': 0.1894}), (17, 0.185, {'top1': 0.185}), (18, 0.1294, {'top1': 0.1294}), (19, 0.1792, {'top1': 0.1792}), (20, 0.1764, {'top1': 0.1764}), (21, 0.173, {'top1': 0.173}), (22, 0.1784, {'top1': 0.1784}), (23, 0.1826, {'top1': 0.1826}), (24, 0.1914, {'top1': 0.1914}), (25, 0.1926, {'top1': 0.1926}), (26, 0.1498, {'top1': 0.1498}), (27, 0.1932, {'top1': 0.1932}), (28, 0.1908, {'top1': 0.1908}), (29, 0.1858, {'top1': 0.1858}), (30, 0.1864, {'top1': 0.1864}), (31, 0.189, {'top1': 0.189}), (32, 0.185, {'top1': 0.185}), (35, 0.1926, {'top1': 0.1926}), (36, 0.1752, {'top1': 0.1752}), (37, 0.1828, {'top1': 0.1828}), (38, 0.1894, {'top1': 0.1894}), (39, 0.1884, {'top1': 0.1884}), (40, 0.1924, {'top1': 0.1924}), (41, 0.1912, {'top1': 0.1912}), (42, 0.1896, {'top1': 0.1896}), (43, 0.1868, {'top1': 0.1868}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1904, {'top1': 0.1904}), (46, 0.19, {'top1': 0.19}), (47, 0.1868, {'top1': 0.1868}), (48, 0.1916, {'top1': 0.1916}), (50, 0.1896, {'top1': 0.1896}), (51, 0.1898, {'top1': 0.1898}), (52, 0.192, {'top1': 0.192}), (53, 0.1372, {'top1': 0.1372})]
just computed impact of block 9 . accuracy after removing:  0.1938
removed block 9 current accuracy 0.1938 loss from initial  -0.009000000000000008
since last training loss: -0.009000000000000008 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.171, {'top1': 0.171}), (1, 0.1818, {'top1': 0.1818}), (2, 0.1818, {'top1': 0.1818}), (3, 0.1812, {'top1': 0.1812}), (4, 0.1838, {'top1': 0.1838}), (5, 0.1886, {'top1': 0.1886}), (6, 0.1828, {'top1': 0.1828}), (7, 0.184, {'top1': 0.184}), (8, 0.179, {'top1': 0.179}), (10, 0.1896, {'top1': 0.1896}), (11, 0.184, {'top1': 0.184}), (12, 0.1816, {'top1': 0.1816}), (14, 0.1924, {'top1': 0.1924}), (15, 0.1876, {'top1': 0.1876}), (16, 0.189, {'top1': 0.189}), (17, 0.184, {'top1': 0.184}), (18, 0.126, {'top1': 0.126}), (19, 0.1796, {'top1': 0.1796}), (20, 0.1772, {'top1': 0.1772}), (21, 0.1716, {'top1': 0.1716}), (22, 0.1782, {'top1': 0.1782}), (23, 0.186, {'top1': 0.186}), (24, 0.1894, {'top1': 0.1894}), (25, 0.1922, {'top1': 0.1922}), (26, 0.1484, {'top1': 0.1484}), (27, 0.1938, {'top1': 0.1938}), (28, 0.1902, {'top1': 0.1902}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1868, {'top1': 0.1868}), (31, 0.1898, {'top1': 0.1898}), (32, 0.1866, {'top1': 0.1866}), (35, 0.192, {'top1': 0.192}), (36, 0.177, {'top1': 0.177}), (37, 0.1848, {'top1': 0.1848}), (38, 0.1892, {'top1': 0.1892}), (39, 0.1872, {'top1': 0.1872}), (40, 0.191, {'top1': 0.191}), (41, 0.189, {'top1': 0.189}), (42, 0.1898, {'top1': 0.1898}), (43, 0.1848, {'top1': 0.1848}), (44, 0.189, {'top1': 0.189}), (45, 0.1902, {'top1': 0.1902}), (46, 0.1882, {'top1': 0.1882}), (47, 0.1864, {'top1': 0.1864}), (48, 0.1928, {'top1': 0.1928}), (50, 0.1902, {'top1': 0.1902}), (51, 0.1942, {'top1': 0.1942}), (52, 0.191, {'top1': 0.191}), (53, 0.1344, {'top1': 0.1344})]
just computed impact of block 51 . accuracy after removing:  0.1942
removed block 51 current accuracy 0.1942 loss from initial  -0.00940000000000002
since last training loss: -0.00940000000000002 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.1714, {'top1': 0.1714}), (1, 0.181, {'top1': 0.181}), (2, 0.1818, {'top1': 0.1818}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1838, {'top1': 0.1838}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1804, {'top1': 0.1804}), (7, 0.1842, {'top1': 0.1842}), (8, 0.1802, {'top1': 0.1802}), (10, 0.1892, {'top1': 0.1892}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1824, {'top1': 0.1824}), (14, 0.1932, {'top1': 0.1932}), (15, 0.1874, {'top1': 0.1874}), (16, 0.1896, {'top1': 0.1896}), (17, 0.1848, {'top1': 0.1848}), (18, 0.1228, {'top1': 0.1228}), (19, 0.1792, {'top1': 0.1792}), (20, 0.1742, {'top1': 0.1742}), (21, 0.1698, {'top1': 0.1698}), (22, 0.1752, {'top1': 0.1752}), (23, 0.1874, {'top1': 0.1874}), (24, 0.191, {'top1': 0.191}), (25, 0.1936, {'top1': 0.1936}), (26, 0.1456, {'top1': 0.1456}), (27, 0.195, {'top1': 0.195}), (28, 0.1912, {'top1': 0.1912}), (29, 0.185, {'top1': 0.185}), (30, 0.19, {'top1': 0.19}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1846, {'top1': 0.1846}), (35, 0.1932, {'top1': 0.1932}), (36, 0.1746, {'top1': 0.1746}), (37, 0.1844, {'top1': 0.1844}), (38, 0.1916, {'top1': 0.1916}), (39, 0.1886, {'top1': 0.1886}), (40, 0.1906, {'top1': 0.1906}), (41, 0.1894, {'top1': 0.1894}), (42, 0.189, {'top1': 0.189}), (43, 0.1886, {'top1': 0.1886}), (44, 0.1908, {'top1': 0.1908}), (45, 0.19, {'top1': 0.19}), (46, 0.1902, {'top1': 0.1902}), (47, 0.1902, {'top1': 0.1902}), (48, 0.194, {'top1': 0.194}), (50, 0.19, {'top1': 0.19}), (52, 0.194, {'top1': 0.194}), (53, 0.136, {'top1': 0.136})]
just computed impact of block 27 . accuracy after removing:  0.195
removed block 27 current accuracy 0.195 loss from initial  -0.010200000000000015
since last training loss: -0.010200000000000015 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.169, {'top1': 0.169}), (1, 0.1822, {'top1': 0.1822}), (2, 0.1824, {'top1': 0.1824}), (3, 0.1816, {'top1': 0.1816}), (4, 0.1824, {'top1': 0.1824}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1806, {'top1': 0.1806}), (7, 0.1836, {'top1': 0.1836}), (8, 0.1796, {'top1': 0.1796}), (10, 0.1894, {'top1': 0.1894}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1822, {'top1': 0.1822}), (14, 0.1936, {'top1': 0.1936}), (15, 0.1888, {'top1': 0.1888}), (16, 0.189, {'top1': 0.189}), (17, 0.186, {'top1': 0.186}), (18, 0.121, {'top1': 0.121}), (19, 0.1802, {'top1': 0.1802}), (20, 0.175, {'top1': 0.175}), (21, 0.1722, {'top1': 0.1722}), (22, 0.1772, {'top1': 0.1772}), (23, 0.1858, {'top1': 0.1858}), (24, 0.1908, {'top1': 0.1908}), (25, 0.1934, {'top1': 0.1934}), (26, 0.1408, {'top1': 0.1408}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1862, {'top1': 0.1862}), (30, 0.1884, {'top1': 0.1884}), (31, 0.1926, {'top1': 0.1926}), (32, 0.1868, {'top1': 0.1868}), (35, 0.1924, {'top1': 0.1924}), (36, 0.1724, {'top1': 0.1724}), (37, 0.1846, {'top1': 0.1846}), (38, 0.191, {'top1': 0.191}), (39, 0.1906, {'top1': 0.1906}), (40, 0.1908, {'top1': 0.1908}), (41, 0.1894, {'top1': 0.1894}), (42, 0.1898, {'top1': 0.1898}), (43, 0.1914, {'top1': 0.1914}), (44, 0.191, {'top1': 0.191}), (45, 0.1922, {'top1': 0.1922}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1912, {'top1': 0.1912}), (48, 0.194, {'top1': 0.194}), (50, 0.1914, {'top1': 0.1914}), (52, 0.1936, {'top1': 0.1936}), (53, 0.1364, {'top1': 0.1364})]
just computed impact of block 48 . accuracy after removing:  0.194
removed block 48 current accuracy 0.194 loss from initial  -0.009200000000000014
since last training loss: -0.009200000000000014 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.1724, {'top1': 0.1724}), (1, 0.1792, {'top1': 0.1792}), (2, 0.1802, {'top1': 0.1802}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1816, {'top1': 0.1816}), (5, 0.188, {'top1': 0.188}), (6, 0.1786, {'top1': 0.1786}), (7, 0.183, {'top1': 0.183}), (8, 0.1748, {'top1': 0.1748}), (10, 0.1886, {'top1': 0.1886}), (11, 0.1816, {'top1': 0.1816}), (12, 0.1798, {'top1': 0.1798}), (14, 0.1938, {'top1': 0.1938}), (15, 0.1852, {'top1': 0.1852}), (16, 0.1922, {'top1': 0.1922}), (17, 0.1828, {'top1': 0.1828}), (18, 0.1138, {'top1': 0.1138}), (19, 0.179, {'top1': 0.179}), (20, 0.169, {'top1': 0.169}), (21, 0.1698, {'top1': 0.1698}), (22, 0.1732, {'top1': 0.1732}), (23, 0.1822, {'top1': 0.1822}), (24, 0.1892, {'top1': 0.1892}), (25, 0.1916, {'top1': 0.1916}), (26, 0.1354, {'top1': 0.1354}), (28, 0.1902, {'top1': 0.1902}), (29, 0.181, {'top1': 0.181}), (30, 0.1842, {'top1': 0.1842}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1824, {'top1': 0.1824}), (35, 0.1932, {'top1': 0.1932}), (36, 0.1664, {'top1': 0.1664}), (37, 0.182, {'top1': 0.182}), (38, 0.1862, {'top1': 0.1862}), (39, 0.1848, {'top1': 0.1848}), (40, 0.1948, {'top1': 0.1948}), (41, 0.1944, {'top1': 0.1944}), (42, 0.1938, {'top1': 0.1938}), (43, 0.1864, {'top1': 0.1864}), (44, 0.1924, {'top1': 0.1924}), (45, 0.1896, {'top1': 0.1896}), (46, 0.187, {'top1': 0.187}), (47, 0.1946, {'top1': 0.1946}), (50, 0.1888, {'top1': 0.1888}), (52, 0.188, {'top1': 0.188}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 40 . accuracy after removing:  0.1948
removed block 40 current accuracy 0.1948 loss from initial  -0.010000000000000009
since last training loss: -0.010000000000000009 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.1814, {'top1': 0.1814}), (2, 0.181, {'top1': 0.181}), (3, 0.1824, {'top1': 0.1824}), (4, 0.1818, {'top1': 0.1818}), (5, 0.19, {'top1': 0.19}), (6, 0.18, {'top1': 0.18}), (7, 0.1838, {'top1': 0.1838}), (8, 0.18, {'top1': 0.18}), (10, 0.19, {'top1': 0.19}), (11, 0.1828, {'top1': 0.1828}), (12, 0.1826, {'top1': 0.1826}), (14, 0.194, {'top1': 0.194}), (15, 0.1896, {'top1': 0.1896}), (16, 0.1898, {'top1': 0.1898}), (17, 0.1874, {'top1': 0.1874}), (18, 0.1212, {'top1': 0.1212}), (19, 0.1822, {'top1': 0.1822}), (20, 0.177, {'top1': 0.177}), (21, 0.1706, {'top1': 0.1706}), (22, 0.1766, {'top1': 0.1766}), (23, 0.187, {'top1': 0.187}), (24, 0.1912, {'top1': 0.1912}), (25, 0.1948, {'top1': 0.1948}), (26, 0.1438, {'top1': 0.1438}), (28, 0.1902, {'top1': 0.1902}), (29, 0.1862, {'top1': 0.1862}), (30, 0.189, {'top1': 0.189}), (31, 0.1926, {'top1': 0.1926}), (32, 0.1886, {'top1': 0.1886}), (35, 0.1922, {'top1': 0.1922}), (36, 0.1728, {'top1': 0.1728}), (37, 0.187, {'top1': 0.187}), (38, 0.1906, {'top1': 0.1906}), (39, 0.1882, {'top1': 0.1882}), (41, 0.1908, {'top1': 0.1908}), (42, 0.1906, {'top1': 0.1906}), (43, 0.1904, {'top1': 0.1904}), (44, 0.1904, {'top1': 0.1904}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1912, {'top1': 0.1912}), (47, 0.193, {'top1': 0.193}), (50, 0.191, {'top1': 0.191}), (52, 0.1918, {'top1': 0.1918}), (53, 0.1352, {'top1': 0.1352})]
just computed impact of block 25 . accuracy after removing:  0.1948
removed block 25 current accuracy 0.1948 loss from initial  -0.010000000000000009
since last training loss: -0.010000000000000009 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.1808, {'top1': 0.1808}), (2, 0.181, {'top1': 0.181}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1812, {'top1': 0.1812}), (5, 0.1888, {'top1': 0.1888}), (6, 0.1812, {'top1': 0.1812}), (7, 0.1832, {'top1': 0.1832}), (8, 0.1796, {'top1': 0.1796}), (10, 0.1898, {'top1': 0.1898}), (11, 0.182, {'top1': 0.182}), (12, 0.1812, {'top1': 0.1812}), (14, 0.192, {'top1': 0.192}), (15, 0.1908, {'top1': 0.1908}), (16, 0.188, {'top1': 0.188}), (17, 0.1858, {'top1': 0.1858}), (18, 0.1164, {'top1': 0.1164}), (19, 0.181, {'top1': 0.181}), (20, 0.1712, {'top1': 0.1712}), (21, 0.169, {'top1': 0.169}), (22, 0.1744, {'top1': 0.1744}), (23, 0.184, {'top1': 0.184}), (24, 0.1896, {'top1': 0.1896}), (26, 0.134, {'top1': 0.134}), (28, 0.191, {'top1': 0.191}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1906, {'top1': 0.1906}), (32, 0.1828, {'top1': 0.1828}), (35, 0.194, {'top1': 0.194}), (36, 0.172, {'top1': 0.172}), (37, 0.1852, {'top1': 0.1852}), (38, 0.1888, {'top1': 0.1888}), (39, 0.189, {'top1': 0.189}), (41, 0.1898, {'top1': 0.1898}), (42, 0.1898, {'top1': 0.1898}), (43, 0.19, {'top1': 0.19}), (44, 0.1902, {'top1': 0.1902}), (45, 0.1898, {'top1': 0.1898}), (46, 0.1906, {'top1': 0.1906}), (47, 0.1906, {'top1': 0.1906}), (50, 0.189, {'top1': 0.189}), (52, 0.1906, {'top1': 0.1906}), (53, 0.135, {'top1': 0.135})]
just computed impact of block 35 . accuracy after removing:  0.194
removed block 35 current accuracy 0.194 loss from initial  -0.009200000000000014
since last training loss: -0.009200000000000014 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.1694, {'top1': 0.1694}), (1, 0.1834, {'top1': 0.1834}), (2, 0.1822, {'top1': 0.1822}), (3, 0.1842, {'top1': 0.1842}), (4, 0.1852, {'top1': 0.1852}), (5, 0.1904, {'top1': 0.1904}), (6, 0.1818, {'top1': 0.1818}), (7, 0.1844, {'top1': 0.1844}), (8, 0.1802, {'top1': 0.1802}), (10, 0.1914, {'top1': 0.1914}), (11, 0.1838, {'top1': 0.1838}), (12, 0.1812, {'top1': 0.1812}), (14, 0.1906, {'top1': 0.1906}), (15, 0.1886, {'top1': 0.1886}), (16, 0.1892, {'top1': 0.1892}), (17, 0.1872, {'top1': 0.1872}), (18, 0.1214, {'top1': 0.1214}), (19, 0.1824, {'top1': 0.1824}), (20, 0.1768, {'top1': 0.1768}), (21, 0.1736, {'top1': 0.1736}), (22, 0.1812, {'top1': 0.1812}), (23, 0.1862, {'top1': 0.1862}), (24, 0.1902, {'top1': 0.1902}), (26, 0.14, {'top1': 0.14}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1866, {'top1': 0.1866}), (30, 0.1878, {'top1': 0.1878}), (31, 0.1918, {'top1': 0.1918}), (32, 0.1864, {'top1': 0.1864}), (36, 0.1762, {'top1': 0.1762}), (37, 0.1882, {'top1': 0.1882}), (38, 0.189, {'top1': 0.189}), (39, 0.1886, {'top1': 0.1886}), (41, 0.1916, {'top1': 0.1916}), (42, 0.1918, {'top1': 0.1918}), (43, 0.1894, {'top1': 0.1894}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1914, {'top1': 0.1914}), (47, 0.1896, {'top1': 0.1896}), (50, 0.1926, {'top1': 0.1926}), (52, 0.192, {'top1': 0.192}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 50 . accuracy after removing:  0.1926
removed block 50 current accuracy 0.1926 loss from initial  -0.007800000000000001
since last training loss: -0.007800000000000001 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.17, {'top1': 0.17}), (1, 0.1794, {'top1': 0.1794}), (2, 0.1832, {'top1': 0.1832}), (3, 0.1786, {'top1': 0.1786}), (4, 0.1804, {'top1': 0.1804}), (5, 0.1878, {'top1': 0.1878}), (6, 0.177, {'top1': 0.177}), (7, 0.179, {'top1': 0.179}), (8, 0.172, {'top1': 0.172}), (10, 0.1888, {'top1': 0.1888}), (11, 0.1806, {'top1': 0.1806}), (12, 0.1794, {'top1': 0.1794}), (14, 0.1914, {'top1': 0.1914}), (15, 0.1826, {'top1': 0.1826}), (16, 0.1908, {'top1': 0.1908}), (17, 0.1802, {'top1': 0.1802}), (18, 0.112, {'top1': 0.112}), (19, 0.1796, {'top1': 0.1796}), (20, 0.1644, {'top1': 0.1644}), (21, 0.162, {'top1': 0.162}), (22, 0.1734, {'top1': 0.1734}), (23, 0.179, {'top1': 0.179}), (24, 0.189, {'top1': 0.189}), (26, 0.127, {'top1': 0.127}), (28, 0.186, {'top1': 0.186}), (29, 0.1772, {'top1': 0.1772}), (30, 0.1792, {'top1': 0.1792}), (31, 0.1882, {'top1': 0.1882}), (32, 0.1764, {'top1': 0.1764}), (36, 0.1638, {'top1': 0.1638}), (37, 0.18, {'top1': 0.18}), (38, 0.1834, {'top1': 0.1834}), (39, 0.1844, {'top1': 0.1844}), (41, 0.1936, {'top1': 0.1936}), (42, 0.1938, {'top1': 0.1938}), (43, 0.185, {'top1': 0.185}), (44, 0.193, {'top1': 0.193}), (45, 0.187, {'top1': 0.187}), (46, 0.186, {'top1': 0.186}), (47, 0.193, {'top1': 0.193}), (52, 0.1866, {'top1': 0.1866}), (53, 0.1338, {'top1': 0.1338})]
just computed impact of block 42 . accuracy after removing:  0.1938
removed block 42 current accuracy 0.1938 loss from initial  -0.009000000000000008
since last training loss: -0.009000000000000008 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.1714, {'top1': 0.1714}), (1, 0.1808, {'top1': 0.1808}), (2, 0.1804, {'top1': 0.1804}), (3, 0.1802, {'top1': 0.1802}), (4, 0.1816, {'top1': 0.1816}), (5, 0.19, {'top1': 0.19}), (6, 0.18, {'top1': 0.18}), (7, 0.1826, {'top1': 0.1826}), (8, 0.1786, {'top1': 0.1786}), (10, 0.1896, {'top1': 0.1896}), (11, 0.1804, {'top1': 0.1804}), (12, 0.1794, {'top1': 0.1794}), (14, 0.1928, {'top1': 0.1928}), (15, 0.1848, {'top1': 0.1848}), (16, 0.1892, {'top1': 0.1892}), (17, 0.1824, {'top1': 0.1824}), (18, 0.1156, {'top1': 0.1156}), (19, 0.1812, {'top1': 0.1812}), (20, 0.1728, {'top1': 0.1728}), (21, 0.1692, {'top1': 0.1692}), (22, 0.178, {'top1': 0.178}), (23, 0.1836, {'top1': 0.1836}), (24, 0.1898, {'top1': 0.1898}), (26, 0.1342, {'top1': 0.1342}), (28, 0.1904, {'top1': 0.1904}), (29, 0.1848, {'top1': 0.1848}), (30, 0.1834, {'top1': 0.1834}), (31, 0.191, {'top1': 0.191}), (32, 0.181, {'top1': 0.181}), (36, 0.1706, {'top1': 0.1706}), (37, 0.1866, {'top1': 0.1866}), (38, 0.188, {'top1': 0.188}), (39, 0.1874, {'top1': 0.1874}), (41, 0.1908, {'top1': 0.1908}), (43, 0.1872, {'top1': 0.1872}), (44, 0.1906, {'top1': 0.1906}), (45, 0.1912, {'top1': 0.1912}), (46, 0.1892, {'top1': 0.1892}), (47, 0.1918, {'top1': 0.1918}), (52, 0.189, {'top1': 0.189}), (53, 0.134, {'top1': 0.134})]
just computed impact of block 14 . accuracy after removing:  0.1928
removed block 14 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.1646, {'top1': 0.1646}), (1, 0.184, {'top1': 0.184}), (2, 0.1842, {'top1': 0.1842}), (3, 0.183, {'top1': 0.183}), (4, 0.1854, {'top1': 0.1854}), (5, 0.1902, {'top1': 0.1902}), (6, 0.1822, {'top1': 0.1822}), (7, 0.1828, {'top1': 0.1828}), (8, 0.1798, {'top1': 0.1798}), (10, 0.191, {'top1': 0.191}), (11, 0.186, {'top1': 0.186}), (12, 0.1792, {'top1': 0.1792}), (15, 0.1884, {'top1': 0.1884}), (16, 0.189, {'top1': 0.189}), (17, 0.1874, {'top1': 0.1874}), (18, 0.1128, {'top1': 0.1128}), (19, 0.1824, {'top1': 0.1824}), (20, 0.1718, {'top1': 0.1718}), (21, 0.1714, {'top1': 0.1714}), (22, 0.177, {'top1': 0.177}), (23, 0.1842, {'top1': 0.1842}), (24, 0.1868, {'top1': 0.1868}), (26, 0.1348, {'top1': 0.1348}), (28, 0.1916, {'top1': 0.1916}), (29, 0.1858, {'top1': 0.1858}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1902, {'top1': 0.1902}), (32, 0.1844, {'top1': 0.1844}), (36, 0.1738, {'top1': 0.1738}), (37, 0.1866, {'top1': 0.1866}), (38, 0.187, {'top1': 0.187}), (39, 0.188, {'top1': 0.188}), (41, 0.1898, {'top1': 0.1898}), (43, 0.1878, {'top1': 0.1878}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1908, {'top1': 0.1908}), (46, 0.1904, {'top1': 0.1904}), (47, 0.1906, {'top1': 0.1906}), (52, 0.1912, {'top1': 0.1912}), (53, 0.1354, {'top1': 0.1354})]
just computed impact of block 28 . accuracy after removing:  0.1916
removed block 28 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.167, {'top1': 0.167}), (1, 0.1762, {'top1': 0.1762}), (2, 0.1798, {'top1': 0.1798}), (3, 0.1782, {'top1': 0.1782}), (4, 0.1766, {'top1': 0.1766}), (5, 0.1818, {'top1': 0.1818}), (6, 0.1742, {'top1': 0.1742}), (7, 0.1804, {'top1': 0.1804}), (8, 0.1714, {'top1': 0.1714}), (10, 0.1858, {'top1': 0.1858}), (11, 0.179, {'top1': 0.179}), (12, 0.1732, {'top1': 0.1732}), (15, 0.1828, {'top1': 0.1828}), (16, 0.1886, {'top1': 0.1886}), (17, 0.179, {'top1': 0.179}), (18, 0.1112, {'top1': 0.1112}), (19, 0.174, {'top1': 0.174}), (20, 0.1568, {'top1': 0.1568}), (21, 0.1578, {'top1': 0.1578}), (22, 0.166, {'top1': 0.166}), (23, 0.1772, {'top1': 0.1772}), (24, 0.1908, {'top1': 0.1908}), (26, 0.1222, {'top1': 0.1222}), (29, 0.1772, {'top1': 0.1772}), (30, 0.1764, {'top1': 0.1764}), (31, 0.1868, {'top1': 0.1868}), (32, 0.169, {'top1': 0.169}), (36, 0.1642, {'top1': 0.1642}), (37, 0.177, {'top1': 0.177}), (38, 0.1808, {'top1': 0.1808}), (39, 0.1806, {'top1': 0.1806}), (41, 0.1936, {'top1': 0.1936}), (43, 0.1808, {'top1': 0.1808}), (44, 0.1926, {'top1': 0.1926}), (45, 0.185, {'top1': 0.185}), (46, 0.1828, {'top1': 0.1828}), (47, 0.1922, {'top1': 0.1922}), (52, 0.1878, {'top1': 0.1878}), (53, 0.1342, {'top1': 0.1342})]
just computed impact of block 41 . accuracy after removing:  0.1936
removed block 41 current accuracy 0.1936 loss from initial  -0.008800000000000002
since last training loss: -0.008800000000000002 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.1702, {'top1': 0.1702}), (1, 0.181, {'top1': 0.181}), (2, 0.1806, {'top1': 0.1806}), (3, 0.1796, {'top1': 0.1796}), (4, 0.1804, {'top1': 0.1804}), (5, 0.1884, {'top1': 0.1884}), (6, 0.1772, {'top1': 0.1772}), (7, 0.1814, {'top1': 0.1814}), (8, 0.1762, {'top1': 0.1762}), (10, 0.1876, {'top1': 0.1876}), (11, 0.1818, {'top1': 0.1818}), (12, 0.1764, {'top1': 0.1764}), (15, 0.185, {'top1': 0.185}), (16, 0.189, {'top1': 0.189}), (17, 0.185, {'top1': 0.185}), (18, 0.115, {'top1': 0.115}), (19, 0.1774, {'top1': 0.1774}), (20, 0.165, {'top1': 0.165}), (21, 0.1662, {'top1': 0.1662}), (22, 0.1724, {'top1': 0.1724}), (23, 0.1822, {'top1': 0.1822}), (24, 0.1908, {'top1': 0.1908}), (26, 0.1252, {'top1': 0.1252}), (29, 0.184, {'top1': 0.184}), (30, 0.1798, {'top1': 0.1798}), (31, 0.1914, {'top1': 0.1914}), (32, 0.1776, {'top1': 0.1776}), (36, 0.1742, {'top1': 0.1742}), (37, 0.1838, {'top1': 0.1838}), (38, 0.187, {'top1': 0.187}), (39, 0.1868, {'top1': 0.1868}), (43, 0.1872, {'top1': 0.1872}), (44, 0.1908, {'top1': 0.1908}), (45, 0.1886, {'top1': 0.1886}), (46, 0.1896, {'top1': 0.1896}), (47, 0.1916, {'top1': 0.1916}), (52, 0.1886, {'top1': 0.1886}), (53, 0.135, {'top1': 0.135})]
just computed impact of block 47 . accuracy after removing:  0.1916
removed block 47 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.165, {'top1': 0.165}), (1, 0.18, {'top1': 0.18}), (2, 0.1822, {'top1': 0.1822}), (3, 0.181, {'top1': 0.181}), (4, 0.1822, {'top1': 0.1822}), (5, 0.1868, {'top1': 0.1868}), (6, 0.1778, {'top1': 0.1778}), (7, 0.183, {'top1': 0.183}), (8, 0.1768, {'top1': 0.1768}), (10, 0.189, {'top1': 0.189}), (11, 0.1854, {'top1': 0.1854}), (12, 0.1778, {'top1': 0.1778}), (15, 0.1884, {'top1': 0.1884}), (16, 0.1888, {'top1': 0.1888}), (17, 0.1876, {'top1': 0.1876}), (18, 0.117, {'top1': 0.117}), (19, 0.1808, {'top1': 0.1808}), (20, 0.169, {'top1': 0.169}), (21, 0.1708, {'top1': 0.1708}), (22, 0.1752, {'top1': 0.1752}), (23, 0.1854, {'top1': 0.1854}), (24, 0.1852, {'top1': 0.1852}), (26, 0.1288, {'top1': 0.1288}), (29, 0.186, {'top1': 0.186}), (30, 0.1864, {'top1': 0.1864}), (31, 0.1898, {'top1': 0.1898}), (32, 0.1844, {'top1': 0.1844}), (36, 0.1796, {'top1': 0.1796}), (37, 0.1848, {'top1': 0.1848}), (38, 0.1894, {'top1': 0.1894}), (39, 0.1906, {'top1': 0.1906}), (43, 0.1896, {'top1': 0.1896}), (44, 0.1924, {'top1': 0.1924}), (45, 0.1926, {'top1': 0.1926}), (46, 0.1916, {'top1': 0.1916}), (52, 0.1928, {'top1': 0.1928}), (53, 0.1274, {'top1': 0.1274})]
just computed impact of block 52 . accuracy after removing:  0.1928
removed block 52 current accuracy 0.1928 loss from initial  -0.008000000000000007
since last training loss: -0.008000000000000007 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.1674, {'top1': 0.1674}), (1, 0.1796, {'top1': 0.1796}), (2, 0.18, {'top1': 0.18}), (3, 0.18, {'top1': 0.18}), (4, 0.1822, {'top1': 0.1822}), (5, 0.186, {'top1': 0.186}), (6, 0.1756, {'top1': 0.1756}), (7, 0.1806, {'top1': 0.1806}), (8, 0.1736, {'top1': 0.1736}), (10, 0.1888, {'top1': 0.1888}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1768, {'top1': 0.1768}), (15, 0.1848, {'top1': 0.1848}), (16, 0.1916, {'top1': 0.1916}), (17, 0.1816, {'top1': 0.1816}), (18, 0.1138, {'top1': 0.1138}), (19, 0.1778, {'top1': 0.1778}), (20, 0.1596, {'top1': 0.1596}), (21, 0.1618, {'top1': 0.1618}), (22, 0.168, {'top1': 0.168}), (23, 0.1832, {'top1': 0.1832}), (24, 0.1902, {'top1': 0.1902}), (26, 0.1234, {'top1': 0.1234}), (29, 0.1842, {'top1': 0.1842}), (30, 0.1802, {'top1': 0.1802}), (31, 0.1912, {'top1': 0.1912}), (32, 0.1768, {'top1': 0.1768}), (36, 0.169, {'top1': 0.169}), (37, 0.182, {'top1': 0.182}), (38, 0.1842, {'top1': 0.1842}), (39, 0.1856, {'top1': 0.1856}), (43, 0.1858, {'top1': 0.1858}), (44, 0.1916, {'top1': 0.1916}), (45, 0.1876, {'top1': 0.1876}), (46, 0.1868, {'top1': 0.1868}), (53, 0.117, {'top1': 0.117})]
just computed impact of block 16 . accuracy after removing:  0.1916
removed block 16 current accuracy 0.1916 loss from initial  -0.0068000000000000005
since last training loss: -0.0068000000000000005 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.1676, {'top1': 0.1676}), (1, 0.178, {'top1': 0.178}), (2, 0.1778, {'top1': 0.1778}), (3, 0.1804, {'top1': 0.1804}), (4, 0.179, {'top1': 0.179}), (5, 0.1862, {'top1': 0.1862}), (6, 0.1778, {'top1': 0.1778}), (7, 0.1808, {'top1': 0.1808}), (8, 0.1766, {'top1': 0.1766}), (10, 0.1876, {'top1': 0.1876}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1758, {'top1': 0.1758}), (15, 0.1868, {'top1': 0.1868}), (17, 0.1888, {'top1': 0.1888}), (18, 0.112, {'top1': 0.112}), (19, 0.1766, {'top1': 0.1766}), (20, 0.1614, {'top1': 0.1614}), (21, 0.1628, {'top1': 0.1628}), (22, 0.1716, {'top1': 0.1716}), (23, 0.1816, {'top1': 0.1816}), (24, 0.1866, {'top1': 0.1866}), (26, 0.124, {'top1': 0.124}), (29, 0.1832, {'top1': 0.1832}), (30, 0.1826, {'top1': 0.1826}), (31, 0.1892, {'top1': 0.1892}), (32, 0.1766, {'top1': 0.1766}), (36, 0.1742, {'top1': 0.1742}), (37, 0.1828, {'top1': 0.1828}), (38, 0.184, {'top1': 0.184}), (39, 0.1854, {'top1': 0.1854}), (43, 0.1848, {'top1': 0.1848}), (44, 0.1892, {'top1': 0.1892}), (45, 0.1838, {'top1': 0.1838}), (46, 0.1836, {'top1': 0.1836}), (53, 0.1142, {'top1': 0.1142})]
just computed impact of block 31 . accuracy after removing:  0.1892
removed block 31 current accuracy 0.1892 loss from initial  -0.004400000000000015
since last training loss: -0.004400000000000015 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.1662, {'top1': 0.1662}), (1, 0.1802, {'top1': 0.1802}), (2, 0.1808, {'top1': 0.1808}), (3, 0.1788, {'top1': 0.1788}), (4, 0.179, {'top1': 0.179}), (5, 0.1848, {'top1': 0.1848}), (6, 0.1768, {'top1': 0.1768}), (7, 0.1788, {'top1': 0.1788}), (8, 0.1776, {'top1': 0.1776}), (10, 0.1886, {'top1': 0.1886}), (11, 0.1824, {'top1': 0.1824}), (12, 0.1746, {'top1': 0.1746}), (15, 0.184, {'top1': 0.184}), (17, 0.187, {'top1': 0.187}), (18, 0.112, {'top1': 0.112}), (19, 0.1744, {'top1': 0.1744}), (20, 0.1612, {'top1': 0.1612}), (21, 0.1612, {'top1': 0.1612}), (22, 0.1698, {'top1': 0.1698}), (23, 0.1802, {'top1': 0.1802}), (24, 0.1884, {'top1': 0.1884}), (26, 0.123, {'top1': 0.123}), (29, 0.1788, {'top1': 0.1788}), (30, 0.1804, {'top1': 0.1804}), (32, 0.174, {'top1': 0.174}), (36, 0.1682, {'top1': 0.1682}), (37, 0.1798, {'top1': 0.1798}), (38, 0.1824, {'top1': 0.1824}), (39, 0.1832, {'top1': 0.1832}), (43, 0.1816, {'top1': 0.1816}), (44, 0.1906, {'top1': 0.1906}), (45, 0.1846, {'top1': 0.1846}), (46, 0.1832, {'top1': 0.1832}), (53, 0.1136, {'top1': 0.1136})]
just computed impact of block 44 . accuracy after removing:  0.1906
removed block 44 current accuracy 0.1906 loss from initial  -0.0058
since last training loss: -0.0058 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.1674, {'top1': 0.1674}), (1, 0.1776, {'top1': 0.1776}), (2, 0.1784, {'top1': 0.1784}), (3, 0.1808, {'top1': 0.1808}), (4, 0.1794, {'top1': 0.1794}), (5, 0.1894, {'top1': 0.1894}), (6, 0.1818, {'top1': 0.1818}), (7, 0.1804, {'top1': 0.1804}), (8, 0.176, {'top1': 0.176}), (10, 0.1912, {'top1': 0.1912}), (11, 0.1848, {'top1': 0.1848}), (12, 0.1804, {'top1': 0.1804}), (15, 0.1864, {'top1': 0.1864}), (17, 0.1902, {'top1': 0.1902}), (18, 0.1154, {'top1': 0.1154}), (19, 0.1744, {'top1': 0.1744}), (20, 0.1656, {'top1': 0.1656}), (21, 0.1664, {'top1': 0.1664}), (22, 0.1714, {'top1': 0.1714}), (23, 0.1802, {'top1': 0.1802}), (24, 0.1868, {'top1': 0.1868}), (26, 0.1282, {'top1': 0.1282}), (29, 0.182, {'top1': 0.182}), (30, 0.1828, {'top1': 0.1828}), (32, 0.181, {'top1': 0.181}), (36, 0.1746, {'top1': 0.1746}), (37, 0.1778, {'top1': 0.1778}), (38, 0.1838, {'top1': 0.1838}), (39, 0.185, {'top1': 0.185}), (43, 0.185, {'top1': 0.185}), (45, 0.1844, {'top1': 0.1844}), (46, 0.1842, {'top1': 0.1842}), (53, 0.1094, {'top1': 0.1094})]
just computed impact of block 10 . accuracy after removing:  0.1912
removed block 10 current accuracy 0.1912 loss from initial  -0.006400000000000017
since last training loss: -0.006400000000000017 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.1664, {'top1': 0.1664}), (1, 0.1784, {'top1': 0.1784}), (2, 0.178, {'top1': 0.178}), (3, 0.1808, {'top1': 0.1808}), (4, 0.182, {'top1': 0.182}), (5, 0.1846, {'top1': 0.1846}), (6, 0.1762, {'top1': 0.1762}), (7, 0.1804, {'top1': 0.1804}), (8, 0.1714, {'top1': 0.1714}), (11, 0.1836, {'top1': 0.1836}), (12, 0.1752, {'top1': 0.1752}), (15, 0.1866, {'top1': 0.1866}), (17, 0.1886, {'top1': 0.1886}), (18, 0.1128, {'top1': 0.1128}), (19, 0.1762, {'top1': 0.1762}), (20, 0.1598, {'top1': 0.1598}), (21, 0.1622, {'top1': 0.1622}), (22, 0.166, {'top1': 0.166}), (23, 0.1806, {'top1': 0.1806}), (24, 0.1856, {'top1': 0.1856}), (26, 0.1252, {'top1': 0.1252}), (29, 0.1826, {'top1': 0.1826}), (30, 0.1812, {'top1': 0.1812}), (32, 0.1788, {'top1': 0.1788}), (36, 0.1712, {'top1': 0.1712}), (37, 0.1816, {'top1': 0.1816}), (38, 0.1846, {'top1': 0.1846}), (39, 0.1868, {'top1': 0.1868}), (43, 0.1878, {'top1': 0.1878}), (45, 0.1852, {'top1': 0.1852}), (46, 0.1866, {'top1': 0.1866}), (53, 0.1082, {'top1': 0.1082})]
just computed impact of block 17 . accuracy after removing:  0.1886
removed block 17 current accuracy 0.1886 loss from initial  -0.003799999999999998
since last training loss: -0.003799999999999998 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.1698, {'top1': 0.1698}), (1, 0.177, {'top1': 0.177}), (2, 0.1784, {'top1': 0.1784}), (3, 0.1796, {'top1': 0.1796}), (4, 0.1818, {'top1': 0.1818}), (5, 0.1852, {'top1': 0.1852}), (6, 0.1754, {'top1': 0.1754}), (7, 0.1782, {'top1': 0.1782}), (8, 0.1722, {'top1': 0.1722}), (11, 0.178, {'top1': 0.178}), (12, 0.1732, {'top1': 0.1732}), (15, 0.1834, {'top1': 0.1834}), (18, 0.1136, {'top1': 0.1136}), (19, 0.1768, {'top1': 0.1768}), (20, 0.1614, {'top1': 0.1614}), (21, 0.1626, {'top1': 0.1626}), (22, 0.1692, {'top1': 0.1692}), (23, 0.179, {'top1': 0.179}), (24, 0.182, {'top1': 0.182}), (26, 0.1236, {'top1': 0.1236}), (29, 0.1788, {'top1': 0.1788}), (30, 0.1794, {'top1': 0.1794}), (32, 0.1768, {'top1': 0.1768}), (36, 0.172, {'top1': 0.172}), (37, 0.1802, {'top1': 0.1802}), (38, 0.1828, {'top1': 0.1828}), (39, 0.1848, {'top1': 0.1848}), (43, 0.1852, {'top1': 0.1852}), (45, 0.1844, {'top1': 0.1844}), (46, 0.1852, {'top1': 0.1852}), (53, 0.1096, {'top1': 0.1096})]
just computed impact of block 5 . accuracy after removing:  0.1852
removed block 5 current accuracy 0.1852 loss from initial  -0.00040000000000001146
since last training loss: -0.00040000000000001146 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.1684, {'top1': 0.1684}), (1, 0.1782, {'top1': 0.1782}), (2, 0.1786, {'top1': 0.1786}), (3, 0.1758, {'top1': 0.1758}), (4, 0.1792, {'top1': 0.1792}), (6, 0.1734, {'top1': 0.1734}), (7, 0.1736, {'top1': 0.1736}), (8, 0.1722, {'top1': 0.1722}), (11, 0.1798, {'top1': 0.1798}), (12, 0.1738, {'top1': 0.1738}), (15, 0.1828, {'top1': 0.1828}), (18, 0.112, {'top1': 0.112}), (19, 0.1748, {'top1': 0.1748}), (20, 0.1586, {'top1': 0.1586}), (21, 0.1576, {'top1': 0.1576}), (22, 0.1622, {'top1': 0.1622}), (23, 0.1776, {'top1': 0.1776}), (24, 0.1816, {'top1': 0.1816}), (26, 0.1174, {'top1': 0.1174}), (29, 0.1748, {'top1': 0.1748}), (30, 0.1762, {'top1': 0.1762}), (32, 0.1716, {'top1': 0.1716}), (36, 0.1706, {'top1': 0.1706}), (37, 0.1754, {'top1': 0.1754}), (38, 0.18, {'top1': 0.18}), (39, 0.1792, {'top1': 0.1792}), (43, 0.179, {'top1': 0.179}), (45, 0.1786, {'top1': 0.1786}), (46, 0.179, {'top1': 0.179}), (53, 0.108, {'top1': 0.108})]
just computed impact of block 15 . accuracy after removing:  0.1828
removed block 15 current accuracy 0.1828 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.1776, {'top1': 0.1776}), (1, 0.175, {'top1': 0.175}), (2, 0.1772, {'top1': 0.1772}), (3, 0.1748, {'top1': 0.1748}), (4, 0.1762, {'top1': 0.1762}), (6, 0.17, {'top1': 0.17}), (7, 0.1716, {'top1': 0.1716}), (8, 0.1684, {'top1': 0.1684}), (11, 0.1762, {'top1': 0.1762}), (12, 0.172, {'top1': 0.172}), (18, 0.1104, {'top1': 0.1104}), (19, 0.1684, {'top1': 0.1684}), (20, 0.1516, {'top1': 0.1516}), (21, 0.1554, {'top1': 0.1554}), (22, 0.159, {'top1': 0.159}), (23, 0.174, {'top1': 0.174}), (24, 0.1842, {'top1': 0.1842}), (26, 0.113, {'top1': 0.113}), (29, 0.1692, {'top1': 0.1692}), (30, 0.171, {'top1': 0.171}), (32, 0.17, {'top1': 0.17}), (36, 0.1678, {'top1': 0.1678}), (37, 0.1714, {'top1': 0.1714}), (38, 0.1728, {'top1': 0.1728}), (39, 0.1724, {'top1': 0.1724}), (43, 0.1726, {'top1': 0.1726}), (45, 0.1742, {'top1': 0.1742}), (46, 0.174, {'top1': 0.174}), (53, 0.1126, {'top1': 0.1126})]
just computed impact of block 24 . accuracy after removing:  0.1842
removed block 24 current accuracy 0.1842 loss from initial  0.0005999999999999894
since last training loss: 0.0005999999999999894 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.1696, {'top1': 0.1696}), (1, 0.1766, {'top1': 0.1766}), (2, 0.1774, {'top1': 0.1774}), (3, 0.1842, {'top1': 0.1842}), (4, 0.186, {'top1': 0.186}), (6, 0.1778, {'top1': 0.1778}), (7, 0.178, {'top1': 0.178}), (8, 0.1786, {'top1': 0.1786}), (11, 0.1822, {'top1': 0.1822}), (12, 0.1794, {'top1': 0.1794}), (18, 0.1214, {'top1': 0.1214}), (19, 0.1802, {'top1': 0.1802}), (20, 0.1718, {'top1': 0.1718}), (21, 0.1616, {'top1': 0.1616}), (22, 0.169, {'top1': 0.169}), (23, 0.1842, {'top1': 0.1842}), (26, 0.1186, {'top1': 0.1186}), (29, 0.1808, {'top1': 0.1808}), (30, 0.1798, {'top1': 0.1798}), (32, 0.1768, {'top1': 0.1768}), (36, 0.1768, {'top1': 0.1768}), (37, 0.1804, {'top1': 0.1804}), (38, 0.1818, {'top1': 0.1818}), (39, 0.1838, {'top1': 0.1838}), (43, 0.183, {'top1': 0.183}), (45, 0.1872, {'top1': 0.1872}), (46, 0.1844, {'top1': 0.1844}), (53, 0.1052, {'top1': 0.1052})]
just computed impact of block 45 . accuracy after removing:  0.1872
removed block 45 current accuracy 0.1872 loss from initial  -0.0024000000000000132
since last training loss: -0.0024000000000000132 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.1714, {'top1': 0.1714}), (1, 0.1782, {'top1': 0.1782}), (2, 0.1786, {'top1': 0.1786}), (3, 0.1778, {'top1': 0.1778}), (4, 0.1792, {'top1': 0.1792}), (6, 0.17, {'top1': 0.17}), (7, 0.1716, {'top1': 0.1716}), (8, 0.171, {'top1': 0.171}), (11, 0.1772, {'top1': 0.1772}), (12, 0.1722, {'top1': 0.1722}), (18, 0.1096, {'top1': 0.1096}), (19, 0.1772, {'top1': 0.1772}), (20, 0.1588, {'top1': 0.1588}), (21, 0.1542, {'top1': 0.1542}), (22, 0.1584, {'top1': 0.1584}), (23, 0.1734, {'top1': 0.1734}), (26, 0.1106, {'top1': 0.1106}), (29, 0.1678, {'top1': 0.1678}), (30, 0.1716, {'top1': 0.1716}), (32, 0.1672, {'top1': 0.1672}), (36, 0.169, {'top1': 0.169}), (37, 0.171, {'top1': 0.171}), (38, 0.1746, {'top1': 0.1746}), (39, 0.1752, {'top1': 0.1752}), (43, 0.1742, {'top1': 0.1742}), (46, 0.174, {'top1': 0.174}), (53, 0.121, {'top1': 0.121})]
just computed impact of block 4 . accuracy after removing:  0.1792
removed block 4 current accuracy 0.1792 loss from initial  0.005599999999999994
since last training loss: 0.005599999999999994 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.171, {'top1': 0.171}), (1, 0.1752, {'top1': 0.1752}), (2, 0.1744, {'top1': 0.1744}), (3, 0.1728, {'top1': 0.1728}), (6, 0.1648, {'top1': 0.1648}), (7, 0.1662, {'top1': 0.1662}), (8, 0.1706, {'top1': 0.1706}), (11, 0.1752, {'top1': 0.1752}), (12, 0.1712, {'top1': 0.1712}), (18, 0.1106, {'top1': 0.1106}), (19, 0.1746, {'top1': 0.1746}), (20, 0.1576, {'top1': 0.1576}), (21, 0.1488, {'top1': 0.1488}), (22, 0.1568, {'top1': 0.1568}), (23, 0.1726, {'top1': 0.1726}), (26, 0.106, {'top1': 0.106}), (29, 0.1664, {'top1': 0.1664}), (30, 0.1688, {'top1': 0.1688}), (32, 0.1648, {'top1': 0.1648}), (36, 0.1648, {'top1': 0.1648}), (37, 0.171, {'top1': 0.171}), (38, 0.1724, {'top1': 0.1724}), (39, 0.1738, {'top1': 0.1738}), (43, 0.1726, {'top1': 0.1726}), (46, 0.172, {'top1': 0.172}), (53, 0.122, {'top1': 0.122})]
just computed impact of block 1 . accuracy after removing:  0.1752
removed block 1 current accuracy 0.1752 loss from initial  0.009599999999999997
since last training loss: 0.009599999999999997 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.1776, {'top1': 0.1776}), (2, 0.1684, {'top1': 0.1684}), (3, 0.1684, {'top1': 0.1684}), (6, 0.1674, {'top1': 0.1674}), (7, 0.1688, {'top1': 0.1688}), (8, 0.1696, {'top1': 0.1696}), (11, 0.1694, {'top1': 0.1694}), (12, 0.17, {'top1': 0.17}), (18, 0.1208, {'top1': 0.1208}), (19, 0.166, {'top1': 0.166}), (20, 0.161, {'top1': 0.161}), (21, 0.1582, {'top1': 0.1582}), (22, 0.1602, {'top1': 0.1602}), (23, 0.1724, {'top1': 0.1724}), (26, 0.1168, {'top1': 0.1168}), (29, 0.1684, {'top1': 0.1684}), (30, 0.168, {'top1': 0.168}), (32, 0.1658, {'top1': 0.1658}), (36, 0.1672, {'top1': 0.1672}), (37, 0.169, {'top1': 0.169}), (38, 0.1726, {'top1': 0.1726}), (39, 0.1724, {'top1': 0.1724}), (43, 0.171, {'top1': 0.171}), (46, 0.1698, {'top1': 0.1698}), (53, 0.1214, {'top1': 0.1214})]
just computed impact of block 0 . accuracy after removing:  0.1776
removed block 0 current accuracy 0.1776 loss from initial  0.007199999999999984
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(2, 0.1616, {'top1': 0.1616}), (3, 0.171, {'top1': 0.171}), (6, 0.1602, {'top1': 0.1602}), (7, 0.1712, {'top1': 0.1712}), (8, 0.1712, {'top1': 0.1712}), (11, 0.1756, {'top1': 0.1756}), (12, 0.1712, {'top1': 0.1712}), (18, 0.0998, {'top1': 0.0998}), (19, 0.1706, {'top1': 0.1706}), (20, 0.1544, {'top1': 0.1544}), (21, 0.144, {'top1': 0.144}), (22, 0.1514, {'top1': 0.1514}), (23, 0.1698, {'top1': 0.1698}), (26, 0.102, {'top1': 0.102}), (29, 0.172, {'top1': 0.172}), (30, 0.1706, {'top1': 0.1706}), (32, 0.171, {'top1': 0.171}), (36, 0.173, {'top1': 0.173}), (37, 0.1708, {'top1': 0.1708}), (38, 0.1716, {'top1': 0.1716}), (39, 0.1684, {'top1': 0.1684}), (43, 0.1688, {'top1': 0.1688}), (46, 0.1694, {'top1': 0.1694}), (53, 0.1078, {'top1': 0.1078})]
just computed impact of block 11 . accuracy after removing:  0.1756
removed block 11 current accuracy 0.1756 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(2, 0.157, {'top1': 0.157}), (3, 0.1716, {'top1': 0.1716}), (6, 0.1566, {'top1': 0.1566}), (7, 0.1604, {'top1': 0.1604}), (8, 0.1622, {'top1': 0.1622}), (12, 0.1636, {'top1': 0.1636}), (18, 0.0992, {'top1': 0.0992}), (19, 0.1694, {'top1': 0.1694}), (20, 0.1418, {'top1': 0.1418}), (21, 0.1344, {'top1': 0.1344}), (22, 0.1408, {'top1': 0.1408}), (23, 0.1716, {'top1': 0.1716}), (26, 0.1002, {'top1': 0.1002}), (29, 0.1688, {'top1': 0.1688}), (30, 0.166, {'top1': 0.166}), (32, 0.1692, {'top1': 0.1692}), (36, 0.1678, {'top1': 0.1678}), (37, 0.1698, {'top1': 0.1698}), (38, 0.17, {'top1': 0.17}), (39, 0.1692, {'top1': 0.1692}), (43, 0.1702, {'top1': 0.1702}), (46, 0.1684, {'top1': 0.1684}), (53, 0.114, {'top1': 0.114})]
just computed impact of block 3 . accuracy after removing:  0.1716
removed block 3 current accuracy 0.1716 loss from initial  0.01319999999999999
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(2, 0.1448, {'top1': 0.1448}), (6, 0.149, {'top1': 0.149}), (7, 0.1498, {'top1': 0.1498}), (8, 0.1516, {'top1': 0.1516}), (12, 0.1512, {'top1': 0.1512}), (18, 0.0998, {'top1': 0.0998}), (19, 0.1502, {'top1': 0.1502}), (20, 0.1274, {'top1': 0.1274}), (21, 0.1218, {'top1': 0.1218}), (22, 0.1274, {'top1': 0.1274}), (23, 0.163, {'top1': 0.163}), (26, 0.0996, {'top1': 0.0996}), (29, 0.1548, {'top1': 0.1548}), (30, 0.1482, {'top1': 0.1482}), (32, 0.1546, {'top1': 0.1546}), (36, 0.1496, {'top1': 0.1496}), (37, 0.1562, {'top1': 0.1562}), (38, 0.1602, {'top1': 0.1602}), (39, 0.1618, {'top1': 0.1618}), (43, 0.1582, {'top1': 0.1582}), (46, 0.1586, {'top1': 0.1586}), (53, 0.1184, {'top1': 0.1184})]
just computed impact of block 23 . accuracy after removing:  0.163
removed block 23 current accuracy 0.163 loss from initial  0.021799999999999986
since last training loss: 0.021799999999999986 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(2, 0.1396, {'top1': 0.1396}), (6, 0.134, {'top1': 0.134}), (7, 0.1386, {'top1': 0.1386}), (8, 0.1426, {'top1': 0.1426}), (12, 0.1408, {'top1': 0.1408}), (18, 0.1, {'top1': 0.1}), (19, 0.1402, {'top1': 0.1402}), (20, 0.1148, {'top1': 0.1148}), (21, 0.1104, {'top1': 0.1104}), (22, 0.114, {'top1': 0.114}), (26, 0.1, {'top1': 0.1}), (29, 0.1314, {'top1': 0.1314}), (30, 0.1238, {'top1': 0.1238}), (32, 0.1328, {'top1': 0.1328}), (36, 0.1262, {'top1': 0.1262}), (37, 0.1352, {'top1': 0.1352}), (38, 0.141, {'top1': 0.141}), (39, 0.143, {'top1': 0.143}), (43, 0.1398, {'top1': 0.1398}), (46, 0.137, {'top1': 0.137}), (53, 0.1208, {'top1': 0.1208})]
just computed impact of block 39 . accuracy after removing:  0.143
removed block 39 current accuracy 0.143 loss from initial  0.041800000000000004
since last training loss: 0.041800000000000004 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(2, 0.1292, {'top1': 0.1292}), (6, 0.1184, {'top1': 0.1184}), (7, 0.122, {'top1': 0.122}), (8, 0.1262, {'top1': 0.1262}), (12, 0.123, {'top1': 0.123}), (18, 0.1, {'top1': 0.1}), (19, 0.1212, {'top1': 0.1212}), (20, 0.105, {'top1': 0.105}), (21, 0.1026, {'top1': 0.1026}), (22, 0.1034, {'top1': 0.1034}), (26, 0.1, {'top1': 0.1}), (29, 0.1138, {'top1': 0.1138}), (30, 0.1114, {'top1': 0.1114}), (32, 0.113, {'top1': 0.113}), (36, 0.1106, {'top1': 0.1106}), (37, 0.1186, {'top1': 0.1186}), (38, 0.121, {'top1': 0.121}), (43, 0.1214, {'top1': 0.1214}), (46, 0.1192, {'top1': 0.1192}), (53, 0.1262, {'top1': 0.1262})]
just computed impact of block 2 . accuracy after removing:  0.1292
removed block 2 current accuracy 0.1292 loss from initial  0.05559999999999998
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(6, 0.117, {'top1': 0.117}), (7, 0.118, {'top1': 0.118}), (8, 0.1198, {'top1': 0.1198}), (12, 0.1188, {'top1': 0.1188}), (18, 0.1, {'top1': 0.1}), (19, 0.1174, {'top1': 0.1174}), (20, 0.1048, {'top1': 0.1048}), (21, 0.1032, {'top1': 0.1032}), (22, 0.1044, {'top1': 0.1044}), (26, 0.1, {'top1': 0.1}), (29, 0.1114, {'top1': 0.1114}), (30, 0.1108, {'top1': 0.1108}), (32, 0.109, {'top1': 0.109}), (36, 0.109, {'top1': 0.109}), (37, 0.115, {'top1': 0.115}), (38, 0.1166, {'top1': 0.1166}), (43, 0.1176, {'top1': 0.1176}), (46, 0.1156, {'top1': 0.1156}), (53, 0.1238, {'top1': 0.1238})]
just computed impact of block 53 . accuracy after removing:  0.1238
removed block 53 current accuracy 0.1238 loss from initial  0.061
since last training loss: 0.061 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(6, 0.1184, {'top1': 0.1184}), (7, 0.1192, {'top1': 0.1192}), (8, 0.12, {'top1': 0.12}), (12, 0.1196, {'top1': 0.1196}), (18, 0.1024, {'top1': 0.1024}), (19, 0.1222, {'top1': 0.1222}), (20, 0.1194, {'top1': 0.1194}), (21, 0.1164, {'top1': 0.1164}), (22, 0.1164, {'top1': 0.1164}), (26, 0.102, {'top1': 0.102}), (29, 0.1214, {'top1': 0.1214}), (30, 0.1198, {'top1': 0.1198}), (32, 0.1246, {'top1': 0.1246}), (36, 0.114, {'top1': 0.114}), (37, 0.1202, {'top1': 0.1202}), (38, 0.1214, {'top1': 0.1214}), (43, 0.1212, {'top1': 0.1212}), (46, 0.1184, {'top1': 0.1184})]
just computed impact of block 32 . accuracy after removing:  0.1246
removed block 32 current accuracy 0.1246 loss from initial  0.06019999999999999
since last training loss: 0.06019999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(6, 0.1194, {'top1': 0.1194}), (7, 0.1196, {'top1': 0.1196}), (8, 0.119, {'top1': 0.119}), (12, 0.1198, {'top1': 0.1198}), (18, 0.102, {'top1': 0.102}), (19, 0.127, {'top1': 0.127}), (20, 0.1186, {'top1': 0.1186}), (21, 0.1184, {'top1': 0.1184}), (22, 0.1184, {'top1': 0.1184}), (26, 0.1022, {'top1': 0.1022}), (29, 0.1212, {'top1': 0.1212}), (30, 0.1204, {'top1': 0.1204}), (36, 0.1096, {'top1': 0.1096}), (37, 0.12, {'top1': 0.12}), (38, 0.1346, {'top1': 0.1346}), (43, 0.1208, {'top1': 0.1208}), (46, 0.1174, {'top1': 0.1174})]
just computed impact of block 38 . accuracy after removing:  0.1346
removed block 38 current accuracy 0.1346 loss from initial  0.050199999999999995
since last training loss: 0.050199999999999995 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(6, 0.1182, {'top1': 0.1182}), (7, 0.121, {'top1': 0.121}), (8, 0.1216, {'top1': 0.1216}), (12, 0.1224, {'top1': 0.1224}), (18, 0.101, {'top1': 0.101}), (19, 0.1084, {'top1': 0.1084}), (20, 0.1136, {'top1': 0.1136}), (21, 0.1024, {'top1': 0.1024}), (22, 0.1028, {'top1': 0.1028}), (26, 0.101, {'top1': 0.101}), (29, 0.1054, {'top1': 0.1054}), (30, 0.1272, {'top1': 0.1272}), (36, 0.1268, {'top1': 0.1268}), (37, 0.1046, {'top1': 0.1046}), (43, 0.1054, {'top1': 0.1054}), (46, 0.1196, {'top1': 0.1196})]
just computed impact of block 30 . accuracy after removing:  0.1272
removed block 30 current accuracy 0.1272 loss from initial  0.057599999999999985
since last training loss: 0.057599999999999985 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(6, 0.1144, {'top1': 0.1144}), (7, 0.116, {'top1': 0.116}), (8, 0.118, {'top1': 0.118}), (12, 0.1174, {'top1': 0.1174}), (18, 0.101, {'top1': 0.101}), (19, 0.1032, {'top1': 0.1032}), (20, 0.1048, {'top1': 0.1048}), (21, 0.1044, {'top1': 0.1044}), (22, 0.1046, {'top1': 0.1046}), (26, 0.101, {'top1': 0.101}), (29, 0.1172, {'top1': 0.1172}), (36, 0.1166, {'top1': 0.1166}), (37, 0.1038, {'top1': 0.1038}), (43, 0.1078, {'top1': 0.1078}), (46, 0.113, {'top1': 0.113})]
just computed impact of block 8 . accuracy after removing:  0.118
removed block 8 current accuracy 0.118 loss from initial  0.0668
since last training loss: 0.0668 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(6, 0.1074, {'top1': 0.1074}), (7, 0.1076, {'top1': 0.1076}), (12, 0.1104, {'top1': 0.1104}), (18, 0.101, {'top1': 0.101}), (19, 0.1018, {'top1': 0.1018}), (20, 0.103, {'top1': 0.103}), (21, 0.1028, {'top1': 0.1028}), (22, 0.1028, {'top1': 0.1028}), (26, 0.101, {'top1': 0.101}), (29, 0.1082, {'top1': 0.1082}), (36, 0.1076, {'top1': 0.1076}), (37, 0.1016, {'top1': 0.1016}), (43, 0.103, {'top1': 0.103}), (46, 0.1058, {'top1': 0.1058})]
just computed impact of block 12 . accuracy after removing:  0.1104
removed block 12 current accuracy 0.1104 loss from initial  0.0744
since last training loss: 0.0744 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(6, 0.1048, {'top1': 0.1048}), (7, 0.1048, {'top1': 0.1048}), (18, 0.101, {'top1': 0.101}), (19, 0.101, {'top1': 0.101}), (20, 0.1016, {'top1': 0.1016}), (21, 0.1018, {'top1': 0.1018}), (22, 0.102, {'top1': 0.102}), (26, 0.101, {'top1': 0.101}), (29, 0.1044, {'top1': 0.1044}), (36, 0.1044, {'top1': 0.1044}), (37, 0.1008, {'top1': 0.1008}), (43, 0.1022, {'top1': 0.1022}), (46, 0.1038, {'top1': 0.1038})]
just computed impact of block 6 . accuracy after removing:  0.1048
removed block 6 current accuracy 0.1048 loss from initial  0.07999999999999999
since last training loss: 0.07999999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(7, 0.1026, {'top1': 0.1026}), (18, 0.101, {'top1': 0.101}), (19, 0.101, {'top1': 0.101}), (20, 0.101, {'top1': 0.101}), (21, 0.101, {'top1': 0.101}), (22, 0.101, {'top1': 0.101}), (26, 0.101, {'top1': 0.101}), (29, 0.1026, {'top1': 0.1026}), (36, 0.1024, {'top1': 0.1024}), (37, 0.1008, {'top1': 0.1008}), (43, 0.1008, {'top1': 0.1008}), (46, 0.102, {'top1': 0.102})]
just computed impact of block 7 . accuracy after removing:  0.1026
removed block 7 current accuracy 0.1026 loss from initial  0.0822
since last training loss: 0.0822 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(18, 0.101, {'top1': 0.101}), (19, 0.1008, {'top1': 0.1008}), (20, 0.101, {'top1': 0.101}), (21, 0.101, {'top1': 0.101}), (22, 0.101, {'top1': 0.101}), (26, 0.101, {'top1': 0.101}), (29, 0.1012, {'top1': 0.1012}), (36, 0.101, {'top1': 0.101}), (37, 0.101, {'top1': 0.101}), (43, 0.101, {'top1': 0.101}), (46, 0.101, {'top1': 0.101})]
just computed impact of block 29 . accuracy after removing:  0.1012
removed block 29 current accuracy 0.1012 loss from initial  0.0836
since last training loss: 0.0836 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(18, 0.101, {'top1': 0.101}), (19, 0.101, {'top1': 0.101}), (20, 0.101, {'top1': 0.101}), (21, 0.101, {'top1': 0.101}), (22, 0.101, {'top1': 0.101}), (26, 0.101, {'top1': 0.101}), (36, 0.101, {'top1': 0.101}), (37, 0.101, {'top1': 0.101}), (43, 0.101, {'top1': 0.101}), (46, 0.101, {'top1': 0.101})]
just computed impact of block 18 . accuracy after removing:  0.101
removed block 18 current accuracy 0.101 loss from initial  0.08379999999999999
training start
training epoch 0 val accuracy 0.369 topk_dict {'top1': 0.369} is_best True lr [0.1]
training epoch 1 val accuracy 0.4412 topk_dict {'top1': 0.4412} is_best True lr [0.1]
training epoch 2 val accuracy 0.5312 topk_dict {'top1': 0.5312} is_best True lr [0.1]
training epoch 3 val accuracy 0.4918 topk_dict {'top1': 0.4918} is_best False lr [0.1]
training epoch 4 val accuracy 0.6316 topk_dict {'top1': 0.6316} is_best True lr [0.1]
training epoch 5 val accuracy 0.6486 topk_dict {'top1': 0.6486} is_best True lr [0.1]
training epoch 6 val accuracy 0.6936 topk_dict {'top1': 0.6936} is_best True lr [0.1]
training epoch 7 val accuracy 0.6904 topk_dict {'top1': 0.6904} is_best False lr [0.1]
training epoch 8 val accuracy 0.7188 topk_dict {'top1': 0.7188} is_best True lr [0.1]
training epoch 9 val accuracy 0.7416 topk_dict {'top1': 0.7416} is_best True lr [0.1]
training epoch 10 val accuracy 0.765 topk_dict {'top1': 0.765} is_best True lr [0.1]
training epoch 11 val accuracy 0.7924 topk_dict {'top1': 0.7924} is_best True lr [0.1]
training epoch 12 val accuracy 0.7728 topk_dict {'top1': 0.7728} is_best False lr [0.1]
training epoch 13 val accuracy 0.7942 topk_dict {'top1': 0.7942} is_best True lr [0.1]
training epoch 14 val accuracy 0.773 topk_dict {'top1': 0.773} is_best False lr [0.1]
training epoch 15 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best True lr [0.1]
training epoch 16 val accuracy 0.7924 topk_dict {'top1': 0.7924} is_best False lr [0.1]
training epoch 17 val accuracy 0.7704 topk_dict {'top1': 0.7704} is_best False lr [0.1]
training epoch 18 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best True lr [0.1]
training epoch 19 val accuracy 0.7954 topk_dict {'top1': 0.7954} is_best False lr [0.1]
training epoch 20 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best True lr [0.1]
training epoch 21 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best False lr [0.1]
training epoch 22 val accuracy 0.8166 topk_dict {'top1': 0.8166} is_best True lr [0.1]
training epoch 23 val accuracy 0.7906 topk_dict {'top1': 0.7906} is_best False lr [0.1]
training epoch 24 val accuracy 0.817 topk_dict {'top1': 0.817} is_best True lr [0.1]
training epoch 25 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best False lr [0.1]
training epoch 26 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.1]
training epoch 27 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best False lr [0.1]
training epoch 28 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best True lr [0.1]
training epoch 29 val accuracy 0.8168 topk_dict {'top1': 0.8168} is_best False lr [0.1]
training epoch 30 val accuracy 0.8164 topk_dict {'top1': 0.8164} is_best False lr [0.1]
training epoch 31 val accuracy 0.7932 topk_dict {'top1': 0.7932} is_best False lr [0.1]
training epoch 32 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.1]
training epoch 33 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best False lr [0.1]
training epoch 34 val accuracy 0.8292 topk_dict {'top1': 0.8292} is_best False lr [0.1]
training epoch 35 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.1]
training epoch 36 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.1]
training epoch 37 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.1]
training epoch 38 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.1]
training epoch 39 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 40 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 41 val accuracy 0.845 topk_dict {'top1': 0.845} is_best True lr [0.1]
training epoch 42 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 43 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.1]
training epoch 44 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best False lr [0.1]
training epoch 45 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 46 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 47 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.1]
training epoch 48 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 49 val accuracy 0.7898 topk_dict {'top1': 0.7898} is_best False lr [0.1]
training epoch 50 val accuracy 0.8112 topk_dict {'top1': 0.8112} is_best False lr [0.1]
training epoch 51 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best False lr [0.1]
training epoch 52 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 53 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 54 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 55 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 56 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.1]
training epoch 57 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 58 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 59 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 60 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 61 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best False lr [0.1]
training epoch 62 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best False lr [0.1]
training epoch 63 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.1]
training epoch 64 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 65 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.1]
training epoch 66 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 67 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 68 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 69 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 70 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best False lr [0.1]
training epoch 71 val accuracy 0.8226 topk_dict {'top1': 0.8226} is_best False lr [0.1]
training epoch 72 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 73 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 74 val accuracy 0.8396 topk_dict {'top1': 0.8396} is_best False lr [0.1]
training epoch 75 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best False lr [0.1]
training epoch 76 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 77 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 78 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 79 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.1]
training epoch 80 val accuracy 0.8206 topk_dict {'top1': 0.8206} is_best False lr [0.1]
training epoch 81 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 82 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 83 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 84 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.1]
training epoch 85 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.1]
training epoch 86 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 87 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 88 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 89 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best False lr [0.1]
training epoch 90 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 91 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 92 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.1]
training epoch 93 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 94 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 95 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 96 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 97 val accuracy 0.821 topk_dict {'top1': 0.821} is_best False lr [0.1]
training epoch 98 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 99 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 100 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 101 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 102 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 103 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 104 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 105 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 106 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 107 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 108 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 109 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best False lr [0.1]
training epoch 110 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 111 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 112 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 113 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 114 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 115 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 116 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 117 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 118 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 119 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 120 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 121 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 122 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 123 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 124 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 125 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.1]
training epoch 126 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 127 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 128 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 129 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 130 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 131 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 132 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 133 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 134 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.1]
training epoch 135 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 136 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 137 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 138 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 139 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 140 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 141 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 142 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 143 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 144 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 145 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 146 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 147 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 148 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 149 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 150 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 151 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 152 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 153 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 154 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 155 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 156 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 157 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 158 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 159 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 160 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 161 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 162 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 163 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 164 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 165 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 166 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 167 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 168 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 169 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 170 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 171 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 172 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 173 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 174 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 175 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 176 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 177 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 178 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 179 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 180 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 181 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 182 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 183 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 184 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 185 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 186 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 187 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 188 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 189 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 190 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 191 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 192 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.1]
training epoch 193 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best False lr [0.1]
training epoch 194 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 195 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 196 val accuracy 0.829 topk_dict {'top1': 0.829} is_best False lr [0.1]
training epoch 197 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 198 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 199 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 200 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 201 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 202 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 203 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 204 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 205 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 206 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 207 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 208 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 209 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best False lr [0.1]
training epoch 210 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 211 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 212 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 213 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 214 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 215 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 216 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 217 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 218 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 219 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 220 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 221 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 222 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 223 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 224 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 225 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 226 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 227 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 228 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 229 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 230 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 231 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 232 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 233 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 234 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best False lr [0.1]
training epoch 235 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 236 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 237 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 238 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 239 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 240 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 241 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 242 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 243 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 244 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 245 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 246 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 247 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 248 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 249 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.010000000000000002]
training epoch 250 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.010000000000000002]
training epoch 252 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.010000000000000002]
training epoch 253 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.010000000000000002]
training epoch 255 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.010000000000000002]
training epoch 256 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.010000000000000002]
training epoch 257 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.010000000000000002]
training epoch 259 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.010000000000000002]
training epoch 260 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.010000000000000002]
training epoch 262 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.010000000000000002]
training epoch 285 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 367 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 368 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 369 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.010000000000000002]
training epoch 370 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 371 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 372 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 373 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 374 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 481 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 489 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 490 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 491 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 492 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 493 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 494 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 495 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 496 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 497 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 498 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
loading model_best from epoch 284 (acc 0.913800)
finished training. finished 499 epochs. accuracy 0.9138 topk_dict {'top1': 0.9138}
