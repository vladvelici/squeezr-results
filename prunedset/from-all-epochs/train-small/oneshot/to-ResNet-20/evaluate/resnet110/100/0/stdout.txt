start iteration 0
(cache recomputed) Accuracy log [(0, 0.8126, {'top1': 0.8126}), (1, 0.8734, {'top1': 0.8734}), (2, 0.8204, {'top1': 0.8204}), (3, 0.846, {'top1': 0.846}), (4, 0.8438, {'top1': 0.8438}), (5, 0.8136, {'top1': 0.8136}), (6, 0.8416, {'top1': 0.8416}), (7, 0.8256, {'top1': 0.8256}), (8, 0.8202, {'top1': 0.8202}), (9, 0.8314, {'top1': 0.8314}), (10, 0.8258, {'top1': 0.8258}), (11, 0.8446, {'top1': 0.8446}), (12, 0.8292, {'top1': 0.8292}), (13, 0.8404, {'top1': 0.8404}), (14, 0.839, {'top1': 0.839}), (15, 0.8182, {'top1': 0.8182}), (16, 0.8322, {'top1': 0.8322}), (17, 0.861, {'top1': 0.861}), (18, 0.3862, {'top1': 0.3862}), (19, 0.8354, {'top1': 0.8354}), (20, 0.8658, {'top1': 0.8658}), (21, 0.8404, {'top1': 0.8404}), (22, 0.8594, {'top1': 0.8594}), (23, 0.861, {'top1': 0.861}), (24, 0.86, {'top1': 0.86}), (25, 0.8572, {'top1': 0.8572}), (26, 0.8578, {'top1': 0.8578}), (27, 0.8368, {'top1': 0.8368}), (28, 0.8654, {'top1': 0.8654}), (29, 0.8628, {'top1': 0.8628}), (30, 0.8628, {'top1': 0.8628}), (31, 0.8624, {'top1': 0.8624}), (32, 0.8738, {'top1': 0.8738}), (33, 0.86, {'top1': 0.86}), (34, 0.8632, {'top1': 0.8632}), (35, 0.8638, {'top1': 0.8638}), (36, 0.5116, {'top1': 0.5116}), (37, 0.8606, {'top1': 0.8606}), (38, 0.8638, {'top1': 0.8638}), (39, 0.8562, {'top1': 0.8562}), (40, 0.8632, {'top1': 0.8632}), (41, 0.861, {'top1': 0.861}), (42, 0.8698, {'top1': 0.8698}), (43, 0.8646, {'top1': 0.8646}), (44, 0.8622, {'top1': 0.8622}), (45, 0.868, {'top1': 0.868}), (46, 0.8622, {'top1': 0.8622}), (47, 0.8624, {'top1': 0.8624}), (48, 0.862, {'top1': 0.862}), (49, 0.869, {'top1': 0.869}), (50, 0.8464, {'top1': 0.8464}), (51, 0.778, {'top1': 0.778}), (52, 0.7806, {'top1': 0.7806}), (53, 0.3376, {'top1': 0.3376})]
just computed impact of block 32 . accuracy after removing:  0.8738
removed block 32 current accuracy 0.8738 loss from initial  -0.011600000000000055
since last training loss: -0.011600000000000055 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.8232, {'top1': 0.8232}), (1, 0.8802, {'top1': 0.8802}), (2, 0.832, {'top1': 0.832}), (3, 0.8588, {'top1': 0.8588}), (4, 0.8552, {'top1': 0.8552}), (5, 0.83, {'top1': 0.83}), (6, 0.854, {'top1': 0.854}), (7, 0.8414, {'top1': 0.8414}), (8, 0.8338, {'top1': 0.8338}), (9, 0.8452, {'top1': 0.8452}), (10, 0.8362, {'top1': 0.8362}), (11, 0.8568, {'top1': 0.8568}), (12, 0.8388, {'top1': 0.8388}), (13, 0.8514, {'top1': 0.8514}), (14, 0.8508, {'top1': 0.8508}), (15, 0.832, {'top1': 0.832}), (16, 0.8428, {'top1': 0.8428}), (17, 0.873, {'top1': 0.873}), (18, 0.3924, {'top1': 0.3924}), (19, 0.85, {'top1': 0.85}), (20, 0.874, {'top1': 0.874}), (21, 0.8524, {'top1': 0.8524}), (22, 0.8718, {'top1': 0.8718}), (23, 0.8714, {'top1': 0.8714}), (24, 0.8722, {'top1': 0.8722}), (25, 0.8708, {'top1': 0.8708}), (26, 0.8688, {'top1': 0.8688}), (27, 0.849, {'top1': 0.849}), (28, 0.8768, {'top1': 0.8768}), (29, 0.8726, {'top1': 0.8726}), (30, 0.8748, {'top1': 0.8748}), (31, 0.8724, {'top1': 0.8724}), (33, 0.8718, {'top1': 0.8718}), (34, 0.8732, {'top1': 0.8732}), (35, 0.8706, {'top1': 0.8706}), (36, 0.4976, {'top1': 0.4976}), (37, 0.8682, {'top1': 0.8682}), (38, 0.8744, {'top1': 0.8744}), (39, 0.8672, {'top1': 0.8672}), (40, 0.875, {'top1': 0.875}), (41, 0.872, {'top1': 0.872}), (42, 0.876, {'top1': 0.876}), (43, 0.8738, {'top1': 0.8738}), (44, 0.8734, {'top1': 0.8734}), (45, 0.878, {'top1': 0.878}), (46, 0.8746, {'top1': 0.8746}), (47, 0.8742, {'top1': 0.8742}), (48, 0.8728, {'top1': 0.8728}), (49, 0.8766, {'top1': 0.8766}), (50, 0.858, {'top1': 0.858}), (51, 0.7902, {'top1': 0.7902}), (52, 0.7882, {'top1': 0.7882}), (53, 0.3432, {'top1': 0.3432})]
just computed impact of block 1 . accuracy after removing:  0.8802
removed block 1 current accuracy 0.8802 loss from initial  -0.018000000000000016
since last training loss: -0.018000000000000016 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8022, {'top1': 0.8022}), (2, 0.8146, {'top1': 0.8146}), (3, 0.8564, {'top1': 0.8564}), (4, 0.8654, {'top1': 0.8654}), (5, 0.8528, {'top1': 0.8528}), (6, 0.8448, {'top1': 0.8448}), (7, 0.835, {'top1': 0.835}), (8, 0.8358, {'top1': 0.8358}), (9, 0.85, {'top1': 0.85}), (10, 0.8426, {'top1': 0.8426}), (11, 0.853, {'top1': 0.853}), (12, 0.8506, {'top1': 0.8506}), (13, 0.86, {'top1': 0.86}), (14, 0.8568, {'top1': 0.8568}), (15, 0.8396, {'top1': 0.8396}), (16, 0.8474, {'top1': 0.8474}), (17, 0.8714, {'top1': 0.8714}), (18, 0.423, {'top1': 0.423}), (19, 0.8724, {'top1': 0.8724}), (20, 0.8866, {'top1': 0.8866}), (21, 0.8594, {'top1': 0.8594}), (22, 0.882, {'top1': 0.882}), (23, 0.8764, {'top1': 0.8764}), (24, 0.8822, {'top1': 0.8822}), (25, 0.8798, {'top1': 0.8798}), (26, 0.8794, {'top1': 0.8794}), (27, 0.8618, {'top1': 0.8618}), (28, 0.8792, {'top1': 0.8792}), (29, 0.8774, {'top1': 0.8774}), (30, 0.8796, {'top1': 0.8796}), (31, 0.8798, {'top1': 0.8798}), (33, 0.8756, {'top1': 0.8756}), (34, 0.877, {'top1': 0.877}), (35, 0.8798, {'top1': 0.8798}), (36, 0.495, {'top1': 0.495}), (37, 0.8784, {'top1': 0.8784}), (38, 0.878, {'top1': 0.878}), (39, 0.8744, {'top1': 0.8744}), (40, 0.88, {'top1': 0.88}), (41, 0.8786, {'top1': 0.8786}), (42, 0.884, {'top1': 0.884}), (43, 0.8816, {'top1': 0.8816}), (44, 0.8788, {'top1': 0.8788}), (45, 0.8842, {'top1': 0.8842}), (46, 0.8798, {'top1': 0.8798}), (47, 0.8808, {'top1': 0.8808}), (48, 0.8836, {'top1': 0.8836}), (49, 0.8838, {'top1': 0.8838}), (50, 0.8708, {'top1': 0.8708}), (51, 0.8092, {'top1': 0.8092}), (52, 0.7876, {'top1': 0.7876}), (53, 0.3376, {'top1': 0.3376})]
just computed impact of block 20 . accuracy after removing:  0.8866
removed block 20 current accuracy 0.8866 loss from initial  -0.02440000000000009
since last training loss: -0.02440000000000009 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.8096, {'top1': 0.8096}), (2, 0.8222, {'top1': 0.8222}), (3, 0.8638, {'top1': 0.8638}), (4, 0.8728, {'top1': 0.8728}), (5, 0.846, {'top1': 0.846}), (6, 0.8562, {'top1': 0.8562}), (7, 0.8308, {'top1': 0.8308}), (8, 0.8354, {'top1': 0.8354}), (9, 0.8562, {'top1': 0.8562}), (10, 0.8488, {'top1': 0.8488}), (11, 0.8656, {'top1': 0.8656}), (12, 0.8548, {'top1': 0.8548}), (13, 0.87, {'top1': 0.87}), (14, 0.8664, {'top1': 0.8664}), (15, 0.851, {'top1': 0.851}), (16, 0.8668, {'top1': 0.8668}), (17, 0.8818, {'top1': 0.8818}), (18, 0.3926, {'top1': 0.3926}), (19, 0.8614, {'top1': 0.8614}), (21, 0.865, {'top1': 0.865}), (22, 0.8844, {'top1': 0.8844}), (23, 0.8804, {'top1': 0.8804}), (24, 0.8896, {'top1': 0.8896}), (25, 0.887, {'top1': 0.887}), (26, 0.8828, {'top1': 0.8828}), (27, 0.8624, {'top1': 0.8624}), (28, 0.8862, {'top1': 0.8862}), (29, 0.8802, {'top1': 0.8802}), (30, 0.8856, {'top1': 0.8856}), (31, 0.8844, {'top1': 0.8844}), (33, 0.88, {'top1': 0.88}), (34, 0.8826, {'top1': 0.8826}), (35, 0.8858, {'top1': 0.8858}), (36, 0.4588, {'top1': 0.4588}), (37, 0.8848, {'top1': 0.8848}), (38, 0.8812, {'top1': 0.8812}), (39, 0.8772, {'top1': 0.8772}), (40, 0.8886, {'top1': 0.8886}), (41, 0.8866, {'top1': 0.8866}), (42, 0.8898, {'top1': 0.8898}), (43, 0.8862, {'top1': 0.8862}), (44, 0.8868, {'top1': 0.8868}), (45, 0.8914, {'top1': 0.8914}), (46, 0.884, {'top1': 0.884}), (47, 0.8846, {'top1': 0.8846}), (48, 0.8902, {'top1': 0.8902}), (49, 0.8888, {'top1': 0.8888}), (50, 0.87, {'top1': 0.87}), (51, 0.8074, {'top1': 0.8074}), (52, 0.7774, {'top1': 0.7774}), (53, 0.3294, {'top1': 0.3294})]
just computed impact of block 45 . accuracy after removing:  0.8914
removed block 45 current accuracy 0.8914 loss from initial  -0.029200000000000004
since last training loss: -0.029200000000000004 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8158, {'top1': 0.8158}), (2, 0.826, {'top1': 0.826}), (3, 0.8698, {'top1': 0.8698}), (4, 0.8748, {'top1': 0.8748}), (5, 0.8508, {'top1': 0.8508}), (6, 0.8584, {'top1': 0.8584}), (7, 0.836, {'top1': 0.836}), (8, 0.8424, {'top1': 0.8424}), (9, 0.8606, {'top1': 0.8606}), (10, 0.858, {'top1': 0.858}), (11, 0.8732, {'top1': 0.8732}), (12, 0.861, {'top1': 0.861}), (13, 0.8716, {'top1': 0.8716}), (14, 0.8708, {'top1': 0.8708}), (15, 0.8544, {'top1': 0.8544}), (16, 0.8724, {'top1': 0.8724}), (17, 0.8864, {'top1': 0.8864}), (18, 0.388, {'top1': 0.388}), (19, 0.87, {'top1': 0.87}), (21, 0.8682, {'top1': 0.8682}), (22, 0.8864, {'top1': 0.8864}), (23, 0.8812, {'top1': 0.8812}), (24, 0.8932, {'top1': 0.8932}), (25, 0.8908, {'top1': 0.8908}), (26, 0.887, {'top1': 0.887}), (27, 0.8678, {'top1': 0.8678}), (28, 0.8878, {'top1': 0.8878}), (29, 0.8868, {'top1': 0.8868}), (30, 0.8902, {'top1': 0.8902}), (31, 0.89, {'top1': 0.89}), (33, 0.8846, {'top1': 0.8846}), (34, 0.8876, {'top1': 0.8876}), (35, 0.8872, {'top1': 0.8872}), (36, 0.4316, {'top1': 0.4316}), (37, 0.8896, {'top1': 0.8896}), (38, 0.8858, {'top1': 0.8858}), (39, 0.8842, {'top1': 0.8842}), (40, 0.8922, {'top1': 0.8922}), (41, 0.8908, {'top1': 0.8908}), (42, 0.8942, {'top1': 0.8942}), (43, 0.8934, {'top1': 0.8934}), (44, 0.8904, {'top1': 0.8904}), (46, 0.889, {'top1': 0.889}), (47, 0.8902, {'top1': 0.8902}), (48, 0.8942, {'top1': 0.8942}), (49, 0.8926, {'top1': 0.8926}), (50, 0.876, {'top1': 0.876}), (51, 0.8104, {'top1': 0.8104}), (52, 0.7706, {'top1': 0.7706}), (53, 0.3312, {'top1': 0.3312})]
just computed impact of block 42 . accuracy after removing:  0.8942
removed block 42 current accuracy 0.8942 loss from initial  -0.03200000000000003
since last training loss: -0.03200000000000003 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8214, {'top1': 0.8214}), (2, 0.832, {'top1': 0.832}), (3, 0.8746, {'top1': 0.8746}), (4, 0.8806, {'top1': 0.8806}), (5, 0.8546, {'top1': 0.8546}), (6, 0.8648, {'top1': 0.8648}), (7, 0.8458, {'top1': 0.8458}), (8, 0.8468, {'top1': 0.8468}), (9, 0.867, {'top1': 0.867}), (10, 0.8638, {'top1': 0.8638}), (11, 0.8762, {'top1': 0.8762}), (12, 0.8658, {'top1': 0.8658}), (13, 0.8762, {'top1': 0.8762}), (14, 0.8772, {'top1': 0.8772}), (15, 0.86, {'top1': 0.86}), (16, 0.874, {'top1': 0.874}), (17, 0.8864, {'top1': 0.8864}), (18, 0.3968, {'top1': 0.3968}), (19, 0.8726, {'top1': 0.8726}), (21, 0.873, {'top1': 0.873}), (22, 0.8874, {'top1': 0.8874}), (23, 0.8878, {'top1': 0.8878}), (24, 0.896, {'top1': 0.896}), (25, 0.893, {'top1': 0.893}), (26, 0.8928, {'top1': 0.8928}), (27, 0.871, {'top1': 0.871}), (28, 0.892, {'top1': 0.892}), (29, 0.8896, {'top1': 0.8896}), (30, 0.8936, {'top1': 0.8936}), (31, 0.8924, {'top1': 0.8924}), (33, 0.888, {'top1': 0.888}), (34, 0.8908, {'top1': 0.8908}), (35, 0.8912, {'top1': 0.8912}), (36, 0.4676, {'top1': 0.4676}), (37, 0.8938, {'top1': 0.8938}), (38, 0.8916, {'top1': 0.8916}), (39, 0.8886, {'top1': 0.8886}), (40, 0.8948, {'top1': 0.8948}), (41, 0.8938, {'top1': 0.8938}), (43, 0.897, {'top1': 0.897}), (44, 0.8924, {'top1': 0.8924}), (46, 0.8946, {'top1': 0.8946}), (47, 0.8912, {'top1': 0.8912}), (48, 0.8976, {'top1': 0.8976}), (49, 0.8948, {'top1': 0.8948}), (50, 0.8778, {'top1': 0.8778}), (51, 0.8164, {'top1': 0.8164}), (52, 0.7648, {'top1': 0.7648}), (53, 0.3272, {'top1': 0.3272})]
just computed impact of block 48 . accuracy after removing:  0.8976
removed block 48 current accuracy 0.8976 loss from initial  -0.03539999999999999
since last training loss: -0.03539999999999999 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.8208, {'top1': 0.8208}), (2, 0.8334, {'top1': 0.8334}), (3, 0.8764, {'top1': 0.8764}), (4, 0.8826, {'top1': 0.8826}), (5, 0.8538, {'top1': 0.8538}), (6, 0.8642, {'top1': 0.8642}), (7, 0.8458, {'top1': 0.8458}), (8, 0.845, {'top1': 0.845}), (9, 0.8656, {'top1': 0.8656}), (10, 0.867, {'top1': 0.867}), (11, 0.8776, {'top1': 0.8776}), (12, 0.867, {'top1': 0.867}), (13, 0.8746, {'top1': 0.8746}), (14, 0.8756, {'top1': 0.8756}), (15, 0.8586, {'top1': 0.8586}), (16, 0.8718, {'top1': 0.8718}), (17, 0.8862, {'top1': 0.8862}), (18, 0.413, {'top1': 0.413}), (19, 0.8722, {'top1': 0.8722}), (21, 0.8724, {'top1': 0.8724}), (22, 0.8888, {'top1': 0.8888}), (23, 0.8884, {'top1': 0.8884}), (24, 0.8962, {'top1': 0.8962}), (25, 0.8936, {'top1': 0.8936}), (26, 0.8946, {'top1': 0.8946}), (27, 0.8726, {'top1': 0.8726}), (28, 0.8948, {'top1': 0.8948}), (29, 0.8904, {'top1': 0.8904}), (30, 0.8942, {'top1': 0.8942}), (31, 0.8924, {'top1': 0.8924}), (33, 0.89, {'top1': 0.89}), (34, 0.8916, {'top1': 0.8916}), (35, 0.8944, {'top1': 0.8944}), (36, 0.4746, {'top1': 0.4746}), (37, 0.8948, {'top1': 0.8948}), (38, 0.8936, {'top1': 0.8936}), (39, 0.8894, {'top1': 0.8894}), (40, 0.898, {'top1': 0.898}), (41, 0.8964, {'top1': 0.8964}), (43, 0.8966, {'top1': 0.8966}), (44, 0.896, {'top1': 0.896}), (46, 0.8936, {'top1': 0.8936}), (47, 0.892, {'top1': 0.892}), (49, 0.8954, {'top1': 0.8954}), (50, 0.8796, {'top1': 0.8796}), (51, 0.8144, {'top1': 0.8144}), (52, 0.7594, {'top1': 0.7594}), (53, 0.3152, {'top1': 0.3152})]
just computed impact of block 40 . accuracy after removing:  0.898
removed block 40 current accuracy 0.898 loss from initial  -0.035800000000000054
since last training loss: -0.035800000000000054 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.823, {'top1': 0.823}), (2, 0.8352, {'top1': 0.8352}), (3, 0.8752, {'top1': 0.8752}), (4, 0.884, {'top1': 0.884}), (5, 0.8572, {'top1': 0.8572}), (6, 0.868, {'top1': 0.868}), (7, 0.8496, {'top1': 0.8496}), (8, 0.8508, {'top1': 0.8508}), (9, 0.8674, {'top1': 0.8674}), (10, 0.8668, {'top1': 0.8668}), (11, 0.881, {'top1': 0.881}), (12, 0.8656, {'top1': 0.8656}), (13, 0.8726, {'top1': 0.8726}), (14, 0.8776, {'top1': 0.8776}), (15, 0.86, {'top1': 0.86}), (16, 0.871, {'top1': 0.871}), (17, 0.89, {'top1': 0.89}), (18, 0.4096, {'top1': 0.4096}), (19, 0.8714, {'top1': 0.8714}), (21, 0.8732, {'top1': 0.8732}), (22, 0.8896, {'top1': 0.8896}), (23, 0.8888, {'top1': 0.8888}), (24, 0.8978, {'top1': 0.8978}), (25, 0.8942, {'top1': 0.8942}), (26, 0.8934, {'top1': 0.8934}), (27, 0.8758, {'top1': 0.8758}), (28, 0.8954, {'top1': 0.8954}), (29, 0.89, {'top1': 0.89}), (30, 0.8972, {'top1': 0.8972}), (31, 0.8922, {'top1': 0.8922}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8932, {'top1': 0.8932}), (35, 0.8952, {'top1': 0.8952}), (36, 0.4776, {'top1': 0.4776}), (37, 0.898, {'top1': 0.898}), (38, 0.8934, {'top1': 0.8934}), (39, 0.8904, {'top1': 0.8904}), (41, 0.8972, {'top1': 0.8972}), (43, 0.898, {'top1': 0.898}), (44, 0.8958, {'top1': 0.8958}), (46, 0.8958, {'top1': 0.8958}), (47, 0.8932, {'top1': 0.8932}), (49, 0.899, {'top1': 0.899}), (50, 0.879, {'top1': 0.879}), (51, 0.8146, {'top1': 0.8146}), (52, 0.7632, {'top1': 0.7632}), (53, 0.3226, {'top1': 0.3226})]
just computed impact of block 49 . accuracy after removing:  0.899
removed block 49 current accuracy 0.899 loss from initial  -0.036800000000000055
since last training loss: -0.036800000000000055 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.8332, {'top1': 0.8332}), (2, 0.8436, {'top1': 0.8436}), (3, 0.8804, {'top1': 0.8804}), (4, 0.8888, {'top1': 0.8888}), (5, 0.8638, {'top1': 0.8638}), (6, 0.8726, {'top1': 0.8726}), (7, 0.8586, {'top1': 0.8586}), (8, 0.8588, {'top1': 0.8588}), (9, 0.8756, {'top1': 0.8756}), (10, 0.8754, {'top1': 0.8754}), (11, 0.8858, {'top1': 0.8858}), (12, 0.8718, {'top1': 0.8718}), (13, 0.8808, {'top1': 0.8808}), (14, 0.8852, {'top1': 0.8852}), (15, 0.87, {'top1': 0.87}), (16, 0.876, {'top1': 0.876}), (17, 0.8906, {'top1': 0.8906}), (18, 0.414, {'top1': 0.414}), (19, 0.877, {'top1': 0.877}), (21, 0.8756, {'top1': 0.8756}), (22, 0.8948, {'top1': 0.8948}), (23, 0.8918, {'top1': 0.8918}), (24, 0.8968, {'top1': 0.8968}), (25, 0.8958, {'top1': 0.8958}), (26, 0.895, {'top1': 0.895}), (27, 0.882, {'top1': 0.882}), (28, 0.8964, {'top1': 0.8964}), (29, 0.8904, {'top1': 0.8904}), (30, 0.8978, {'top1': 0.8978}), (31, 0.893, {'top1': 0.893}), (33, 0.8912, {'top1': 0.8912}), (34, 0.894, {'top1': 0.894}), (35, 0.8942, {'top1': 0.8942}), (36, 0.4822, {'top1': 0.4822}), (37, 0.898, {'top1': 0.898}), (38, 0.8948, {'top1': 0.8948}), (39, 0.891, {'top1': 0.891}), (41, 0.8942, {'top1': 0.8942}), (43, 0.8978, {'top1': 0.8978}), (44, 0.898, {'top1': 0.898}), (46, 0.8954, {'top1': 0.8954}), (47, 0.8972, {'top1': 0.8972}), (50, 0.881, {'top1': 0.881}), (51, 0.8198, {'top1': 0.8198}), (52, 0.7508, {'top1': 0.7508}), (53, 0.3246, {'top1': 0.3246})]
just computed impact of block 37 . accuracy after removing:  0.898
removed block 37 current accuracy 0.898 loss from initial  -0.035800000000000054
since last training loss: -0.035800000000000054 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8304, {'top1': 0.8304}), (2, 0.843, {'top1': 0.843}), (3, 0.8792, {'top1': 0.8792}), (4, 0.888, {'top1': 0.888}), (5, 0.8628, {'top1': 0.8628}), (6, 0.8734, {'top1': 0.8734}), (7, 0.8584, {'top1': 0.8584}), (8, 0.8588, {'top1': 0.8588}), (9, 0.8756, {'top1': 0.8756}), (10, 0.8704, {'top1': 0.8704}), (11, 0.8814, {'top1': 0.8814}), (12, 0.8722, {'top1': 0.8722}), (13, 0.878, {'top1': 0.878}), (14, 0.8814, {'top1': 0.8814}), (15, 0.8634, {'top1': 0.8634}), (16, 0.8702, {'top1': 0.8702}), (17, 0.8874, {'top1': 0.8874}), (18, 0.4328, {'top1': 0.4328}), (19, 0.878, {'top1': 0.878}), (21, 0.8748, {'top1': 0.8748}), (22, 0.895, {'top1': 0.895}), (23, 0.8906, {'top1': 0.8906}), (24, 0.897, {'top1': 0.897}), (25, 0.8944, {'top1': 0.8944}), (26, 0.894, {'top1': 0.894}), (27, 0.8804, {'top1': 0.8804}), (28, 0.8966, {'top1': 0.8966}), (29, 0.8928, {'top1': 0.8928}), (30, 0.901, {'top1': 0.901}), (31, 0.8954, {'top1': 0.8954}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8926, {'top1': 0.8926}), (35, 0.8958, {'top1': 0.8958}), (36, 0.4206, {'top1': 0.4206}), (38, 0.8934, {'top1': 0.8934}), (39, 0.8906, {'top1': 0.8906}), (41, 0.8936, {'top1': 0.8936}), (43, 0.8978, {'top1': 0.8978}), (44, 0.8998, {'top1': 0.8998}), (46, 0.8956, {'top1': 0.8956}), (47, 0.8972, {'top1': 0.8972}), (50, 0.8804, {'top1': 0.8804}), (51, 0.8194, {'top1': 0.8194}), (52, 0.755, {'top1': 0.755}), (53, 0.3286, {'top1': 0.3286})]
just computed impact of block 30 . accuracy after removing:  0.901
removed block 30 current accuracy 0.901 loss from initial  -0.03880000000000006
since last training loss: -0.03880000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.8276, {'top1': 0.8276}), (2, 0.8462, {'top1': 0.8462}), (3, 0.8798, {'top1': 0.8798}), (4, 0.8896, {'top1': 0.8896}), (5, 0.863, {'top1': 0.863}), (6, 0.8716, {'top1': 0.8716}), (7, 0.856, {'top1': 0.856}), (8, 0.8578, {'top1': 0.8578}), (9, 0.8756, {'top1': 0.8756}), (10, 0.871, {'top1': 0.871}), (11, 0.8838, {'top1': 0.8838}), (12, 0.8746, {'top1': 0.8746}), (13, 0.8794, {'top1': 0.8794}), (14, 0.8834, {'top1': 0.8834}), (15, 0.8656, {'top1': 0.8656}), (16, 0.8722, {'top1': 0.8722}), (17, 0.8864, {'top1': 0.8864}), (18, 0.4376, {'top1': 0.4376}), (19, 0.873, {'top1': 0.873}), (21, 0.8756, {'top1': 0.8756}), (22, 0.8928, {'top1': 0.8928}), (23, 0.8914, {'top1': 0.8914}), (24, 0.8944, {'top1': 0.8944}), (25, 0.8924, {'top1': 0.8924}), (26, 0.8948, {'top1': 0.8948}), (27, 0.8804, {'top1': 0.8804}), (28, 0.896, {'top1': 0.896}), (29, 0.8914, {'top1': 0.8914}), (31, 0.8936, {'top1': 0.8936}), (33, 0.89, {'top1': 0.89}), (34, 0.893, {'top1': 0.893}), (35, 0.8956, {'top1': 0.8956}), (36, 0.394, {'top1': 0.394}), (38, 0.8948, {'top1': 0.8948}), (39, 0.8892, {'top1': 0.8892}), (41, 0.8972, {'top1': 0.8972}), (43, 0.9, {'top1': 0.9}), (44, 0.8996, {'top1': 0.8996}), (46, 0.8962, {'top1': 0.8962}), (47, 0.8974, {'top1': 0.8974}), (50, 0.8778, {'top1': 0.8778}), (51, 0.816, {'top1': 0.816}), (52, 0.7492, {'top1': 0.7492}), (53, 0.3248, {'top1': 0.3248})]
just computed impact of block 43 . accuracy after removing:  0.9
removed block 43 current accuracy 0.9 loss from initial  -0.037800000000000056
since last training loss: -0.037800000000000056 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.8308, {'top1': 0.8308}), (2, 0.8492, {'top1': 0.8492}), (3, 0.8816, {'top1': 0.8816}), (4, 0.8912, {'top1': 0.8912}), (5, 0.861, {'top1': 0.861}), (6, 0.8718, {'top1': 0.8718}), (7, 0.8574, {'top1': 0.8574}), (8, 0.8572, {'top1': 0.8572}), (9, 0.873, {'top1': 0.873}), (10, 0.8712, {'top1': 0.8712}), (11, 0.8858, {'top1': 0.8858}), (12, 0.8766, {'top1': 0.8766}), (13, 0.8822, {'top1': 0.8822}), (14, 0.8844, {'top1': 0.8844}), (15, 0.869, {'top1': 0.869}), (16, 0.8716, {'top1': 0.8716}), (17, 0.8868, {'top1': 0.8868}), (18, 0.4268, {'top1': 0.4268}), (19, 0.8714, {'top1': 0.8714}), (21, 0.8728, {'top1': 0.8728}), (22, 0.8922, {'top1': 0.8922}), (23, 0.8918, {'top1': 0.8918}), (24, 0.8932, {'top1': 0.8932}), (25, 0.8934, {'top1': 0.8934}), (26, 0.8938, {'top1': 0.8938}), (27, 0.8782, {'top1': 0.8782}), (28, 0.8944, {'top1': 0.8944}), (29, 0.892, {'top1': 0.892}), (31, 0.892, {'top1': 0.892}), (33, 0.8922, {'top1': 0.8922}), (34, 0.8934, {'top1': 0.8934}), (35, 0.8952, {'top1': 0.8952}), (36, 0.3978, {'top1': 0.3978}), (38, 0.8948, {'top1': 0.8948}), (39, 0.8874, {'top1': 0.8874}), (41, 0.8954, {'top1': 0.8954}), (44, 0.8998, {'top1': 0.8998}), (46, 0.8964, {'top1': 0.8964}), (47, 0.895, {'top1': 0.895}), (50, 0.8766, {'top1': 0.8766}), (51, 0.8148, {'top1': 0.8148}), (52, 0.7412, {'top1': 0.7412}), (53, 0.324, {'top1': 0.324})]
just computed impact of block 44 . accuracy after removing:  0.8998
removed block 44 current accuracy 0.8998 loss from initial  -0.03760000000000008
since last training loss: -0.03760000000000008 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.8272, {'top1': 0.8272}), (2, 0.8484, {'top1': 0.8484}), (3, 0.8802, {'top1': 0.8802}), (4, 0.8906, {'top1': 0.8906}), (5, 0.8606, {'top1': 0.8606}), (6, 0.8684, {'top1': 0.8684}), (7, 0.8562, {'top1': 0.8562}), (8, 0.855, {'top1': 0.855}), (9, 0.8726, {'top1': 0.8726}), (10, 0.8708, {'top1': 0.8708}), (11, 0.884, {'top1': 0.884}), (12, 0.8766, {'top1': 0.8766}), (13, 0.8828, {'top1': 0.8828}), (14, 0.8846, {'top1': 0.8846}), (15, 0.8666, {'top1': 0.8666}), (16, 0.873, {'top1': 0.873}), (17, 0.8886, {'top1': 0.8886}), (18, 0.4188, {'top1': 0.4188}), (19, 0.8724, {'top1': 0.8724}), (21, 0.8742, {'top1': 0.8742}), (22, 0.8906, {'top1': 0.8906}), (23, 0.8914, {'top1': 0.8914}), (24, 0.8934, {'top1': 0.8934}), (25, 0.893, {'top1': 0.893}), (26, 0.895, {'top1': 0.895}), (27, 0.8802, {'top1': 0.8802}), (28, 0.8952, {'top1': 0.8952}), (29, 0.8902, {'top1': 0.8902}), (31, 0.8934, {'top1': 0.8934}), (33, 0.891, {'top1': 0.891}), (34, 0.8926, {'top1': 0.8926}), (35, 0.8936, {'top1': 0.8936}), (36, 0.3982, {'top1': 0.3982}), (38, 0.8924, {'top1': 0.8924}), (39, 0.886, {'top1': 0.886}), (41, 0.891, {'top1': 0.891}), (46, 0.8926, {'top1': 0.8926}), (47, 0.8968, {'top1': 0.8968}), (50, 0.874, {'top1': 0.874}), (51, 0.812, {'top1': 0.812}), (52, 0.7356, {'top1': 0.7356}), (53, 0.324, {'top1': 0.324})]
just computed impact of block 47 . accuracy after removing:  0.8968
removed block 47 current accuracy 0.8968 loss from initial  -0.034600000000000075
since last training loss: -0.034600000000000075 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.8284, {'top1': 0.8284}), (2, 0.8494, {'top1': 0.8494}), (3, 0.8742, {'top1': 0.8742}), (4, 0.8858, {'top1': 0.8858}), (5, 0.857, {'top1': 0.857}), (6, 0.8668, {'top1': 0.8668}), (7, 0.852, {'top1': 0.852}), (8, 0.855, {'top1': 0.855}), (9, 0.8686, {'top1': 0.8686}), (10, 0.8704, {'top1': 0.8704}), (11, 0.881, {'top1': 0.881}), (12, 0.876, {'top1': 0.876}), (13, 0.8804, {'top1': 0.8804}), (14, 0.8832, {'top1': 0.8832}), (15, 0.8648, {'top1': 0.8648}), (16, 0.869, {'top1': 0.869}), (17, 0.883, {'top1': 0.883}), (18, 0.435, {'top1': 0.435}), (19, 0.871, {'top1': 0.871}), (21, 0.8714, {'top1': 0.8714}), (22, 0.8906, {'top1': 0.8906}), (23, 0.888, {'top1': 0.888}), (24, 0.8936, {'top1': 0.8936}), (25, 0.8872, {'top1': 0.8872}), (26, 0.8944, {'top1': 0.8944}), (27, 0.8782, {'top1': 0.8782}), (28, 0.8938, {'top1': 0.8938}), (29, 0.891, {'top1': 0.891}), (31, 0.8926, {'top1': 0.8926}), (33, 0.8918, {'top1': 0.8918}), (34, 0.8924, {'top1': 0.8924}), (35, 0.8918, {'top1': 0.8918}), (36, 0.4154, {'top1': 0.4154}), (38, 0.889, {'top1': 0.889}), (39, 0.8854, {'top1': 0.8854}), (41, 0.8886, {'top1': 0.8886}), (46, 0.8906, {'top1': 0.8906}), (50, 0.8718, {'top1': 0.8718}), (51, 0.8068, {'top1': 0.8068}), (52, 0.73, {'top1': 0.73}), (53, 0.3176, {'top1': 0.3176})]
just computed impact of block 26 . accuracy after removing:  0.8944
removed block 26 current accuracy 0.8944 loss from initial  -0.032200000000000006
since last training loss: -0.032200000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.8256, {'top1': 0.8256}), (2, 0.8426, {'top1': 0.8426}), (3, 0.8702, {'top1': 0.8702}), (4, 0.8824, {'top1': 0.8824}), (5, 0.8544, {'top1': 0.8544}), (6, 0.8616, {'top1': 0.8616}), (7, 0.848, {'top1': 0.848}), (8, 0.8524, {'top1': 0.8524}), (9, 0.863, {'top1': 0.863}), (10, 0.8692, {'top1': 0.8692}), (11, 0.878, {'top1': 0.878}), (12, 0.871, {'top1': 0.871}), (13, 0.8776, {'top1': 0.8776}), (14, 0.8804, {'top1': 0.8804}), (15, 0.8616, {'top1': 0.8616}), (16, 0.8616, {'top1': 0.8616}), (17, 0.8782, {'top1': 0.8782}), (18, 0.4184, {'top1': 0.4184}), (19, 0.8658, {'top1': 0.8658}), (21, 0.8666, {'top1': 0.8666}), (22, 0.886, {'top1': 0.886}), (23, 0.8834, {'top1': 0.8834}), (24, 0.8866, {'top1': 0.8866}), (25, 0.8828, {'top1': 0.8828}), (27, 0.8716, {'top1': 0.8716}), (28, 0.8912, {'top1': 0.8912}), (29, 0.883, {'top1': 0.883}), (31, 0.8904, {'top1': 0.8904}), (33, 0.8866, {'top1': 0.8866}), (34, 0.8902, {'top1': 0.8902}), (35, 0.8884, {'top1': 0.8884}), (36, 0.3972, {'top1': 0.3972}), (38, 0.8868, {'top1': 0.8868}), (39, 0.883, {'top1': 0.883}), (41, 0.889, {'top1': 0.889}), (46, 0.8906, {'top1': 0.8906}), (50, 0.8616, {'top1': 0.8616}), (51, 0.8, {'top1': 0.8}), (52, 0.7244, {'top1': 0.7244}), (53, 0.3178, {'top1': 0.3178})]
just computed impact of block 28 . accuracy after removing:  0.8912
removed block 28 current accuracy 0.8912 loss from initial  -0.029000000000000026
since last training loss: -0.029000000000000026 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.8186, {'top1': 0.8186}), (2, 0.8412, {'top1': 0.8412}), (3, 0.8706, {'top1': 0.8706}), (4, 0.8784, {'top1': 0.8784}), (5, 0.8568, {'top1': 0.8568}), (6, 0.861, {'top1': 0.861}), (7, 0.85, {'top1': 0.85}), (8, 0.851, {'top1': 0.851}), (9, 0.8668, {'top1': 0.8668}), (10, 0.8628, {'top1': 0.8628}), (11, 0.8756, {'top1': 0.8756}), (12, 0.8688, {'top1': 0.8688}), (13, 0.8754, {'top1': 0.8754}), (14, 0.8758, {'top1': 0.8758}), (15, 0.8612, {'top1': 0.8612}), (16, 0.8624, {'top1': 0.8624}), (17, 0.876, {'top1': 0.876}), (18, 0.451, {'top1': 0.451}), (19, 0.8596, {'top1': 0.8596}), (21, 0.8626, {'top1': 0.8626}), (22, 0.8792, {'top1': 0.8792}), (23, 0.8794, {'top1': 0.8794}), (24, 0.8838, {'top1': 0.8838}), (25, 0.8804, {'top1': 0.8804}), (27, 0.8664, {'top1': 0.8664}), (29, 0.8792, {'top1': 0.8792}), (31, 0.887, {'top1': 0.887}), (33, 0.8848, {'top1': 0.8848}), (34, 0.8844, {'top1': 0.8844}), (35, 0.8846, {'top1': 0.8846}), (36, 0.3752, {'top1': 0.3752}), (38, 0.8858, {'top1': 0.8858}), (39, 0.8792, {'top1': 0.8792}), (41, 0.8838, {'top1': 0.8838}), (46, 0.887, {'top1': 0.887}), (50, 0.8586, {'top1': 0.8586}), (51, 0.7982, {'top1': 0.7982}), (52, 0.7042, {'top1': 0.7042}), (53, 0.3188, {'top1': 0.3188})]
just computed impact of block 31 . accuracy after removing:  0.887
removed block 31 current accuracy 0.887 loss from initial  -0.024800000000000044
since last training loss: -0.024800000000000044 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.8204, {'top1': 0.8204}), (2, 0.8422, {'top1': 0.8422}), (3, 0.8678, {'top1': 0.8678}), (4, 0.8774, {'top1': 0.8774}), (5, 0.855, {'top1': 0.855}), (6, 0.859, {'top1': 0.859}), (7, 0.85, {'top1': 0.85}), (8, 0.848, {'top1': 0.848}), (9, 0.8646, {'top1': 0.8646}), (10, 0.8622, {'top1': 0.8622}), (11, 0.8762, {'top1': 0.8762}), (12, 0.8706, {'top1': 0.8706}), (13, 0.872, {'top1': 0.872}), (14, 0.871, {'top1': 0.871}), (15, 0.8584, {'top1': 0.8584}), (16, 0.856, {'top1': 0.856}), (17, 0.8726, {'top1': 0.8726}), (18, 0.4572, {'top1': 0.4572}), (19, 0.8606, {'top1': 0.8606}), (21, 0.8586, {'top1': 0.8586}), (22, 0.8764, {'top1': 0.8764}), (23, 0.8762, {'top1': 0.8762}), (24, 0.8836, {'top1': 0.8836}), (25, 0.878, {'top1': 0.878}), (27, 0.864, {'top1': 0.864}), (29, 0.878, {'top1': 0.878}), (33, 0.8808, {'top1': 0.8808}), (34, 0.879, {'top1': 0.879}), (35, 0.8808, {'top1': 0.8808}), (36, 0.3454, {'top1': 0.3454}), (38, 0.8804, {'top1': 0.8804}), (39, 0.8762, {'top1': 0.8762}), (41, 0.8812, {'top1': 0.8812}), (46, 0.883, {'top1': 0.883}), (50, 0.8582, {'top1': 0.8582}), (51, 0.796, {'top1': 0.796}), (52, 0.6948, {'top1': 0.6948}), (53, 0.3216, {'top1': 0.3216})]
just computed impact of block 24 . accuracy after removing:  0.8836
removed block 24 current accuracy 0.8836 loss from initial  -0.021400000000000086
since last training loss: -0.021400000000000086 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.8094, {'top1': 0.8094}), (2, 0.8344, {'top1': 0.8344}), (3, 0.8616, {'top1': 0.8616}), (4, 0.8726, {'top1': 0.8726}), (5, 0.8426, {'top1': 0.8426}), (6, 0.852, {'top1': 0.852}), (7, 0.8398, {'top1': 0.8398}), (8, 0.841, {'top1': 0.841}), (9, 0.855, {'top1': 0.855}), (10, 0.8584, {'top1': 0.8584}), (11, 0.8668, {'top1': 0.8668}), (12, 0.8664, {'top1': 0.8664}), (13, 0.8638, {'top1': 0.8638}), (14, 0.865, {'top1': 0.865}), (15, 0.8512, {'top1': 0.8512}), (16, 0.8466, {'top1': 0.8466}), (17, 0.8632, {'top1': 0.8632}), (18, 0.415, {'top1': 0.415}), (19, 0.8494, {'top1': 0.8494}), (21, 0.8508, {'top1': 0.8508}), (22, 0.867, {'top1': 0.867}), (23, 0.8656, {'top1': 0.8656}), (25, 0.8688, {'top1': 0.8688}), (27, 0.857, {'top1': 0.857}), (29, 0.8712, {'top1': 0.8712}), (33, 0.8776, {'top1': 0.8776}), (34, 0.8746, {'top1': 0.8746}), (35, 0.8774, {'top1': 0.8774}), (36, 0.3216, {'top1': 0.3216}), (38, 0.8772, {'top1': 0.8772}), (39, 0.8728, {'top1': 0.8728}), (41, 0.8756, {'top1': 0.8756}), (46, 0.8764, {'top1': 0.8764}), (50, 0.8506, {'top1': 0.8506}), (51, 0.7898, {'top1': 0.7898}), (52, 0.693, {'top1': 0.693}), (53, 0.3082, {'top1': 0.3082})]
just computed impact of block 33 . accuracy after removing:  0.8776
removed block 33 current accuracy 0.8776 loss from initial  -0.01540000000000008
since last training loss: -0.01540000000000008 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.8042, {'top1': 0.8042}), (2, 0.8268, {'top1': 0.8268}), (3, 0.8542, {'top1': 0.8542}), (4, 0.8642, {'top1': 0.8642}), (5, 0.8386, {'top1': 0.8386}), (6, 0.8454, {'top1': 0.8454}), (7, 0.8362, {'top1': 0.8362}), (8, 0.837, {'top1': 0.837}), (9, 0.8534, {'top1': 0.8534}), (10, 0.855, {'top1': 0.855}), (11, 0.8628, {'top1': 0.8628}), (12, 0.8606, {'top1': 0.8606}), (13, 0.862, {'top1': 0.862}), (14, 0.8616, {'top1': 0.8616}), (15, 0.8486, {'top1': 0.8486}), (16, 0.8434, {'top1': 0.8434}), (17, 0.8638, {'top1': 0.8638}), (18, 0.414, {'top1': 0.414}), (19, 0.8462, {'top1': 0.8462}), (21, 0.8428, {'top1': 0.8428}), (22, 0.86, {'top1': 0.86}), (23, 0.8616, {'top1': 0.8616}), (25, 0.8622, {'top1': 0.8622}), (27, 0.8484, {'top1': 0.8484}), (29, 0.8624, {'top1': 0.8624}), (34, 0.8656, {'top1': 0.8656}), (35, 0.8686, {'top1': 0.8686}), (36, 0.292, {'top1': 0.292}), (38, 0.8716, {'top1': 0.8716}), (39, 0.8648, {'top1': 0.8648}), (41, 0.8732, {'top1': 0.8732}), (46, 0.8708, {'top1': 0.8708}), (50, 0.8442, {'top1': 0.8442}), (51, 0.7824, {'top1': 0.7824}), (52, 0.6796, {'top1': 0.6796}), (53, 0.3014, {'top1': 0.3014})]
just computed impact of block 41 . accuracy after removing:  0.8732
removed block 41 current accuracy 0.8732 loss from initial  -0.01100000000000001
since last training loss: -0.01100000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.7992, {'top1': 0.7992}), (2, 0.82, {'top1': 0.82}), (3, 0.8512, {'top1': 0.8512}), (4, 0.8602, {'top1': 0.8602}), (5, 0.8392, {'top1': 0.8392}), (6, 0.8446, {'top1': 0.8446}), (7, 0.8352, {'top1': 0.8352}), (8, 0.834, {'top1': 0.834}), (9, 0.852, {'top1': 0.852}), (10, 0.8498, {'top1': 0.8498}), (11, 0.8602, {'top1': 0.8602}), (12, 0.8564, {'top1': 0.8564}), (13, 0.8578, {'top1': 0.8578}), (14, 0.8602, {'top1': 0.8602}), (15, 0.8488, {'top1': 0.8488}), (16, 0.842, {'top1': 0.842}), (17, 0.859, {'top1': 0.859}), (18, 0.4244, {'top1': 0.4244}), (19, 0.842, {'top1': 0.842}), (21, 0.8364, {'top1': 0.8364}), (22, 0.8504, {'top1': 0.8504}), (23, 0.8526, {'top1': 0.8526}), (25, 0.858, {'top1': 0.858}), (27, 0.8466, {'top1': 0.8466}), (29, 0.859, {'top1': 0.859}), (34, 0.8608, {'top1': 0.8608}), (35, 0.8626, {'top1': 0.8626}), (36, 0.3136, {'top1': 0.3136}), (38, 0.865, {'top1': 0.865}), (39, 0.8596, {'top1': 0.8596}), (46, 0.866, {'top1': 0.866}), (50, 0.836, {'top1': 0.836}), (51, 0.7684, {'top1': 0.7684}), (52, 0.6692, {'top1': 0.6692}), (53, 0.2974, {'top1': 0.2974})]
just computed impact of block 46 . accuracy after removing:  0.866
removed block 46 current accuracy 0.866 loss from initial  -0.0038000000000000256
since last training loss: -0.0038000000000000256 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.7922, {'top1': 0.7922}), (2, 0.8138, {'top1': 0.8138}), (3, 0.8452, {'top1': 0.8452}), (4, 0.8554, {'top1': 0.8554}), (5, 0.8332, {'top1': 0.8332}), (6, 0.8384, {'top1': 0.8384}), (7, 0.8306, {'top1': 0.8306}), (8, 0.828, {'top1': 0.828}), (9, 0.8454, {'top1': 0.8454}), (10, 0.8448, {'top1': 0.8448}), (11, 0.8566, {'top1': 0.8566}), (12, 0.852, {'top1': 0.852}), (13, 0.8516, {'top1': 0.8516}), (14, 0.8546, {'top1': 0.8546}), (15, 0.8444, {'top1': 0.8444}), (16, 0.8342, {'top1': 0.8342}), (17, 0.8534, {'top1': 0.8534}), (18, 0.4304, {'top1': 0.4304}), (19, 0.8362, {'top1': 0.8362}), (21, 0.8298, {'top1': 0.8298}), (22, 0.8464, {'top1': 0.8464}), (23, 0.8452, {'top1': 0.8452}), (25, 0.8512, {'top1': 0.8512}), (27, 0.8404, {'top1': 0.8404}), (29, 0.8524, {'top1': 0.8524}), (34, 0.8522, {'top1': 0.8522}), (35, 0.8584, {'top1': 0.8584}), (36, 0.3226, {'top1': 0.3226}), (38, 0.8602, {'top1': 0.8602}), (39, 0.8552, {'top1': 0.8552}), (50, 0.8278, {'top1': 0.8278}), (51, 0.7576, {'top1': 0.7576}), (52, 0.6596, {'top1': 0.6596}), (53, 0.2994, {'top1': 0.2994})]
just computed impact of block 38 . accuracy after removing:  0.8602
removed block 38 current accuracy 0.8602 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.791, {'top1': 0.791}), (2, 0.81, {'top1': 0.81}), (3, 0.8432, {'top1': 0.8432}), (4, 0.8526, {'top1': 0.8526}), (5, 0.8302, {'top1': 0.8302}), (6, 0.8316, {'top1': 0.8316}), (7, 0.827, {'top1': 0.827}), (8, 0.8252, {'top1': 0.8252}), (9, 0.8468, {'top1': 0.8468}), (10, 0.8396, {'top1': 0.8396}), (11, 0.8504, {'top1': 0.8504}), (12, 0.8484, {'top1': 0.8484}), (13, 0.849, {'top1': 0.849}), (14, 0.85, {'top1': 0.85}), (15, 0.8426, {'top1': 0.8426}), (16, 0.831, {'top1': 0.831}), (17, 0.8458, {'top1': 0.8458}), (18, 0.4214, {'top1': 0.4214}), (19, 0.8318, {'top1': 0.8318}), (21, 0.8258, {'top1': 0.8258}), (22, 0.8446, {'top1': 0.8446}), (23, 0.8418, {'top1': 0.8418}), (25, 0.847, {'top1': 0.847}), (27, 0.8346, {'top1': 0.8346}), (29, 0.8488, {'top1': 0.8488}), (34, 0.8468, {'top1': 0.8468}), (35, 0.8516, {'top1': 0.8516}), (36, 0.3094, {'top1': 0.3094}), (39, 0.8506, {'top1': 0.8506}), (50, 0.8218, {'top1': 0.8218}), (51, 0.7566, {'top1': 0.7566}), (52, 0.6578, {'top1': 0.6578}), (53, 0.297, {'top1': 0.297})]
just computed impact of block 4 . accuracy after removing:  0.8526
removed block 4 current accuracy 0.8526 loss from initial  0.009599999999999942
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7732, {'top1': 0.7732}), (2, 0.792, {'top1': 0.792}), (3, 0.8324, {'top1': 0.8324}), (5, 0.8174, {'top1': 0.8174}), (6, 0.819, {'top1': 0.819}), (7, 0.812, {'top1': 0.812}), (8, 0.813, {'top1': 0.813}), (9, 0.8246, {'top1': 0.8246}), (10, 0.8268, {'top1': 0.8268}), (11, 0.8348, {'top1': 0.8348}), (12, 0.8368, {'top1': 0.8368}), (13, 0.8354, {'top1': 0.8354}), (14, 0.8388, {'top1': 0.8388}), (15, 0.8292, {'top1': 0.8292}), (16, 0.8136, {'top1': 0.8136}), (17, 0.8328, {'top1': 0.8328}), (18, 0.4254, {'top1': 0.4254}), (19, 0.8236, {'top1': 0.8236}), (21, 0.8216, {'top1': 0.8216}), (22, 0.8398, {'top1': 0.8398}), (23, 0.835, {'top1': 0.835}), (25, 0.841, {'top1': 0.841}), (27, 0.8284, {'top1': 0.8284}), (29, 0.842, {'top1': 0.842}), (34, 0.842, {'top1': 0.842}), (35, 0.8474, {'top1': 0.8474}), (36, 0.3064, {'top1': 0.3064}), (39, 0.8428, {'top1': 0.8428}), (50, 0.8112, {'top1': 0.8112}), (51, 0.7446, {'top1': 0.7446}), (52, 0.6528, {'top1': 0.6528}), (53, 0.2936, {'top1': 0.2936})]
just computed impact of block 35 . accuracy after removing:  0.8474
removed block 35 current accuracy 0.8474 loss from initial  0.014799999999999924
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7682, {'top1': 0.7682}), (2, 0.785, {'top1': 0.785}), (3, 0.8238, {'top1': 0.8238}), (5, 0.8194, {'top1': 0.8194}), (6, 0.812, {'top1': 0.812}), (7, 0.8072, {'top1': 0.8072}), (8, 0.8106, {'top1': 0.8106}), (9, 0.8176, {'top1': 0.8176}), (10, 0.8212, {'top1': 0.8212}), (11, 0.8314, {'top1': 0.8314}), (12, 0.8332, {'top1': 0.8332}), (13, 0.8234, {'top1': 0.8234}), (14, 0.8302, {'top1': 0.8302}), (15, 0.8252, {'top1': 0.8252}), (16, 0.8034, {'top1': 0.8034}), (17, 0.8224, {'top1': 0.8224}), (18, 0.4306, {'top1': 0.4306}), (19, 0.8118, {'top1': 0.8118}), (21, 0.8118, {'top1': 0.8118}), (22, 0.8292, {'top1': 0.8292}), (23, 0.822, {'top1': 0.822}), (25, 0.8284, {'top1': 0.8284}), (27, 0.8158, {'top1': 0.8158}), (29, 0.8322, {'top1': 0.8322}), (34, 0.8316, {'top1': 0.8316}), (36, 0.2908, {'top1': 0.2908}), (39, 0.837, {'top1': 0.837}), (50, 0.7992, {'top1': 0.7992}), (51, 0.734, {'top1': 0.734}), (52, 0.6338, {'top1': 0.6338}), (53, 0.2918, {'top1': 0.2918})]
just computed impact of block 39 . accuracy after removing:  0.837
removed block 39 current accuracy 0.837 loss from initial  0.0252
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7566, {'top1': 0.7566}), (2, 0.7726, {'top1': 0.7726}), (3, 0.8116, {'top1': 0.8116}), (5, 0.8074, {'top1': 0.8074}), (6, 0.801, {'top1': 0.801}), (7, 0.7966, {'top1': 0.7966}), (8, 0.7988, {'top1': 0.7988}), (9, 0.8068, {'top1': 0.8068}), (10, 0.8106, {'top1': 0.8106}), (11, 0.8198, {'top1': 0.8198}), (12, 0.817, {'top1': 0.817}), (13, 0.8178, {'top1': 0.8178}), (14, 0.8198, {'top1': 0.8198}), (15, 0.8106, {'top1': 0.8106}), (16, 0.7938, {'top1': 0.7938}), (17, 0.8204, {'top1': 0.8204}), (18, 0.4212, {'top1': 0.4212}), (19, 0.8056, {'top1': 0.8056}), (21, 0.797, {'top1': 0.797}), (22, 0.8198, {'top1': 0.8198}), (23, 0.812, {'top1': 0.812}), (25, 0.8186, {'top1': 0.8186}), (27, 0.8044, {'top1': 0.8044}), (29, 0.821, {'top1': 0.821}), (34, 0.824, {'top1': 0.824}), (36, 0.2706, {'top1': 0.2706}), (50, 0.79, {'top1': 0.79}), (51, 0.7256, {'top1': 0.7256}), (52, 0.6152, {'top1': 0.6152}), (53, 0.2888, {'top1': 0.2888})]
just computed impact of block 34 . accuracy after removing:  0.824
removed block 34 current accuracy 0.824 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.7426, {'top1': 0.7426}), (2, 0.758, {'top1': 0.758}), (3, 0.7968, {'top1': 0.7968}), (5, 0.8004, {'top1': 0.8004}), (6, 0.7878, {'top1': 0.7878}), (7, 0.786, {'top1': 0.786}), (8, 0.788, {'top1': 0.788}), (9, 0.7942, {'top1': 0.7942}), (10, 0.7946, {'top1': 0.7946}), (11, 0.8084, {'top1': 0.8084}), (12, 0.8014, {'top1': 0.8014}), (13, 0.8042, {'top1': 0.8042}), (14, 0.809, {'top1': 0.809}), (15, 0.7954, {'top1': 0.7954}), (16, 0.774, {'top1': 0.774}), (17, 0.8046, {'top1': 0.8046}), (18, 0.421, {'top1': 0.421}), (19, 0.7862, {'top1': 0.7862}), (21, 0.7762, {'top1': 0.7762}), (22, 0.801, {'top1': 0.801}), (23, 0.7958, {'top1': 0.7958}), (25, 0.801, {'top1': 0.801}), (27, 0.7878, {'top1': 0.7878}), (29, 0.8016, {'top1': 0.8016}), (36, 0.2418, {'top1': 0.2418}), (50, 0.77, {'top1': 0.77}), (51, 0.7064, {'top1': 0.7064}), (52, 0.5914, {'top1': 0.5914}), (53, 0.2848, {'top1': 0.2848})]
just computed impact of block 14 . accuracy after removing:  0.809
removed block 14 current accuracy 0.809 loss from initial  0.053199999999999914
since last training loss: 0.053199999999999914 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.7172, {'top1': 0.7172}), (2, 0.726, {'top1': 0.726}), (3, 0.7752, {'top1': 0.7752}), (5, 0.7848, {'top1': 0.7848}), (6, 0.7626, {'top1': 0.7626}), (7, 0.7606, {'top1': 0.7606}), (8, 0.7546, {'top1': 0.7546}), (9, 0.7592, {'top1': 0.7592}), (10, 0.7572, {'top1': 0.7572}), (11, 0.776, {'top1': 0.776}), (12, 0.7862, {'top1': 0.7862}), (13, 0.7484, {'top1': 0.7484}), (15, 0.7452, {'top1': 0.7452}), (16, 0.6948, {'top1': 0.6948}), (17, 0.755, {'top1': 0.755}), (18, 0.4122, {'top1': 0.4122}), (19, 0.7784, {'top1': 0.7784}), (21, 0.7664, {'top1': 0.7664}), (22, 0.79, {'top1': 0.79}), (23, 0.7866, {'top1': 0.7866}), (25, 0.792, {'top1': 0.792}), (27, 0.7722, {'top1': 0.7722}), (29, 0.7918, {'top1': 0.7918}), (36, 0.2358, {'top1': 0.2358}), (50, 0.7566, {'top1': 0.7566}), (51, 0.6958, {'top1': 0.6958}), (52, 0.6046, {'top1': 0.6046}), (53, 0.307, {'top1': 0.307})]
just computed impact of block 25 . accuracy after removing:  0.792
removed block 25 current accuracy 0.792 loss from initial  0.07019999999999993
since last training loss: 0.07019999999999993 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.6972, {'top1': 0.6972}), (2, 0.7134, {'top1': 0.7134}), (3, 0.7578, {'top1': 0.7578}), (5, 0.7726, {'top1': 0.7726}), (6, 0.749, {'top1': 0.749}), (7, 0.7472, {'top1': 0.7472}), (8, 0.7454, {'top1': 0.7454}), (9, 0.7348, {'top1': 0.7348}), (10, 0.7396, {'top1': 0.7396}), (11, 0.7598, {'top1': 0.7598}), (12, 0.7766, {'top1': 0.7766}), (13, 0.7294, {'top1': 0.7294}), (15, 0.7346, {'top1': 0.7346}), (16, 0.6678, {'top1': 0.6678}), (17, 0.729, {'top1': 0.729}), (18, 0.3724, {'top1': 0.3724}), (19, 0.7538, {'top1': 0.7538}), (21, 0.744, {'top1': 0.744}), (22, 0.7634, {'top1': 0.7634}), (23, 0.7624, {'top1': 0.7624}), (27, 0.7496, {'top1': 0.7496}), (29, 0.7778, {'top1': 0.7778}), (36, 0.2068, {'top1': 0.2068}), (50, 0.7338, {'top1': 0.7338}), (51, 0.6724, {'top1': 0.6724}), (52, 0.5978, {'top1': 0.5978}), (53, 0.2846, {'top1': 0.2846})]
just computed impact of block 29 . accuracy after removing:  0.7778
removed block 29 current accuracy 0.7778 loss from initial  0.08439999999999992
since last training loss: 0.08439999999999992 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.6818, {'top1': 0.6818}), (2, 0.6854, {'top1': 0.6854}), (3, 0.7382, {'top1': 0.7382}), (5, 0.7586, {'top1': 0.7586}), (6, 0.7296, {'top1': 0.7296}), (7, 0.7328, {'top1': 0.7328}), (8, 0.7274, {'top1': 0.7274}), (9, 0.7184, {'top1': 0.7184}), (10, 0.727, {'top1': 0.727}), (11, 0.7442, {'top1': 0.7442}), (12, 0.7594, {'top1': 0.7594}), (13, 0.715, {'top1': 0.715}), (15, 0.7208, {'top1': 0.7208}), (16, 0.659, {'top1': 0.659}), (17, 0.7208, {'top1': 0.7208}), (18, 0.376, {'top1': 0.376}), (19, 0.7366, {'top1': 0.7366}), (21, 0.7228, {'top1': 0.7228}), (22, 0.742, {'top1': 0.742}), (23, 0.7444, {'top1': 0.7444}), (27, 0.7248, {'top1': 0.7248}), (36, 0.1922, {'top1': 0.1922}), (50, 0.7086, {'top1': 0.7086}), (51, 0.6448, {'top1': 0.6448}), (52, 0.5766, {'top1': 0.5766}), (53, 0.2718, {'top1': 0.2718})]
just computed impact of block 12 . accuracy after removing:  0.7594
removed block 12 current accuracy 0.7594 loss from initial  0.1028
since last training loss: 0.1028 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.6594, {'top1': 0.6594}), (2, 0.6436, {'top1': 0.6436}), (3, 0.7096, {'top1': 0.7096}), (5, 0.7054, {'top1': 0.7054}), (6, 0.6976, {'top1': 0.6976}), (7, 0.6846, {'top1': 0.6846}), (8, 0.684, {'top1': 0.684}), (9, 0.695, {'top1': 0.695}), (10, 0.6898, {'top1': 0.6898}), (11, 0.7146, {'top1': 0.7146}), (13, 0.7068, {'top1': 0.7068}), (15, 0.6922, {'top1': 0.6922}), (16, 0.6246, {'top1': 0.6246}), (17, 0.7076, {'top1': 0.7076}), (18, 0.3806, {'top1': 0.3806}), (19, 0.7228, {'top1': 0.7228}), (21, 0.7032, {'top1': 0.7032}), (22, 0.7254, {'top1': 0.7254}), (23, 0.7398, {'top1': 0.7398}), (27, 0.703, {'top1': 0.703}), (36, 0.1878, {'top1': 0.1878}), (50, 0.6916, {'top1': 0.6916}), (51, 0.627, {'top1': 0.627}), (52, 0.5572, {'top1': 0.5572}), (53, 0.2694, {'top1': 0.2694})]
just computed impact of block 23 . accuracy after removing:  0.7398
removed block 23 current accuracy 0.7398 loss from initial  0.12239999999999995
since last training loss: 0.12239999999999995 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.637, {'top1': 0.637}), (2, 0.6232, {'top1': 0.6232}), (3, 0.6906, {'top1': 0.6906}), (5, 0.6956, {'top1': 0.6956}), (6, 0.6814, {'top1': 0.6814}), (7, 0.6668, {'top1': 0.6668}), (8, 0.677, {'top1': 0.677}), (9, 0.6666, {'top1': 0.6666}), (10, 0.679, {'top1': 0.679}), (11, 0.697, {'top1': 0.697}), (13, 0.678, {'top1': 0.678}), (15, 0.6824, {'top1': 0.6824}), (16, 0.6118, {'top1': 0.6118}), (17, 0.6868, {'top1': 0.6868}), (18, 0.3364, {'top1': 0.3364}), (19, 0.6946, {'top1': 0.6946}), (21, 0.6754, {'top1': 0.6754}), (22, 0.7016, {'top1': 0.7016}), (27, 0.6772, {'top1': 0.6772}), (36, 0.1756, {'top1': 0.1756}), (50, 0.6704, {'top1': 0.6704}), (51, 0.6, {'top1': 0.6}), (52, 0.5312, {'top1': 0.5312}), (53, 0.251, {'top1': 0.251})]
just computed impact of block 22 . accuracy after removing:  0.7016
removed block 22 current accuracy 0.7016 loss from initial  0.16059999999999997
since last training loss: 0.16059999999999997 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.6054, {'top1': 0.6054}), (2, 0.5858, {'top1': 0.5858}), (3, 0.6468, {'top1': 0.6468}), (5, 0.655, {'top1': 0.655}), (6, 0.6418, {'top1': 0.6418}), (7, 0.6244, {'top1': 0.6244}), (8, 0.6368, {'top1': 0.6368}), (9, 0.6246, {'top1': 0.6246}), (10, 0.6422, {'top1': 0.6422}), (11, 0.668, {'top1': 0.668}), (13, 0.6422, {'top1': 0.6422}), (15, 0.6462, {'top1': 0.6462}), (16, 0.592, {'top1': 0.592}), (17, 0.6504, {'top1': 0.6504}), (18, 0.321, {'top1': 0.321}), (19, 0.6394, {'top1': 0.6394}), (21, 0.6276, {'top1': 0.6276}), (27, 0.6316, {'top1': 0.6316}), (36, 0.1708, {'top1': 0.1708}), (50, 0.6346, {'top1': 0.6346}), (51, 0.5498, {'top1': 0.5498}), (52, 0.4786, {'top1': 0.4786}), (53, 0.2242, {'top1': 0.2242})]
just computed impact of block 11 . accuracy after removing:  0.668
removed block 11 current accuracy 0.668 loss from initial  0.19419999999999993
since last training loss: 0.19419999999999993 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.5546, {'top1': 0.5546}), (2, 0.5626, {'top1': 0.5626}), (3, 0.6156, {'top1': 0.6156}), (5, 0.6116, {'top1': 0.6116}), (6, 0.6126, {'top1': 0.6126}), (7, 0.5898, {'top1': 0.5898}), (8, 0.6026, {'top1': 0.6026}), (9, 0.5802, {'top1': 0.5802}), (10, 0.5962, {'top1': 0.5962}), (13, 0.5594, {'top1': 0.5594}), (15, 0.5942, {'top1': 0.5942}), (16, 0.5062, {'top1': 0.5062}), (17, 0.5778, {'top1': 0.5778}), (18, 0.2814, {'top1': 0.2814}), (19, 0.6188, {'top1': 0.6188}), (21, 0.6108, {'top1': 0.6108}), (27, 0.6142, {'top1': 0.6142}), (36, 0.171, {'top1': 0.171}), (50, 0.586, {'top1': 0.586}), (51, 0.5464, {'top1': 0.5464}), (52, 0.4896, {'top1': 0.4896}), (53, 0.257, {'top1': 0.257})]
just computed impact of block 19 . accuracy after removing:  0.6188
removed block 19 current accuracy 0.6188 loss from initial  0.24339999999999995
since last training loss: 0.24339999999999995 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.4944, {'top1': 0.4944}), (2, 0.4968, {'top1': 0.4968}), (3, 0.5562, {'top1': 0.5562}), (5, 0.5568, {'top1': 0.5568}), (6, 0.557, {'top1': 0.557}), (7, 0.5358, {'top1': 0.5358}), (8, 0.547, {'top1': 0.547}), (9, 0.5306, {'top1': 0.5306}), (10, 0.5444, {'top1': 0.5444}), (13, 0.5136, {'top1': 0.5136}), (15, 0.539, {'top1': 0.539}), (16, 0.446, {'top1': 0.446}), (17, 0.5258, {'top1': 0.5258}), (18, 0.2268, {'top1': 0.2268}), (21, 0.5462, {'top1': 0.5462}), (27, 0.5478, {'top1': 0.5478}), (36, 0.1658, {'top1': 0.1658}), (50, 0.5264, {'top1': 0.5264}), (51, 0.4856, {'top1': 0.4856}), (52, 0.4268, {'top1': 0.4268}), (53, 0.2496, {'top1': 0.2496})]
just computed impact of block 6 . accuracy after removing:  0.557
removed block 6 current accuracy 0.557 loss from initial  0.3051999999999999
since last training loss: 0.3051999999999999 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.4234, {'top1': 0.4234}), (2, 0.4218, {'top1': 0.4218}), (3, 0.4834, {'top1': 0.4834}), (5, 0.4718, {'top1': 0.4718}), (7, 0.4422, {'top1': 0.4422}), (8, 0.466, {'top1': 0.466}), (9, 0.4674, {'top1': 0.4674}), (10, 0.479, {'top1': 0.479}), (13, 0.4606, {'top1': 0.4606}), (15, 0.48, {'top1': 0.48}), (16, 0.3998, {'top1': 0.3998}), (17, 0.4832, {'top1': 0.4832}), (18, 0.2262, {'top1': 0.2262}), (21, 0.4852, {'top1': 0.4852}), (27, 0.4856, {'top1': 0.4856}), (36, 0.1662, {'top1': 0.1662}), (50, 0.4752, {'top1': 0.4752}), (51, 0.435, {'top1': 0.435}), (52, 0.4236, {'top1': 0.4236}), (53, 0.227, {'top1': 0.227})]
just computed impact of block 27 . accuracy after removing:  0.4856
removed block 27 current accuracy 0.4856 loss from initial  0.3766
since last training loss: 0.3766 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.3712, {'top1': 0.3712}), (2, 0.3626, {'top1': 0.3626}), (3, 0.4078, {'top1': 0.4078}), (5, 0.4032, {'top1': 0.4032}), (7, 0.3748, {'top1': 0.3748}), (8, 0.3992, {'top1': 0.3992}), (9, 0.4124, {'top1': 0.4124}), (10, 0.4194, {'top1': 0.4194}), (13, 0.4136, {'top1': 0.4136}), (15, 0.4124, {'top1': 0.4124}), (16, 0.3466, {'top1': 0.3466}), (17, 0.4246, {'top1': 0.4246}), (18, 0.2216, {'top1': 0.2216}), (21, 0.4082, {'top1': 0.4082}), (36, 0.163, {'top1': 0.163}), (50, 0.411, {'top1': 0.411}), (51, 0.3728, {'top1': 0.3728}), (52, 0.38, {'top1': 0.38}), (53, 0.206, {'top1': 0.206})]
just computed impact of block 17 . accuracy after removing:  0.4246
removed block 17 current accuracy 0.4246 loss from initial  0.4376
since last training loss: 0.4376 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.3248, {'top1': 0.3248}), (2, 0.3236, {'top1': 0.3236}), (3, 0.3632, {'top1': 0.3632}), (5, 0.3466, {'top1': 0.3466}), (7, 0.342, {'top1': 0.342}), (8, 0.3506, {'top1': 0.3506}), (9, 0.3542, {'top1': 0.3542}), (10, 0.341, {'top1': 0.341}), (13, 0.3118, {'top1': 0.3118}), (15, 0.3176, {'top1': 0.3176}), (16, 0.2678, {'top1': 0.2678}), (18, 0.2024, {'top1': 0.2024}), (21, 0.367, {'top1': 0.367}), (36, 0.157, {'top1': 0.157}), (50, 0.3558, {'top1': 0.3558}), (51, 0.3466, {'top1': 0.3466}), (52, 0.3728, {'top1': 0.3728}), (53, 0.1902, {'top1': 0.1902})]
just computed impact of block 52 . accuracy after removing:  0.3728
removed block 52 current accuracy 0.3728 loss from initial  0.48939999999999995
since last training loss: 0.48939999999999995 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.2966, {'top1': 0.2966}), (2, 0.252, {'top1': 0.252}), (3, 0.3356, {'top1': 0.3356}), (5, 0.3242, {'top1': 0.3242}), (7, 0.3186, {'top1': 0.3186}), (8, 0.3306, {'top1': 0.3306}), (9, 0.3208, {'top1': 0.3208}), (10, 0.3272, {'top1': 0.3272}), (13, 0.3218, {'top1': 0.3218}), (15, 0.3222, {'top1': 0.3222}), (16, 0.2896, {'top1': 0.2896}), (18, 0.1112, {'top1': 0.1112}), (21, 0.3098, {'top1': 0.3098}), (36, 0.1748, {'top1': 0.1748}), (50, 0.3078, {'top1': 0.3078}), (51, 0.2576, {'top1': 0.2576}), (53, 0.1718, {'top1': 0.1718})]
just computed impact of block 3 . accuracy after removing:  0.3356
removed block 3 current accuracy 0.3356 loss from initial  0.5266
since last training loss: 0.5266 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.2322, {'top1': 0.2322}), (2, 0.1842, {'top1': 0.1842}), (5, 0.2628, {'top1': 0.2628}), (7, 0.2474, {'top1': 0.2474}), (8, 0.2722, {'top1': 0.2722}), (9, 0.2776, {'top1': 0.2776}), (10, 0.2704, {'top1': 0.2704}), (13, 0.2816, {'top1': 0.2816}), (15, 0.263, {'top1': 0.263}), (16, 0.2528, {'top1': 0.2528}), (18, 0.113, {'top1': 0.113}), (21, 0.2532, {'top1': 0.2532}), (36, 0.1618, {'top1': 0.1618}), (50, 0.2882, {'top1': 0.2882}), (51, 0.2536, {'top1': 0.2536}), (53, 0.16, {'top1': 0.16})]
just computed impact of block 50 . accuracy after removing:  0.2882
removed block 50 current accuracy 0.2882 loss from initial  0.574
since last training loss: 0.574 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.2354, {'top1': 0.2354}), (2, 0.1938, {'top1': 0.1938}), (5, 0.233, {'top1': 0.233}), (7, 0.2342, {'top1': 0.2342}), (8, 0.2586, {'top1': 0.2586}), (9, 0.2538, {'top1': 0.2538}), (10, 0.2544, {'top1': 0.2544}), (13, 0.2704, {'top1': 0.2704}), (15, 0.255, {'top1': 0.255}), (16, 0.2698, {'top1': 0.2698}), (18, 0.159, {'top1': 0.159}), (21, 0.2528, {'top1': 0.2528}), (36, 0.1946, {'top1': 0.1946}), (51, 0.2412, {'top1': 0.2412}), (53, 0.1592, {'top1': 0.1592})]
just computed impact of block 13 . accuracy after removing:  0.2704
removed block 13 current accuracy 0.2704 loss from initial  0.5918
since last training loss: 0.5918 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.237, {'top1': 0.237}), (2, 0.1714, {'top1': 0.1714}), (5, 0.2322, {'top1': 0.2322}), (7, 0.2346, {'top1': 0.2346}), (8, 0.2472, {'top1': 0.2472}), (9, 0.2224, {'top1': 0.2224}), (10, 0.2436, {'top1': 0.2436}), (15, 0.2368, {'top1': 0.2368}), (16, 0.2416, {'top1': 0.2416}), (18, 0.1468, {'top1': 0.1468}), (21, 0.2288, {'top1': 0.2288}), (36, 0.196, {'top1': 0.196}), (51, 0.205, {'top1': 0.205}), (53, 0.1228, {'top1': 0.1228})]
just computed impact of block 8 . accuracy after removing:  0.2472
removed block 8 current accuracy 0.2472 loss from initial  0.615
since last training loss: 0.615 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.2218, {'top1': 0.2218}), (2, 0.1564, {'top1': 0.1564}), (5, 0.2206, {'top1': 0.2206}), (7, 0.2148, {'top1': 0.2148}), (9, 0.193, {'top1': 0.193}), (10, 0.216, {'top1': 0.216}), (15, 0.2054, {'top1': 0.2054}), (16, 0.2214, {'top1': 0.2214}), (18, 0.1396, {'top1': 0.1396}), (21, 0.193, {'top1': 0.193}), (36, 0.173, {'top1': 0.173}), (51, 0.188, {'top1': 0.188}), (53, 0.107, {'top1': 0.107})]
just computed impact of block 0 . accuracy after removing:  0.2218
removed block 0 current accuracy 0.2218 loss from initial  0.6404
since last training loss: 0.6404 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(2, 0.161, {'top1': 0.161}), (5, 0.1778, {'top1': 0.1778}), (7, 0.1844, {'top1': 0.1844}), (9, 0.1886, {'top1': 0.1886}), (10, 0.2172, {'top1': 0.2172}), (15, 0.1922, {'top1': 0.1922}), (16, 0.1998, {'top1': 0.1998}), (18, 0.1234, {'top1': 0.1234}), (21, 0.1778, {'top1': 0.1778}), (36, 0.1608, {'top1': 0.1608}), (51, 0.1778, {'top1': 0.1778}), (53, 0.1022, {'top1': 0.1022})]
just computed impact of block 10 . accuracy after removing:  0.2172
removed block 10 current accuracy 0.2172 loss from initial  0.645
since last training loss: 0.645 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(2, 0.1494, {'top1': 0.1494}), (5, 0.19, {'top1': 0.19}), (7, 0.1764, {'top1': 0.1764}), (9, 0.1888, {'top1': 0.1888}), (15, 0.177, {'top1': 0.177}), (16, 0.1862, {'top1': 0.1862}), (18, 0.148, {'top1': 0.148}), (21, 0.1558, {'top1': 0.1558}), (36, 0.1492, {'top1': 0.1492}), (51, 0.1712, {'top1': 0.1712}), (53, 0.091, {'top1': 0.091})]
just computed impact of block 5 . accuracy after removing:  0.19
removed block 5 current accuracy 0.19 loss from initial  0.6721999999999999
since last training loss: 0.6721999999999999 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(2, 0.1374, {'top1': 0.1374}), (7, 0.1642, {'top1': 0.1642}), (9, 0.1888, {'top1': 0.1888}), (15, 0.1594, {'top1': 0.1594}), (16, 0.183, {'top1': 0.183}), (18, 0.1542, {'top1': 0.1542}), (21, 0.141, {'top1': 0.141}), (36, 0.1552, {'top1': 0.1552}), (51, 0.1652, {'top1': 0.1652}), (53, 0.0826, {'top1': 0.0826})]
just computed impact of block 9 . accuracy after removing:  0.1888
removed block 9 current accuracy 0.1888 loss from initial  0.6734
training start
training epoch 0 val accuracy 0.797 topk_dict {'top1': 0.797} is_best True lr [0.1]
training epoch 1 val accuracy 0.7936 topk_dict {'top1': 0.7936} is_best False lr [0.1]
training epoch 2 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best True lr [0.1]
training epoch 3 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best True lr [0.1]
training epoch 4 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.1]
training epoch 5 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.1]
training epoch 6 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best False lr [0.1]
training epoch 7 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 8 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.1]
training epoch 9 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 10 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 11 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.1]
training epoch 12 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best True lr [0.1]
training epoch 13 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 14 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 15 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 16 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best False lr [0.1]
training epoch 17 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 18 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 19 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 20 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 21 val accuracy 0.8248 topk_dict {'top1': 0.8248} is_best False lr [0.1]
training epoch 22 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 23 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best False lr [0.1]
training epoch 24 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 25 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 26 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 27 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 28 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 29 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best False lr [0.1]
training epoch 30 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 31 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 32 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 33 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 34 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 35 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 36 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 37 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 38 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 39 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 40 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 41 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 42 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 43 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 44 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 45 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 46 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 47 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 48 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.1]
training epoch 49 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 50 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 51 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.1]
training epoch 52 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 53 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 54 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 55 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 56 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 57 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 58 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 59 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 60 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 61 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 62 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 63 val accuracy 0.806 topk_dict {'top1': 0.806} is_best False lr [0.1]
training epoch 64 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 65 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 66 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 67 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 68 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 69 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 70 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 71 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 72 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 73 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 74 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 75 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 76 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 77 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 78 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 79 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 80 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 81 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 82 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 83 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 84 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 85 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 86 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 87 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 88 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 89 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 90 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 91 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 92 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 93 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 94 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 95 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 96 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 97 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 98 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 99 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 100 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 101 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 102 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 103 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 104 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 105 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 106 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 107 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 108 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 109 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 110 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 111 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 112 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 113 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 114 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 115 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 116 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 117 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 118 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 119 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 120 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best True lr [0.1]
training epoch 121 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 122 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 123 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 124 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 125 val accuracy 0.8028 topk_dict {'top1': 0.8028} is_best False lr [0.1]
training epoch 126 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 127 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 128 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 129 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 130 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 131 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 132 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 133 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 134 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.1]
training epoch 135 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 136 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 137 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 138 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 139 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 140 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 141 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 142 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 143 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 144 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 145 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 146 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 147 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 148 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 149 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 150 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 151 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 152 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 153 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 154 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 155 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 156 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 157 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 158 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 159 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 160 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 161 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 162 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 163 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 164 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 165 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 166 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 167 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 168 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 169 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 170 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 171 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 172 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 173 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 174 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 175 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 176 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 177 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 178 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 179 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 180 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 181 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 182 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 183 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 184 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 185 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 186 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 187 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 188 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 189 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 190 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 191 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 192 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 193 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 194 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 195 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 196 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 197 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 198 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 199 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.010000000000000002]
training epoch 200 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.010000000000000002]
training epoch 201 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.010000000000000002]
training epoch 202 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 203 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 204 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 205 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 206 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 207 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 208 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 209 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.010000000000000002]
training epoch 210 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 211 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 212 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 213 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 214 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.010000000000000002]
training epoch 215 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 216 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 217 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 218 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 219 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 220 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 221 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 222 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 223 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 224 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.010000000000000002]
training epoch 225 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 226 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 227 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 228 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 229 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 230 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 231 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 232 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 233 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 234 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.010000000000000002]
training epoch 235 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 236 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 237 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 238 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 239 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 240 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 241 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 242 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.010000000000000002]
training epoch 246 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 250 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 300 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.0010000000000000002]
training epoch 301 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 302 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 303 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 304 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 305 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 306 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 307 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 308 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 309 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 310 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 311 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 312 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 313 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 314 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 315 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 316 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 317 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 318 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 319 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 320 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 321 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 322 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 323 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 324 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 325 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 326 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 327 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 328 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 329 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 330 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 331 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 332 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 333 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 334 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 335 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 336 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 337 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 338 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 339 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 340 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 341 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 342 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 343 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 344 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 345 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 346 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 347 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 348 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 349 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 350 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 351 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 352 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 353 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 354 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 355 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 356 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 357 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 358 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 359 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 366 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
loading model_best from epoch 300 (acc 0.923000)
finished training. finished 399 epochs. accuracy 0.923 topk_dict {'top1': 0.923}
