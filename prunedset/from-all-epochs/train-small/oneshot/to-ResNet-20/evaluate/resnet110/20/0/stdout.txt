start iteration 0
(cache recomputed) Accuracy log [(0, 0.7956, {'top1': 0.7956}), (1, 0.8216, {'top1': 0.8216}), (2, 0.6462, {'top1': 0.6462}), (3, 0.8156, {'top1': 0.8156}), (4, 0.8306, {'top1': 0.8306}), (5, 0.8042, {'top1': 0.8042}), (6, 0.8184, {'top1': 0.8184}), (7, 0.826, {'top1': 0.826}), (8, 0.8114, {'top1': 0.8114}), (9, 0.751, {'top1': 0.751}), (10, 0.8382, {'top1': 0.8382}), (11, 0.8312, {'top1': 0.8312}), (12, 0.8284, {'top1': 0.8284}), (13, 0.809, {'top1': 0.809}), (14, 0.8396, {'top1': 0.8396}), (15, 0.8382, {'top1': 0.8382}), (16, 0.8298, {'top1': 0.8298}), (17, 0.828, {'top1': 0.828}), (18, 0.6004, {'top1': 0.6004}), (19, 0.7712, {'top1': 0.7712}), (20, 0.8222, {'top1': 0.8222}), (21, 0.8454, {'top1': 0.8454}), (22, 0.8294, {'top1': 0.8294}), (23, 0.8372, {'top1': 0.8372}), (24, 0.8284, {'top1': 0.8284}), (25, 0.8344, {'top1': 0.8344}), (26, 0.8378, {'top1': 0.8378}), (27, 0.83, {'top1': 0.83}), (28, 0.84, {'top1': 0.84}), (29, 0.8306, {'top1': 0.8306}), (30, 0.8298, {'top1': 0.8298}), (31, 0.8392, {'top1': 0.8392}), (32, 0.8402, {'top1': 0.8402}), (33, 0.8396, {'top1': 0.8396}), (34, 0.8374, {'top1': 0.8374}), (35, 0.8348, {'top1': 0.8348}), (36, 0.6044, {'top1': 0.6044}), (37, 0.8394, {'top1': 0.8394}), (38, 0.8414, {'top1': 0.8414}), (39, 0.8396, {'top1': 0.8396}), (40, 0.84, {'top1': 0.84}), (41, 0.8388, {'top1': 0.8388}), (42, 0.8392, {'top1': 0.8392}), (43, 0.8392, {'top1': 0.8392}), (44, 0.8368, {'top1': 0.8368}), (45, 0.837, {'top1': 0.837}), (46, 0.8378, {'top1': 0.8378}), (47, 0.8388, {'top1': 0.8388}), (48, 0.8384, {'top1': 0.8384}), (49, 0.841, {'top1': 0.841}), (50, 0.825, {'top1': 0.825}), (51, 0.761, {'top1': 0.761}), (52, 0.329, {'top1': 0.329}), (53, 0.1664, {'top1': 0.1664})]
just computed impact of block 21 . accuracy after removing:  0.8454
removed block 21 current accuracy 0.8454 loss from initial  -0.007400000000000073
since last training loss: -0.007400000000000073 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.8024, {'top1': 0.8024}), (1, 0.8214, {'top1': 0.8214}), (2, 0.6514, {'top1': 0.6514}), (3, 0.8202, {'top1': 0.8202}), (4, 0.8324, {'top1': 0.8324}), (5, 0.8114, {'top1': 0.8114}), (6, 0.8204, {'top1': 0.8204}), (7, 0.8282, {'top1': 0.8282}), (8, 0.815, {'top1': 0.815}), (9, 0.7704, {'top1': 0.7704}), (10, 0.8392, {'top1': 0.8392}), (11, 0.8328, {'top1': 0.8328}), (12, 0.8338, {'top1': 0.8338}), (13, 0.8184, {'top1': 0.8184}), (14, 0.843, {'top1': 0.843}), (15, 0.8414, {'top1': 0.8414}), (16, 0.8314, {'top1': 0.8314}), (17, 0.8344, {'top1': 0.8344}), (18, 0.5868, {'top1': 0.5868}), (19, 0.7558, {'top1': 0.7558}), (20, 0.814, {'top1': 0.814}), (22, 0.8098, {'top1': 0.8098}), (23, 0.831, {'top1': 0.831}), (24, 0.828, {'top1': 0.828}), (25, 0.8302, {'top1': 0.8302}), (26, 0.8412, {'top1': 0.8412}), (27, 0.8288, {'top1': 0.8288}), (28, 0.8434, {'top1': 0.8434}), (29, 0.8346, {'top1': 0.8346}), (30, 0.8318, {'top1': 0.8318}), (31, 0.8396, {'top1': 0.8396}), (32, 0.8386, {'top1': 0.8386}), (33, 0.8426, {'top1': 0.8426}), (34, 0.8414, {'top1': 0.8414}), (35, 0.839, {'top1': 0.839}), (36, 0.5702, {'top1': 0.5702}), (37, 0.8432, {'top1': 0.8432}), (38, 0.8454, {'top1': 0.8454}), (39, 0.8426, {'top1': 0.8426}), (40, 0.8448, {'top1': 0.8448}), (41, 0.8428, {'top1': 0.8428}), (42, 0.8462, {'top1': 0.8462}), (43, 0.843, {'top1': 0.843}), (44, 0.8424, {'top1': 0.8424}), (45, 0.8438, {'top1': 0.8438}), (46, 0.8436, {'top1': 0.8436}), (47, 0.8438, {'top1': 0.8438}), (48, 0.8442, {'top1': 0.8442}), (49, 0.8454, {'top1': 0.8454}), (50, 0.827, {'top1': 0.827}), (51, 0.766, {'top1': 0.766}), (52, 0.296, {'top1': 0.296}), (53, 0.1524, {'top1': 0.1524})]
just computed impact of block 42 . accuracy after removing:  0.8462
removed block 42 current accuracy 0.8462 loss from initial  -0.008199999999999985
since last training loss: -0.008199999999999985 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8054, {'top1': 0.8054}), (1, 0.8204, {'top1': 0.8204}), (2, 0.6544, {'top1': 0.6544}), (3, 0.824, {'top1': 0.824}), (4, 0.8348, {'top1': 0.8348}), (5, 0.8122, {'top1': 0.8122}), (6, 0.8226, {'top1': 0.8226}), (7, 0.8312, {'top1': 0.8312}), (8, 0.818, {'top1': 0.818}), (9, 0.775, {'top1': 0.775}), (10, 0.8436, {'top1': 0.8436}), (11, 0.8356, {'top1': 0.8356}), (12, 0.8384, {'top1': 0.8384}), (13, 0.8188, {'top1': 0.8188}), (14, 0.8446, {'top1': 0.8446}), (15, 0.8434, {'top1': 0.8434}), (16, 0.8344, {'top1': 0.8344}), (17, 0.8374, {'top1': 0.8374}), (18, 0.5816, {'top1': 0.5816}), (19, 0.7544, {'top1': 0.7544}), (20, 0.8168, {'top1': 0.8168}), (22, 0.8126, {'top1': 0.8126}), (23, 0.8316, {'top1': 0.8316}), (24, 0.829, {'top1': 0.829}), (25, 0.8318, {'top1': 0.8318}), (26, 0.8436, {'top1': 0.8436}), (27, 0.8324, {'top1': 0.8324}), (28, 0.845, {'top1': 0.845}), (29, 0.8372, {'top1': 0.8372}), (30, 0.8358, {'top1': 0.8358}), (31, 0.8404, {'top1': 0.8404}), (32, 0.8438, {'top1': 0.8438}), (33, 0.8442, {'top1': 0.8442}), (34, 0.8428, {'top1': 0.8428}), (35, 0.8408, {'top1': 0.8408}), (36, 0.5722, {'top1': 0.5722}), (37, 0.8444, {'top1': 0.8444}), (38, 0.8468, {'top1': 0.8468}), (39, 0.8432, {'top1': 0.8432}), (40, 0.8454, {'top1': 0.8454}), (41, 0.8428, {'top1': 0.8428}), (43, 0.8446, {'top1': 0.8446}), (44, 0.8448, {'top1': 0.8448}), (45, 0.8456, {'top1': 0.8456}), (46, 0.8436, {'top1': 0.8436}), (47, 0.8446, {'top1': 0.8446}), (48, 0.8456, {'top1': 0.8456}), (49, 0.8468, {'top1': 0.8468}), (50, 0.8262, {'top1': 0.8262}), (51, 0.7696, {'top1': 0.7696}), (52, 0.2892, {'top1': 0.2892}), (53, 0.1542, {'top1': 0.1542})]
just computed impact of block 38 . accuracy after removing:  0.8468
removed block 38 current accuracy 0.8468 loss from initial  -0.00880000000000003
since last training loss: -0.00880000000000003 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.806, {'top1': 0.806}), (1, 0.822, {'top1': 0.822}), (2, 0.66, {'top1': 0.66}), (3, 0.8252, {'top1': 0.8252}), (4, 0.8376, {'top1': 0.8376}), (5, 0.8132, {'top1': 0.8132}), (6, 0.8266, {'top1': 0.8266}), (7, 0.8314, {'top1': 0.8314}), (8, 0.8202, {'top1': 0.8202}), (9, 0.7748, {'top1': 0.7748}), (10, 0.844, {'top1': 0.844}), (11, 0.838, {'top1': 0.838}), (12, 0.8406, {'top1': 0.8406}), (13, 0.818, {'top1': 0.818}), (14, 0.8454, {'top1': 0.8454}), (15, 0.8436, {'top1': 0.8436}), (16, 0.8356, {'top1': 0.8356}), (17, 0.8382, {'top1': 0.8382}), (18, 0.5746, {'top1': 0.5746}), (19, 0.7544, {'top1': 0.7544}), (20, 0.821, {'top1': 0.821}), (22, 0.8156, {'top1': 0.8156}), (23, 0.8314, {'top1': 0.8314}), (24, 0.8312, {'top1': 0.8312}), (25, 0.8332, {'top1': 0.8332}), (26, 0.8438, {'top1': 0.8438}), (27, 0.835, {'top1': 0.835}), (28, 0.845, {'top1': 0.845}), (29, 0.84, {'top1': 0.84}), (30, 0.8356, {'top1': 0.8356}), (31, 0.844, {'top1': 0.844}), (32, 0.8464, {'top1': 0.8464}), (33, 0.847, {'top1': 0.847}), (34, 0.844, {'top1': 0.844}), (35, 0.8436, {'top1': 0.8436}), (36, 0.5794, {'top1': 0.5794}), (37, 0.8444, {'top1': 0.8444}), (39, 0.8448, {'top1': 0.8448}), (40, 0.846, {'top1': 0.846}), (41, 0.8454, {'top1': 0.8454}), (43, 0.8458, {'top1': 0.8458}), (44, 0.8466, {'top1': 0.8466}), (45, 0.8454, {'top1': 0.8454}), (46, 0.8444, {'top1': 0.8444}), (47, 0.845, {'top1': 0.845}), (48, 0.848, {'top1': 0.848}), (49, 0.8458, {'top1': 0.8458}), (50, 0.8274, {'top1': 0.8274}), (51, 0.7712, {'top1': 0.7712}), (52, 0.2844, {'top1': 0.2844}), (53, 0.1594, {'top1': 0.1594})]
just computed impact of block 48 . accuracy after removing:  0.848
removed block 48 current accuracy 0.848 loss from initial  -0.010000000000000009
since last training loss: -0.010000000000000009 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.8066, {'top1': 0.8066}), (1, 0.8224, {'top1': 0.8224}), (2, 0.6664, {'top1': 0.6664}), (3, 0.8286, {'top1': 0.8286}), (4, 0.8422, {'top1': 0.8422}), (5, 0.815, {'top1': 0.815}), (6, 0.828, {'top1': 0.828}), (7, 0.8352, {'top1': 0.8352}), (8, 0.822, {'top1': 0.822}), (9, 0.7816, {'top1': 0.7816}), (10, 0.8458, {'top1': 0.8458}), (11, 0.8378, {'top1': 0.8378}), (12, 0.8446, {'top1': 0.8446}), (13, 0.819, {'top1': 0.819}), (14, 0.8478, {'top1': 0.8478}), (15, 0.8458, {'top1': 0.8458}), (16, 0.8386, {'top1': 0.8386}), (17, 0.8406, {'top1': 0.8406}), (18, 0.5764, {'top1': 0.5764}), (19, 0.7532, {'top1': 0.7532}), (20, 0.8232, {'top1': 0.8232}), (22, 0.814, {'top1': 0.814}), (23, 0.8298, {'top1': 0.8298}), (24, 0.834, {'top1': 0.834}), (25, 0.8332, {'top1': 0.8332}), (26, 0.8474, {'top1': 0.8474}), (27, 0.8368, {'top1': 0.8368}), (28, 0.8478, {'top1': 0.8478}), (29, 0.842, {'top1': 0.842}), (30, 0.8358, {'top1': 0.8358}), (31, 0.8462, {'top1': 0.8462}), (32, 0.8476, {'top1': 0.8476}), (33, 0.8484, {'top1': 0.8484}), (34, 0.8448, {'top1': 0.8448}), (35, 0.8442, {'top1': 0.8442}), (36, 0.5782, {'top1': 0.5782}), (37, 0.8464, {'top1': 0.8464}), (39, 0.8466, {'top1': 0.8466}), (40, 0.8482, {'top1': 0.8482}), (41, 0.8466, {'top1': 0.8466}), (43, 0.847, {'top1': 0.847}), (44, 0.8464, {'top1': 0.8464}), (45, 0.8464, {'top1': 0.8464}), (46, 0.8474, {'top1': 0.8474}), (47, 0.8494, {'top1': 0.8494}), (49, 0.849, {'top1': 0.849}), (50, 0.8298, {'top1': 0.8298}), (51, 0.767, {'top1': 0.767}), (52, 0.2798, {'top1': 0.2798}), (53, 0.1602, {'top1': 0.1602})]
just computed impact of block 47 . accuracy after removing:  0.8494
removed block 47 current accuracy 0.8494 loss from initial  -0.011400000000000077
since last training loss: -0.011400000000000077 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.807, {'top1': 0.807}), (1, 0.8172, {'top1': 0.8172}), (2, 0.676, {'top1': 0.676}), (3, 0.8264, {'top1': 0.8264}), (4, 0.8402, {'top1': 0.8402}), (5, 0.8138, {'top1': 0.8138}), (6, 0.8286, {'top1': 0.8286}), (7, 0.8346, {'top1': 0.8346}), (8, 0.8248, {'top1': 0.8248}), (9, 0.7818, {'top1': 0.7818}), (10, 0.8472, {'top1': 0.8472}), (11, 0.8414, {'top1': 0.8414}), (12, 0.8468, {'top1': 0.8468}), (13, 0.8152, {'top1': 0.8152}), (14, 0.8478, {'top1': 0.8478}), (15, 0.8476, {'top1': 0.8476}), (16, 0.8356, {'top1': 0.8356}), (17, 0.8392, {'top1': 0.8392}), (18, 0.58, {'top1': 0.58}), (19, 0.7522, {'top1': 0.7522}), (20, 0.8252, {'top1': 0.8252}), (22, 0.8146, {'top1': 0.8146}), (23, 0.8316, {'top1': 0.8316}), (24, 0.8348, {'top1': 0.8348}), (25, 0.8352, {'top1': 0.8352}), (26, 0.8472, {'top1': 0.8472}), (27, 0.8388, {'top1': 0.8388}), (28, 0.8498, {'top1': 0.8498}), (29, 0.8446, {'top1': 0.8446}), (30, 0.8404, {'top1': 0.8404}), (31, 0.8466, {'top1': 0.8466}), (32, 0.8474, {'top1': 0.8474}), (33, 0.8484, {'top1': 0.8484}), (34, 0.8452, {'top1': 0.8452}), (35, 0.8444, {'top1': 0.8444}), (36, 0.5914, {'top1': 0.5914}), (37, 0.8464, {'top1': 0.8464}), (39, 0.8466, {'top1': 0.8466}), (40, 0.8462, {'top1': 0.8462}), (41, 0.8464, {'top1': 0.8464}), (43, 0.8464, {'top1': 0.8464}), (44, 0.8448, {'top1': 0.8448}), (45, 0.847, {'top1': 0.847}), (46, 0.845, {'top1': 0.845}), (49, 0.8472, {'top1': 0.8472}), (50, 0.8254, {'top1': 0.8254}), (51, 0.763, {'top1': 0.763}), (52, 0.2724, {'top1': 0.2724}), (53, 0.1604, {'top1': 0.1604})]
just computed impact of block 28 . accuracy after removing:  0.8498
removed block 28 current accuracy 0.8498 loss from initial  -0.011800000000000033
since last training loss: -0.011800000000000033 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.8066, {'top1': 0.8066}), (1, 0.8172, {'top1': 0.8172}), (2, 0.6662, {'top1': 0.6662}), (3, 0.825, {'top1': 0.825}), (4, 0.8384, {'top1': 0.8384}), (5, 0.8136, {'top1': 0.8136}), (6, 0.824, {'top1': 0.824}), (7, 0.8318, {'top1': 0.8318}), (8, 0.8244, {'top1': 0.8244}), (9, 0.788, {'top1': 0.788}), (10, 0.8412, {'top1': 0.8412}), (11, 0.8402, {'top1': 0.8402}), (12, 0.8422, {'top1': 0.8422}), (13, 0.821, {'top1': 0.821}), (14, 0.8486, {'top1': 0.8486}), (15, 0.8464, {'top1': 0.8464}), (16, 0.8358, {'top1': 0.8358}), (17, 0.8418, {'top1': 0.8418}), (18, 0.5852, {'top1': 0.5852}), (19, 0.7574, {'top1': 0.7574}), (20, 0.8254, {'top1': 0.8254}), (22, 0.8056, {'top1': 0.8056}), (23, 0.8246, {'top1': 0.8246}), (24, 0.8334, {'top1': 0.8334}), (25, 0.8302, {'top1': 0.8302}), (26, 0.8426, {'top1': 0.8426}), (27, 0.836, {'top1': 0.836}), (29, 0.8394, {'top1': 0.8394}), (30, 0.8372, {'top1': 0.8372}), (31, 0.8426, {'top1': 0.8426}), (32, 0.8452, {'top1': 0.8452}), (33, 0.847, {'top1': 0.847}), (34, 0.8412, {'top1': 0.8412}), (35, 0.8444, {'top1': 0.8444}), (36, 0.5736, {'top1': 0.5736}), (37, 0.8452, {'top1': 0.8452}), (39, 0.8454, {'top1': 0.8454}), (40, 0.848, {'top1': 0.848}), (41, 0.8456, {'top1': 0.8456}), (43, 0.8464, {'top1': 0.8464}), (44, 0.8474, {'top1': 0.8474}), (45, 0.846, {'top1': 0.846}), (46, 0.8464, {'top1': 0.8464}), (49, 0.8484, {'top1': 0.8484}), (50, 0.829, {'top1': 0.829}), (51, 0.764, {'top1': 0.764}), (52, 0.2742, {'top1': 0.2742}), (53, 0.16, {'top1': 0.16})]
just computed impact of block 14 . accuracy after removing:  0.8486
removed block 14 current accuracy 0.8486 loss from initial  -0.010600000000000054
since last training loss: -0.010600000000000054 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.8048, {'top1': 0.8048}), (1, 0.8196, {'top1': 0.8196}), (2, 0.6636, {'top1': 0.6636}), (3, 0.8262, {'top1': 0.8262}), (4, 0.8382, {'top1': 0.8382}), (5, 0.8234, {'top1': 0.8234}), (6, 0.8292, {'top1': 0.8292}), (7, 0.8362, {'top1': 0.8362}), (8, 0.827, {'top1': 0.827}), (9, 0.781, {'top1': 0.781}), (10, 0.8392, {'top1': 0.8392}), (11, 0.8334, {'top1': 0.8334}), (12, 0.8418, {'top1': 0.8418}), (13, 0.8126, {'top1': 0.8126}), (15, 0.8428, {'top1': 0.8428}), (16, 0.8196, {'top1': 0.8196}), (17, 0.8328, {'top1': 0.8328}), (18, 0.5838, {'top1': 0.5838}), (19, 0.7546, {'top1': 0.7546}), (20, 0.823, {'top1': 0.823}), (22, 0.8036, {'top1': 0.8036}), (23, 0.824, {'top1': 0.824}), (24, 0.8348, {'top1': 0.8348}), (25, 0.8284, {'top1': 0.8284}), (26, 0.8426, {'top1': 0.8426}), (27, 0.8348, {'top1': 0.8348}), (29, 0.8416, {'top1': 0.8416}), (30, 0.8388, {'top1': 0.8388}), (31, 0.8444, {'top1': 0.8444}), (32, 0.8464, {'top1': 0.8464}), (33, 0.8478, {'top1': 0.8478}), (34, 0.8426, {'top1': 0.8426}), (35, 0.847, {'top1': 0.847}), (36, 0.5772, {'top1': 0.5772}), (37, 0.846, {'top1': 0.846}), (39, 0.8476, {'top1': 0.8476}), (40, 0.8476, {'top1': 0.8476}), (41, 0.8478, {'top1': 0.8478}), (43, 0.848, {'top1': 0.848}), (44, 0.847, {'top1': 0.847}), (45, 0.8464, {'top1': 0.8464}), (46, 0.848, {'top1': 0.848}), (49, 0.8496, {'top1': 0.8496}), (50, 0.8308, {'top1': 0.8308}), (51, 0.7648, {'top1': 0.7648}), (52, 0.2784, {'top1': 0.2784}), (53, 0.154, {'top1': 0.154})]
just computed impact of block 49 . accuracy after removing:  0.8496
removed block 49 current accuracy 0.8496 loss from initial  -0.011600000000000055
since last training loss: -0.011600000000000055 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.806, {'top1': 0.806}), (1, 0.8202, {'top1': 0.8202}), (2, 0.6684, {'top1': 0.6684}), (3, 0.8258, {'top1': 0.8258}), (4, 0.8364, {'top1': 0.8364}), (5, 0.8234, {'top1': 0.8234}), (6, 0.8282, {'top1': 0.8282}), (7, 0.8378, {'top1': 0.8378}), (8, 0.83, {'top1': 0.83}), (9, 0.7852, {'top1': 0.7852}), (10, 0.8396, {'top1': 0.8396}), (11, 0.835, {'top1': 0.835}), (12, 0.8438, {'top1': 0.8438}), (13, 0.8116, {'top1': 0.8116}), (15, 0.8432, {'top1': 0.8432}), (16, 0.8196, {'top1': 0.8196}), (17, 0.8374, {'top1': 0.8374}), (18, 0.5818, {'top1': 0.5818}), (19, 0.751, {'top1': 0.751}), (20, 0.8202, {'top1': 0.8202}), (22, 0.8058, {'top1': 0.8058}), (23, 0.8244, {'top1': 0.8244}), (24, 0.8354, {'top1': 0.8354}), (25, 0.8294, {'top1': 0.8294}), (26, 0.8444, {'top1': 0.8444}), (27, 0.8362, {'top1': 0.8362}), (29, 0.844, {'top1': 0.844}), (30, 0.8392, {'top1': 0.8392}), (31, 0.8464, {'top1': 0.8464}), (32, 0.8456, {'top1': 0.8456}), (33, 0.849, {'top1': 0.849}), (34, 0.8452, {'top1': 0.8452}), (35, 0.8456, {'top1': 0.8456}), (36, 0.5798, {'top1': 0.5798}), (37, 0.8464, {'top1': 0.8464}), (39, 0.8478, {'top1': 0.8478}), (40, 0.8464, {'top1': 0.8464}), (41, 0.8474, {'top1': 0.8474}), (43, 0.8466, {'top1': 0.8466}), (44, 0.8466, {'top1': 0.8466}), (45, 0.8478, {'top1': 0.8478}), (46, 0.847, {'top1': 0.847}), (50, 0.83, {'top1': 0.83}), (51, 0.7602, {'top1': 0.7602}), (52, 0.2754, {'top1': 0.2754}), (53, 0.154, {'top1': 0.154})]
just computed impact of block 33 . accuracy after removing:  0.849
removed block 33 current accuracy 0.849 loss from initial  -0.01100000000000001
since last training loss: -0.01100000000000001 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.8058, {'top1': 0.8058}), (1, 0.8224, {'top1': 0.8224}), (2, 0.6652, {'top1': 0.6652}), (3, 0.8246, {'top1': 0.8246}), (4, 0.835, {'top1': 0.835}), (5, 0.8266, {'top1': 0.8266}), (6, 0.8296, {'top1': 0.8296}), (7, 0.8388, {'top1': 0.8388}), (8, 0.8318, {'top1': 0.8318}), (9, 0.7908, {'top1': 0.7908}), (10, 0.837, {'top1': 0.837}), (11, 0.8316, {'top1': 0.8316}), (12, 0.8428, {'top1': 0.8428}), (13, 0.8118, {'top1': 0.8118}), (15, 0.8446, {'top1': 0.8446}), (16, 0.8194, {'top1': 0.8194}), (17, 0.8348, {'top1': 0.8348}), (18, 0.5864, {'top1': 0.5864}), (19, 0.755, {'top1': 0.755}), (20, 0.8186, {'top1': 0.8186}), (22, 0.8004, {'top1': 0.8004}), (23, 0.8266, {'top1': 0.8266}), (24, 0.832, {'top1': 0.832}), (25, 0.8286, {'top1': 0.8286}), (26, 0.844, {'top1': 0.844}), (27, 0.8316, {'top1': 0.8316}), (29, 0.8446, {'top1': 0.8446}), (30, 0.8406, {'top1': 0.8406}), (31, 0.8454, {'top1': 0.8454}), (32, 0.8432, {'top1': 0.8432}), (34, 0.8432, {'top1': 0.8432}), (35, 0.8458, {'top1': 0.8458}), (36, 0.5622, {'top1': 0.5622}), (37, 0.8468, {'top1': 0.8468}), (39, 0.8468, {'top1': 0.8468}), (40, 0.847, {'top1': 0.847}), (41, 0.8464, {'top1': 0.8464}), (43, 0.8484, {'top1': 0.8484}), (44, 0.8482, {'top1': 0.8482}), (45, 0.8484, {'top1': 0.8484}), (46, 0.8472, {'top1': 0.8472}), (50, 0.8296, {'top1': 0.8296}), (51, 0.7606, {'top1': 0.7606}), (52, 0.277, {'top1': 0.277}), (53, 0.1504, {'top1': 0.1504})]
just computed impact of block 43 . accuracy after removing:  0.8484
removed block 43 current accuracy 0.8484 loss from initial  -0.010400000000000076
since last training loss: -0.010400000000000076 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.804, {'top1': 0.804}), (1, 0.8184, {'top1': 0.8184}), (2, 0.6668, {'top1': 0.6668}), (3, 0.8252, {'top1': 0.8252}), (4, 0.8352, {'top1': 0.8352}), (5, 0.8246, {'top1': 0.8246}), (6, 0.826, {'top1': 0.826}), (7, 0.836, {'top1': 0.836}), (8, 0.8306, {'top1': 0.8306}), (9, 0.7902, {'top1': 0.7902}), (10, 0.8384, {'top1': 0.8384}), (11, 0.8336, {'top1': 0.8336}), (12, 0.845, {'top1': 0.845}), (13, 0.813, {'top1': 0.813}), (15, 0.8436, {'top1': 0.8436}), (16, 0.8224, {'top1': 0.8224}), (17, 0.8352, {'top1': 0.8352}), (18, 0.582, {'top1': 0.582}), (19, 0.7502, {'top1': 0.7502}), (20, 0.8154, {'top1': 0.8154}), (22, 0.8026, {'top1': 0.8026}), (23, 0.8258, {'top1': 0.8258}), (24, 0.8322, {'top1': 0.8322}), (25, 0.8288, {'top1': 0.8288}), (26, 0.8438, {'top1': 0.8438}), (27, 0.832, {'top1': 0.832}), (29, 0.8434, {'top1': 0.8434}), (30, 0.8388, {'top1': 0.8388}), (31, 0.8464, {'top1': 0.8464}), (32, 0.8422, {'top1': 0.8422}), (34, 0.844, {'top1': 0.844}), (35, 0.8428, {'top1': 0.8428}), (36, 0.5684, {'top1': 0.5684}), (37, 0.8466, {'top1': 0.8466}), (39, 0.8464, {'top1': 0.8464}), (40, 0.8472, {'top1': 0.8472}), (41, 0.8452, {'top1': 0.8452}), (44, 0.8462, {'top1': 0.8462}), (45, 0.8476, {'top1': 0.8476}), (46, 0.8466, {'top1': 0.8466}), (50, 0.828, {'top1': 0.828}), (51, 0.759, {'top1': 0.759}), (52, 0.2654, {'top1': 0.2654}), (53, 0.1498, {'top1': 0.1498})]
just computed impact of block 45 . accuracy after removing:  0.8476
removed block 45 current accuracy 0.8476 loss from initial  -0.009600000000000053
since last training loss: -0.009600000000000053 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.8006, {'top1': 0.8006}), (1, 0.8154, {'top1': 0.8154}), (2, 0.6632, {'top1': 0.6632}), (3, 0.823, {'top1': 0.823}), (4, 0.8358, {'top1': 0.8358}), (5, 0.819, {'top1': 0.819}), (6, 0.8268, {'top1': 0.8268}), (7, 0.8368, {'top1': 0.8368}), (8, 0.8262, {'top1': 0.8262}), (9, 0.7902, {'top1': 0.7902}), (10, 0.8408, {'top1': 0.8408}), (11, 0.8326, {'top1': 0.8326}), (12, 0.8432, {'top1': 0.8432}), (13, 0.8136, {'top1': 0.8136}), (15, 0.8448, {'top1': 0.8448}), (16, 0.8262, {'top1': 0.8262}), (17, 0.839, {'top1': 0.839}), (18, 0.5862, {'top1': 0.5862}), (19, 0.7456, {'top1': 0.7456}), (20, 0.8116, {'top1': 0.8116}), (22, 0.8044, {'top1': 0.8044}), (23, 0.827, {'top1': 0.827}), (24, 0.8324, {'top1': 0.8324}), (25, 0.8292, {'top1': 0.8292}), (26, 0.8424, {'top1': 0.8424}), (27, 0.8312, {'top1': 0.8312}), (29, 0.8406, {'top1': 0.8406}), (30, 0.8372, {'top1': 0.8372}), (31, 0.8442, {'top1': 0.8442}), (32, 0.842, {'top1': 0.842}), (34, 0.841, {'top1': 0.841}), (35, 0.8438, {'top1': 0.8438}), (36, 0.5606, {'top1': 0.5606}), (37, 0.8462, {'top1': 0.8462}), (39, 0.8448, {'top1': 0.8448}), (40, 0.8466, {'top1': 0.8466}), (41, 0.8442, {'top1': 0.8442}), (44, 0.8448, {'top1': 0.8448}), (46, 0.8442, {'top1': 0.8442}), (50, 0.8252, {'top1': 0.8252}), (51, 0.7572, {'top1': 0.7572}), (52, 0.2648, {'top1': 0.2648}), (53, 0.1502, {'top1': 0.1502})]
just computed impact of block 40 . accuracy after removing:  0.8466
removed block 40 current accuracy 0.8466 loss from initial  -0.008600000000000052
since last training loss: -0.008600000000000052 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.8022, {'top1': 0.8022}), (1, 0.8156, {'top1': 0.8156}), (2, 0.6702, {'top1': 0.6702}), (3, 0.8246, {'top1': 0.8246}), (4, 0.8376, {'top1': 0.8376}), (5, 0.82, {'top1': 0.82}), (6, 0.8274, {'top1': 0.8274}), (7, 0.8378, {'top1': 0.8378}), (8, 0.829, {'top1': 0.829}), (9, 0.7956, {'top1': 0.7956}), (10, 0.8386, {'top1': 0.8386}), (11, 0.8328, {'top1': 0.8328}), (12, 0.8448, {'top1': 0.8448}), (13, 0.8096, {'top1': 0.8096}), (15, 0.843, {'top1': 0.843}), (16, 0.8244, {'top1': 0.8244}), (17, 0.838, {'top1': 0.838}), (18, 0.5878, {'top1': 0.5878}), (19, 0.7438, {'top1': 0.7438}), (20, 0.8088, {'top1': 0.8088}), (22, 0.8014, {'top1': 0.8014}), (23, 0.8224, {'top1': 0.8224}), (24, 0.8308, {'top1': 0.8308}), (25, 0.8274, {'top1': 0.8274}), (26, 0.8414, {'top1': 0.8414}), (27, 0.8316, {'top1': 0.8316}), (29, 0.8428, {'top1': 0.8428}), (30, 0.8378, {'top1': 0.8378}), (31, 0.842, {'top1': 0.842}), (32, 0.8396, {'top1': 0.8396}), (34, 0.8408, {'top1': 0.8408}), (35, 0.8418, {'top1': 0.8418}), (36, 0.5706, {'top1': 0.5706}), (37, 0.8434, {'top1': 0.8434}), (39, 0.844, {'top1': 0.844}), (41, 0.8448, {'top1': 0.8448}), (44, 0.8446, {'top1': 0.8446}), (46, 0.8442, {'top1': 0.8442}), (50, 0.8204, {'top1': 0.8204}), (51, 0.756, {'top1': 0.756}), (52, 0.2584, {'top1': 0.2584}), (53, 0.152, {'top1': 0.152})]
just computed impact of block 12 . accuracy after removing:  0.8448
removed block 12 current accuracy 0.8448 loss from initial  -0.006800000000000028
since last training loss: -0.006800000000000028 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.793, {'top1': 0.793}), (1, 0.815, {'top1': 0.815}), (2, 0.6254, {'top1': 0.6254}), (3, 0.814, {'top1': 0.814}), (4, 0.8322, {'top1': 0.8322}), (5, 0.8076, {'top1': 0.8076}), (6, 0.8222, {'top1': 0.8222}), (7, 0.8264, {'top1': 0.8264}), (8, 0.7914, {'top1': 0.7914}), (9, 0.7782, {'top1': 0.7782}), (10, 0.8268, {'top1': 0.8268}), (11, 0.8084, {'top1': 0.8084}), (13, 0.81, {'top1': 0.81}), (15, 0.8306, {'top1': 0.8306}), (16, 0.8074, {'top1': 0.8074}), (17, 0.8174, {'top1': 0.8174}), (18, 0.5864, {'top1': 0.5864}), (19, 0.7476, {'top1': 0.7476}), (20, 0.8062, {'top1': 0.8062}), (22, 0.7846, {'top1': 0.7846}), (23, 0.816, {'top1': 0.816}), (24, 0.8288, {'top1': 0.8288}), (25, 0.8196, {'top1': 0.8196}), (26, 0.8316, {'top1': 0.8316}), (27, 0.821, {'top1': 0.821}), (29, 0.8344, {'top1': 0.8344}), (30, 0.8304, {'top1': 0.8304}), (31, 0.8384, {'top1': 0.8384}), (32, 0.8322, {'top1': 0.8322}), (34, 0.837, {'top1': 0.837}), (35, 0.8422, {'top1': 0.8422}), (36, 0.535, {'top1': 0.535}), (37, 0.8434, {'top1': 0.8434}), (39, 0.842, {'top1': 0.842}), (41, 0.8426, {'top1': 0.8426}), (44, 0.8444, {'top1': 0.8444}), (46, 0.8418, {'top1': 0.8418}), (50, 0.8222, {'top1': 0.8222}), (51, 0.7536, {'top1': 0.7536}), (52, 0.2844, {'top1': 0.2844}), (53, 0.1472, {'top1': 0.1472})]
just computed impact of block 44 . accuracy after removing:  0.8444
removed block 44 current accuracy 0.8444 loss from initial  -0.006400000000000072
since last training loss: -0.006400000000000072 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.7942, {'top1': 0.7942}), (1, 0.8182, {'top1': 0.8182}), (2, 0.6268, {'top1': 0.6268}), (3, 0.813, {'top1': 0.813}), (4, 0.8314, {'top1': 0.8314}), (5, 0.809, {'top1': 0.809}), (6, 0.823, {'top1': 0.823}), (7, 0.8246, {'top1': 0.8246}), (8, 0.792, {'top1': 0.792}), (9, 0.7794, {'top1': 0.7794}), (10, 0.8282, {'top1': 0.8282}), (11, 0.81, {'top1': 0.81}), (13, 0.8106, {'top1': 0.8106}), (15, 0.833, {'top1': 0.833}), (16, 0.8128, {'top1': 0.8128}), (17, 0.8172, {'top1': 0.8172}), (18, 0.5742, {'top1': 0.5742}), (19, 0.7452, {'top1': 0.7452}), (20, 0.8038, {'top1': 0.8038}), (22, 0.787, {'top1': 0.787}), (23, 0.8166, {'top1': 0.8166}), (24, 0.829, {'top1': 0.829}), (25, 0.821, {'top1': 0.821}), (26, 0.835, {'top1': 0.835}), (27, 0.8214, {'top1': 0.8214}), (29, 0.836, {'top1': 0.836}), (30, 0.8278, {'top1': 0.8278}), (31, 0.84, {'top1': 0.84}), (32, 0.8322, {'top1': 0.8322}), (34, 0.8372, {'top1': 0.8372}), (35, 0.8398, {'top1': 0.8398}), (36, 0.5416, {'top1': 0.5416}), (37, 0.8428, {'top1': 0.8428}), (39, 0.842, {'top1': 0.842}), (41, 0.8436, {'top1': 0.8436}), (46, 0.8412, {'top1': 0.8412}), (50, 0.819, {'top1': 0.819}), (51, 0.7518, {'top1': 0.7518}), (52, 0.2874, {'top1': 0.2874}), (53, 0.1506, {'top1': 0.1506})]
just computed impact of block 41 . accuracy after removing:  0.8436
removed block 41 current accuracy 0.8436 loss from initial  -0.005600000000000049
since last training loss: -0.005600000000000049 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.791, {'top1': 0.791}), (1, 0.8156, {'top1': 0.8156}), (2, 0.6218, {'top1': 0.6218}), (3, 0.8102, {'top1': 0.8102}), (4, 0.8298, {'top1': 0.8298}), (5, 0.8064, {'top1': 0.8064}), (6, 0.8208, {'top1': 0.8208}), (7, 0.822, {'top1': 0.822}), (8, 0.7916, {'top1': 0.7916}), (9, 0.7768, {'top1': 0.7768}), (10, 0.8264, {'top1': 0.8264}), (11, 0.806, {'top1': 0.806}), (13, 0.8088, {'top1': 0.8088}), (15, 0.8306, {'top1': 0.8306}), (16, 0.8086, {'top1': 0.8086}), (17, 0.8154, {'top1': 0.8154}), (18, 0.569, {'top1': 0.569}), (19, 0.7496, {'top1': 0.7496}), (20, 0.8004, {'top1': 0.8004}), (22, 0.7852, {'top1': 0.7852}), (23, 0.8166, {'top1': 0.8166}), (24, 0.8242, {'top1': 0.8242}), (25, 0.8192, {'top1': 0.8192}), (26, 0.8316, {'top1': 0.8316}), (27, 0.8186, {'top1': 0.8186}), (29, 0.8326, {'top1': 0.8326}), (30, 0.8232, {'top1': 0.8232}), (31, 0.8376, {'top1': 0.8376}), (32, 0.8318, {'top1': 0.8318}), (34, 0.8352, {'top1': 0.8352}), (35, 0.8372, {'top1': 0.8372}), (36, 0.5446, {'top1': 0.5446}), (37, 0.8418, {'top1': 0.8418}), (39, 0.8378, {'top1': 0.8378}), (46, 0.8394, {'top1': 0.8394}), (50, 0.8158, {'top1': 0.8158}), (51, 0.7516, {'top1': 0.7516}), (52, 0.2918, {'top1': 0.2918}), (53, 0.1542, {'top1': 0.1542})]
just computed impact of block 37 . accuracy after removing:  0.8418
removed block 37 current accuracy 0.8418 loss from initial  -0.0038000000000000256
since last training loss: -0.0038000000000000256 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.7892, {'top1': 0.7892}), (1, 0.8118, {'top1': 0.8118}), (2, 0.6256, {'top1': 0.6256}), (3, 0.8104, {'top1': 0.8104}), (4, 0.83, {'top1': 0.83}), (5, 0.805, {'top1': 0.805}), (6, 0.8212, {'top1': 0.8212}), (7, 0.8216, {'top1': 0.8216}), (8, 0.7896, {'top1': 0.7896}), (9, 0.7802, {'top1': 0.7802}), (10, 0.8246, {'top1': 0.8246}), (11, 0.8036, {'top1': 0.8036}), (13, 0.8082, {'top1': 0.8082}), (15, 0.8278, {'top1': 0.8278}), (16, 0.805, {'top1': 0.805}), (17, 0.8164, {'top1': 0.8164}), (18, 0.5616, {'top1': 0.5616}), (19, 0.7466, {'top1': 0.7466}), (20, 0.8022, {'top1': 0.8022}), (22, 0.7802, {'top1': 0.7802}), (23, 0.8144, {'top1': 0.8144}), (24, 0.8186, {'top1': 0.8186}), (25, 0.8136, {'top1': 0.8136}), (26, 0.8298, {'top1': 0.8298}), (27, 0.815, {'top1': 0.815}), (29, 0.8286, {'top1': 0.8286}), (30, 0.8222, {'top1': 0.8222}), (31, 0.8346, {'top1': 0.8346}), (32, 0.83, {'top1': 0.83}), (34, 0.8334, {'top1': 0.8334}), (35, 0.8354, {'top1': 0.8354}), (36, 0.532, {'top1': 0.532}), (39, 0.8358, {'top1': 0.8358}), (46, 0.8396, {'top1': 0.8396}), (50, 0.809, {'top1': 0.809}), (51, 0.7522, {'top1': 0.7522}), (52, 0.2988, {'top1': 0.2988}), (53, 0.154, {'top1': 0.154})]
just computed impact of block 46 . accuracy after removing:  0.8396
removed block 46 current accuracy 0.8396 loss from initial  -0.0016000000000000458
since last training loss: -0.0016000000000000458 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.7866, {'top1': 0.7866}), (1, 0.8076, {'top1': 0.8076}), (2, 0.6228, {'top1': 0.6228}), (3, 0.804, {'top1': 0.804}), (4, 0.8286, {'top1': 0.8286}), (5, 0.8008, {'top1': 0.8008}), (6, 0.8164, {'top1': 0.8164}), (7, 0.8192, {'top1': 0.8192}), (8, 0.7886, {'top1': 0.7886}), (9, 0.7762, {'top1': 0.7762}), (10, 0.8238, {'top1': 0.8238}), (11, 0.8046, {'top1': 0.8046}), (13, 0.8078, {'top1': 0.8078}), (15, 0.8274, {'top1': 0.8274}), (16, 0.8078, {'top1': 0.8078}), (17, 0.8132, {'top1': 0.8132}), (18, 0.5636, {'top1': 0.5636}), (19, 0.7422, {'top1': 0.7422}), (20, 0.796, {'top1': 0.796}), (22, 0.7788, {'top1': 0.7788}), (23, 0.8096, {'top1': 0.8096}), (24, 0.819, {'top1': 0.819}), (25, 0.8156, {'top1': 0.8156}), (26, 0.8282, {'top1': 0.8282}), (27, 0.8118, {'top1': 0.8118}), (29, 0.8274, {'top1': 0.8274}), (30, 0.8204, {'top1': 0.8204}), (31, 0.832, {'top1': 0.832}), (32, 0.8274, {'top1': 0.8274}), (34, 0.832, {'top1': 0.832}), (35, 0.8338, {'top1': 0.8338}), (36, 0.5282, {'top1': 0.5282}), (39, 0.8348, {'top1': 0.8348}), (50, 0.8056, {'top1': 0.8056}), (51, 0.7486, {'top1': 0.7486}), (52, 0.3136, {'top1': 0.3136}), (53, 0.1546, {'top1': 0.1546})]
just computed impact of block 39 . accuracy after removing:  0.8348
removed block 39 current accuracy 0.8348 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.7836, {'top1': 0.7836}), (1, 0.8024, {'top1': 0.8024}), (2, 0.6138, {'top1': 0.6138}), (3, 0.7988, {'top1': 0.7988}), (4, 0.8198, {'top1': 0.8198}), (5, 0.7918, {'top1': 0.7918}), (6, 0.8112, {'top1': 0.8112}), (7, 0.8158, {'top1': 0.8158}), (8, 0.7848, {'top1': 0.7848}), (9, 0.7702, {'top1': 0.7702}), (10, 0.8172, {'top1': 0.8172}), (11, 0.8028, {'top1': 0.8028}), (13, 0.81, {'top1': 0.81}), (15, 0.824, {'top1': 0.824}), (16, 0.805, {'top1': 0.805}), (17, 0.8114, {'top1': 0.8114}), (18, 0.5622, {'top1': 0.5622}), (19, 0.742, {'top1': 0.742}), (20, 0.795, {'top1': 0.795}), (22, 0.7736, {'top1': 0.7736}), (23, 0.8098, {'top1': 0.8098}), (24, 0.8134, {'top1': 0.8134}), (25, 0.8128, {'top1': 0.8128}), (26, 0.8228, {'top1': 0.8228}), (27, 0.8066, {'top1': 0.8066}), (29, 0.8236, {'top1': 0.8236}), (30, 0.8152, {'top1': 0.8152}), (31, 0.8264, {'top1': 0.8264}), (32, 0.8218, {'top1': 0.8218}), (34, 0.829, {'top1': 0.829}), (35, 0.8272, {'top1': 0.8272}), (36, 0.5226, {'top1': 0.5226}), (50, 0.8012, {'top1': 0.8012}), (51, 0.7426, {'top1': 0.7426}), (52, 0.3182, {'top1': 0.3182}), (53, 0.1594, {'top1': 0.1594})]
just computed impact of block 34 . accuracy after removing:  0.829
removed block 34 current accuracy 0.829 loss from initial  0.009000000000000008
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.7772, {'top1': 0.7772}), (1, 0.7956, {'top1': 0.7956}), (2, 0.6092, {'top1': 0.6092}), (3, 0.7904, {'top1': 0.7904}), (4, 0.8128, {'top1': 0.8128}), (5, 0.7844, {'top1': 0.7844}), (6, 0.8024, {'top1': 0.8024}), (7, 0.8044, {'top1': 0.8044}), (8, 0.7788, {'top1': 0.7788}), (9, 0.7608, {'top1': 0.7608}), (10, 0.8068, {'top1': 0.8068}), (11, 0.7962, {'top1': 0.7962}), (13, 0.7972, {'top1': 0.7972}), (15, 0.8182, {'top1': 0.8182}), (16, 0.7968, {'top1': 0.7968}), (17, 0.8022, {'top1': 0.8022}), (18, 0.531, {'top1': 0.531}), (19, 0.724, {'top1': 0.724}), (20, 0.7874, {'top1': 0.7874}), (22, 0.7614, {'top1': 0.7614}), (23, 0.7968, {'top1': 0.7968}), (24, 0.8004, {'top1': 0.8004}), (25, 0.8, {'top1': 0.8}), (26, 0.8108, {'top1': 0.8108}), (27, 0.7984, {'top1': 0.7984}), (29, 0.8118, {'top1': 0.8118}), (30, 0.8026, {'top1': 0.8026}), (31, 0.8144, {'top1': 0.8144}), (32, 0.812, {'top1': 0.812}), (35, 0.8216, {'top1': 0.8216}), (36, 0.4918, {'top1': 0.4918}), (50, 0.796, {'top1': 0.796}), (51, 0.729, {'top1': 0.729}), (52, 0.2938, {'top1': 0.2938}), (53, 0.1558, {'top1': 0.1558})]
just computed impact of block 35 . accuracy after removing:  0.8216
removed block 35 current accuracy 0.8216 loss from initial  0.01639999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.7744, {'top1': 0.7744}), (1, 0.7912, {'top1': 0.7912}), (2, 0.5998, {'top1': 0.5998}), (3, 0.7782, {'top1': 0.7782}), (4, 0.8026, {'top1': 0.8026}), (5, 0.7794, {'top1': 0.7794}), (6, 0.7944, {'top1': 0.7944}), (7, 0.7998, {'top1': 0.7998}), (8, 0.7764, {'top1': 0.7764}), (9, 0.7506, {'top1': 0.7506}), (10, 0.8052, {'top1': 0.8052}), (11, 0.7972, {'top1': 0.7972}), (13, 0.7954, {'top1': 0.7954}), (15, 0.813, {'top1': 0.813}), (16, 0.796, {'top1': 0.796}), (17, 0.8026, {'top1': 0.8026}), (18, 0.5092, {'top1': 0.5092}), (19, 0.7066, {'top1': 0.7066}), (20, 0.7762, {'top1': 0.7762}), (22, 0.7582, {'top1': 0.7582}), (23, 0.7914, {'top1': 0.7914}), (24, 0.795, {'top1': 0.795}), (25, 0.7902, {'top1': 0.7902}), (26, 0.8056, {'top1': 0.8056}), (27, 0.7908, {'top1': 0.7908}), (29, 0.8036, {'top1': 0.8036}), (30, 0.7942, {'top1': 0.7942}), (31, 0.8048, {'top1': 0.8048}), (32, 0.806, {'top1': 0.806}), (36, 0.4718, {'top1': 0.4718}), (50, 0.7858, {'top1': 0.7858}), (51, 0.708, {'top1': 0.708}), (52, 0.2722, {'top1': 0.2722}), (53, 0.146, {'top1': 0.146})]
just computed impact of block 15 . accuracy after removing:  0.813
removed block 15 current accuracy 0.813 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.764, {'top1': 0.764}), (1, 0.7882, {'top1': 0.7882}), (2, 0.5916, {'top1': 0.5916}), (3, 0.775, {'top1': 0.775}), (4, 0.8, {'top1': 0.8}), (5, 0.7762, {'top1': 0.7762}), (6, 0.7916, {'top1': 0.7916}), (7, 0.7998, {'top1': 0.7998}), (8, 0.7606, {'top1': 0.7606}), (9, 0.7478, {'top1': 0.7478}), (10, 0.7886, {'top1': 0.7886}), (11, 0.7706, {'top1': 0.7706}), (13, 0.7698, {'top1': 0.7698}), (16, 0.7582, {'top1': 0.7582}), (17, 0.761, {'top1': 0.761}), (18, 0.5066, {'top1': 0.5066}), (19, 0.695, {'top1': 0.695}), (20, 0.7744, {'top1': 0.7744}), (22, 0.7504, {'top1': 0.7504}), (23, 0.784, {'top1': 0.784}), (24, 0.7932, {'top1': 0.7932}), (25, 0.7878, {'top1': 0.7878}), (26, 0.7988, {'top1': 0.7988}), (27, 0.7862, {'top1': 0.7862}), (29, 0.8028, {'top1': 0.8028}), (30, 0.7918, {'top1': 0.7918}), (31, 0.7992, {'top1': 0.7992}), (32, 0.799, {'top1': 0.799}), (36, 0.469, {'top1': 0.469}), (50, 0.7846, {'top1': 0.7846}), (51, 0.7114, {'top1': 0.7114}), (52, 0.2882, {'top1': 0.2882}), (53, 0.1394, {'top1': 0.1394})]
just computed impact of block 29 . accuracy after removing:  0.8028
removed block 29 current accuracy 0.8028 loss from initial  0.03520000000000001
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7458, {'top1': 0.7458}), (1, 0.7746, {'top1': 0.7746}), (2, 0.5518, {'top1': 0.5518}), (3, 0.7476, {'top1': 0.7476}), (4, 0.7826, {'top1': 0.7826}), (5, 0.7518, {'top1': 0.7518}), (6, 0.768, {'top1': 0.768}), (7, 0.7702, {'top1': 0.7702}), (8, 0.7358, {'top1': 0.7358}), (9, 0.728, {'top1': 0.728}), (10, 0.772, {'top1': 0.772}), (11, 0.7566, {'top1': 0.7566}), (13, 0.7632, {'top1': 0.7632}), (16, 0.7472, {'top1': 0.7472}), (17, 0.7526, {'top1': 0.7526}), (18, 0.486, {'top1': 0.486}), (19, 0.6882, {'top1': 0.6882}), (20, 0.7674, {'top1': 0.7674}), (22, 0.7196, {'top1': 0.7196}), (23, 0.7614, {'top1': 0.7614}), (24, 0.7724, {'top1': 0.7724}), (25, 0.7716, {'top1': 0.7716}), (26, 0.7774, {'top1': 0.7774}), (27, 0.7584, {'top1': 0.7584}), (30, 0.7664, {'top1': 0.7664}), (31, 0.7772, {'top1': 0.7772}), (32, 0.7764, {'top1': 0.7764}), (36, 0.4218, {'top1': 0.4218}), (50, 0.7752, {'top1': 0.7752}), (51, 0.6894, {'top1': 0.6894}), (52, 0.2892, {'top1': 0.2892}), (53, 0.1364, {'top1': 0.1364})]
just computed impact of block 4 . accuracy after removing:  0.7826
removed block 4 current accuracy 0.7826 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.7228, {'top1': 0.7228}), (1, 0.7492, {'top1': 0.7492}), (2, 0.5196, {'top1': 0.5196}), (3, 0.7146, {'top1': 0.7146}), (5, 0.7204, {'top1': 0.7204}), (6, 0.7434, {'top1': 0.7434}), (7, 0.7432, {'top1': 0.7432}), (8, 0.7166, {'top1': 0.7166}), (9, 0.6884, {'top1': 0.6884}), (10, 0.7484, {'top1': 0.7484}), (11, 0.7504, {'top1': 0.7504}), (13, 0.752, {'top1': 0.752}), (16, 0.7296, {'top1': 0.7296}), (17, 0.7404, {'top1': 0.7404}), (18, 0.445, {'top1': 0.445}), (19, 0.6666, {'top1': 0.6666}), (20, 0.7538, {'top1': 0.7538}), (22, 0.7086, {'top1': 0.7086}), (23, 0.7494, {'top1': 0.7494}), (24, 0.7524, {'top1': 0.7524}), (25, 0.754, {'top1': 0.754}), (26, 0.7636, {'top1': 0.7636}), (27, 0.7374, {'top1': 0.7374}), (30, 0.751, {'top1': 0.751}), (31, 0.7616, {'top1': 0.7616}), (32, 0.7616, {'top1': 0.7616}), (36, 0.3968, {'top1': 0.3968}), (50, 0.7686, {'top1': 0.7686}), (51, 0.6636, {'top1': 0.6636}), (52, 0.3416, {'top1': 0.3416}), (53, 0.1306, {'top1': 0.1306})]
just computed impact of block 50 . accuracy after removing:  0.7686
removed block 50 current accuracy 0.7686 loss from initial  0.06940000000000002
since last training loss: 0.06940000000000002 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.6846, {'top1': 0.6846}), (1, 0.7344, {'top1': 0.7344}), (2, 0.4874, {'top1': 0.4874}), (3, 0.7052, {'top1': 0.7052}), (5, 0.69, {'top1': 0.69}), (6, 0.7256, {'top1': 0.7256}), (7, 0.719, {'top1': 0.719}), (8, 0.6826, {'top1': 0.6826}), (9, 0.6644, {'top1': 0.6644}), (10, 0.7352, {'top1': 0.7352}), (11, 0.7356, {'top1': 0.7356}), (13, 0.7372, {'top1': 0.7372}), (16, 0.7202, {'top1': 0.7202}), (17, 0.7264, {'top1': 0.7264}), (18, 0.4492, {'top1': 0.4492}), (19, 0.63, {'top1': 0.63}), (20, 0.7196, {'top1': 0.7196}), (22, 0.6868, {'top1': 0.6868}), (23, 0.7234, {'top1': 0.7234}), (24, 0.7286, {'top1': 0.7286}), (25, 0.7272, {'top1': 0.7272}), (26, 0.748, {'top1': 0.748}), (27, 0.7214, {'top1': 0.7214}), (30, 0.7264, {'top1': 0.7264}), (31, 0.7452, {'top1': 0.7452}), (32, 0.7496, {'top1': 0.7496}), (36, 0.381, {'top1': 0.381}), (51, 0.6432, {'top1': 0.6432}), (52, 0.29, {'top1': 0.29}), (53, 0.1252, {'top1': 0.1252})]
just computed impact of block 32 . accuracy after removing:  0.7496
removed block 32 current accuracy 0.7496 loss from initial  0.08839999999999992
since last training loss: 0.08839999999999992 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.6602, {'top1': 0.6602}), (1, 0.7202, {'top1': 0.7202}), (2, 0.4726, {'top1': 0.4726}), (3, 0.6878, {'top1': 0.6878}), (5, 0.6698, {'top1': 0.6698}), (6, 0.7038, {'top1': 0.7038}), (7, 0.6962, {'top1': 0.6962}), (8, 0.6556, {'top1': 0.6556}), (9, 0.6512, {'top1': 0.6512}), (10, 0.711, {'top1': 0.711}), (11, 0.7104, {'top1': 0.7104}), (13, 0.7172, {'top1': 0.7172}), (16, 0.7, {'top1': 0.7}), (17, 0.708, {'top1': 0.708}), (18, 0.4216, {'top1': 0.4216}), (19, 0.6098, {'top1': 0.6098}), (20, 0.7024, {'top1': 0.7024}), (22, 0.6486, {'top1': 0.6486}), (23, 0.6918, {'top1': 0.6918}), (24, 0.7026, {'top1': 0.7026}), (25, 0.7016, {'top1': 0.7016}), (26, 0.7192, {'top1': 0.7192}), (27, 0.6928, {'top1': 0.6928}), (30, 0.7026, {'top1': 0.7026}), (31, 0.7226, {'top1': 0.7226}), (36, 0.3402, {'top1': 0.3402}), (51, 0.6288, {'top1': 0.6288}), (52, 0.2914, {'top1': 0.2914}), (53, 0.1198, {'top1': 0.1198})]
just computed impact of block 31 . accuracy after removing:  0.7226
removed block 31 current accuracy 0.7226 loss from initial  0.11539999999999995
since last training loss: 0.11539999999999995 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.6342, {'top1': 0.6342}), (1, 0.6936, {'top1': 0.6936}), (2, 0.4392, {'top1': 0.4392}), (3, 0.6564, {'top1': 0.6564}), (5, 0.6354, {'top1': 0.6354}), (6, 0.6758, {'top1': 0.6758}), (7, 0.6582, {'top1': 0.6582}), (8, 0.6262, {'top1': 0.6262}), (9, 0.6216, {'top1': 0.6216}), (10, 0.6782, {'top1': 0.6782}), (11, 0.6854, {'top1': 0.6854}), (13, 0.6918, {'top1': 0.6918}), (16, 0.681, {'top1': 0.681}), (17, 0.6794, {'top1': 0.6794}), (18, 0.391, {'top1': 0.391}), (19, 0.582, {'top1': 0.582}), (20, 0.6736, {'top1': 0.6736}), (22, 0.6172, {'top1': 0.6172}), (23, 0.665, {'top1': 0.665}), (24, 0.6746, {'top1': 0.6746}), (25, 0.672, {'top1': 0.672}), (26, 0.6852, {'top1': 0.6852}), (27, 0.6574, {'top1': 0.6574}), (30, 0.6654, {'top1': 0.6654}), (36, 0.313, {'top1': 0.313}), (51, 0.5984, {'top1': 0.5984}), (52, 0.2924, {'top1': 0.2924}), (53, 0.1174, {'top1': 0.1174})]
just computed impact of block 1 . accuracy after removing:  0.6936
removed block 1 current accuracy 0.6936 loss from initial  0.14439999999999997
since last training loss: 0.14439999999999997 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.5648, {'top1': 0.5648}), (2, 0.3376, {'top1': 0.3376}), (3, 0.6228, {'top1': 0.6228}), (5, 0.6044, {'top1': 0.6044}), (6, 0.6456, {'top1': 0.6456}), (7, 0.6214, {'top1': 0.6214}), (8, 0.6044, {'top1': 0.6044}), (9, 0.5854, {'top1': 0.5854}), (10, 0.6612, {'top1': 0.6612}), (11, 0.6744, {'top1': 0.6744}), (13, 0.6548, {'top1': 0.6548}), (16, 0.6482, {'top1': 0.6482}), (17, 0.659, {'top1': 0.659}), (18, 0.3644, {'top1': 0.3644}), (19, 0.547, {'top1': 0.547}), (20, 0.6434, {'top1': 0.6434}), (22, 0.5778, {'top1': 0.5778}), (23, 0.6284, {'top1': 0.6284}), (24, 0.6546, {'top1': 0.6546}), (25, 0.6466, {'top1': 0.6466}), (26, 0.6602, {'top1': 0.6602}), (27, 0.6412, {'top1': 0.6412}), (30, 0.6472, {'top1': 0.6472}), (36, 0.3032, {'top1': 0.3032}), (51, 0.5608, {'top1': 0.5608}), (52, 0.2498, {'top1': 0.2498}), (53, 0.1136, {'top1': 0.1136})]
just computed impact of block 11 . accuracy after removing:  0.6744
removed block 11 current accuracy 0.6744 loss from initial  0.16359999999999997
since last training loss: 0.16359999999999997 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.5278, {'top1': 0.5278}), (2, 0.3282, {'top1': 0.3282}), (3, 0.611, {'top1': 0.611}), (5, 0.5998, {'top1': 0.5998}), (6, 0.6214, {'top1': 0.6214}), (7, 0.6046, {'top1': 0.6046}), (8, 0.556, {'top1': 0.556}), (9, 0.5546, {'top1': 0.5546}), (10, 0.6224, {'top1': 0.6224}), (13, 0.592, {'top1': 0.592}), (16, 0.5808, {'top1': 0.5808}), (17, 0.565, {'top1': 0.565}), (18, 0.3244, {'top1': 0.3244}), (19, 0.545, {'top1': 0.545}), (20, 0.619, {'top1': 0.619}), (22, 0.5262, {'top1': 0.5262}), (23, 0.5888, {'top1': 0.5888}), (24, 0.6282, {'top1': 0.6282}), (25, 0.6188, {'top1': 0.6188}), (26, 0.6318, {'top1': 0.6318}), (27, 0.6064, {'top1': 0.6064}), (30, 0.6246, {'top1': 0.6246}), (36, 0.262, {'top1': 0.262}), (51, 0.567, {'top1': 0.567}), (52, 0.2508, {'top1': 0.2508}), (53, 0.117, {'top1': 0.117})]
just computed impact of block 26 . accuracy after removing:  0.6318
removed block 26 current accuracy 0.6318 loss from initial  0.20619999999999994
since last training loss: 0.20619999999999994 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.4806, {'top1': 0.4806}), (2, 0.302, {'top1': 0.302}), (3, 0.5626, {'top1': 0.5626}), (5, 0.5506, {'top1': 0.5506}), (6, 0.5732, {'top1': 0.5732}), (7, 0.5534, {'top1': 0.5534}), (8, 0.5018, {'top1': 0.5018}), (9, 0.5126, {'top1': 0.5126}), (10, 0.5768, {'top1': 0.5768}), (13, 0.5602, {'top1': 0.5602}), (16, 0.5426, {'top1': 0.5426}), (17, 0.5208, {'top1': 0.5208}), (18, 0.2634, {'top1': 0.2634}), (19, 0.5134, {'top1': 0.5134}), (20, 0.587, {'top1': 0.587}), (22, 0.4646, {'top1': 0.4646}), (23, 0.5358, {'top1': 0.5358}), (24, 0.5842, {'top1': 0.5842}), (25, 0.5702, {'top1': 0.5702}), (27, 0.5512, {'top1': 0.5512}), (30, 0.5712, {'top1': 0.5712}), (36, 0.2224, {'top1': 0.2224}), (51, 0.523, {'top1': 0.523}), (52, 0.2684, {'top1': 0.2684}), (53, 0.1208, {'top1': 0.1208})]
just computed impact of block 20 . accuracy after removing:  0.587
removed block 20 current accuracy 0.587 loss from initial  0.251
since last training loss: 0.251 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.461, {'top1': 0.461}), (2, 0.2958, {'top1': 0.2958}), (3, 0.5374, {'top1': 0.5374}), (5, 0.5004, {'top1': 0.5004}), (6, 0.5364, {'top1': 0.5364}), (7, 0.5132, {'top1': 0.5132}), (8, 0.48, {'top1': 0.48}), (9, 0.5026, {'top1': 0.5026}), (10, 0.5396, {'top1': 0.5396}), (13, 0.5248, {'top1': 0.5248}), (16, 0.524, {'top1': 0.524}), (17, 0.5164, {'top1': 0.5164}), (18, 0.3048, {'top1': 0.3048}), (19, 0.441, {'top1': 0.441}), (22, 0.4252, {'top1': 0.4252}), (23, 0.4792, {'top1': 0.4792}), (24, 0.541, {'top1': 0.541}), (25, 0.529, {'top1': 0.529}), (27, 0.5124, {'top1': 0.5124}), (30, 0.5176, {'top1': 0.5176}), (36, 0.2072, {'top1': 0.2072}), (51, 0.4918, {'top1': 0.4918}), (52, 0.2098, {'top1': 0.2098}), (53, 0.1154, {'top1': 0.1154})]
just computed impact of block 24 . accuracy after removing:  0.541
removed block 24 current accuracy 0.541 loss from initial  0.29699999999999993
since last training loss: 0.29699999999999993 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.4262, {'top1': 0.4262}), (2, 0.263, {'top1': 0.263}), (3, 0.4754, {'top1': 0.4754}), (5, 0.448, {'top1': 0.448}), (6, 0.4872, {'top1': 0.4872}), (7, 0.4698, {'top1': 0.4698}), (8, 0.4358, {'top1': 0.4358}), (9, 0.4544, {'top1': 0.4544}), (10, 0.4908, {'top1': 0.4908}), (13, 0.4734, {'top1': 0.4734}), (16, 0.4728, {'top1': 0.4728}), (17, 0.4688, {'top1': 0.4688}), (18, 0.2814, {'top1': 0.2814}), (19, 0.402, {'top1': 0.402}), (22, 0.3726, {'top1': 0.3726}), (23, 0.4216, {'top1': 0.4216}), (25, 0.4618, {'top1': 0.4618}), (27, 0.4564, {'top1': 0.4564}), (30, 0.4622, {'top1': 0.4622}), (36, 0.1858, {'top1': 0.1858}), (51, 0.4524, {'top1': 0.4524}), (52, 0.2112, {'top1': 0.2112}), (53, 0.113, {'top1': 0.113})]
just computed impact of block 10 . accuracy after removing:  0.4908
removed block 10 current accuracy 0.4908 loss from initial  0.34719999999999995
since last training loss: 0.34719999999999995 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.3898, {'top1': 0.3898}), (2, 0.2486, {'top1': 0.2486}), (3, 0.4284, {'top1': 0.4284}), (5, 0.3936, {'top1': 0.3936}), (6, 0.4338, {'top1': 0.4338}), (7, 0.4176, {'top1': 0.4176}), (8, 0.386, {'top1': 0.386}), (9, 0.4078, {'top1': 0.4078}), (13, 0.4128, {'top1': 0.4128}), (16, 0.4154, {'top1': 0.4154}), (17, 0.404, {'top1': 0.404}), (18, 0.2662, {'top1': 0.2662}), (19, 0.3724, {'top1': 0.3724}), (22, 0.3416, {'top1': 0.3416}), (23, 0.3782, {'top1': 0.3782}), (25, 0.416, {'top1': 0.416}), (27, 0.4118, {'top1': 0.4118}), (30, 0.4158, {'top1': 0.4158}), (36, 0.1732, {'top1': 0.1732}), (51, 0.4152, {'top1': 0.4152}), (52, 0.2368, {'top1': 0.2368}), (53, 0.1108, {'top1': 0.1108})]
just computed impact of block 6 . accuracy after removing:  0.4338
removed block 6 current accuracy 0.4338 loss from initial  0.40419999999999995
since last training loss: 0.40419999999999995 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(0, 0.341, {'top1': 0.341}), (2, 0.2218, {'top1': 0.2218}), (3, 0.375, {'top1': 0.375}), (5, 0.3424, {'top1': 0.3424}), (7, 0.3482, {'top1': 0.3482}), (8, 0.3404, {'top1': 0.3404}), (9, 0.3524, {'top1': 0.3524}), (13, 0.3774, {'top1': 0.3774}), (16, 0.367, {'top1': 0.367}), (17, 0.3518, {'top1': 0.3518}), (18, 0.2588, {'top1': 0.2588}), (19, 0.3342, {'top1': 0.3342}), (22, 0.31, {'top1': 0.31}), (23, 0.335, {'top1': 0.335}), (25, 0.3642, {'top1': 0.3642}), (27, 0.3648, {'top1': 0.3648}), (30, 0.371, {'top1': 0.371}), (36, 0.158, {'top1': 0.158}), (51, 0.3718, {'top1': 0.3718}), (52, 0.2528, {'top1': 0.2528}), (53, 0.1126, {'top1': 0.1126})]
just computed impact of block 13 . accuracy after removing:  0.3774
removed block 13 current accuracy 0.3774 loss from initial  0.46059999999999995
since last training loss: 0.46059999999999995 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.3216, {'top1': 0.3216}), (2, 0.1928, {'top1': 0.1928}), (3, 0.3344, {'top1': 0.3344}), (5, 0.3302, {'top1': 0.3302}), (7, 0.3212, {'top1': 0.3212}), (8, 0.3278, {'top1': 0.3278}), (9, 0.2876, {'top1': 0.2876}), (16, 0.3046, {'top1': 0.3046}), (17, 0.2614, {'top1': 0.2614}), (18, 0.2164, {'top1': 0.2164}), (19, 0.2936, {'top1': 0.2936}), (22, 0.2942, {'top1': 0.2942}), (23, 0.3, {'top1': 0.3}), (25, 0.3172, {'top1': 0.3172}), (27, 0.3246, {'top1': 0.3246}), (30, 0.3278, {'top1': 0.3278}), (36, 0.1624, {'top1': 0.1624}), (51, 0.3232, {'top1': 0.3232}), (52, 0.2214, {'top1': 0.2214}), (53, 0.1106, {'top1': 0.1106})]
just computed impact of block 3 . accuracy after removing:  0.3344
removed block 3 current accuracy 0.3344 loss from initial  0.5036
since last training loss: 0.5036 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.2874, {'top1': 0.2874}), (2, 0.1684, {'top1': 0.1684}), (5, 0.277, {'top1': 0.277}), (7, 0.281, {'top1': 0.281}), (8, 0.2876, {'top1': 0.2876}), (9, 0.2536, {'top1': 0.2536}), (16, 0.2762, {'top1': 0.2762}), (17, 0.2642, {'top1': 0.2642}), (18, 0.1942, {'top1': 0.1942}), (19, 0.262, {'top1': 0.262}), (22, 0.2552, {'top1': 0.2552}), (23, 0.2606, {'top1': 0.2606}), (25, 0.2596, {'top1': 0.2596}), (27, 0.2878, {'top1': 0.2878}), (30, 0.2784, {'top1': 0.2784}), (36, 0.1636, {'top1': 0.1636}), (51, 0.3086, {'top1': 0.3086}), (52, 0.2272, {'top1': 0.2272}), (53, 0.1096, {'top1': 0.1096})]
just computed impact of block 51 . accuracy after removing:  0.3086
removed block 51 current accuracy 0.3086 loss from initial  0.5294
since last training loss: 0.5294 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.2342, {'top1': 0.2342}), (2, 0.1352, {'top1': 0.1352}), (5, 0.2452, {'top1': 0.2452}), (7, 0.2504, {'top1': 0.2504}), (8, 0.2422, {'top1': 0.2422}), (9, 0.2478, {'top1': 0.2478}), (16, 0.2662, {'top1': 0.2662}), (17, 0.207, {'top1': 0.207}), (18, 0.1376, {'top1': 0.1376}), (19, 0.2766, {'top1': 0.2766}), (22, 0.2254, {'top1': 0.2254}), (23, 0.2378, {'top1': 0.2378}), (25, 0.2716, {'top1': 0.2716}), (27, 0.2506, {'top1': 0.2506}), (30, 0.2656, {'top1': 0.2656}), (36, 0.154, {'top1': 0.154}), (52, 0.1658, {'top1': 0.1658}), (53, 0.125, {'top1': 0.125})]
just computed impact of block 19 . accuracy after removing:  0.2766
removed block 19 current accuracy 0.2766 loss from initial  0.5613999999999999
since last training loss: 0.5613999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.2278, {'top1': 0.2278}), (2, 0.1244, {'top1': 0.1244}), (5, 0.2308, {'top1': 0.2308}), (7, 0.238, {'top1': 0.238}), (8, 0.2338, {'top1': 0.2338}), (9, 0.273, {'top1': 0.273}), (16, 0.2576, {'top1': 0.2576}), (17, 0.2002, {'top1': 0.2002}), (18, 0.1364, {'top1': 0.1364}), (22, 0.1972, {'top1': 0.1972}), (23, 0.225, {'top1': 0.225}), (25, 0.2248, {'top1': 0.2248}), (27, 0.2216, {'top1': 0.2216}), (30, 0.2118, {'top1': 0.2118}), (36, 0.1614, {'top1': 0.1614}), (52, 0.1248, {'top1': 0.1248}), (53, 0.124, {'top1': 0.124})]
just computed impact of block 9 . accuracy after removing:  0.273
removed block 9 current accuracy 0.273 loss from initial  0.565
since last training loss: 0.565 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.2304, {'top1': 0.2304}), (2, 0.1298, {'top1': 0.1298}), (5, 0.2682, {'top1': 0.2682}), (7, 0.2404, {'top1': 0.2404}), (8, 0.2426, {'top1': 0.2426}), (16, 0.2382, {'top1': 0.2382}), (17, 0.1836, {'top1': 0.1836}), (18, 0.1248, {'top1': 0.1248}), (22, 0.197, {'top1': 0.197}), (23, 0.2292, {'top1': 0.2292}), (25, 0.2408, {'top1': 0.2408}), (27, 0.2066, {'top1': 0.2066}), (30, 0.2264, {'top1': 0.2264}), (36, 0.1518, {'top1': 0.1518}), (52, 0.1214, {'top1': 0.1214}), (53, 0.1172, {'top1': 0.1172})]
just computed impact of block 5 . accuracy after removing:  0.2682
removed block 5 current accuracy 0.2682 loss from initial  0.5698
since last training loss: 0.5698 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.2222, {'top1': 0.2222}), (2, 0.118, {'top1': 0.118}), (7, 0.2338, {'top1': 0.2338}), (8, 0.2326, {'top1': 0.2326}), (16, 0.2404, {'top1': 0.2404}), (17, 0.1846, {'top1': 0.1846}), (18, 0.1452, {'top1': 0.1452}), (22, 0.1992, {'top1': 0.1992}), (23, 0.2286, {'top1': 0.2286}), (25, 0.2198, {'top1': 0.2198}), (27, 0.2148, {'top1': 0.2148}), (30, 0.2058, {'top1': 0.2058}), (36, 0.1578, {'top1': 0.1578}), (52, 0.1184, {'top1': 0.1184}), (53, 0.1124, {'top1': 0.1124})]
just computed impact of block 16 . accuracy after removing:  0.2404
removed block 16 current accuracy 0.2404 loss from initial  0.5975999999999999
since last training loss: 0.5975999999999999 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.2084, {'top1': 0.2084}), (2, 0.1294, {'top1': 0.1294}), (7, 0.2186, {'top1': 0.2186}), (8, 0.214, {'top1': 0.214}), (17, 0.1852, {'top1': 0.1852}), (18, 0.1736, {'top1': 0.1736}), (22, 0.212, {'top1': 0.212}), (23, 0.2242, {'top1': 0.2242}), (25, 0.2282, {'top1': 0.2282}), (27, 0.2098, {'top1': 0.2098}), (30, 0.2244, {'top1': 0.2244}), (36, 0.1512, {'top1': 0.1512}), (52, 0.1534, {'top1': 0.1534}), (53, 0.1078, {'top1': 0.1078})]
just computed impact of block 25 . accuracy after removing:  0.2282
removed block 25 current accuracy 0.2282 loss from initial  0.6098
since last training loss: 0.6098 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.2076, {'top1': 0.2076}), (2, 0.1236, {'top1': 0.1236}), (7, 0.2174, {'top1': 0.2174}), (8, 0.2234, {'top1': 0.2234}), (17, 0.216, {'top1': 0.216}), (18, 0.1774, {'top1': 0.1774}), (22, 0.1958, {'top1': 0.1958}), (23, 0.2188, {'top1': 0.2188}), (27, 0.2214, {'top1': 0.2214}), (30, 0.1864, {'top1': 0.1864}), (36, 0.159, {'top1': 0.159}), (52, 0.1558, {'top1': 0.1558}), (53, 0.1002, {'top1': 0.1002})]
just computed impact of block 8 . accuracy after removing:  0.2234
removed block 8 current accuracy 0.2234 loss from initial  0.6146
since last training loss: 0.6146 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(0, 0.2038, {'top1': 0.2038}), (2, 0.1238, {'top1': 0.1238}), (7, 0.2146, {'top1': 0.2146}), (17, 0.1864, {'top1': 0.1864}), (18, 0.1576, {'top1': 0.1576}), (22, 0.197, {'top1': 0.197}), (23, 0.219, {'top1': 0.219}), (27, 0.2088, {'top1': 0.2088}), (30, 0.186, {'top1': 0.186}), (36, 0.1436, {'top1': 0.1436}), (52, 0.1744, {'top1': 0.1744}), (53, 0.1028, {'top1': 0.1028})]
just computed impact of block 23 . accuracy after removing:  0.219
removed block 23 current accuracy 0.219 loss from initial  0.619
since last training loss: 0.619 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(0, 0.1926, {'top1': 0.1926}), (2, 0.1226, {'top1': 0.1226}), (7, 0.202, {'top1': 0.202}), (17, 0.1738, {'top1': 0.1738}), (18, 0.1508, {'top1': 0.1508}), (22, 0.2028, {'top1': 0.2028}), (27, 0.1962, {'top1': 0.1962}), (30, 0.1824, {'top1': 0.1824}), (36, 0.1372, {'top1': 0.1372}), (52, 0.1786, {'top1': 0.1786}), (53, 0.0906, {'top1': 0.0906})]
just computed impact of block 22 . accuracy after removing:  0.2028
removed block 22 current accuracy 0.2028 loss from initial  0.6352
since last training loss: 0.6352 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(0, 0.174, {'top1': 0.174}), (2, 0.1196, {'top1': 0.1196}), (7, 0.1914, {'top1': 0.1914}), (17, 0.1506, {'top1': 0.1506}), (18, 0.1138, {'top1': 0.1138}), (27, 0.1852, {'top1': 0.1852}), (30, 0.1908, {'top1': 0.1908}), (36, 0.1056, {'top1': 0.1056}), (52, 0.188, {'top1': 0.188}), (53, 0.087, {'top1': 0.087})]
just computed impact of block 7 . accuracy after removing:  0.1914
removed block 7 current accuracy 0.1914 loss from initial  0.6466
training start
training epoch 0 val accuracy 0.738 topk_dict {'top1': 0.738} is_best True lr [0.1]
training epoch 1 val accuracy 0.7026 topk_dict {'top1': 0.7026} is_best False lr [0.1]
training epoch 2 val accuracy 0.7954 topk_dict {'top1': 0.7954} is_best True lr [0.1]
training epoch 3 val accuracy 0.7534 topk_dict {'top1': 0.7534} is_best False lr [0.1]
training epoch 4 val accuracy 0.7728 topk_dict {'top1': 0.7728} is_best False lr [0.1]
training epoch 5 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best False lr [0.1]
training epoch 6 val accuracy 0.8006 topk_dict {'top1': 0.8006} is_best True lr [0.1]
training epoch 7 val accuracy 0.774 topk_dict {'top1': 0.774} is_best False lr [0.1]
training epoch 8 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best True lr [0.1]
training epoch 9 val accuracy 0.812 topk_dict {'top1': 0.812} is_best True lr [0.1]
training epoch 10 val accuracy 0.7692 topk_dict {'top1': 0.7692} is_best False lr [0.1]
training epoch 11 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best False lr [0.1]
training epoch 12 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best False lr [0.1]
training epoch 13 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best True lr [0.1]
training epoch 14 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best False lr [0.1]
training epoch 15 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best False lr [0.1]
training epoch 16 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best False lr [0.1]
training epoch 17 val accuracy 0.7936 topk_dict {'top1': 0.7936} is_best False lr [0.1]
training epoch 18 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.1]
training epoch 19 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 20 val accuracy 0.811 topk_dict {'top1': 0.811} is_best False lr [0.1]
training epoch 21 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 22 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.1]
training epoch 23 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.1]
training epoch 24 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.1]
training epoch 25 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best False lr [0.1]
training epoch 26 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 27 val accuracy 0.8292 topk_dict {'top1': 0.8292} is_best False lr [0.1]
training epoch 28 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.1]
training epoch 29 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 30 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.1]
training epoch 31 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 32 val accuracy 0.794 topk_dict {'top1': 0.794} is_best False lr [0.1]
training epoch 33 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 34 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 35 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 36 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 37 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.1]
training epoch 38 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 39 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 40 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 41 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 42 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.1]
training epoch 43 val accuracy 0.7798 topk_dict {'top1': 0.7798} is_best False lr [0.1]
training epoch 44 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 45 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 46 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best False lr [0.1]
training epoch 47 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 48 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 49 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 50 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 51 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 52 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 53 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 54 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 55 val accuracy 0.8122 topk_dict {'top1': 0.8122} is_best False lr [0.1]
training epoch 56 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 57 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 58 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 59 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 60 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best False lr [0.1]
training epoch 61 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 62 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 63 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 64 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 65 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 66 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 67 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 68 val accuracy 0.8106 topk_dict {'top1': 0.8106} is_best False lr [0.1]
training epoch 69 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 70 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 71 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 72 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 73 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 74 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 75 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 76 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 77 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 78 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 79 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 80 val accuracy 0.7956 topk_dict {'top1': 0.7956} is_best False lr [0.1]
training epoch 81 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 82 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 83 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 84 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 85 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 86 val accuracy 0.7942 topk_dict {'top1': 0.7942} is_best False lr [0.1]
training epoch 87 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 88 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 89 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 90 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 91 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 92 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 93 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 94 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 95 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 96 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 97 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 98 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.1]
training epoch 99 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 100 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 101 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 102 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 103 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 104 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 105 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 106 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 107 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best False lr [0.1]
training epoch 108 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 109 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 110 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 111 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 112 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 113 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 114 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.1]
training epoch 115 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 116 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 117 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 118 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 119 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 120 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 121 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 122 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 123 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 124 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 125 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 126 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 127 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 128 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 129 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 130 val accuracy 0.84 topk_dict {'top1': 0.84} is_best False lr [0.1]
training epoch 131 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best False lr [0.1]
training epoch 132 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 133 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 134 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 135 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 136 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 137 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 138 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 139 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 140 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 141 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 142 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 143 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 144 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 145 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 146 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 147 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 148 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 149 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 150 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 151 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 152 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 153 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 154 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 155 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 156 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 157 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 158 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 159 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 160 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 161 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 162 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 163 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 164 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 165 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 166 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 167 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 168 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 169 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 170 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 171 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 172 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 173 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 174 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 175 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 176 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 177 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.1]
training epoch 178 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 179 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 180 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 181 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 182 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 183 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 184 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 185 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 186 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 187 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 188 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 189 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 190 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 191 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 192 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 193 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 194 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 195 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 196 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 197 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 198 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 199 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 200 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 201 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 202 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 203 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 204 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 205 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 206 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 207 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 208 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 209 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 210 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 211 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 212 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 213 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 214 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 215 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 216 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 217 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 218 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 219 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 220 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 221 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 222 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 223 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 224 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 225 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 226 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 227 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 228 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 229 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 230 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 231 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 232 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 233 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 234 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 235 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 236 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 237 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 238 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 239 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.010000000000000002]
training epoch 240 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 241 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 242 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 243 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 244 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 245 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.010000000000000002]
training epoch 246 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 247 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.010000000000000002]
training epoch 248 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.010000000000000002]
training epoch 249 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 250 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.010000000000000002]
training epoch 251 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 253 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 256 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 360 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 361 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 362 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 363 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 364 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 365 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 366 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 367 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 368 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 369 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 370 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 371 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 372 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 373 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 374 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 375 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
loading model_best from epoch 387 (acc 0.923400)
finished training. finished 479 epochs. accuracy 0.9234 topk_dict {'top1': 0.9234}
