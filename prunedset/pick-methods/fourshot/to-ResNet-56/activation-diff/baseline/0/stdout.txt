start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806221771985), (30, 0.007531446230132133), (2, 0.007728804717771709), (31, 0.009409212740138173), (34, 0.010633390164002776), (33, 0.010768219362944365), (35, 0.010826651123352349), (32, 0.011131544364616275), (28, 0.012192571186460555), (29, 0.013092639623209834), (26, 0.01327010674867779), (25, 0.014763001818209887), (27, 0.015783545095473528), (24, 0.015805189730599523), (22, 0.01584369910415262), (23, 0.017308009788393974), (39, 0.019983843667432666), (42, 0.020841387566179037), (38, 0.021028662333264947), (14, 0.021516708191484213), (43, 0.021687703672796488), (5, 0.021877118153497577), (41, 0.022125155432149768), (44, 0.022776450496166945), (45, 0.023535518907010555), (40, 0.024229633389040828), (47, 0.02465185197070241), (37, 0.02517395932227373), (49, 0.025184793630614877), (3, 0.02567107160575688), (21, 0.02570294332690537), (50, 0.02576585952192545), (20, 0.02723034261725843), (46, 0.02861855924129486), (17, 0.02994978497736156), (51, 0.03131366614252329), (48, 0.03152880142442882), (19, 0.034745858050882816), (16, 0.04510569479316473), (15, 0.04667254630476236), (0, 0.04746154835447669), (6, 0.05039409967139363), (7, 0.050692159216850996), (4, 0.05092597519978881), (10, 0.06328557385131717), (13, 0.06400972604751587), (8, 0.06672555953264236), (52, 0.0682881223037839), (12, 0.07267716806381941), (11, 0.07419469952583313), (9, 0.07928674947470427), (36, 0.3385251797735691), (18, 0.4787600599229336), (53, 0.9074814990162849)]
computing accuracy for after removing block 1 . block score: 0.004111806221771985
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.0075583591824397445), (2, 0.007992399914655834), (31, 0.009376695612445474), (34, 0.010569098289124668), (33, 0.010759366443380713), (35, 0.010833792039193213), (32, 0.011090524611063302), (28, 0.012191425077617168), (29, 0.0131408735178411), (26, 0.013311112415976822), (25, 0.014746291330084205), (24, 0.015801146859303117), (22, 0.015853287186473608), (27, 0.015870402799919248), (23, 0.0172501967754215), (39, 0.019925505854189396), (42, 0.020839827600866556), (38, 0.02093886467628181), (5, 0.021410029381513596), (14, 0.021470680134370923), (43, 0.021646990906447172), (41, 0.022096744505688548), (44, 0.022830850444734097), (45, 0.023494189837947488), (40, 0.024263028521090746), (47, 0.0246264326851815), (37, 0.02515707165002823), (49, 0.025184772675856948), (21, 0.025624873116612434), (50, 0.025800990872085094), (3, 0.026267620734870434), (20, 0.02712654136121273), (46, 0.028638296760618687), (17, 0.03002214664593339), (51, 0.03129110112786293), (48, 0.03151489142328501), (19, 0.03466663230210543), (16, 0.04479835834354162), (15, 0.04640808515250683), (0, 0.04746154835447669), (4, 0.05093049490824342), (6, 0.05134963057935238), (7, 0.05156157165765762), (10, 0.06291997665539384), (13, 0.06426404323428869), (52, 0.0681746331974864), (8, 0.06839867029339075), (12, 0.07294023409485817), (11, 0.07450826652348042), (9, 0.08042858820408583), (36, 0.3383275605738163), (18, 0.4787031263113022), (53, 0.9076696112751961)]
computing accuracy for after removing block 30 . block score: 0.0075583591824397445
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.00799239968182519), (31, 0.009402871248312294), (34, 0.010204410180449486), (35, 0.01043578318785876), (33, 0.010974526521749794), (32, 0.011320484918542206), (28, 0.012191424844786525), (29, 0.0131408735178411), (26, 0.013311111950315535), (25, 0.014746290631592274), (24, 0.015801147557795048), (22, 0.015853287070058286), (27, 0.015870402101427317), (23, 0.0172501967754215), (39, 0.01986637688241899), (38, 0.020629742881283164), (42, 0.020691831596195698), (5, 0.021410030080005527), (14, 0.021470679668709636), (43, 0.021839085035026073), (41, 0.022011037450283766), (44, 0.02278478699736297), (45, 0.023337426595389843), (47, 0.024608810665085912), (40, 0.02479364164173603), (49, 0.02500509051606059), (21, 0.02562487358227372), (37, 0.02566643711179495), (50, 0.025765019468963146), (3, 0.026267620967701077), (20, 0.02712654136121273), (46, 0.028450446436181664), (17, 0.030022146878764033), (51, 0.030892509501427412), (48, 0.03145507141016424), (19, 0.03466663137078285), (16, 0.044798357877880335), (15, 0.046408084221184254), (0, 0.0474615478888154), (4, 0.05093049490824342), (6, 0.05134962871670723), (7, 0.05156156932935119), (10, 0.06291997479274869), (13, 0.06426404230296612), (52, 0.06774707324802876), (8, 0.06839866936206818), (12, 0.07294023130089045), (11, 0.07450826466083527), (9, 0.08042858727276325), (36, 0.341789361089468), (18, 0.4787031263113022), (53, 0.9106026589870453)]
computing accuracy for after removing block 2 . block score: 0.00799239968182519
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.009391383733600378), (34, 0.010356180369853973), (35, 0.010530833387747407), (33, 0.010978628066368401), (32, 0.011285086045973003), (28, 0.01222222566138953), (29, 0.01339500502217561), (26, 0.013411890715360641), (25, 0.014773015747778118), (24, 0.01589584769681096), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (39, 0.01986844907514751), (42, 0.0207440045196563), (38, 0.02075049956329167), (5, 0.021117351483553648), (14, 0.021327618043869734), (43, 0.02179282298311591), (41, 0.021959959995001554), (44, 0.02287760702893138), (45, 0.023284759605303407), (47, 0.024535593343898654), (40, 0.024922655895352364), (49, 0.024976716842502356), (21, 0.025540468050166965), (50, 0.025736608309671283), (37, 0.025740001816302538), (3, 0.026626083767041564), (20, 0.027130911592394114), (46, 0.028354250825941563), (17, 0.030052859103307128), (51, 0.03080705483444035), (48, 0.031364004127681255), (19, 0.03459096746519208), (16, 0.044494171626865864), (15, 0.046184624545276165), (0, 0.047461549285799265), (4, 0.05093384673818946), (7, 0.052482133731245995), (6, 0.05318683013319969), (10, 0.06307358853518963), (13, 0.06417542602866888), (52, 0.06737186573445797), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423978857696056), (9, 0.08192321471869946), (36, 0.342931903898716), (18, 0.48187142238020897), (53, 0.9105552658438683)]
computing accuracy for after removing block 31 . block score: 0.009391383733600378
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670424349606), (35, 0.01044982101302594), (33, 0.010985722299665213), (32, 0.011304144631139934), (28, 0.01222222566138953), (29, 0.01339500502217561), (26, 0.013411890366114676), (25, 0.014773016329854727), (24, 0.015895847231149673), (22, 0.015945045510306954), (27, 0.01605706592090428), (23, 0.017187519930303097), (39, 0.01979714771732688), (38, 0.020344304852187634), (42, 0.02058867714367807), (5, 0.02111735171638429), (14, 0.021327617345377803), (43, 0.021761030424386263), (41, 0.02186914556659758), (44, 0.022828260203823447), (45, 0.023396301781758666), (47, 0.024508256232365966), (49, 0.02499568462371826), (40, 0.025056052254512906), (21, 0.025540467584505677), (37, 0.02570135099813342), (50, 0.02590625174343586), (3, 0.026626083767041564), (20, 0.02713091066107154), (46, 0.02855197270400822), (17, 0.030052859103307128), (51, 0.030911056324839592), (48, 0.031486503314226866), (19, 0.03459096606820822), (16, 0.04449417255818844), (15, 0.04618462407961488), (0, 0.04746154509484768), (4, 0.05093384860083461), (7, 0.05248213419690728), (6, 0.053186831064522266), (10, 0.06307358853518963), (13, 0.06417542416602373), (52, 0.06731625832617283), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423979137092829), (9, 0.08192321751266718), (36, 0.34496788308024406), (18, 0.48187143728137016), (53, 0.9170897305011749)]
computing accuracy for after removing block 34 . block score: 0.010089670424349606
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489317704923451), (33, 0.010985721950419247), (32, 0.011304144631139934), (28, 0.012222225894220173), (29, 0.01339500502217561), (26, 0.01341189059894532), (25, 0.014773015980608761), (24, 0.01589584699831903), (22, 0.015945045510306954), (27, 0.016057066153734922), (23, 0.017187519697472453), (39, 0.0192666407674551), (38, 0.019315700279548764), (42, 0.019673911156132817), (5, 0.021117351250723004), (41, 0.021174800116568804), (43, 0.021180003182962537), (14, 0.021327617345377803), (44, 0.02225361089222133), (45, 0.023224937729537487), (47, 0.024223520187661052), (49, 0.024662331910803914), (40, 0.024751327466219664), (37, 0.025114945601671934), (21, 0.025540466653183103), (50, 0.025639905594289303), (3, 0.02662608353421092), (20, 0.027130910428240895), (46, 0.02807540912181139), (17, 0.03005285793915391), (51, 0.03030704567208886), (48, 0.031094568083062768), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.0461846268735826), (0, 0.04746154975146055), (4, 0.05093384766951203), (7, 0.05248213466256857), (6, 0.053186831530183554), (10, 0.06307358760386705), (13, 0.06417542602866888), (52, 0.06632223632186651), (8, 0.07143167965114117), (12, 0.07294507883489132), (11, 0.07423979137092829), (9, 0.0819232165813446), (36, 0.341898325830698), (18, 0.48187144100666046), (53, 0.9368007630109787)]
computing accuracy for after removing block 35 . block score: 0.010489317704923451
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 1 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.011004. All blocks and scores: [(33, 0.01100378215778619), (32, 0.011730853468179703), (28, 0.012246647151187062), (26, 0.013149931444786489), (29, 0.01320238912012428), (25, 0.014885845594108105), (22, 0.015719980699941516), (27, 0.01581893884576857), (24, 0.015985548961907625), (23, 0.017490130616351962), (39, 0.01977317687124014), (42, 0.02021419513039291), (43, 0.02110435557551682), (38, 0.021341889398172498), (14, 0.02137683588080108), (41, 0.02174892812035978), (5, 0.02210715552791953), (44, 0.022326752776280046), (45, 0.023374659940600395), (40, 0.023420182056725025), (47, 0.02447089389897883), (37, 0.02515497710555792), (49, 0.02524232305586338), (50, 0.025617749197408557), (21, 0.025635659927502275), (3, 0.02593709295615554), (20, 0.027414158452302217), (46, 0.028009623056277633), (17, 0.029842662625014782), (48, 0.030938263749703765), (51, 0.031406825641170144), (19, 0.034664022736251354), (16, 0.04442551778629422), (15, 0.04618990048766136), (0, 0.047890853602439165), (6, 0.04956296645104885), (7, 0.05035129236057401), (4, 0.05067072482779622), (10, 0.0620653978548944), (13, 0.06387460976839066), (8, 0.06733095273375511), (52, 0.06751985102891922), (12, 0.07205680478364229), (11, 0.07317984383553267), (9, 0.07823782600462437), (36, 0.32804178819060326), (18, 0.4752264842391014), (53, 0.9039135277271271)]
computing accuracy for after removing block 33 . block score: 0.01100378215778619
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011731. All blocks and scores: [(32, 0.011730853235349059), (28, 0.01224664703477174), (26, 0.013149931328371167), (29, 0.013202389585785568), (25, 0.014885845012031496), (22, 0.015719980816356838), (27, 0.01581893884576857), (24, 0.015985548496246338), (23, 0.01749013038352132), (39, 0.019479349488392472), (42, 0.019823642913252115), (43, 0.020462963730096817), (38, 0.020748954033479095), (41, 0.021209151949733496), (14, 0.02137683588080108), (44, 0.021874499041587114), (5, 0.022107155760750175), (40, 0.02265276457183063), (45, 0.02336615091189742), (47, 0.023694243980571628), (37, 0.02470244374126196), (49, 0.024737033061683178), (50, 0.025276584085077047), (21, 0.025635659229010344), (3, 0.02593709295615554), (20, 0.027414158452302217), (46, 0.027434405870735645), (17, 0.02984266192652285), (48, 0.030341047327965498), (51, 0.030684013152495027), (19, 0.03466402133926749), (16, 0.044425517320632935), (15, 0.04618990095332265), (0, 0.04789085313677788), (6, 0.04956296691671014), (7, 0.05035129329189658), (4, 0.05067072343081236), (10, 0.062065396923571825), (13, 0.06387461069971323), (52, 0.0656397296115756), (8, 0.06733095552772284), (12, 0.07205680571496487), (11, 0.07317984756082296), (9, 0.07823782600462437), (36, 0.3230576030910015), (18, 0.4752264730632305), (53, 0.9254898577928543)]
computing accuracy for after removing block 32 . block score: 0.011730853235349059
removed block 32 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012247. All blocks and scores: [(28, 0.01224664703477174), (26, 0.013149930979125202), (29, 0.013202389352954924), (25, 0.014885845477692783), (22, 0.01571998023428023), (27, 0.01581893884576857), (24, 0.015985548496246338), (23, 0.01749013108201325), (42, 0.0191552781034261), (39, 0.019265437964349985), (38, 0.020259930519387126), (43, 0.02027795184403658), (41, 0.021163397934287786), (14, 0.02137683588080108), (44, 0.021522512659430504), (5, 0.022107155295088887), (40, 0.022902269149199128), (47, 0.023381204111501575), (45, 0.023381586652249098), (37, 0.023996687261387706), (49, 0.024467440554872155), (50, 0.02490091440267861), (21, 0.025635658530518413), (3, 0.025937093188986182), (46, 0.02716322080232203), (20, 0.02741415798664093), (17, 0.02984266239218414), (51, 0.03023161133751273), (48, 0.030345708830282092), (19, 0.03466402227059007), (16, 0.04442551778629422), (15, 0.04618990048766136), (0, 0.047890853602439165), (6, 0.049562967382371426), (7, 0.05035129236057401), (4, 0.05067072296515107), (10, 0.062065398786216974), (13, 0.0638746079057455), (52, 0.06488635297864676), (8, 0.06733095459640026), (12, 0.07205680385231972), (11, 0.07317984290421009), (9, 0.07823782414197922), (36, 0.32130368053913116), (18, 0.475226491689682), (53, 0.9352012574672699)]
computing accuracy for after removing block 28 . block score: 0.01224664703477174
removed block 28 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.012947. All blocks and scores: [(29, 0.012946801725775003), (26, 0.013149931794032454), (25, 0.014885845012031496), (22, 0.015719980583526194), (27, 0.015818938612937927), (24, 0.015985548961907625), (23, 0.01749013038352132), (42, 0.01851792843081057), (39, 0.019257780630141497), (43, 0.019778284709900618), (38, 0.019950822927057743), (41, 0.02092346060089767), (44, 0.021159092895686626), (14, 0.02137683588080108), (5, 0.022107155062258244), (40, 0.02228201599791646), (47, 0.022820572601631284), (45, 0.023042501648887992), (37, 0.02371376962400973), (49, 0.02396693197079003), (50, 0.024639672366902232), (21, 0.02563565969467163), (3, 0.02593709249049425), (46, 0.026793425902724266), (20, 0.027414158917963505), (51, 0.02957049454562366), (48, 0.029791773064062), (17, 0.02984266239218414), (19, 0.03466402227059007), (16, 0.04442551685497165), (15, 0.04618990235030651), (0, 0.04789085313677788), (6, 0.049562965519726276), (7, 0.05035129236057401), (4, 0.050670723896473646), (10, 0.06206539738923311), (52, 0.06378048192709684), (13, 0.06387460883706808), (8, 0.06733095552772284), (12, 0.07205680385231972), (11, 0.07317984569817781), (9, 0.07823782414197922), (36, 0.3170490823686123), (18, 0.4752264842391014), (53, 0.9501034542918205)]
computing accuracy for after removing block 29 . block score: 0.012946801725775003
removed block 29 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013150. All blocks and scores: [(26, 0.013149930979125202), (25, 0.014885845128446817), (22, 0.015719980583526194), (27, 0.015818939078599215), (24, 0.01598554872907698), (23, 0.01749013038352132), (42, 0.01864238199777901), (39, 0.018996116472408175), (38, 0.01914956048130989), (43, 0.01963704894296825), (44, 0.020675361854955554), (41, 0.020748239941895008), (14, 0.021376835647970438), (5, 0.02210715552791953), (40, 0.022473546909168363), (47, 0.022615307942032814), (45, 0.022962467512115836), (49, 0.02352679963223636), (37, 0.023533864878118038), (50, 0.024534670636057854), (21, 0.0256356589961797), (3, 0.025937092723324895), (46, 0.026918695541098714), (20, 0.027414158917963505), (51, 0.029334769817069173), (17, 0.02984266239218414), (48, 0.029843982309103012), (19, 0.03466402320191264), (16, 0.04442551825195551), (15, 0.046189900022000074), (0, 0.04789085406810045), (6, 0.049562967382371426), (7, 0.05035129236057401), (4, 0.050670724362134933), (10, 0.06206539738923311), (52, 0.06343621667474508), (13, 0.06387460976839066), (8, 0.06733095459640026), (12, 0.07205680385231972), (11, 0.07317984569817781), (9, 0.07823782414197922), (36, 0.3205096162855625), (18, 0.4752264730632305), (53, 0.9550683051347733)]
computing accuracy for after removing block 26 . block score: 0.013149930979125202
removed block 26 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014886. All blocks and scores: [(25, 0.014885845012031496), (22, 0.015719980467110872), (24, 0.015985548263415694), (27, 0.016145152738317847), (23, 0.017490130150690675), (42, 0.0179241388104856), (39, 0.018532589310780168), (38, 0.018918605288490653), (43, 0.019206544617190957), (44, 0.020425521535798907), (41, 0.020444449735805392), (14, 0.021376835647970438), (40, 0.02210185886360705), (5, 0.02210715552791953), (47, 0.022393248043954372), (45, 0.022767165210098028), (37, 0.02327173901721835), (49, 0.02329677063971758), (50, 0.024646135745570064), (21, 0.0256356589961797), (3, 0.025937092257663608), (46, 0.026366041507571936), (20, 0.027414158219471574), (51, 0.028546944027766585), (48, 0.029784555546939373), (17, 0.029842662159353495), (19, 0.034664022736251354), (16, 0.04442551778629422), (15, 0.046189900022000074), (0, 0.047890853602439165), (6, 0.049562965519726276), (7, 0.05035129329189658), (4, 0.050670723896473646), (10, 0.06206539925187826), (52, 0.062282292637974024), (13, 0.06387460697442293), (8, 0.06733095552772284), (12, 0.07205680478364229), (11, 0.07317984569817781), (9, 0.07823782414197922), (36, 0.31745898723602295), (18, 0.4752264656126499), (53, 0.9752037823200226)]
computing accuracy for after removing block 25 . block score: 0.014885845012031496
removed block 25 current accuracy 0.996 loss from initial  0.0040000000000000036
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 2 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 3 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 5 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 7 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 14 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.017371. All blocks and scores: [(24, 0.017371192574501038), (22, 0.01785272010602057), (27, 0.01832838193513453), (39, 0.019220714224502444), (42, 0.019549873657524586), (23, 0.019697881303727627), (43, 0.02004751213826239), (41, 0.020371452206745744), (38, 0.020932042971253395), (14, 0.021582160610705614), (44, 0.02162054367363453), (5, 0.021834861021488905), (45, 0.022639598697423935), (40, 0.022756408900022507), (47, 0.02396223321557045), (37, 0.024171665078029037), (49, 0.024801948573440313), (50, 0.0249934874009341), (3, 0.02584934188053012), (21, 0.02707295585423708), (46, 0.027140648337081075), (20, 0.029120449675247073), (17, 0.030464340932667255), (48, 0.03071328019723296), (51, 0.03133763815276325), (19, 0.03562350291758776), (16, 0.04559209104627371), (15, 0.04614630062133074), (0, 0.0470162108540535), (6, 0.049323463812470436), (4, 0.05032518785446882), (7, 0.05040533794090152), (10, 0.06175196683034301), (13, 0.06438612844794989), (8, 0.06549872923642397), (52, 0.06762819737195969), (12, 0.07142287772148848), (11, 0.07368604466319084), (9, 0.0772894723340869), (36, 0.32214970514178276), (18, 0.46866442635655403), (53, 0.8870461508631706)]
computing accuracy for after removing block 24 . block score: 0.017371192574501038
removed block 24 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.017483. All blocks and scores: [(27, 0.01748333778232336), (22, 0.01785272010602057), (39, 0.01901009911671281), (42, 0.01903932448476553), (23, 0.019697881070896983), (43, 0.019844516646116972), (41, 0.02015110827051103), (38, 0.0206107753328979), (44, 0.021352163050323725), (14, 0.0215821610763669), (5, 0.021834861719980836), (45, 0.02243225835263729), (40, 0.02243638806976378), (47, 0.02342137391678989), (37, 0.02416149224154651), (49, 0.024247078225016594), (50, 0.024678654735907912), (3, 0.025849342113360763), (46, 0.026479048188775778), (21, 0.02707295515574515), (20, 0.02912045083940029), (48, 0.030098532792180777), (17, 0.030464341398328543), (51, 0.03046904201619327), (19, 0.035623503383249044), (16, 0.045592090114951134), (15, 0.046146301086992025), (0, 0.0470162108540535), (6, 0.04932346427813172), (4, 0.05032518599182367), (7, 0.05040533794090152), (10, 0.061751963570714), (13, 0.06438612844794989), (8, 0.06549873016774654), (52, 0.06605536583811045), (12, 0.07142287865281105), (11, 0.07368604652583599), (9, 0.0772894723340869), (36, 0.3200368210673332), (18, 0.46866442635655403), (53, 0.8964989557862282)]
computing accuracy for after removing block 27 . block score: 0.01748333778232336
removed block 27 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.017853. All blocks and scores: [(22, 0.01785272010602057), (39, 0.01831816043704748), (42, 0.018408432137221098), (43, 0.019004930974915624), (41, 0.019563900073990226), (23, 0.019697881303727627), (38, 0.019700322533026338), (44, 0.021036173682659864), (14, 0.021582160145044327), (40, 0.021752436878159642), (5, 0.02183486195281148), (45, 0.0220049312338233), (47, 0.02257810835726559), (37, 0.023409165209159255), (49, 0.02352764317765832), (50, 0.02463964791968465), (46, 0.02566980989649892), (3, 0.02584934188053012), (21, 0.027072955621406436), (20, 0.02912045083940029), (51, 0.029539623530581594), (48, 0.02957922383211553), (17, 0.03046434256248176), (19, 0.035623503383249044), (16, 0.045592091511934996), (15, 0.04614630155265331), (0, 0.04701620852574706), (6, 0.04932346334680915), (4, 0.05032518785446882), (7, 0.05040533794090152), (10, 0.06175196496769786), (52, 0.06425544992089272), (13, 0.06438612937927246), (8, 0.0654987320303917), (12, 0.07142287865281105), (11, 0.07368604652583599), (9, 0.07728947419673204), (36, 0.3123263157904148), (18, 0.46866442263126373), (53, 0.9135311394929886)]
computing accuracy for after removing block 22 . block score: 0.01785272010602057
removed block 22 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.017288. All blocks and scores: [(42, 0.017287917900830507), (39, 0.018263648496940732), (43, 0.019079183461144567), (23, 0.019079652149230242), (41, 0.01949495356529951), (38, 0.019651867216452956), (40, 0.02101120143197477), (44, 0.0210532417986542), (14, 0.021582160145044327), (5, 0.02183486195281148), (45, 0.02196982060559094), (47, 0.022080233553424478), (49, 0.022980898385867476), (37, 0.02314164931885898), (50, 0.02449190686456859), (46, 0.025444986997172236), (3, 0.02584934141486883), (21, 0.027072956785559654), (51, 0.028484463691711426), (48, 0.028947673505172133), (20, 0.029120450606569648), (17, 0.030464341631159186), (19, 0.03562350198626518), (16, 0.04559209058061242), (15, 0.04614630062133074), (0, 0.04701620899140835), (6, 0.04932346334680915), (4, 0.0503251850605011), (7, 0.050405338406562805), (10, 0.06175196310505271), (52, 0.06277775531634688), (13, 0.06438612844794989), (8, 0.0654987283051014), (12, 0.07142287865281105), (11, 0.07368604652583599), (9, 0.07728947419673204), (36, 0.3093217946588993), (18, 0.46866442263126373), (53, 0.9318509697914124)]
computing accuracy for after removing block 42 . block score: 0.017287917900830507
removed block 42 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 39, with score 0.018264. All blocks and scores: [(39, 0.01826364896260202), (23, 0.019079652382060885), (41, 0.019494953798130155), (38, 0.019651867216452956), (43, 0.02062892890535295), (40, 0.021011201664805412), (14, 0.021582160610705614), (5, 0.02183486125431955), (44, 0.021961575839668512), (47, 0.022126633673906326), (49, 0.023086330853402615), (37, 0.02314164862036705), (45, 0.02317182975821197), (50, 0.024346086662262678), (3, 0.02584934188053012), (46, 0.026178090134635568), (21, 0.02707295655272901), (51, 0.027857781387865543), (48, 0.028600697172805667), (20, 0.029120450606569648), (17, 0.030464342096820474), (19, 0.03562350291758776), (16, 0.045592091511934996), (15, 0.04614630015566945), (0, 0.04701620992273092), (6, 0.049323463812470436), (4, 0.05032518645748496), (7, 0.05040533794090152), (52, 0.06053048139438033), (10, 0.06175196310505271), (13, 0.06438612751662731), (8, 0.0654987320303917), (12, 0.0714228805154562), (11, 0.07368604466319084), (9, 0.07728947326540947), (36, 0.309321790933609), (18, 0.46866441518068314), (53, 0.9596244841814041)]
computing accuracy for after removing block 39 . block score: 0.01826364896260202
removed block 39 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.019080. All blocks and scores: [(23, 0.019079651916399598), (38, 0.019651867216452956), (41, 0.01970840315334499), (43, 0.02054087701253593), (40, 0.02091457531787455), (14, 0.0215821610763669), (5, 0.021834860322996974), (47, 0.022176673403009772), (44, 0.022721747402101755), (49, 0.022971228696405888), (37, 0.02314164978452027), (45, 0.023630459792912006), (50, 0.024182452587410808), (3, 0.025849341182038188), (46, 0.026302899001166224), (51, 0.026964033721014857), (21, 0.02707295655272901), (48, 0.02895932924002409), (20, 0.02912045014090836), (17, 0.030464340932667255), (19, 0.03562350291758776), (16, 0.045592091511934996), (15, 0.04614630015566945), (0, 0.04701621038839221), (6, 0.049323463812470436), (4, 0.0503251850605011), (7, 0.05040533747524023), (52, 0.06006906507536769), (10, 0.06175196310505271), (13, 0.06438613031059504), (8, 0.0654987283051014), (12, 0.07142287772148848), (11, 0.07368604745715857), (9, 0.07728947326540947), (36, 0.309321790933609), (18, 0.46866443380713463), (53, 1.0050731673836708)]
computing accuracy for after removing block 23 . block score: 0.019079651916399598
removed block 23 current accuracy 0.9836 loss from initial  0.01639999999999997
training start
training epoch 0 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 1 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 2 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 3 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 4 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 5 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 6 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 7 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 8 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 9 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 10 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 11 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 12 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 13 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 14 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 15 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 16 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 17 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 18 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 19 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 21 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 23 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 27 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 28 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 35 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 39 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 41 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 42 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 43 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 45 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 46 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 48 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 49 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 18
[activation diff]: block to remove picked: 38, with score 0.021174. All blocks and scores: [(38, 0.021174068562686443), (5, 0.021430304506793618), (41, 0.02183614345267415), (14, 0.022227470064535737), (43, 0.02268711687065661), (44, 0.02294563641771674), (45, 0.023083830252289772), (47, 0.023746855789795518), (49, 0.024209587834775448), (50, 0.02429250511340797), (40, 0.024549552705138922), (3, 0.025268973549827933), (37, 0.025447263149544597), (46, 0.02742021670565009), (48, 0.030178553657606244), (51, 0.030373160494491458), (17, 0.030722340801730752), (21, 0.03419499937444925), (20, 0.03541087405756116), (19, 0.041672954335808754), (0, 0.04391100211068988), (15, 0.04625843092799187), (6, 0.047069134656339884), (16, 0.04727603867650032), (4, 0.0474233110435307), (7, 0.04814917268231511), (10, 0.057981143705546856), (13, 0.06260210229083896), (8, 0.06275633815675974), (52, 0.06630976777523756), (12, 0.07028127647936344), (11, 0.07247353158891201), (9, 0.0755950715392828), (36, 0.31750303506851196), (18, 0.45335833728313446), (53, 0.9033586010336876)]
computing accuracy for after removing block 38 . block score: 0.021174068562686443
removed block 38 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 5, with score 0.021430. All blocks and scores: [(5, 0.021430304273962975), (41, 0.022068580146878958), (14, 0.022227470064535737), (43, 0.02280122018419206), (45, 0.022827389417216182), (50, 0.02328299288637936), (47, 0.023324603214859962), (44, 0.023327084025368094), (49, 0.02334512397646904), (3, 0.02526897401548922), (37, 0.025447263149544597), (40, 0.02588595007546246), (46, 0.02738347789272666), (51, 0.028756748884916306), (48, 0.029296653578057885), (17, 0.030722338939085603), (21, 0.03419500030577183), (20, 0.035410874523222446), (19, 0.04167295480147004), (0, 0.043911002576351166), (15, 0.04625843092799187), (6, 0.047069134656339884), (16, 0.047276037745177746), (4, 0.04742331197485328), (7, 0.048149172216653824), (10, 0.05798113998025656), (13, 0.06260210508480668), (8, 0.06275634141638875), (52, 0.06376962922513485), (12, 0.07028127834200859), (11, 0.07247353065758944), (9, 0.07559506967663765), (36, 0.31750304624438286), (18, 0.45335834845900536), (53, 0.9276477172970772)]
computing accuracy for after removing block 5 . block score: 0.021430304273962975
removed block 5 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 14, with score 0.021419. All blocks and scores: [(14, 0.02141929347999394), (41, 0.022244825260713696), (43, 0.023005891125649214), (45, 0.023053315235301852), (49, 0.023355409735813737), (50, 0.023392317118123174), (47, 0.023483298253268003), (44, 0.023603607900440693), (3, 0.02526897331699729), (37, 0.026696246350184083), (46, 0.02765390696004033), (40, 0.027955123921856284), (51, 0.02849789639003575), (48, 0.0294483145698905), (17, 0.029528007144108415), (21, 0.03341998951509595), (20, 0.034816048108041286), (19, 0.041219383012503386), (0, 0.043911002576351166), (15, 0.04573339270427823), (16, 0.046151505783200264), (6, 0.047020625323057175), (4, 0.04742331197485328), (7, 0.052206136751919985), (10, 0.05794420372694731), (13, 0.061564634554088116), (52, 0.06319557828828692), (8, 0.06437387131154537), (11, 0.0680415565147996), (12, 0.06929143331944942), (9, 0.07544333394616842), (36, 0.324733205139637), (18, 0.4595143534243107), (53, 0.9284402057528496)]
computing accuracy for after removing block 14 . block score: 0.02141929347999394
removed block 14 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.023348. All blocks and scores: [(50, 0.023348159622401), (45, 0.023588275304064155), (47, 0.023751363391056657), (49, 0.024117263965308666), (41, 0.024406794924288988), (44, 0.025077213998883963), (3, 0.02526897331699729), (43, 0.026266930857673287), (37, 0.027388405753299594), (46, 0.028063647216185927), (51, 0.028291303431615233), (48, 0.029484170954674482), (40, 0.029733818490058184), (17, 0.030929388711228967), (21, 0.03322940645739436), (20, 0.03535822220146656), (0, 0.04391100304201245), (19, 0.04501719353720546), (6, 0.047020625323057175), (16, 0.04707877663895488), (4, 0.047423310577869415), (15, 0.04746317630633712), (7, 0.0522061362862587), (10, 0.05794420279562473), (13, 0.06156463548541069), (52, 0.06350542651489377), (8, 0.0643738703802228), (11, 0.06804155837744474), (12, 0.06929143331944942), (9, 0.07544333301484585), (36, 0.3349280096590519), (18, 0.46197758987545967), (53, 0.8934122398495674)]
computing accuracy for after removing block 50 . block score: 0.023348159622401
removed block 50 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.023588. All blocks and scores: [(45, 0.02358827507123351), (47, 0.0237513636238873), (49, 0.02411726303398609), (41, 0.024406795855611563), (44, 0.02507721446454525), (3, 0.025268973084166646), (43, 0.026266930857673287), (37, 0.027388405986130238), (46, 0.02806364791467786), (48, 0.02948417142033577), (40, 0.029733818024396896), (51, 0.030254326295107603), (17, 0.030929389176890254), (21, 0.03322940692305565), (20, 0.035358221270143986), (0, 0.04391100211068988), (19, 0.04501719539985061), (6, 0.04702062578871846), (16, 0.04707877803593874), (4, 0.047423312440514565), (15, 0.047463176771998405), (7, 0.0522061362862587), (10, 0.05794420372694731), (13, 0.06156463595107198), (52, 0.06330935657024384), (8, 0.0643738703802228), (11, 0.0680415565147996), (12, 0.06929143331944942), (9, 0.075443334877491), (36, 0.3349280133843422), (18, 0.46197760105133057), (53, 1.065399020910263)]
computing accuracy for after removing block 45 . block score: 0.02358827507123351
removed block 45 current accuracy 0.9834 loss from initial  0.016599999999999948
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.023657. All blocks and scores: [(47, 0.02365661272779107), (41, 0.024406794691458344), (49, 0.024451409000903368), (44, 0.025077213998883963), (3, 0.025268972385674715), (43, 0.026266930857673287), (37, 0.027388405753299594), (48, 0.02948208199813962), (51, 0.02953464863821864), (40, 0.029733819188550115), (46, 0.030316484859213233), (17, 0.030929389409720898), (21, 0.03322940645739436), (20, 0.035358221270143986), (0, 0.04391100304201245), (19, 0.04501719353720546), (6, 0.04702062485739589), (16, 0.04707877663895488), (4, 0.04742331290617585), (15, 0.047463175375014544), (7, 0.05220613721758127), (10, 0.05794420558959246), (52, 0.060408724937587976), (13, 0.0615646350197494), (8, 0.06437387131154537), (11, 0.06804155744612217), (12, 0.06929143145680428), (9, 0.07544333208352327), (36, 0.3349280208349228), (18, 0.4619775861501694), (53, 1.1588639616966248)]
computing accuracy for after removing block 47 . block score: 0.02365661272779107
removed block 47 current accuracy 0.9634 loss from initial  0.036599999999999966
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.024407. All blocks and scores: [(41, 0.024406795157119632), (44, 0.02507721376605332), (3, 0.025268973549827933), (43, 0.026266930392012), (49, 0.02695664786733687), (37, 0.02738840621896088), (40, 0.029733818490058184), (46, 0.030316485092043877), (51, 0.030866150511428714), (17, 0.03092939010821283), (48, 0.032394774025306106), (21, 0.03322940692305565), (20, 0.03535822033882141), (0, 0.04391100304201245), (19, 0.04501719539985061), (6, 0.0470206243917346), (16, 0.04707877803593874), (4, 0.04742331290617585), (15, 0.04746317630633712), (7, 0.05220613814890385), (10, 0.05794420372694731), (13, 0.061564636416733265), (52, 0.06198944244533777), (8, 0.0643738703802228), (11, 0.06804155837744474), (12, 0.069291434250772), (9, 0.07544333394616842), (36, 0.3349280133843422), (18, 0.46197760105133057), (53, 1.2871571332216263)]
computing accuracy for after removing block 41 . block score: 0.024406795157119632
removed block 41 current accuracy 0.9444 loss from initial  0.05559999999999998
since last training loss: 0.054200000000000026 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 3, with score 0.025269. All blocks and scores: [(3, 0.025268973549827933), (44, 0.026378309819847345), (49, 0.026839150115847588), (37, 0.027388406917452812), (43, 0.028333530062809587), (51, 0.029487635008990765), (40, 0.029733817791566253), (46, 0.030475351260975003), (17, 0.030929389176890254), (48, 0.03215918713249266), (21, 0.03322940645739436), (20, 0.035358221270143986), (0, 0.04391100211068988), (19, 0.04501719446852803), (6, 0.047020623460412025), (16, 0.04707877617329359), (4, 0.04742331290617585), (15, 0.04746317584067583), (7, 0.05220613768324256), (10, 0.057944204192608595), (52, 0.060076020658016205), (13, 0.06156463548541069), (8, 0.06437386851757765), (11, 0.06804155744612217), (12, 0.06929143238812685), (9, 0.07544333301484585), (36, 0.3349280133843422), (18, 0.46197758987545967), (53, 1.400829553604126)]
computing accuracy for after removing block 3 . block score: 0.025268973549827933
removed block 3 current accuracy 0.9364 loss from initial  0.06359999999999999
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.026378. All blocks and scores: [(44, 0.02637838409282267), (49, 0.026724796509370208), (37, 0.027711399598047137), (43, 0.027780228527262807), (51, 0.029051470337435603), (46, 0.029781183693557978), (17, 0.03056202013976872), (40, 0.03070600121282041), (48, 0.03199446457438171), (21, 0.03236038517206907), (20, 0.0348457177169621), (0, 0.04391100304201245), (19, 0.04396764561533928), (16, 0.04516812181100249), (15, 0.04647664958611131), (4, 0.04690500581637025), (6, 0.04994346760213375), (7, 0.05174675723537803), (52, 0.0597331253811717), (13, 0.06087964586913586), (10, 0.062282102182507515), (8, 0.06335814483463764), (12, 0.06715599913150072), (11, 0.06786843668669462), (9, 0.07431301474571228), (36, 0.33278338611125946), (18, 0.4622144140303135), (53, 1.4185687154531479)]
computing accuracy for after removing block 44 . block score: 0.02637838409282267
removed block 44 current accuracy 0.8984 loss from initial  0.10160000000000002
training start
training epoch 0 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 1 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 2 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 3 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 4 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 5 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 6 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 7 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 8 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 9 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 10 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 11 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 12 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 13 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 14 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 15 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 16 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 17 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 18 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 19 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 20 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 21 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 22 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 23 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 24 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 25 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 26 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 27 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 28 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 29 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 30 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 31 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 32 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 33 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 34 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 35 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 36 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 37 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 38 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 39 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 40 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 41 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 42 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 43 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 45 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 46 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 47 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 48 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 49 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.994200)
finished training. finished 50 epochs. accuracy 0.9942 topk_dict {'top1': 0.9942}
