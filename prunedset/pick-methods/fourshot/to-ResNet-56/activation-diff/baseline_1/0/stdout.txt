start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009340. All blocks and scores: [(35, 0.009340325370430946), (27, 0.011103683500550687), (21, 0.011334074195474386), (31, 0.011607038672082126), (34, 0.011916786432266235), (20, 0.012414054479449987), (10, 0.012957266764715314), (29, 0.01319159206468612), (28, 0.014451422030106187), (25, 0.015047204564325511), (32, 0.015597441117279232), (26, 0.015913886483758688), (9, 0.015947437845170498), (33, 0.01621382776647806), (19, 0.016238084062933922), (30, 0.01653508166782558), (13, 0.01730443094857037), (23, 0.017807669239118695), (24, 0.018264206359162927), (47, 0.018334639258682728), (43, 0.018826094456017017), (22, 0.01902754232287407), (42, 0.019418791867792606), (39, 0.01959144975990057), (11, 0.019892503041774035), (46, 0.01998406951315701), (45, 0.020175756653770804), (40, 0.020337841706350446), (44, 0.020350370788946748), (41, 0.02134683378972113), (17, 0.022294857073575258), (14, 0.02316005458123982), (48, 0.023965090047568083), (38, 0.024251851486042142), (49, 0.02534035500138998), (37, 0.02872352977283299), (50, 0.03070739726535976), (51, 0.0362198487855494), (15, 0.03717772848904133), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213463073596358), (5, 0.052416717167943716), (7, 0.05547522474080324), (2, 0.06098463898524642), (16, 0.06157056428492069), (3, 0.06243071798235178), (6, 0.06518651731312275), (52, 0.07758118864148855), (1, 0.1571871805936098), (36, 0.31111688166856766), (18, 0.38249505311250687), (53, 0.863927811384201)]
computing accuracy for after removing block 35 . block score: 0.009340325370430946
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.011104. All blocks and scores: [(27, 0.011103683500550687), (21, 0.011334074195474386), (31, 0.011607038788497448), (34, 0.011916786315850914), (20, 0.012414054130204022), (10, 0.012957266997545958), (29, 0.013191591715440154), (28, 0.014451421913690865), (25, 0.015047203749418259), (32, 0.015597441117279232), (26, 0.015913886483758688), (9, 0.01594743854366243), (33, 0.01621382776647806), (19, 0.016238084062933922), (30, 0.01653508166782558), (13, 0.017304430482909083), (23, 0.01780766947194934), (47, 0.018221579026430845), (24, 0.01826420589350164), (43, 0.018713121069595218), (22, 0.019027542090043426), (42, 0.019336250377818942), (39, 0.01957682752981782), (11, 0.01989250211045146), (46, 0.019986523082479835), (45, 0.02004792680963874), (40, 0.02029632613994181), (44, 0.020512878661975265), (41, 0.02144961175508797), (17, 0.022294857073575258), (14, 0.023160054814070463), (48, 0.023811296094208956), (38, 0.024050168925896287), (49, 0.025408401619642973), (37, 0.02885652845725417), (50, 0.030640449840575457), (51, 0.035981073044240475), (15, 0.03717772848904133), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.052134628873318434), (5, 0.05241671809926629), (7, 0.05547522287815809), (2, 0.060984639916568995), (16, 0.06157056242227554), (3, 0.062430717051029205), (6, 0.06518651638180017), (52, 0.07701416127383709), (1, 0.1571871805936098), (36, 0.3119105026125908), (18, 0.3824950382113457), (53, 0.8734227940440178)]
computing accuracy for after removing block 27 . block score: 0.011103683500550687
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011334. All blocks and scores: [(21, 0.011334074079059064), (31, 0.011815687525086105), (34, 0.011877579614520073), (20, 0.012414053897373378), (10, 0.012957266764715314), (29, 0.013689620420336723), (28, 0.014708209782838821), (25, 0.01504720444791019), (32, 0.015121230389922857), (26, 0.01591388671658933), (9, 0.015947438310831785), (33, 0.01618849183432758), (19, 0.01623808336444199), (30, 0.01633173250593245), (13, 0.017304431181401014), (47, 0.01780617772601545), (23, 0.017807669239118695), (24, 0.01826420589350164), (43, 0.018580012023448944), (22, 0.019027541857212782), (42, 0.01939117512665689), (46, 0.019606942078098655), (39, 0.01960722845979035), (45, 0.01971504185348749), (40, 0.019747436279430985), (11, 0.019892502343282104), (44, 0.020142703782767057), (41, 0.02075307280756533), (17, 0.022294857073575258), (48, 0.02287376089952886), (14, 0.023160054814070463), (38, 0.023989601526409388), (49, 0.024799507576972246), (37, 0.028698160778731108), (50, 0.030612412141636014), (51, 0.03549663396552205), (15, 0.03717772802338004), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042474001646), (4, 0.05213462933897972), (5, 0.052416715770959854), (7, 0.055475224275141954), (2, 0.06098463712260127), (16, 0.06157056288793683), (3, 0.06243071798235178), (6, 0.06518651731312275), (52, 0.07554570771753788), (1, 0.1571871805936098), (36, 0.31206290796399117), (18, 0.38249504193663597), (53, 0.880388155579567)]
computing accuracy for after removing block 21 . block score: 0.011334074079059064
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011639. All blocks and scores: [(31, 0.01163906033616513), (34, 0.01194618665613234), (20, 0.012414054130204022), (10, 0.01295726711396128), (29, 0.013874796568416059), (28, 0.014550405438058078), (25, 0.014715024968609214), (32, 0.015309393173083663), (26, 0.015426585916429758), (9, 0.01594743807800114), (30, 0.01616884022951126), (19, 0.016238084062933922), (33, 0.016239794669672847), (13, 0.017304430715739727), (23, 0.01743555604480207), (47, 0.01766685605980456), (24, 0.01811666740104556), (43, 0.018401946872472763), (42, 0.018988731084391475), (22, 0.019208092475309968), (45, 0.019360199570655823), (40, 0.019363844534382224), (39, 0.01944134454242885), (46, 0.019487919518724084), (11, 0.019892503041774035), (44, 0.020180195104330778), (41, 0.02058564033359289), (17, 0.02229485777206719), (48, 0.022515942342579365), (14, 0.02316005458123982), (38, 0.024127490585669875), (49, 0.024722861126065254), (37, 0.029028164222836494), (50, 0.03045049775391817), (51, 0.03526381449773908), (15, 0.03717772988602519), (0, 0.04586179228499532), (12, 0.047379820607602596), (8, 0.0488704233430326), (4, 0.05213463073596358), (5, 0.052416717633605), (7, 0.05547522334381938), (2, 0.06098463898524642), (16, 0.061570563819259405), (3, 0.06243071798235178), (6, 0.06518651731312275), (52, 0.07456282712519169), (1, 0.1571871843189001), (36, 0.31330903246998787), (18, 0.38249505311250687), (53, 0.8804345726966858)]
computing accuracy for after removing block 31 . block score: 0.01163906033616513
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012262. All blocks and scores: [(34, 0.012262114905752242), (20, 0.012414054479449987), (10, 0.012957266997545958), (29, 0.013874796568416059), (28, 0.014550404972396791), (25, 0.01471502531785518), (32, 0.015284727443940938), (26, 0.015426585916429758), (9, 0.015947437612339854), (33, 0.016090110410004854), (30, 0.016168839996680617), (19, 0.016238084062933922), (13, 0.017304430017247796), (47, 0.01738952216692269), (23, 0.01743555604480207), (43, 0.017958790063858032), (24, 0.018116668099537492), (42, 0.018551464658230543), (40, 0.019011593190953135), (45, 0.01909672189503908), (22, 0.019208091776818037), (46, 0.019322606967762113), (39, 0.019438674673438072), (11, 0.019892502343282104), (44, 0.020096177933737636), (41, 0.020399770699441433), (48, 0.02222239365801215), (17, 0.022294857073575258), (14, 0.023160054348409176), (38, 0.023856615414842963), (49, 0.024399894755333662), (37, 0.029221920762211084), (50, 0.030021414859220386), (51, 0.035006152000278234), (15, 0.0371777294203639), (0, 0.04586179228499532), (12, 0.04737981967628002), (8, 0.04887042520567775), (4, 0.05213462980464101), (5, 0.05241671530529857), (7, 0.055475222412496805), (2, 0.06098463758826256), (16, 0.06157056335359812), (3, 0.062430717051029205), (6, 0.06518652010709047), (52, 0.07356802467256784), (1, 0.15718717873096466), (36, 0.31360404193401337), (18, 0.38249504566192627), (53, 0.887540727853775)]
computing accuracy for after removing block 34 . block score: 0.012262114905752242
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012414. All blocks and scores: [(20, 0.012414053897373378), (10, 0.012957266764715314), (29, 0.01387479668483138), (28, 0.014550405088812113), (25, 0.014715024968609214), (32, 0.015284727094694972), (26, 0.015426586149260402), (9, 0.015947437845170498), (33, 0.016090110642835498), (30, 0.016168840462341905), (19, 0.016238084062933922), (47, 0.01711349585093558), (13, 0.017304431181401014), (23, 0.017435556277632713), (43, 0.017444000812247396), (42, 0.01795332203619182), (24, 0.018116667168214917), (40, 0.018627354875206947), (45, 0.018796849995851517), (46, 0.019162563607096672), (22, 0.019208092475309968), (39, 0.01922150026075542), (11, 0.01989250280894339), (44, 0.020024231635034084), (41, 0.020066209137439728), (48, 0.02205545175820589), (17, 0.022294858004897833), (14, 0.02316005458123982), (38, 0.023407894419506192), (49, 0.02394348639063537), (37, 0.028878843877464533), (50, 0.029550929553806782), (51, 0.034714368637651205), (15, 0.037177730817347765), (0, 0.045861792750656605), (12, 0.047379821073263884), (8, 0.04887042520567775), (4, 0.05213462933897972), (5, 0.05241671670228243), (7, 0.05547522334381938), (2, 0.06098464038223028), (16, 0.06157056288793683), (3, 0.06243071611970663), (6, 0.0651865154504776), (52, 0.07239074632525444), (1, 0.1571871805936098), (36, 0.313132181763649), (18, 0.38249505311250687), (53, 0.8949520662426949)]
computing accuracy for after removing block 20 . block score: 0.012414053897373378
removed block 20 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 4 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012877. All blocks and scores: [(10, 0.012876540888100863), (29, 0.01339388417545706), (28, 0.014257561881095171), (25, 0.014912309357896447), (32, 0.014976722071878612), (26, 0.01553854439407587), (9, 0.015991213731467724), (33, 0.016134295146912336), (30, 0.016216003568843007), (19, 0.016377095133066177), (13, 0.017258582171052694), (23, 0.01743481121957302), (47, 0.017994252732023597), (24, 0.018110815668478608), (43, 0.01856173458509147), (42, 0.018583610421046615), (39, 0.018881714204326272), (22, 0.01926614483818412), (40, 0.01967678521759808), (46, 0.01973399450071156), (11, 0.019748840481042862), (44, 0.019822962349280715), (45, 0.019935988122597337), (41, 0.020706329494714737), (17, 0.02228321204893291), (38, 0.023214410291984677), (14, 0.023244679905474186), (48, 0.02329704794101417), (49, 0.024636230897158384), (37, 0.027660386404022574), (50, 0.029762912774458528), (51, 0.03602482471615076), (15, 0.03660490084439516), (0, 0.045471502002328634), (12, 0.04720908775925636), (8, 0.04789054300636053), (5, 0.05163352098315954), (4, 0.05180487781763077), (7, 0.05453752214089036), (2, 0.060361926443874836), (16, 0.061677996069192886), (3, 0.06196508463472128), (6, 0.06468640174716711), (52, 0.07699937839061022), (1, 0.15459517017006874), (36, 0.3006051629781723), (18, 0.37777024134993553), (53, 0.8534676730632782)]
computing accuracy for after removing block 10 . block score: 0.012876540888100863
removed block 10 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013535. All blocks and scores: [(29, 0.013534608413465321), (28, 0.014180595753714442), (25, 0.014897267217747867), (32, 0.015058705816045403), (26, 0.015430573490448296), (9, 0.015991213964298368), (30, 0.01626000297255814), (33, 0.016272089211270213), (13, 0.016523741651326418), (23, 0.01720491936430335), (19, 0.017371097346767783), (47, 0.017934237606823444), (24, 0.018141593784093857), (42, 0.018488668836653233), (43, 0.018489998299628496), (39, 0.01856878586113453), (22, 0.01900297263637185), (40, 0.019364537904039025), (44, 0.01938407775014639), (46, 0.019422614946961403), (45, 0.019645992433652282), (11, 0.020159254781901836), (41, 0.020505377324298024), (48, 0.02267372887581587), (17, 0.02269948343746364), (14, 0.02289031562395394), (38, 0.02305665612220764), (49, 0.02479467890225351), (37, 0.026546462904661894), (50, 0.02921747206710279), (51, 0.03560085967183113), (15, 0.03678683005273342), (12, 0.042948242742568254), (0, 0.04547150153666735), (8, 0.04789054533466697), (5, 0.05163352144882083), (4, 0.05180487781763077), (7, 0.054537521209567785), (2, 0.06036192597821355), (16, 0.06173544703051448), (3, 0.06196508649736643), (6, 0.06468640267848969), (52, 0.07607051450759172), (1, 0.15459517017006874), (36, 0.2919144220650196), (18, 0.3696726821362972), (53, 0.8538167774677277)]
computing accuracy for after removing block 29 . block score: 0.013534608413465321
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.014181. All blocks and scores: [(28, 0.014180595986545086), (25, 0.014897266635671258), (26, 0.015430573956109583), (32, 0.015499532804824412), (33, 0.01598211214877665), (9, 0.0159912146627903), (13, 0.01652374188415706), (30, 0.017092358088120818), (23, 0.01720491936430335), (19, 0.01737109781242907), (42, 0.01763553312048316), (47, 0.01767101790755987), (24, 0.018141594249755144), (39, 0.018170335330069065), (43, 0.01827343925833702), (46, 0.01895297900773585), (22, 0.01900297310203314), (40, 0.0190305863507092), (44, 0.019035212229937315), (45, 0.01917789620347321), (11, 0.020159255247563124), (41, 0.020208584843203425), (48, 0.022198106162250042), (17, 0.02269948343746364), (38, 0.022881364217028022), (14, 0.022890316089615226), (49, 0.02428326546214521), (37, 0.026410336373373866), (50, 0.028345095459371805), (51, 0.03509383415803313), (15, 0.03678683051839471), (12, 0.04294824181124568), (0, 0.04547150293365121), (8, 0.04789054533466697), (5, 0.05163352098315954), (4, 0.05180487735196948), (7, 0.05453752214089036), (2, 0.06036192551255226), (16, 0.061735447496175766), (3, 0.06196508416905999), (6, 0.06468640267848969), (52, 0.07401398662477732), (1, 0.1545951683074236), (36, 0.2896219678223133), (18, 0.3696726858615875), (53, 0.8653325438499451)]
computing accuracy for after removing block 28 . block score: 0.014180595986545086
removed block 28 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.014897. All blocks and scores: [(25, 0.014897266868501902), (26, 0.015430573606863618), (32, 0.015515318140387535), (33, 0.015852994518354535), (9, 0.015991214429959655), (13, 0.016523741418495774), (42, 0.016953278332948685), (47, 0.017172770109027624), (23, 0.017204919597133994), (19, 0.01737109711393714), (30, 0.017544936388731003), (39, 0.01757877506315708), (43, 0.01783768692985177), (24, 0.018141594482585788), (40, 0.018364337738603354), (46, 0.018399579916149378), (44, 0.01860828814096749), (45, 0.01866841223090887), (22, 0.01900297263637185), (41, 0.0197760839946568), (11, 0.020159254781901836), (48, 0.02143487660214305), (38, 0.022341061616316438), (17, 0.022699483204632998), (14, 0.02289031632244587), (49, 0.02352688740938902), (37, 0.025705944281071424), (50, 0.027365180663764477), (51, 0.03412394504994154), (15, 0.036786830984055996), (12, 0.04294824181124568), (0, 0.04547150107100606), (8, 0.04789054626598954), (5, 0.05163352098315954), (4, 0.05180487688630819), (7, 0.054537523072212934), (2, 0.0603619241155684), (16, 0.06173544842749834), (3, 0.06196508603170514), (6, 0.06468639895319939), (52, 0.07150210998952389), (1, 0.15459517017006874), (36, 0.28651896864175797), (18, 0.3696726858615875), (53, 0.8790201917290688)]
computing accuracy for after removing block 25 . block score: 0.014897266868501902
removed block 25 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014806. All blocks and scores: [(26, 0.014806468272581697), (32, 0.015356729505583644), (33, 0.015959906857460737), (9, 0.01599121419712901), (13, 0.016523741418495774), (47, 0.016722687520086765), (42, 0.017071225913241506), (23, 0.017204919597133994), (19, 0.017371096648275852), (43, 0.017640591831877828), (30, 0.01772523229010403), (39, 0.017851792741566896), (40, 0.0178538856562227), (24, 0.018141593551263213), (46, 0.01823266362771392), (45, 0.018310300074517727), (44, 0.018529116176068783), (22, 0.019002972869202495), (41, 0.019497403176501393), (11, 0.020159255247563124), (48, 0.0209050215780735), (38, 0.022562051191926003), (17, 0.022699483670294285), (14, 0.02289031632244587), (49, 0.022946788696572185), (37, 0.02595796179957688), (50, 0.026997428620234132), (51, 0.03387788916006684), (15, 0.036786830984055996), (12, 0.04294824181124568), (0, 0.045471502002328634), (8, 0.04789054347202182), (5, 0.051633522380143404), (4, 0.051804878283292055), (7, 0.05453752027824521), (2, 0.06036192597821355), (16, 0.061735447496175766), (3, 0.06196508649736643), (6, 0.06468639988452196), (52, 0.06968072149902582), (1, 0.15459517762064934), (36, 0.2900931388139725), (18, 0.3696726970374584), (53, 0.8806807696819305)]
computing accuracy for after removing block 26 . block score: 0.014806468272581697
removed block 26 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 33, with score 0.015864. All blocks and scores: [(33, 0.01586372358724475), (32, 0.01591468055266887), (9, 0.01599121419712901), (13, 0.016523741651326418), (47, 0.016530287452042103), (23, 0.017204919597133994), (19, 0.017371097579598427), (42, 0.01774152391590178), (40, 0.01790131931193173), (43, 0.017979447729885578), (46, 0.018015956273302436), (24, 0.018141594948247075), (45, 0.01819210941903293), (44, 0.01833937270566821), (39, 0.018442548345774412), (30, 0.018518452299758792), (22, 0.01900297310203314), (41, 0.019895696081221104), (11, 0.020159255247563124), (48, 0.020680226618424058), (49, 0.022664665710180998), (17, 0.02269948273897171), (14, 0.022890315856784582), (38, 0.023344014072790742), (50, 0.026616657618433237), (37, 0.02669577393680811), (51, 0.033723775297403336), (15, 0.036786830984055996), (12, 0.04294824227690697), (0, 0.04547150153666735), (8, 0.04789054626598954), (5, 0.05163352098315954), (4, 0.05180487921461463), (7, 0.05453752167522907), (2, 0.06036192597821355), (16, 0.0617354498244822), (3, 0.06196508649736643), (6, 0.06468640174716711), (52, 0.0685559930279851), (1, 0.15459517017006874), (36, 0.2990114651620388), (18, 0.3696726970374584), (53, 0.8775942996144295)]
computing accuracy for after removing block 33 . block score: 0.01586372358724475
removed block 33 current accuracy 0.9928 loss from initial  0.007199999999999984
training start
training epoch 0 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 2 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 4 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 5 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 6 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 37 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.016538. All blocks and scores: [(9, 0.016537504037842155), (13, 0.016896054847165942), (47, 0.017600740771740675), (32, 0.01769545953720808), (19, 0.01793396403081715), (42, 0.01811060355976224), (43, 0.018156401114538312), (39, 0.018586521968245506), (30, 0.018832316622138023), (46, 0.019075103336945176), (40, 0.019138868898153305), (44, 0.019208577694371343), (11, 0.01924568717367947), (45, 0.01942580216564238), (23, 0.020495202392339706), (41, 0.020546242594718933), (24, 0.020783828338608146), (22, 0.02219719346612692), (14, 0.022522006649523973), (17, 0.022650108207017183), (48, 0.02287150453776121), (38, 0.022905128309503198), (49, 0.023804970551282167), (37, 0.02725606644526124), (50, 0.02949969074688852), (51, 0.03501690784469247), (15, 0.03595701837912202), (0, 0.04499726416543126), (12, 0.045600940473377705), (8, 0.04712161235511303), (5, 0.050336935091763735), (4, 0.050620822701603174), (7, 0.05326680978760123), (16, 0.0549826486967504), (3, 0.06005708081647754), (2, 0.060566483065485954), (6, 0.06378784030675888), (52, 0.07772376108914614), (1, 0.15118526853621006), (36, 0.2969341427087784), (18, 0.35672661662101746), (53, 0.8725972548127174)]
computing accuracy for after removing block 9 . block score: 0.016537504037842155
removed block 9 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.016821. All blocks and scores: [(32, 0.01682058908045292), (47, 0.01712990552186966), (42, 0.017879497027024627), (43, 0.01794537389650941), (30, 0.018196279415860772), (19, 0.018366285134106874), (46, 0.01838836004026234), (44, 0.01844403683207929), (13, 0.018575235502794385), (40, 0.01862172898836434), (39, 0.018702078377828002), (45, 0.018762729596346617), (41, 0.019472203450277448), (23, 0.01983684254810214), (11, 0.020134096033871174), (24, 0.020220051985234022), (48, 0.0217942469753325), (22, 0.02228890568949282), (14, 0.022346245823428035), (38, 0.023197894683107734), (17, 0.023407401982694864), (49, 0.02345981332473457), (37, 0.025288358330726624), (50, 0.028327247826382518), (51, 0.03412285167723894), (15, 0.03653350938111544), (12, 0.04393900744616985), (0, 0.04499726230278611), (8, 0.04712161049246788), (5, 0.05033693416044116), (4, 0.0506208217702806), (7, 0.05326681025326252), (16, 0.05760290753096342), (3, 0.06005707988515496), (2, 0.060566483065485954), (6, 0.06378783844411373), (52, 0.07652134168893099), (1, 0.1511852703988552), (36, 0.2841540016233921), (18, 0.34768710657954216), (53, 0.8664738684892654)]
computing accuracy for after removing block 32 . block score: 0.01682058908045292
removed block 32 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 47, with score 0.016608. All blocks and scores: [(47, 0.016607558820396662), (42, 0.01712119416333735), (43, 0.017133761662989855), (40, 0.01761090662330389), (44, 0.017764869146049023), (46, 0.017816979438066483), (45, 0.018060331232845783), (39, 0.01806988543830812), (30, 0.01819627918303013), (19, 0.018366285134106874), (41, 0.018501919927075505), (13, 0.018575235502794385), (23, 0.019836842780932784), (11, 0.020134096033871174), (24, 0.020220051519572735), (48, 0.020671033300459385), (38, 0.022271885769441724), (22, 0.02228890615515411), (14, 0.022346246521919966), (49, 0.02272208407521248), (17, 0.023407401982694864), (37, 0.023933295626193285), (50, 0.027275023516267538), (51, 0.03273033956065774), (15, 0.03653350844979286), (12, 0.04393900791183114), (0, 0.0449972627684474), (8, 0.04712161235511303), (5, 0.05033693229779601), (4, 0.0506208217702806), (7, 0.05326680792495608), (16, 0.057602906599640846), (3, 0.06005708174780011), (2, 0.060566483065485954), (6, 0.0637878393754363), (52, 0.07272726763039827), (1, 0.1511852666735649), (36, 0.2802668400108814), (18, 0.34768711030483246), (53, 0.8962849751114845)]
computing accuracy for after removing block 47 . block score: 0.016607558820396662
removed block 47 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.017121. All blocks and scores: [(42, 0.01712119416333735), (43, 0.0171337618958205), (40, 0.01761090662330389), (44, 0.017764869146049023), (46, 0.017816980136558414), (45, 0.018060331465676427), (39, 0.018069884972646832), (30, 0.01819627918303013), (19, 0.018366285366937518), (41, 0.01850191899575293), (13, 0.018575235968455672), (23, 0.019836843013763428), (11, 0.020134095335379243), (24, 0.02022005175240338), (38, 0.022271885070949793), (22, 0.022288906387984753), (14, 0.022346246987581253), (48, 0.022816740442067385), (17, 0.023407401517033577), (37, 0.023933295626193285), (49, 0.02430704445578158), (50, 0.02825055457651615), (51, 0.03393286885693669), (15, 0.03653350891545415), (12, 0.04393900837749243), (0, 0.044997261837124825), (8, 0.04712161049246788), (5, 0.05033693462610245), (4, 0.05062082316726446), (7, 0.05326681071892381), (16, 0.0576029047369957), (3, 0.06005708174780011), (2, 0.06056648213416338), (6, 0.06378783751279116), (52, 0.07340419292449951), (1, 0.1511852703988552), (36, 0.2802668511867523), (18, 0.34768711030483246), (53, 0.9400831013917923)]
computing accuracy for after removing block 42 . block score: 0.01712119416333735
removed block 42 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.017611. All blocks and scores: [(40, 0.017610906390473247), (39, 0.018069885205477476), (30, 0.01819627918303013), (19, 0.01836628490127623), (46, 0.018419946776703), (41, 0.018501919461414218), (13, 0.01857523573562503), (44, 0.01858751871623099), (43, 0.01900695078074932), (45, 0.01917907828465104), (23, 0.019836843013763428), (11, 0.02013409580104053), (24, 0.020220051985234022), (38, 0.02227188553661108), (22, 0.02228890568949282), (14, 0.02234624605625868), (17, 0.023407401517033577), (37, 0.023933296324685216), (48, 0.024211133364588022), (49, 0.025452560046687722), (50, 0.02895790757611394), (51, 0.03456222219392657), (15, 0.03653350844979286), (12, 0.043939006980508566), (0, 0.04499726230278611), (8, 0.04712161282077432), (5, 0.05033693462610245), (4, 0.050620820838958025), (7, 0.05326681025326252), (16, 0.057602905202656984), (3, 0.060057081282138824), (2, 0.06056648213416338), (6, 0.0637878393754363), (52, 0.07288133352994919), (1, 0.1511852703988552), (36, 0.2802668362855911), (18, 0.34768711775541306), (53, 0.9892624691128731)]
computing accuracy for after removing block 40 . block score: 0.017610906390473247
removed block 40 current accuracy 0.9896 loss from initial  0.010399999999999965
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.018070. All blocks and scores: [(39, 0.018069885671138763), (46, 0.018118337728083134), (30, 0.018196278950199485), (44, 0.01836377684958279), (19, 0.018366285134106874), (13, 0.018575235502794385), (45, 0.01884748274460435), (43, 0.018922279123216867), (41, 0.01914427545852959), (23, 0.01983684254810214), (11, 0.020134095568209887), (24, 0.02022005128674209), (38, 0.02227188483811915), (22, 0.022288906620815396), (14, 0.022346246289089322), (17, 0.023407400818541646), (48, 0.023468185449019074), (37, 0.023933295160531998), (49, 0.024544455809518695), (50, 0.027663711458444595), (51, 0.03286202671006322), (15, 0.03653351031243801), (12, 0.043939006980508566), (0, 0.0449972627684474), (8, 0.04712161049246788), (5, 0.05033693229779601), (4, 0.05062082130461931), (7, 0.05326681025326252), (16, 0.057602907065302134), (3, 0.0600570822134614), (2, 0.06056648259982467), (6, 0.06378783751279116), (52, 0.06839203648269176), (1, 0.1511852666735649), (36, 0.2802668437361717), (18, 0.34768711030483246), (53, 1.0218724831938744)]
computing accuracy for after removing block 39 . block score: 0.018069885671138763
removed block 39 current accuracy 0.986 loss from initial  0.014000000000000012
training start
training epoch 0 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 1 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 2 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 3 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 4 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 5 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 6 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 7 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 8 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 9 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 10 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 11 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 12 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 13 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 14 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 15 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 16 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 17 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 18 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 19 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 22 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 23 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 24 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 27 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 29 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 34 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 35 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 36 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 37 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 38 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 42 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 43 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 44 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 46 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 49 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.999000)
finished training. finished 50 epochs. accuracy 0.999 topk_dict {'top1': 0.999}
start iteration 18
[activation diff]: block to remove picked: 13, with score 0.017963. All blocks and scores: [(13, 0.01796337799169123), (19, 0.019320574356243014), (11, 0.020274988608434796), (46, 0.021152941044420004), (45, 0.02132670604623854), (43, 0.021343415835872293), (44, 0.021439929958432913), (30, 0.022523973369970918), (14, 0.02264643064700067), (41, 0.02309603081084788), (23, 0.02310718991793692), (17, 0.023223512107506394), (22, 0.023386588785797358), (24, 0.023475988069549203), (38, 0.024724819464609027), (48, 0.02546805515885353), (49, 0.026077114045619965), (37, 0.028842815896496177), (50, 0.030226171482354403), (15, 0.03551605250686407), (51, 0.036015956196933985), (0, 0.04293860122561455), (12, 0.043991360347718), (8, 0.04700137162581086), (4, 0.04904750594869256), (5, 0.0492315785959363), (7, 0.052917645778506994), (16, 0.05586750525981188), (2, 0.057865115348249674), (3, 0.05846315575763583), (6, 0.06367548182606697), (52, 0.07923596818000078), (1, 0.14443710446357727), (36, 0.2808225564658642), (18, 0.3400460295379162), (53, 0.8601891174912453)]
computing accuracy for after removing block 13 . block score: 0.01796337799169123
removed block 13 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 19, with score 0.019296. All blocks and scores: [(19, 0.019296211656183004), (11, 0.020274988375604153), (46, 0.020673786057159305), (45, 0.02096454962156713), (44, 0.02111042314209044), (43, 0.021303885150700808), (30, 0.021829022793099284), (23, 0.02223745407536626), (41, 0.022683164570480585), (24, 0.022798975696787238), (22, 0.023097294848412275), (14, 0.023521992843598127), (17, 0.023640015395358205), (48, 0.025243773590773344), (38, 0.025282462825998664), (49, 0.025952643249183893), (37, 0.027986552333459258), (50, 0.029511536937206984), (51, 0.035960603505373), (15, 0.03739848220720887), (0, 0.0429386030882597), (12, 0.04399135988205671), (8, 0.04700137162581086), (4, 0.04904750641435385), (5, 0.04923157952725887), (7, 0.052917647641152143), (2, 0.057865115348249674), (3, 0.05846315482631326), (16, 0.06219911854714155), (6, 0.06367547996342182), (52, 0.0796996196731925), (1, 0.14443710446357727), (36, 0.27621445432305336), (18, 0.34058883786201477), (53, 0.850888229906559)]
computing accuracy for after removing block 19 . block score: 0.019296211656183004
removed block 19 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 11, with score 0.020275. All blocks and scores: [(11, 0.02027498884126544), (46, 0.02032497012987733), (44, 0.020736409351229668), (45, 0.02079827687703073), (43, 0.02090327814221382), (30, 0.021394234150648117), (23, 0.022435310296714306), (41, 0.023015744052827358), (14, 0.023521993309259415), (22, 0.02359230606816709), (17, 0.023640015395358205), (24, 0.02366930292919278), (48, 0.024514911929145455), (38, 0.02539714891463518), (49, 0.025816054549068213), (37, 0.028294252697378397), (50, 0.028746375115588307), (51, 0.03413110692054033), (15, 0.03739848267287016), (0, 0.04293860122561455), (12, 0.043991359416395426), (8, 0.047001372557133436), (4, 0.04904750548303127), (5, 0.04923157952725887), (7, 0.05291764670982957), (2, 0.05786511395126581), (3, 0.05846315575763583), (16, 0.06219912087544799), (6, 0.06367548275738955), (52, 0.07656990084797144), (1, 0.14443710260093212), (36, 0.2765071876347065), (18, 0.3405888266861439), (53, 0.8590469509363174)]
computing accuracy for after removing block 11 . block score: 0.02027498884126544
removed block 11 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.020109. All blocks and scores: [(30, 0.020109188742935658), (44, 0.02020895597524941), (46, 0.02032646955922246), (45, 0.020729817682877183), (43, 0.02132667670957744), (23, 0.02167727565392852), (41, 0.023118417244404554), (24, 0.023292016005143523), (17, 0.02342014294117689), (22, 0.023596403189003468), (48, 0.02442736830562353), (49, 0.02611348545178771), (14, 0.026188648538663983), (38, 0.02692081406712532), (37, 0.0278334051836282), (50, 0.028086363803595304), (51, 0.033717957790941), (15, 0.03948623035103083), (0, 0.04293860075995326), (8, 0.04700137162581086), (12, 0.047725196462124586), (4, 0.04904750548303127), (5, 0.049231579061597586), (7, 0.052917647175490856), (2, 0.05786511395126581), (3, 0.05846315575763583), (6, 0.06367548275738955), (16, 0.06397335603833199), (52, 0.07558722328394651), (1, 0.14443710818886757), (36, 0.27577152475714684), (18, 0.34106987342238426), (53, 0.8491050004959106)]
computing accuracy for after removing block 30 . block score: 0.020109188742935658
removed block 30 current accuracy 0.9886 loss from initial  0.011399999999999966
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.019709. All blocks and scores: [(44, 0.019709142623469234), (46, 0.01987393805757165), (45, 0.020440119318664074), (43, 0.02112569147720933), (23, 0.021677274955436587), (41, 0.02281105797737837), (24, 0.02329201577231288), (17, 0.02342014340683818), (22, 0.02359640272334218), (48, 0.02364791906438768), (49, 0.02517016278579831), (14, 0.02618864900432527), (38, 0.027133974246680737), (50, 0.02733222092501819), (37, 0.027893905993551016), (51, 0.03297399915754795), (15, 0.03948623035103083), (0, 0.042938601691275835), (8, 0.04700137162581086), (12, 0.0477251959964633), (4, 0.04904750548303127), (5, 0.049231577664613724), (7, 0.052917645778506994), (2, 0.05786511488258839), (3, 0.058463153429329395), (6, 0.0636754846200347), (16, 0.06397335417568684), (52, 0.0719606364145875), (1, 0.14443710073828697), (36, 0.282384492456913), (18, 0.34106988087296486), (53, 0.866398386657238)]
computing accuracy for after removing block 44 . block score: 0.019709142623469234
removed block 44 current accuracy 0.9782 loss from initial  0.02180000000000004
since last training loss: 0.02080000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 46, with score 0.020753. All blocks and scores: [(46, 0.020753282587975264), (43, 0.021125691942870617), (23, 0.021677274955436587), (45, 0.022084150463342667), (41, 0.02281105797737837), (24, 0.02329201577231288), (17, 0.023420143174007535), (22, 0.023596403189003468), (48, 0.025271375430747867), (14, 0.026188648771494627), (49, 0.02650210913270712), (38, 0.027133974712342024), (50, 0.027374063152819872), (37, 0.027893906459212303), (51, 0.03217861126177013), (15, 0.039486230816692114), (0, 0.042938601691275835), (8, 0.047001371160149574), (12, 0.04772519739344716), (4, 0.04904750641435385), (5, 0.049231579061597586), (7, 0.05291764810681343), (2, 0.05786511395126581), (3, 0.058463155291974545), (6, 0.06367548275738955), (16, 0.06397335510700941), (52, 0.06961552891880274), (1, 0.14443710632622242), (36, 0.282384492456913), (18, 0.34106986969709396), (53, 0.955780915915966)]
computing accuracy for after removing block 46 . block score: 0.020753282587975264
removed block 46 current accuracy 0.9656 loss from initial  0.034399999999999986
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 43, with score 0.021126. All blocks and scores: [(43, 0.021125691710039973), (23, 0.021677275421097875), (45, 0.022084149764850736), (41, 0.02281105751171708), (24, 0.023292016237974167), (17, 0.023420142009854317), (22, 0.02359640272334218), (14, 0.026188647840172052), (48, 0.02681966032832861), (38, 0.027133974712342024), (37, 0.027893905993551016), (49, 0.027938892133533955), (50, 0.02892551152035594), (51, 0.03197889169678092), (15, 0.03948622988536954), (0, 0.042938601691275835), (8, 0.047001370228827), (12, 0.047725196462124586), (4, 0.04904750548303127), (5, 0.0492315785959363), (7, 0.05291764670982957), (2, 0.0578651144169271), (3, 0.05846315482631326), (6, 0.06367548368871212), (16, 0.06397335696965456), (52, 0.06795982550829649), (1, 0.14443710446357727), (36, 0.2823844961822033), (18, 0.34106988087296486), (53, 1.0592146515846252)]
computing accuracy for after removing block 43 . block score: 0.021125691710039973
removed block 43 current accuracy 0.9462 loss from initial  0.05379999999999996
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 23, with score 0.021677. All blocks and scores: [(23, 0.021677274955436587), (41, 0.022811057744547725), (24, 0.02329201577231288), (17, 0.02342014294117689), (22, 0.023596403189003468), (45, 0.024492135271430016), (14, 0.02618864760734141), (38, 0.027133974712342024), (37, 0.027893905993551016), (49, 0.028820340521633625), (48, 0.029331624740734696), (50, 0.03015552880242467), (51, 0.03253641724586487), (15, 0.03948623035103083), (0, 0.04293860122561455), (8, 0.04700137162581086), (12, 0.04772519879043102), (4, 0.0490475045517087), (5, 0.0492315785959363), (7, 0.05291764810681343), (2, 0.0578651144169271), (3, 0.05846315436065197), (6, 0.0636754808947444), (16, 0.06397335324436426), (52, 0.06707618292421103), (1, 0.14443710446357727), (36, 0.282384492456913), (18, 0.34106988832354546), (53, 1.1642038971185684)]
computing accuracy for after removing block 23 . block score: 0.021677274955436587
removed block 23 current accuracy 0.912 loss from initial  0.08799999999999997
since last training loss: 0.08699999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.022639. All blocks and scores: [(24, 0.02263890323229134), (41, 0.02327107056044042), (17, 0.023420142708346248), (45, 0.023429725086316466), (22, 0.023596402257680893), (14, 0.02618864900432527), (49, 0.027828859398141503), (37, 0.028395883040502667), (38, 0.02888063807040453), (48, 0.02903009857982397), (50, 0.029196186689659953), (51, 0.032421392388641834), (15, 0.03948622941970825), (0, 0.04293860075995326), (8, 0.047001370228827), (12, 0.047725196462124586), (4, 0.049047505017369986), (5, 0.04923157952725887), (7, 0.052917647641152143), (2, 0.0578651144169271), (3, 0.058463157154619694), (6, 0.0636754808947444), (16, 0.06397335696965456), (52, 0.0646195188164711), (1, 0.14443710632622242), (36, 0.28686321526765823), (18, 0.34106987342238426), (53, 1.181691363453865)]
computing accuracy for after removing block 24 . block score: 0.02263890323229134
removed block 24 current accuracy 0.8716 loss from initial  0.12839999999999996
training start
training epoch 0 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 1 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best True lr [0.001]
training epoch 2 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 3 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 4 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 5 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 6 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 7 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 8 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 9 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 10 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 11 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 12 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 13 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 14 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 15 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 16 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 17 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 18 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 19 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 20 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 21 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 22 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 23 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 24 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 25 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 26 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 27 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 28 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 29 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 30 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 31 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 32 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 33 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 34 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 35 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 36 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 37 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 38 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 39 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 40 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 41 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 42 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 43 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 44 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 45 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 46 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 47 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 48 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 49 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.992800)
finished training. finished 50 epochs. accuracy 0.9928 topk_dict {'top1': 0.9928}
