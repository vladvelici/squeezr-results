start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996380798519), (32, 0.009233050630427897), (30, 0.010039401124231517), (31, 0.010361599968746305), (34, 0.013312275987118483), (29, 0.013541154563426971), (35, 0.01601846283301711), (26, 0.016037591500207782), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020232456969097257), (46, 0.021044540219008923), (25, 0.02197260269895196), (23, 0.022379535250365734), (41, 0.022826648084446788), (44, 0.023395078722387552), (40, 0.024025025311857462), (45, 0.02429541014134884), (21, 0.024924598401412368), (22, 0.025168768595904112), (48, 0.025341258849948645), (24, 0.025899537140503526), (50, 0.026409972459077835), (42, 0.026674100663512945), (20, 0.02685900591313839), (49, 0.02703716466203332), (47, 0.029306468553841114), (39, 0.03157071233727038), (38, 0.03163787163794041), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.032628594897687435), (37, 0.03796026110649109), (51, 0.041734172496944666), (9, 0.04340187972411513), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.05924912868067622), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734238862991), (52, 0.06862937286496162), (8, 0.07467832136899233), (10, 0.0803448436781764), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.43758001178503036), (18, 0.5108213052153587), (53, 0.8211488947272301)]
computing accuracy for after removing block 33 . block score: 0.007061996380798519
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039400542154908), (31, 0.010361600201576948), (34, 0.013133947853930295), (29, 0.013541154563426971), (26, 0.016037589637562633), (35, 0.016169289592653513), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.020072476705536246), (46, 0.020731385331600904), (25, 0.021972602466121316), (41, 0.022347092861309648), (23, 0.02237953501753509), (44, 0.02323568775318563), (40, 0.0238410672172904), (45, 0.023965542437508702), (48, 0.024917916394770145), (21, 0.024924598401412368), (22, 0.025168768130242825), (50, 0.02584081282839179), (24, 0.025899537140503526), (42, 0.026315323309972882), (49, 0.026655674912035465), (20, 0.02685900777578354), (47, 0.028728797333315015), (39, 0.031317642191424966), (38, 0.03138036443851888), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.038025843910872936), (51, 0.04122393950819969), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663572743535), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.06095684738829732), (0, 0.06300980970263481), (1, 0.06676734145730734), (52, 0.06745154969394207), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.090420494787395), (5, 0.10667387396097183), (36, 0.43538710102438927), (18, 0.5108213126659393), (53, 0.8222574070096016)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.012765232939273119), (29, 0.013541154330596328), (35, 0.01599275111220777), (26, 0.016037590336054564), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.020075131440535188), (46, 0.020841406425461173), (25, 0.02197260269895196), (41, 0.022319767391309142), (23, 0.022379535250365734), (44, 0.02315405011177063), (40, 0.02388568385504186), (45, 0.024071688763797283), (48, 0.024877466028556228), (21, 0.024924597702920437), (22, 0.025168768828734756), (50, 0.025691178161650896), (24, 0.025899535743519664), (42, 0.026123748160898685), (49, 0.026479421881958842), (20, 0.026859007077291608), (47, 0.028693133033812046), (38, 0.031236795941367745), (39, 0.03129529138095677), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03837669035419822), (51, 0.04111403366550803), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368689954281), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.0572242820635438), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300980783998966), (1, 0.06676734145730734), (52, 0.06700456328690052), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.43640001490712166), (18, 0.5108212977647781), (53, 0.8289349004626274)]
computing accuracy for after removing block 30 . block score: 0.010039400425739586
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372250564396), (34, 0.012387837283313274), (29, 0.013541154563426971), (35, 0.01600809535011649), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020083633484318852), (46, 0.02070444473065436), (25, 0.02197260269895196), (41, 0.022253196919336915), (23, 0.022379535250365734), (44, 0.023267761105671525), (40, 0.02401388017460704), (45, 0.0240929932333529), (48, 0.02466528001241386), (21, 0.024924597702920437), (22, 0.025168768130242825), (50, 0.025459735188633204), (42, 0.02565571293234825), (24, 0.025899537606164813), (49, 0.026287756394594908), (20, 0.026859006844460964), (47, 0.028363423654809594), (38, 0.031047646887600422), (39, 0.03138077235780656), (15, 0.031923392321914434), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03897124528884888), (51, 0.040756202302873135), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.054548466578125954), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.0630098101682961), (52, 0.06586316414177418), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4389924481511116), (18, 0.5108213052153587), (53, 0.8391561508178711)]
computing accuracy for after removing block 31 . block score: 0.010375372250564396
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154912672937), (26, 0.016037590568885207), (35, 0.01605736301280558), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.020049349404871464), (46, 0.020552987698465586), (25, 0.02197260269895196), (41, 0.022067483980208635), (23, 0.02237953571602702), (44, 0.022979132365435362), (40, 0.023858346976339817), (45, 0.02412470243871212), (48, 0.024386122822761536), (21, 0.02492459793575108), (50, 0.025042241904884577), (22, 0.025168767664581537), (42, 0.025414507603272796), (49, 0.025842698523774743), (24, 0.025899536907672882), (20, 0.02685900731012225), (47, 0.028050733730196953), (38, 0.031040058936923742), (39, 0.03150080284103751), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.039112848695367575), (51, 0.04024627339094877), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846331849694), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980923697352), (52, 0.06486208876594901), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.1066738748922944), (36, 0.4381278418004513), (18, 0.5108213052153587), (53, 0.8458427935838699)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154563426971), (26, 0.016037590336054564), (35, 0.01665342040359974), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02050345577299595), (46, 0.020725322421640158), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.02245262893848121), (44, 0.023364473832771182), (48, 0.024290355388075113), (45, 0.024438712745904922), (40, 0.024470558390021324), (21, 0.02492459863424301), (50, 0.02504217275418341), (22, 0.025168768595904112), (49, 0.02587596932426095), (24, 0.02589953667484224), (42, 0.026205406989902258), (20, 0.026859007542952895), (47, 0.02817858220078051), (15, 0.03192339185625315), (38, 0.03208350157365203), (7, 0.03228544723242521), (39, 0.03233744157478213), (19, 0.0326285962946713), (51, 0.039947260171175), (37, 0.04073968296870589), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846704378724), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980923697352), (52, 0.06433630362153053), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387023568153), (36, 0.45053430274128914), (18, 0.5108213126659393), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.013541154563426971
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016443. All blocks and scores: [(26, 0.01644275081343949), (35, 0.016665604896843433), (28, 0.018035550136119127), (27, 0.01931414008140564), (43, 0.020486475666984916), (46, 0.021052596624940634), (25, 0.02238649339415133), (41, 0.022885665763169527), (23, 0.02291146758943796), (44, 0.02373718796297908), (45, 0.024171016877517104), (40, 0.024281554156914353), (21, 0.025362780783325434), (22, 0.0255294032394886), (48, 0.025745480321347713), (50, 0.02625823230482638), (24, 0.026486516231670976), (42, 0.026751115452498198), (49, 0.027003918774425983), (20, 0.027383878361433744), (47, 0.029084559762850404), (39, 0.03107926552183926), (38, 0.031566346529871225), (15, 0.032227122224867344), (7, 0.03242708649486303), (19, 0.03258753754198551), (37, 0.0373440170660615), (51, 0.04158002184703946), (9, 0.0440366449765861), (6, 0.046446751803159714), (4, 0.04689406510442495), (14, 0.0479711489751935), (2, 0.055369720328599215), (3, 0.05860950890928507), (11, 0.05891253426671028), (13, 0.059233929961919785), (17, 0.06244776537641883), (0, 0.06463385932147503), (1, 0.0683202687650919), (52, 0.06905743759125471), (8, 0.07463116478174925), (10, 0.08063695393502712), (16, 0.08495946321636438), (12, 0.09008821658790112), (5, 0.10690754745155573), (36, 0.4299122281372547), (18, 0.5140404030680656), (53, 0.7747419103980064)]
computing accuracy for after removing block 26 . block score: 0.01644275081343949
removed block 26 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015735. All blocks and scores: [(35, 0.015735010616481304), (28, 0.017381599405780435), (27, 0.019055602373555303), (43, 0.01987273059785366), (46, 0.020654145861044526), (41, 0.02191549213603139), (25, 0.022386492928490043), (23, 0.02291146758943796), (44, 0.023506583413109183), (40, 0.023589285789057612), (45, 0.02381825423799455), (42, 0.024991832673549652), (48, 0.025011647026985884), (21, 0.02536278124898672), (22, 0.02552940370514989), (50, 0.02560507459565997), (24, 0.026486516697332263), (49, 0.0266027741599828), (20, 0.027383878827095032), (47, 0.028533700853586197), (39, 0.03037192183546722), (38, 0.030572854913771152), (15, 0.03222712269052863), (7, 0.032427086029201746), (19, 0.03258753754198551), (37, 0.036337155383080244), (51, 0.04036756604909897), (9, 0.0440366449765861), (6, 0.04644675087183714), (4, 0.04689406277611852), (14, 0.04797114944085479), (2, 0.055369720328599215), (3, 0.05860950984060764), (11, 0.05891253473237157), (13, 0.05923393089324236), (17, 0.062447766307741404), (0, 0.0646338565275073), (52, 0.06694713700562716), (1, 0.06832026597112417), (8, 0.07463116850703955), (10, 0.08063695300370455), (16, 0.08495945949107409), (12, 0.09008821751922369), (5, 0.10690755024552345), (36, 0.41940589621663094), (18, 0.514040395617485), (53, 0.7977385595440865)]
computing accuracy for after removing block 35 . block score: 0.015735010616481304
removed block 35 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017382. All blocks and scores: [(28, 0.017381599405780435), (43, 0.01863941876217723), (27, 0.019055602606385946), (46, 0.019581858534365892), (41, 0.020049661863595247), (40, 0.022264765575528145), (25, 0.022386493161320686), (44, 0.02267419407144189), (45, 0.022798080928623676), (23, 0.022911467822268605), (42, 0.022954994812607765), (48, 0.02304366254247725), (50, 0.023806438082829118), (49, 0.025158038595691323), (21, 0.025362780783325434), (22, 0.0255294032394886), (24, 0.026486517395824194), (20, 0.027383878361433744), (47, 0.027409501373767853), (39, 0.02849958441220224), (38, 0.029042845126241446), (15, 0.03222712269052863), (7, 0.03242708556354046), (19, 0.0325875380076468), (37, 0.03381183557212353), (51, 0.03834233246743679), (9, 0.04403664404526353), (6, 0.04644675040617585), (4, 0.046894063241779804), (14, 0.04797114850953221), (2, 0.05536971939727664), (3, 0.05860950751230121), (11, 0.05891253286972642), (13, 0.059233931358903646), (52, 0.06195319211110473), (17, 0.06244776397943497), (0, 0.06463385745882988), (1, 0.0683202687650919), (8, 0.07463116571307182), (10, 0.08063695672899485), (16, 0.08495946042239666), (12, 0.09008821751922369), (5, 0.10690754931420088), (36, 0.40078115835785866), (18, 0.5140404030680656), (53, 0.8377077877521515)]
computing accuracy for after removing block 28 . block score: 0.017381599405780435
removed block 28 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018157. All blocks and scores: [(43, 0.01815667888149619), (46, 0.01897618407383561), (27, 0.01905560283921659), (41, 0.019396824995055795), (40, 0.021872738609090447), (42, 0.02200678433291614), (45, 0.022337788715958595), (48, 0.022385296411812305), (25, 0.022386492928490043), (44, 0.022472410229966044), (23, 0.022911467822268605), (50, 0.023337241960689425), (49, 0.024491984397172928), (21, 0.02536278124898672), (22, 0.0255294032394886), (24, 0.026486517395824194), (47, 0.02658570627681911), (20, 0.02738387929275632), (39, 0.02798389201052487), (38, 0.028205667156726122), (15, 0.03222712408751249), (7, 0.032427086029201746), (19, 0.0325875380076468), (37, 0.03317839000374079), (51, 0.03769660647958517), (9, 0.04403664590790868), (6, 0.04644675040617585), (4, 0.046894063241779804), (14, 0.04797114850953221), (2, 0.05536971893161535), (3, 0.05860950984060764), (11, 0.05891253473237157), (13, 0.059233929961919785), (52, 0.06044730171561241), (17, 0.062447764445096254), (0, 0.0646338565275073), (1, 0.06832026783376932), (8, 0.0746311666443944), (10, 0.08063695672899485), (16, 0.08495946228504181), (12, 0.09008821938186884), (5, 0.10690755303949118), (36, 0.3950059302151203), (18, 0.514040395617485), (53, 0.8518322110176086)]
computing accuracy for after removing block 43 . block score: 0.01815667888149619
removed block 43 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 27, with score 0.019056. All blocks and scores: [(27, 0.019055602373555303), (41, 0.01939682476222515), (46, 0.019566549453884363), (40, 0.021872738376259804), (42, 0.022006783867254853), (25, 0.022386493626981974), (23, 0.02291146758943796), (48, 0.023002367932349443), (50, 0.023279032204300165), (45, 0.023351701674982905), (44, 0.023842120775952935), (49, 0.024256561417132616), (21, 0.02536278171464801), (22, 0.025529403472319245), (24, 0.026486516697332263), (47, 0.02731868182308972), (20, 0.027383879059925675), (39, 0.02798389154486358), (38, 0.028205668088048697), (15, 0.032227123621851206), (7, 0.03242708556354046), (19, 0.03258753754198551), (37, 0.033178388606756926), (51, 0.037183315958827734), (9, 0.04403664544224739), (6, 0.046446749940514565), (4, 0.046894064638763666), (14, 0.0479711489751935), (2, 0.05536971939727664), (3, 0.058609511237591505), (11, 0.05891253333538771), (52, 0.058988597709685564), (13, 0.05923393042758107), (17, 0.06244776491075754), (0, 0.06463385745882988), (1, 0.0683202650398016), (8, 0.07463116757571697), (10, 0.0806369548663497), (16, 0.08495946135371923), (12, 0.09008821938186884), (5, 0.10690754931420088), (36, 0.3950059302151203), (18, 0.5140403881669044), (53, 0.8923601508140564)]
computing accuracy for after removing block 27 . block score: 0.019055602373555303
removed block 27 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.018580. All blocks and scores: [(41, 0.018580375239253044), (46, 0.0189671260304749), (40, 0.021066411631181836), (42, 0.02119017136283219), (48, 0.02214357745833695), (25, 0.022386493626981974), (50, 0.022568002343177795), (23, 0.022911468520760536), (45, 0.022920814575627446), (44, 0.02303551509976387), (49, 0.023506951285526156), (21, 0.025362780783325434), (22, 0.025529404170811176), (47, 0.02623305330052972), (24, 0.026486516697332263), (38, 0.027191187720745802), (39, 0.02726308978162706), (20, 0.027383878594264388), (15, 0.03222712315618992), (37, 0.03239250695332885), (7, 0.032427084632217884), (19, 0.0325875380076468), (51, 0.036015940364450216), (9, 0.0440366449765861), (6, 0.046446749940514565), (4, 0.04689406370744109), (14, 0.047971148043870926), (2, 0.055369720328599215), (52, 0.05678779864683747), (3, 0.05860950844362378), (11, 0.05891253240406513), (13, 0.05923392856493592), (17, 0.06244776537641883), (0, 0.0646338565275073), (1, 0.06832026690244675), (8, 0.07463116757571697), (10, 0.08063695766031742), (16, 0.08495946321636438), (12, 0.09008821751922369), (5, 0.10690755117684603), (36, 0.3854435496032238), (18, 0.5140403881669044), (53, 0.9063040316104889)]
computing accuracy for after removing block 41 . block score: 0.018580375239253044
removed block 41 current accuracy 0.9956 loss from initial  0.0043999999999999595
training start
training epoch 0 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 1 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 2 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 4 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 7 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 8 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 14 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 27 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.021892. All blocks and scores: [(46, 0.021892443299293518), (40, 0.02386525273323059), (45, 0.025072234217077494), (25, 0.025322209112346172), (44, 0.025469516403973103), (23, 0.02580892387777567), (50, 0.025882310699671507), (48, 0.025894887978211045), (49, 0.026269153924658895), (42, 0.027212497545406222), (21, 0.02799703273922205), (22, 0.02843338274396956), (20, 0.028930592350661755), (47, 0.029564720578491688), (24, 0.030724017415195704), (38, 0.03095443989150226), (7, 0.031131392577663064), (39, 0.03127958299592137), (15, 0.03275705594569445), (19, 0.0340447211638093), (37, 0.036401282995939255), (51, 0.04092634795233607), (9, 0.04402469610795379), (6, 0.04602348757907748), (14, 0.04799260338768363), (4, 0.04801114555448294), (2, 0.05449868040159345), (3, 0.05738807609304786), (11, 0.05773630365729332), (13, 0.05792612163349986), (0, 0.06153711350634694), (17, 0.06180841103196144), (1, 0.06561268772929907), (52, 0.06968662142753601), (8, 0.07351419422775507), (10, 0.07855832483619452), (16, 0.08326655067503452), (12, 0.08871253579854965), (5, 0.10381246451288462), (36, 0.41657766699790955), (18, 0.491395503282547), (53, 0.8229808136820793)]
computing accuracy for after removing block 46 . block score: 0.021892443299293518
removed block 46 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.023865. All blocks and scores: [(40, 0.02386525273323059), (45, 0.025072234915569425), (25, 0.025322210043668747), (44, 0.025469517102465034), (23, 0.025808923412114382), (50, 0.025993040530011058), (48, 0.026362051256000996), (49, 0.02681215130724013), (42, 0.027212497778236866), (21, 0.027997033670544624), (22, 0.02843338157981634), (20, 0.02893059211783111), (24, 0.030724016949534416), (38, 0.03095444035716355), (7, 0.031131391413509846), (39, 0.031279583694413304), (47, 0.03170988825149834), (15, 0.03275705501437187), (19, 0.03404472162947059), (37, 0.036401282995939255), (51, 0.040702007710933685), (9, 0.04402469517663121), (6, 0.04602348804473877), (14, 0.04799260292202234), (4, 0.048011146020144224), (2, 0.05449868040159345), (3, 0.057388078421354294), (11, 0.05773630319163203), (13, 0.057926122564822435), (0, 0.0615371149033308), (17, 0.061808411963284016), (1, 0.06561268586665392), (52, 0.06886313576251268), (8, 0.07351419050246477), (10, 0.07855832297354937), (16, 0.08326654974371195), (12, 0.08871253672987223), (5, 0.10381246078759432), (36, 0.41657766327261925), (18, 0.4913955107331276), (53, 0.9150881394743919)]
computing accuracy for after removing block 40 . block score: 0.02386525273323059
removed block 40 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.024633. All blocks and scores: [(45, 0.024632971733808517), (50, 0.02487287321127951), (25, 0.025322210509330034), (48, 0.0254657962359488), (23, 0.025808923644945025), (42, 0.025924714049324393), (49, 0.026192928664386272), (44, 0.02670756238512695), (21, 0.027997032972052693), (22, 0.02843338204547763), (20, 0.028930592583492398), (24, 0.030724017648026347), (38, 0.03095443989150226), (7, 0.031131392577663064), (39, 0.031279583694413304), (47, 0.03189971763640642), (15, 0.03275705548003316), (19, 0.03404472256079316), (37, 0.036401282995939255), (51, 0.039864749647676945), (9, 0.044024694710969925), (6, 0.04602348618209362), (14, 0.047992602456361055), (4, 0.048011146020144224), (2, 0.05449868319556117), (3, 0.05738807562738657), (11, 0.057736302725970745), (13, 0.05792612349614501), (0, 0.06153711536899209), (17, 0.06180840963497758), (1, 0.06561268866062164), (52, 0.06642790790647268), (8, 0.07351419236510992), (10, 0.07855832204222679), (16, 0.08326655067503452), (12, 0.08871253486722708), (5, 0.10381246451288462), (36, 0.41657766699790955), (18, 0.4913955144584179), (53, 1.0115251019597054)]
computing accuracy for after removing block 45 . block score: 0.024632971733808517
removed block 45 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.025026. All blocks and scores: [(50, 0.02502627531066537), (48, 0.025295487605035305), (25, 0.02532220957800746), (23, 0.025808923644945025), (42, 0.025924713350832462), (49, 0.026250721886754036), (44, 0.026707562152296305), (21, 0.027997034369036555), (22, 0.028433382278308272), (20, 0.028930592816323042), (24, 0.03072401718236506), (38, 0.03095443989150226), (7, 0.031131392577663064), (39, 0.03127958346158266), (15, 0.03275705501437187), (47, 0.033430132549256086), (19, 0.03404472069814801), (37, 0.03640128253027797), (51, 0.038650304079055786), (9, 0.04402469517663121), (6, 0.04602348618209362), (14, 0.047992602456361055), (4, 0.0480111432261765), (2, 0.05449868272989988), (3, 0.05738807749003172), (11, 0.05773630365729332), (13, 0.057926122564822435), (0, 0.06153711769729853), (17, 0.06180840916931629), (52, 0.06192201282829046), (1, 0.06561268772929907), (8, 0.0735141932964325), (10, 0.07855832390487194), (16, 0.08326655253767967), (12, 0.08871253579854965), (5, 0.10381246823817492), (36, 0.41657766327261925), (18, 0.4913955181837082), (53, 1.164628878235817)]
computing accuracy for after removing block 50 . block score: 0.02502627531066537
removed block 50 current accuracy 0.9822 loss from initial  0.017800000000000038
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 48, with score 0.025295. All blocks and scores: [(48, 0.025295487139374018), (25, 0.025322210043668747), (23, 0.025808924110606313), (42, 0.025924713350832462), (49, 0.026250722585245967), (44, 0.026707562152296305), (21, 0.02799703413620591), (22, 0.028433382278308272), (20, 0.028930592350661755), (24, 0.03072401718236506), (38, 0.030954439425840974), (7, 0.03113139164634049), (39, 0.03127958416007459), (15, 0.03275705548003316), (47, 0.033430133014917374), (19, 0.0340447211638093), (37, 0.03640128346160054), (51, 0.041437048465013504), (9, 0.04402469424530864), (6, 0.04602348618209362), (14, 0.04799260292202234), (4, 0.04801114462316036), (2, 0.05449868133291602), (3, 0.057388074696063995), (11, 0.057736306451261044), (13, 0.0579261239618063), (0, 0.0615371149033308), (17, 0.06180840823799372), (1, 0.06561268959194422), (52, 0.07106260675936937), (8, 0.07351419236510992), (10, 0.07855832390487194), (16, 0.08326655067503452), (12, 0.0887125339359045), (5, 0.10381246451288462), (36, 0.41657765582203865), (18, 0.4913955144584179), (53, 1.3760973513126373)]
computing accuracy for after removing block 48 . block score: 0.025295487139374018
removed block 48 current accuracy 0.9608 loss from initial  0.03920000000000001
since last training loss: 0.039000000000000035 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.025322. All blocks and scores: [(25, 0.025322210043668747), (23, 0.025808923644945025), (42, 0.025924713350832462), (44, 0.026707561686635017), (21, 0.027997033670544624), (22, 0.02843338274396956), (20, 0.028930592350661755), (49, 0.02996224514208734), (24, 0.03072401788085699), (38, 0.030954439425840974), (7, 0.031131392577663064), (39, 0.031279584392905235), (15, 0.03275705501437187), (47, 0.03343013161793351), (19, 0.034044720232486725), (37, 0.03640128346160054), (51, 0.04199904948472977), (9, 0.04402469517663121), (6, 0.04602348757907748), (14, 0.047992602456361055), (4, 0.04801114555448294), (2, 0.05449868319556117), (3, 0.057388076558709145), (11, 0.057736302725970745), (13, 0.05792612116783857), (0, 0.06153711536899209), (17, 0.061808408703655005), (1, 0.0656126867979765), (8, 0.07351419143378735), (10, 0.07855832297354937), (52, 0.08147065155208111), (16, 0.08326654694974422), (12, 0.08871253486722708), (5, 0.10381246544420719), (36, 0.41657766327261925), (18, 0.4913955144584179), (53, 1.4979998469352722)]
computing accuracy for after removing block 25 . block score: 0.025322210043668747
removed block 25 current accuracy 0.9564 loss from initial  0.04359999999999997
training start
training epoch 0 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 1 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 2 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 3 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 4 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 5 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 6 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 7 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 8 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 9 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 10 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 11 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 12 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 13 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 14 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 16 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 17 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 18 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 19 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 20 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 21 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 22 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 23 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 24 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 25 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 26 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 27 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 28 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 29 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 30 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 31 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 32 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 33 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 34 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 35 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 36 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 37 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 38 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 39 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 40 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 41 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 42 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 43 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 44 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 45 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 46 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 47 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 48 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 49 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.997000)
finished training. finished 50 epochs. accuracy 0.997 topk_dict {'top1': 0.997}
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.027799. All blocks and scores: [(44, 0.027799453353509307), (23, 0.030665032798424363), (42, 0.03076894232071936), (7, 0.03096154355444014), (21, 0.031191838206723332), (38, 0.03150318772532046), (20, 0.031642567832022905), (22, 0.03172429837286472), (39, 0.03294241288676858), (15, 0.03321080096065998), (49, 0.03331429837271571), (47, 0.036279783584177494), (19, 0.03638959862291813), (37, 0.036814249120652676), (24, 0.03712760331109166), (9, 0.042712447699159384), (6, 0.04476491827517748), (4, 0.04567958693951368), (14, 0.04779636673629284), (51, 0.04855691874399781), (2, 0.052951179910451174), (11, 0.05601781001314521), (3, 0.05640893755480647), (13, 0.05665049375966191), (0, 0.05961521062999964), (17, 0.06130911409854889), (1, 0.06347705516964197), (8, 0.06996196880936623), (10, 0.07683390192687511), (16, 0.08086453564465046), (52, 0.08170274645090103), (12, 0.08713537640869617), (5, 0.09970644116401672), (36, 0.3707123473286629), (18, 0.4606129415333271), (53, 0.8576188609004021)]
computing accuracy for after removing block 44 . block score: 0.027799453353509307
removed block 44 current accuracy 0.9912 loss from initial  0.00880000000000003
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.030665. All blocks and scores: [(23, 0.03066503326408565), (42, 0.030768942087888718), (7, 0.030961543088778853), (21, 0.03119183797389269), (38, 0.03150318772532046), (20, 0.031642567832022905), (22, 0.03172429883852601), (49, 0.03190026665106416), (39, 0.032942413818091154), (15, 0.033210801891982555), (19, 0.03638959815725684), (37, 0.036814247723668814), (24, 0.03712760377675295), (47, 0.03845811868086457), (9, 0.042712447233498096), (6, 0.04476491780951619), (4, 0.04567958740517497), (51, 0.046298697125166655), (14, 0.04779636673629284), (2, 0.05295118037611246), (11, 0.056017808616161346), (3, 0.05640893755480647), (13, 0.05665049608796835), (0, 0.059615207370370626), (17, 0.06130911409854889), (1, 0.06347705284133554), (8, 0.06996196880936623), (52, 0.07376609742641449), (10, 0.07683390099555254), (16, 0.08086453657597303), (12, 0.08713537640869617), (5, 0.09970643930137157), (36, 0.3707123436033726), (18, 0.4606129415333271), (53, 1.0125913321971893)]
computing accuracy for after removing block 23 . block score: 0.03066503326408565
removed block 23 current accuracy 0.9852 loss from initial  0.014800000000000035
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.029154. All blocks and scores: [(42, 0.02915427810512483), (38, 0.030821342021226883), (7, 0.030961543321609497), (21, 0.03119183680973947), (49, 0.031358050648123026), (20, 0.031642567832022905), (22, 0.031724297907203436), (39, 0.03261466510593891), (15, 0.03321080096065998), (24, 0.03406694205477834), (19, 0.03638959815725684), (47, 0.03706693556159735), (37, 0.03743731323629618), (9, 0.042712447233498096), (6, 0.04476491827517748), (51, 0.04516920447349548), (4, 0.04567958787083626), (14, 0.047796367201954126), (2, 0.05295118037611246), (11, 0.056017808616161346), (3, 0.05640893615782261), (13, 0.05665049469098449), (0, 0.059615209233015776), (17, 0.061309113167226315), (1, 0.0634770542383194), (52, 0.06942006852477789), (8, 0.0699619697406888), (10, 0.07683390378952026), (16, 0.08086453564465046), (12, 0.0871353754773736), (5, 0.099706438370049), (36, 0.365029938519001), (18, 0.4606129415333271), (53, 1.0175226479768753)]
computing accuracy for after removing block 42 . block score: 0.02915427810512483
removed block 42 current accuracy 0.97 loss from initial  0.030000000000000027
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.030821. All blocks and scores: [(38, 0.030821342254057527), (7, 0.030961543088778853), (21, 0.0311918375082314), (20, 0.03164256736636162), (22, 0.031724297907203436), (39, 0.0326146655716002), (49, 0.032786127645522356), (15, 0.03321080096065998), (24, 0.03406694158911705), (19, 0.03638959862291813), (37, 0.03743731416761875), (47, 0.03996274061501026), (9, 0.042712447699159384), (6, 0.04476491827517748), (51, 0.04564964724704623), (4, 0.045679588336497545), (14, 0.047796367667615414), (2, 0.052951179910451174), (11, 0.05601781001314521), (3, 0.05640893615782261), (13, 0.056650495156645775), (0, 0.059615205973386765), (17, 0.0613091136328876), (1, 0.06347705516964197), (8, 0.06996196880936623), (52, 0.07276186160743237), (10, 0.07683390099555254), (16, 0.08086453378200531), (12, 0.0871353754773736), (5, 0.09970644023269415), (36, 0.3650299347937107), (18, 0.4606129415333271), (53, 1.0932440012693405)]
computing accuracy for after removing block 38 . block score: 0.030821342254057527
removed block 38 current accuracy 0.955 loss from initial  0.04500000000000004
since last training loss: 0.04200000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 7, with score 0.030962. All blocks and scores: [(7, 0.030961542623117566), (21, 0.03119183797389269), (49, 0.03142730123363435), (20, 0.031642567832022905), (22, 0.03172429744154215), (15, 0.03321080096065998), (24, 0.03406694112345576), (39, 0.035259176045656204), (19, 0.03638959862291813), (37, 0.03743731323629618), (47, 0.03746427735313773), (9, 0.042712447699159384), (51, 0.04472329327836633), (6, 0.04476491827517748), (4, 0.045679588336497545), (14, 0.047796367201954126), (2, 0.05295118223875761), (11, 0.05601781001314521), (3, 0.05640893569216132), (13, 0.056650495156645775), (0, 0.059615207836031914), (17, 0.0613091136328876), (1, 0.0634770542383194), (52, 0.06412927387282252), (8, 0.06996196787804365), (10, 0.07683390285819769), (16, 0.08086453471332788), (12, 0.0871353754773736), (5, 0.09970644116401672), (36, 0.3650299310684204), (18, 0.4606129564344883), (53, 1.1967673748731613)]
computing accuracy for after removing block 7 . block score: 0.030961542623117566
removed block 7 current accuracy 0.945 loss from initial  0.05500000000000005
since last training loss: 0.052000000000000046 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.030106. All blocks and scores: [(22, 0.030106357065960765), (49, 0.03058263403363526), (20, 0.03064644569531083), (21, 0.0309820300899446), (24, 0.031206440646201372), (15, 0.03188534080982208), (39, 0.034585564862936735), (19, 0.035534747410565615), (37, 0.03570211725309491), (47, 0.036247721407562494), (9, 0.04249989474192262), (51, 0.043428432662039995), (14, 0.044567597564309835), (6, 0.044764917343854904), (4, 0.04567958880215883), (13, 0.0492490460164845), (2, 0.05295118037611246), (11, 0.05309252440929413), (17, 0.053736886009573936), (3, 0.056408937089145184), (0, 0.05961520690470934), (52, 0.06051513459533453), (1, 0.06347705516964197), (8, 0.06781844422221184), (16, 0.07388556748628616), (10, 0.07992638740688562), (12, 0.08259253669530153), (5, 0.09970644302666187), (36, 0.35292424634099007), (18, 0.4446651041507721), (53, 1.2390805184841156)]
computing accuracy for after removing block 22 . block score: 0.030106357065960765
removed block 22 current accuracy 0.9308 loss from initial  0.06920000000000004
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.027576. All blocks and scores: [(24, 0.027575660031288862), (49, 0.029427392408251762), (20, 0.030646446626633406), (21, 0.030982029857113957), (15, 0.03188533894717693), (39, 0.033307278994470835), (47, 0.03359476150944829), (19, 0.035534747410565615), (37, 0.03555483929812908), (51, 0.04170694202184677), (9, 0.04249989381060004), (14, 0.044567599426954985), (6, 0.04476491780951619), (4, 0.045679588336497545), (13, 0.04924904461950064), (2, 0.052951179444789886), (11, 0.05309252580627799), (52, 0.05343259731307626), (17, 0.05373688694089651), (3, 0.056408937089145184), (0, 0.059615207836031914), (1, 0.0634770542383194), (8, 0.06781844235956669), (16, 0.07388556748628616), (10, 0.07992638740688562), (12, 0.08259253483265638), (5, 0.09970643930137157), (36, 0.3419260308146477), (18, 0.444665115326643), (53, 1.2263770252466202)]
computing accuracy for after removing block 24 . block score: 0.027575660031288862
removed block 24 current accuracy 0.8968 loss from initial  0.10319999999999996
since last training loss: 0.10019999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.027407. All blocks and scores: [(49, 0.027406914392486215), (20, 0.03064644685946405), (21, 0.030982029624283314), (47, 0.03149543423205614), (15, 0.03188533987849951), (39, 0.031992796808481216), (37, 0.033950740937143564), (19, 0.035534747410565615), (51, 0.03868205612525344), (9, 0.04249989567324519), (14, 0.04456759849563241), (6, 0.044764918740838766), (4, 0.045679588336497545), (52, 0.04609745880588889), (13, 0.04924904415383935), (2, 0.052951179444789886), (11, 0.05309252627193928), (17, 0.0537368874065578), (3, 0.05640893802046776), (0, 0.059615207370370626), (1, 0.0634770542383194), (8, 0.06781844515353441), (16, 0.07388556655496359), (10, 0.07992638740688562), (12, 0.08259253390133381), (5, 0.09970644023269415), (36, 0.3257264159619808), (18, 0.4446651041507721), (53, 1.2389347553253174)]
computing accuracy for after removing block 49 . block score: 0.027406914392486215
removed block 49 current accuracy 0.8504 loss from initial  0.14959999999999996
since last training loss: 0.14659999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.030646. All blocks and scores: [(20, 0.030646445229649544), (21, 0.030982029857113957), (47, 0.03149543423205614), (15, 0.03188534127548337), (39, 0.031992797274142504), (37, 0.033950740937143564), (19, 0.0355347478762269), (51, 0.03903960529714823), (9, 0.042499893344938755), (14, 0.044567599426954985), (6, 0.044764918740838766), (4, 0.04567958880215883), (13, 0.04924904461950064), (52, 0.051702231634408236), (2, 0.052951179910451174), (11, 0.053092526737600565), (17, 0.053736886475235224), (3, 0.056408936623483896), (0, 0.05961520643904805), (1, 0.0634770542383194), (8, 0.06781844515353441), (16, 0.07388556841760874), (10, 0.07992638647556305), (12, 0.08259253483265638), (5, 0.09970644023269415), (36, 0.3257264196872711), (18, 0.4446651078760624), (53, 1.5297570675611496)]
computing accuracy for after removing block 20 . block score: 0.030646445229649544
removed block 20 current accuracy 0.82 loss from initial  0.18000000000000005
training start
training epoch 0 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 1 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.001]
training epoch 2 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best True lr [0.001]
training epoch 3 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.001]
training epoch 4 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.001]
training epoch 5 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.001]
training epoch 6 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.001]
training epoch 7 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 8 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 9 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.001]
training epoch 10 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 11 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 12 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.001]
training epoch 13 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 14 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best True lr [0.001]
training epoch 15 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 16 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 17 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 18 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 19 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 20 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 21 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best True lr [0.001]
training epoch 22 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 23 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 24 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 25 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 26 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 27 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 28 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 29 val accuracy 0.978 topk_dict {'top1': 0.978} is_best True lr [0.001]
training epoch 30 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 31 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 32 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 33 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 34 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 35 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 36 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 37 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 38 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 39 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 40 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 41 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 42 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 43 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 44 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 45 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 46 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 47 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 48 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 49 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.981000)
finished training. finished 50 epochs. accuracy 0.981 topk_dict {'top1': 0.981}
