start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975077856332), (20, 0.008696247939951718), (27, 0.00919829506892711), (31, 0.00967550405766815), (29, 0.01003042096272111), (22, 0.010588386678136885), (23, 0.010651617776602507), (21, 0.010725351399742067), (28, 0.011828799499198794), (24, 0.012058728723786771), (17, 0.012199450400657952), (19, 0.01317794865462929), (33, 0.0132797866826877), (35, 0.013483816059306264), (25, 0.013839342049323022), (11, 0.013912909431383014), (32, 0.013956584851257503), (16, 0.01476623781491071), (30, 0.015491605270653963), (9, 0.015547690447419882), (40, 0.015986334765329957), (34, 0.01665632240474224), (39, 0.017517176689580083), (44, 0.01864156685769558), (37, 0.01879900461062789), (43, 0.018935034284368157), (42, 0.0195143383461982), (41, 0.019590021576732397), (45, 0.019901464926078916), (38, 0.020000957883894444), (14, 0.020047534490004182), (8, 0.021667920984327793), (7, 0.021806211210787296), (15, 0.02483329689130187), (46, 0.025212791748344898), (10, 0.02590036136098206), (49, 0.027116776444017887), (48, 0.027511440217494965), (47, 0.027820877032354474), (50, 0.02872324548661709), (51, 0.031788797583431005), (12, 0.03298327047377825), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.03804349433630705), (3, 0.043747184332460165), (52, 0.0525340442545712), (13, 0.05450336076319218), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.27274293079972267), (18, 0.30386047437787056), (53, 0.8891633152961731)]
computing accuracy for after removing block 26 . block score: 0.007451975077856332
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.008696247823536396), (27, 0.00956932723056525), (31, 0.009736894513480365), (29, 0.010370098054409027), (22, 0.010588386561721563), (23, 0.010651617776602507), (21, 0.010725351050496101), (24, 0.012058728374540806), (28, 0.012067585485056043), (17, 0.012199450749903917), (19, 0.01317794865462929), (33, 0.013200338464230299), (35, 0.013297738507390022), (32, 0.013540126499719918), (25, 0.013839342398568988), (11, 0.013912909082137048), (16, 0.01476623781491071), (30, 0.015476006898097694), (9, 0.015547690447419882), (34, 0.01633565383963287), (40, 0.016489707864820957), (39, 0.018151730066165328), (44, 0.01880926568992436), (43, 0.019272045930847526), (37, 0.0193706217687577), (41, 0.019797630375251174), (42, 0.0198463867418468), (14, 0.0200475356541574), (38, 0.020208331756293774), (45, 0.020282168872654438), (8, 0.021667920984327793), (7, 0.021806211210787296), (15, 0.02483329689130187), (46, 0.025710681220516562), (10, 0.025900361593812704), (49, 0.02717575686983764), (48, 0.027807614766061306), (47, 0.02826968370936811), (50, 0.02872340544126928), (51, 0.03195985872298479), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.04374718340113759), (52, 0.052661973517388105), (13, 0.05450336029753089), (2, 0.0612060371786356), (1, 0.07061250787228346), (0, 0.14636892639100552), (36, 0.2777215540409088), (18, 0.30386046692728996), (53, 0.8825649917125702)]
computing accuracy for after removing block 20 . block score: 0.008696247823536396
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.009247071109712124), (31, 0.009490355267189443), (29, 0.010141469654627144), (23, 0.010720769176259637), (21, 0.0108736950205639), (22, 0.01095143985003233), (28, 0.011602518148720264), (17, 0.01219945086631924), (24, 0.012428545043803751), (33, 0.013006685534492135), (32, 0.013030687579885125), (35, 0.013141492730937898), (19, 0.013177948538213968), (11, 0.013912909314967692), (25, 0.014337054919451475), (30, 0.014731099247001112), (16, 0.014766237116418779), (9, 0.015547689981758595), (34, 0.01595074124634266), (40, 0.016676967265084386), (39, 0.018123318906873465), (44, 0.019042733125388622), (43, 0.019525704439729452), (37, 0.019535947125405073), (41, 0.020023913122713566), (42, 0.02002461184747517), (14, 0.02004753495566547), (38, 0.02022995217703283), (45, 0.020495346514508128), (8, 0.02166792005300522), (7, 0.02180621027946472), (15, 0.024833297124132514), (10, 0.025900361128151417), (46, 0.026008821558207273), (49, 0.027358210179954767), (48, 0.027944064931944013), (47, 0.028558713383972645), (50, 0.028874032897874713), (51, 0.03197578387334943), (12, 0.03298326954245567), (5, 0.03333624405786395), (6, 0.03351968294009566), (4, 0.03804349293932319), (3, 0.0437471829354763), (52, 0.05319312820211053), (13, 0.0545033598318696), (2, 0.061206035781651735), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.27894822135567665), (18, 0.30386047065258026), (53, 0.8746765404939651)]
computing accuracy for after removing block 27 . block score: 0.009247071109712124
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703439893200994), (29, 0.010401993989944458), (23, 0.010720769059844315), (21, 0.010873694671317935), (22, 0.01095143985003233), (28, 0.011904270388185978), (17, 0.012199450517073274), (24, 0.012428545393049717), (33, 0.012989282375201583), (35, 0.01303201261907816), (32, 0.013032321585342288), (19, 0.013177948771044612), (11, 0.013912909314967692), (25, 0.01433705457020551), (30, 0.014530949760228395), (16, 0.014766237698495388), (34, 0.015523916226811707), (9, 0.015547689865343273), (40, 0.01742828404530883), (39, 0.01863569999113679), (44, 0.0193233760073781), (43, 0.019895022036507726), (14, 0.0200475356541574), (37, 0.02016281825490296), (38, 0.02019783016294241), (42, 0.020295765018090606), (41, 0.020331317791715264), (45, 0.02073849458247423), (8, 0.021667920285835862), (7, 0.02180621144361794), (15, 0.024833296658471227), (10, 0.02590036136098206), (46, 0.0262983120046556), (49, 0.027372207958251238), (48, 0.02811374608427286), (47, 0.028824042296037078), (50, 0.02908248594030738), (51, 0.03204397251829505), (12, 0.03298327000811696), (5, 0.03333624266088009), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.05334703717380762), (13, 0.054503361228853464), (2, 0.06120603671297431), (1, 0.07061250600963831), (0, 0.14636891894042492), (36, 0.2865508534014225), (18, 0.30386047810316086), (53, 0.8739226683974266)]
computing accuracy for after removing block 31 . block score: 0.009703439893200994
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401994222775102), (23, 0.010720769292674959), (21, 0.010873694787733257), (22, 0.010951439733617008), (28, 0.011904270271770656), (17, 0.012199450517073274), (24, 0.012428545160219073), (33, 0.013075273367576301), (19, 0.013177949120290577), (32, 0.013221941306255758), (35, 0.013311224756762385), (11, 0.013912909547798336), (25, 0.014337054919451475), (30, 0.014530949876643717), (16, 0.014766237465664744), (34, 0.015109014231711626), (9, 0.015547690214589238), (40, 0.017963848309591413), (44, 0.019172759726643562), (39, 0.019229266326874495), (38, 0.019627249101176858), (43, 0.019773422041907907), (42, 0.020014989655464888), (14, 0.020047535188496113), (41, 0.020369442645460367), (45, 0.020458240061998367), (37, 0.020535161951556802), (8, 0.021667921217158437), (7, 0.02180621144361794), (15, 0.024833296425640583), (10, 0.025900361128151417), (46, 0.026439889566972852), (49, 0.027319707674905658), (48, 0.028306723106652498), (47, 0.028651983477175236), (50, 0.029288704739883542), (51, 0.03214396722614765), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.05252913665026426), (13, 0.0545033598318696), (2, 0.061206033919006586), (1, 0.07061250880360603), (0, 0.14636892266571522), (36, 0.29571831971406937), (18, 0.30386048182845116), (53, 0.885270394384861)]
computing accuracy for after removing block 29 . block score: 0.010401994222775102
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.010720769059844315), (21, 0.010873694787733257), (22, 0.010951439733617008), (28, 0.011904270155355334), (17, 0.012199450633488595), (24, 0.012428545160219073), (33, 0.01309553359169513), (19, 0.013177948771044612), (32, 0.013331791036762297), (35, 0.013342682155780494), (11, 0.013912908616475761), (25, 0.014337054686620831), (16, 0.014766237582080066), (34, 0.014780625118874013), (30, 0.014848081395030022), (9, 0.015547690680250525), (40, 0.017947440268471837), (44, 0.018570148153230548), (38, 0.018818871583789587), (39, 0.01928418385796249), (42, 0.01955016772262752), (43, 0.019667528802528977), (41, 0.020019967341795564), (14, 0.020047535886988044), (45, 0.02014507818967104), (37, 0.02077811397612095), (8, 0.021667920518666506), (7, 0.021806210977956653), (15, 0.024833297124132514), (10, 0.025900361593812704), (46, 0.026351966429501772), (49, 0.02699960768222809), (48, 0.027823995798826218), (47, 0.028508094139397144), (50, 0.029334592632949352), (51, 0.03217176906764507), (12, 0.03298326954245567), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.043747182469815016), (52, 0.051905466709285975), (13, 0.05450336029753089), (2, 0.061206035781651735), (1, 0.07061250787228346), (0, 0.14636892266571522), (36, 0.2995104119181633), (18, 0.30386047810316086), (53, 0.8962140306830406)]
computing accuracy for after removing block 23 . block score: 0.010720769059844315
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010965. All blocks and scores: [(21, 0.01096484495792538), (22, 0.011535240104421973), (17, 0.012125574168749154), (28, 0.013160653179511428), (19, 0.013209980097599328), (33, 0.013490397366695106), (24, 0.013522637425921857), (11, 0.013882361934520304), (35, 0.013929978711530566), (16, 0.014723330736160278), (25, 0.014761257218196988), (32, 0.01489983033388853), (9, 0.015561448759399354), (40, 0.015912402886897326), (30, 0.01618768787011504), (34, 0.017249662661924958), (39, 0.017333745723590255), (43, 0.018454135861247778), (44, 0.018612423446029425), (37, 0.018771540140733123), (42, 0.01909464574418962), (41, 0.019277084851637483), (45, 0.019621929619461298), (38, 0.019729699240997434), (14, 0.020046850200742483), (8, 0.021855428582057357), (7, 0.0219906868878752), (15, 0.024884876562282443), (46, 0.025507242884486914), (10, 0.026183436857536435), (49, 0.02693653479218483), (47, 0.0272530154325068), (48, 0.02752288756892085), (50, 0.028685708064585924), (51, 0.031151699367910624), (12, 0.03298152144998312), (5, 0.033321029506623745), (6, 0.0334871388040483), (4, 0.0384796978905797), (3, 0.04364790115505457), (52, 0.050921129528433084), (13, 0.054173827171325684), (2, 0.060276145581156015), (1, 0.0705570774152875), (0, 0.14405427873134613), (36, 0.27069591730833054), (18, 0.3037679083645344), (53, 0.887718454003334)]
computing accuracy for after removing block 21 . block score: 0.01096484495792538
removed block 21 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 22, with score 0.011598. All blocks and scores: [(22, 0.011597828357480466), (17, 0.012125573703087866), (28, 0.012188524124212563), (33, 0.012942602974362671), (35, 0.012973138014785945), (19, 0.013209979399107397), (24, 0.013245511101558805), (11, 0.01388236228376627), (32, 0.01399959425907582), (25, 0.014514282811433077), (16, 0.014723329804837704), (30, 0.01515892765019089), (9, 0.01556144852656871), (40, 0.016017653048038483), (34, 0.016770424786955118), (39, 0.017487706383690238), (43, 0.018677521497011185), (44, 0.018776758573949337), (37, 0.01888428023084998), (42, 0.01940904022194445), (38, 0.019817146938294172), (45, 0.019864781759679317), (14, 0.020046850433573127), (41, 0.02006519795395434), (8, 0.021855429047718644), (7, 0.021990687353536487), (15, 0.024884877260774374), (10, 0.026183437323197722), (46, 0.02624364849179983), (49, 0.027350836666300893), (48, 0.027647383511066437), (47, 0.027669639326632023), (50, 0.028824597829952836), (51, 0.031648237723857164), (12, 0.03298152098432183), (5, 0.033321029506623745), (6, 0.033487139735370874), (4, 0.03847969649359584), (3, 0.04364790162071586), (52, 0.05158647522330284), (13, 0.05417382624000311), (2, 0.060276145581156015), (1, 0.07055707927793264), (0, 0.14405428059399128), (36, 0.2707845866680145), (18, 0.3037679120898247), (53, 0.8905049934983253)]
computing accuracy for after removing block 22 . block score: 0.011597828357480466
removed block 22 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.011767. All blocks and scores: [(28, 0.011766852578148246), (17, 0.012125574052333832), (24, 0.012183941784314811), (33, 0.012486950494349003), (35, 0.012515033595263958), (32, 0.012884333496913314), (19, 0.013209979981184006), (11, 0.013882362400181592), (25, 0.013965089106932282), (30, 0.014375461614690721), (16, 0.014723330386914313), (9, 0.015561448992229998), (40, 0.015887706307694316), (34, 0.016223751474171877), (39, 0.017463526455685496), (43, 0.018273369874805212), (44, 0.018306518206372857), (37, 0.01851060544140637), (42, 0.01906456029973924), (45, 0.019459497882053256), (38, 0.019492274383082986), (14, 0.020046850433573127), (41, 0.02023313380777836), (8, 0.02185542951337993), (7, 0.021990687120705843), (15, 0.024884877260774374), (10, 0.02618343662470579), (46, 0.026257328921929002), (49, 0.027418690267950296), (48, 0.027602948481217027), (47, 0.02778923185542226), (50, 0.028584925457835197), (51, 0.03179360227659345), (12, 0.03298152098432183), (5, 0.03332102810963988), (6, 0.03348713926970959), (4, 0.03847969742491841), (3, 0.04364790255203843), (52, 0.051367546897381544), (13, 0.054173827171325684), (2, 0.060276144184172153), (1, 0.0705570774152875), (0, 0.14405428245663643), (36, 0.2681144140660763), (18, 0.3037679046392441), (53, 0.897602416574955)]
computing accuracy for after removing block 28 . block score: 0.011766852578148246
removed block 28 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 35, with score 0.012040. All blocks and scores: [(35, 0.012039782362990081), (17, 0.01212557393591851), (24, 0.01218394166789949), (32, 0.012366036651656032), (33, 0.012433558353222907), (19, 0.013209979515522718), (11, 0.013882361818104982), (25, 0.01396508899051696), (30, 0.01413053332362324), (16, 0.014723330619744956), (9, 0.015561448642984033), (34, 0.015793359489180148), (40, 0.016473840223625302), (39, 0.01814345712773502), (44, 0.018335389206185937), (43, 0.018480644561350346), (38, 0.018742572981864214), (37, 0.01877038669772446), (42, 0.018968732794746757), (45, 0.01978549431078136), (14, 0.020046850200742483), (41, 0.02037711418233812), (8, 0.021855428814888), (7, 0.021990687819197774), (15, 0.024884877260774374), (10, 0.02618343709036708), (46, 0.026661029551178217), (48, 0.027296601328998804), (49, 0.02741508395411074), (47, 0.02800442581064999), (50, 0.028632724890485406), (51, 0.03229645499959588), (12, 0.03298152098432183), (5, 0.033321027643978596), (6, 0.0334871388040483), (4, 0.0384796978905797), (3, 0.043647902086377144), (52, 0.05109492689371109), (13, 0.054173826705664396), (2, 0.060276144184172153), (1, 0.07055708020925522), (0, 0.14405427873134613), (36, 0.27555473893880844), (18, 0.3037679120898247), (53, 0.9044275283813477)]
computing accuracy for after removing block 35 . block score: 0.012039782362990081
removed block 35 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 17, with score 0.012126. All blocks and scores: [(17, 0.012125573470257223), (24, 0.01218394166789949), (32, 0.012366036302410066), (33, 0.012433558236807585), (19, 0.01320998021401465), (11, 0.01388236228376627), (25, 0.013965089689008892), (30, 0.014130533556453884), (16, 0.01472333015408367), (9, 0.015561448759399354), (40, 0.0157740272115916), (34, 0.015793359256349504), (44, 0.017747698351740837), (39, 0.01788068446330726), (37, 0.01804799633100629), (43, 0.018220127560198307), (38, 0.018341076094657183), (42, 0.018701950320973992), (45, 0.01954106823541224), (14, 0.02004685066640377), (41, 0.020250142319127917), (8, 0.021855428814888), (7, 0.02199068758636713), (15, 0.024884877260774374), (10, 0.02618343709036708), (48, 0.026705715572461486), (46, 0.02716921316459775), (49, 0.02781408652663231), (47, 0.027908449759706855), (50, 0.028501874301582575), (51, 0.03239688137546182), (12, 0.03298152098432183), (5, 0.03332102857530117), (6, 0.03348714020103216), (4, 0.0384796978905797), (3, 0.043647902086377144), (52, 0.049878878984600306), (13, 0.05417382763698697), (2, 0.06027614511549473), (1, 0.07055707834661007), (0, 0.14405427873134613), (36, 0.27721764519810677), (18, 0.3037678971886635), (53, 0.9166658446192741)]
computing accuracy for after removing block 17 . block score: 0.012125573470257223
removed block 17 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 33, with score 0.011911. All blocks and scores: [(33, 0.011911360896192491), (24, 0.012170077068731189), (32, 0.01217457721941173), (19, 0.01222148712258786), (25, 0.01308867905754596), (30, 0.013325922540389001), (11, 0.013882362400181592), (16, 0.014723330736160278), (34, 0.015165081713348627), (9, 0.015561448992229998), (40, 0.01615764992311597), (44, 0.017736095702275634), (38, 0.018012960208579898), (37, 0.018065480748191476), (43, 0.01806880976073444), (42, 0.018268569605425), (39, 0.018309932202100754), (45, 0.01916945422999561), (14, 0.020046850899234414), (41, 0.020443197805434465), (8, 0.02185542951337993), (7, 0.02199068758636713), (15, 0.024884876795113087), (10, 0.026183436391875148), (48, 0.026607411680743098), (46, 0.027409277856349945), (47, 0.027676195139065385), (49, 0.027794550405815244), (50, 0.028150832979008555), (51, 0.03176960861310363), (12, 0.03298152098432183), (5, 0.03332102997228503), (6, 0.03348713926970959), (4, 0.038479696959257126), (3, 0.04364790115505457), (52, 0.048759679310023785), (13, 0.054173827171325684), (2, 0.06027614325284958), (1, 0.07055707834661007), (0, 0.14405427686870098), (36, 0.28113071620464325), (18, 0.3107377365231514), (53, 0.9077708646655083)]
computing accuracy for after removing block 33 . block score: 0.011911360896192491
removed block 33 current accuracy 0.9892 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 2 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 3 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 5 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 6 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 7 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 29 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation diff]: block to remove picked: 11, with score 0.013934. All blocks and scores: [(11, 0.013933832058683038), (19, 0.01523590984288603), (16, 0.015652116271667182), (40, 0.01565599348396063), (9, 0.015697096241638064), (24, 0.0161012455355376), (25, 0.01657865266315639), (32, 0.01710135256871581), (39, 0.017298648366704583), (44, 0.017684328369796276), (43, 0.017925575375556946), (37, 0.01818350935354829), (41, 0.018367962446063757), (42, 0.018590786028653383), (45, 0.019083314342424273), (38, 0.01924195233732462), (34, 0.019344632513821125), (14, 0.019845378352329135), (30, 0.020004348130896688), (7, 0.02096619550138712), (8, 0.021212396677583456), (46, 0.0242437063716352), (15, 0.02588666626252234), (49, 0.026149248238652945), (48, 0.02621645526960492), (10, 0.026523751439526677), (47, 0.02657611994072795), (50, 0.02774471719749272), (51, 0.030831060372292995), (5, 0.03229527408257127), (12, 0.032407164108008146), (6, 0.03309072833508253), (4, 0.038083209190517664), (3, 0.042709481436759233), (52, 0.050550485495477915), (13, 0.054050931707024574), (2, 0.059664362110197544), (1, 0.06779658794403076), (0, 0.1422524731606245), (36, 0.26438045874238014), (18, 0.29115448147058487), (53, 0.8858154788613319)]
computing accuracy for after removing block 11 . block score: 0.013933832058683038
removed block 11 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.015027. All blocks and scores: [(19, 0.015027255285531282), (40, 0.015516608254984021), (9, 0.01569709670729935), (24, 0.015904825762845576), (16, 0.016058956272900105), (25, 0.01608046516776085), (32, 0.01675854017958045), (39, 0.016848913161084056), (43, 0.01761012338101864), (44, 0.017639088677242398), (37, 0.017824682174250484), (42, 0.01814952353015542), (41, 0.01849025906994939), (30, 0.018854196649044752), (14, 0.018996472703292966), (38, 0.018997898790985346), (34, 0.019012971315532923), (45, 0.019246544921770692), (7, 0.020966195268556476), (8, 0.021212395979091525), (46, 0.024272740120068192), (15, 0.025791384978219867), (48, 0.025823677191510797), (49, 0.026281320257112384), (47, 0.026394604705274105), (10, 0.026523751905187964), (50, 0.02759330766275525), (51, 0.030612534377723932), (12, 0.030650332337245345), (5, 0.03229527361690998), (6, 0.033090727869421244), (4, 0.03808320872485638), (3, 0.04270948050543666), (52, 0.05031284550204873), (13, 0.05178141500800848), (2, 0.05966436071321368), (1, 0.06779658608138561), (0, 0.1422524806112051), (36, 0.2618900313973427), (18, 0.28351253271102905), (53, 0.8708586916327477)]
computing accuracy for after removing block 19 . block score: 0.015027255285531282
removed block 19 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.015154. All blocks and scores: [(25, 0.015154121443629265), (9, 0.015697096241638064), (40, 0.01597610325552523), (16, 0.016058956505730748), (24, 0.016293296590447426), (32, 0.016463957959786057), (39, 0.016854739282280207), (44, 0.017747828038409352), (43, 0.01782129448838532), (37, 0.017956558847799897), (30, 0.018018646631389856), (34, 0.018123745918273926), (42, 0.01835592300631106), (41, 0.018654416082426906), (38, 0.01870684907771647), (14, 0.018996473401784897), (45, 0.019584283232688904), (7, 0.020966195268556476), (8, 0.021212396677583456), (46, 0.02459452860057354), (48, 0.025768855353817344), (15, 0.02579138521105051), (49, 0.02637006132863462), (10, 0.026523751206696033), (47, 0.026623032754287124), (50, 0.02770549594424665), (12, 0.03065033257007599), (51, 0.030781870940700173), (5, 0.03229527361690998), (6, 0.03309072880074382), (4, 0.038083209190517664), (3, 0.042709480971097946), (52, 0.05025801947340369), (13, 0.05178141361102462), (2, 0.059664362110197544), (1, 0.06779658980667591), (0, 0.1422524768859148), (36, 0.2655835188925266), (18, 0.28351253643631935), (53, 0.8664781749248505)]
computing accuracy for after removing block 25 . block score: 0.015154121443629265
removed block 25 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 9, with score 0.015697. All blocks and scores: [(9, 0.01569709670729935), (32, 0.01596776000224054), (16, 0.016058956738561392), (24, 0.01629329682327807), (40, 0.016344768460839987), (34, 0.017624944681301713), (30, 0.017745547462254763), (39, 0.017843454610556364), (44, 0.018018673406913877), (43, 0.01802730793133378), (42, 0.018065713811665773), (38, 0.01845151255838573), (37, 0.018537031719461083), (14, 0.018996473168954253), (41, 0.019185189390555024), (45, 0.0200139912776649), (7, 0.02096619550138712), (8, 0.02121239621192217), (46, 0.02459144056774676), (48, 0.025682068429887295), (15, 0.02579138590954244), (49, 0.02627812442369759), (10, 0.026523750508204103), (47, 0.026701613795012236), (50, 0.027118871454149485), (51, 0.030493219615891576), (12, 0.030650333501398563), (5, 0.03229527408257127), (6, 0.03309072833508253), (4, 0.038083209190517664), (3, 0.0427094791084528), (52, 0.048485841136425734), (13, 0.05178141361102462), (2, 0.05966436164453626), (1, 0.06779658701270819), (0, 0.1422524768859148), (36, 0.27507520839571953), (18, 0.28351254016160965), (53, 0.8590302467346191)]
computing accuracy for after removing block 9 . block score: 0.01569709670729935
removed block 9 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 16, with score 0.014944. All blocks and scores: [(16, 0.014943927992135286), (32, 0.015082824742421508), (24, 0.015626563574187458), (40, 0.01586018782109022), (30, 0.016787642613053322), (39, 0.01707008294761181), (34, 0.0171559217851609), (14, 0.017402426106855273), (43, 0.01743699051439762), (44, 0.017671929439529777), (42, 0.017720459960401058), (37, 0.017763206269592047), (38, 0.01796936080791056), (41, 0.019605271518230438), (45, 0.019633345305919647), (7, 0.020966195268556476), (8, 0.02121239621192217), (46, 0.024249200243502855), (48, 0.024959954200312495), (10, 0.025011172285303473), (15, 0.025346860522404313), (47, 0.025748152285814285), (49, 0.025855822023004293), (50, 0.026750093791633844), (51, 0.029666296672075987), (12, 0.029917373787611723), (5, 0.03229527361690998), (6, 0.03309072973206639), (4, 0.03808321012184024), (3, 0.04270948003977537), (52, 0.046549045480787754), (13, 0.04714495223015547), (2, 0.05966436164453626), (1, 0.06779658608138561), (0, 0.14225247874855995), (36, 0.2700483873486519), (18, 0.2714092284440994), (53, 0.8599310740828514)]
computing accuracy for after removing block 16 . block score: 0.014943927992135286
removed block 16 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 32, with score 0.015216. All blocks and scores: [(32, 0.015215516090393066), (40, 0.015507499920204282), (30, 0.016437861835584044), (39, 0.01679741172119975), (24, 0.017183786258101463), (34, 0.017221275717020035), (43, 0.01736578089185059), (14, 0.01740242587402463), (37, 0.017607250483706594), (42, 0.017649543937295675), (44, 0.017707698047161102), (38, 0.01807920355349779), (45, 0.019709487911313772), (41, 0.020695810904726386), (7, 0.02096619550138712), (8, 0.02121239621192217), (46, 0.023497753543779254), (48, 0.024401120143011212), (10, 0.025011172518134117), (15, 0.025346860522404313), (49, 0.025412619346752763), (47, 0.025514915818348527), (50, 0.026045311242341995), (51, 0.02869546739384532), (12, 0.02991737355478108), (5, 0.03229527408257127), (6, 0.033090727869421244), (4, 0.03808320965617895), (3, 0.042709479574114084), (52, 0.04533216916024685), (13, 0.04714495223015547), (2, 0.05966435931622982), (1, 0.06779658794403076), (0, 0.14225247502326965), (36, 0.26799434795975685), (18, 0.2759600915014744), (53, 0.8598221689462662)]
computing accuracy for after removing block 32 . block score: 0.015215516090393066
removed block 32 current accuracy 0.9786 loss from initial  0.021399999999999975
training start
training epoch 0 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 2 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 3 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 4 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 5 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 6 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 7 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 8 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 9 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 10 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 11 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 12 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 13 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 14 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 17 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 19 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 20 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 21 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 24 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 25 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 26 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 27 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 28 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 29 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 30 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 31 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 32 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 35 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 36 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 37 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 40 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 41 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 42 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 44 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 45 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 46 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 47 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 48 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.999200)
finished training. finished 50 epochs. accuracy 0.9992 topk_dict {'top1': 0.9992}
start iteration 18
[activation diff]: block to remove picked: 40, with score 0.015819. All blocks and scores: [(40, 0.015818547806702554), (39, 0.017558846157044172), (44, 0.01770486542955041), (43, 0.017831379547715187), (41, 0.018423282774165273), (37, 0.01856281445361674), (45, 0.0187046374194324), (42, 0.01871177786961198), (38, 0.019534412771463394), (14, 0.019997339695692062), (24, 0.02029993385076523), (34, 0.021624693414196372), (8, 0.022065508412197232), (7, 0.02234192145988345), (46, 0.02389910537749529), (30, 0.024084068834781647), (49, 0.02555389190092683), (47, 0.026085826568305492), (48, 0.026267974404618144), (15, 0.026286220410838723), (10, 0.026879946468397975), (50, 0.027463229605928063), (51, 0.030534107703715563), (12, 0.031357479048892856), (5, 0.0323345810174942), (6, 0.03287362493574619), (4, 0.037746828980743885), (3, 0.04088456463068724), (52, 0.05248976359143853), (13, 0.05351863009855151), (2, 0.05687469057738781), (1, 0.06351183215156198), (0, 0.13143951818346977), (36, 0.25867222249507904), (18, 0.2721564546227455), (53, 0.8767973482608795)]
computing accuracy for after removing block 40 . block score: 0.015818547806702554
removed block 40 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.017559. All blocks and scores: [(39, 0.01755884545855224), (44, 0.018124723806977272), (43, 0.018477352801710367), (37, 0.018562813522294164), (45, 0.01881435327231884), (38, 0.01953441253863275), (41, 0.01968545140698552), (42, 0.01971357990987599), (14, 0.019997339230030775), (24, 0.02029993338510394), (34, 0.021624694112688303), (8, 0.022065508412197232), (7, 0.02234192076139152), (30, 0.02408406906761229), (46, 0.02450409485027194), (49, 0.02597220498137176), (48, 0.025998656172305346), (47, 0.026131593389436603), (15, 0.026286219945177436), (10, 0.026879946934059262), (50, 0.02808671980164945), (51, 0.03106930712237954), (12, 0.03135747951455414), (5, 0.032334580551832914), (6, 0.03287362540140748), (4, 0.0377468285150826), (3, 0.0408845660276711), (52, 0.05200308375060558), (13, 0.05351863009855151), (2, 0.05687469011172652), (1, 0.06351183215156198), (0, 0.13143951632082462), (36, 0.25867222994565964), (18, 0.2721564620733261), (53, 0.8946133404970169)]
computing accuracy for after removing block 39 . block score: 0.01755884545855224
removed block 39 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.018297. All blocks and scores: [(44, 0.018296786583960056), (37, 0.018562813755124807), (43, 0.01872712722979486), (45, 0.018869871040806174), (38, 0.01953441323712468), (14, 0.019997338764369488), (41, 0.02024510526098311), (24, 0.02029993385076523), (42, 0.02152783516794443), (34, 0.021624692948535085), (8, 0.022065508412197232), (7, 0.02234192076139152), (30, 0.02408406976610422), (46, 0.0250886722933501), (48, 0.025699513033032417), (47, 0.026173800695687532), (15, 0.026286219712346792), (49, 0.0263957679271698), (10, 0.02687994670122862), (50, 0.028117384063079953), (51, 0.030711419647559524), (12, 0.03135747998021543), (5, 0.0323345810174942), (6, 0.032873624470084906), (4, 0.0377468285150826), (3, 0.040884565096348524), (52, 0.05254518939182162), (13, 0.053518629632890224), (2, 0.05687469244003296), (1, 0.06351183075457811), (0, 0.13143952004611492), (36, 0.25867222249507904), (18, 0.2721564583480358), (53, 0.8944003134965897)]
computing accuracy for after removing block 44 . block score: 0.018296786583960056
removed block 44 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 37, with score 0.018563. All blocks and scores: [(37, 0.01856281398795545), (43, 0.01872712722979486), (38, 0.019534412305802107), (14, 0.019997339695692062), (41, 0.02024510526098311), (24, 0.02029993338510394), (45, 0.020427119452506304), (42, 0.021527835400775075), (34, 0.02162469318136573), (8, 0.022065508412197232), (7, 0.022341920295730233), (30, 0.024084068834781647), (48, 0.025833847699686885), (15, 0.026286220410838723), (46, 0.026552245020866394), (47, 0.026665110141038895), (49, 0.026681707939133048), (10, 0.026879946468397975), (50, 0.02816883334890008), (51, 0.030633632326498628), (12, 0.03135747951455414), (5, 0.032334581948816776), (6, 0.03287362493574619), (4, 0.0377468285150826), (3, 0.04088456463068724), (52, 0.0508074932731688), (13, 0.053518629632890224), (2, 0.05687469057738781), (1, 0.06351183168590069), (0, 0.13143951445817947), (36, 0.25867222249507904), (18, 0.2721564546227455), (53, 0.951690211892128)]
computing accuracy for after removing block 37 . block score: 0.01856281398795545
removed block 37 current accuracy 0.9874 loss from initial  0.012599999999999945
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 43, with score 0.018106. All blocks and scores: [(43, 0.018105740193277597), (45, 0.01949838874861598), (14, 0.01999733899720013), (41, 0.02001521992497146), (24, 0.02029993338510394), (38, 0.020964642288163304), (34, 0.021624693414196372), (42, 0.022027329774573445), (8, 0.022065508645027876), (7, 0.022341920994222164), (30, 0.024084068601951003), (48, 0.02415840420871973), (49, 0.025233554653823376), (47, 0.025390854105353355), (46, 0.025802179239690304), (15, 0.026286220410838723), (50, 0.02639284636825323), (10, 0.02687994739972055), (51, 0.028266933746635914), (12, 0.03135747998021543), (5, 0.03233458148315549), (6, 0.03287362400442362), (4, 0.0377468285150826), (3, 0.04088456416502595), (52, 0.04520277073606849), (13, 0.053518631495535374), (2, 0.05687469011172652), (1, 0.0635118312202394), (0, 0.13143951632082462), (36, 0.25867222249507904), (18, 0.2721564583480358), (53, 0.9976469948887825)]
computing accuracy for after removing block 43 . block score: 0.018105740193277597
removed block 43 current accuracy 0.9746 loss from initial  0.025399999999999978
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.019948. All blocks and scores: [(45, 0.01994849368929863), (14, 0.01999733899720013), (41, 0.020015220157802105), (24, 0.02029993385076523), (38, 0.020964642288163304), (34, 0.02162469318136573), (42, 0.022027330473065376), (8, 0.022065508412197232), (7, 0.022341921227052808), (48, 0.02352383267134428), (30, 0.024084068601951003), (49, 0.02527707302942872), (47, 0.025803869357332587), (50, 0.026167486794292927), (15, 0.02628622017800808), (10, 0.02687994623556733), (46, 0.027029370423406363), (51, 0.02764217951335013), (12, 0.03135747951455414), (5, 0.0323345810174942), (6, 0.03287362586706877), (4, 0.03774682944640517), (3, 0.040884565096348524), (52, 0.04333686688914895), (13, 0.053518629632890224), (2, 0.056874689646065235), (1, 0.06351183075457811), (0, 0.13143951632082462), (36, 0.25867222994565964), (18, 0.2721564583480358), (53, 1.0643123537302017)]
computing accuracy for after removing block 45 . block score: 0.01994849368929863
removed block 45 current accuracy 0.9622 loss from initial  0.037799999999999945
since last training loss: 0.03699999999999992 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 14, with score 0.019997. All blocks and scores: [(14, 0.019997338764369488), (41, 0.020015219459310174), (24, 0.020299933152273297), (38, 0.020964642288163304), (34, 0.02162469318136573), (42, 0.0220273295417428), (8, 0.022065508412197232), (7, 0.022341920295730233), (30, 0.02408406836912036), (48, 0.02471565129235387), (15, 0.026286219945177436), (49, 0.026521546067669988), (10, 0.026879947632551193), (50, 0.026971602579578757), (47, 0.027250279672443867), (51, 0.028297307202592492), (46, 0.030711951898410916), (12, 0.031357479048892856), (5, 0.032334580551832914), (6, 0.03287362400442362), (4, 0.0377468285150826), (3, 0.04088456463068724), (52, 0.043064295779913664), (13, 0.05351862870156765), (2, 0.05687469011172652), (1, 0.06351183261722326), (0, 0.13143951445817947), (36, 0.25867222994565964), (18, 0.2721564546227455), (53, 1.140930250287056)]
computing accuracy for after removing block 14 . block score: 0.019997338764369488
removed block 14 current accuracy 0.9444 loss from initial  0.05559999999999998
since last training loss: 0.05479999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.020214. All blocks and scores: [(38, 0.020213651936501265), (41, 0.02042412362061441), (24, 0.020616167224943638), (34, 0.020907604601234198), (42, 0.021680255653336644), (8, 0.02206550887785852), (7, 0.022341919830068946), (30, 0.02354568662121892), (48, 0.024298632750287652), (50, 0.026829633628949523), (10, 0.02687994670122862), (47, 0.02714861067943275), (49, 0.027265169890597463), (51, 0.02772744558751583), (15, 0.0286461990326643), (12, 0.03135747951455414), (46, 0.03141478053294122), (5, 0.03233458008617163), (6, 0.03287362540140748), (4, 0.03774682804942131), (3, 0.04088456695899367), (52, 0.042265099473297596), (13, 0.05351863009855151), (2, 0.056874692905694246), (1, 0.06351183075457811), (0, 0.13143951818346977), (36, 0.268188051879406), (18, 0.2840144447982311), (53, 1.1145821511745453)]
computing accuracy for after removing block 38 . block score: 0.020213651936501265
removed block 38 current accuracy 0.9218 loss from initial  0.07820000000000005
since last training loss: 0.07740000000000002 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.020616. All blocks and scores: [(24, 0.0206161686219275), (34, 0.02090760483406484), (41, 0.02109431428834796), (8, 0.022065508645027876), (7, 0.022341920994222164), (42, 0.022540101315826178), (48, 0.02303633908741176), (30, 0.023545686854049563), (50, 0.025401436258107424), (51, 0.02593449200503528), (47, 0.026179292239248753), (49, 0.026503956178203225), (10, 0.02687994739972055), (15, 0.028646199265494943), (46, 0.03104954631999135), (12, 0.03135747858323157), (5, 0.0323345810174942), (6, 0.032873624470084906), (4, 0.037746828980743885), (52, 0.038205983117222786), (3, 0.04088456695899367), (13, 0.053518631029874086), (2, 0.0568746910430491), (1, 0.06351183028891683), (0, 0.13143951632082462), (36, 0.2681880481541157), (18, 0.2840144410729408), (53, 1.1513271778821945)]
computing accuracy for after removing block 24 . block score: 0.0206161686219275
removed block 24 current accuracy 0.9044 loss from initial  0.09560000000000002
training start
training epoch 0 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 1 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best True lr [0.001]
training epoch 2 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 3 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 4 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 5 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 6 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 7 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 8 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 9 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 10 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best False lr [0.001]
training epoch 11 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 12 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 13 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 14 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 15 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 16 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 17 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 18 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 19 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 20 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 21 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 22 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 23 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 24 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 25 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 26 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 27 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 28 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 29 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 30 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 31 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 32 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 33 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 34 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 35 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 36 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 37 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 38 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 39 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 40 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 41 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 42 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 43 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 44 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 45 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 46 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 47 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 48 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 49 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.991800)
finished training. finished 50 epochs. accuracy 0.9918 topk_dict {'top1': 0.9918}
