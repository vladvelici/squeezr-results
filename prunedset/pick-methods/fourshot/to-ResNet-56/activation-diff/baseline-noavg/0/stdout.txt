start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101632449776), (24, 0.006592476915102452), (25, 0.0076017758110538125), (21, 0.008612961391918361), (27, 0.00896506942808628), (5, 0.009674609289504588), (23, 0.011229233117774129), (19, 0.01145498757250607), (35, 0.011519728694111109), (32, 0.013281174935400486), (29, 0.014178815414197743), (20, 0.014508438762277365), (31, 0.014615894411690533), (3, 0.014681299799121916), (26, 0.014724894892424345), (30, 0.014915360603481531), (7, 0.015097478521056473), (28, 0.016234831884503365), (37, 0.018546362640336156), (33, 0.02161785331554711), (39, 0.021876287879422307), (6, 0.022251416463404894), (50, 0.022445981623604894), (34, 0.022565887309610844), (49, 0.022602886660024524), (8, 0.023474456975236535), (38, 0.023851263104006648), (41, 0.024523034691810608), (40, 0.024661971488967538), (1, 0.025388095062226057), (46, 0.02624473161995411), (45, 0.026683186646550894), (48, 0.026970999082550406), (44, 0.02806173008866608), (51, 0.02873983816243708), (42, 0.028769567608833313), (43, 0.030795483849942684), (47, 0.031195558374747634), (0, 0.03271650895476341), (13, 0.03601941978558898), (15, 0.04315127898007631), (14, 0.043412636034190655), (16, 0.04433065978810191), (12, 0.04965688334777951), (4, 0.05115430895239115), (11, 0.052178621757775545), (52, 0.05327532719820738), (2, 0.05518383253365755), (10, 0.06016709888353944), (9, 0.08553026523441076), (17, 0.18986638635396957), (18, 0.2766866199672222), (36, 0.2898172102868557), (53, 0.8816948309540749)]
computing accuracy for after removing block 22 . block score: 0.005787101632449776
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.006946946610696614), (25, 0.007925601676106453), (21, 0.008612961508333683), (27, 0.008884541573934257), (5, 0.009674609638750553), (19, 0.011454987688921392), (23, 0.011499474057927728), (35, 0.011587338638491929), (32, 0.013315335963852704), (29, 0.014122492400929332), (20, 0.014508438180200756), (31, 0.014535366441123188), (3, 0.01468130003195256), (30, 0.014953501988202333), (7, 0.015097477938979864), (26, 0.015386730199679732), (28, 0.01665737177245319), (37, 0.018698561936616898), (33, 0.02183614973910153), (6, 0.022251416696235538), (39, 0.022278543561697006), (50, 0.0223967214114964), (34, 0.02257942408323288), (49, 0.02258834894746542), (8, 0.023474457440897822), (38, 0.024010848719626665), (41, 0.024710635421797633), (40, 0.024832446593791246), (1, 0.025388096226379275), (46, 0.026328841457143426), (45, 0.026519648963585496), (48, 0.02686534752137959), (51, 0.028594730654731393), (44, 0.028690783539786935), (42, 0.028934543719515204), (47, 0.030598992248997092), (43, 0.03088917676359415), (0, 0.03271650802344084), (13, 0.03601941978558898), (15, 0.04315127898007631), (14, 0.04341263696551323), (16, 0.0443306602537632), (12, 0.04965688521042466), (4, 0.051154307555407286), (11, 0.05217862315475941), (52, 0.05274482071399689), (2, 0.0551838343963027), (10, 0.06016709981486201), (9, 0.08553026244044304), (17, 0.18986639194190502), (18, 0.2766866236925125), (36, 0.29418329894542694), (53, 0.8765672668814659)]
computing accuracy for after removing block 24 . block score: 0.006946946610696614
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.007964791730046272), (27, 0.00850203714799136), (21, 0.008612961508333683), (5, 0.009674609638750553), (35, 0.01112444803584367), (19, 0.011454987921752036), (23, 0.01149947417434305), (32, 0.012667875504121184), (29, 0.013618954923003912), (31, 0.014255343121476471), (30, 0.014440408791415393), (20, 0.014508438762277365), (3, 0.014681299915537238), (7, 0.015097477938979864), (26, 0.015341690857894719), (28, 0.01654152455739677), (37, 0.01884897705167532), (34, 0.02149180113337934), (33, 0.021746610989794135), (50, 0.022144784219563007), (6, 0.022251416696235538), (49, 0.02257367572747171), (39, 0.022594626061618328), (8, 0.02347445674240589), (38, 0.02391935046762228), (41, 0.024731411365792155), (40, 0.02521214378066361), (1, 0.025388095760717988), (45, 0.02628527325578034), (46, 0.026299894554540515), (48, 0.026813949923962355), (51, 0.028448980767279863), (44, 0.028867241693660617), (42, 0.02887698565609753), (47, 0.030472575686872005), (43, 0.03083793236874044), (0, 0.03271650895476341), (13, 0.03601941978558898), (15, 0.043151278514415026), (14, 0.043412636034190655), (16, 0.044330660719424486), (12, 0.0496568875387311), (4, 0.051154309418052435), (11, 0.052178621757775545), (52, 0.05221219267696142), (2, 0.05518383486196399), (10, 0.06016709702089429), (9, 0.08553026616573334), (17, 0.18986638449132442), (18, 0.2766866199672222), (36, 0.295624066144228), (53, 0.8761104643344879)]
computing accuracy for after removing block 25 . block score: 0.007964791730046272
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.00820748379919678), (21, 0.008612961391918361), (5, 0.009674609638750553), (35, 0.010663895984180272), (19, 0.011454987688921392), (23, 0.011499474407173693), (32, 0.012014233274385333), (29, 0.012787628686055541), (31, 0.01386567682493478), (30, 0.013961306540295482), (20, 0.014508438645862043), (3, 0.014681300148367882), (26, 0.014919800916686654), (7, 0.015097478637471795), (28, 0.01572392089292407), (37, 0.01879318873398006), (34, 0.020361810689792037), (33, 0.021328614559024572), (50, 0.02163330325856805), (49, 0.02223234553821385), (6, 0.02225141692906618), (39, 0.02252841927111149), (8, 0.02347445674240589), (38, 0.023843124508857727), (41, 0.024403041228652), (40, 0.025254084262996912), (1, 0.025388095062226057), (45, 0.02569323475472629), (46, 0.02590800356119871), (48, 0.02639063890092075), (51, 0.027748762629926205), (42, 0.028475591680034995), (44, 0.028856614604592323), (47, 0.029799402225762606), (43, 0.03020182903856039), (0, 0.03271650895476341), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.04341263696551323), (16, 0.04433065978810191), (12, 0.04965688334777951), (52, 0.050796679221093655), (4, 0.05115430802106857), (11, 0.05217862082645297), (2, 0.055183832067996264), (10, 0.0601671002805233), (9, 0.08553026802837849), (17, 0.18986638262867928), (18, 0.2766866162419319), (36, 0.2947889678180218), (53, 0.8695808574557304)]
computing accuracy for after removing block 27 . block score: 0.00820748379919678
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.00861296127550304), (5, 0.009674609755165875), (35, 0.010487184976227582), (19, 0.01145498815458268), (23, 0.011499474057927728), (32, 0.011747056618332863), (29, 0.012900045490823686), (31, 0.013738625450059772), (30, 0.013831986230798066), (20, 0.014508438529446721), (3, 0.01468130003195256), (26, 0.01491980068385601), (7, 0.015097478404641151), (28, 0.01626567356288433), (37, 0.01866634958423674), (34, 0.02014545490965247), (50, 0.021326793590560555), (33, 0.02158285747282207), (49, 0.022118564462289214), (6, 0.022251416696235538), (39, 0.0222895669285208), (8, 0.023474457440897822), (38, 0.02361668087542057), (41, 0.02451603813096881), (40, 0.02536682435311377), (45, 0.02536774007603526), (1, 0.02538809599354863), (46, 0.025604827562347054), (48, 0.026125093223527074), (51, 0.027203565929085016), (42, 0.02829334605485201), (44, 0.02932620490901172), (47, 0.029351704055443406), (43, 0.030030404217541218), (0, 0.032716508489102125), (13, 0.03601942025125027), (15, 0.04315127758309245), (14, 0.04341263649985194), (16, 0.04433065978810191), (12, 0.04965688521042466), (52, 0.05003825528547168), (4, 0.05115430802106857), (11, 0.05217862268909812), (2, 0.05518383486196399), (10, 0.06016709841787815), (9, 0.08553026523441076), (17, 0.18986639194190502), (18, 0.2766866236925125), (36, 0.29525746405124664), (53, 0.8683891594409943)]
computing accuracy for after removing block 21 . block score: 0.00861296127550304
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.009674609755165875), (35, 0.010542472125962377), (19, 0.011454987921752036), (23, 0.011545549728907645), (32, 0.01169671502429992), (29, 0.013034457922913134), (30, 0.013541992637328804), (31, 0.01366134756244719), (20, 0.014508438645862043), (26, 0.014561282121576369), (3, 0.014681300381198525), (7, 0.015097478404641151), (28, 0.01627222285605967), (37, 0.018855378031730652), (34, 0.02017069421708584), (50, 0.021195362089201808), (33, 0.021736358059570193), (49, 0.022025791462510824), (6, 0.02225141739472747), (39, 0.022593395318835974), (8, 0.023474456975236535), (38, 0.0237947222776711), (41, 0.024486313806846738), (45, 0.02517408598214388), (1, 0.025388095527887344), (46, 0.02559636766090989), (40, 0.02570292539894581), (48, 0.02593583008274436), (51, 0.026903111953288317), (42, 0.028371039079502225), (47, 0.029131258139386773), (44, 0.029263161588460207), (43, 0.030276519246399403), (0, 0.03271650802344084), (13, 0.03601942025125027), (15, 0.04315127898007631), (14, 0.04341263510286808), (16, 0.0443306602537632), (52, 0.04949297895655036), (12, 0.04965688521042466), (4, 0.05115430802106857), (11, 0.05217862222343683), (2, 0.0551838343963027), (10, 0.06016709888353944), (9, 0.08553026337176561), (17, 0.18986638262867928), (18, 0.2766866199672222), (36, 0.2977275960147381), (53, 0.8672097474336624)]
computing accuracy for after removing block 5 . block score: 0.009674609755165875
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.011179. All blocks and scores: [(35, 0.011178507935255766), (19, 0.011530683725140989), (23, 0.013430062681436539), (32, 0.013754014042206109), (29, 0.014355180668644607), (3, 0.014637765823863447), (20, 0.014684247085824609), (26, 0.014833459863439202), (31, 0.01488834829069674), (30, 0.015740763628855348), (28, 0.016555308364331722), (7, 0.01846068538725376), (37, 0.018701122840866446), (39, 0.021829769015312195), (50, 0.02221990213729441), (34, 0.02235067170113325), (33, 0.022467669565230608), (49, 0.022547621047124267), (38, 0.02371688815765083), (6, 0.024278968339785933), (41, 0.024561561178416014), (40, 0.0250924292486161), (8, 0.025100581347942352), (1, 0.025184644386172295), (46, 0.026637407718226314), (45, 0.026830078568309546), (48, 0.02707875636406243), (44, 0.027939605759456754), (51, 0.028521460480988026), (42, 0.02880442887544632), (43, 0.03047315706498921), (47, 0.0306412719655782), (0, 0.03229591250419617), (13, 0.03411515522748232), (14, 0.042333492543548346), (15, 0.042880378663539886), (16, 0.04515989404171705), (12, 0.049907654989510775), (4, 0.0508204004727304), (11, 0.05219573527574539), (52, 0.05455241957679391), (2, 0.05560993915423751), (10, 0.06234064884483814), (9, 0.08350299578160048), (17, 0.19132849760353565), (18, 0.2772461920976639), (36, 0.2918630465865135), (53, 0.8780602365732193)]
computing accuracy for after removing block 35 . block score: 0.011178507935255766
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011531. All blocks and scores: [(19, 0.011530683492310345), (23, 0.013430062448605895), (32, 0.013754014507867396), (29, 0.014355180785059929), (3, 0.014637764892540872), (20, 0.014684246852993965), (26, 0.01483345974702388), (31, 0.014888348407112062), (30, 0.015740763628855348), (28, 0.016555308364331722), (7, 0.018460684921592474), (37, 0.01860359823331237), (39, 0.021906087873503566), (50, 0.022323095938190818), (34, 0.022350671933963895), (33, 0.022467669565230608), (49, 0.022507636807858944), (38, 0.022962343646213412), (6, 0.024278969503939152), (41, 0.024495104793459177), (40, 0.024881202960386872), (8, 0.025100581347942352), (1, 0.02518464415334165), (46, 0.026328924112021923), (45, 0.026702115312218666), (48, 0.02688028523698449), (44, 0.02764422306790948), (51, 0.028564995154738426), (42, 0.02873725607059896), (43, 0.029948211507871747), (47, 0.030237341998144984), (0, 0.03229591343551874), (13, 0.034115156158804893), (14, 0.04233349300920963), (15, 0.0428803781978786), (16, 0.04515989450737834), (12, 0.049907653126865625), (4, 0.0508204004727304), (11, 0.05219573574140668), (52, 0.053875249810516834), (2, 0.05560993775725365), (10, 0.06234064791351557), (9, 0.08350299298763275), (17, 0.1913285069167614), (18, 0.2772461995482445), (36, 0.29292264580726624), (53, 0.8797507956624031)]
computing accuracy for after removing block 19 . block score: 0.011530683492310345
removed block 19 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.013395. All blocks and scores: [(32, 0.013395431567914784), (23, 0.013402492855675519), (26, 0.013935192255303264), (29, 0.014170192298479378), (31, 0.014277495094574988), (3, 0.014637765125371516), (20, 0.015149225830100477), (30, 0.015427923295646906), (28, 0.01642955793067813), (7, 0.018460684455931187), (37, 0.01859300769865513), (39, 0.021537462947890162), (50, 0.022079203510656953), (49, 0.022138868924230337), (34, 0.02219630777835846), (33, 0.02244085678830743), (38, 0.022526228800415993), (41, 0.02395465108565986), (6, 0.024278969038277864), (40, 0.02483829203993082), (8, 0.025100582046434283), (1, 0.025184644851833582), (46, 0.02568067004904151), (45, 0.026177367893978953), (48, 0.026395618682727218), (44, 0.027027600444853306), (51, 0.02801775000989437), (42, 0.028358090668916702), (43, 0.02935496694408357), (47, 0.030056633288040757), (0, 0.032295912969857454), (13, 0.034115156158804893), (14, 0.04233349300920963), (15, 0.0428803781978786), (16, 0.04515989404171705), (12, 0.04990765452384949), (4, 0.05082040186971426), (11, 0.05219573527574539), (52, 0.052974379155784845), (2, 0.055609938222914934), (10, 0.06234064791351557), (9, 0.08350299019366503), (17, 0.19132849760353565), (18, 0.2772462032735348), (36, 0.28506193682551384), (53, 0.8856744840741158)]
computing accuracy for after removing block 32 . block score: 0.013395431567914784
removed block 32 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.013402. All blocks and scores: [(23, 0.013402492622844875), (26, 0.013935192371718585), (29, 0.0141701924148947), (31, 0.014277495094574988), (3, 0.014637765125371516), (20, 0.015149225946515799), (30, 0.015427922364324331), (28, 0.016429556999355555), (37, 0.01843842351809144), (7, 0.01846068538725376), (34, 0.021844279253855348), (39, 0.021866226568818092), (50, 0.022173865465447307), (38, 0.022193503566086292), (49, 0.022338133305311203), (33, 0.023150994442403316), (41, 0.024139091838151217), (6, 0.02427896880544722), (8, 0.025100581347942352), (1, 0.02518464461900294), (40, 0.025660342071205378), (46, 0.02571907266974449), (45, 0.026117066852748394), (48, 0.026867914712056518), (51, 0.027966166846454144), (44, 0.027978413039818406), (42, 0.028745881048962474), (43, 0.029534404166042805), (47, 0.03044686745852232), (0, 0.03229591250419617), (13, 0.034115155693143606), (14, 0.04233349347487092), (15, 0.042880377266556025), (16, 0.04515989404171705), (12, 0.049907654989510775), (4, 0.050820400938391685), (11, 0.05219573387876153), (52, 0.05255442438647151), (2, 0.05560993682593107), (10, 0.062340646516531706), (9, 0.08350299391895533), (17, 0.19132850877940655), (18, 0.2772461995482445), (36, 0.29524506628513336), (53, 0.8916184678673744)]
computing accuracy for after removing block 23 . block score: 0.013402492622844875
removed block 23 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013151. All blocks and scores: [(26, 0.013150726328603923), (31, 0.01386527984868735), (29, 0.014553168322890997), (3, 0.014637765125371516), (30, 0.015103858662769198), (20, 0.015149225597269833), (28, 0.016323887510225177), (7, 0.018460685154423118), (37, 0.01877353899180889), (34, 0.021424633217975497), (50, 0.021856379695236683), (49, 0.022001413395628333), (38, 0.02237159456126392), (39, 0.022582331905141473), (41, 0.024036796763539314), (6, 0.02427896880544722), (33, 0.02442176826298237), (8, 0.025100581347942352), (1, 0.02518464461900294), (46, 0.02561368723399937), (45, 0.025824460200965405), (40, 0.026066798251122236), (48, 0.026591684902086854), (51, 0.027508232044056058), (44, 0.027639239793643355), (42, 0.028804884292185307), (43, 0.029650561744347215), (47, 0.030107649508863688), (0, 0.03229591343551874), (13, 0.03411515662446618), (14, 0.04233349394053221), (15, 0.042880379129201174), (16, 0.04515989497303963), (12, 0.049907654989510775), (4, 0.0508204004727304), (52, 0.05090434104204178), (11, 0.05219573574140668), (2, 0.055609936360269785), (10, 0.06234064698219299), (9, 0.08350299578160048), (17, 0.19132849760353565), (18, 0.2772461958229542), (36, 0.2977162189781666), (53, 0.8912764340639114)]
computing accuracy for after removing block 26 . block score: 0.013150726328603923
removed block 26 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.013425. All blocks and scores: [(31, 0.013425290817394853), (29, 0.014164036372676492), (30, 0.014523270074278116), (3, 0.014637765241786838), (20, 0.015149226179346442), (28, 0.01793196192011237), (37, 0.018214559415355325), (7, 0.018460684921592474), (34, 0.01977815432474017), (50, 0.021452187793329358), (49, 0.021622895961627364), (38, 0.02162487874738872), (39, 0.022224764106795192), (41, 0.02337024617008865), (6, 0.024278969271108508), (33, 0.024538538185879588), (46, 0.02455797977745533), (45, 0.024671708000823855), (8, 0.025100580882281065), (1, 0.025184644386172295), (48, 0.025831731036305428), (40, 0.02592896460555494), (51, 0.026636367663741112), (44, 0.02751320064999163), (42, 0.028185660485178232), (43, 0.028714539483189583), (47, 0.029488193104043603), (0, 0.03229591250419617), (13, 0.034115155693143606), (14, 0.042333492543548346), (15, 0.042880378663539886), (16, 0.04515989497303963), (52, 0.048707709182053804), (12, 0.04990765359252691), (4, 0.05082040140405297), (11, 0.052195736207067966), (2, 0.05560994008556008), (10, 0.06234064698219299), (9, 0.08350299391895533), (17, 0.1913285031914711), (18, 0.2772462032735348), (36, 0.29126105830073357), (53, 0.8959333375096321)]
computing accuracy for after removing block 31 . block score: 0.013425290817394853
removed block 31 current accuracy 0.9908 loss from initial  0.009199999999999986
training start
training epoch 0 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 1 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 5 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 6 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 8 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 15 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 16 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 19 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 25 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 26 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 38 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 12
[activation diff]: block to remove picked: 3, with score 0.014933. All blocks and scores: [(3, 0.014932505320757627), (20, 0.016818955773487687), (7, 0.01724651036784053), (29, 0.01755192130804062), (37, 0.017880361760035157), (30, 0.018418913474306464), (28, 0.019568461226299405), (39, 0.020857065683230758), (50, 0.021662086946889758), (49, 0.02168990671634674), (34, 0.022917365422472358), (38, 0.023213086649775505), (8, 0.023724188562482595), (41, 0.02383864764124155), (40, 0.02416452905163169), (6, 0.02425202797167003), (33, 0.024516571778804064), (1, 0.024792631389573216), (45, 0.02544952998869121), (46, 0.02562262420542538), (48, 0.025850139558315277), (44, 0.027198371710255742), (42, 0.027732488932088017), (51, 0.02813451667316258), (43, 0.029518197290599346), (47, 0.029573039850220084), (0, 0.03035111236386001), (13, 0.0341534074395895), (14, 0.04221473028883338), (15, 0.042610370088368654), (16, 0.04394821682944894), (12, 0.04962985450401902), (4, 0.05030544055625796), (11, 0.051074698101729155), (52, 0.052817877382040024), (2, 0.054305171594023705), (10, 0.057741216849535704), (9, 0.08131593000143766), (17, 0.18579413555562496), (18, 0.26187748461961746), (36, 0.2846490927040577), (53, 0.8717134594917297)]
computing accuracy for after removing block 3 . block score: 0.014932505320757627
removed block 3 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.016124. All blocks and scores: [(20, 0.016124006593599916), (29, 0.01701647648587823), (30, 0.017994331428781152), (37, 0.018972416641190648), (28, 0.01957154693081975), (7, 0.020344428718090057), (39, 0.020771939773112535), (50, 0.02148584951646626), (49, 0.022216699086129665), (38, 0.022469687508419156), (34, 0.02286480786278844), (6, 0.023754597874358296), (41, 0.024106163065880537), (33, 0.02415082510560751), (8, 0.024492495926097035), (1, 0.024792632088065147), (40, 0.025635598693042994), (45, 0.02565754856914282), (46, 0.025807666825130582), (48, 0.02597175701521337), (44, 0.02682570111937821), (42, 0.027985459892079234), (51, 0.028373146895319223), (47, 0.0296646433416754), (43, 0.029978291364386678), (0, 0.03035111236386001), (13, 0.0316221434623003), (14, 0.03781428001821041), (15, 0.041927422396838665), (16, 0.04230603622272611), (11, 0.05138438381254673), (12, 0.052199728321284056), (52, 0.052824261132627726), (4, 0.05385319283232093), (2, 0.05430517205968499), (10, 0.059533612336963415), (9, 0.08507777657359838), (17, 0.18590178899466991), (18, 0.26027369126677513), (36, 0.28839197009801865), (53, 0.8715593740344048)]
computing accuracy for after removing block 20 . block score: 0.016124006593599916
removed block 20 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 29, with score 0.016811. All blocks and scores: [(29, 0.01681142533197999), (30, 0.01817626692354679), (37, 0.018944184528663754), (28, 0.019240380031988025), (7, 0.020344428485259414), (39, 0.020518034463748336), (50, 0.021128443768247962), (49, 0.021660080645233393), (38, 0.021999611286446452), (34, 0.02296331454999745), (41, 0.023290723329409957), (6, 0.023754597874358296), (45, 0.024004043079912663), (8, 0.024492495693266392), (46, 0.02467650081962347), (1, 0.02479263162240386), (33, 0.02506552287377417), (48, 0.025207040831446648), (44, 0.026418215362355113), (40, 0.026445701019838452), (42, 0.026937016984447837), (51, 0.026996189961209893), (47, 0.02873114519752562), (43, 0.028746704570949078), (0, 0.03035111236386001), (13, 0.0316221434623003), (14, 0.03781428001821041), (15, 0.04192742286249995), (16, 0.04230603436008096), (52, 0.04961596289649606), (11, 0.05138438427820802), (12, 0.052199728321284056), (4, 0.05385319096967578), (2, 0.054305173456668854), (10, 0.059533612336963415), (9, 0.08507777843624353), (17, 0.1859017927199602), (18, 0.26027368754148483), (36, 0.28278757259249687), (53, 0.8666095361113548)]
computing accuracy for after removing block 29 . block score: 0.01681142533197999
removed block 29 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 30, with score 0.018387. All blocks and scores: [(30, 0.01838702359236777), (37, 0.018795925192534924), (28, 0.019240379566326737), (7, 0.020344428485259414), (50, 0.02085362747311592), (39, 0.02094620536081493), (49, 0.021651145769283175), (38, 0.02196385501883924), (34, 0.02254824945703149), (41, 0.02295961999334395), (45, 0.02343654353171587), (6, 0.02375459740869701), (46, 0.02402762626297772), (8, 0.024492494529113173), (1, 0.024792631156742573), (48, 0.024843909544870257), (51, 0.026024964172393084), (33, 0.026076107751578093), (44, 0.027036502957344055), (42, 0.027057648869231343), (40, 0.0272010019980371), (47, 0.028038620483130217), (43, 0.028608887223526835), (0, 0.03035111236386001), (13, 0.03162214392796159), (14, 0.037814279552549124), (15, 0.04192742332816124), (16, 0.04230603529140353), (52, 0.04810268199071288), (11, 0.05138438381254673), (12, 0.05219972878694534), (4, 0.0538531937636435), (2, 0.05430517252534628), (10, 0.05953361373394728), (9, 0.08507777750492096), (17, 0.18590178713202477), (18, 0.26027367264032364), (36, 0.2867344617843628), (53, 0.8683510199189186)]
computing accuracy for after removing block 30 . block score: 0.01838702359236777
removed block 30 current accuracy 0.9896 loss from initial  0.010399999999999965
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 37, with score 0.018850. All blocks and scores: [(37, 0.0188504948746413), (28, 0.019240379566326737), (7, 0.020344428019598126), (50, 0.020745612448081374), (39, 0.021559847285971045), (38, 0.021856911946088076), (49, 0.02193244989030063), (34, 0.022047581151127815), (41, 0.022922541946172714), (45, 0.02315486897714436), (6, 0.023754597874358296), (46, 0.024109977995976806), (8, 0.024492495460435748), (1, 0.024792632088065147), (48, 0.02516827010549605), (51, 0.025801394367590547), (42, 0.0273432161193341), (44, 0.02778931800276041), (47, 0.028126129880547523), (33, 0.02829201309941709), (40, 0.028338223695755005), (43, 0.028670720756053925), (0, 0.030351112131029367), (13, 0.031622142530977726), (14, 0.037814279086887836), (15, 0.04192742286249995), (16, 0.04230603575706482), (52, 0.04670564504340291), (11, 0.051384384743869305), (12, 0.052199728321284056), (4, 0.05385319283232093), (2, 0.05430517252534628), (10, 0.05953361187130213), (9, 0.08507777936756611), (17, 0.18590179458260536), (18, 0.26027368754148483), (36, 0.29750383272767067), (53, 0.8737963438034058)]
computing accuracy for after removing block 37 . block score: 0.0188504948746413
removed block 37 current accuracy 0.9836 loss from initial  0.01639999999999997
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 28, with score 0.019240. All blocks and scores: [(28, 0.01924037910066545), (50, 0.020086635369807482), (7, 0.02034442825242877), (49, 0.020852527348324656), (45, 0.021920221159234643), (34, 0.02204758091829717), (39, 0.022376261418685317), (46, 0.02281921007670462), (41, 0.023003355832770467), (38, 0.023276553954929113), (6, 0.023754597175866365), (48, 0.024051424814388156), (8, 0.024492495693266392), (51, 0.024755692575126886), (1, 0.024792632088065147), (44, 0.025743491481989622), (47, 0.026661558775231242), (42, 0.026711798273026943), (43, 0.02699012798257172), (33, 0.02829201309941709), (40, 0.028893094044178724), (0, 0.030351112596690655), (13, 0.03162214299663901), (14, 0.03781428001821041), (15, 0.04192742379382253), (16, 0.04230603622272611), (52, 0.044450249057263136), (11, 0.05138438241556287), (12, 0.052199726924300194), (4, 0.05385319236665964), (2, 0.05430517252534628), (10, 0.05953361187130213), (9, 0.08507777750492096), (17, 0.1859017964452505), (18, 0.26027369126677513), (36, 0.29750384762883186), (53, 0.8998214080929756)]
computing accuracy for after removing block 28 . block score: 0.01924037910066545
removed block 28 current accuracy 0.9668 loss from initial  0.03320000000000001
training start
training epoch 0 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 1 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 2 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 3 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 4 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 5 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 6 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 7 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 8 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 9 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 10 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 11 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 14 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 16 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 20 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 21 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 24 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 27 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 29 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 32 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 36 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 40 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 42 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 43 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 45 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 47 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 48 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
loading model_best from epoch 19 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 18
[activation diff]: block to remove picked: 7, with score 0.019132. All blocks and scores: [(7, 0.019131797831505537), (50, 0.021236938191577792), (49, 0.021526241907849908), (39, 0.02173066884279251), (38, 0.023718042764812708), (8, 0.02409883332438767), (41, 0.02424712502397597), (46, 0.024754070676863194), (40, 0.024931648513302207), (45, 0.02503932872787118), (48, 0.025831900537014008), (1, 0.026017896365374327), (44, 0.026563710998743773), (6, 0.02670257701538503), (51, 0.02703006425872445), (42, 0.027449842309579253), (34, 0.027855733409523964), (47, 0.029139464255422354), (43, 0.029674314660951495), (0, 0.03128215787000954), (33, 0.03188136639073491), (13, 0.03376322099938989), (16, 0.042013781145215034), (14, 0.04220941849052906), (15, 0.04373993864282966), (12, 0.04888535616919398), (11, 0.05028347531333566), (4, 0.052575250156223774), (52, 0.05307152261957526), (2, 0.05621072417125106), (10, 0.05661801155656576), (9, 0.08175142761319876), (17, 0.18030295334756374), (18, 0.256701298058033), (36, 0.2850012294948101), (53, 0.8620469197630882)]
computing accuracy for after removing block 7 . block score: 0.019131797831505537
removed block 7 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 38, with score 0.020180. All blocks and scores: [(38, 0.02018015435896814), (39, 0.02034269366413355), (50, 0.02035556174814701), (49, 0.02109226258471608), (41, 0.023390700109302998), (46, 0.024057332193478942), (44, 0.024491762509569526), (40, 0.024719009874388576), (45, 0.024863949744030833), (48, 0.025195849128067493), (34, 0.025661705993115902), (1, 0.026017896365374327), (6, 0.026702577248215675), (51, 0.026707565179094672), (42, 0.02672454295679927), (47, 0.028270724462345243), (43, 0.02871096134185791), (33, 0.029265927616506815), (8, 0.029404765693470836), (0, 0.03128215693868697), (13, 0.03182183299213648), (14, 0.037638898473232985), (16, 0.040368573274463415), (15, 0.041985915042459965), (12, 0.04604326467961073), (11, 0.04887693468481302), (52, 0.05197326000779867), (4, 0.052575250156223774), (10, 0.05508876591920853), (2, 0.05621072184294462), (9, 0.08304876834154129), (17, 0.16120212897658348), (18, 0.24505101144313812), (36, 0.27099553868174553), (53, 0.8823002576828003)]
computing accuracy for after removing block 38 . block score: 0.02018015435896814
removed block 38 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.019614. All blocks and scores: [(50, 0.019614212680608034), (49, 0.020048660458996892), (39, 0.02309224847704172), (44, 0.023255179170519114), (48, 0.023332214215770364), (46, 0.023449040250852704), (45, 0.023784562945365906), (41, 0.023936558049172163), (51, 0.02563127619214356), (34, 0.025661705993115902), (1, 0.026017896132543683), (47, 0.02634233725257218), (6, 0.02670257701538503), (42, 0.02670481102541089), (40, 0.026705038035288453), (43, 0.028800116619095206), (33, 0.029265928314998746), (8, 0.02940476522780955), (0, 0.031282157404348254), (13, 0.03182183252647519), (14, 0.037638898473232985), (16, 0.0403685737401247), (15, 0.04198591457679868), (12, 0.046043263748288155), (52, 0.04866568371653557), (11, 0.048876934219151735), (4, 0.05257524969056249), (10, 0.05508876405656338), (2, 0.05621072091162205), (9, 0.08304876647889614), (17, 0.16120213642716408), (18, 0.24505101516842842), (36, 0.27099553868174553), (53, 0.8981825783848763)]
computing accuracy for after removing block 50 . block score: 0.019614212680608034
removed block 50 current accuracy 0.9842 loss from initial  0.015800000000000036
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.020049. All blocks and scores: [(49, 0.020048659993335605), (39, 0.023092249175533652), (44, 0.023255178704857826), (48, 0.023332213051617146), (46, 0.02344904001802206), (45, 0.023784562246873975), (41, 0.023936557583510876), (34, 0.02566170576028526), (1, 0.026017896132543683), (47, 0.026342338416725397), (6, 0.02670257701538503), (42, 0.026704810559749603), (40, 0.026705037336796522), (51, 0.02743634581565857), (43, 0.02880011568777263), (33, 0.02926592784933746), (8, 0.029404766159132123), (0, 0.03128215693868697), (13, 0.031821833457797766), (14, 0.03763889940455556), (16, 0.04036857420578599), (15, 0.0419859136454761), (12, 0.04604326467961073), (52, 0.048724174965173006), (11, 0.0488769356161356), (4, 0.05257524969056249), (10, 0.05508876359090209), (2, 0.05621072184294462), (9, 0.08304876741021872), (17, 0.16120213083922863), (18, 0.24505101703107357), (36, 0.27099553868174553), (53, 1.1085742563009262)]
computing accuracy for after removing block 49 . block score: 0.020048659993335605
removed block 49 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.023092. All blocks and scores: [(39, 0.023092248709872365), (44, 0.02325517893768847), (48, 0.023332214215770364), (46, 0.02344903931953013), (45, 0.023784563643857837), (41, 0.02393655851483345), (34, 0.02566170645877719), (1, 0.026017896132543683), (47, 0.02634233864955604), (6, 0.026702577248215675), (42, 0.026704811258241534), (40, 0.02670503780245781), (43, 0.02880011615343392), (33, 0.02926592738367617), (8, 0.029404764994978905), (51, 0.030277334386482835), (0, 0.03128215647302568), (13, 0.031821832060813904), (14, 0.03763889940455556), (16, 0.04036857420578599), (15, 0.04198591411113739), (12, 0.04604326421394944), (11, 0.04887693468481302), (52, 0.05245289113372564), (4, 0.05257524875923991), (10, 0.05508876591920853), (2, 0.0562107227742672), (9, 0.08304876647889614), (17, 0.16120212711393833), (18, 0.24505101330578327), (36, 0.27099553495645523), (53, 1.3567886799573898)]
computing accuracy for after removing block 39 . block score: 0.023092248709872365
removed block 39 current accuracy 0.9666 loss from initial  0.033399999999999985
since last training loss: 0.03200000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.021465. All blocks and scores: [(48, 0.02146502723917365), (44, 0.022300247568637133), (45, 0.022512498777359724), (46, 0.02287749433889985), (47, 0.024743993068113923), (41, 0.025176081340759993), (34, 0.025661705993115902), (1, 0.026017896132543683), (6, 0.026702577248215675), (42, 0.02728077652864158), (43, 0.028298659482970834), (51, 0.02911020372994244), (40, 0.029251402709633112), (33, 0.029265927616506815), (8, 0.02940476522780955), (0, 0.0312821576371789), (13, 0.03182183299213648), (14, 0.0376388980075717), (16, 0.04036857280880213), (15, 0.04198591457679868), (12, 0.04604326607659459), (11, 0.048876936081796885), (52, 0.04950439929962158), (4, 0.052575248293578625), (10, 0.05508876591920853), (2, 0.0562107227742672), (9, 0.08304876647889614), (17, 0.16120213270187378), (18, 0.24505101330578327), (36, 0.2709955424070358), (53, 1.4562965035438538)]
computing accuracy for after removing block 48 . block score: 0.02146502723917365
removed block 48 current accuracy 0.9496 loss from initial  0.0504
since last training loss: 0.049000000000000044 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 44, with score 0.022300. All blocks and scores: [(44, 0.022300246637314558), (45, 0.022512499475851655), (46, 0.022877493873238564), (47, 0.024743993300944567), (41, 0.025176080409437418), (34, 0.025661706225946546), (1, 0.026017896132543683), (6, 0.026702577248215675), (42, 0.02728077652864158), (43, 0.028298659017309546), (40, 0.029251402243971825), (33, 0.029265928082168102), (8, 0.029404765693470836), (0, 0.031282157404348254), (13, 0.03182183252647519), (51, 0.03210419835522771), (14, 0.037638898473232985), (16, 0.04036857280880213), (15, 0.04198591457679868), (12, 0.04604326328262687), (11, 0.04887693654745817), (4, 0.05257524875923991), (52, 0.05296216532588005), (10, 0.055088766384869814), (2, 0.05621072370558977), (9, 0.08304876554757357), (17, 0.16120213083922863), (18, 0.24505100585520267), (36, 0.2709955461323261), (53, 1.6935410499572754)]
computing accuracy for after removing block 44 . block score: 0.022300246637314558
removed block 44 current accuracy 0.914 loss from initial  0.08599999999999997
since last training loss: 0.08460000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 46, with score 0.024673. All blocks and scores: [(46, 0.02467271313071251), (45, 0.024818687699735165), (41, 0.025176080875098705), (47, 0.025201749056577682), (34, 0.02566170576028526), (1, 0.026017896831035614), (6, 0.02670257701538503), (42, 0.02728077652864158), (43, 0.028298658784478903), (40, 0.02925140201114118), (33, 0.02926592784933746), (8, 0.02940476592630148), (0, 0.0312821576371789), (13, 0.031821832060813904), (51, 0.031866654753685), (14, 0.0376388980075717), (16, 0.0403685737401247), (15, 0.04198591411113739), (12, 0.046043265610933304), (11, 0.048876936081796885), (4, 0.05257524875923991), (52, 0.05258673569187522), (10, 0.0550887668505311), (2, 0.05621072370558977), (9, 0.08304876834154129), (17, 0.16120213456451893), (18, 0.24505100958049297), (36, 0.27099553868174553), (53, 1.7932732999324799)]
computing accuracy for after removing block 46 . block score: 0.02467271313071251
removed block 46 current accuracy 0.8644 loss from initial  0.13560000000000005
since last training loss: 0.1342000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.024819. All blocks and scores: [(45, 0.02481868746690452), (41, 0.02517608110792935), (34, 0.025661706225946546), (1, 0.02601789659820497), (6, 0.026702577248215675), (42, 0.02728077652864158), (47, 0.02770940074697137), (43, 0.02829865925014019), (40, 0.029251401545479894), (33, 0.029265928314998746), (8, 0.029404764994978905), (0, 0.03128215717151761), (13, 0.03182183299213648), (51, 0.03300814097747207), (14, 0.03763889893889427), (16, 0.04036857420578599), (15, 0.04198591271415353), (12, 0.04604326607659459), (11, 0.04887693468481302), (4, 0.05257524875923991), (52, 0.05331331817433238), (10, 0.05508876359090209), (2, 0.05621072510257363), (9, 0.08304876834154129), (17, 0.16120212897658348), (18, 0.24505102075636387), (36, 0.2709955461323261), (53, 2.018706649541855)]
computing accuracy for after removing block 45 . block score: 0.02481868746690452
removed block 45 current accuracy 0.8136 loss from initial  0.1864
training start
training epoch 0 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.001]
training epoch 1 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 2 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best True lr [0.001]
training epoch 3 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best True lr [0.001]
training epoch 4 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best True lr [0.001]
training epoch 5 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 6 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 7 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 8 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 9 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 10 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 11 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 12 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 13 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 14 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 15 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 16 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 17 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 18 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 19 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 20 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 21 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 22 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 23 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 24 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 25 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 26 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 27 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 28 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 29 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 30 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 31 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 32 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 33 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 34 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 35 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 36 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 37 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 38 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 39 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 40 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best False lr [0.001]
training epoch 41 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 42 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 43 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 44 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 45 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 46 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 47 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
training epoch 48 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 49 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.987200)
finished training. finished 50 epochs. accuracy 0.9872 topk_dict {'top1': 0.9872}
