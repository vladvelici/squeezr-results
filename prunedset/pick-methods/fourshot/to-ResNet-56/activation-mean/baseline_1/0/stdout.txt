start iteration 0
[activation mean]: block to remove picked: 35, with score 0.068065. All blocks and scores: [(35, 0.06806544493883848), (34, 0.07155500166118145), (29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (40, 0.1485865917056799), (42, 0.14862949401140213), (39, 0.1502137091010809), (43, 0.15118332393467426), (16, 0.1542689297348261), (44, 0.1568443477153778), (41, 0.15819761157035828), (8, 0.1629196796566248), (38, 0.16311836056411266), (45, 0.16416819021105766), (7, 0.1642463244497776), (37, 0.1721880678087473), (46, 0.17476965300738811), (47, 0.17773926071822643), (0, 0.18282040394842625), (48, 0.18591997772455215), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.20708752237260342), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2280910387635231), (51, 0.26267513632774353), (52, 0.30729563161730766), (1, 0.3230183348059654), (36, 0.4830818697810173), (18, 0.48591700568795204), (53, 0.6321986317634583)]
computing accuracy for after removing block 35 . block score: 0.06806544493883848
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071555. All blocks and scores: [(34, 0.07155500166118145), (29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1475937645882368), (40, 0.14824344776570797), (39, 0.14968669041991234), (43, 0.15022495575249195), (16, 0.1542689297348261), (44, 0.15705609321594238), (41, 0.1583851631730795), (38, 0.16271816939115524), (8, 0.1629196796566248), (45, 0.16294064186513424), (7, 0.1642463244497776), (37, 0.17224120907485485), (46, 0.17422440648078918), (47, 0.17651107348501682), (0, 0.18282040394842625), (48, 0.18564523942768574), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.20694553293287754), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22779344767332077), (51, 0.2625165581703186), (52, 0.3068947494029999), (1, 0.3230183348059654), (36, 0.484864454716444), (18, 0.48591700568795204), (53, 0.6351279094815254)]
computing accuracy for after removing block 34 . block score: 0.07155500166118145
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074390. All blocks and scores: [(29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.14523832313716412), (40, 0.14652326703071594), (43, 0.14793959073722363), (39, 0.14857716858386993), (16, 0.1542689297348261), (44, 0.15653456933796406), (41, 0.15711732022464275), (38, 0.1611128505319357), (45, 0.1615363098680973), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.1709775011986494), (46, 0.17292680777609348), (47, 0.17471239902079105), (0, 0.18282040394842625), (48, 0.1851693782955408), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.2042350433766842), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2266900520771742), (51, 0.2621644251048565), (52, 0.3062927797436714), (1, 0.3230183348059654), (36, 0.48343389481306076), (18, 0.48591700568795204), (53, 0.6365829855203629)]
computing accuracy for after removing block 29 . block score: 0.07439009193331003
removed block 29 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074757. All blocks and scores: [(27, 0.07475671451538801), (32, 0.07766200136393309), (31, 0.08081165514886379), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (33, 0.09446824062615633), (30, 0.09540940541774035), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1416273321956396), (40, 0.14506280422210693), (43, 0.14668023772537708), (39, 0.14681650139391422), (16, 0.1542689297348261), (44, 0.15490625984966755), (41, 0.15599514544010162), (45, 0.15919861383736134), (38, 0.16000054217875004), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.16922264359891415), (46, 0.16999387182295322), (47, 0.1726976167410612), (0, 0.18282040394842625), (48, 0.18339907936751842), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.20185521431267262), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2245034370571375), (51, 0.2610628716647625), (52, 0.3041844554245472), (1, 0.3230183348059654), (36, 0.48202379792928696), (18, 0.48591700568795204), (53, 0.6394148096442223)]
computing accuracy for after removing block 27 . block score: 0.07475671451538801
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.077250. All blocks and scores: [(32, 0.07724968623369932), (31, 0.08117342926561832), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08469565119594336), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (33, 0.09415383636951447), (30, 0.0952159846201539), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.14108119904994965), (40, 0.143192321062088), (43, 0.14595255255699158), (39, 0.14667929895222187), (44, 0.1532077770680189), (16, 0.1542689297348261), (41, 0.15477589331567287), (45, 0.1573938149958849), (38, 0.1598621904850006), (8, 0.1629196796566248), (7, 0.1642463244497776), (46, 0.16795594990253448), (37, 0.16871255822479725), (47, 0.16997651755809784), (48, 0.18075465224683285), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.19900811649858952), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22411376610398293), (51, 0.25980237126350403), (52, 0.3028869405388832), (1, 0.3230183348059654), (36, 0.48296551406383514), (18, 0.48591700568795204), (53, 0.6423995345830917)]
computing accuracy for after removing block 32 . block score: 0.07724968623369932
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081173. All blocks and scores: [(31, 0.08117342926561832), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08469565119594336), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.0952159846201539), (33, 0.09552602842450142), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1386425532400608), (40, 0.14054096303880215), (43, 0.1436892468482256), (39, 0.14488192275166512), (44, 0.15123293921351433), (41, 0.15253233164548874), (16, 0.1542689297348261), (45, 0.15517016500234604), (38, 0.15800295397639275), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.16566774062812328), (46, 0.16586396656930447), (47, 0.16746729612350464), (48, 0.1787626538425684), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.196839589625597), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22219744883477688), (51, 0.257920503616333), (52, 0.3000909201800823), (1, 0.3230183348059654), (36, 0.48227667063474655), (18, 0.48591700568795204), (53, 0.6499040573835373)]
computing accuracy for after removing block 31 . block score: 0.08117342926561832
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation mean]: block to remove picked: 10, with score 0.081667. All blocks and scores: [(10, 0.0816665068268776), (21, 0.08240773342549801), (28, 0.08423226792365313), (13, 0.08846219908446074), (20, 0.09114335104823112), (17, 0.09269931074231863), (30, 0.09462716337293386), (11, 0.09634058829396963), (33, 0.09705741424113512), (9, 0.09796750452369452), (19, 0.09892376326024532), (24, 0.10002083424478769), (26, 0.10150071233510971), (25, 0.10197478346526623), (22, 0.10694666020572186), (14, 0.10855336021631956), (23, 0.10949319507926702), (12, 0.12496982421725988), (15, 0.13145055808126926), (40, 0.14651958644390106), (42, 0.1470299083739519), (39, 0.14762475714087486), (43, 0.150278152897954), (16, 0.1532527655363083), (44, 0.15660778991878033), (41, 0.15769979171454906), (38, 0.16045759059488773), (8, 0.16262085363268852), (7, 0.1638692542910576), (45, 0.1652688104659319), (37, 0.1722030360251665), (46, 0.1754702664911747), (47, 0.17888377234339714), (0, 0.18292646296322346), (48, 0.18680942617356777), (4, 0.18830466456711292), (5, 0.19220188073813915), (3, 0.20241725258529186), (49, 0.207901356741786), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.2288473006337881), (51, 0.263069961220026), (52, 0.31170646473765373), (1, 0.3212628923356533), (36, 0.48032988980412483), (18, 0.4859442859888077), (53, 0.6289017051458359)]
computing accuracy for after removing block 10 . block score: 0.0816665068268776
removed block 10 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.081919. All blocks and scores: [(21, 0.08191905356943607), (28, 0.08420826774090528), (13, 0.08693682588636875), (20, 0.09121189173310995), (17, 0.09369234088808298), (30, 0.09502679668366909), (33, 0.09759871382266283), (11, 0.09785840194672346), (9, 0.09796750452369452), (24, 0.10002587456256151), (26, 0.10076300706714392), (19, 0.10191257670521736), (25, 0.10196964722126722), (22, 0.10668227821588516), (14, 0.1078283628448844), (23, 0.10959011036902666), (12, 0.1199630843475461), (15, 0.13127677515149117), (40, 0.1454030778259039), (39, 0.14603924565017223), (42, 0.14609861187636852), (43, 0.14981896057724953), (16, 0.15349161624908447), (44, 0.15524032898247242), (41, 0.15691697597503662), (38, 0.16037794575095177), (8, 0.16262085363268852), (45, 0.1638092827051878), (7, 0.1638692542910576), (37, 0.16929959505796432), (46, 0.17418414168059826), (47, 0.1783431265503168), (0, 0.18292646296322346), (48, 0.18428733572363853), (4, 0.18830466456711292), (5, 0.19220188073813915), (3, 0.20241725258529186), (49, 0.20895437337458134), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.22713099606335163), (51, 0.26160650700330734), (52, 0.3103732317686081), (1, 0.3212628923356533), (36, 0.47546733170747757), (18, 0.48441876471042633), (53, 0.628418818116188)]
computing accuracy for after removing block 21 . block score: 0.08191905356943607
removed block 21 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.083723. All blocks and scores: [(28, 0.08372335229068995), (13, 0.08693682588636875), (20, 0.09121189173310995), (17, 0.09369234088808298), (30, 0.09503767360001802), (33, 0.09756799135357141), (11, 0.09785840194672346), (9, 0.09796750452369452), (26, 0.09894459135830402), (24, 0.10044529475271702), (25, 0.10102364234626293), (19, 0.10191257670521736), (22, 0.10685270465910435), (14, 0.1078283628448844), (23, 0.10926192533224821), (12, 0.1199630843475461), (15, 0.13127677515149117), (42, 0.14324240386486053), (40, 0.1434861160814762), (39, 0.1445802953094244), (43, 0.1483826357871294), (16, 0.15349161624908447), (44, 0.15453279577195644), (41, 0.15631134621798992), (38, 0.16064637154340744), (45, 0.1615448947995901), (8, 0.16262085363268852), (7, 0.1638692542910576), (37, 0.16963673010468483), (46, 0.17303761094808578), (47, 0.17648905515670776), (48, 0.182632090523839), (0, 0.18292646296322346), (4, 0.18830466456711292), (5, 0.19220188073813915), (3, 0.20241725258529186), (49, 0.20778913423419), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.2258225493133068), (51, 0.26095085963606834), (52, 0.30962715297937393), (1, 0.3212628923356533), (36, 0.4761800840497017), (18, 0.48441876471042633), (53, 0.6276756376028061)]
computing accuracy for after removing block 28 . block score: 0.08372335229068995
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.086937. All blocks and scores: [(13, 0.08693682588636875), (20, 0.09121189173310995), (17, 0.09369234088808298), (30, 0.0951444087550044), (33, 0.09703876823186874), (11, 0.09785840194672346), (9, 0.09796750452369452), (26, 0.09894459135830402), (24, 0.10044529475271702), (25, 0.10102364234626293), (19, 0.10191257670521736), (22, 0.10685270465910435), (14, 0.1078283628448844), (23, 0.10926192533224821), (12, 0.1199630843475461), (15, 0.13127677515149117), (42, 0.1394458469003439), (40, 0.14067549258470535), (39, 0.1414579525589943), (43, 0.1461851093918085), (44, 0.15242254361510277), (16, 0.15349161624908447), (41, 0.1548045352101326), (38, 0.15799052268266678), (45, 0.1582691241055727), (8, 0.16262085363268852), (7, 0.1638692542910576), (37, 0.16672488301992416), (46, 0.1687415298074484), (47, 0.17256356589496136), (48, 0.17992104776203632), (0, 0.18292646296322346), (4, 0.18830466456711292), (5, 0.19220188073813915), (3, 0.20241725258529186), (49, 0.20392919890582561), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.22312480211257935), (51, 0.2590974345803261), (52, 0.3068491406738758), (1, 0.3212628923356533), (36, 0.4743782803416252), (18, 0.48441876471042633), (53, 0.6324239447712898)]
computing accuracy for after removing block 13 . block score: 0.08693682588636875
removed block 13 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.090263. All blocks and scores: [(20, 0.09026305563747883), (17, 0.09411996509879827), (30, 0.0945154968649149), (33, 0.09700319170951843), (11, 0.09785840194672346), (9, 0.09796750452369452), (26, 0.09807217493653297), (24, 0.09964993502944708), (25, 0.09972247295081615), (19, 0.10223655309528112), (22, 0.10657700337469578), (23, 0.10780466627329588), (14, 0.10981230530887842), (12, 0.1199630843475461), (15, 0.1335350051522255), (42, 0.1394787561148405), (40, 0.13951198756694794), (39, 0.1425322461873293), (43, 0.1455825101584196), (44, 0.15163656510412693), (41, 0.1543254554271698), (45, 0.15709933452308178), (38, 0.15834828652441502), (16, 0.15922635421156883), (8, 0.16262085363268852), (7, 0.1638692542910576), (37, 0.1642823163419962), (46, 0.16697999835014343), (47, 0.17055195197463036), (48, 0.17914281599223614), (0, 0.18292646296322346), (4, 0.18830466456711292), (5, 0.19220188073813915), (3, 0.20241725258529186), (49, 0.2031649798154831), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.22128287330269814), (51, 0.25836075469851494), (52, 0.30716731771826744), (1, 0.3212628923356533), (36, 0.4710353910923004), (18, 0.4886895716190338), (53, 0.6306163370609283)]
computing accuracy for after removing block 20 . block score: 0.09026305563747883
removed block 20 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 30, with score 0.092532. All blocks and scores: [(30, 0.09253210946917534), (17, 0.09411996509879827), (33, 0.09659845195710659), (26, 0.09662708919495344), (25, 0.0977926179766655), (11, 0.09785840194672346), (9, 0.09796750452369452), (24, 0.09882428497076035), (19, 0.10223655309528112), (22, 0.10662704054266214), (23, 0.1073594931513071), (14, 0.10981230530887842), (12, 0.1199630843475461), (15, 0.1335350051522255), (42, 0.1368916742503643), (40, 0.13691748678684235), (39, 0.14125561527907848), (43, 0.14274456538259983), (44, 0.1507735252380371), (41, 0.15279053524136543), (45, 0.15440526232123375), (38, 0.1581910029053688), (16, 0.15922635421156883), (8, 0.16262085363268852), (7, 0.1638692542910576), (37, 0.16429924219846725), (46, 0.16620095819234848), (47, 0.16774613596498966), (48, 0.17774182558059692), (0, 0.18292646296322346), (4, 0.18830466456711292), (5, 0.19220188073813915), (49, 0.20079842396080494), (3, 0.20241725258529186), (2, 0.2094015832990408), (6, 0.21389766596257687), (50, 0.21957391873002052), (51, 0.2570316344499588), (52, 0.30566592887043953), (1, 0.3212628923356533), (36, 0.4715293124318123), (18, 0.4886895716190338), (53, 0.6307781115174294)]
computing accuracy for after removing block 30 . block score: 0.09253210946917534
removed block 30 current accuracy 0.9938 loss from initial  0.006199999999999983
training start
training epoch 0 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 2 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 5 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 6 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 12 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 16 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation mean]: block to remove picked: 17, with score 0.095759. All blocks and scores: [(17, 0.09575854521244764), (11, 0.09677237924188375), (9, 0.10203494410961866), (33, 0.10214263945817947), (19, 0.10235517006367445), (24, 0.10492188856005669), (26, 0.10506447032094002), (25, 0.10734409186989069), (14, 0.10906694829463959), (22, 0.11180462781339884), (23, 0.11466370616108179), (12, 0.12212762050330639), (15, 0.13140223734080791), (40, 0.143291637301445), (42, 0.14558842033147812), (39, 0.14666812494397163), (43, 0.14765543676912785), (16, 0.1478532962501049), (44, 0.15525424294173717), (41, 0.15612084046006203), (38, 0.15769656747579575), (45, 0.16331493854522705), (7, 0.1634382102638483), (8, 0.16389216110110283), (37, 0.16894369386136532), (46, 0.17306694947183132), (47, 0.17539740912616253), (0, 0.1808356512337923), (48, 0.18564190715551376), (4, 0.18675794452428818), (5, 0.19137907586991787), (3, 0.2010598536580801), (49, 0.20507095754146576), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.22694358229637146), (51, 0.26282137259840965), (52, 0.30945004150271416), (1, 0.3187404125928879), (36, 0.47593996673822403), (18, 0.47672050073742867), (53, 0.6294830590486526)]
computing accuracy for after removing block 17 . block score: 0.09575854521244764
removed block 17 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 11, with score 0.096772. All blocks and scores: [(11, 0.09677237924188375), (9, 0.10203494410961866), (33, 0.10245892871171236), (19, 0.10250322613865137), (24, 0.10333705600351095), (26, 0.10434104781597853), (25, 0.10708252433687449), (14, 0.10906694829463959), (22, 0.11109167616814375), (23, 0.11214017029851675), (12, 0.12212762050330639), (15, 0.13140223734080791), (40, 0.14362157694995403), (42, 0.14622755907475948), (16, 0.1478532962501049), (39, 0.1482473574578762), (43, 0.1484401933848858), (41, 0.15466703101992607), (44, 0.15547123737633228), (38, 0.1584916990250349), (45, 0.163150854408741), (7, 0.1634382102638483), (8, 0.16389216110110283), (37, 0.16637735068798065), (46, 0.17117780819535255), (47, 0.1738615334033966), (0, 0.1808356512337923), (48, 0.18456237576901913), (4, 0.18675794452428818), (5, 0.19137907586991787), (3, 0.2010598536580801), (49, 0.20346049778163433), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.2249376568943262), (51, 0.26108232140541077), (52, 0.3091016821563244), (1, 0.3187404125928879), (36, 0.47026440501213074), (18, 0.4773026071488857), (53, 0.6271054744720459)]
computing accuracy for after removing block 11 . block score: 0.09677237924188375
removed block 11 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 9, with score 0.102035. All blocks and scores: [(9, 0.10203494410961866), (33, 0.10220213234424591), (24, 0.10225464217364788), (26, 0.10417483374476433), (19, 0.10493514407426119), (25, 0.10581408627331257), (23, 0.10981637611985207), (22, 0.1104827243834734), (14, 0.11446903366595507), (12, 0.12490613292902708), (15, 0.1344102192670107), (40, 0.14474928937852383), (42, 0.14589152671396732), (43, 0.14941838011145592), (16, 0.14969142340123653), (39, 0.1515229493379593), (44, 0.15429033152759075), (41, 0.1553206667304039), (38, 0.16078466549515724), (45, 0.1623967159539461), (7, 0.1634382102638483), (8, 0.16389216110110283), (37, 0.16478630900382996), (46, 0.17052501626312733), (47, 0.17281388118863106), (0, 0.1808356512337923), (48, 0.18409371189773083), (4, 0.18675794452428818), (5, 0.19137907586991787), (3, 0.2010598536580801), (49, 0.20494849979877472), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.22356354258954525), (51, 0.25924062356352806), (52, 0.3071375750005245), (1, 0.3187404125928879), (36, 0.46956100314855576), (18, 0.47885772213339806), (53, 0.6264584809541702)]
computing accuracy for after removing block 9 . block score: 0.10203494410961866
removed block 9 current accuracy 0.9904 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.100235. All blocks and scores: [(24, 0.10023476369678974), (33, 0.1027711071074009), (26, 0.10351954866200686), (25, 0.10449966043233871), (19, 0.10627832170575857), (23, 0.1079968148842454), (22, 0.11013160366564989), (14, 0.11542814131826162), (12, 0.12339329905807972), (15, 0.1359736043959856), (42, 0.14295034669339657), (40, 0.14350171759724617), (43, 0.1470462754368782), (44, 0.15172705054283142), (41, 0.15232793241739273), (39, 0.15276057086884975), (16, 0.1552922036498785), (37, 0.15883279591798782), (45, 0.1588864717632532), (38, 0.1614273078739643), (7, 0.1634382102638483), (8, 0.16389216110110283), (46, 0.1665398608893156), (47, 0.16858973167836666), (48, 0.1788815874606371), (0, 0.1808356512337923), (4, 0.18675794452428818), (5, 0.19137907586991787), (3, 0.2010598536580801), (49, 0.2038668915629387), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.21860584989190102), (51, 0.253637932240963), (52, 0.30168069899082184), (1, 0.3187404125928879), (36, 0.458587821573019), (18, 0.47663871943950653), (53, 0.6265481114387512)]
computing accuracy for after removing block 24 . block score: 0.10023476369678974
removed block 24 current accuracy 0.9834 loss from initial  0.016599999999999948
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 33, with score 0.100238. All blocks and scores: [(33, 0.10023752693086863), (26, 0.10075220372527838), (25, 0.1021055169403553), (19, 0.10627832170575857), (23, 0.1079968148842454), (22, 0.11013160366564989), (14, 0.11542814131826162), (12, 0.12339329905807972), (15, 0.1359736043959856), (40, 0.14077681861817837), (42, 0.14229905791580677), (43, 0.1434011347591877), (44, 0.14906220696866512), (41, 0.15077119879424572), (39, 0.154897915199399), (45, 0.1552434153854847), (16, 0.1552922036498785), (37, 0.15725071169435978), (38, 0.1598082985728979), (46, 0.1622096486389637), (47, 0.16321468539536), (7, 0.1634382102638483), (8, 0.16389216110110283), (48, 0.1761743687093258), (0, 0.1808356512337923), (4, 0.18675794452428818), (5, 0.19137907586991787), (49, 0.19860180281102657), (3, 0.2010598536580801), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.21538490615785122), (51, 0.25244786962866783), (52, 0.30064311623573303), (1, 0.3187404125928879), (36, 0.4601517543196678), (18, 0.47663871943950653), (53, 0.6299568712711334)]
computing accuracy for after removing block 33 . block score: 0.10023752693086863
removed block 33 current accuracy 0.9778 loss from initial  0.022199999999999998
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 26, with score 0.100752. All blocks and scores: [(26, 0.10075220372527838), (25, 0.1021055169403553), (19, 0.10627832170575857), (23, 0.1079968148842454), (22, 0.11013160366564989), (14, 0.11542814131826162), (12, 0.12339329905807972), (15, 0.1359736043959856), (40, 0.1399231292307377), (43, 0.14063042774796486), (42, 0.14264611713588238), (41, 0.14863247238099575), (44, 0.14876767061650753), (45, 0.15345688723027706), (39, 0.15410000644624233), (16, 0.1552922036498785), (37, 0.15643631666898727), (38, 0.1582015622407198), (47, 0.16070673242211342), (46, 0.16118559427559376), (7, 0.1634382102638483), (8, 0.16389216110110283), (48, 0.1757384054362774), (0, 0.1808356512337923), (4, 0.18675794452428818), (5, 0.19137907586991787), (49, 0.1948541533201933), (3, 0.2010598536580801), (2, 0.20857125706970692), (6, 0.21303528919816017), (50, 0.21369016356766224), (51, 0.2520024199038744), (52, 0.29965145140886307), (1, 0.3187404125928879), (36, 0.46608778461813927), (18, 0.47663871943950653), (53, 0.6374702900648117)]
computing accuracy for after removing block 26 . block score: 0.10075220372527838
removed block 26 current accuracy 0.9646 loss from initial  0.03539999999999999
training start
training epoch 0 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 1 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 2 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 3 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 4 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 5 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 6 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 7 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 9 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 10 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 11 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 18 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 20 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 21 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 24 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 27 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 28 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 29 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 30 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 31 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 32 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 33 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 34 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 35 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 36 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 37 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 41 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 42 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 43 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 45 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 46 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 47 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 48 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 49 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 18
[activation mean]: block to remove picked: 19, with score 0.107913. All blocks and scores: [(19, 0.10791336093097925), (14, 0.11647159792482853), (25, 0.12148390617221594), (22, 0.12321486324071884), (12, 0.12415293324738741), (23, 0.12765191867947578), (15, 0.1346445195376873), (40, 0.14177599921822548), (42, 0.14426865428686142), (39, 0.14559739641845226), (43, 0.14667587913572788), (44, 0.1542095933109522), (41, 0.15592359565198421), (38, 0.15703584626317024), (16, 0.15791908279061317), (45, 0.16202455572783947), (7, 0.16248828172683716), (8, 0.1669121291488409), (37, 0.16757827810943127), (46, 0.17200696468353271), (47, 0.17471834272146225), (0, 0.1756419502198696), (48, 0.18273686058819294), (4, 0.18292388319969177), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (49, 0.20351291820406914), (6, 0.2128924559801817), (50, 0.2254692018032074), (51, 0.2612727880477905), (52, 0.3078375905752182), (1, 0.31169842183589935), (18, 0.466721098870039), (36, 0.47439366206526756), (53, 0.640767514705658)]
computing accuracy for after removing block 19 . block score: 0.10791336093097925
removed block 19 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 14, with score 0.116472. All blocks and scores: [(14, 0.11647159792482853), (25, 0.12186023220419884), (22, 0.12384680658578873), (12, 0.12415293324738741), (23, 0.12765978649258614), (15, 0.1346445195376873), (40, 0.140697805210948), (42, 0.14125228859484196), (39, 0.1442582942545414), (43, 0.14428166300058365), (44, 0.15247361548244953), (41, 0.15676840022206306), (38, 0.1575965117663145), (16, 0.15791908279061317), (45, 0.1602601706981659), (7, 0.16248828172683716), (8, 0.1669121291488409), (37, 0.1682315655052662), (46, 0.16993114165961742), (47, 0.1721598170697689), (0, 0.1756419502198696), (48, 0.17964605800807476), (4, 0.18292388319969177), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (49, 0.20271744951605797), (6, 0.2128924559801817), (50, 0.22328426130115986), (51, 0.25683195516467094), (52, 0.3033599369227886), (1, 0.31169842183589935), (18, 0.466721098870039), (36, 0.47720079496502876), (53, 0.642634354531765)]
computing accuracy for after removing block 14 . block score: 0.11647159792482853
removed block 14 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 25, with score 0.119386. All blocks and scores: [(25, 0.11938553676009178), (22, 0.12238345481455326), (12, 0.12415293324738741), (23, 0.12431865837424994), (42, 0.1400591991841793), (40, 0.14151904918253422), (15, 0.14338937401771545), (43, 0.14447960816323757), (39, 0.14558486826717854), (44, 0.15248116850852966), (41, 0.155145812779665), (38, 0.15879316441714764), (45, 0.15917419455945492), (7, 0.16248828172683716), (16, 0.16379491612315178), (37, 0.1661358680576086), (8, 0.1669121291488409), (46, 0.1690395139157772), (47, 0.1705987025052309), (0, 0.1756419502198696), (48, 0.1788699496537447), (4, 0.18292388319969177), (5, 0.18972509913146496), (3, 0.1990012302994728), (49, 0.2004862204194069), (2, 0.20237131975591183), (6, 0.2128924559801817), (50, 0.2212499249726534), (51, 0.25540313869714737), (52, 0.30260737240314484), (1, 0.31169842183589935), (18, 0.46502700448036194), (36, 0.47428664565086365), (53, 0.640382282435894)]
computing accuracy for after removing block 25 . block score: 0.11938553676009178
removed block 25 current accuracy 0.9902 loss from initial  0.009800000000000031
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 22, with score 0.122383. All blocks and scores: [(22, 0.12238345481455326), (12, 0.12415293324738741), (23, 0.12431865837424994), (40, 0.13651862181723118), (42, 0.1374070756137371), (43, 0.1404132954776287), (15, 0.14338937401771545), (39, 0.14496962539851665), (44, 0.14908674359321594), (41, 0.15197587199509144), (45, 0.15393765456974506), (38, 0.15674285404384136), (7, 0.16248828172683716), (47, 0.16278363578021526), (37, 0.16370358876883984), (16, 0.16379491612315178), (46, 0.16447333805263042), (8, 0.1669121291488409), (48, 0.1737342868000269), (0, 0.1756419502198696), (4, 0.18292388319969177), (5, 0.18972509913146496), (49, 0.1936012450605631), (3, 0.1990012302994728), (2, 0.20237131975591183), (6, 0.2128924559801817), (50, 0.21703535690903664), (51, 0.2525124251842499), (52, 0.29847049713134766), (1, 0.31169842183589935), (18, 0.46502700448036194), (36, 0.4785095602273941), (53, 0.6435389593243599)]
computing accuracy for after removing block 22 . block score: 0.12238345481455326
removed block 22 current accuracy 0.9734 loss from initial  0.026599999999999957
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 23, with score 0.121752. All blocks and scores: [(23, 0.12175223883241415), (12, 0.12415293324738741), (43, 0.1374999713152647), (40, 0.13804182596504688), (42, 0.14033719524741173), (15, 0.14338937401771545), (44, 0.14805751107633114), (45, 0.1509046945720911), (39, 0.15100670978426933), (41, 0.15522127225995064), (47, 0.1579003520309925), (38, 0.16034137085080147), (7, 0.16248828172683716), (16, 0.16379491612315178), (46, 0.16431782394647598), (8, 0.1669121291488409), (37, 0.1692032665014267), (48, 0.17156106978654861), (0, 0.1756419502198696), (4, 0.18292388319969177), (49, 0.1892802957445383), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (6, 0.2128924559801817), (50, 0.21444989927113056), (51, 0.25294065847992897), (52, 0.29599741473793983), (1, 0.31169842183589935), (18, 0.46502700448036194), (36, 0.49238303303718567), (53, 0.6421604007482529)]
computing accuracy for after removing block 23 . block score: 0.12175223883241415
removed block 23 current accuracy 0.9346 loss from initial  0.06540000000000001
since last training loss: 0.06420000000000003 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 12, with score 0.124153. All blocks and scores: [(12, 0.12415293324738741), (43, 0.13643553107976913), (40, 0.13890365324914455), (42, 0.14215939119458199), (15, 0.14338937401771545), (44, 0.14501507952809334), (45, 0.14622413739562035), (47, 0.15174809843301773), (41, 0.1583336777985096), (39, 0.1586855798959732), (46, 0.16105286963284016), (7, 0.16248828172683716), (16, 0.16379491612315178), (38, 0.1664585918188095), (8, 0.1669121291488409), (48, 0.16731320321559906), (37, 0.1724356785416603), (0, 0.1756419502198696), (4, 0.18292388319969177), (49, 0.18486233241856098), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (50, 0.21082143858075142), (6, 0.2128924559801817), (51, 0.250493410974741), (52, 0.2909531742334366), (1, 0.31169842183589935), (18, 0.46502700448036194), (36, 0.5032200366258621), (53, 0.6460906639695168)]
computing accuracy for after removing block 12 . block score: 0.12415293324738741
removed block 12 current accuracy 0.9326 loss from initial  0.06740000000000002
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 43, with score 0.134825. All blocks and scores: [(43, 0.13482467830181122), (40, 0.13829954341053963), (42, 0.14057066477835178), (44, 0.14532123319804668), (45, 0.1459413468837738), (15, 0.14953679777681828), (47, 0.15158124268054962), (39, 0.15631456300616264), (41, 0.15697012096643448), (7, 0.16248828172683716), (46, 0.16326230950653553), (38, 0.1666356362402439), (8, 0.1669121291488409), (48, 0.16848020441830158), (16, 0.17100520990788937), (37, 0.17269286140799522), (0, 0.1756419502198696), (4, 0.18292388319969177), (49, 0.18595014326274395), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (50, 0.211096016690135), (6, 0.2128924559801817), (51, 0.2512039244174957), (52, 0.2901722379028797), (1, 0.31169842183589935), (18, 0.46594296395778656), (36, 0.5040769800543785), (53, 0.6525153517723083)]
computing accuracy for after removing block 43 . block score: 0.13482467830181122
removed block 43 current accuracy 0.916 loss from initial  0.08399999999999996
since last training loss: 0.08279999999999998 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 40, with score 0.138300. All blocks and scores: [(40, 0.13829954341053963), (42, 0.14057066477835178), (44, 0.1470106989145279), (45, 0.14818160235881805), (15, 0.14953679777681828), (47, 0.15264259092509747), (39, 0.15631456300616264), (41, 0.15697012096643448), (7, 0.16248828172683716), (46, 0.16537920199334621), (38, 0.1666356362402439), (8, 0.1669121291488409), (48, 0.1701772827655077), (16, 0.17100520990788937), (37, 0.17269286140799522), (0, 0.1756419502198696), (4, 0.18292388319969177), (49, 0.18559687212109566), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (50, 0.21274493634700775), (6, 0.2128924559801817), (51, 0.251550380140543), (52, 0.28752391040325165), (1, 0.31169842183589935), (18, 0.46594296395778656), (36, 0.5040769800543785), (53, 0.6769858077168465)]
computing accuracy for after removing block 40 . block score: 0.13829954341053963
removed block 40 current accuracy 0.8956 loss from initial  0.10440000000000005
since last training loss: 0.10320000000000007 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 42, with score 0.141692. All blocks and scores: [(42, 0.14169168286025524), (44, 0.1455758884549141), (45, 0.14687731489539146), (15, 0.14953679777681828), (47, 0.15186879597604275), (39, 0.15631456300616264), (41, 0.16029789298772812), (7, 0.16248828172683716), (46, 0.16490792110562325), (38, 0.1666356362402439), (8, 0.1669121291488409), (48, 0.16863737627863884), (16, 0.17100520990788937), (37, 0.17269286140799522), (0, 0.1756419502198696), (49, 0.18204955384135246), (4, 0.18292388319969177), (5, 0.18972509913146496), (3, 0.1990012302994728), (2, 0.20237131975591183), (50, 0.20936498418450356), (6, 0.2128924559801817), (51, 0.2479284629225731), (52, 0.2833346799015999), (1, 0.31169842183589935), (18, 0.46594296395778656), (36, 0.5040769800543785), (53, 0.6842300519347191)]
computing accuracy for after removing block 42 . block score: 0.14169168286025524
removed block 42 current accuracy 0.8902 loss from initial  0.10980000000000001
training start
training epoch 0 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best True lr [0.001]
training epoch 1 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 2 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 3 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 4 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 5 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 6 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 7 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 8 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 9 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 10 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 11 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 12 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 13 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 14 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 15 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 16 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 17 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 18 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 19 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 20 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 21 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 22 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 23 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 24 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 25 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 26 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 27 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 28 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 29 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 30 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 31 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 32 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 33 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 34 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 35 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 37 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 38 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 39 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 40 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 42 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 43 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 45 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 46 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 47 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 48 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 49 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.993200)
finished training. finished 50 epochs. accuracy 0.9932 topk_dict {'top1': 0.9932}
