start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054019. All blocks and scores: [(1, 0.05401874938979745), (34, 0.061866582836955786), (2, 0.06475786492228508), (31, 0.06720060762017965), (30, 0.06731617357581854), (35, 0.06825095508247614), (33, 0.07037476543337107), (32, 0.07732165139168501), (26, 0.07798098493367434), (28, 0.08341042045503855), (29, 0.09326864033937454), (25, 0.09926075674593449), (22, 0.09950833860784769), (27, 0.10294455103576183), (24, 0.10354442428797483), (23, 0.10383972246199846), (5, 0.11125390511006117), (14, 0.11721509229391813), (21, 0.1265479288995266), (3, 0.12764153257012367), (17, 0.1317060887813568), (20, 0.13274890556931496), (38, 0.146248584613204), (39, 0.1483139432966709), (16, 0.1503186635673046), (42, 0.1513474602252245), (37, 0.15663454495370388), (19, 0.15664509125053883), (41, 0.15758543461561203), (15, 0.15763606317341328), (40, 0.15781855769455433), (43, 0.15963220037519932), (4, 0.16029647924005985), (0, 0.17056752927601337), (44, 0.1717367023229599), (6, 0.17450461722910404), (13, 0.17458787001669407), (7, 0.17770990170538425), (45, 0.179588433355093), (47, 0.19627228192985058), (46, 0.19685631431639194), (8, 0.1990743726491928), (10, 0.20246456190943718), (12, 0.2052889671176672), (11, 0.20776454359292984), (9, 0.21767907962203026), (49, 0.22418830171227455), (48, 0.22521410137414932), (50, 0.23762784898281097), (51, 0.25685056671500206), (52, 0.2942989207804203), (36, 0.5084430128335953), (18, 0.5554970726370811), (53, 0.6521949768066406)]
computing accuracy for after removing block 1 . block score: 0.05401874938979745
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061784. All blocks and scores: [(34, 0.06178395077586174), (2, 0.06498363334685564), (31, 0.0671510873362422), (30, 0.06738731637597084), (35, 0.06822698190808296), (33, 0.07039163634181023), (32, 0.07726792711764574), (26, 0.07807760033756495), (28, 0.08352132048457861), (29, 0.09340976644307375), (25, 0.09919525776058435), (22, 0.09952599834650755), (27, 0.10326564870774746), (24, 0.10346821788698435), (23, 0.10366112925112247), (5, 0.11025469191372395), (14, 0.11720024887472391), (21, 0.1264019664376974), (3, 0.12822039984166622), (17, 0.13202346116304398), (20, 0.13253550231456757), (38, 0.14596638642251492), (39, 0.14783446677029133), (16, 0.1502179093658924), (42, 0.15124032646417618), (37, 0.1563769429922104), (19, 0.1566394306719303), (15, 0.1573416255414486), (41, 0.15746974758803844), (40, 0.15765290148556232), (43, 0.15933381579816341), (4, 0.1596198696643114), (0, 0.17056752927601337), (44, 0.17190805822610855), (13, 0.1750413067638874), (6, 0.1762730125337839), (45, 0.17932291887700558), (7, 0.1796624306589365), (47, 0.19619962759315968), (46, 0.1970810890197754), (10, 0.2021530196070671), (8, 0.20421498641371727), (12, 0.20567899011075497), (11, 0.20789441838860512), (9, 0.21970454044640064), (49, 0.22410406358540058), (48, 0.22510374709963799), (50, 0.23775307647883892), (51, 0.25690556690096855), (52, 0.29428064450621605), (36, 0.5084273591637611), (18, 0.5557390600442886), (53, 0.6521297469735146)]
computing accuracy for after removing block 34 . block score: 0.06178395077586174
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.064984. All blocks and scores: [(2, 0.06498363334685564), (31, 0.0671510873362422), (30, 0.06738731637597084), (35, 0.06815146654844284), (33, 0.07039163634181023), (32, 0.07726792711764574), (26, 0.07807760033756495), (28, 0.08352132048457861), (29, 0.09340976644307375), (25, 0.09919525776058435), (22, 0.09952599834650755), (27, 0.10326564870774746), (24, 0.10346821788698435), (23, 0.10366112925112247), (5, 0.11025469191372395), (14, 0.11720024887472391), (21, 0.1264019664376974), (3, 0.12822039984166622), (17, 0.13202346116304398), (20, 0.13253550231456757), (38, 0.14242407493293285), (39, 0.14578756876289845), (42, 0.1473459228873253), (16, 0.1502179093658924), (37, 0.15457867458462715), (41, 0.15483219921588898), (43, 0.15608007833361626), (40, 0.15629969350993633), (19, 0.1566394306719303), (15, 0.1573416255414486), (4, 0.1596198696643114), (44, 0.16899384930729866), (0, 0.17056752927601337), (13, 0.1750413067638874), (6, 0.1762730125337839), (45, 0.17868873290717602), (7, 0.1796624306589365), (47, 0.1949667390435934), (46, 0.19536413624882698), (10, 0.2021530196070671), (8, 0.20421498641371727), (12, 0.20567899011075497), (11, 0.20789441838860512), (9, 0.21970454044640064), (49, 0.22241780534386635), (48, 0.22368756122887135), (50, 0.23690163902938366), (51, 0.25510936975479126), (52, 0.29285823553800583), (36, 0.506484217941761), (18, 0.5557390600442886), (53, 0.6576055884361267)]
computing accuracy for after removing block 2 . block score: 0.06498363334685564
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067171. All blocks and scores: [(31, 0.06717052403837442), (30, 0.06770070735365152), (35, 0.06853656843304634), (33, 0.07045937329530716), (32, 0.07728759571909904), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.1427512913942337), (39, 0.1455790363252163), (42, 0.14751579612493515), (16, 0.1500795278698206), (37, 0.15462797693908215), (41, 0.15463546849787235), (43, 0.155882453545928), (40, 0.15648241341114044), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.16945297829806805), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17847860790789127), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.1949198991060257), (46, 0.19539336301386356), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (9, 0.22204345278441906), (49, 0.22231651470065117), (48, 0.22340366803109646), (50, 0.23685323260724545), (51, 0.2551177330315113), (52, 0.2926546782255173), (36, 0.5076062008738518), (18, 0.5585161447525024), (53, 0.6573801562190056)]
computing accuracy for after removing block 31 . block score: 0.06717052403837442
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067701. All blocks and scores: [(30, 0.06770070735365152), (35, 0.06832328625023365), (33, 0.06998600997030735), (32, 0.07691892981529236), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.14124376513063908), (39, 0.1451344545930624), (42, 0.14719805493950844), (16, 0.1500795278698206), (41, 0.1538275834172964), (37, 0.15450537204742432), (43, 0.15520221926271915), (40, 0.15676734037697315), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.16849523596465588), (0, 0.17056752927601337), (13, 0.17503763176500797), (6, 0.17874738574028015), (45, 0.1790821421891451), (7, 0.18173840269446373), (47, 0.19454056397080421), (46, 0.1959428545087576), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.22173571959137917), (9, 0.22204345278441906), (48, 0.22318027541041374), (50, 0.23713134415447712), (51, 0.2552882209420204), (52, 0.29228881001472473), (36, 0.509839341044426), (18, 0.5585161447525024), (53, 0.6598142385482788)]
computing accuracy for after removing block 30 . block score: 0.06770070735365152
removed block 30 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066485. All blocks and scores: [(35, 0.06648518890142441), (33, 0.0697032455354929), (32, 0.0773529801517725), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.13987880758941174), (39, 0.14415700547397137), (42, 0.1466123703867197), (16, 0.1500795278698206), (41, 0.15383746661245823), (37, 0.15544690564274788), (43, 0.1558341272175312), (19, 0.15676895901560783), (15, 0.15711238607764244), (40, 0.15844319015741348), (4, 0.15924772806465626), (44, 0.16802092269062996), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17812410183250904), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.19442151859402657), (46, 0.19502928480505943), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.22065376862883568), (9, 0.22204345278441906), (48, 0.2229733020067215), (50, 0.23717963695526123), (51, 0.2544683553278446), (52, 0.2924013286828995), (36, 0.5146597698330879), (18, 0.5585161447525024), (53, 0.6609868407249451)]
computing accuracy for after removing block 35 . block score: 0.06648518890142441
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.071690. All blocks and scores: [(33, 0.07168966345489025), (26, 0.07787996158003807), (32, 0.07932463195174932), (28, 0.08327107224613428), (29, 0.09324672631919384), (25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.10271034110337496), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.14511667005717754), (39, 0.14705477096140385), (16, 0.1506669782102108), (42, 0.15088973194360733), (40, 0.15631160326302052), (37, 0.15638612769544125), (41, 0.15687490813434124), (19, 0.157118147239089), (15, 0.15718332305550575), (43, 0.15807663649320602), (4, 0.16022039018571377), (44, 0.1705614235252142), (0, 0.17103483527898788), (6, 0.1743504088371992), (13, 0.17572588473558426), (7, 0.17813357710838318), (45, 0.1791818868368864), (46, 0.1956884264945984), (47, 0.19669770635664463), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (9, 0.21840771473944187), (49, 0.2250458374619484), (48, 0.22547714971005917), (50, 0.23731585778295994), (51, 0.25705865025520325), (52, 0.29452335089445114), (36, 0.5015763938426971), (18, 0.5567422136664391), (53, 0.6507446691393852)]
computing accuracy for after removing block 33 . block score: 0.07168966345489025
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.077880. All blocks and scores: [(26, 0.07787996158003807), (32, 0.07932463195174932), (28, 0.08327107224613428), (29, 0.09324672631919384), (25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.10271034110337496), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.14297030679881573), (39, 0.14573324285447598), (42, 0.14893910102546215), (16, 0.1506669782102108), (40, 0.15416381508111954), (41, 0.15434058383107185), (37, 0.15512786991894245), (43, 0.15514671616256237), (19, 0.157118147239089), (15, 0.15718332305550575), (4, 0.16022039018571377), (44, 0.16838677041232586), (0, 0.17103483527898788), (6, 0.1743504088371992), (13, 0.17572588473558426), (7, 0.17813357710838318), (45, 0.17930898256599903), (46, 0.19344030134379864), (47, 0.1940353959798813), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (9, 0.21840771473944187), (49, 0.22254214249551296), (48, 0.22297798097133636), (50, 0.2354623768478632), (51, 0.2546454593539238), (52, 0.2913750112056732), (36, 0.4980050027370453), (18, 0.5567422136664391), (53, 0.6563807129859924)]
computing accuracy for after removing block 26 . block score: 0.07787996158003807
removed block 26 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.078784. All blocks and scores: [(32, 0.07878368254750967), (28, 0.0820171432569623), (29, 0.0929709579795599), (25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.1030255164951086), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.14142784848809242), (39, 0.14343618787825108), (42, 0.1460074707865715), (16, 0.1506669782102108), (43, 0.15259752795100212), (40, 0.15276290476322174), (41, 0.1534629948437214), (37, 0.1544624250382185), (19, 0.157118147239089), (15, 0.15718332305550575), (4, 0.16022039018571377), (44, 0.16681340336799622), (0, 0.17103483527898788), (6, 0.1743504088371992), (13, 0.17572588473558426), (7, 0.17813357710838318), (45, 0.1781607735902071), (46, 0.19084535352885723), (47, 0.19267897680401802), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (9, 0.21840771473944187), (49, 0.2211033795028925), (48, 0.22216492518782616), (50, 0.23552379943430424), (51, 0.2532983683049679), (52, 0.2900161184370518), (36, 0.49778566509485245), (18, 0.5567422136664391), (53, 0.6607798859477043)]
computing accuracy for after removing block 32 . block score: 0.07878368254750967
removed block 32 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.082017. All blocks and scores: [(28, 0.0820171432569623), (29, 0.0929709579795599), (25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.1030255164951086), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.13908099196851254), (39, 0.1419685147702694), (42, 0.14310292713344097), (16, 0.1506669782102108), (37, 0.15192713402211666), (43, 0.1519563440233469), (41, 0.15276754647493362), (40, 0.153540950268507), (19, 0.157118147239089), (15, 0.15718332305550575), (4, 0.16022039018571377), (44, 0.16497032344341278), (0, 0.17103483527898788), (6, 0.1743504088371992), (13, 0.17572588473558426), (45, 0.17785809375345707), (7, 0.17813357710838318), (46, 0.1886373944580555), (47, 0.19085372053086758), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (9, 0.21840771473944187), (49, 0.21891354024410248), (48, 0.22168064676225185), (50, 0.23340226337313652), (51, 0.2511530164629221), (52, 0.2889232747256756), (36, 0.4970492608845234), (18, 0.5567422136664391), (53, 0.6630627512931824)]
computing accuracy for after removing block 28 . block score: 0.0820171432569623
removed block 28 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.092305. All blocks and scores: [(29, 0.09230543300509453), (25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.1030255164951086), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.1372627057135105), (42, 0.1405782662332058), (39, 0.14195826835930347), (43, 0.1497885324060917), (16, 0.1506669782102108), (37, 0.15083426423370838), (41, 0.15154080465435982), (40, 0.1515727862715721), (19, 0.157118147239089), (15, 0.15718332305550575), (4, 0.16022039018571377), (44, 0.1632316540926695), (0, 0.17103483527898788), (6, 0.1743504088371992), (13, 0.17572588473558426), (45, 0.176346892490983), (7, 0.17813357710838318), (46, 0.1868428122252226), (47, 0.1882498636841774), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (49, 0.21630686149001122), (9, 0.21840771473944187), (48, 0.21943928860127926), (50, 0.23229901120066643), (51, 0.24860799685120583), (52, 0.28720319271087646), (36, 0.4936506189405918), (18, 0.5567422136664391), (53, 0.6665436327457428)]
computing accuracy for after removing block 29 . block score: 0.09230543300509453
removed block 29 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.099540. All blocks and scores: [(25, 0.09953985922038555), (22, 0.09985021594911814), (27, 0.1030255164951086), (24, 0.10397691931575537), (23, 0.10452832002192736), (5, 0.11198819521814585), (14, 0.1175733832642436), (21, 0.12705031968653202), (3, 0.12763920985162258), (17, 0.1324505042284727), (20, 0.13340618088841438), (38, 0.13448605500161648), (39, 0.14043756760656834), (42, 0.14095922000706196), (43, 0.14932044595479965), (37, 0.15009933151304722), (41, 0.1505758035928011), (16, 0.1506669782102108), (40, 0.15209264680743217), (19, 0.157118147239089), (15, 0.15718332305550575), (4, 0.16022039018571377), (44, 0.16033504903316498), (0, 0.17103483527898788), (6, 0.1743504088371992), (45, 0.17554572597146034), (13, 0.17572588473558426), (7, 0.17813357710838318), (46, 0.18641946651041508), (47, 0.18677089177072048), (8, 0.20022751204669476), (10, 0.20250470377504826), (12, 0.2055080346763134), (11, 0.2084429245442152), (49, 0.21350642293691635), (9, 0.21840771473944187), (48, 0.2190124597400427), (50, 0.2313237264752388), (51, 0.24721170589327812), (52, 0.28666912391781807), (36, 0.495721947401762), (18, 0.5567422136664391), (53, 0.6687872558832169)]
computing accuracy for after removing block 25 . block score: 0.09953985922038555
removed block 25 current accuracy 0.996 loss from initial  0.0040000000000000036
training start
training epoch 0 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 1 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 3 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 4 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 5 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 6 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 10 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation mean]: block to remove picked: 22, with score 0.105999. All blocks and scores: [(22, 0.10599949490278959), (27, 0.10803084075450897), (24, 0.10921623837202787), (5, 0.11086906772106886), (23, 0.11113594565540552), (14, 0.1166242565959692), (3, 0.12741797976195812), (21, 0.13014651276171207), (17, 0.1349477916955948), (20, 0.1368366740643978), (38, 0.1433778889477253), (39, 0.14515984430909157), (42, 0.1488467324525118), (16, 0.1521659456193447), (41, 0.15258478745818138), (37, 0.1531549133360386), (40, 0.15464063175022602), (43, 0.15516674518585205), (15, 0.15797854959964752), (19, 0.15985766425728798), (4, 0.1599413137882948), (44, 0.16802439652383327), (0, 0.17026074044406414), (6, 0.17558012157678604), (45, 0.17613855749368668), (13, 0.17617258243262768), (7, 0.17658044025301933), (46, 0.19066944904625416), (47, 0.19571512378752232), (8, 0.1991326157003641), (10, 0.2012934610247612), (12, 0.2051009237766266), (11, 0.20758231356739998), (9, 0.21690478175878525), (49, 0.2229187972843647), (48, 0.22424720972776413), (50, 0.2348023559898138), (51, 0.256166934967041), (52, 0.29619263485074043), (36, 0.4928477518260479), (18, 0.5527054816484451), (53, 0.6416698917746544)]
computing accuracy for after removing block 22 . block score: 0.10599949490278959
removed block 22 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 27, with score 0.107056. All blocks and scores: [(27, 0.10705642681568861), (24, 0.1084387507289648), (23, 0.10885222908109426), (5, 0.11086906772106886), (14, 0.1166242565959692), (3, 0.12741797976195812), (21, 0.13014651276171207), (17, 0.1349477916955948), (20, 0.1368366740643978), (38, 0.14245703257620335), (42, 0.1438854429870844), (39, 0.1445445530116558), (37, 0.15114479139447212), (40, 0.15215668082237244), (16, 0.1521659456193447), (41, 0.1521676927804947), (43, 0.15541756711900234), (15, 0.15797854959964752), (19, 0.15985766425728798), (4, 0.1599413137882948), (44, 0.16726337932050228), (0, 0.17026074044406414), (45, 0.17509564384818077), (6, 0.17558012157678604), (13, 0.17617258243262768), (7, 0.17658044025301933), (46, 0.18912926875054836), (47, 0.1932112704962492), (8, 0.1991326157003641), (10, 0.2012934610247612), (12, 0.2051009237766266), (11, 0.20758231356739998), (9, 0.21690478175878525), (49, 0.21942183561623096), (48, 0.22173646837472916), (50, 0.23355140537023544), (51, 0.25245680660009384), (52, 0.29419293254613876), (36, 0.49345502629876137), (18, 0.5527054816484451), (53, 0.6472532078623772)]
computing accuracy for after removing block 27 . block score: 0.10705642681568861
removed block 27 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.108439. All blocks and scores: [(24, 0.1084387507289648), (23, 0.10885222908109426), (5, 0.11086906772106886), (14, 0.1166242565959692), (3, 0.12741797976195812), (21, 0.13014651276171207), (17, 0.1349477916955948), (20, 0.1368366740643978), (38, 0.13858484663069248), (42, 0.14042541943490505), (39, 0.14095420204102993), (37, 0.14841051399707794), (41, 0.14901212230324745), (40, 0.1492122132331133), (43, 0.15096787177026272), (16, 0.1521659456193447), (15, 0.15797854959964752), (19, 0.15985766425728798), (4, 0.1599413137882948), (44, 0.1647862046957016), (0, 0.17026074044406414), (45, 0.1720019243657589), (6, 0.17558012157678604), (13, 0.17617258243262768), (7, 0.17658044025301933), (46, 0.18494124710559845), (47, 0.18904834613204002), (8, 0.1991326157003641), (10, 0.2012934610247612), (12, 0.2051009237766266), (11, 0.20758231356739998), (49, 0.2152090072631836), (9, 0.21690478175878525), (48, 0.21845120377838612), (50, 0.2327614575624466), (51, 0.2492380142211914), (52, 0.29243019223213196), (36, 0.48784487694501877), (18, 0.5527054816484451), (53, 0.6501425430178642)]
computing accuracy for after removing block 24 . block score: 0.1084387507289648
removed block 24 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.108852. All blocks and scores: [(23, 0.10885222908109426), (5, 0.11086906772106886), (14, 0.1166242565959692), (3, 0.12741797976195812), (21, 0.13014651276171207), (17, 0.1349477916955948), (20, 0.1368366740643978), (38, 0.13721751794219017), (42, 0.1388678178191185), (39, 0.13993561081588268), (40, 0.14766591228544712), (41, 0.14812888391315937), (37, 0.14852290228009224), (43, 0.14976797997951508), (16, 0.1521659456193447), (15, 0.15797854959964752), (19, 0.15985766425728798), (4, 0.1599413137882948), (44, 0.16299171932041645), (0, 0.17026074044406414), (45, 0.17036798410117626), (6, 0.17558012157678604), (13, 0.17617258243262768), (7, 0.17658044025301933), (46, 0.18215334974229336), (47, 0.1864836923778057), (8, 0.1991326157003641), (10, 0.2012934610247612), (12, 0.2051009237766266), (11, 0.20758231356739998), (49, 0.21219523809850216), (48, 0.2156571764498949), (9, 0.21690478175878525), (50, 0.23169441521167755), (51, 0.24629263952374458), (52, 0.2905520834028721), (36, 0.48911579325795174), (18, 0.5527054816484451), (53, 0.6523346900939941)]
computing accuracy for after removing block 23 . block score: 0.10885222908109426
removed block 23 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 5, with score 0.110869. All blocks and scores: [(5, 0.11086906772106886), (14, 0.1166242565959692), (3, 0.12741797976195812), (21, 0.13014651276171207), (38, 0.13447364047169685), (17, 0.1349477916955948), (42, 0.13603784143924713), (20, 0.1368366740643978), (39, 0.13784221187233925), (37, 0.14596057124435902), (41, 0.1459681000560522), (40, 0.14630769193172455), (43, 0.14955372735857964), (16, 0.1521659456193447), (15, 0.15797854959964752), (19, 0.15985766425728798), (4, 0.1599413137882948), (44, 0.16126984171569347), (45, 0.16705522686243057), (0, 0.17026074044406414), (6, 0.17558012157678604), (13, 0.17617258243262768), (7, 0.17658044025301933), (46, 0.17913412302732468), (47, 0.18326236493885517), (8, 0.1991326157003641), (10, 0.2012934610247612), (12, 0.2051009237766266), (11, 0.20758231356739998), (49, 0.2076497171074152), (48, 0.21289788000285625), (9, 0.21690478175878525), (50, 0.22896965593099594), (51, 0.24196364544332027), (52, 0.28775833174586296), (36, 0.49103840813040733), (18, 0.5527054816484451), (53, 0.6552583426237106)]
computing accuracy for after removing block 5 . block score: 0.11086906772106886
removed block 5 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.114631. All blocks and scores: [(14, 0.11463129613548517), (3, 0.12741797976195812), (21, 0.12903932482004166), (17, 0.13285142369568348), (38, 0.1354387104511261), (20, 0.1357915010303259), (42, 0.13673038966953754), (39, 0.13881877809762955), (41, 0.14578195475041866), (37, 0.14817320555448532), (43, 0.14989168755710125), (40, 0.15001332014799118), (16, 0.15031623654067516), (15, 0.15656154230237007), (4, 0.1599413137882948), (19, 0.15999497659504414), (44, 0.1619267277419567), (45, 0.16771463677287102), (0, 0.17026074044406414), (13, 0.17507020756602287), (6, 0.17637494578957558), (46, 0.18062980100512505), (7, 0.18377213180065155), (47, 0.18474296107888222), (10, 0.19975261017680168), (11, 0.20009887218475342), (8, 0.2011527307331562), (12, 0.20216414891183376), (49, 0.2075536884367466), (48, 0.21366186439990997), (9, 0.21536995470523834), (50, 0.22894520871341228), (51, 0.24119588546454906), (52, 0.28718580305576324), (36, 0.49698882922530174), (18, 0.5589441880583763), (53, 0.6575128510594368)]
computing accuracy for after removing block 14 . block score: 0.11463129613548517
removed block 14 current accuracy 0.9868 loss from initial  0.01319999999999999
training start
training epoch 0 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 1 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 2 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 4 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 5 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 7 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 8 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 9 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 10 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 11 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 12 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 13 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 15 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 16 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 17 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 19 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 20 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 21 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 22 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 23 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 24 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 25 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 26 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 30 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 31 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 32 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 33 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 34 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 35 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 36 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 37 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 40 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 41 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 42 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 43 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 44 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 45 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 46 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 47 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 49 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.999200)
finished training. finished 50 epochs. accuracy 0.9992 topk_dict {'top1': 0.9992}
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.126179. All blocks and scores: [(3, 0.12617894262075424), (17, 0.13501519337296486), (38, 0.14214009791612625), (39, 0.14288538694381714), (42, 0.1471712365746498), (21, 0.15020468831062317), (37, 0.15085318498313427), (16, 0.15258289501070976), (40, 0.15289660915732384), (41, 0.15304800868034363), (20, 0.15441852062940598), (43, 0.1545506026595831), (15, 0.15967034548521042), (4, 0.1597329918295145), (44, 0.16627546958625317), (0, 0.1701215412467718), (6, 0.17187141254544258), (19, 0.17261282168328762), (7, 0.17405351251363754), (45, 0.17418531514704227), (13, 0.1762490440160036), (46, 0.18737669847905636), (47, 0.1924727652221918), (8, 0.19363276660442352), (10, 0.19762939773499966), (12, 0.20192425698041916), (11, 0.20834891870617867), (9, 0.21208980679512024), (49, 0.22006702050566673), (48, 0.22114542499184608), (50, 0.2327386513352394), (51, 0.25370920822024345), (52, 0.29059336706995964), (36, 0.49071474745869637), (18, 0.5342703312635422), (53, 0.6529075279831886)]
computing accuracy for after removing block 3 . block score: 0.12617894262075424
removed block 3 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.134353. All blocks and scores: [(17, 0.13435333035886288), (39, 0.14307013154029846), (38, 0.14320207200944424), (42, 0.1452597640454769), (21, 0.14879756793379784), (16, 0.149842731654644), (37, 0.1511547714471817), (41, 0.15239214152097702), (20, 0.1526852622628212), (43, 0.15350331366062164), (40, 0.15439103730022907), (4, 0.15742598287761211), (15, 0.1583195347338915), (44, 0.16647237911820412), (0, 0.1701215412467718), (19, 0.17110296711325645), (45, 0.17409175634384155), (7, 0.17507780715823174), (13, 0.17526649311184883), (6, 0.18261283077299595), (46, 0.1862697545439005), (8, 0.192350247874856), (47, 0.19256942719221115), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (49, 0.21927839145064354), (48, 0.22117835097014904), (50, 0.2330106422305107), (51, 0.2524331957101822), (52, 0.2893010191619396), (36, 0.49142536893486977), (18, 0.5375839918851852), (53, 0.654647670686245)]
computing accuracy for after removing block 17 . block score: 0.13435333035886288
removed block 17 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.140090. All blocks and scores: [(42, 0.14008971117436886), (39, 0.14331963658332825), (38, 0.14546240866184235), (20, 0.14687145687639713), (21, 0.14699558727443218), (37, 0.14903314411640167), (16, 0.149842731654644), (40, 0.15310192666947842), (41, 0.15571674332022667), (4, 0.15742598287761211), (15, 0.1583195347338915), (43, 0.15837995894253254), (44, 0.16641448438167572), (19, 0.1687059160321951), (0, 0.1701215412467718), (45, 0.17170018702745438), (7, 0.17507780715823174), (13, 0.17526649311184883), (6, 0.18261283077299595), (46, 0.18309676088392735), (47, 0.19127819128334522), (8, 0.192350247874856), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (49, 0.21735339239239693), (48, 0.22028988786041737), (50, 0.23106678389012814), (51, 0.2482581976801157), (52, 0.2877395935356617), (36, 0.4880504868924618), (18, 0.5287285149097443), (53, 0.6533439755439758)]
computing accuracy for after removing block 42 . block score: 0.14008971117436886
removed block 42 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 39, with score 0.143320. All blocks and scores: [(39, 0.14331963658332825), (38, 0.14546240866184235), (20, 0.14687145687639713), (21, 0.14699558727443218), (37, 0.14903314411640167), (16, 0.149842731654644), (40, 0.15310192666947842), (41, 0.15571674332022667), (4, 0.15742598287761211), (15, 0.1583195347338915), (43, 0.16249413043260574), (44, 0.16647608391940594), (19, 0.1687059160321951), (0, 0.1701215412467718), (45, 0.17360211163759232), (7, 0.17507780715823174), (13, 0.17526649311184883), (6, 0.18261283077299595), (46, 0.18333480134606361), (47, 0.19112874008715153), (8, 0.192350247874856), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (49, 0.21658360585570335), (48, 0.21733334474265575), (50, 0.22903634794056416), (51, 0.2465941272675991), (52, 0.2855704203248024), (36, 0.4880504868924618), (18, 0.5287285149097443), (53, 0.6617971956729889)]
computing accuracy for after removing block 39 . block score: 0.14331963658332825
removed block 39 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.145462. All blocks and scores: [(38, 0.14546240866184235), (20, 0.14687145687639713), (21, 0.14699558727443218), (37, 0.14903314411640167), (16, 0.149842731654644), (40, 0.1506412997841835), (41, 0.15436748415231705), (4, 0.15742598287761211), (15, 0.1583195347338915), (43, 0.15920201875269413), (44, 0.16750831343233585), (19, 0.1687059160321951), (0, 0.1701215412467718), (45, 0.173765379935503), (7, 0.17507780715823174), (13, 0.17526649311184883), (46, 0.18246393278241158), (6, 0.18261283077299595), (47, 0.19048031978309155), (8, 0.192350247874856), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (49, 0.2163422331213951), (48, 0.21818938292562962), (50, 0.22888511419296265), (51, 0.2454500924795866), (52, 0.2842019237577915), (36, 0.4880504868924618), (18, 0.5287285149097443), (53, 0.6730812266469002)]
computing accuracy for after removing block 38 . block score: 0.14546240866184235
removed block 38 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 20, with score 0.146871. All blocks and scores: [(20, 0.14687145687639713), (21, 0.14699558727443218), (37, 0.14903314411640167), (16, 0.149842731654644), (40, 0.15149844624102116), (41, 0.1534097120165825), (43, 0.15665770135819912), (4, 0.15742598287761211), (15, 0.1583195347338915), (19, 0.1687059160321951), (44, 0.16926146298646927), (0, 0.1701215412467718), (45, 0.17128942906856537), (7, 0.17507780715823174), (13, 0.17526649311184883), (46, 0.18173052929341793), (6, 0.18261283077299595), (47, 0.1893505584448576), (8, 0.192350247874856), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (49, 0.21305237337946892), (48, 0.21653862670063972), (50, 0.22573797777295113), (51, 0.24124474450945854), (52, 0.28132447600364685), (36, 0.4880504868924618), (18, 0.5287285149097443), (53, 0.6788237988948822)]
computing accuracy for after removing block 20 . block score: 0.14687145687639713
removed block 20 current accuracy 0.9802 loss from initial  0.01980000000000004
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 37, with score 0.146399. All blocks and scores: [(37, 0.14639866165816784), (40, 0.1467742957174778), (21, 0.14883860759437084), (16, 0.149842731654644), (41, 0.15012512728571892), (43, 0.1522718109190464), (4, 0.15742598287761211), (15, 0.1583195347338915), (45, 0.16411002911627293), (44, 0.1655931118875742), (19, 0.1687059160321951), (0, 0.1701215412467718), (7, 0.17507780715823174), (13, 0.17526649311184883), (46, 0.17788789421319962), (6, 0.18261283077299595), (47, 0.18551640026271343), (8, 0.192350247874856), (12, 0.1987566389143467), (49, 0.20353443548083305), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (48, 0.2110397294163704), (50, 0.22235415130853653), (51, 0.23303335346281528), (52, 0.2737733721733093), (36, 0.48733457177877426), (18, 0.5287285149097443), (53, 0.6859103366732597)]
computing accuracy for after removing block 37 . block score: 0.14639866165816784
removed block 37 current accuracy 0.97 loss from initial  0.030000000000000027
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 21, with score 0.148839. All blocks and scores: [(21, 0.14883860759437084), (16, 0.149842731654644), (43, 0.15072240866720676), (40, 0.15073895826935768), (41, 0.15232080221176147), (4, 0.15742598287761211), (15, 0.1583195347338915), (45, 0.1604199055582285), (44, 0.1637331284582615), (19, 0.1687059160321951), (0, 0.1701215412467718), (7, 0.17507780715823174), (13, 0.17526649311184883), (46, 0.17540491558611393), (6, 0.18261283077299595), (47, 0.18554161116480827), (8, 0.192350247874856), (49, 0.1981083732098341), (12, 0.1987566389143467), (10, 0.20369978994131088), (11, 0.20631131157279015), (48, 0.20770699344575405), (9, 0.21072405017912388), (50, 0.21537326090037823), (51, 0.22521325573325157), (52, 0.2668965682387352), (36, 0.48733457177877426), (18, 0.5287285149097443), (53, 0.6870746314525604)]
computing accuracy for after removing block 21 . block score: 0.14883860759437084
removed block 21 current accuracy 0.9438 loss from initial  0.05620000000000003
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.146789. All blocks and scores: [(40, 0.14678888954222202), (43, 0.14767515659332275), (16, 0.149842731654644), (41, 0.15183995477855206), (45, 0.1554951649159193), (4, 0.15742598287761211), (15, 0.1583195347338915), (44, 0.16042536310851574), (19, 0.1687059160321951), (46, 0.16928143613040447), (0, 0.1701215412467718), (7, 0.17507780715823174), (13, 0.17526649311184883), (47, 0.180326035246253), (6, 0.18261283077299595), (49, 0.1914245467633009), (8, 0.192350247874856), (12, 0.1987566389143467), (48, 0.2022377885878086), (10, 0.20369978994131088), (11, 0.20631131157279015), (9, 0.21072405017912388), (50, 0.2111983820796013), (51, 0.21773510426282883), (52, 0.26284435018897057), (36, 0.48746394738554955), (18, 0.5287285149097443), (53, 0.6809541210532188)]
computing accuracy for after removing block 40 . block score: 0.14678888954222202
removed block 40 current accuracy 0.921 loss from initial  0.07899999999999996
training start
training epoch 0 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 1 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 2 val accuracy 0.986 topk_dict {'top1': 0.986} is_best True lr [0.001]
training epoch 3 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 4 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 5 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 6 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 7 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 8 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 9 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 10 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 11 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 12 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 13 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 14 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 15 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 16 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 17 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 18 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 19 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 20 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 21 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 22 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 23 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 24 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 25 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 26 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 27 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 28 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 29 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 30 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 32 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 33 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 34 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 36 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 37 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 38 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 39 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 40 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 41 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 43 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 44 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 45 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 46 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 47 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 48 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 49 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
