start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067571. All blocks and scores: [(32, 0.0675714211538434), (31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07914633490145206), (33, 0.08192148618400097), (28, 0.08897436503320932), (35, 0.09150646720081568), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16807220317423344), (39, 0.17391434125602245), (38, 0.17409800179302692), (40, 0.1747935749590397), (44, 0.17559202574193478), (42, 0.1763687338680029), (2, 0.17818448692560196), (43, 0.18028480000793934), (37, 0.1874171681702137), (45, 0.1913505643606186), (46, 0.19167010858654976), (16, 0.19186081551015377), (47, 0.1938924305140972), (0, 0.2014507930725813), (48, 0.2074642963707447), (49, 0.2087792381644249), (50, 0.2150480169802904), (51, 0.23200893960893154), (5, 0.23247346468269825), (52, 0.24538944847881794), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5694299265742302), (53, 0.5812843516469002)]
computing accuracy for after removing block 32 . block score: 0.0675714211538434
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075980. All blocks and scores: [(31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07963871583342552), (33, 0.08215188421308994), (28, 0.08897436503320932), (35, 0.09255937859416008), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16619791090488434), (38, 0.1706629153341055), (40, 0.17233950085937977), (44, 0.17322266846895218), (39, 0.17388461343944073), (42, 0.17525410652160645), (2, 0.17818448692560196), (43, 0.17904356308281422), (37, 0.18435736000537872), (46, 0.18958506174385548), (45, 0.1906456109136343), (16, 0.19186081551015377), (47, 0.19291129149496555), (0, 0.2014507930725813), (48, 0.2059937696903944), (49, 0.2078111693263054), (50, 0.2136209774762392), (51, 0.2316721361130476), (5, 0.23247346468269825), (52, 0.24407040141522884), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5649380832910538), (53, 0.5846557393670082)]
computing accuracy for after removing block 31 . block score: 0.07598021812736988
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076864. All blocks and scores: [(30, 0.07686383835971355), (34, 0.0803083973005414), (33, 0.0824452992528677), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.0937052397057414), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16335336491465569), (14, 0.16607324592769146), (38, 0.16689680889248848), (40, 0.16941766813397408), (44, 0.17088529095053673), (39, 0.173272417858243), (42, 0.17336755990982056), (2, 0.17818448692560196), (43, 0.17835192382335663), (37, 0.18097997643053532), (46, 0.18729917518794537), (45, 0.189705615863204), (47, 0.19152643717825413), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20431426540017128), (49, 0.20694035664200783), (50, 0.21236521005630493), (51, 0.23184024542570114), (5, 0.23247346468269825), (52, 0.24304170347750187), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5598013773560524), (53, 0.5874009430408478)]
computing accuracy for after removing block 30 . block score: 0.07686383835971355
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079782. All blocks and scores: [(34, 0.07978176791220903), (33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09433686546981335), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16367061622440815), (14, 0.16607324592769146), (38, 0.16689884662628174), (40, 0.1688882727175951), (44, 0.16993452981114388), (39, 0.17342626862227917), (42, 0.17362496629357338), (43, 0.1767871119081974), (2, 0.17818448692560196), (37, 0.18006489984691143), (46, 0.18585865385830402), (45, 0.1900129672139883), (47, 0.19076526165008545), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20426686480641365), (49, 0.20699637196958065), (50, 0.2116481103003025), (51, 0.23162324354052544), (5, 0.23247346468269825), (52, 0.24221924878656864), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5604959651827812), (53, 0.5873366072773933)]
computing accuracy for after removing block 34 . block score: 0.07978176791220903
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.082971. All blocks and scores: [(33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09587994497269392), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.1610505860298872), (38, 0.1633784919977188), (14, 0.16607324592769146), (40, 0.1664226781576872), (44, 0.1675016302615404), (39, 0.16972871869802475), (42, 0.17223737947642803), (43, 0.17614286206662655), (37, 0.17686635814607143), (2, 0.17818448692560196), (46, 0.1853218786418438), (45, 0.18889996781945229), (47, 0.18968128971755505), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20193634182214737), (49, 0.20599747449159622), (50, 0.21036292426288128), (51, 0.23076499067246914), (5, 0.23247346468269825), (52, 0.24034381844103336), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5582085475325584), (53, 0.5918786898255348)]
computing accuracy for after removing block 33 . block score: 0.08297098055481911
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088974. All blocks and scores: [(28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09792979713529348), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16093394719064236), (38, 0.16253862343728542), (40, 0.16475909017026424), (44, 0.1657320111989975), (14, 0.16607324592769146), (39, 0.17084676586091518), (42, 0.17239164374768734), (37, 0.1755716409534216), (43, 0.1766559574753046), (2, 0.17818448692560196), (46, 0.18369029462337494), (47, 0.1886796187609434), (45, 0.1887859608978033), (16, 0.19186081551015377), (48, 0.200510635972023), (0, 0.2014507930725813), (49, 0.20520283095538616), (50, 0.21048511005938053), (51, 0.23036987893283367), (5, 0.23247346468269825), (52, 0.2400742694735527), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5590175092220306), (53, 0.5941508710384369)]
computing accuracy for after removing block 28 . block score: 0.08897436503320932
removed block 28 current accuracy 0.9982 loss from initial  0.0018000000000000238
training start
training epoch 0 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 1 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 41 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.095102. All blocks and scores: [(35, 0.09510243963450193), (29, 0.09601220674812794), (7, 0.10070326179265976), (26, 0.10326786525547504), (8, 0.10335877723991871), (6, 0.10808895342051983), (27, 0.11051097698509693), (25, 0.1139901764690876), (24, 0.11471375916153193), (22, 0.1210368387401104), (23, 0.12121990695595741), (21, 0.12482842244207859), (4, 0.12489433027803898), (11, 0.12631352804601192), (10, 0.12677070125937462), (13, 0.13216149993240833), (3, 0.13862604275345802), (1, 0.1406853161752224), (12, 0.15039301291108131), (15, 0.15085599571466446), (9, 0.15158978663384914), (20, 0.15562897734344006), (19, 0.1597061064094305), (14, 0.1647819634526968), (41, 0.1655013132840395), (39, 0.17062886618077755), (38, 0.17075373232364655), (40, 0.1719499360769987), (44, 0.17286528833210468), (2, 0.17474600486457348), (42, 0.17491892911493778), (43, 0.17812693119049072), (37, 0.18455216102302074), (45, 0.1891899649053812), (46, 0.1904012057930231), (16, 0.1914434190839529), (47, 0.19306938163936138), (0, 0.19696346297860146), (48, 0.2060616035014391), (49, 0.2082208264619112), (50, 0.21572889760136604), (5, 0.22873122617602348), (51, 0.2311234101653099), (52, 0.24412999860942364), (17, 0.31612495332956314), (18, 0.529721237719059), (36, 0.5583055764436722), (53, 0.5719906240701675)]
computing accuracy for after removing block 35 . block score: 0.09510243963450193
removed block 35 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.096012. All blocks and scores: [(29, 0.09601220674812794), (7, 0.10070326179265976), (26, 0.10326786525547504), (8, 0.10335877723991871), (6, 0.10808895342051983), (27, 0.11051097698509693), (25, 0.1139901764690876), (24, 0.11471375916153193), (22, 0.1210368387401104), (23, 0.12121990695595741), (21, 0.12482842244207859), (4, 0.12489433027803898), (11, 0.12631352804601192), (10, 0.12677070125937462), (13, 0.13216149993240833), (3, 0.13862604275345802), (1, 0.1406853161752224), (12, 0.15039301291108131), (15, 0.15085599571466446), (9, 0.15158978663384914), (20, 0.15562897734344006), (41, 0.15936334431171417), (19, 0.1597061064094305), (39, 0.16255605965852737), (38, 0.16292745247483253), (14, 0.1647819634526968), (40, 0.16482140496373177), (44, 0.16834492795169353), (42, 0.1698685772716999), (43, 0.1738940142095089), (2, 0.17474600486457348), (37, 0.1770578995347023), (45, 0.18513518385589123), (46, 0.1869553066790104), (47, 0.18801819160580635), (16, 0.1914434190839529), (0, 0.19696346297860146), (48, 0.19908570870757103), (49, 0.20462821424007416), (50, 0.2108873426914215), (5, 0.22873122617602348), (51, 0.22936969622969627), (52, 0.2406750340014696), (17, 0.31612495332956314), (18, 0.529721237719059), (36, 0.5492940843105316), (53, 0.5804548263549805)]
computing accuracy for after removing block 29 . block score: 0.09601220674812794
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.100703. All blocks and scores: [(7, 0.10070326179265976), (26, 0.10326786525547504), (8, 0.10335877723991871), (6, 0.10808895342051983), (27, 0.11051097698509693), (25, 0.1139901764690876), (24, 0.11471375916153193), (22, 0.1210368387401104), (23, 0.12121990695595741), (21, 0.12482842244207859), (4, 0.12489433027803898), (11, 0.12631352804601192), (10, 0.12677070125937462), (13, 0.13216149993240833), (3, 0.13862604275345802), (1, 0.1406853161752224), (12, 0.15039301291108131), (15, 0.15085599571466446), (9, 0.15158978663384914), (20, 0.15562897734344006), (41, 0.1587942410260439), (19, 0.1597061064094305), (38, 0.1601389218121767), (39, 0.1611245721578598), (40, 0.16254837438464165), (14, 0.1647819634526968), (44, 0.16609097830951214), (42, 0.16763849556446075), (43, 0.17143245972692966), (2, 0.17474600486457348), (37, 0.1750809382647276), (45, 0.1843388881534338), (46, 0.1847276035696268), (47, 0.18575558438897133), (16, 0.1914434190839529), (0, 0.19696346297860146), (48, 0.19721766002476215), (49, 0.20355045050382614), (50, 0.20876879803836346), (5, 0.22873122617602348), (51, 0.2302413284778595), (52, 0.24011016078293324), (17, 0.31612495332956314), (18, 0.529721237719059), (36, 0.5472586303949356), (53, 0.5824755355715752)]
computing accuracy for after removing block 7 . block score: 0.10070326179265976
removed block 7 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.102982. All blocks and scores: [(26, 0.10298194922506809), (8, 0.10536051541566849), (6, 0.10808895342051983), (27, 0.10879439767450094), (25, 0.11175655573606491), (24, 0.11253118049353361), (23, 0.11714650224894285), (22, 0.11958470568060875), (21, 0.12177943903952837), (4, 0.12489433027803898), (11, 0.12605952471494675), (10, 0.12684266828000546), (13, 0.13167499750852585), (3, 0.13862604275345802), (1, 0.1406853161752224), (12, 0.14913000538945198), (15, 0.1499181054532528), (9, 0.1514542680233717), (20, 0.1530629526823759), (38, 0.1555147636681795), (41, 0.15592865273356438), (19, 0.1567590981721878), (39, 0.157986618578434), (40, 0.1580014005303383), (14, 0.16315839625895023), (44, 0.16528958827257156), (42, 0.16564969159662724), (43, 0.16780509054660797), (37, 0.1715637929737568), (2, 0.17474600486457348), (45, 0.1820860393345356), (46, 0.1823225561529398), (47, 0.18350840918719769), (16, 0.18833304569125175), (48, 0.194740891456604), (0, 0.19696346297860146), (49, 0.20283085852861404), (50, 0.20718768425285816), (5, 0.22873122617602348), (51, 0.2304035946726799), (52, 0.23944983258843422), (17, 0.3088495060801506), (18, 0.5208758637309074), (36, 0.5402051582932472), (53, 0.5815677419304848)]
computing accuracy for after removing block 26 . block score: 0.10298194922506809
removed block 26 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 8, with score 0.105361. All blocks and scores: [(8, 0.10536051541566849), (27, 0.10647919401526451), (6, 0.10808895342051983), (25, 0.11175655573606491), (24, 0.11253118049353361), (23, 0.11714650224894285), (22, 0.11958470568060875), (21, 0.12177943903952837), (4, 0.12489433027803898), (11, 0.12605952471494675), (10, 0.12684266828000546), (13, 0.13167499750852585), (3, 0.13862604275345802), (1, 0.1406853161752224), (12, 0.14913000538945198), (15, 0.1499181054532528), (38, 0.15145407430827618), (9, 0.1514542680233717), (20, 0.1530629526823759), (41, 0.15411696583032608), (40, 0.15440025366842747), (39, 0.1548999734222889), (19, 0.1567590981721878), (44, 0.16176361218094826), (14, 0.16315839625895023), (42, 0.16376242227852345), (43, 0.16506598703563213), (37, 0.16748737916350365), (2, 0.17474600486457348), (46, 0.1792665533721447), (45, 0.17985580675303936), (47, 0.1808675415813923), (16, 0.18833304569125175), (48, 0.1904633454978466), (0, 0.19696346297860146), (49, 0.20065047778189182), (50, 0.20495247654616833), (5, 0.22873122617602348), (51, 0.2300486583262682), (52, 0.23788762837648392), (17, 0.3088495060801506), (18, 0.5208758637309074), (36, 0.5385331586003304), (53, 0.585682213306427)]
computing accuracy for after removing block 8 . block score: 0.10536051541566849
removed block 8 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 27, with score 0.104493. All blocks and scores: [(27, 0.1044929726049304), (6, 0.10808895342051983), (24, 0.10968201793730259), (25, 0.10986440721899271), (23, 0.1139577953144908), (22, 0.11768849194049835), (21, 0.11843113601207733), (4, 0.12489433027803898), (10, 0.12645643763244152), (11, 0.12792494893074036), (13, 0.13228978775441647), (3, 0.13862604275345802), (1, 0.1406853161752224), (38, 0.14785663038492203), (12, 0.1489904299378395), (9, 0.14929724670946598), (15, 0.1496763452887535), (40, 0.1511139739304781), (20, 0.1516160760074854), (41, 0.15186366252601147), (39, 0.15251964144408703), (19, 0.154053108766675), (44, 0.16052677668631077), (14, 0.1611052304506302), (42, 0.16228398866951466), (43, 0.16262447834014893), (37, 0.16570989787578583), (2, 0.17474600486457348), (46, 0.1770658940076828), (45, 0.17776748724281788), (47, 0.17927936278283596), (16, 0.18585761822760105), (48, 0.18817194737493992), (0, 0.19696346297860146), (49, 0.20006811991333961), (50, 0.20381245762109756), (5, 0.22873122617602348), (51, 0.23013465479016304), (52, 0.23727393336594105), (17, 0.30218685045838356), (18, 0.5131242349743843), (36, 0.5333689972758293), (53, 0.5837270095944405)]
computing accuracy for after removing block 27 . block score: 0.1044929726049304
removed block 27 current accuracy 0.9978 loss from initial  0.0021999999999999797
training start
training epoch 0 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 1 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 5 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 6 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 36 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 14 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.109745. All blocks and scores: [(6, 0.10974473226815462), (24, 0.1179938018321991), (25, 0.11947854328900576), (22, 0.12350881192833185), (11, 0.12366954796016216), (10, 0.12506972905248404), (23, 0.1251060524955392), (4, 0.12606322206556797), (21, 0.13028362393379211), (13, 0.13253991678357124), (1, 0.13901945389807224), (3, 0.13924419321119785), (9, 0.14888435415923595), (12, 0.15260731801390648), (15, 0.15458901226520538), (20, 0.15712361596524715), (19, 0.16032284311950207), (14, 0.16414174064993858), (41, 0.16526759788393974), (38, 0.16778679005801678), (39, 0.16943814791738987), (40, 0.17148270085453987), (44, 0.17191470228135586), (42, 0.1731373928487301), (43, 0.17595695704221725), (2, 0.17666473425924778), (37, 0.18259271048009396), (45, 0.18663635291159153), (16, 0.18930652551352978), (46, 0.18952487967908382), (47, 0.19200887717306614), (0, 0.1944815218448639), (48, 0.20558350160717964), (49, 0.20746513456106186), (50, 0.21381613239645958), (5, 0.22912007756531239), (51, 0.2301385961472988), (52, 0.24288269504904747), (17, 0.3096286915242672), (18, 0.5176900774240494), (36, 0.5542580410838127), (53, 0.5730465948581696)]
computing accuracy for after removing block 6 . block score: 0.10974473226815462
removed block 6 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.113976. All blocks and scores: [(24, 0.11397608276456594), (25, 0.11710674408823252), (23, 0.12103262543678284), (22, 0.12146954610943794), (4, 0.12606322206556797), (11, 0.12630179896950722), (21, 0.12710021995007992), (10, 0.12930910475552082), (13, 0.13713439367711544), (1, 0.13901945389807224), (3, 0.13924419321119785), (9, 0.15115105919539928), (12, 0.15324228443205357), (20, 0.15514794178307056), (15, 0.15619048662483692), (19, 0.15703838504850864), (41, 0.1645957212895155), (38, 0.16559120267629623), (14, 0.1669356096535921), (39, 0.1673752497881651), (40, 0.1681553404778242), (44, 0.17121844366192818), (42, 0.17139047011733055), (43, 0.17270749993622303), (2, 0.17666473425924778), (37, 0.18083522096276283), (45, 0.1845248993486166), (46, 0.1874448750168085), (16, 0.18845158070325851), (47, 0.18920193798840046), (0, 0.1944815218448639), (48, 0.20281942561268806), (49, 0.20597818307578564), (50, 0.21244505606591702), (5, 0.22912007756531239), (51, 0.23027940653264523), (52, 0.2423250712454319), (17, 0.30862700194120407), (18, 0.5104934200644493), (36, 0.548248253762722), (53, 0.5706909000873566)]
computing accuracy for after removing block 24 . block score: 0.11397608276456594
removed block 24 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.117641. All blocks and scores: [(25, 0.11764130182564259), (23, 0.12103262543678284), (22, 0.12146954610943794), (4, 0.12606322206556797), (11, 0.12630179896950722), (21, 0.12710021995007992), (10, 0.12930910475552082), (13, 0.13713439367711544), (1, 0.13901945389807224), (3, 0.13924419321119785), (9, 0.15115105919539928), (12, 0.15324228443205357), (20, 0.15514794178307056), (15, 0.15619048662483692), (19, 0.15703838504850864), (41, 0.1608120072633028), (38, 0.16246528923511505), (39, 0.16290192306041718), (40, 0.16449702717363834), (14, 0.1669356096535921), (44, 0.16718190908432007), (42, 0.16794620640575886), (43, 0.16935695335268974), (2, 0.17666473425924778), (37, 0.17703420482575893), (45, 0.1817779242992401), (46, 0.18528172001242638), (47, 0.18559611216187477), (16, 0.18845158070325851), (0, 0.1944815218448639), (48, 0.19903344474732876), (49, 0.20307707227766514), (50, 0.20908930711448193), (5, 0.22912007756531239), (51, 0.22968501970171928), (52, 0.240015035495162), (17, 0.30862700194120407), (18, 0.5104934200644493), (36, 0.5455379113554955), (53, 0.5756401494145393)]
computing accuracy for after removing block 25 . block score: 0.11764130182564259
removed block 25 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.121033. All blocks and scores: [(23, 0.12103262543678284), (22, 0.12146954610943794), (4, 0.12606322206556797), (11, 0.12630179896950722), (21, 0.12710021995007992), (10, 0.12930910475552082), (13, 0.13713439367711544), (1, 0.13901945389807224), (3, 0.13924419321119785), (9, 0.15115105919539928), (12, 0.15324228443205357), (38, 0.15506548434495926), (41, 0.15511896274983883), (20, 0.15514794178307056), (39, 0.15618794038891792), (15, 0.15619048662483692), (19, 0.15703838504850864), (40, 0.15901674143970013), (44, 0.16275264509022236), (42, 0.16418573446571827), (43, 0.16658672876656055), (14, 0.1669356096535921), (37, 0.17055250704288483), (2, 0.17666473425924778), (45, 0.17967740632593632), (46, 0.18239327892661095), (47, 0.1825767084956169), (16, 0.18845158070325851), (48, 0.19374497421085835), (0, 0.1944815218448639), (49, 0.1997168343514204), (50, 0.2050805725157261), (5, 0.22912007756531239), (51, 0.22937843203544617), (52, 0.23783540539443493), (17, 0.30862700194120407), (18, 0.5104934200644493), (36, 0.5370855182409286), (53, 0.5803650617599487)]
computing accuracy for after removing block 23 . block score: 0.12103262543678284
removed block 23 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.121470. All blocks and scores: [(22, 0.12146954610943794), (4, 0.12606322206556797), (11, 0.12630179896950722), (21, 0.12710021995007992), (10, 0.12930910475552082), (13, 0.13713439367711544), (1, 0.13901945389807224), (3, 0.13924419321119785), (9, 0.15115105919539928), (12, 0.15324228443205357), (41, 0.1535507682710886), (38, 0.15504744462668896), (20, 0.15514794178307056), (15, 0.15619048662483692), (39, 0.15622185356914997), (19, 0.15703838504850864), (40, 0.15797855332493782), (44, 0.16089136712253094), (42, 0.16361292637884617), (43, 0.16442755609750748), (14, 0.1669356096535921), (37, 0.17044466361403465), (2, 0.17666473425924778), (45, 0.17893817834556103), (47, 0.17992691323161125), (46, 0.17996029555797577), (16, 0.18845158070325851), (48, 0.19178367778658867), (0, 0.1944815218448639), (49, 0.19786358252167702), (50, 0.20383761823177338), (5, 0.22912007756531239), (51, 0.22937523946166039), (52, 0.23658484779298306), (17, 0.30862700194120407), (18, 0.5104934200644493), (36, 0.536475658416748), (53, 0.5779374986886978)]
computing accuracy for after removing block 22 . block score: 0.12146954610943794
removed block 22 current accuracy 0.9878 loss from initial  0.012199999999999989
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 4, with score 0.126063. All blocks and scores: [(4, 0.12606322206556797), (11, 0.12630179896950722), (21, 0.12710021995007992), (10, 0.12930910475552082), (13, 0.13713439367711544), (1, 0.13901945389807224), (3, 0.13924419321119785), (41, 0.14846722967922688), (9, 0.15115105919539928), (38, 0.15148826502263546), (39, 0.15198512747883797), (40, 0.15259084478020668), (12, 0.15324228443205357), (20, 0.15514794178307056), (15, 0.15619048662483692), (44, 0.1568730529397726), (19, 0.15703838504850864), (42, 0.15798767283558846), (43, 0.16133485734462738), (37, 0.166128883138299), (14, 0.1669356096535921), (47, 0.17559736967086792), (45, 0.1758531630039215), (46, 0.17647093161940575), (2, 0.17666473425924778), (48, 0.18548512645065784), (16, 0.18845158070325851), (49, 0.19389960169792175), (0, 0.1944815218448639), (50, 0.2009309735149145), (5, 0.22912007756531239), (51, 0.22941914200782776), (52, 0.23392782732844353), (17, 0.30862700194120407), (18, 0.5104934200644493), (36, 0.526404932141304), (53, 0.5778141468763351)]
computing accuracy for after removing block 4 . block score: 0.12606322206556797
removed block 4 current accuracy 0.9842 loss from initial  0.015800000000000036
training start
training epoch 0 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 1 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 2 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 4 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 5 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 6 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 7 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 8 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 9 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 10 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 11 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 12 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 13 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 14 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 15 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 16 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 21 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 24 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 27 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 29 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 33 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 34 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 42 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 43 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 44 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 45 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 46 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 47 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 49 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.998400)
finished training. finished 50 epochs. accuracy 0.9984 topk_dict {'top1': 0.9984}
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.126115. All blocks and scores: [(11, 0.12611490860581398), (10, 0.1320265382528305), (13, 0.1339634507894516), (1, 0.1353838425129652), (9, 0.14680612087249756), (3, 0.1468067243695259), (15, 0.15545464120805264), (21, 0.15549599565565586), (12, 0.1555679626762867), (41, 0.16439129784703255), (14, 0.16707992367446423), (38, 0.16885494627058506), (39, 0.16981461085379124), (44, 0.17126188799738884), (42, 0.17141562141478062), (40, 0.1716852057725191), (43, 0.17461681552231312), (20, 0.17686635628342628), (2, 0.17766922153532505), (19, 0.17894507572054863), (37, 0.18277598731219769), (45, 0.18692969903349876), (0, 0.18821639381349087), (46, 0.1884553749114275), (16, 0.18894911743700504), (47, 0.1912559401243925), (48, 0.205152690410614), (49, 0.2064068242907524), (50, 0.21313955448567867), (51, 0.2284544352442026), (5, 0.2314226422458887), (52, 0.24269777908921242), (17, 0.30507929250597954), (18, 0.5071464627981186), (36, 0.5539714246988297), (53, 0.5766696333885193)]
computing accuracy for after removing block 11 . block score: 0.12611490860581398
removed block 11 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 10, with score 0.132027. All blocks and scores: [(10, 0.1320265382528305), (1, 0.1353838425129652), (13, 0.13863359577953815), (9, 0.14680612087249756), (3, 0.1468067243695259), (21, 0.14881586097180843), (12, 0.1578009594231844), (15, 0.15870903432369232), (41, 0.16245231963694096), (38, 0.16265448555350304), (40, 0.16619080305099487), (39, 0.16751225851476192), (42, 0.16782712936401367), (14, 0.1686918493360281), (44, 0.17094440199434757), (43, 0.17237384989857674), (20, 0.17434916645288467), (19, 0.17469744943082333), (2, 0.17766922153532505), (37, 0.17861689813435078), (45, 0.18303950503468513), (46, 0.18443284183740616), (0, 0.18821639381349087), (47, 0.19022082164883614), (16, 0.19193841703236103), (48, 0.20216157287359238), (49, 0.20376928709447384), (50, 0.21129190735518932), (51, 0.22816283628344536), (5, 0.2314226422458887), (52, 0.2412364836782217), (17, 0.3016866557300091), (18, 0.5008059442043304), (36, 0.5504164323210716), (53, 0.5809455588459969)]
computing accuracy for after removing block 10 . block score: 0.1320265382528305
removed block 10 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 1, with score 0.135384. All blocks and scores: [(1, 0.1353838425129652), (13, 0.1367180421948433), (21, 0.14135571382939816), (9, 0.14680612087249756), (3, 0.1468067243695259), (38, 0.15373895689845085), (41, 0.15758016705513), (12, 0.15847616456449032), (40, 0.15875460021197796), (15, 0.16065655648708344), (39, 0.16270517371594906), (42, 0.16396822035312653), (44, 0.16720580868422985), (43, 0.16748970188200474), (19, 0.1675070971250534), (14, 0.16895871050655842), (20, 0.1702505238354206), (37, 0.17184180952608585), (2, 0.17766922153532505), (45, 0.17858464643359184), (46, 0.1812132317572832), (47, 0.1872057542204857), (0, 0.18821639381349087), (16, 0.1908048279583454), (48, 0.19744594022631645), (49, 0.20101582631468773), (50, 0.2077438160777092), (51, 0.22766881436109543), (5, 0.2314226422458887), (52, 0.23921018093824387), (17, 0.29660073667764664), (18, 0.49141373485326767), (36, 0.5363258793950081), (53, 0.5841664969921112)]
computing accuracy for after removing block 1 . block score: 0.1353838425129652
removed block 1 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 21, with score 0.138604. All blocks and scores: [(21, 0.1386035904288292), (13, 0.14079394936561584), (9, 0.14758555963635445), (3, 0.1486851815134287), (38, 0.1511650402098894), (41, 0.15422654524445534), (40, 0.15713847242295742), (12, 0.15888173319399357), (39, 0.1604969147592783), (15, 0.16138288378715515), (42, 0.16296470910310745), (44, 0.16590315662324429), (19, 0.16597933322191238), (43, 0.16613099165260792), (20, 0.1668942403048277), (14, 0.16893362253904343), (37, 0.16941969096660614), (45, 0.17771581932902336), (2, 0.17828115820884705), (46, 0.1807728409767151), (47, 0.18741830810904503), (0, 0.18821639381349087), (16, 0.18968231789767742), (48, 0.19607411324977875), (49, 0.20171304233372211), (50, 0.20714358054101467), (51, 0.22754373960196972), (5, 0.22934098914265633), (52, 0.23826906830072403), (17, 0.293458741158247), (18, 0.48617522045969963), (36, 0.5314829424023628), (53, 0.5864081606268883)]
computing accuracy for after removing block 21 . block score: 0.1386035904288292
removed block 21 current accuracy 0.9854 loss from initial  0.014599999999999946
since last training loss: 0.0129999999999999 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.140303. All blocks and scores: [(38, 0.14030275121331215), (13, 0.14079394936561584), (41, 0.1437167413532734), (40, 0.14678587578237057), (9, 0.14758555963635445), (3, 0.1486851815134287), (39, 0.15014925971627235), (42, 0.15559659525752068), (44, 0.15665549412369728), (12, 0.15888173319399357), (37, 0.159757474437356), (43, 0.16083122603595257), (15, 0.16138288378715515), (19, 0.16597933322191238), (20, 0.1668942403048277), (14, 0.16893362253904343), (45, 0.1721752341836691), (46, 0.17519364319741726), (2, 0.17828115820884705), (47, 0.18032697588205338), (48, 0.18434671871364117), (0, 0.18821639381349087), (16, 0.18968231789767742), (49, 0.194857370108366), (50, 0.20059549808502197), (51, 0.22688912227749825), (5, 0.22934098914265633), (52, 0.23367765545845032), (17, 0.293458741158247), (18, 0.48617522045969963), (36, 0.5148952379822731), (53, 0.591004990041256)]
computing accuracy for after removing block 38 . block score: 0.14030275121331215
removed block 38 current accuracy 0.979 loss from initial  0.02100000000000002
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 41, with score 0.137883. All blocks and scores: [(41, 0.13788297772407532), (13, 0.14079394936561584), (40, 0.14455507323145866), (44, 0.14684153720736504), (9, 0.14758555963635445), (3, 0.1486851815134287), (39, 0.14970704913139343), (42, 0.1507342029362917), (43, 0.1569876316934824), (12, 0.15888173319399357), (37, 0.159757474437356), (15, 0.16138288378715515), (45, 0.1657361388206482), (19, 0.16597933322191238), (20, 0.1668942403048277), (14, 0.16893362253904343), (46, 0.17051886767148972), (47, 0.17533668503165245), (48, 0.17688493430614471), (2, 0.17828115820884705), (0, 0.18821639381349087), (49, 0.18958194367587566), (16, 0.18968231789767742), (50, 0.19450125657022), (51, 0.2259583342820406), (52, 0.22756815142929554), (5, 0.22934098914265633), (17, 0.293458741158247), (18, 0.48617522045969963), (36, 0.5148952379822731), (53, 0.6079694777727127)]
computing accuracy for after removing block 41 . block score: 0.13788297772407532
removed block 41 current accuracy 0.9684 loss from initial  0.03159999999999996
since last training loss: 0.029999999999999916 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 13, with score 0.140794. All blocks and scores: [(13, 0.14079394936561584), (44, 0.1423932258039713), (40, 0.14455507323145866), (42, 0.14624681323766708), (9, 0.14758555963635445), (3, 0.1486851815134287), (39, 0.14970704913139343), (43, 0.15336714498698711), (12, 0.15888173319399357), (37, 0.159757474437356), (45, 0.160830520093441), (15, 0.16138288378715515), (19, 0.16597933322191238), (20, 0.1668942403048277), (46, 0.1683848276734352), (14, 0.16893362253904343), (47, 0.17125683836638927), (48, 0.17302669025957584), (2, 0.17828115820884705), (49, 0.18470872566103935), (0, 0.18821639381349087), (16, 0.18968231789767742), (50, 0.19002865441143513), (51, 0.2221914641559124), (52, 0.223321832716465), (5, 0.22934098914265633), (17, 0.293458741158247), (18, 0.48617522045969963), (36, 0.5148952379822731), (53, 0.637972854077816)]
computing accuracy for after removing block 13 . block score: 0.14079394936561584
removed block 13 current accuracy 0.9472 loss from initial  0.05279999999999996
since last training loss: 0.05119999999999991 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 40, with score 0.140843. All blocks and scores: [(40, 0.14084321074187756), (44, 0.14186025969684124), (42, 0.144957073032856), (39, 0.14661641046404839), (9, 0.14758555963635445), (3, 0.1486851815134287), (43, 0.15133815445005894), (45, 0.1570891011506319), (37, 0.1573097575455904), (12, 0.15888173319399357), (19, 0.16371189057826996), (15, 0.16373738460242748), (20, 0.16408425755798817), (46, 0.16649075411260128), (47, 0.16909120604395866), (48, 0.169639952480793), (14, 0.17486672289669514), (2, 0.17828115820884705), (49, 0.18202420510351658), (0, 0.18821639381349087), (50, 0.18832794204354286), (16, 0.19416586682200432), (52, 0.22238429263234138), (51, 0.22253497317433357), (5, 0.22934098914265633), (17, 0.2968435734510422), (18, 0.48173369094729424), (36, 0.5123821273446083), (53, 0.6329426988959312)]
computing accuracy for after removing block 40 . block score: 0.14084321074187756
removed block 40 current accuracy 0.9224 loss from initial  0.0776
since last training loss: 0.07599999999999996 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 44, with score 0.136282. All blocks and scores: [(44, 0.13628198578953743), (42, 0.14242253080010414), (43, 0.14656325243413448), (39, 0.14661641046404839), (9, 0.14758555963635445), (3, 0.1486851815134287), (45, 0.15159826911985874), (37, 0.1573097575455904), (12, 0.15888173319399357), (46, 0.16269723884761333), (19, 0.16371189057826996), (15, 0.16373738460242748), (20, 0.16408425755798817), (47, 0.16449337266385555), (48, 0.16630595177412033), (14, 0.17486672289669514), (49, 0.17799990437924862), (2, 0.17828115820884705), (50, 0.18530998565256596), (0, 0.18821639381349087), (16, 0.19416586682200432), (52, 0.21946636028587818), (51, 0.2202619481831789), (5, 0.22934098914265633), (17, 0.2968435734510422), (18, 0.48173369094729424), (36, 0.5123821273446083), (53, 0.6599965691566467)]
computing accuracy for after removing block 44 . block score: 0.13628198578953743
removed block 44 current accuracy 0.8994 loss from initial  0.10060000000000002
training start
training epoch 0 val accuracy 0.984 topk_dict {'top1': 0.984} is_best True lr [0.001]
training epoch 1 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 2 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 3 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 4 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 5 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 6 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 7 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 8 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 9 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 10 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 11 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 12 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 13 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 14 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 15 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 16 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 17 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 18 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 19 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 20 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 21 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 22 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 23 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 24 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 25 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 26 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 27 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 28 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 29 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 30 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 31 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 32 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 33 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 34 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 35 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 36 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 37 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 38 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 39 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 40 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 41 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 42 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 43 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 44 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 45 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 46 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 47 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 48 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 49 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.993200)
finished training. finished 50 epochs. accuracy 0.9932 topk_dict {'top1': 0.9932}
