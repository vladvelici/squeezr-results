start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062186. All blocks and scores: [(33, 0.062185654416680336), (31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08460694830864668), (29, 0.08930057473480701), (35, 0.09068185184150934), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.15793540328741074), (41, 0.1598859392106533), (40, 0.16328190825879574), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (13, 0.17231429554522038), (16, 0.17250859178602695), (42, 0.173072362318635), (3, 0.17561711743474007), (44, 0.17696543596684933), (39, 0.18027342669665813), (46, 0.18065034598112106), (45, 0.18211421370506287), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.1851444821804762), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20122026838362217), (48, 0.20766260288655758), (47, 0.21044609509408474), (10, 0.21198169328272343), (49, 0.21626885049045086), (12, 0.2171211950480938), (50, 0.2270798273384571), (5, 0.24775297567248344), (51, 0.25931933149695396), (52, 0.27953876554965973), (18, 0.562093511223793), (36, 0.5809764266014099), (53, 0.6345704793930054)]
computing accuracy for after removing block 33 . block score: 0.062185654416680336
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075665. All blocks and scores: [(31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08419696148484945), (29, 0.08930057473480701), (35, 0.09093761537224054), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.1572423968464136), (41, 0.157970754429698), (40, 0.16252249106764793), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.1718137189745903), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17635269090533257), (46, 0.17947880178689957), (39, 0.1794979516416788), (45, 0.18079246766865253), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18429154343903065), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20149224624037743), (48, 0.20621014572679996), (47, 0.2088273111730814), (10, 0.21198169328272343), (49, 0.21557523868978024), (12, 0.2171211950480938), (50, 0.2254290860146284), (5, 0.24775297567248344), (51, 0.2583659961819649), (52, 0.2788151502609253), (18, 0.562093511223793), (36, 0.5792211890220642), (53, 0.6342398598790169)]
computing accuracy for after removing block 31 . block score: 0.07566479779779911
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077217. All blocks and scores: [(32, 0.0772171588614583), (30, 0.08002207893878222), (34, 0.08413633890450001), (29, 0.08930057473480701), (35, 0.0912106977775693), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.15681212209165096), (9, 0.15687535144388676), (41, 0.1570850908756256), (40, 0.161650612950325), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17076795920729637), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17494448646903038), (3, 0.17561711743474007), (46, 0.17894328385591507), (39, 0.1794340517371893), (45, 0.18090466037392616), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.184414841234684), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20150442980229855), (48, 0.2049737572669983), (47, 0.2079013716429472), (10, 0.21198169328272343), (49, 0.2145967148244381), (12, 0.2171211950480938), (50, 0.22419615276157856), (5, 0.24775297567248344), (51, 0.2574971169233322), (52, 0.27774784341454506), (18, 0.562093511223793), (36, 0.578696958720684), (53, 0.6368038207292557)]
computing accuracy for after removing block 32 . block score: 0.0772171588614583
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080022. All blocks and scores: [(30, 0.08002207893878222), (34, 0.08331287186592817), (29, 0.08930057473480701), (35, 0.09091351181268692), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.1567240171134472), (9, 0.15687535144388676), (41, 0.15688308142125607), (40, 0.16149466298520565), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17011075653135777), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.1743054185062647), (3, 0.17561711743474007), (39, 0.17930877394974232), (46, 0.1793159805238247), (45, 0.1810449492186308), (11, 0.18289094977080822), (38, 0.18401959165930748), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20230499655008316), (48, 0.20458471588790417), (47, 0.20751793310046196), (10, 0.21198169328272343), (49, 0.21405635960400105), (12, 0.2171211950480938), (50, 0.22361480072140694), (5, 0.24775297567248344), (51, 0.2571289539337158), (52, 0.2768261544406414), (18, 0.562093511223793), (36, 0.5805345475673676), (53, 0.6388764828443527)]
computing accuracy for after removing block 30 . block score: 0.08002207893878222
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082327. All blocks and scores: [(34, 0.0823270846158266), (29, 0.08930057473480701), (35, 0.09074232261627913), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (41, 0.15666824020445347), (43, 0.1568149123340845), (9, 0.15687535144388676), (40, 0.16184155084192753), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.16879690065979958), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17466101422905922), (3, 0.17561711743474007), (46, 0.17866099812090397), (39, 0.17968248948454857), (45, 0.1809448804706335), (11, 0.18289094977080822), (38, 0.18364996276795864), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.20370880514383316), (37, 0.20395098999142647), (47, 0.20615417696535587), (10, 0.21198169328272343), (49, 0.21362591721117496), (12, 0.2171211950480938), (50, 0.22279280424118042), (5, 0.24775297567248344), (51, 0.2562031261622906), (52, 0.2757616192102432), (18, 0.562093511223793), (36, 0.5833301842212677), (53, 0.6426545828580856)]
computing accuracy for after removing block 34 . block score: 0.0823270846158266
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.089301. All blocks and scores: [(29, 0.08930057473480701), (35, 0.09233403950929642), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (41, 0.15786897018551826), (43, 0.15851951949298382), (40, 0.16382364183664322), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17144694924354553), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17642127722501755), (46, 0.1792240459471941), (39, 0.18195353262126446), (45, 0.1821158267557621), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18651140667498112), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.2036153506487608), (47, 0.20668456703424454), (37, 0.20811929553747177), (10, 0.21198169328272343), (49, 0.21409878507256508), (12, 0.2171211950480938), (50, 0.2226774599403143), (5, 0.24775297567248344), (51, 0.25564805790781975), (52, 0.2756016328930855), (18, 0.562093511223793), (36, 0.5907158851623535), (53, 0.6423948332667351)]
computing accuracy for after removing block 29 . block score: 0.08930057473480701
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.092921. All blocks and scores: [(35, 0.09292142558842897), (26, 0.10393581166863441), (28, 0.10705067962408066), (27, 0.11842420790344477), (23, 0.12323085311800241), (25, 0.12373425997793674), (24, 0.1291238572448492), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (17, 0.14762406423687935), (19, 0.15387777611613274), (43, 0.15734304301440716), (9, 0.1576198674738407), (41, 0.15941575542092323), (40, 0.16412774845957756), (4, 0.16433029249310493), (14, 0.16527099162340164), (6, 0.16871571354568005), (42, 0.17268656566739082), (13, 0.1729179173707962), (16, 0.17330581322312355), (3, 0.1761795300990343), (44, 0.1794678457081318), (39, 0.17984911054372787), (46, 0.18119648285210133), (45, 0.18178314715623856), (11, 0.1827423870563507), (8, 0.18450185470283031), (38, 0.18487593345344067), (2, 0.18961193598806858), (0, 0.19334901683032513), (37, 0.19921151921153069), (1, 0.20237149111926556), (48, 0.20745281875133514), (47, 0.2100185863673687), (10, 0.212400758638978), (49, 0.21637022122740746), (12, 0.21791709400713444), (50, 0.22613773494958878), (5, 0.2480470836162567), (51, 0.2602362185716629), (52, 0.2788708284497261), (18, 0.5641599148511887), (36, 0.5765669345855713), (53, 0.6255461722612381)]
computing accuracy for after removing block 35 . block score: 0.09292142558842897
removed block 35 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.103936. All blocks and scores: [(26, 0.10393581166863441), (28, 0.10705067962408066), (27, 0.11842420790344477), (23, 0.12323085311800241), (25, 0.12373425997793674), (24, 0.1291238572448492), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (17, 0.14762406423687935), (43, 0.15029681287705898), (41, 0.15144086256623268), (19, 0.15387777611613274), (9, 0.1576198674738407), (40, 0.15921249985694885), (4, 0.16433029249310493), (42, 0.16439138166606426), (14, 0.16527099162340164), (6, 0.16871571354568005), (13, 0.1729179173707962), (16, 0.17330581322312355), (39, 0.17419115640223026), (46, 0.17533907108008862), (44, 0.17539609409868717), (3, 0.1761795300990343), (45, 0.17678336054086685), (38, 0.1800736617296934), (11, 0.1827423870563507), (8, 0.18450185470283031), (2, 0.18961193598806858), (37, 0.1909533254802227), (0, 0.19334901683032513), (48, 0.19954573921859264), (1, 0.20237149111926556), (47, 0.20640361495316029), (10, 0.212400758638978), (49, 0.2127536777406931), (12, 0.21791709400713444), (50, 0.2198577169328928), (5, 0.2480470836162567), (51, 0.25670045241713524), (52, 0.2751644402742386), (18, 0.5641599148511887), (36, 0.5674768909811974), (53, 0.6371515467762947)]
computing accuracy for after removing block 26 . block score: 0.10393581166863441
removed block 26 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.104456. All blocks and scores: [(28, 0.10445586871355772), (27, 0.1162051884457469), (23, 0.12323085311800241), (25, 0.12373425997793674), (24, 0.1291238572448492), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (43, 0.1474209427833557), (17, 0.14762406423687935), (41, 0.14769201166927814), (19, 0.15387777611613274), (40, 0.1567951049655676), (9, 0.1576198674738407), (42, 0.1591502670198679), (4, 0.16433029249310493), (14, 0.16527099162340164), (6, 0.16871571354568005), (39, 0.17205287516117096), (13, 0.1729179173707962), (46, 0.17301328107714653), (16, 0.17330581322312355), (44, 0.17385785654187202), (45, 0.17461331747472286), (3, 0.1761795300990343), (38, 0.17703080363571644), (11, 0.1827423870563507), (8, 0.18450185470283031), (37, 0.18815975077450275), (2, 0.18961193598806858), (0, 0.19334901683032513), (48, 0.19635861180722713), (1, 0.20237149111926556), (47, 0.20377699099481106), (49, 0.2112168986350298), (10, 0.212400758638978), (50, 0.21723414957523346), (12, 0.21791709400713444), (5, 0.2480470836162567), (51, 0.25461266189813614), (52, 0.27352872863411903), (36, 0.5626258999109268), (18, 0.5641599148511887), (53, 0.6439222395420074)]
computing accuracy for after removing block 28 . block score: 0.10445586871355772
removed block 28 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.116205. All blocks and scores: [(27, 0.1162051884457469), (23, 0.12323085311800241), (25, 0.12373425997793674), (24, 0.1291238572448492), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (41, 0.14461474120616913), (43, 0.1447495799511671), (17, 0.14762406423687935), (19, 0.15387777611613274), (40, 0.15473323874175549), (42, 0.15518486127257347), (9, 0.1576198674738407), (4, 0.16433029249310493), (14, 0.16527099162340164), (6, 0.16871571354568005), (46, 0.16967489384114742), (39, 0.16992546245455742), (45, 0.1716324109584093), (44, 0.17189611867070198), (13, 0.1729179173707962), (16, 0.17330581322312355), (38, 0.17402836866676807), (3, 0.1761795300990343), (11, 0.1827423870563507), (8, 0.18450185470283031), (37, 0.1858161985874176), (2, 0.18961193598806858), (48, 0.19294840656220913), (0, 0.19334901683032513), (47, 0.20037435553967953), (1, 0.20237149111926556), (49, 0.20871265977621078), (10, 0.212400758638978), (50, 0.21492432802915573), (12, 0.21791709400713444), (5, 0.2480470836162567), (51, 0.2530633211135864), (52, 0.2723194658756256), (36, 0.5583181604743004), (18, 0.5641599148511887), (53, 0.6474203839898109)]
computing accuracy for after removing block 27 . block score: 0.1162051884457469
removed block 27 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.123231. All blocks and scores: [(23, 0.12323085311800241), (25, 0.12373425997793674), (24, 0.1291238572448492), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (41, 0.14107157848775387), (43, 0.1418190859258175), (17, 0.14762406423687935), (42, 0.15150718204677105), (40, 0.15166622586548328), (19, 0.15387777611613274), (9, 0.1576198674738407), (4, 0.16433029249310493), (14, 0.16527099162340164), (46, 0.16699604131281376), (39, 0.1671060025691986), (6, 0.16871571354568005), (44, 0.16878194361925125), (45, 0.16936455108225346), (38, 0.17055923119187355), (13, 0.1729179173707962), (16, 0.17330581322312355), (3, 0.1761795300990343), (11, 0.1827423870563507), (37, 0.18279701098799706), (8, 0.18450185470283031), (2, 0.18961193598806858), (48, 0.18961399234831333), (0, 0.19334901683032513), (47, 0.19697809219360352), (1, 0.20237149111926556), (49, 0.20672715455293655), (50, 0.21239057928323746), (10, 0.212400758638978), (12, 0.21791709400713444), (5, 0.2480470836162567), (51, 0.2511538341641426), (52, 0.2709101215004921), (36, 0.55284383893013), (18, 0.5641599148511887), (53, 0.6500711143016815)]
computing accuracy for after removing block 23 . block score: 0.12323085311800241
removed block 23 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.123699. All blocks and scores: [(25, 0.12369898613542318), (24, 0.12558578420430422), (21, 0.13077533803880215), (22, 0.13335224241018295), (15, 0.1367457378655672), (20, 0.1386471576988697), (7, 0.13889748975634575), (41, 0.13971862569451332), (43, 0.1417806576937437), (17, 0.14762406423687935), (42, 0.14942137524485588), (40, 0.15090573392808437), (19, 0.15387777611613274), (9, 0.1576198674738407), (4, 0.16433029249310493), (14, 0.16527099162340164), (46, 0.165355721488595), (39, 0.16744758561253548), (44, 0.16746528446674347), (6, 0.16871571354568005), (45, 0.16901392862200737), (38, 0.16990106366574764), (13, 0.1729179173707962), (16, 0.17330581322312355), (3, 0.1761795300990343), (11, 0.1827423870563507), (8, 0.18450185470283031), (37, 0.1851132232695818), (48, 0.18780362978577614), (2, 0.18961193598806858), (0, 0.19334901683032513), (47, 0.19467893056571484), (1, 0.20237149111926556), (49, 0.20561565645039082), (50, 0.2105124406516552), (10, 0.212400758638978), (12, 0.21791709400713444), (5, 0.2480470836162567), (51, 0.24970688857138157), (52, 0.26907191798090935), (36, 0.5534424856305122), (18, 0.5641599148511887), (53, 0.6494711562991142)]
computing accuracy for after removing block 25 . block score: 0.12369898613542318
removed block 25 current accuracy 0.9886 loss from initial  0.011399999999999966
training start
training epoch 0 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 2 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 4 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 7 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 8 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 9 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 10 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 15 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 16 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 19 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 20 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 26 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 35 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 12
[activation mean]: block to remove picked: 7, with score 0.134888. All blocks and scores: [(7, 0.1348880771547556), (15, 0.13962308317422867), (21, 0.14501877315342426), (22, 0.1465609110891819), (24, 0.14669637940824032), (17, 0.14807351492345333), (20, 0.1483184527605772), (43, 0.15440766140818596), (41, 0.15493896417319775), (9, 0.15629813633859158), (40, 0.15997361950576305), (19, 0.16006173007190228), (4, 0.16130051016807556), (14, 0.16396383754909039), (6, 0.16698021441698074), (13, 0.16916688345372677), (42, 0.16919236816465855), (16, 0.17071732319891453), (3, 0.17408417351543903), (44, 0.17454866878688335), (39, 0.1762471590191126), (45, 0.17810926586389542), (46, 0.17832169122993946), (11, 0.1797430980950594), (38, 0.18203227035701275), (8, 0.18216405995190144), (2, 0.1855091191828251), (0, 0.1888012047857046), (37, 0.1957006473094225), (1, 0.19657267816364765), (48, 0.20627628453075886), (47, 0.20702918618917465), (10, 0.21038681082427502), (12, 0.21450137346982956), (49, 0.2147034015506506), (50, 0.22441046498715878), (5, 0.24218344874680042), (51, 0.25801726430654526), (52, 0.28032077848911285), (18, 0.5472824275493622), (36, 0.5700891464948654), (53, 0.6243966668844223)]
computing accuracy for after removing block 7 . block score: 0.1348880771547556
removed block 7 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 15, with score 0.138457. All blocks and scores: [(15, 0.1384567879140377), (17, 0.1405661329627037), (24, 0.14133050106465816), (22, 0.14258269406855106), (21, 0.14461293444037437), (20, 0.14601873233914375), (41, 0.14762505888938904), (43, 0.14984858967363834), (9, 0.1578531228005886), (40, 0.1579285617917776), (19, 0.15855427272617817), (14, 0.15873641148209572), (13, 0.15993696451187134), (4, 0.16130051016807556), (42, 0.16466648690402508), (16, 0.16576758213341236), (6, 0.16698021441698074), (46, 0.17308995313942432), (44, 0.17375656962394714), (3, 0.17408417351543903), (11, 0.1747812107205391), (39, 0.17496991902589798), (45, 0.1753388363867998), (8, 0.18015578016638756), (38, 0.18222684040665627), (2, 0.1855091191828251), (0, 0.1888012047857046), (37, 0.19209279119968414), (1, 0.19657267816364765), (48, 0.20058887265622616), (47, 0.20513147301971912), (12, 0.20810502395033836), (10, 0.21044370159506798), (49, 0.2128007486462593), (50, 0.22076412290334702), (5, 0.24218344874680042), (51, 0.2558630369603634), (52, 0.2783598564565182), (18, 0.5435418859124184), (36, 0.5614843517541885), (53, 0.6323141902685165)]
computing accuracy for after removing block 15 . block score: 0.1384567879140377
removed block 15 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 22, with score 0.138384. All blocks and scores: [(22, 0.13838356733322144), (24, 0.13896111585199833), (21, 0.13973742350935936), (20, 0.1417226307094097), (17, 0.14204499870538712), (41, 0.14551964029669762), (43, 0.15073144435882568), (40, 0.15537800081074238), (9, 0.1578531228005886), (14, 0.15873641148209572), (19, 0.15962773375213146), (13, 0.15993696451187134), (4, 0.16130051016807556), (42, 0.16186164878308773), (6, 0.16698021441698074), (16, 0.17071926593780518), (44, 0.1709453146904707), (39, 0.1734093725681305), (3, 0.17408417351543903), (11, 0.1747812107205391), (45, 0.17533405497670174), (46, 0.17550929635763168), (8, 0.18015578016638756), (38, 0.18270208686590195), (2, 0.1855091191828251), (0, 0.1888012047857046), (37, 0.19265568628907204), (1, 0.19657267816364765), (48, 0.20120235532522202), (47, 0.20579147711396217), (12, 0.20810502395033836), (10, 0.21044370159506798), (49, 0.21245921216905117), (50, 0.22132172994315624), (5, 0.24218344874680042), (51, 0.25609811395406723), (52, 0.2792510464787483), (18, 0.5406172648072243), (36, 0.558800645172596), (53, 0.6313887238502502)]
computing accuracy for after removing block 22 . block score: 0.13838356733322144
removed block 22 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.132072. All blocks and scores: [(24, 0.13207216188311577), (41, 0.1393739301711321), (21, 0.13973742350935936), (20, 0.1417226307094097), (17, 0.14204499870538712), (43, 0.14657146111130714), (40, 0.15107174217700958), (42, 0.1546988319605589), (9, 0.1578531228005886), (14, 0.15873641148209572), (19, 0.15962773375213146), (13, 0.15993696451187134), (4, 0.16130051016807556), (44, 0.16470429673790932), (6, 0.16698021441698074), (46, 0.16892793774604797), (39, 0.170096879824996), (16, 0.17071926593780518), (45, 0.17098093032836914), (3, 0.17408417351543903), (11, 0.1747812107205391), (8, 0.18015578016638756), (38, 0.18026286736130714), (2, 0.1855091191828251), (0, 0.1888012047857046), (37, 0.19187121465802193), (48, 0.19390434958040714), (1, 0.19657267816364765), (47, 0.20017927885055542), (12, 0.20810502395033836), (49, 0.2084027323871851), (10, 0.21044370159506798), (50, 0.215667637065053), (5, 0.24218344874680042), (51, 0.2527797445654869), (52, 0.2758132182061672), (18, 0.5406172648072243), (36, 0.5532233119010925), (53, 0.6349067613482475)]
computing accuracy for after removing block 24 . block score: 0.13207216188311577
removed block 24 current accuracy 0.9804 loss from initial  0.01959999999999995
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 41, with score 0.131369. All blocks and scores: [(41, 0.13136903010308743), (21, 0.13973742350935936), (43, 0.14125374518334866), (20, 0.1417226307094097), (17, 0.14204499870538712), (40, 0.14650565944612026), (42, 0.14790132269263268), (9, 0.1578531228005886), (44, 0.15817286632955074), (14, 0.15873641148209572), (19, 0.15962773375213146), (13, 0.15993696451187134), (4, 0.16130051016807556), (46, 0.16217480413615704), (45, 0.1666947603225708), (6, 0.16698021441698074), (39, 0.16784288734197617), (16, 0.17071926593780518), (3, 0.17408417351543903), (11, 0.1747812107205391), (38, 0.1769820749759674), (8, 0.18015578016638756), (2, 0.1855091191828251), (48, 0.18699047900736332), (0, 0.1888012047857046), (37, 0.18935945816338062), (47, 0.19587690010666847), (1, 0.19657267816364765), (49, 0.20353016816079617), (12, 0.20810502395033836), (50, 0.20933332107961178), (10, 0.21044370159506798), (5, 0.24218344874680042), (51, 0.2473763693124056), (52, 0.27016182616353035), (18, 0.5406172648072243), (36, 0.54483912140131), (53, 0.6443324163556099)]
computing accuracy for after removing block 41 . block score: 0.13136903010308743
removed block 41 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 43, with score 0.139672. All blocks and scores: [(43, 0.1396718192845583), (21, 0.13973742350935936), (20, 0.1417226307094097), (17, 0.14204499870538712), (40, 0.14650565944612026), (42, 0.1473926454782486), (9, 0.1578531228005886), (44, 0.1581800878047943), (46, 0.1584168951958418), (14, 0.15873641148209572), (19, 0.15962773375213146), (13, 0.15993696451187134), (4, 0.16130051016807556), (45, 0.165330208837986), (6, 0.16698021441698074), (39, 0.16784288734197617), (16, 0.17071926593780518), (3, 0.17408417351543903), (11, 0.1747812107205391), (38, 0.1769820749759674), (8, 0.18015578016638756), (48, 0.18174866028130054), (2, 0.1855091191828251), (0, 0.1888012047857046), (37, 0.18935945816338062), (47, 0.19601748697459698), (1, 0.19657267816364765), (49, 0.2010034080594778), (50, 0.20573651231825352), (12, 0.20810502395033836), (10, 0.21044370159506798), (5, 0.24218344874680042), (51, 0.24457324482500553), (52, 0.26733438670635223), (18, 0.5406172648072243), (36, 0.54483912140131), (53, 0.6614049226045609)]
computing accuracy for after removing block 43 . block score: 0.1396718192845583
removed block 43 current accuracy 0.9676 loss from initial  0.032399999999999984
training start
training epoch 0 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 1 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 2 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 3 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 4 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 5 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 6 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 7 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 8 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 9 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 10 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 11 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 12 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 13 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 14 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 16 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 17 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 18 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 19 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 20 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 21 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 22 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 23 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 24 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 25 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 26 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 27 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 28 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 29 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 30 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 31 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 32 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 33 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 34 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 35 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 36 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 37 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 38 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 39 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 40 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 41 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 42 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 43 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 44 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 45 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 46 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 47 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 48 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 49 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.997600)
finished training. finished 50 epochs. accuracy 0.9976 topk_dict {'top1': 0.9976}
start iteration 18
[activation mean]: block to remove picked: 17, with score 0.150229. All blocks and scores: [(17, 0.15022946149110794), (9, 0.1576048508286476), (4, 0.158766008913517), (14, 0.16462564282119274), (40, 0.1648942492902279), (6, 0.16662907786667347), (13, 0.16860858909785748), (20, 0.16887127608060837), (21, 0.17022934556007385), (3, 0.1708000022917986), (16, 0.1718661691993475), (19, 0.1719280742108822), (42, 0.17375516705214977), (44, 0.17682884819805622), (11, 0.1770381648093462), (8, 0.17870236933231354), (46, 0.1792693678289652), (45, 0.17949330806732178), (39, 0.18044627457857132), (2, 0.18101461231708527), (0, 0.18404578045010567), (38, 0.18516816571354866), (1, 0.1937603112310171), (37, 0.19713287614285946), (47, 0.20806516520678997), (10, 0.20882651023566723), (48, 0.20916754752397537), (12, 0.2130588535219431), (49, 0.21466595493257046), (50, 0.22620222717523575), (5, 0.24233797937631607), (51, 0.25640716403722763), (52, 0.27934809029102325), (18, 0.5312973037362099), (36, 0.5617284327745438), (53, 0.6358247101306915)]
computing accuracy for after removing block 17 . block score: 0.15022946149110794
removed block 17 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 9, with score 0.157605. All blocks and scores: [(9, 0.1576048508286476), (40, 0.15818966180086136), (4, 0.158766008913517), (20, 0.16411643289029598), (14, 0.16462564282119274), (42, 0.16510131023824215), (21, 0.16632716543972492), (6, 0.16662907786667347), (44, 0.16845009289681911), (13, 0.16860858909785748), (19, 0.1706969328224659), (3, 0.1708000022917986), (16, 0.1718661691993475), (45, 0.1746349260210991), (39, 0.175677377730608), (11, 0.1770381648093462), (46, 0.17805101349949837), (8, 0.17870236933231354), (2, 0.18101461231708527), (38, 0.18170579709112644), (0, 0.18404578045010567), (37, 0.189507769420743), (1, 0.1937603112310171), (48, 0.20339208468794823), (47, 0.2061384581029415), (10, 0.20882651023566723), (49, 0.21039474569261074), (12, 0.2130588535219431), (50, 0.22120102681219578), (5, 0.24233797937631607), (51, 0.25396901182830334), (52, 0.2769014798104763), (18, 0.5171593353152275), (36, 0.5427280887961388), (53, 0.6400580778717995)]
computing accuracy for after removing block 9 . block score: 0.1576048508286476
removed block 9 current accuracy 0.9872 loss from initial  0.012800000000000034
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 40, with score 0.152121. All blocks and scores: [(40, 0.1521207969635725), (42, 0.15552755817770958), (4, 0.158766008913517), (14, 0.16018259525299072), (16, 0.16169695928692818), (44, 0.1629492063075304), (20, 0.16312887519598007), (21, 0.16516676731407642), (6, 0.16662907786667347), (13, 0.16675596870481968), (11, 0.16990347020328045), (46, 0.17001376673579216), (45, 0.17048269510269165), (3, 0.1708000022917986), (39, 0.17208950221538544), (19, 0.17458402179181576), (37, 0.17747182212769985), (38, 0.17780651524662971), (8, 0.17870236933231354), (2, 0.18101461231708527), (0, 0.18404578045010567), (48, 0.19148758798837662), (1, 0.1937603112310171), (12, 0.20152522437274456), (47, 0.20541838370263577), (49, 0.20618638955056667), (10, 0.20774323865771294), (50, 0.21326766721904278), (5, 0.24233797937631607), (51, 0.25050294771790504), (52, 0.27219919115304947), (18, 0.513234093785286), (36, 0.527755081653595), (53, 0.6541731581091881)]
computing accuracy for after removing block 40 . block score: 0.1521207969635725
removed block 40 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 42, with score 0.149958. All blocks and scores: [(42, 0.14995810762047768), (4, 0.158766008913517), (14, 0.16018259525299072), (16, 0.16169695928692818), (44, 0.16292086616158485), (20, 0.16312887519598007), (46, 0.16505291871726513), (21, 0.16516676731407642), (6, 0.16662907786667347), (13, 0.16675596870481968), (45, 0.1672458741813898), (11, 0.16990347020328045), (3, 0.1708000022917986), (39, 0.17208950221538544), (19, 0.17458402179181576), (37, 0.17747182212769985), (38, 0.17780651524662971), (8, 0.17870236933231354), (2, 0.18101461231708527), (0, 0.18404578045010567), (48, 0.18505541421473026), (1, 0.1937603112310171), (12, 0.20152522437274456), (49, 0.2030056230723858), (47, 0.20490804500877857), (50, 0.2071506455540657), (10, 0.20774323865771294), (5, 0.24233797937631607), (51, 0.2481526881456375), (52, 0.26915886253118515), (18, 0.513234093785286), (36, 0.527755081653595), (53, 0.6851246654987335)]
computing accuracy for after removing block 42 . block score: 0.14995810762047768
removed block 42 current accuracy 0.9762 loss from initial  0.023800000000000043
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 4, with score 0.158766. All blocks and scores: [(4, 0.158766008913517), (14, 0.16018259525299072), (16, 0.16169695928692818), (44, 0.16227164678275585), (20, 0.16312887519598007), (46, 0.1640815269201994), (21, 0.16516676731407642), (6, 0.16662907786667347), (13, 0.16675596870481968), (45, 0.1671361867338419), (11, 0.16990347020328045), (3, 0.1708000022917986), (39, 0.17208950221538544), (19, 0.17458402179181576), (37, 0.17747182212769985), (38, 0.17780651524662971), (8, 0.17870236933231354), (2, 0.18101461231708527), (48, 0.18240277282893658), (0, 0.18404578045010567), (1, 0.1937603112310171), (49, 0.20133900456130505), (12, 0.20152522437274456), (47, 0.20322534814476967), (50, 0.20526217110455036), (10, 0.20774323865771294), (5, 0.24233797937631607), (51, 0.24447111785411835), (52, 0.26567813009023666), (18, 0.513234093785286), (36, 0.527755081653595), (53, 0.7029973119497299)]
computing accuracy for after removing block 4 . block score: 0.158766008913517
removed block 4 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 16, with score 0.155870. All blocks and scores: [(16, 0.15586992725729942), (14, 0.1579252015799284), (44, 0.1619345284998417), (20, 0.16249175369739532), (21, 0.1645547840744257), (46, 0.16491993702948093), (11, 0.16552923806011677), (13, 0.16683959402143955), (45, 0.1676410175859928), (3, 0.1708000022917986), (6, 0.17201818712055683), (39, 0.1720692366361618), (38, 0.17766595259308815), (37, 0.17906569130718708), (19, 0.17961787432432175), (8, 0.1807940974831581), (2, 0.18101461231708527), (48, 0.18275241740047932), (0, 0.18404578045010567), (1, 0.1937603112310171), (49, 0.20006615296006203), (12, 0.20094877295196056), (47, 0.20168523490428925), (50, 0.20391840301454067), (10, 0.20941484160721302), (51, 0.2440747730433941), (5, 0.24845594353973866), (52, 0.2649666331708431), (18, 0.5173427909612656), (36, 0.5304441675543785), (53, 0.7008359432220459)]
computing accuracy for after removing block 16 . block score: 0.15586992725729942
removed block 16 current accuracy 0.9334 loss from initial  0.06659999999999999
since last training loss: 0.06420000000000003 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 44, with score 0.154593. All blocks and scores: [(44, 0.15459349937736988), (20, 0.15781550109386444), (14, 0.1579252015799284), (21, 0.1588469184935093), (11, 0.16552923806011677), (45, 0.16610891744494438), (13, 0.16683959402143955), (46, 0.16841204091906548), (3, 0.1708000022917986), (39, 0.17159710824489594), (6, 0.17201818712055683), (38, 0.17583479173481464), (37, 0.17890134826302528), (8, 0.1807940974831581), (2, 0.18101461231708527), (48, 0.18187615275382996), (0, 0.18404578045010567), (19, 0.18492038175463676), (1, 0.1937603112310171), (49, 0.1938972771167755), (47, 0.200509462505579), (12, 0.20094877295196056), (50, 0.20212322659790516), (10, 0.20941484160721302), (51, 0.24166666343808174), (5, 0.24845594353973866), (52, 0.2606751322746277), (36, 0.5138043016195297), (18, 0.5139495432376862), (53, 0.6906762644648552)]
computing accuracy for after removing block 44 . block score: 0.15459349937736988
removed block 44 current accuracy 0.9162 loss from initial  0.08379999999999999
since last training loss: 0.08140000000000003 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 45, with score 0.157692. All blocks and scores: [(45, 0.1576916091144085), (20, 0.15781550109386444), (14, 0.1579252015799284), (21, 0.1588469184935093), (46, 0.1627962775528431), (11, 0.16552923806011677), (13, 0.16683959402143955), (3, 0.1708000022917986), (39, 0.17159710824489594), (6, 0.17201818712055683), (48, 0.17513386346399784), (38, 0.17583479173481464), (37, 0.17890134826302528), (8, 0.1807940974831581), (2, 0.18101461231708527), (0, 0.18404578045010567), (19, 0.18492038175463676), (49, 0.1888966429978609), (1, 0.1937603112310171), (50, 0.1973920725286007), (47, 0.19929000735282898), (12, 0.20094877295196056), (10, 0.20941484160721302), (51, 0.2362645138055086), (5, 0.24845594353973866), (52, 0.2563568316400051), (36, 0.5138043016195297), (18, 0.5139495432376862), (53, 0.7323655858635902)]
computing accuracy for after removing block 45 . block score: 0.1576916091144085
removed block 45 current accuracy 0.8926 loss from initial  0.10740000000000005
since last training loss: 0.1050000000000001 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 46, with score 0.154997. All blocks and scores: [(46, 0.1549974624067545), (20, 0.15781550109386444), (14, 0.1579252015799284), (21, 0.1588469184935093), (11, 0.16552923806011677), (13, 0.16683959402143955), (48, 0.17048301734030247), (3, 0.1708000022917986), (39, 0.17159710824489594), (6, 0.17201818712055683), (38, 0.17583479173481464), (37, 0.17890134826302528), (8, 0.1807940974831581), (2, 0.18101461231708527), (0, 0.18404578045010567), (49, 0.18480068631470203), (19, 0.18492038175463676), (50, 0.193120701238513), (1, 0.1937603112310171), (47, 0.19853961654007435), (12, 0.20094877295196056), (10, 0.20941484160721302), (51, 0.2292430978268385), (5, 0.24845594353973866), (52, 0.2519420348107815), (36, 0.5138043016195297), (18, 0.5139495432376862), (53, 0.7909759283065796)]
computing accuracy for after removing block 46 . block score: 0.1549974624067545
removed block 46 current accuracy 0.8762 loss from initial  0.12380000000000002
training start
training epoch 0 val accuracy 0.975 topk_dict {'top1': 0.975} is_best True lr [0.001]
training epoch 1 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 2 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best True lr [0.001]
training epoch 3 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 4 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best True lr [0.001]
training epoch 5 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 6 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 7 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 8 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 9 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 10 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
training epoch 11 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 12 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 13 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 14 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best True lr [0.001]
training epoch 15 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 16 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 17 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 18 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 19 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 20 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 21 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 22 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 23 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 24 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 25 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 26 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 27 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 28 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 29 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 30 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 31 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 32 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 33 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 34 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 35 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 36 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 37 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 38 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 39 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 40 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 41 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 42 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 43 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 44 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 45 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 46 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 47 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 48 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 49 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.991000)
finished training. finished 50 epochs. accuracy 0.991 topk_dict {'top1': 0.991}
