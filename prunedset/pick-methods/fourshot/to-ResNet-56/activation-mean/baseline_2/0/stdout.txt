start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068702. All blocks and scores: [(26, 0.06870234198868275), (27, 0.0741223581135273), (31, 0.07421684544533491), (35, 0.07685474585741758), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08143280725926161), (24, 0.08224374894052744), (34, 0.08227442763745785), (33, 0.08310604561120272), (23, 0.08412310108542442), (32, 0.08623841684311628), (28, 0.0872054873034358), (22, 0.08930969890207052), (30, 0.09091433975845575), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13720723055303097), (39, 0.13744624331593513), (37, 0.14209549687802792), (38, 0.14290856197476387), (6, 0.14786463603377342), (41, 0.1508424561470747), (42, 0.15258264541625977), (4, 0.15538891777396202), (43, 0.15601677261292934), (44, 0.15883748047053814), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16798720695078373), (2, 0.18457405641674995), (46, 0.18493103049695492), (1, 0.20192440785467625), (47, 0.2080467976629734), (48, 0.21010252088308334), (49, 0.224680308252573), (50, 0.23862904869019985), (51, 0.25924162939190865), (52, 0.28526581451296806), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4550497271120548), (53, 0.6487655118107796)]
computing accuracy for after removing block 26 . block score: 0.06870234198868275
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074250. All blocks and scores: [(31, 0.07425017189234495), (27, 0.07438226789236069), (35, 0.0760756740346551), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08178351167589426), (34, 0.08181511238217354), (24, 0.08224374894052744), (33, 0.08314474113285542), (23, 0.08412310108542442), (32, 0.08550294954329729), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13959151320159435), (39, 0.1399664543569088), (37, 0.14363272115588188), (38, 0.1437524501234293), (6, 0.14786463603377342), (41, 0.15150794386863708), (42, 0.15349512174725533), (4, 0.15538891777396202), (43, 0.15715143270790577), (13, 0.1590876206755638), (44, 0.15911891870200634), (3, 0.16731475666165352), (45, 0.16931429505348206), (2, 0.18457405641674995), (46, 0.186824394389987), (1, 0.20192440785467625), (47, 0.20976067893207073), (48, 0.2109022866934538), (49, 0.2249483335763216), (50, 0.23839633911848068), (51, 0.2592626102268696), (52, 0.2852507643401623), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4592660255730152), (53, 0.6468537002801895)]
computing accuracy for after removing block 31 . block score: 0.07425017189234495
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074382. All blocks and scores: [(27, 0.07438226789236069), (35, 0.07612952496856451), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (34, 0.08106645382940769), (29, 0.08178351167589426), (24, 0.08224374894052744), (33, 0.08338531665503979), (23, 0.08412310108542442), (32, 0.08539257477968931), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14128642156720161), (40, 0.14169061370193958), (39, 0.14174902439117432), (37, 0.14439108967781067), (6, 0.14786463603377342), (41, 0.15143204852938652), (42, 0.15228785201907158), (4, 0.15538891777396202), (43, 0.15636706165969372), (44, 0.15833302028477192), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16788306273519993), (2, 0.18457405641674995), (46, 0.1864120475947857), (1, 0.20192440785467625), (47, 0.20843712612986565), (48, 0.21100311167538166), (49, 0.22473796643316746), (50, 0.23855118453502655), (51, 0.2591783180832863), (52, 0.28372708708047867), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.46568959951400757), (53, 0.6510000601410866)]
computing accuracy for after removing block 27 . block score: 0.07438226789236069
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075854. All blocks and scores: [(35, 0.07585428189486265), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14026966504752636), (39, 0.14322753064334393), (40, 0.14488770440220833), (37, 0.14594712853431702), (6, 0.14786463603377342), (41, 0.15189490653574467), (42, 0.15252277441322803), (4, 0.15538891777396202), (43, 0.15715407766401768), (44, 0.15864605642855167), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.1683814972639084), (2, 0.18457405641674995), (46, 0.18689549528062344), (1, 0.20192440785467625), (47, 0.20870989188551903), (48, 0.21123779565095901), (49, 0.22443696111440659), (50, 0.23874318413436413), (51, 0.2584992125630379), (52, 0.2828393988311291), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4712146706879139), (53, 0.6518600136041641)]
computing accuracy for after removing block 35 . block score: 0.07585428189486265
removed block 35 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076914. All blocks and scores: [(20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1385685559362173), (40, 0.13947991654276848), (39, 0.14093938656151295), (37, 0.14259942434728146), (6, 0.14786463603377342), (41, 0.15029864758253098), (42, 0.15072360262274742), (43, 0.15525723062455654), (44, 0.1552812773734331), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.16552621126174927), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.1869147438555956), (1, 0.20192440785467625), (48, 0.20716596953570843), (47, 0.20739650540053844), (49, 0.22507839649915695), (50, 0.23703056946396828), (51, 0.25911351665854454), (52, 0.28219735622406006), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.47133130580186844), (53, 0.6564537882804871)]
computing accuracy for after removing block 20 . block score: 0.07691387087106705
removed block 20 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079448. All blocks and scores: [(17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08003473933786154), (29, 0.08079283125698566), (21, 0.08103854302316904), (25, 0.08157523907721043), (24, 0.0828929403796792), (33, 0.08348109386861324), (23, 0.08391222264617682), (32, 0.0845849085599184), (28, 0.08620174136012793), (30, 0.088497344404459), (22, 0.09044258669018745), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13876904174685478), (40, 0.14043930359184742), (39, 0.14079759642481804), (37, 0.1433244775980711), (6, 0.14786463603377342), (41, 0.15065929107367992), (42, 0.15136869624257088), (4, 0.15538891777396202), (44, 0.1556632611900568), (43, 0.15633762441575527), (13, 0.1590876206755638), (45, 0.1662806160748005), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18815029971301556), (1, 0.20192440785467625), (48, 0.20721778832376003), (47, 0.208082502707839), (49, 0.22565172612667084), (50, 0.23704500310122967), (51, 0.2587750032544136), (52, 0.28254886716604233), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4735274948179722), (53, 0.6537546589970589)]
computing accuracy for after removing block 17 . block score: 0.07944803778082132
removed block 17 current accuracy 0.999 loss from initial  0.0010000000000000009
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 0 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 6
[activation mean]: block to remove picked: 16, with score 0.080494. All blocks and scores: [(16, 0.08049378078430891), (21, 0.08099170122295618), (29, 0.08262892346829176), (25, 0.08356109634041786), (33, 0.08380077220499516), (34, 0.08491654135286808), (23, 0.08713013306260109), (24, 0.08758161030709743), (32, 0.08850333839654922), (28, 0.09007833991199732), (30, 0.09205055888742208), (14, 0.09304100833833218), (22, 0.09395491797477007), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10254105553030968), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (12, 0.13088404387235641), (5, 0.13333929516375065), (39, 0.13801253959536552), (40, 0.13869628496468067), (37, 0.14244613982737064), (38, 0.14284108020365238), (41, 0.14843916334211826), (6, 0.14843924529850483), (42, 0.15180617198348045), (43, 0.15562153980135918), (4, 0.15597552619874477), (44, 0.15750132128596306), (13, 0.1591800209134817), (45, 0.16675496473908424), (3, 0.16804952174425125), (46, 0.1856578979641199), (2, 0.18588272482156754), (1, 0.20290620997548103), (47, 0.2073010765016079), (48, 0.20989301428198814), (49, 0.22453929856419563), (50, 0.24011359736323357), (51, 0.2588793933391571), (52, 0.28529252856969833), (0, 0.316878791898489), (18, 0.4311935305595398), (36, 0.4558991342782974), (53, 0.6484871655702591)]
computing accuracy for after removing block 16 . block score: 0.08049378078430891
removed block 16 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.079943. All blocks and scores: [(21, 0.07994326669722795), (29, 0.08229111693799496), (33, 0.08276316896080971), (25, 0.0834104847162962), (34, 0.08454221300780773), (23, 0.08675982430577278), (32, 0.08905906602740288), (24, 0.08950872160494328), (28, 0.08963470812886953), (30, 0.09101324528455734), (14, 0.09304100833833218), (22, 0.09372269455343485), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10170862171798944), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (12, 0.13088404387235641), (5, 0.13333929516375065), (39, 0.13671603985130787), (40, 0.13745998218655586), (37, 0.14212877303361893), (38, 0.1431175246834755), (6, 0.14843924529850483), (41, 0.14997790940105915), (42, 0.15088225528597832), (43, 0.15543087013065815), (4, 0.15597552619874477), (44, 0.15737612172961235), (13, 0.1591800209134817), (45, 0.16642526909708977), (3, 0.16804952174425125), (46, 0.1848247740417719), (2, 0.18588272482156754), (1, 0.20290620997548103), (47, 0.20686675608158112), (48, 0.20832686126232147), (49, 0.22382374107837677), (50, 0.23758140951395035), (51, 0.2570042163133621), (52, 0.2834351733326912), (0, 0.316878791898489), (18, 0.4334053359925747), (36, 0.45476019755005836), (53, 0.6497446373105049)]
computing accuracy for after removing block 21 . block score: 0.07994326669722795
removed block 21 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 29, with score 0.080853. All blocks and scores: [(29, 0.08085269015282393), (33, 0.08156977500766516), (25, 0.0827195355668664), (34, 0.08357100188732147), (23, 0.0847189212217927), (28, 0.08722357079386711), (32, 0.08765707165002823), (24, 0.08855286426842213), (30, 0.08958282973617315), (14, 0.09304100833833218), (22, 0.09407546557486057), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10170862171798944), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (12, 0.13088404387235641), (5, 0.13333929516375065), (39, 0.13682261668145657), (40, 0.1378477606922388), (37, 0.14234263449907303), (38, 0.14283950999379158), (6, 0.14843924529850483), (42, 0.15139703266322613), (41, 0.15198401361703873), (4, 0.15597552619874477), (43, 0.15609486028552055), (44, 0.15704855509102345), (13, 0.1591800209134817), (45, 0.16620052978396416), (3, 0.16804952174425125), (2, 0.18588272482156754), (46, 0.186519680544734), (1, 0.20290620997548103), (47, 0.20711930096149445), (48, 0.20776741579174995), (49, 0.22446015663444996), (50, 0.23730061575770378), (51, 0.2580159641802311), (52, 0.28423601761460304), (0, 0.316878791898489), (18, 0.4334053359925747), (36, 0.4559750147163868), (53, 0.6503522843122482)]
computing accuracy for after removing block 29 . block score: 0.08085269015282393
removed block 29 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 33, with score 0.081683. All blocks and scores: [(33, 0.08168346155434847), (34, 0.0826862184330821), (25, 0.0827195355668664), (23, 0.0847189212217927), (28, 0.08722357079386711), (32, 0.08746472746133804), (24, 0.08855286426842213), (30, 0.08897352777421474), (14, 0.09304100833833218), (22, 0.09407546557486057), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10170862171798944), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (12, 0.13088404387235641), (5, 0.13333929516375065), (39, 0.13641701824963093), (40, 0.13769614696502686), (38, 0.13933805003762245), (37, 0.14180460758507252), (6, 0.14843924529850483), (42, 0.14968796633183956), (41, 0.15121921710669994), (43, 0.1548559982329607), (44, 0.15490135364234447), (4, 0.15597552619874477), (13, 0.1591800209134817), (45, 0.16482079587876797), (3, 0.16804952174425125), (2, 0.18588272482156754), (46, 0.18628385476768017), (1, 0.20290620997548103), (47, 0.20581276156008244), (48, 0.2058576885610819), (49, 0.22345862910151482), (50, 0.23668395914137363), (51, 0.2568807825446129), (52, 0.28266825899481773), (0, 0.316878791898489), (18, 0.4334053359925747), (36, 0.4591715969145298), (53, 0.6534361243247986)]
computing accuracy for after removing block 33 . block score: 0.08168346155434847
removed block 33 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 34, with score 0.082419. All blocks and scores: [(34, 0.0824190303683281), (25, 0.0827195355668664), (23, 0.0847189212217927), (28, 0.08722357079386711), (32, 0.08746472746133804), (24, 0.08855286426842213), (30, 0.08897352777421474), (14, 0.09304100833833218), (22, 0.09407546557486057), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10170862171798944), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (12, 0.13088404387235641), (38, 0.13138801231980324), (39, 0.13195277005434036), (5, 0.13333929516375065), (40, 0.13358948566019535), (37, 0.13629291579127312), (42, 0.1458059698343277), (41, 0.14651738479733467), (6, 0.14843924529850483), (43, 0.14939872361719608), (44, 0.1499504502862692), (4, 0.15597552619874477), (45, 0.15878688916563988), (13, 0.1591800209134817), (3, 0.16804952174425125), (46, 0.18211714550852776), (2, 0.18588272482156754), (48, 0.1996716521680355), (47, 0.1998428087681532), (1, 0.20290620997548103), (49, 0.22186520509421825), (50, 0.2330565433949232), (51, 0.25491105020046234), (52, 0.2774486765265465), (0, 0.316878791898489), (18, 0.4334053359925747), (36, 0.45501748099923134), (53, 0.6637718826532364)]
computing accuracy for after removing block 34 . block score: 0.0824190303683281
removed block 34 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.082720. All blocks and scores: [(25, 0.0827195355668664), (23, 0.0847189212217927), (28, 0.08722357079386711), (32, 0.08746472746133804), (24, 0.08855286426842213), (30, 0.08897352777421474), (14, 0.09304100833833218), (22, 0.09407546557486057), (9, 0.09742058720439672), (11, 0.10104105714708567), (19, 0.10170862171798944), (8, 0.10724302846938372), (15, 0.11575217079371214), (7, 0.11796319391578436), (10, 0.12412854097783566), (38, 0.1284631695598364), (12, 0.13088404387235641), (40, 0.1328599862754345), (39, 0.13288545608520508), (5, 0.13333929516375065), (37, 0.1357643697410822), (42, 0.14757229201495647), (43, 0.1478027869015932), (44, 0.14842554554343224), (6, 0.14843924529850483), (41, 0.14880367368459702), (4, 0.15597552619874477), (45, 0.15686856396496296), (13, 0.1591800209134817), (3, 0.16804952174425125), (46, 0.18097404018044472), (2, 0.18588272482156754), (48, 0.19768301025032997), (47, 0.1989864706993103), (1, 0.20290620997548103), (49, 0.2229046579450369), (50, 0.2316845767199993), (51, 0.25468750670552254), (52, 0.27609098702669144), (0, 0.316878791898489), (18, 0.4334053359925747), (36, 0.4641994908452034), (53, 0.6684985458850861)]
computing accuracy for after removing block 25 . block score: 0.0827195355668664
removed block 25 current accuracy 0.9924 loss from initial  0.007600000000000051
training start
training epoch 0 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 1 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 2 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 4 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 5 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 6 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 9 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 13 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.091257. All blocks and scores: [(23, 0.09125743433833122), (32, 0.0926727494224906), (14, 0.09412926994264126), (24, 0.09455257654190063), (28, 0.09492445643991232), (9, 0.09864831250160933), (22, 0.09874123614281416), (30, 0.09917579311877489), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (10, 0.12585659883916378), (12, 0.13128016516566277), (5, 0.13140631653368473), (40, 0.13630343973636627), (39, 0.13645638339221478), (38, 0.1401772778481245), (37, 0.1414908692240715), (41, 0.1464201919734478), (6, 0.14784260280430317), (42, 0.1498244609683752), (43, 0.151786208152771), (44, 0.15521744824945927), (4, 0.15567885152995586), (13, 0.16253158450126648), (45, 0.16439413651823997), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.18232711032032967), (1, 0.19928722456097603), (47, 0.20374305732548237), (48, 0.2073107697069645), (49, 0.22163542546331882), (50, 0.236699303612113), (51, 0.25855743512511253), (52, 0.282245896756649), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.44514934346079826), (53, 0.6464309543371201)]
computing accuracy for after removing block 23 . block score: 0.09125743433833122
removed block 23 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.091074. All blocks and scores: [(32, 0.09107418730854988), (24, 0.09302567038685083), (28, 0.09336150996387005), (14, 0.09412926994264126), (30, 0.09750490449368954), (9, 0.09864831250160933), (22, 0.09874123614281416), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (10, 0.12585659883916378), (12, 0.13128016516566277), (5, 0.13140631653368473), (40, 0.13630853593349457), (39, 0.1386731006205082), (38, 0.13876240514218807), (37, 0.14085651189088821), (41, 0.1462056078016758), (6, 0.14784260280430317), (42, 0.14796972461044788), (43, 0.15037008747458458), (44, 0.15313854441046715), (4, 0.15567885152995586), (45, 0.16210684925317764), (13, 0.16253158450126648), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.18252617865800858), (1, 0.19928722456097603), (47, 0.20285524800419807), (48, 0.2054951023310423), (49, 0.22146521136164665), (50, 0.23529583029448986), (51, 0.25924237817525864), (52, 0.28223706409335136), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.4468607269227505), (53, 0.6471931040287018)]
computing accuracy for after removing block 32 . block score: 0.09107418730854988
removed block 32 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.093026. All blocks and scores: [(24, 0.09302567038685083), (28, 0.09336150996387005), (14, 0.09412926994264126), (30, 0.09750490449368954), (9, 0.09864831250160933), (22, 0.09874123614281416), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (10, 0.12585659883916378), (12, 0.13128016516566277), (5, 0.13140631653368473), (38, 0.1327525284141302), (40, 0.13496158830821514), (39, 0.13720531575381756), (37, 0.13806868344545364), (41, 0.14343427121639252), (42, 0.14481764286756516), (43, 0.14694547280669212), (6, 0.14784260280430317), (44, 0.1491488590836525), (4, 0.15567885152995586), (45, 0.15834892354905605), (13, 0.16253158450126648), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.18137347139418125), (1, 0.19928722456097603), (47, 0.19975396990776062), (48, 0.20162616483867168), (49, 0.22054775804281235), (50, 0.23220966197550297), (51, 0.2576592490077019), (52, 0.27791183069348335), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.4497092068195343), (53, 0.6538985818624496)]
computing accuracy for after removing block 24 . block score: 0.09302567038685083
removed block 24 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 28, with score 0.091913. All blocks and scores: [(28, 0.09191307984292507), (14, 0.09412926994264126), (30, 0.09483740665018559), (9, 0.09864831250160933), (22, 0.09874123614281416), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (10, 0.12585659883916378), (38, 0.1301540695130825), (12, 0.13128016516566277), (5, 0.13140631653368473), (40, 0.13590821251273155), (37, 0.13770867139101028), (39, 0.1402164325118065), (41, 0.14344841986894608), (42, 0.14426463283598423), (43, 0.14755125902593136), (6, 0.14784260280430317), (44, 0.1490897201001644), (4, 0.15567885152995586), (45, 0.15798870660364628), (13, 0.16253158450126648), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.1820441037416458), (47, 0.19890479370951653), (1, 0.19928722456097603), (48, 0.20017593912780285), (49, 0.22066747397184372), (50, 0.2302594780921936), (51, 0.2573050297796726), (52, 0.27657752856612206), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.4562678337097168), (53, 0.6538663804531097)]
computing accuracy for after removing block 28 . block score: 0.09191307984292507
removed block 28 current accuracy 0.9816 loss from initial  0.018399999999999972
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 30, with score 0.092866. All blocks and scores: [(30, 0.09286622423678637), (14, 0.09412926994264126), (9, 0.09864831250160933), (22, 0.09874123614281416), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (38, 0.12467758450657129), (10, 0.12585659883916378), (12, 0.13128016516566277), (5, 0.13140631653368473), (37, 0.13745345547795296), (40, 0.13936816900968552), (42, 0.14172433130443096), (41, 0.14303086325526237), (39, 0.14445411413908005), (43, 0.14699772372841835), (44, 0.14715264737606049), (6, 0.14784260280430317), (4, 0.15567885152995586), (45, 0.15779939107596874), (13, 0.16253158450126648), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.18228837102651596), (48, 0.19770375825464725), (47, 0.1980996336787939), (1, 0.19928722456097603), (49, 0.21942228823900223), (50, 0.22872873581945896), (51, 0.25707514956593513), (52, 0.27322931587696075), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.4661172032356262), (53, 0.6613632142543793)]
computing accuracy for after removing block 30 . block score: 0.09286622423678637
removed block 30 current accuracy 0.9456 loss from initial  0.054400000000000004
since last training loss: 0.054400000000000004 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.094129. All blocks and scores: [(14, 0.09412926994264126), (9, 0.09864831250160933), (22, 0.09874123614281416), (11, 0.10316256619989872), (19, 0.10553125943988562), (8, 0.10584475100040436), (7, 0.11620658170431852), (15, 0.11974070966243744), (38, 0.12051387503743172), (10, 0.12585659883916378), (12, 0.13128016516566277), (5, 0.13140631653368473), (37, 0.13799980655312538), (42, 0.1384051200002432), (41, 0.14181184209883213), (43, 0.14368520118296146), (44, 0.14412886835634708), (40, 0.14443359710276127), (6, 0.14784260280430317), (39, 0.1511363461613655), (45, 0.15543220564723015), (4, 0.15567885152995586), (13, 0.16253158450126648), (3, 0.16531501896679401), (2, 0.18087788857519627), (46, 0.18231206946074963), (48, 0.1965651586651802), (47, 0.1968731265515089), (1, 0.19928722456097603), (49, 0.2183586284518242), (50, 0.22754081152379513), (51, 0.2565915584564209), (52, 0.266949113458395), (0, 0.3081238940358162), (18, 0.42469514161348343), (36, 0.48223675414919853), (53, 0.6705250293016434)]
computing accuracy for after removing block 14 . block score: 0.09412926994264126
removed block 14 current accuracy 0.9326 loss from initial  0.06740000000000002
training start
training epoch 0 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 1 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 2 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 3 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 4 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 5 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 6 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 7 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 8 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 9 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 10 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 11 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 12 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 13 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 14 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 15 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 16 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 17 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 20 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 21 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 23 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 24 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 25 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 26 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 27 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 28 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 29 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 30 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 31 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 32 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 33 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 34 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 35 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 36 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 37 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 38 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 39 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 40 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 41 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 42 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 44 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 45 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 46 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 47 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 48 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 49 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.998000)
finished training. finished 50 epochs. accuracy 0.998 topk_dict {'top1': 0.998}
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.101083. All blocks and scores: [(9, 0.10108273196965456), (8, 0.10538348089903593), (11, 0.10662343539297581), (7, 0.11606823932379484), (19, 0.12070802319794893), (10, 0.125553447753191), (22, 0.1257458357140422), (15, 0.1279830876737833), (5, 0.12910091504454613), (12, 0.13030388019979), (39, 0.1355461198836565), (40, 0.13657664507627487), (38, 0.14099080301821232), (37, 0.14164026640355587), (41, 0.14542375691235065), (6, 0.14758170768618584), (42, 0.14910702966153622), (43, 0.15157514438033104), (44, 0.1547314766794443), (4, 0.15699742548167706), (3, 0.16371755860745907), (45, 0.16468818858265877), (13, 0.1660459078848362), (2, 0.17895141430199146), (46, 0.18116066604852676), (1, 0.19486674293875694), (47, 0.20212183520197868), (48, 0.20614813454449177), (49, 0.22016831301152706), (50, 0.2362266480922699), (51, 0.2568362168967724), (52, 0.2819928824901581), (0, 0.3043207600712776), (18, 0.4173184484243393), (36, 0.4495078846812248), (53, 0.6487423107028008)]
computing accuracy for after removing block 9 . block score: 0.10108273196965456
removed block 9 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 8, with score 0.105383. All blocks and scores: [(8, 0.10538348089903593), (11, 0.10671348217874765), (7, 0.11606823932379484), (19, 0.12015496101230383), (10, 0.12207171879708767), (22, 0.12341871578246355), (15, 0.12534720078110695), (12, 0.12721185572445393), (5, 0.12910091504454613), (39, 0.130902461707592), (40, 0.13349399156868458), (37, 0.13895408995449543), (38, 0.13920585624873638), (41, 0.14622298814356327), (42, 0.1467545460909605), (6, 0.14758170768618584), (43, 0.14948158152401447), (44, 0.1535175908356905), (4, 0.15699742548167706), (13, 0.1582201886922121), (45, 0.16299130022525787), (3, 0.16371755860745907), (2, 0.17895141430199146), (46, 0.1799132563173771), (1, 0.19486674293875694), (47, 0.19816484861075878), (48, 0.2033855877816677), (49, 0.21881170570850372), (50, 0.23514179699122906), (51, 0.255287230014801), (52, 0.27978093922138214), (0, 0.3043207600712776), (18, 0.41004087775945663), (36, 0.4458656907081604), (53, 0.6479334086179733)]
computing accuracy for after removing block 8 . block score: 0.10538348089903593
removed block 8 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 11, with score 0.108949. All blocks and scores: [(11, 0.10894858464598656), (7, 0.11606823932379484), (19, 0.11951857712119818), (22, 0.12353105191141367), (10, 0.12441040575504303), (15, 0.12514451332390308), (12, 0.12768900394439697), (5, 0.12910091504454613), (39, 0.12974126636981964), (40, 0.13273518346250057), (37, 0.13823637925088406), (38, 0.14237467013299465), (42, 0.14309578947722912), (41, 0.14494944922626019), (6, 0.14758170768618584), (43, 0.15043863840401173), (44, 0.15105713345110416), (4, 0.15699742548167706), (45, 0.16039397940039635), (13, 0.16111424565315247), (3, 0.16371755860745907), (2, 0.17895141430199146), (46, 0.18010975793004036), (1, 0.19486674293875694), (47, 0.19851135648787022), (48, 0.20228661969304085), (49, 0.2188199684023857), (50, 0.23384832218289375), (51, 0.25435226783156395), (52, 0.2785985544323921), (0, 0.3043207600712776), (18, 0.40897246077656746), (36, 0.4455547109246254), (53, 0.64474668353796)]
computing accuracy for after removing block 11 . block score: 0.10894858464598656
removed block 11 current accuracy 0.991 loss from initial  0.009000000000000008
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 7, with score 0.116068. All blocks and scores: [(7, 0.11606823932379484), (19, 0.11824235692620277), (22, 0.1219975808635354), (10, 0.12441040575504303), (15, 0.1251840926706791), (39, 0.12648368999361992), (5, 0.12910091504454613), (12, 0.12922192551195621), (40, 0.1302001867443323), (37, 0.1357271708548069), (38, 0.14043709076941013), (42, 0.14122124202549458), (41, 0.14465107582509518), (6, 0.14758170768618584), (43, 0.14856846444308758), (44, 0.15105348080396652), (4, 0.15699742548167706), (45, 0.16023161821067333), (13, 0.16077298298478127), (3, 0.16371755860745907), (2, 0.17895141430199146), (46, 0.17954172752797604), (1, 0.19486674293875694), (47, 0.19617380015552044), (48, 0.19816226325929165), (49, 0.2184745017439127), (50, 0.2310071587562561), (51, 0.25270652770996094), (52, 0.276083268225193), (0, 0.3043207600712776), (18, 0.40438515692949295), (36, 0.4444512762129307), (53, 0.6388553828001022)]
computing accuracy for after removing block 7 . block score: 0.11606823932379484
removed block 7 current accuracy 0.9834 loss from initial  0.016599999999999948
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 19, with score 0.117868. All blocks and scores: [(19, 0.11786806769669056), (22, 0.11897037830203772), (39, 0.12258994951844215), (15, 0.12259452231228352), (10, 0.12315090931952), (40, 0.1233107540756464), (5, 0.12910091504454613), (12, 0.13109948113560677), (37, 0.1315138339996338), (42, 0.13773213885724545), (38, 0.13876773416996002), (41, 0.14306343346834183), (43, 0.14490237645804882), (6, 0.14758170768618584), (44, 0.14807450026273727), (4, 0.15699742548167706), (45, 0.15771792829036713), (13, 0.1609889380633831), (3, 0.16371755860745907), (46, 0.1740946676582098), (2, 0.17895141430199146), (48, 0.19190786965191364), (47, 0.1938475016504526), (1, 0.19486674293875694), (49, 0.21452263556420803), (50, 0.224563492462039), (51, 0.2487358320504427), (52, 0.27032995223999023), (0, 0.3043207600712776), (18, 0.3969558887183666), (36, 0.43832478299736977), (53, 0.6378468722105026)]
computing accuracy for after removing block 19 . block score: 0.11786806769669056
removed block 19 current accuracy 0.9702 loss from initial  0.02980000000000005
since last training loss: 0.027800000000000047 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 22, with score 0.118682. All blocks and scores: [(22, 0.1186822522431612), (15, 0.12259452231228352), (39, 0.12276901956647635), (10, 0.12315090931952), (40, 0.1287868246436119), (5, 0.12910091504454613), (12, 0.13109948113560677), (37, 0.13375173322856426), (42, 0.13964292220771313), (38, 0.14048991538584232), (41, 0.14515725523233414), (6, 0.14758170768618584), (43, 0.14760428108274937), (44, 0.14926905930042267), (4, 0.15699742548167706), (13, 0.1609889380633831), (45, 0.16103499755263329), (3, 0.16371755860745907), (46, 0.17573791928589344), (2, 0.17895141430199146), (48, 0.19190969690680504), (47, 0.19455252960324287), (1, 0.19486674293875694), (49, 0.21451252326369286), (50, 0.22258459776639938), (51, 0.24725957587361336), (52, 0.26764004677534103), (0, 0.3043207600712776), (18, 0.3969558887183666), (36, 0.45349864289164543), (53, 0.6344911232590675)]
computing accuracy for after removing block 22 . block score: 0.1186822522431612
removed block 22 current accuracy 0.9452 loss from initial  0.05479999999999996
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 15, with score 0.122595. All blocks and scores: [(15, 0.12259452231228352), (10, 0.12315090931952), (39, 0.1267057117074728), (5, 0.12910091504454613), (37, 0.1308931466192007), (12, 0.13109948113560677), (40, 0.13458065129816532), (42, 0.13695817813277245), (38, 0.1399273630231619), (43, 0.14463315531611443), (44, 0.1456316914409399), (41, 0.14687101729214191), (6, 0.14758170768618584), (4, 0.15699742548167706), (45, 0.15850512869656086), (13, 0.1609889380633831), (3, 0.16371755860745907), (46, 0.17599655874073505), (2, 0.17895141430199146), (48, 0.19114800542593002), (47, 0.1946439314633608), (1, 0.19486674293875694), (49, 0.21516653336584568), (50, 0.21787315607070923), (51, 0.24616104550659657), (52, 0.26199352368712425), (0, 0.3043207600712776), (18, 0.3969558887183666), (36, 0.46798375993967056), (53, 0.6463121995329857)]
computing accuracy for after removing block 15 . block score: 0.12259452231228352
removed block 15 current accuracy 0.8978 loss from initial  0.10219999999999996
since last training loss: 0.10019999999999996 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 10, with score 0.123151. All blocks and scores: [(10, 0.12315090931952), (37, 0.1274817194789648), (5, 0.12910091504454613), (39, 0.13081633672118187), (12, 0.13109948113560677), (42, 0.13608272932469845), (38, 0.13725139200687408), (40, 0.1406101044267416), (43, 0.14412654750049114), (44, 0.14541801437735558), (41, 0.14666911959648132), (6, 0.14758170768618584), (45, 0.1546730101108551), (4, 0.15699742548167706), (13, 0.1609889380633831), (3, 0.16371755860745907), (46, 0.17632665298879147), (2, 0.17895141430199146), (48, 0.1864323541522026), (47, 0.19017620012164116), (1, 0.19486674293875694), (50, 0.2122760247439146), (49, 0.2133580446243286), (51, 0.24086768552660942), (52, 0.25329411774873734), (0, 0.3043207600712776), (18, 0.4096478894352913), (36, 0.4750024192035198), (53, 0.6445198133587837)]
computing accuracy for after removing block 10 . block score: 0.12315090931952
removed block 10 current accuracy 0.8282 loss from initial  0.17179999999999995
since last training loss: 0.16979999999999995 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 37, with score 0.123093. All blocks and scores: [(37, 0.12309306766837835), (39, 0.12725414521992207), (42, 0.12826555408537388), (5, 0.12910091504454613), (41, 0.13364092260599136), (12, 0.13497441820800304), (38, 0.13846096023917198), (44, 0.14234546199440956), (40, 0.14422520622611046), (43, 0.1443930696696043), (6, 0.14758170768618584), (45, 0.15171127580106258), (4, 0.15699742548167706), (3, 0.16371755860745907), (13, 0.16697140969336033), (2, 0.17895141430199146), (46, 0.18126308731734753), (48, 0.18209954351186752), (47, 0.18650328926742077), (1, 0.19486674293875694), (50, 0.21121863648295403), (49, 0.21315275691449642), (51, 0.2360607348382473), (52, 0.24527454376220703), (0, 0.3043207600712776), (18, 0.42035599052906036), (36, 0.4755609519779682), (53, 0.6382299810647964)]
computing accuracy for after removing block 37 . block score: 0.12309306766837835
removed block 37 current accuracy 0.8108 loss from initial  0.18920000000000003
training start
training epoch 0 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 1 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 2 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 3 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 4 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 5 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 6 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 7 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 8 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 9 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 10 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 11 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 12 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 13 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 14 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 15 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 16 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 17 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 18 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 20 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 21 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 22 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 24 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 26 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 27 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 28 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 29 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 31 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 32 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 33 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 34 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 36 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 37 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 38 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 39 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 40 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 42 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 43 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 44 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 45 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 46 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 47 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 48 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 49 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.993600)
finished training. finished 50 epochs. accuracy 0.9936 topk_dict {'top1': 0.9936}
