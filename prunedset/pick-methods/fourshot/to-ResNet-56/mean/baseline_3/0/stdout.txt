start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9908 loss from initial  0.009199999999999986
training start
training epoch 0 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 1 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 2 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (33, 0.04155272990465164), (34, 0.042144956067204475), (35, 0.04311100021004677), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (48, 0.04440980404615402), (49, 0.04369702748954296), (53, 0.050268642604351044)]
computing accuracy for after removing block 33 . block score: 0.04155272990465164
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (34, 0.042144956067204475), (35, 0.04311100021004677), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (48, 0.04440980404615402), (49, 0.04369702748954296), (53, 0.050268642604351044)]
computing accuracy for after removing block 34 . block score: 0.042144956067204475
removed block 34 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (35, 0.04311100021004677), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (48, 0.04440980404615402), (49, 0.04369702748954296), (53, 0.050268642604351044)]
computing accuracy for after removing block 35 . block score: 0.04311100021004677
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (48, 0.04440980404615402), (49, 0.04369702748954296), (53, 0.050268642604351044)]
computing accuracy for after removing block 49 . block score: 0.04369702748954296
removed block 49 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (48, 0.04440980404615402), (53, 0.050268642604351044)]
computing accuracy for after removing block 48 . block score: 0.04440980404615402
removed block 48 current accuracy 0.989 loss from initial  0.01100000000000001
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06567423045635223), (1, 0.05571506731212139), (2, 0.07441310584545135), (3, 0.07765693217515945), (4, 0.06131322681903839), (5, 0.09367995336651802), (6, 0.05917223356664181), (7, 0.05998365767300129), (8, 0.06629509851336479), (9, 0.07997827604413033), (10, 0.0794215090572834), (11, 0.06821052357554436), (12, 0.08173023909330368), (13, 0.07461404800415039), (14, 0.0849543958902359), (15, 0.0879148505628109), (16, 0.10413087531924248), (17, 0.1228448860347271), (18, 0.27044835314154625), (19, 0.06995002925395966), (20, 0.06811671331524849), (21, 0.06295071355998516), (22, 0.06120455823838711), (23, 0.05798693932592869), (24, 0.057362623512744904), (25, 0.05723544396460056), (26, 0.050965435802936554), (27, 0.05547996982932091), (28, 0.04659526236355305), (29, 0.0461937990039587), (36, 0.18048099428415298), (37, 0.05480348691344261), (38, 0.053586363792419434), (39, 0.054526561871171), (40, 0.05333986319601536), (41, 0.05051194131374359), (42, 0.0530843511223793), (43, 0.051393430680036545), (44, 0.04973592422902584), (45, 0.05079226568341255), (46, 0.046459635719656944), (47, 0.04476318880915642), (53, 0.050268642604351044)]
computing accuracy for after removing block 47 . block score: 0.04476318880915642
removed block 47 current accuracy 0.9724 loss from initial  0.027599999999999958
training start
training epoch 0 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 1 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 2 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 3 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 4 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 5 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 6 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 7 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 8 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 9 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 10 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 11 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 14 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 16 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 17 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 18 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 19 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 20 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 21 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 22 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 23 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 24 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 25 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 26 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 27 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 28 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 29 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 32 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 33 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 34 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 35 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 36 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 37 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 38 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 39 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 40 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 41 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 42 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 43 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 44 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 45 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 46 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 47 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 49 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (28, 0.04605371505022049), (29, 0.04566423036158085), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (44, 0.04914900287985802), (45, 0.050198595970869064), (46, 0.04590141400694847), (53, 0.04964952915906906)]
computing accuracy for after removing block 29 . block score: 0.04566423036158085
removed block 29 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (28, 0.04605371505022049), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (44, 0.04914900287985802), (45, 0.050198595970869064), (46, 0.04590141400694847), (53, 0.04964952915906906)]
computing accuracy for after removing block 46 . block score: 0.04590141400694847
removed block 46 current accuracy 0.9902 loss from initial  0.009800000000000031
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (28, 0.04605371505022049), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (44, 0.04914900287985802), (45, 0.050198595970869064), (53, 0.04964952915906906)]
computing accuracy for after removing block 28 . block score: 0.04605371505022049
removed block 28 current accuracy 0.9868 loss from initial  0.01319999999999999
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (44, 0.04914900287985802), (45, 0.050198595970869064), (53, 0.04964952915906906)]
computing accuracy for after removing block 44 . block score: 0.04914900287985802
removed block 44 current accuracy 0.9688 loss from initial  0.031200000000000006
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (45, 0.050198595970869064), (53, 0.04964952915906906)]
computing accuracy for after removing block 53 . block score: 0.04964952915906906
removed block 53 current accuracy 0.6698 loss from initial  0.33020000000000005
since last training loss: 0.32900000000000007 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06488761305809021), (1, 0.055073073133826256), (2, 0.07354734092950821), (3, 0.07674916088581085), (4, 0.06062096729874611), (5, 0.0926007330417633), (6, 0.05850476585328579), (7, 0.05931622348725796), (8, 0.06553730741143227), (9, 0.07902713119983673), (10, 0.07851818203926086), (11, 0.06743364036083221), (12, 0.08075500279664993), (13, 0.07374649867415428), (14, 0.08398640528321266), (15, 0.08689912036061287), (16, 0.10289906710386276), (17, 0.12140225991606712), (18, 0.2672036960721016), (19, 0.06915486231446266), (20, 0.06731296516954899), (21, 0.06220213137567043), (22, 0.06047721765935421), (23, 0.057299163192510605), (24, 0.05670029856264591), (25, 0.05656939372420311), (26, 0.050372397527098656), (27, 0.05485546216368675), (36, 0.17829234898090363), (37, 0.054169923067092896), (38, 0.05295868031680584), (39, 0.053883299231529236), (40, 0.05271783471107483), (41, 0.04992595501244068), (42, 0.05245170556008816), (43, 0.05079282447695732), (45, 0.050198595970869064)]
computing accuracy for after removing block 41 . block score: 0.04992595501244068
removed block 41 current accuracy 0.6652 loss from initial  0.3348
training start
training epoch 0 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.001]
training epoch 1 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 2 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 4 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 5 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 6 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.001]
training epoch 7 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.001]
training epoch 8 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.001]
training epoch 9 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.001]
training epoch 10 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.001]
training epoch 11 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best True lr [0.001]
training epoch 12 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 13 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 14 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 15 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 16 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 17 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 18 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 19 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 20 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 21 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 22 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 23 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 24 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 25 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 26 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 27 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 28 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 29 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 30 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 31 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 32 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 33 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 34 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 35 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 36 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 37 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 38 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 39 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 40 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 41 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 42 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 43 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 44 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 45 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 46 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 47 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 48 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 49 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.984800)
finished training. finished 50 epochs. accuracy 0.9848 topk_dict {'top1': 0.9848}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (26, 0.04976971447467804), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931), (40, 0.051975445821881294), (42, 0.05170077830553055), (43, 0.05006174370646477), (45, 0.04948802478611469)]
computing accuracy for after removing block 45 . block score: 0.04948802478611469
removed block 45 current accuracy 0.9514 loss from initial  0.04859999999999998
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (26, 0.04976971447467804), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931), (40, 0.051975445821881294), (42, 0.05170077830553055), (43, 0.05006174370646477)]
computing accuracy for after removing block 26 . block score: 0.04976971447467804
removed block 26 current accuracy 0.9436 loss from initial  0.056400000000000006
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931), (40, 0.051975445821881294), (42, 0.05170077830553055), (43, 0.05006174370646477)]
computing accuracy for after removing block 43 . block score: 0.05006174370646477
removed block 43 current accuracy 0.8594 loss from initial  0.14059999999999995
since last training loss: 0.12539999999999996 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931), (40, 0.051975445821881294), (42, 0.05170077830553055)]
computing accuracy for after removing block 42 . block score: 0.05170077830553055
removed block 42 current accuracy 0.7982 loss from initial  0.20179999999999998
since last training loss: 0.1866 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931), (40, 0.051975445821881294)]
computing accuracy for after removing block 40 . block score: 0.051975445821881294
removed block 40 current accuracy 0.719 loss from initial  0.281
since last training loss: 0.26580000000000004 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (38, 0.052234841510653496), (39, 0.053128682076931)]
computing accuracy for after removing block 38 . block score: 0.052234841510653496
removed block 38 current accuracy 0.6842 loss from initial  0.31579999999999997
since last training loss: 0.3006 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016), (39, 0.053128682076931)]
computing accuracy for after removing block 39 . block score: 0.053128682076931
removed block 39 current accuracy 0.6006 loss from initial  0.3994
since last training loss: 0.3842 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985), (37, 0.053447138518095016)]
computing accuracy for after removing block 37 . block score: 0.053447138518095016
removed block 37 current accuracy 0.565 loss from initial  0.43500000000000005
since last training loss: 0.41980000000000006 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06401512399315834), (1, 0.054548848420381546), (2, 0.07255913317203522), (3, 0.07572348415851593), (4, 0.05985269881784916), (5, 0.09144837409257889), (6, 0.05773799121379852), (7, 0.058591000735759735), (8, 0.06476025469601154), (9, 0.07790610566735268), (10, 0.07745863869786263), (11, 0.0666758231818676), (12, 0.07960237562656403), (13, 0.07284259051084518), (14, 0.08282431215047836), (15, 0.08583051338791847), (16, 0.10154015198349953), (17, 0.11971922591328621), (18, 0.263518288731575), (19, 0.06825539469718933), (20, 0.06643334031105042), (21, 0.06135448440909386), (22, 0.05967332050204277), (23, 0.05657709948718548), (24, 0.05602729134261608), (25, 0.055850204080343246), (27, 0.05421089194715023), (36, 0.17596385627985)]
computing accuracy for after removing block 27 . block score: 0.05421089194715023
removed block 27 current accuracy 0.5084 loss from initial  0.49160000000000004
training start
training epoch 0 val accuracy 0.728 topk_dict {'top1': 0.728} is_best True lr [0.001]
training epoch 1 val accuracy 0.7614 topk_dict {'top1': 0.7614} is_best True lr [0.001]
training epoch 2 val accuracy 0.7854 topk_dict {'top1': 0.7854} is_best True lr [0.001]
training epoch 3 val accuracy 0.809 topk_dict {'top1': 0.809} is_best True lr [0.001]
training epoch 4 val accuracy 0.8228 topk_dict {'top1': 0.8228} is_best True lr [0.001]
training epoch 5 val accuracy 0.8346 topk_dict {'top1': 0.8346} is_best True lr [0.001]
training epoch 6 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best True lr [0.001]
training epoch 7 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best True lr [0.001]
training epoch 8 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best True lr [0.001]
training epoch 9 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.001]
training epoch 10 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.001]
training epoch 11 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best True lr [0.001]
training epoch 12 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.001]
training epoch 13 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best True lr [0.001]
training epoch 14 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.001]
training epoch 15 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.001]
training epoch 16 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.001]
training epoch 17 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 18 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
training epoch 19 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.001]
training epoch 20 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.001]
training epoch 21 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 22 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.001]
training epoch 23 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.001]
training epoch 24 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.001]
training epoch 25 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 26 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.001]
training epoch 27 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.001]
training epoch 28 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 29 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.001]
training epoch 30 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.001]
training epoch 31 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 32 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.001]
training epoch 33 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 34 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.001]
training epoch 35 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 36 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 37 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 38 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 40 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 41 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.001]
training epoch 42 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 43 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.001]
training epoch 44 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 45 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 46 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 47 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 48 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 49 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.905000)
finished training. finished 50 epochs. accuracy 0.905 topk_dict {'top1': 0.905}
