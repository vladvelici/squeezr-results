start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9984 loss from initial  0.0016000000000000458
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.0342362392693758), (2, 0.04202817566692829), (4, 0.05322228744626045), (6, 0.03387458436191082), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (19, 0.0339395496994257), (20, 0.03238741401582956), (23, 0.038234585896134377), (25, 0.03558480925858021), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 20 . block score: 0.03238741401582956
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.0342362392693758), (2, 0.04202817566692829), (4, 0.05322228744626045), (6, 0.03387458436191082), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (19, 0.0339395496994257), (23, 0.038234585896134377), (25, 0.03558480925858021), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 6 . block score: 0.03387458436191082
removed block 6 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.0342362392693758), (2, 0.04202817566692829), (4, 0.05322228744626045), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (19, 0.0339395496994257), (23, 0.038234585896134377), (25, 0.03558480925858021), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 19 . block score: 0.0339395496994257
removed block 19 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.0342362392693758), (2, 0.04202817566692829), (4, 0.05322228744626045), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (23, 0.038234585896134377), (25, 0.03558480925858021), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 0 . block score: 0.0342362392693758
removed block 0 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04202817566692829), (4, 0.05322228744626045), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (23, 0.038234585896134377), (25, 0.03558480925858021), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 25 . block score: 0.03558480925858021
removed block 25 current accuracy 0.9922 loss from initial  0.007800000000000029
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04202817566692829), (4, 0.05322228744626045), (7, 0.04154222644865513), (8, 0.041009070351719856), (9, 0.06648899614810944), (10, 0.06237682327628136), (11, 0.05497456528246403), (12, 0.062126705422997475), (13, 0.05077830329537392), (14, 0.06617040187120438), (15, 0.07063843496143818), (16, 0.060022398829460144), (17, 0.0941152386367321), (18, 0.19118499755859375), (23, 0.038234585896134377), (26, 0.044832104817032814), (27, 0.03842857480049133), (28, 0.04189017601311207), (29, 0.04041758179664612), (30, 0.03727882634848356), (31, 0.04227733053267002), (32, 0.04250309616327286), (33, 0.04577937163412571), (34, 0.04655118100345135), (35, 0.039661215618252754), (36, 0.16077808290719986), (37, 0.04170875810086727), (38, 0.045022765174508095), (39, 0.04729989357292652), (40, 0.05067506060004234), (41, 0.051251037046313286), (42, 0.05267087370157242), (43, 0.05395425669848919), (44, 0.051605964079499245), (45, 0.0512715894728899), (46, 0.051214929670095444), (47, 0.04890699312090874), (48, 0.046611953526735306), (49, 0.04512947238981724), (50, 0.0448335912078619), (51, 0.04404095187783241), (52, 0.04336647130548954), (53, 0.05082247219979763)]
computing accuracy for after removing block 30 . block score: 0.03727882634848356
removed block 30 current accuracy 0.9886 loss from initial  0.011399999999999966
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 4 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (8, 0.04096780717372894), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (23, 0.03817920386791229), (26, 0.044764818623661995), (27, 0.03837464936077595), (28, 0.041825249791145325), (29, 0.04036433808505535), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (35, 0.03959991969168186), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 23 . block score: 0.03817920386791229
removed block 23 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (8, 0.04096780717372894), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (26, 0.044764818623661995), (27, 0.03837464936077595), (28, 0.041825249791145325), (29, 0.04036433808505535), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (35, 0.03959991969168186), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 27 . block score: 0.03837464936077595
removed block 27 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (8, 0.04096780717372894), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (26, 0.044764818623661995), (28, 0.041825249791145325), (29, 0.04036433808505535), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (35, 0.03959991969168186), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 35 . block score: 0.03959991969168186
removed block 35 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (8, 0.04096780717372894), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (26, 0.044764818623661995), (28, 0.041825249791145325), (29, 0.04036433808505535), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 29 . block score: 0.04036433808505535
removed block 29 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (8, 0.04096780717372894), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (26, 0.044764818623661995), (28, 0.041825249791145325), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 8 . block score: 0.04096780717372894
removed block 8 current accuracy 0.9862 loss from initial  0.013800000000000034
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.0420205220580101), (4, 0.05316212959587574), (7, 0.04150252230465412), (9, 0.06642318516969681), (10, 0.06230509467422962), (11, 0.0549149252474308), (12, 0.062032753601670265), (13, 0.05071433633565903), (14, 0.06610026210546494), (15, 0.07053676061332226), (16, 0.05993347615003586), (17, 0.09397231414914131), (18, 0.19083338975906372), (26, 0.044764818623661995), (28, 0.041825249791145325), (31, 0.04221624508500099), (32, 0.04242992773652077), (33, 0.045713797211647034), (34, 0.046479303389787674), (36, 0.16055041924118996), (37, 0.04164433851838112), (38, 0.04495254158973694), (39, 0.047226544469594955), (40, 0.05059575475752354), (41, 0.051171671599149704), (42, 0.052588196471333504), (43, 0.053871698677539825), (44, 0.051526425406336784), (45, 0.05119236931204796), (46, 0.05113721080124378), (47, 0.04883107356727123), (48, 0.04654064401984215), (49, 0.04506002925336361), (50, 0.04476518556475639), (51, 0.04397381655871868), (52, 0.04330039769411087), (53, 0.050742536783218384)]
computing accuracy for after removing block 7 . block score: 0.04150252230465412
removed block 7 current accuracy 0.9498 loss from initial  0.05020000000000002
training start
training epoch 0 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 1 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 2 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 3 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 4 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 9 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 16 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 23 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.04188024438917637), (4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (28, 0.04153965041041374), (31, 0.041911469772458076), (32, 0.04211968556046486), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (37, 0.04133766517043114), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 37 . block score: 0.04133766517043114
removed block 37 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.04188024438917637), (4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (28, 0.04153965041041374), (31, 0.041911469772458076), (32, 0.04211968556046486), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 28 . block score: 0.04153965041041374
removed block 28 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.04188024438917637), (4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (31, 0.041911469772458076), (32, 0.04211968556046486), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 2 . block score: 0.04188024438917637
removed block 2 current accuracy 0.9748 loss from initial  0.0252
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (31, 0.041911469772458076), (32, 0.04211968556046486), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 31 . block score: 0.041911469772458076
removed block 31 current accuracy 0.9668 loss from initial  0.03320000000000001
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (32, 0.04211968556046486), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 32 . block score: 0.04211968556046486
removed block 32 current accuracy 0.952 loss from initial  0.04800000000000004
since last training loss: 0.047800000000000065 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (52, 0.04298597387969494), (53, 0.05036400258541107)]
computing accuracy for after removing block 52 . block score: 0.04298597387969494
removed block 52 current accuracy 0.9436 loss from initial  0.056400000000000006
since last training loss: 0.05620000000000003 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (51, 0.04364870861172676), (53, 0.05036400258541107)]
computing accuracy for after removing block 51 . block score: 0.04364870861172676
removed block 51 current accuracy 0.9274 loss from initial  0.0726
since last training loss: 0.07240000000000002 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (50, 0.04443969577550888), (53, 0.05036400258541107)]
computing accuracy for after removing block 50 . block score: 0.04443969577550888
removed block 50 current accuracy 0.9052 loss from initial  0.0948
since last training loss: 0.09460000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.053052010014653206), (9, 0.06603828072547913), (10, 0.06186585873365402), (11, 0.054440196603536606), (12, 0.06158272176980972), (13, 0.05034894123673439), (14, 0.06569212675094604), (15, 0.07005997747182846), (16, 0.059485604986548424), (17, 0.09326286613941193), (18, 0.1893770433962345), (26, 0.04446538910269737), (33, 0.0453933160752058), (34, 0.046155206859111786), (36, 0.1594473123550415), (38, 0.04462072625756264), (39, 0.046875232830643654), (40, 0.05022234469652176), (41, 0.05079558864235878), (42, 0.05219595693051815), (43, 0.053478142246603966), (44, 0.05114657245576382), (45, 0.05081527680158615), (46, 0.050762467086315155), (47, 0.04847073554992676), (48, 0.046196093782782555), (49, 0.04473147913813591), (53, 0.05036400258541107)]
computing accuracy for after removing block 26 . block score: 0.04446538910269737
removed block 26 current accuracy 0.8706 loss from initial  0.12939999999999996
training start
training epoch 0 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best True lr [0.001]
training epoch 1 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 2 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best True lr [0.001]
training epoch 3 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 4 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 5 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 6 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 7 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 8 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 9 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 10 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 11 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 12 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 13 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 14 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 15 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 16 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 17 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 18 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 19 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 21 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 22 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 24 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 25 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 26 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 27 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 28 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 29 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 30 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 31 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 32 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 33 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 34 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 35 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 36 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 37 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 38 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 39 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 40 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 41 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 42 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 43 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 44 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 45 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 46 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 47 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 48 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
