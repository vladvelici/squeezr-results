start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.999 loss from initial  0.0010000000000000009
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 25 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (14, 0.04081123694777489), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (24, 0.04145362041890621), (25, 0.04043716564774513), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (30, 0.040910786017775536), (32, 0.040537068620324135), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 25 . block score: 0.04043716564774513
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (14, 0.04081123694777489), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (24, 0.04145362041890621), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (30, 0.040910786017775536), (32, 0.040537068620324135), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 32 . block score: 0.040537068620324135
removed block 32 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (14, 0.04081123694777489), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (24, 0.04145362041890621), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (30, 0.040910786017775536), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 14 . block score: 0.04081123694777489
removed block 14 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (24, 0.04145362041890621), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (30, 0.040910786017775536), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 30 . block score: 0.040910786017775536
removed block 30 current accuracy 0.989 loss from initial  0.01100000000000001
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (24, 0.04145362041890621), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 24 . block score: 0.04145362041890621
removed block 24 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09894359111785889), (1, 0.07638230919837952), (2, 0.09066585451364517), (3, 0.0810435339808464), (4, 0.0748046487569809), (5, 0.06973875313997269), (6, 0.07675441354513168), (7, 0.06068582646548748), (8, 0.05719935894012451), (9, 0.06179033778607845), (10, 0.06237703561782837), (11, 0.05163463391363621), (12, 0.06377873010933399), (13, 0.06689137779176235), (15, 0.0603225976228714), (16, 0.05004064179956913), (17, 0.05227777361869812), (18, 0.20828082039952278), (19, 0.04254750534892082), (21, 0.041993552818894386), (22, 0.04290401749312878), (27, 0.04258733615279198), (28, 0.04429619945585728), (29, 0.04187200218439102), (33, 0.042548319324851036), (36, 0.15863342583179474), (37, 0.042868660762906075), (38, 0.042037369683384895), (39, 0.04164156690239906), (40, 0.0422870758920908), (41, 0.042791739106178284), (42, 0.04401116073131561), (43, 0.04454478621482849), (44, 0.04387575760483742), (45, 0.04592777229845524), (46, 0.048664893954992294), (47, 0.05042189732193947), (48, 0.04768835008144379), (49, 0.04943859577178955), (50, 0.047063229605555534), (51, 0.04480201378464699), (52, 0.04353629983961582), (53, 0.05158740282058716)]
computing accuracy for after removing block 39 . block score: 0.04164156690239906
removed block 39 current accuracy 0.9772 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 1 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 2 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (21, 0.041953837499022484), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (29, 0.04183255508542061), (33, 0.0425115842372179), (36, 0.15849187597632408), (37, 0.04282860644161701), (38, 0.041996195912361145), (40, 0.042249396443367004), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 29 . block score: 0.04183255508542061
removed block 29 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (21, 0.041953837499022484), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (33, 0.0425115842372179), (36, 0.15849187597632408), (37, 0.04282860644161701), (38, 0.041996195912361145), (40, 0.042249396443367004), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 21 . block score: 0.041953837499022484
removed block 21 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (33, 0.0425115842372179), (36, 0.15849187597632408), (37, 0.04282860644161701), (38, 0.041996195912361145), (40, 0.042249396443367004), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 38 . block score: 0.041996195912361145
removed block 38 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (33, 0.0425115842372179), (36, 0.15849187597632408), (37, 0.04282860644161701), (40, 0.042249396443367004), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 40 . block score: 0.042249396443367004
removed block 40 current accuracy 0.9858 loss from initial  0.01419999999999999
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (33, 0.0425115842372179), (36, 0.15849187597632408), (37, 0.04282860644161701), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 33 . block score: 0.0425115842372179
removed block 33 current accuracy 0.9788 loss from initial  0.021199999999999997
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09886719658970833), (1, 0.0763002410531044), (2, 0.09058650210499763), (3, 0.08097236976027489), (4, 0.0747344121336937), (5, 0.06967997923493385), (6, 0.07667462527751923), (7, 0.0606377050280571), (8, 0.05714268423616886), (9, 0.06173393502831459), (10, 0.06232921779155731), (11, 0.051580728963017464), (12, 0.06372553296387196), (13, 0.06683332286775112), (15, 0.06026857905089855), (16, 0.05000311695039272), (17, 0.05224388465285301), (18, 0.20807037502527237), (19, 0.04251229763031006), (22, 0.04286825284361839), (27, 0.042549747973680496), (28, 0.04426651448011398), (36, 0.15849187597632408), (37, 0.04282860644161701), (41, 0.042751139029860497), (42, 0.04397177696228027), (43, 0.04450329393148422), (44, 0.04383574426174164), (45, 0.04588611237704754), (46, 0.04862042888998985), (47, 0.05037633888423443), (48, 0.0476458165794611), (49, 0.04939523711800575), (50, 0.0470193512737751), (51, 0.044761598110198975), (52, 0.04349389858543873), (53, 0.051538389176130295)]
computing accuracy for after removing block 19 . block score: 0.04251229763031006
removed block 19 current accuracy 0.975 loss from initial  0.025000000000000022
training start
training epoch 0 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 1 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 2 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 3 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 4 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 5 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 6 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 7 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 8 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 9 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 10 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 11 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 12 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 13 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 14 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 15 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 16 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 17 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 18 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 19 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 20 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 21 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 23 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 24 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 25 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 26 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 27 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 28 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 29 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 33 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 34 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 35 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 36 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 39 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 41 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 42 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 43 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 44 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 45 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 48 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 49 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (22, 0.04228843376040459), (27, 0.04194372147321701), (28, 0.043716706335544586), (36, 0.1559373326599598), (37, 0.042170656844973564), (41, 0.04209060221910477), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (52, 0.04283934459090233), (53, 0.050734445452690125)]
computing accuracy for after removing block 27 . block score: 0.04194372147321701
removed block 27 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (22, 0.04228843376040459), (28, 0.043716706335544586), (36, 0.1559373326599598), (37, 0.042170656844973564), (41, 0.04209060221910477), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (52, 0.04283934459090233), (53, 0.050734445452690125)]
computing accuracy for after removing block 41 . block score: 0.04209060221910477
removed block 41 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (22, 0.04228843376040459), (28, 0.043716706335544586), (36, 0.1559373326599598), (37, 0.042170656844973564), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (52, 0.04283934459090233), (53, 0.050734445452690125)]
computing accuracy for after removing block 37 . block score: 0.042170656844973564
removed block 37 current accuracy 0.981 loss from initial  0.019000000000000017
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (22, 0.04228843376040459), (28, 0.043716706335544586), (36, 0.1559373326599598), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (52, 0.04283934459090233), (53, 0.050734445452690125)]
computing accuracy for after removing block 22 . block score: 0.04228843376040459
removed block 22 current accuracy 0.961 loss from initial  0.039000000000000035
since last training loss: 0.037800000000000056 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (28, 0.043716706335544586), (36, 0.1559373326599598), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (52, 0.04283934459090233), (53, 0.050734445452690125)]
computing accuracy for after removing block 52 . block score: 0.04283934459090233
removed block 52 current accuracy 0.9238 loss from initial  0.07620000000000005
since last training loss: 0.07500000000000007 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (28, 0.043716706335544586), (36, 0.1559373326599598), (42, 0.04331361502408981), (43, 0.04382625222206116), (44, 0.04317478463053703), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (53, 0.050734445452690125)]
computing accuracy for after removing block 44 . block score: 0.04317478463053703
removed block 44 current accuracy 0.9064 loss from initial  0.09360000000000002
since last training loss: 0.09240000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (28, 0.043716706335544586), (36, 0.1559373326599598), (42, 0.04331361502408981), (43, 0.04382625222206116), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (53, 0.050734445452690125)]
computing accuracy for after removing block 42 . block score: 0.04331361502408981
removed block 42 current accuracy 0.8688 loss from initial  0.13119999999999998
since last training loss: 0.13 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (28, 0.043716706335544586), (36, 0.1559373326599598), (43, 0.04382625222206116), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (53, 0.050734445452690125)]
computing accuracy for after removing block 28 . block score: 0.043716706335544586
removed block 28 current accuracy 0.7776 loss from initial  0.22240000000000004
since last training loss: 0.22120000000000006 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09739252179861069), (1, 0.07516925409436226), (2, 0.08924835175275803), (3, 0.07974744960665703), (4, 0.07364724949002266), (5, 0.06862889602780342), (6, 0.07548422366380692), (7, 0.05975379981100559), (8, 0.056285636499524117), (9, 0.06082574278116226), (10, 0.06140863336622715), (11, 0.05084707774221897), (12, 0.06282477453351021), (13, 0.06592771224677563), (15, 0.05939181335270405), (16, 0.04936928488314152), (17, 0.05157064460217953), (18, 0.20484061166644096), (36, 0.1559373326599598), (43, 0.04382625222206116), (45, 0.04518859647214413), (46, 0.047882989048957825), (47, 0.04961725324392319), (48, 0.04693318344652653), (49, 0.04866531305015087), (50, 0.04630765877664089), (51, 0.04408728890120983), (53, 0.050734445452690125)]
computing accuracy for after removing block 43 . block score: 0.04382625222206116
removed block 43 current accuracy 0.7394 loss from initial  0.26060000000000005
training start
training epoch 0 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 1 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.001]
training epoch 2 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.001]
training epoch 3 val accuracy 0.963 topk_dict {'top1': 0.963} is_best True lr [0.001]
training epoch 4 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.001]
training epoch 5 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.001]
training epoch 6 val accuracy 0.968 topk_dict {'top1': 0.968} is_best True lr [0.001]
training epoch 7 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.001]
training epoch 8 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.001]
training epoch 9 val accuracy 0.972 topk_dict {'top1': 0.972} is_best True lr [0.001]
training epoch 10 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 11 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 12 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 13 val accuracy 0.973 topk_dict {'top1': 0.973} is_best True lr [0.001]
training epoch 14 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.001]
training epoch 15 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.001]
training epoch 16 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 17 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 18 val accuracy 0.975 topk_dict {'top1': 0.975} is_best True lr [0.001]
training epoch 19 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 20 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best True lr [0.001]
training epoch 21 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 23 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 24 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 25 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 26 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 27 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.001]
training epoch 28 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 29 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 30 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 31 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 32 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 33 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 34 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 35 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 36 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 37 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 38 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 39 val accuracy 0.977 topk_dict {'top1': 0.977} is_best True lr [0.001]
training epoch 40 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.001]
training epoch 41 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 42 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 43 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 44 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 45 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 46 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 47 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 48 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 49 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.977000)
finished training. finished 50 epochs. accuracy 0.977 topk_dict {'top1': 0.977}
