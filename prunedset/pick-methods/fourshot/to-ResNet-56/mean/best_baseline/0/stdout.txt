start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.996 loss from initial  0.0040000000000000036
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 2 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (29, 0.04711625911295414), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (48, 0.044870615005493164), (49, 0.04675511457026005), (50, 0.04428320936858654), (51, 0.04709475301206112), (53, 0.05361795425415039)]
computing accuracy for after removing block 50 . block score: 0.04428320936858654
removed block 50 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (29, 0.04711625911295414), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (48, 0.044870615005493164), (49, 0.04675511457026005), (51, 0.04709475301206112), (53, 0.05361795425415039)]
computing accuracy for after removing block 48 . block score: 0.044870615005493164
removed block 48 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (29, 0.04711625911295414), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (49, 0.04675511457026005), (51, 0.04709475301206112), (53, 0.05361795425415039)]
computing accuracy for after removing block 49 . block score: 0.04675511457026005
removed block 49 current accuracy 0.985 loss from initial  0.015000000000000013
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (29, 0.04711625911295414), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (51, 0.04709475301206112), (53, 0.05361795425415039)]
computing accuracy for after removing block 51 . block score: 0.04709475301206112
removed block 51 current accuracy 0.95 loss from initial  0.050000000000000044
since last training loss: 0.050000000000000044 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (29, 0.04711625911295414), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (53, 0.05361795425415039)]
computing accuracy for after removing block 29 . block score: 0.04711625911295414
removed block 29 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05400000000000005 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05729574337601662), (1, 0.07391077280044556), (2, 0.07894883677363396), (3, 0.09380914643406868), (4, 0.07509956508874893), (5, 0.09897292777895927), (6, 0.09057333692908287), (7, 0.08044072613120079), (8, 0.08190097287297249), (9, 0.09517859667539597), (10, 0.09534537419676781), (11, 0.07676231861114502), (12, 0.1021089218556881), (13, 0.08729089424014091), (14, 0.07670528814196587), (15, 0.06838871352374554), (16, 0.08270709961652756), (17, 0.0744827426970005), (18, 0.2623070329427719), (19, 0.06593914330005646), (20, 0.06622323021292686), (21, 0.06672362983226776), (22, 0.0655229277908802), (23, 0.061007093638181686), (24, 0.06466370820999146), (25, 0.05947573110461235), (26, 0.05383865907788277), (27, 0.05355665273964405), (28, 0.05341978371143341), (35, 0.047623638063669205), (36, 0.18342144414782524), (37, 0.05663675256073475), (38, 0.056053441017866135), (39, 0.05632832273840904), (40, 0.05083194747567177), (41, 0.04979277402162552), (42, 0.05008120276033878), (43, 0.048785747960209846), (44, 0.05070798099040985), (45, 0.048938147723674774), (46, 0.048514194786548615), (47, 0.05037922225892544), (53, 0.05361795425415039)]
computing accuracy for after removing block 35 . block score: 0.047623638063669205
removed block 35 current accuracy 0.9352 loss from initial  0.06479999999999997
training start
training epoch 0 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 1 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 2 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 3 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 4 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 5 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 6 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 7 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 8 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 9 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 11 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 12 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 13 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 14 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 15 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 16 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 17 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 18 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 19 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 20 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 21 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 22 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 23 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 24 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 27 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 28 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 30 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 32 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 35 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 36 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 41 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 42 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 43 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 44 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 45 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 46 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 47 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 48 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 49 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (41, 0.049074409529566765), (42, 0.049352286383509636), (43, 0.048077382147312164), (44, 0.049980826675891876), (45, 0.04822654277086258), (46, 0.04780849628150463), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 46 . block score: 0.04780849628150463
removed block 46 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (41, 0.049074409529566765), (42, 0.049352286383509636), (43, 0.048077382147312164), (44, 0.049980826675891876), (45, 0.04822654277086258), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 43 . block score: 0.048077382147312164
removed block 43 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (41, 0.049074409529566765), (42, 0.049352286383509636), (44, 0.049980826675891876), (45, 0.04822654277086258), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 45 . block score: 0.04822654277086258
removed block 45 current accuracy 0.9794 loss from initial  0.02059999999999995
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (41, 0.049074409529566765), (42, 0.049352286383509636), (44, 0.049980826675891876), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 41 . block score: 0.049074409529566765
removed block 41 current accuracy 0.9672 loss from initial  0.03280000000000005
since last training loss: 0.03160000000000007 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (42, 0.049352286383509636), (44, 0.049980826675891876), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 42 . block score: 0.049352286383509636
removed block 42 current accuracy 0.9476 loss from initial  0.0524
since last training loss: 0.05120000000000002 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05646003223955631), (1, 0.07283071801066399), (2, 0.07778709009289742), (3, 0.09244861081242561), (4, 0.07396843284368515), (5, 0.09766832366585732), (6, 0.08926814794540405), (7, 0.0792885310947895), (8, 0.08070994913578033), (9, 0.09384075552225113), (10, 0.09396908059716225), (11, 0.07567131519317627), (12, 0.10062848776578903), (13, 0.08606402575969696), (14, 0.07566983252763748), (15, 0.06744404882192612), (16, 0.08153074607253075), (17, 0.07341490685939789), (18, 0.25833335146307945), (19, 0.06497384235262871), (20, 0.06526913493871689), (21, 0.06574758887290955), (22, 0.0645616389811039), (23, 0.060121309012174606), (24, 0.0637266393750906), (25, 0.05861998163163662), (26, 0.05304702930152416), (27, 0.05279905907809734), (28, 0.052649738267064095), (36, 0.18067172914743423), (37, 0.055807869881391525), (38, 0.055256038904190063), (39, 0.05552138015627861), (40, 0.050092920660972595), (44, 0.049980826675891876), (47, 0.04963488131761551), (53, 0.0528392493724823)]
computing accuracy for after removing block 47 . block score: 0.04963488131761551
removed block 47 current accuracy 0.8772 loss from initial  0.12280000000000002
training start
training epoch 0 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.001]
training epoch 1 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 2 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best True lr [0.001]
training epoch 3 val accuracy 0.973 topk_dict {'top1': 0.973} is_best True lr [0.001]
training epoch 4 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 5 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 6 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 7 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 8 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 9 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 10 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 11 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 12 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 13 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 14 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best True lr [0.001]
training epoch 15 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 16 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 17 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 18 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 19 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 20 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 21 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 22 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 23 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 24 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 25 val accuracy 0.986 topk_dict {'top1': 0.986} is_best True lr [0.001]
training epoch 26 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 27 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 28 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 29 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 30 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 31 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 32 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 33 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 34 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 35 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
training epoch 36 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 37 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 38 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 39 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 40 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
training epoch 41 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 42 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 43 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 44 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 45 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
training epoch 46 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best True lr [0.001]
training epoch 47 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best False lr [0.001]
training epoch 48 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 49 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.988200)
finished training. finished 50 epochs. accuracy 0.9882 topk_dict {'top1': 0.9882}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (27, 0.052110521122813225), (28, 0.05193256214261055), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497), (40, 0.049408718943595886), (44, 0.04929452762007713), (53, 0.052085475996136665)]
computing accuracy for after removing block 44 . block score: 0.04929452762007713
removed block 44 current accuracy 0.9506 loss from initial  0.0494
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (27, 0.052110521122813225), (28, 0.05193256214261055), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497), (40, 0.049408718943595886), (53, 0.052085475996136665)]
computing accuracy for after removing block 40 . block score: 0.049408718943595886
removed block 40 current accuracy 0.9158 loss from initial  0.08420000000000005
since last training loss: 0.07240000000000002 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (27, 0.052110521122813225), (28, 0.05193256214261055), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497), (53, 0.052085475996136665)]
computing accuracy for after removing block 28 . block score: 0.05193256214261055
removed block 28 current accuracy 0.9066 loss from initial  0.09340000000000004
since last training loss: 0.0816 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (27, 0.052110521122813225), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497), (53, 0.052085475996136665)]
computing accuracy for after removing block 53 . block score: 0.052085475996136665
removed block 53 current accuracy 0.602 loss from initial  0.398
since last training loss: 0.3862 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (27, 0.052110521122813225), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497)]
computing accuracy for after removing block 27 . block score: 0.052110521122813225
removed block 27 current accuracy 0.5938 loss from initial  0.4062
since last training loss: 0.3944 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (26, 0.05228118412196636), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497)]
computing accuracy for after removing block 26 . block score: 0.05228118412196636
removed block 26 current accuracy 0.573 loss from initial  0.42700000000000005
since last training loss: 0.4152 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (36, 0.1780959777534008), (37, 0.05499612167477608), (38, 0.05450265295803547), (39, 0.05474497750401497)]
computing accuracy for after removing block 38 . block score: 0.05450265295803547
removed block 38 current accuracy 0.5362 loss from initial  0.4638
since last training loss: 0.45199999999999996 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (36, 0.1780959777534008), (37, 0.05499612167477608), (39, 0.05474497750401497)]
computing accuracy for after removing block 39 . block score: 0.05474497750401497
removed block 39 current accuracy 0.4444 loss from initial  0.5556
since last training loss: 0.5438 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.055710259824991226), (1, 0.07179776579141617), (2, 0.07661725208163261), (3, 0.09113387390971184), (4, 0.07288162410259247), (5, 0.09635205194354057), (6, 0.08804003149271011), (7, 0.07821634039282799), (8, 0.07958811521530151), (9, 0.09253735095262527), (10, 0.09271465614438057), (11, 0.07464365288615227), (12, 0.09913574531674385), (13, 0.08489550277590752), (14, 0.07465991377830505), (15, 0.0665787048637867), (16, 0.08037094399333), (17, 0.07247279398143291), (18, 0.2545080855488777), (19, 0.06406980752944946), (20, 0.06437515467405319), (21, 0.06482457369565964), (22, 0.06363658048212528), (23, 0.05927315168082714), (24, 0.06285550072789192), (25, 0.05781003087759018), (36, 0.1780959777534008), (37, 0.05499612167477608)]
computing accuracy for after removing block 37 . block score: 0.05499612167477608
removed block 37 current accuracy 0.4262 loss from initial  0.5738
training start
training epoch 0 val accuracy 0.678 topk_dict {'top1': 0.678} is_best True lr [0.001]
training epoch 1 val accuracy 0.7214 topk_dict {'top1': 0.7214} is_best True lr [0.001]
training epoch 2 val accuracy 0.7506 topk_dict {'top1': 0.7506} is_best True lr [0.001]
training epoch 3 val accuracy 0.77 topk_dict {'top1': 0.77} is_best True lr [0.001]
training epoch 4 val accuracy 0.7892 topk_dict {'top1': 0.7892} is_best True lr [0.001]
training epoch 5 val accuracy 0.8036 topk_dict {'top1': 0.8036} is_best True lr [0.001]
training epoch 6 val accuracy 0.815 topk_dict {'top1': 0.815} is_best True lr [0.001]
training epoch 7 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.001]
training epoch 8 val accuracy 0.83 topk_dict {'top1': 0.83} is_best True lr [0.001]
training epoch 9 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.001]
training epoch 10 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best True lr [0.001]
training epoch 11 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.001]
training epoch 12 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.001]
training epoch 13 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best True lr [0.001]
training epoch 14 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.001]
training epoch 15 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.001]
training epoch 16 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.001]
training epoch 17 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.001]
training epoch 18 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.001]
training epoch 19 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best True lr [0.001]
training epoch 20 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.001]
training epoch 21 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.001]
training epoch 22 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.001]
training epoch 23 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.001]
training epoch 24 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 25 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 26 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 27 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.001]
training epoch 28 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 29 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.001]
training epoch 31 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.001]
training epoch 32 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 33 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 34 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.001]
training epoch 35 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.001]
training epoch 36 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 37 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 38 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 39 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.001]
training epoch 40 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 41 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 42 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.001]
training epoch 43 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.001]
training epoch 44 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 45 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 46 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 47 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.001]
training epoch 48 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 49 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.909000)
finished training. finished 50 epochs. accuracy 0.909 topk_dict {'top1': 0.909}
