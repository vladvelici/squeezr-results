start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975136063993), (20, 0.008696247590705752), (27, 0.009198294952511787), (31, 0.00967550405766815), (29, 0.010030421079136431), (22, 0.010588386445306242), (23, 0.01065161800943315), (21, 0.010725351050496101), (28, 0.011828799615614116), (24, 0.012058728490956128), (17, 0.012199450633488595), (19, 0.013177949003875256), (33, 0.0132797866826877), (35, 0.01348381640855223), (25, 0.01383934251498431), (11, 0.01391290919855237), (32, 0.013956584851257503), (16, 0.014766237698495388), (30, 0.015491604921407998), (9, 0.015547690680250525), (40, 0.015986334765329957), (34, 0.01665632170625031), (39, 0.01751717645674944), (44, 0.018641567090526223), (37, 0.018799005076289177), (43, 0.01893503381870687), (42, 0.019514339277520776), (41, 0.01959002041257918), (45, 0.019901464693248272), (38, 0.02000095834955573), (14, 0.020047536585479975), (8, 0.021667920518666506), (7, 0.021806210512295365), (15, 0.024833295727148652), (46, 0.02521279128268361), (10, 0.025900361128151417), (49, 0.027116776444017887), (48, 0.027511440683156252), (47, 0.027820878429338336), (50, 0.02872324758209288), (51, 0.03178879711776972), (12, 0.032983270939439535), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.05253404472023249), (13, 0.05450336076319218), (2, 0.06120603531599045), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.2727429233491421), (18, 0.30386047437787056), (53, 0.8891633301973343)]
computing accuracy for after removing block 26 . block score: 0.007451975136063993
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.008696247939951718), (27, 0.009569327346980572), (31, 0.009736894746311009), (29, 0.01037009828723967), (22, 0.010588386678136885), (23, 0.01065161800943315), (21, 0.010725351166911423), (24, 0.012058728490956128), (28, 0.01206758595071733), (17, 0.012199450633488595), (19, 0.01317794865462929), (33, 0.013200338231399655), (35, 0.013297738623805344), (32, 0.013540126266889274), (25, 0.013839342282153666), (11, 0.013912909431383014), (16, 0.014766237931326032), (30, 0.015476007014513016), (9, 0.015547690563835204), (34, 0.01633565267547965), (40, 0.016489707864820957), (39, 0.018151729833334684), (44, 0.018809265224263072), (43, 0.019272045930847526), (37, 0.019370622467249632), (41, 0.01979763014242053), (42, 0.019846386276185513), (14, 0.020047534722834826), (38, 0.020208331989124417), (45, 0.020282169338315725), (8, 0.02166792075149715), (7, 0.021806211676448584), (15, 0.024833297124132514), (46, 0.025710681453347206), (10, 0.025900360895320773), (49, 0.027175756637006998), (48, 0.027807615231722593), (47, 0.028269682079553604), (50, 0.02872340497560799), (51, 0.031959859654307365), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.0335196852684021), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.05266197398304939), (13, 0.05450335890054703), (2, 0.06120603531599045), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.2777215614914894), (18, 0.30386048182845116), (53, 0.8825649842619896)]
computing accuracy for after removing block 20 . block score: 0.008696247939951718
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.009247071342542768), (31, 0.009490355267189443), (29, 0.010141469305381179), (23, 0.010720769292674959), (21, 0.010873694671317935), (22, 0.010951439733617008), (28, 0.011602517799474299), (17, 0.01219945086631924), (24, 0.012428545043803751), (33, 0.013006685534492135), (32, 0.013030687812715769), (35, 0.01314149284735322), (19, 0.01317794865462929), (11, 0.013912908965721726), (25, 0.014337054919451475), (30, 0.014731098897755146), (16, 0.014766237582080066), (9, 0.015547689981758595), (34, 0.015950741479173303), (40, 0.016676967032253742), (39, 0.018123319139704108), (44, 0.019042733823880553), (43, 0.019525705138221383), (37, 0.019535947358235717), (41, 0.020023913122713566), (42, 0.020024611614644527), (14, 0.020047534490004182), (38, 0.02022995171137154), (45, 0.020495346980169415), (8, 0.021667920518666506), (7, 0.02180621144361794), (15, 0.02483329689130187), (10, 0.025900361593812704), (46, 0.026008821791037917), (49, 0.027358209947124124), (48, 0.027944064000621438), (47, 0.02855871361680329), (50, 0.028874032199382782), (51, 0.031975784339010715), (12, 0.03298327000811696), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.03804349387064576), (3, 0.0437471829354763), (52, 0.053193128667771816), (13, 0.05450336076319218), (2, 0.061206035781651735), (1, 0.07061250600963831), (0, 0.14636892080307007), (36, 0.27894822880625725), (18, 0.30386048182845116), (53, 0.8746765330433846)]
computing accuracy for after removing block 27 . block score: 0.009247071342542768
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703439893200994), (29, 0.010401993873529136), (23, 0.010720769176259637), (21, 0.010873694438487291), (22, 0.010951439966447651), (28, 0.011904270155355334), (17, 0.012199450517073274), (24, 0.012428545276634395), (33, 0.012989282375201583), (35, 0.013032012968324125), (32, 0.013032321585342288), (19, 0.013177948887459934), (11, 0.013912909314967692), (25, 0.014337054686620831), (30, 0.014530949993059039), (16, 0.014766237349249423), (34, 0.015523916343227029), (9, 0.015547690447419882), (40, 0.017428284278139472), (39, 0.01863569999113679), (44, 0.0193233760073781), (43, 0.019895021338015795), (14, 0.020047536119818687), (37, 0.020162818487733603), (38, 0.020197829930111766), (42, 0.02029576594941318), (41, 0.020331318024545908), (45, 0.020738494815304875), (8, 0.02166792075149715), (7, 0.021806210977956653), (15, 0.024833296658471227), (10, 0.025900361593812704), (46, 0.026298311771824956), (49, 0.02737220679409802), (48, 0.02811374608427286), (47, 0.028824042296037078), (50, 0.02908248663879931), (51, 0.03204397251829505), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.043747182469815016), (52, 0.05334703763946891), (13, 0.0545033598318696), (2, 0.06120603485032916), (1, 0.07061250600963831), (0, 0.14636892266571522), (36, 0.2865508496761322), (18, 0.30386048182845116), (53, 0.8739226385951042)]
computing accuracy for after removing block 31 . block score: 0.009703439893200994
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.01040199410635978), (23, 0.010720769059844315), (21, 0.010873694554902613), (22, 0.010951440082862973), (28, 0.011904270388185978), (17, 0.012199450517073274), (24, 0.012428544810973108), (33, 0.01307527325116098), (19, 0.013177949120290577), (32, 0.013221941189840436), (35, 0.013311224873177707), (11, 0.013912908965721726), (25, 0.014337054337374866), (30, 0.014530949876643717), (16, 0.014766237582080066), (34, 0.015109014115296304), (9, 0.01554768974892795), (40, 0.01796384807676077), (44, 0.019172759726643562), (39, 0.019229266326874495), (38, 0.0196272493340075), (43, 0.01977342227473855), (42, 0.02001498988829553), (14, 0.0200475356541574), (41, 0.020369442412629724), (45, 0.02045823959633708), (37, 0.020535162184387445), (8, 0.021667920518666506), (7, 0.02180621027946472), (15, 0.024833297356963158), (10, 0.02590036205947399), (46, 0.026439889799803495), (49, 0.027319708606228232), (48, 0.028306722873821855), (47, 0.02865198371000588), (50, 0.029288705671206117), (51, 0.03214396629482508), (12, 0.03298326954245567), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.0437471829354763), (52, 0.05252913665026426), (13, 0.05450336076319218), (2, 0.06120603671297431), (1, 0.07061250507831573), (0, 0.14636892266571522), (36, 0.29571831226348877), (18, 0.30386046692728996), (53, 0.885270394384861)]
computing accuracy for after removing block 29 . block score: 0.01040199410635978
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.01072076940909028), (21, 0.010873694787733257), (22, 0.010951439500786364), (28, 0.011904270155355334), (17, 0.012199450982734561), (24, 0.012428545043803751), (33, 0.013095533475279808), (19, 0.013177948305383325), (32, 0.013331790687516332), (35, 0.013342681806534529), (11, 0.013912908849306405), (25, 0.014337054337374866), (16, 0.014766237931326032), (34, 0.014780625700950623), (30, 0.014848081395030022), (9, 0.01554769033100456), (40, 0.01794743980281055), (44, 0.018570148153230548), (38, 0.018818872049450874), (39, 0.019284184090793133), (42, 0.019550167489796877), (43, 0.01966752763837576), (41, 0.02001996710896492), (14, 0.020047535188496113), (45, 0.02014507818967104), (37, 0.02077811397612095), (8, 0.021667920984327793), (7, 0.021806209813803434), (15, 0.024833297124132514), (10, 0.02590036136098206), (46, 0.026351967360824347), (49, 0.02699960581958294), (48, 0.02782399649731815), (47, 0.02850809460505843), (50, 0.02933459193445742), (51, 0.0321717681363225), (12, 0.03298326954245567), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718479812145), (52, 0.051905466709285975), (13, 0.054503359366208315), (2, 0.06120603671297431), (1, 0.07061250600963831), (0, 0.14636892266571522), (36, 0.299510408192873), (18, 0.30386047065258026), (53, 0.896213985979557)]
computing accuracy for after removing block 23 . block score: 0.01072076940909028
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.010873694671317935), (22, 0.010951439966447651), (28, 0.011454624822363257), (24, 0.011984123499132693), (17, 0.012199450400657952), (35, 0.013001650921069086), (32, 0.013018106226809323), (33, 0.013115601730532944), (19, 0.013177948771044612), (25, 0.013824697118252516), (11, 0.013912908732891083), (30, 0.014240247895941138), (34, 0.01470337773207575), (16, 0.014766238164156675), (9, 0.015547690447419882), (40, 0.018065202981233597), (44, 0.01830046600662172), (38, 0.01860098447650671), (42, 0.01934517058543861), (43, 0.01955112931318581), (39, 0.01982236560434103), (45, 0.019911037757992744), (41, 0.020028739236295223), (14, 0.020047535188496113), (37, 0.02084771986119449), (8, 0.02166792075149715), (7, 0.021806210977956653), (15, 0.024833296658471227), (10, 0.02590036136098206), (46, 0.026478099869564176), (49, 0.026978092966601253), (48, 0.027518166694790125), (47, 0.028530239826068282), (50, 0.029085059417411685), (51, 0.03238660329952836), (12, 0.03298327047377825), (5, 0.03333624266088009), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718386679888), (52, 0.05187077634036541), (13, 0.05450335843488574), (2, 0.0612060371786356), (1, 0.07061250600963831), (0, 0.14636892080307007), (36, 0.3020646683871746), (18, 0.30386047437787056), (53, 0.8938302919268608)]
computing accuracy for after removing block 21 . block score: 0.010873694671317935
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718230856582522), (22, 0.011124414741061628), (24, 0.01173454150557518), (17, 0.01219945086631924), (32, 0.01233904401306063), (35, 0.012350354809314013), (33, 0.01277335628401488), (19, 0.013177949120290577), (30, 0.013385720551013947), (25, 0.013581673498265445), (11, 0.013912908732891083), (34, 0.014493828522972763), (16, 0.014766238047741354), (9, 0.015547690447419882), (40, 0.01817885460332036), (44, 0.018340063048526645), (38, 0.018629685742780566), (42, 0.019575109472498298), (43, 0.0197298398707062), (39, 0.019833360332995653), (14, 0.0200475356541574), (45, 0.0200941888615489), (41, 0.02073429198935628), (37, 0.02079579746350646), (8, 0.02166792075149715), (7, 0.02180621027946472), (15, 0.024833297124132514), (10, 0.025900360429659486), (46, 0.027196240611374378), (49, 0.02729213354177773), (48, 0.027600203873589635), (47, 0.0289066256955266), (50, 0.0291686428245157), (51, 0.03279080847278237), (12, 0.03298327047377825), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.0437471829354763), (52, 0.05234553711488843), (13, 0.05450336029753089), (2, 0.0612060371786356), (1, 0.07061250694096088), (0, 0.14636891894042492), (18, 0.30386047437787056), (36, 0.3042290173470974), (53, 0.8967952728271484)]
computing accuracy for after removing block 28 . block score: 0.010718230856582522
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011124. All blocks and scores: [(22, 0.01112441485747695), (24, 0.011734541854821146), (32, 0.012095691869035363), (35, 0.012157876160927117), (17, 0.012199450633488595), (33, 0.013105916674248874), (19, 0.013177948887459934), (30, 0.013323650578968227), (25, 0.013581673731096089), (11, 0.013912909082137048), (34, 0.014369337121024728), (16, 0.014766237698495388), (9, 0.015547690214589238), (38, 0.017921381164342165), (44, 0.01819704077206552), (40, 0.018912273924797773), (42, 0.019364925799891353), (43, 0.019978849217295647), (14, 0.0200475356541574), (45, 0.020337820518761873), (39, 0.02059708838351071), (41, 0.02072914084419608), (37, 0.02132129459641874), (8, 0.021667920518666506), (7, 0.021806210512295365), (15, 0.024833296658471227), (10, 0.025900361128151417), (49, 0.027097658487036824), (48, 0.02719514723867178), (46, 0.027485697763040662), (47, 0.029074370861053467), (50, 0.0291694903280586), (12, 0.03298327000811696), (51, 0.033133427146822214), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.0380434924736619), (3, 0.04374718386679888), (52, 0.05157360155135393), (13, 0.05450335890054703), (2, 0.0612060371786356), (1, 0.07061250600963831), (0, 0.14636892080307007), (18, 0.30386047437787056), (36, 0.31568818166852), (53, 0.9053315073251724)]
computing accuracy for after removing block 22 . block score: 0.01112441485747695
removed block 22 current accuracy 0.9804 loss from initial  0.01959999999999995
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 3 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 12 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
[activation diff]: block to remove picked: 17, with score 0.012622. All blocks and scores: [(17, 0.01262203708756715), (33, 0.013617081916891038), (11, 0.013703024364076555), (19, 0.014374000835232437), (16, 0.014628689736127853), (35, 0.01479968277271837), (24, 0.014976452570408583), (9, 0.01555526105221361), (32, 0.015590029652230442), (25, 0.01562333747278899), (40, 0.01621897518634796), (39, 0.01764749875292182), (34, 0.018054830376058817), (30, 0.018372517079114914), (44, 0.018525614868849516), (43, 0.01866145059466362), (37, 0.018767663976177573), (41, 0.019341312581673265), (42, 0.0194926296826452), (45, 0.019605542765930295), (14, 0.019827018026262522), (38, 0.020004075253382325), (8, 0.021663530031219125), (7, 0.021690366324037313), (15, 0.025276540080085397), (46, 0.02528697601519525), (10, 0.02645520935766399), (49, 0.02681834902614355), (48, 0.027383349370211363), (47, 0.027408576803281903), (50, 0.028561871265992522), (51, 0.031179246492683887), (12, 0.03263650741428137), (5, 0.03295837761834264), (6, 0.03385453810915351), (4, 0.03782794298604131), (3, 0.04365377966314554), (52, 0.05103453155606985), (13, 0.054748840630054474), (2, 0.05981456907466054), (1, 0.06918997131288052), (0, 0.1442418061196804), (36, 0.26856594532728195), (18, 0.29869407787919044), (53, 0.8785388097167015)]
computing accuracy for after removing block 17 . block score: 0.01262203708756715
removed block 17 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 33, with score 0.013171. All blocks and scores: [(33, 0.013170794118195772), (19, 0.013330577523447573), (11, 0.013703025062568486), (35, 0.014561308547854424), (16, 0.014628689736127853), (25, 0.014685249305330217), (24, 0.01487681653816253), (32, 0.015355765004642308), (9, 0.015555261168628931), (40, 0.016583202639594674), (34, 0.01705380156636238), (30, 0.017349934671074152), (39, 0.017945215804502368), (43, 0.018489793641492724), (44, 0.018623432610183954), (37, 0.018711507320404053), (42, 0.01903650490567088), (45, 0.019313754281029105), (38, 0.019606603775173426), (41, 0.019651856971904635), (14, 0.019827017793431878), (8, 0.02166352979838848), (7, 0.021690367255359888), (15, 0.025276540778577328), (46, 0.025590918259695172), (10, 0.02645520935766399), (49, 0.02694834815338254), (47, 0.02710957219824195), (48, 0.027290543541312218), (50, 0.028423174982890487), (51, 0.03069678577594459), (12, 0.032636506482958794), (5, 0.032958378084003925), (6, 0.03385453624650836), (4, 0.03782794298604131), (3, 0.04365378059446812), (52, 0.050569923128932714), (13, 0.05474884249269962), (2, 0.05981456860899925), (1, 0.06918997224420309), (0, 0.14424180798232555), (36, 0.2725590392947197), (18, 0.30524154752492905), (53, 0.8654306009411812)]
computing accuracy for after removing block 33 . block score: 0.013170794118195772
removed block 33 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 19, with score 0.013331. All blocks and scores: [(19, 0.013330577523447573), (11, 0.013703024596907198), (16, 0.014628690085373819), (25, 0.014685249188914895), (24, 0.014876816887408495), (32, 0.015355765237472951), (35, 0.01543367700651288), (9, 0.015555260819382966), (40, 0.016085435869172215), (34, 0.016680704662576318), (39, 0.01731480029411614), (30, 0.01734993443824351), (43, 0.01752531062811613), (44, 0.017657711170613766), (37, 0.01766638341359794), (38, 0.01773707871325314), (45, 0.018213688861578703), (42, 0.018244854174554348), (41, 0.018727035028859973), (14, 0.019827017793431878), (8, 0.02166352979838848), (7, 0.021690367022529244), (46, 0.024876895593479276), (15, 0.02527653961442411), (47, 0.026036622002720833), (48, 0.026221803855150938), (10, 0.026455209590494633), (49, 0.026666383491829038), (50, 0.02770268521271646), (51, 0.030198347754776478), (12, 0.03263650694862008), (5, 0.03295837761834264), (6, 0.03385453764349222), (4, 0.03782794205471873), (3, 0.043653781060129404), (52, 0.0483142682351172), (13, 0.05474884295836091), (2, 0.05981456767767668), (1, 0.06918997131288052), (0, 0.1442418098449707), (36, 0.27050600945949554), (18, 0.30524154007434845), (53, 0.8949620798230171)]
computing accuracy for after removing block 19 . block score: 0.013330577523447573
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 11, with score 0.013703. All blocks and scores: [(11, 0.013703024829737842), (25, 0.013740992872044444), (16, 0.014628689968958497), (24, 0.01498879014980048), (35, 0.015063741826452315), (32, 0.01512318686582148), (9, 0.01555526105221361), (34, 0.015997051959857345), (30, 0.01654438441619277), (40, 0.01655599963851273), (39, 0.017372275469824672), (38, 0.017478583613410592), (43, 0.01776248589158058), (37, 0.01776349195279181), (44, 0.017803610069677234), (42, 0.01851573772728443), (45, 0.01853015716187656), (41, 0.01885202806442976), (14, 0.019827017793431878), (8, 0.02166352979838848), (7, 0.02169036748819053), (46, 0.025133563904091716), (15, 0.02527653961442411), (47, 0.026245713932439685), (48, 0.02627069898881018), (10, 0.02645520935766399), (49, 0.026757143437862396), (50, 0.027857582783326507), (51, 0.03040097700431943), (12, 0.03263650694862008), (5, 0.03295837761834264), (6, 0.033854537177830935), (4, 0.03782794252038002), (3, 0.04365378059446812), (52, 0.04837385145947337), (13, 0.05474884016439319), (2, 0.05981456721201539), (1, 0.06918997131288052), (0, 0.1442418061196804), (36, 0.2752589099109173), (18, 0.30524154752492905), (53, 0.8918138071894646)]
computing accuracy for after removing block 11 . block score: 0.013703024829737842
removed block 11 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.013436. All blocks and scores: [(25, 0.01343617239035666), (32, 0.014793369336985052), (16, 0.014966270769946277), (35, 0.015024722320958972), (24, 0.015031463699415326), (9, 0.015555261168628931), (30, 0.015623509068973362), (34, 0.015779331559315324), (40, 0.016564319375902414), (39, 0.017041072947904468), (38, 0.017236633226275444), (37, 0.017458986956626177), (43, 0.017501957714557648), (44, 0.017713882960379124), (42, 0.018079342786222696), (45, 0.01876686606556177), (41, 0.01894921576604247), (14, 0.018952542915940285), (8, 0.021663529565557837), (7, 0.021690366556867957), (46, 0.025165681494399905), (15, 0.02522974950261414), (48, 0.025781428907066584), (47, 0.02602445730008185), (10, 0.026455209124833345), (49, 0.02680981601588428), (50, 0.02761806081980467), (51, 0.030075022019445896), (12, 0.030780488159507513), (5, 0.03295837715268135), (6, 0.03385453671216965), (4, 0.03782794252038002), (3, 0.043653781060129404), (52, 0.04768135538324714), (13, 0.052381770219653845), (2, 0.05981456767767668), (1, 0.06918997131288052), (0, 0.14424180798232555), (36, 0.27456608787178993), (18, 0.2985977977514267), (53, 0.8786108866333961)]
computing accuracy for after removing block 25 . block score: 0.01343617239035666
removed block 25 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 32, with score 0.014237. All blocks and scores: [(32, 0.01423673634417355), (35, 0.014358568703755736), (16, 0.014966271701268852), (24, 0.015031464048661292), (34, 0.015429500490427017), (30, 0.015435882494784892), (9, 0.015555260935798287), (40, 0.016945398412644863), (38, 0.01695128600113094), (43, 0.01759038120508194), (42, 0.017786899348720908), (44, 0.01783755049109459), (37, 0.017924591433256865), (39, 0.018024028977379203), (14, 0.018952542217448354), (45, 0.019033722346648574), (41, 0.019334602169692516), (8, 0.021663530031219125), (7, 0.0216903667896986), (46, 0.025029433658346534), (15, 0.025229749036952853), (48, 0.025751131121069193), (47, 0.02602800796739757), (10, 0.026455209124833345), (49, 0.02675837930291891), (50, 0.027094042859971523), (51, 0.02986480388790369), (12, 0.030780486995354295), (5, 0.03295837854966521), (6, 0.033854537177830935), (4, 0.03782794252038002), (3, 0.04365377966314554), (52, 0.04612956056371331), (13, 0.052381770219653845), (2, 0.05981456767767668), (1, 0.06918997131288052), (0, 0.1442418061196804), (36, 0.2830749563872814), (18, 0.2985977940261364), (53, 0.8722665160894394)]
computing accuracy for after removing block 32 . block score: 0.01423673634417355
removed block 32 current accuracy 0.9802 loss from initial  0.01980000000000004
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 16, with score 0.014966. All blocks and scores: [(16, 0.014966271352022886), (24, 0.015031463466584682), (34, 0.015183094306848943), (35, 0.015421802876517177), (30, 0.015435882611200213), (9, 0.015555260935798287), (38, 0.015805257367901504), (44, 0.01703818910755217), (43, 0.017192784696817398), (40, 0.01733223767951131), (42, 0.017444849712774158), (37, 0.017588139045983553), (39, 0.01828167773783207), (45, 0.018695738399401307), (41, 0.01888675126247108), (14, 0.018952542217448354), (8, 0.021663529565557837), (7, 0.021690367255359888), (46, 0.025056763319298625), (15, 0.02522975020110607), (48, 0.02550837746821344), (47, 0.02602773136459291), (10, 0.026455209590494633), (49, 0.026689423713833094), (50, 0.02671833452768624), (51, 0.029559991089627147), (12, 0.030780486529693007), (5, 0.03295837715268135), (6, 0.033854537177830935), (4, 0.03782794298604131), (3, 0.04365378012880683), (52, 0.0442665065638721), (13, 0.05238176975399256), (2, 0.05981456907466054), (1, 0.06918997131288052), (0, 0.14424180798232555), (36, 0.2924454063177109), (18, 0.2985977940261364), (53, 0.8912622258067131)]
computing accuracy for after removing block 16 . block score: 0.014966271352022886
removed block 16 current accuracy 0.9768 loss from initial  0.0232
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 30, with score 0.014978. All blocks and scores: [(30, 0.01497828890569508), (35, 0.015040123602375388), (34, 0.015257454826496542), (9, 0.01555526105221361), (38, 0.015847141621634364), (24, 0.016442010179162025), (40, 0.01696911361068487), (44, 0.017035917611792684), (43, 0.017052480019629), (42, 0.01730220136232674), (37, 0.017441923962906003), (39, 0.01814124220982194), (45, 0.01881428179331124), (14, 0.018952542450278997), (41, 0.019831477664411068), (8, 0.021663529332727194), (7, 0.021690366556867957), (46, 0.02431136230006814), (48, 0.024723463458940387), (15, 0.02522975020110607), (47, 0.02579881949350238), (50, 0.02597300661727786), (49, 0.026170631870627403), (10, 0.026455209823325276), (51, 0.028632631758227944), (12, 0.030780486995354295), (5, 0.03295837715268135), (6, 0.03385453810915351), (4, 0.03782794252038002), (52, 0.0430064951069653), (3, 0.04365378152579069), (13, 0.05238177115097642), (2, 0.059814570005983114), (1, 0.06918997410684824), (0, 0.1442418061196804), (36, 0.2901885397732258), (18, 0.30405760556459427), (53, 0.8948038518428802)]
computing accuracy for after removing block 30 . block score: 0.01497828890569508
removed block 30 current accuracy 0.9448 loss from initial  0.05520000000000003
since last training loss: 0.05520000000000003 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 34, with score 0.015264. All blocks and scores: [(34, 0.015263920417055488), (38, 0.015431112376973033), (35, 0.015520690707489848), (9, 0.015555261285044253), (24, 0.016442010179162025), (44, 0.016837515868246555), (43, 0.016857126727700233), (42, 0.0171322925016284), (37, 0.0183900345582515), (40, 0.018430703319609165), (45, 0.018934582825750113), (14, 0.018952542217448354), (39, 0.020220825215801597), (41, 0.020292707020416856), (8, 0.02166352979838848), (7, 0.021690367022529244), (46, 0.024714641273021698), (48, 0.02484607556834817), (15, 0.02522975020110607), (50, 0.025926238857209682), (47, 0.026073708664625883), (49, 0.026289326138794422), (10, 0.026455209823325276), (51, 0.028929109452292323), (12, 0.030780486529693007), (5, 0.03295837761834264), (6, 0.03385453671216965), (4, 0.03782794252038002), (52, 0.04122442426159978), (3, 0.04365378012880683), (13, 0.05238176928833127), (2, 0.05981456907466054), (1, 0.06918997224420309), (0, 0.1442418061196804), (18, 0.30405759811401367), (36, 0.31209147721529007), (53, 0.9067881405353546)]
computing accuracy for after removing block 34 . block score: 0.015263920417055488
removed block 34 current accuracy 0.9278 loss from initial  0.07220000000000004
training start
training epoch 0 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 1 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 2 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 3 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 4 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 5 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 6 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 7 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 8 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 9 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 10 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 11 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 12 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 13 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 14 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 15 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 16 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 18 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 20 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 21 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 22 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 23 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 27 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 28 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 29 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 33 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 34 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 37 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 38 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 41 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 42 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 43 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 44 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 45 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 46 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 47 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 49 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 18
[activation diff]: block to remove picked: 40, with score 0.015877. All blocks and scores: [(40, 0.015877491794526577), (9, 0.01620763703249395), (39, 0.017816410632804036), (44, 0.017911606468260288), (43, 0.018064406467601657), (41, 0.018559885676950216), (42, 0.018804807914420962), (37, 0.018838393967598677), (45, 0.019215997541323304), (38, 0.019981129094958305), (14, 0.020775423850864172), (8, 0.02143000951036811), (7, 0.022268890868872404), (35, 0.022467038361355662), (24, 0.02322702598758042), (46, 0.024235034128651023), (49, 0.02573240827769041), (48, 0.026395661756396294), (47, 0.02647510706447065), (15, 0.026587647385895252), (10, 0.027378611732274294), (50, 0.028068106155842543), (51, 0.030534177785739303), (5, 0.03194634383544326), (12, 0.032216099090874195), (6, 0.03391672903671861), (4, 0.03897353447973728), (3, 0.041258756536990404), (52, 0.04955420969054103), (13, 0.053843979723751545), (2, 0.05827694619074464), (1, 0.06497599557042122), (0, 0.13789674825966358), (36, 0.26431630179286003), (18, 0.2801053449511528), (53, 0.8909339904785156)]
computing accuracy for after removing block 40 . block score: 0.015877491794526577
removed block 40 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 9, with score 0.016208. All blocks and scores: [(9, 0.016207637265324593), (39, 0.017816411098465323), (44, 0.01833804207853973), (43, 0.018688809126615524), (37, 0.018838393967598677), (45, 0.01930922642350197), (41, 0.019793549552559853), (42, 0.0198277544695884), (38, 0.019981129560619593), (14, 0.020775423850864172), (8, 0.021430009976029396), (7, 0.022268891101703048), (35, 0.022467038361355662), (24, 0.02322702552191913), (46, 0.02473397832363844), (49, 0.02613068465143442), (48, 0.026147523429244757), (47, 0.02653006697073579), (15, 0.02658764715306461), (10, 0.027378611732274294), (50, 0.02865647221915424), (51, 0.031111092306673527), (5, 0.03194634336978197), (12, 0.032216099090874195), (6, 0.03391672903671861), (4, 0.038973532151430845), (3, 0.04125875560566783), (52, 0.049152715131640434), (13, 0.05384398344904184), (2, 0.058276945259422064), (1, 0.0649759965017438), (0, 0.13789674825966358), (36, 0.26431630551815033), (18, 0.2801053449511528), (53, 0.9079271927475929)]
computing accuracy for after removing block 9 . block score: 0.016207637265324593
removed block 9 current accuracy 0.9946 loss from initial  0.00539999999999996
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.017007. All blocks and scores: [(39, 0.01700707687996328), (43, 0.01783697260543704), (37, 0.0178647986613214), (44, 0.017981502693146467), (14, 0.018801273545250297), (45, 0.01884175674058497), (42, 0.019038404803723097), (38, 0.01954438374377787), (41, 0.02033882774412632), (35, 0.0208483156748116), (8, 0.02143000951036811), (24, 0.022043252596631646), (7, 0.02226889133453369), (46, 0.024391609709709883), (48, 0.02537999930791557), (47, 0.025729439221322536), (49, 0.025729639921337366), (10, 0.02599196694791317), (15, 0.026113723870366812), (50, 0.028362927259877324), (51, 0.03040459123440087), (12, 0.03045443189330399), (5, 0.031946342438459396), (6, 0.03391672903671861), (4, 0.03897353261709213), (3, 0.04125875514000654), (52, 0.047715602442622185), (13, 0.049071027897298336), (2, 0.058276945259422064), (1, 0.0649759965017438), (0, 0.13789674453437328), (36, 0.25761449337005615), (18, 0.26813673973083496), (53, 0.9096377789974213)]
computing accuracy for after removing block 39 . block score: 0.01700707687996328
removed block 39 current accuracy 0.9912 loss from initial  0.00880000000000003
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 37, with score 0.017865. All blocks and scores: [(37, 0.017864799359813333), (43, 0.01791380811482668), (44, 0.018005486810579896), (45, 0.018790502101182938), (14, 0.01880127377808094), (38, 0.01954438374377787), (42, 0.02065720851533115), (35, 0.020848315441980958), (41, 0.021055996417999268), (8, 0.021430008811876178), (24, 0.022043252596631646), (7, 0.022268891101703048), (46, 0.02472879528068006), (48, 0.024867683416232467), (47, 0.025484030367806554), (49, 0.025966735556721687), (10, 0.025991967413574457), (15, 0.0261137243360281), (50, 0.028215370373800397), (51, 0.029796776128932834), (12, 0.030454432358965278), (5, 0.03194634476676583), (6, 0.03391672903671861), (4, 0.038973532151430845), (3, 0.04125875560566783), (52, 0.04770021606236696), (13, 0.04907102696597576), (2, 0.058276943396776915), (1, 0.0649759965017438), (0, 0.13789675198495388), (36, 0.25761448219418526), (18, 0.26813674345612526), (53, 0.9087993875145912)]
computing accuracy for after removing block 37 . block score: 0.017864799359813333
removed block 37 current accuracy 0.9868 loss from initial  0.01319999999999999
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.016953. All blocks and scores: [(44, 0.016952810809016228), (43, 0.017280576517805457), (45, 0.017795023741200566), (14, 0.01880127307958901), (35, 0.020848315907642245), (38, 0.020912749925628304), (41, 0.020934103289619088), (42, 0.02103882608935237), (8, 0.021430009277537465), (24, 0.02204325213097036), (7, 0.02226889133453369), (48, 0.023143958300352097), (46, 0.023843435803428292), (47, 0.024192309705540538), (49, 0.02449548919685185), (10, 0.025991966715082526), (15, 0.026113724801689386), (50, 0.026379050221294165), (51, 0.02763264300301671), (12, 0.030454431660473347), (5, 0.03194634336978197), (6, 0.03391672903671861), (4, 0.038973534014075994), (3, 0.04125875607132912), (52, 0.042249839287251234), (13, 0.04907102882862091), (2, 0.05827694432809949), (1, 0.06497599557042122), (0, 0.13789675198495388), (36, 0.25761449709534645), (18, 0.26813675463199615), (53, 0.9411522299051285)]
computing accuracy for after removing block 44 . block score: 0.016952810809016228
removed block 44 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 43, with score 0.017281. All blocks and scores: [(43, 0.0172805767506361), (14, 0.018801273312419653), (45, 0.019419924588873982), (35, 0.020848316373303533), (38, 0.02091274969279766), (41, 0.020934103755280375), (42, 0.02103882608935237), (8, 0.021430009743198752), (24, 0.02204325213097036), (7, 0.022268891101703048), (48, 0.023296853294596076), (49, 0.02460284694097936), (47, 0.02473754365928471), (46, 0.025302213616669178), (10, 0.02599196624942124), (15, 0.026113724801689386), (50, 0.02633541775867343), (51, 0.02744711935520172), (12, 0.030454431660473347), (5, 0.031946344301104546), (6, 0.03391672903671861), (4, 0.038973532151430845), (52, 0.04068503808230162), (3, 0.04125875607132912), (13, 0.049071027897298336), (2, 0.058276944793760777), (1, 0.06497599743306637), (0, 0.13789675012230873), (36, 0.25761448964476585), (18, 0.26813674718141556), (53, 0.9945895075798035)]
computing accuracy for after removing block 43 . block score: 0.0172805767506361
removed block 43 current accuracy 0.9674 loss from initial  0.03259999999999996
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 14, with score 0.018801. All blocks and scores: [(14, 0.01880127377808094), (45, 0.019952272064983845), (35, 0.020848315907642245), (38, 0.020912750158458948), (41, 0.020934103522449732), (42, 0.0210388267878443), (8, 0.02143000951036811), (24, 0.022043252363801003), (7, 0.02226889063604176), (48, 0.022676533088088036), (49, 0.024667033925652504), (47, 0.02520396956242621), (10, 0.025991967180743814), (50, 0.02602311223745346), (15, 0.0261137243360281), (46, 0.02627042937092483), (51, 0.026803992688655853), (12, 0.03045443189330399), (5, 0.03194634476676583), (6, 0.033916729502379894), (4, 0.038973534014075994), (52, 0.03900324460119009), (3, 0.04125875607132912), (13, 0.049071026500314474), (2, 0.0582769438624382), (1, 0.06497599557042122), (0, 0.13789675012230873), (36, 0.25761448591947556), (18, 0.26813674718141556), (53, 1.0548837035894394)]
computing accuracy for after removing block 14 . block score: 0.01880127377808094
removed block 14 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.04859999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.020315. All blocks and scores: [(38, 0.02031476190313697), (45, 0.020412189187482), (35, 0.020449714735150337), (42, 0.020927840610966086), (41, 0.021329464856535196), (8, 0.02143000951036811), (7, 0.022268889704719186), (48, 0.02239798102527857), (24, 0.022650561295449734), (47, 0.024998702108860016), (49, 0.025391844334080815), (10, 0.025991967180743814), (50, 0.02601195080205798), (51, 0.026481477776542306), (46, 0.027124974643811584), (15, 0.028323206584900618), (12, 0.030454432126134634), (5, 0.03194634383544326), (6, 0.033916729502379894), (52, 0.038488530553877354), (4, 0.03897353308275342), (3, 0.04125875560566783), (13, 0.04907102882862091), (2, 0.05827694432809949), (1, 0.0649759965017438), (0, 0.13789674825966358), (36, 0.2699206545948982), (18, 0.2803500220179558), (53, 1.0257890224456787)]
computing accuracy for after removing block 38 . block score: 0.02031476190313697
removed block 38 current accuracy 0.9256 loss from initial  0.07440000000000002
since last training loss: 0.07320000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.019133. All blocks and scores: [(45, 0.01913334452547133), (35, 0.020449715433642268), (48, 0.021111709531396627), (8, 0.02143000904470682), (42, 0.021722155157476664), (7, 0.02226889063604176), (41, 0.02227911725640297), (24, 0.02265056176111102), (47, 0.02407353208400309), (49, 0.024594932328909636), (50, 0.024694381514564157), (51, 0.024977492168545723), (10, 0.025991967879235744), (46, 0.02655959501862526), (15, 0.02832320681773126), (12, 0.030454432126134634), (5, 0.03194634383544326), (6, 0.03391672903671861), (52, 0.03488967381417751), (4, 0.03897353261709213), (3, 0.04125875560566783), (13, 0.04907102743163705), (2, 0.05827694432809949), (1, 0.0649759965017438), (0, 0.13789674639701843), (36, 0.2699206508696079), (18, 0.2803500406444073), (53, 1.0403210073709488)]
computing accuracy for after removing block 45 . block score: 0.01913334452547133
removed block 45 current accuracy 0.9006 loss from initial  0.09940000000000004
training start
training epoch 0 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 1 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 2 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 3 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 4 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 5 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 6 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 7 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 8 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 9 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 10 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 11 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 12 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 13 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 14 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 15 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 16 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 17 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 18 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 19 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 20 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 21 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 22 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 23 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 24 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 26 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 27 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 28 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 29 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 30 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 32 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 33 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 34 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 35 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 36 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 38 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 40 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 41 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 42 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 43 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 44 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 45 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 46 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 47 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 48 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 49 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.993600)
finished training. finished 50 epochs. accuracy 0.9936 topk_dict {'top1': 0.9936}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.022298. All blocks and scores: [(7, 0.022298236144706607), (8, 0.023824703879654408), (49, 0.02633422752842307), (42, 0.026883684564381838), (10, 0.02743563475087285), (50, 0.027878064196556807), (41, 0.02842881064862013), (48, 0.02902703545987606), (51, 0.030054431641474366), (15, 0.030600241385400295), (46, 0.030768237076699734), (47, 0.03078553033992648), (35, 0.031226040329784155), (5, 0.03240072587504983), (6, 0.03266003308817744), (24, 0.03293255856260657), (12, 0.03329226979985833), (4, 0.039053056854754686), (3, 0.04004123713821173), (52, 0.04865097580477595), (13, 0.05557277472689748), (2, 0.05649281246587634), (1, 0.06263838801532984), (0, 0.1297301333397627), (36, 0.24756494536995888), (18, 0.2663268744945526), (53, 0.8915670737624168)]
computing accuracy for after removing block 7 . block score: 0.022298236144706607
removed block 7 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 8, with score 0.023502. All blocks and scores: [(8, 0.023501866031438112), (42, 0.025215320521965623), (49, 0.02544756862334907), (10, 0.02636857028119266), (50, 0.02648617560043931), (48, 0.027756099356338382), (41, 0.028804447501897812), (51, 0.028878647834062576), (46, 0.029127733083441854), (15, 0.029511012136936188), (35, 0.029668864095583558), (47, 0.03006123029626906), (12, 0.031278305454179645), (24, 0.031614440493285656), (5, 0.03240072587504983), (6, 0.03266003215685487), (4, 0.03905305592343211), (3, 0.04004123713821173), (52, 0.04660042515024543), (13, 0.056048814207315445), (2, 0.05649281293153763), (1, 0.06263839080929756), (0, 0.12973013147711754), (36, 0.23992550186812878), (18, 0.25599338859319687), (53, 0.8897547051310539)]
computing accuracy for after removing block 8 . block score: 0.023501866031438112
removed block 8 current accuracy 0.982 loss from initial  0.018000000000000016
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 42, with score 0.023814. All blocks and scores: [(42, 0.0238142148591578), (49, 0.025330702774226665), (50, 0.02551747369579971), (48, 0.027018612250685692), (10, 0.027306403499096632), (51, 0.02779460698366165), (35, 0.028414798667654395), (41, 0.02866106480360031), (46, 0.02901470963843167), (15, 0.029695848235860467), (47, 0.03013364947400987), (24, 0.03158044652082026), (12, 0.03222087910398841), (5, 0.03240072634071112), (6, 0.03266003215685487), (4, 0.0390530563890934), (3, 0.04004123667255044), (52, 0.04460607236251235), (2, 0.056492813397198915), (13, 0.05871008336544037), (1, 0.0626383894123137), (0, 0.1297301296144724), (36, 0.23539897054433823), (18, 0.25377006456255913), (53, 0.8727900460362434)]
computing accuracy for after removing block 42 . block score: 0.0238142148591578
removed block 42 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 50, with score 0.025348. All blocks and scores: [(50, 0.025348418159410357), (49, 0.02587856608442962), (51, 0.02677222341299057), (48, 0.026947205420583487), (10, 0.027306403499096632), (35, 0.02841479890048504), (41, 0.02866106410510838), (15, 0.02969584916718304), (46, 0.029775870963931084), (47, 0.031035703606903553), (24, 0.031580446753650904), (12, 0.03222087770700455), (5, 0.032400724943727255), (6, 0.032660032622516155), (4, 0.03905305592343211), (3, 0.04004123713821173), (52, 0.040360760409384966), (2, 0.0564928138628602), (13, 0.05871008289977908), (1, 0.06263838987797499), (0, 0.12973013147711754), (36, 0.23539897240698338), (18, 0.25377006456255913), (53, 0.9630037173628807)]
computing accuracy for after removing block 50 . block score: 0.025348418159410357
removed block 50 current accuracy 0.9566 loss from initial  0.043399999999999994
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 49, with score 0.025879. All blocks and scores: [(49, 0.025878564920276403), (48, 0.026947205420583487), (10, 0.02730640326626599), (35, 0.02841479843482375), (41, 0.028661064337939024), (15, 0.029695849400013685), (46, 0.02977587189525366), (47, 0.03103570267558098), (24, 0.03158044791780412), (51, 0.031886177603155375), (12, 0.032220878172665834), (5, 0.03240072634071112), (6, 0.03266003355383873), (4, 0.039053057320415974), (3, 0.0400412380695343), (52, 0.04371871938928962), (2, 0.05649281479418278), (13, 0.05871008196845651), (1, 0.06263838754966855), (0, 0.12973013147711754), (36, 0.23539896495640278), (18, 0.25377006083726883), (53, 1.154138445854187)]
computing accuracy for after removing block 49 . block score: 0.025878564920276403
removed block 49 current accuracy 0.923 loss from initial  0.07699999999999996
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 48, with score 0.026947. All blocks and scores: [(48, 0.02694720565341413), (10, 0.02730640326626599), (35, 0.02841479773633182), (41, 0.02866106596775353), (15, 0.02969584846869111), (46, 0.029775870265439153), (47, 0.031035702908411622), (24, 0.031580446753650904), (12, 0.03222087863832712), (5, 0.03240072587504983), (6, 0.03266003215685487), (51, 0.03602228173986077), (4, 0.03905305499210954), (3, 0.04004123667255044), (52, 0.04183938121423125), (2, 0.05649281432852149), (13, 0.05871008289977908), (1, 0.06263838894665241), (0, 0.12973013147711754), (36, 0.23539896495640278), (18, 0.2537700682878494), (53, 1.3978838473558426)]
computing accuracy for after removing block 48 . block score: 0.02694720565341413
removed block 48 current accuracy 0.8654 loss from initial  0.13460000000000005
since last training loss: 0.1282000000000001 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 10, with score 0.027306. All blocks and scores: [(10, 0.027306403731927276), (35, 0.028414798667654395), (41, 0.028661064570769668), (15, 0.029695848235860467), (46, 0.029775871196761727), (47, 0.03103570337407291), (24, 0.03158044698648155), (12, 0.032220878172665834), (5, 0.032400724943727255), (6, 0.03266003169119358), (4, 0.03905305592343211), (3, 0.04004123620688915), (51, 0.04186413902789354), (52, 0.045898768585175276), (2, 0.056492813397198915), (13, 0.05871008150279522), (1, 0.06263838894665241), (0, 0.12973013147711754), (36, 0.23539896681904793), (18, 0.25377006083726883), (53, 1.6607584208250046)]
computing accuracy for after removing block 10 . block score: 0.027306403731927276
removed block 10 current accuracy 0.8192 loss from initial  0.18079999999999996
since last training loss: 0.1744 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 41, with score 0.026419. All blocks and scores: [(41, 0.02641870896331966), (35, 0.026629311963915825), (47, 0.030561599181964993), (46, 0.03126156656071544), (24, 0.031294964952394366), (15, 0.03150760428979993), (5, 0.032400724943727255), (6, 0.03266003169119358), (12, 0.035584155935794115), (4, 0.03905305778607726), (3, 0.040041237603873014), (51, 0.04056934965774417), (52, 0.04361456772312522), (2, 0.05649281479418278), (1, 0.06263839080929756), (13, 0.06635712925344706), (0, 0.12973013520240784), (36, 0.22944705933332443), (18, 0.25537753105163574), (53, 1.6024102568626404)]
computing accuracy for after removing block 41 . block score: 0.02641870896331966
removed block 41 current accuracy 0.7638 loss from initial  0.23619999999999997
since last training loss: 0.2298 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 35, with score 0.026629. All blocks and scores: [(35, 0.026629311498254538), (24, 0.031294964253902435), (47, 0.031451390124857426), (15, 0.0315076052211225), (5, 0.03240072587504983), (6, 0.03266003122553229), (46, 0.0333014247007668), (12, 0.03558415500447154), (4, 0.039053057320415974), (3, 0.040041237603873014), (51, 0.041680254973471165), (52, 0.043208213057368994), (2, 0.056492813397198915), (1, 0.06263838987797499), (13, 0.06635713018476963), (0, 0.1297301296144724), (36, 0.22944705374538898), (18, 0.25537752360105515), (53, 1.6482102274894714)]
computing accuracy for after removing block 35 . block score: 0.026629311498254538
removed block 35 current accuracy 0.7084 loss from initial  0.29159999999999997
since last training loss: 0.2852 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 47, with score 0.029719. All blocks and scores: [(47, 0.029718644451349974), (24, 0.03129496588371694), (15, 0.03150760568678379), (5, 0.03240072634071112), (6, 0.03266003308817744), (46, 0.03359104413539171), (12, 0.035584155935794115), (4, 0.03905305592343211), (52, 0.03927580872550607), (3, 0.040041235741227865), (51, 0.0427873726002872), (2, 0.05649281572550535), (1, 0.06263838754966855), (13, 0.06635712925344706), (0, 0.12973013147711754), (36, 0.2384092714637518), (18, 0.25537753105163574), (53, 1.7725665122270584)]
computing accuracy for after removing block 47 . block score: 0.029718644451349974
removed block 47 current accuracy 0.5464 loss from initial  0.4536
since last training loss: 0.44720000000000004 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 24, with score 0.031295. All blocks and scores: [(24, 0.03129496402107179), (15, 0.031507604755461216), (5, 0.032400724943727255), (6, 0.03266003122553229), (46, 0.03359104273840785), (12, 0.035584154073148966), (4, 0.039053056854754686), (3, 0.040041237603873014), (52, 0.042823551688343287), (51, 0.04608879471197724), (2, 0.05649281432852149), (1, 0.06263839080929756), (13, 0.06635713018476963), (0, 0.1297301333397627), (36, 0.23840927332639694), (18, 0.25537753105163574), (53, 2.065571278333664)]
computing accuracy for after removing block 24 . block score: 0.03129496402107179
removed block 24 current accuracy 0.4982 loss from initial  0.5018
since last training loss: 0.49540000000000006 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 15, with score 0.031508. All blocks and scores: [(15, 0.031507604755461216), (5, 0.032400724943727255), (6, 0.03266003308817744), (12, 0.03558415453881025), (4, 0.039053056854754686), (46, 0.03910587355494499), (3, 0.04004123713821173), (52, 0.0463582593947649), (51, 0.04954043496400118), (2, 0.05649281432852149), (1, 0.06263838987797499), (13, 0.0663571311160922), (0, 0.1297301333397627), (18, 0.25537752732634544), (36, 0.2757483497262001), (53, 2.1655335128307343)]
computing accuracy for after removing block 15 . block score: 0.031507604755461216
removed block 15 current accuracy 0.418 loss from initial  0.5820000000000001
training start
training epoch 0 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.001]
training epoch 1 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 2 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.001]
training epoch 3 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 4 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 5 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 6 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 7 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 8 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 25 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 27 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 29 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 30 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 31 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 35 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 37 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 38 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 46 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 47 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 48 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 49 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
loading model_best from epoch 25 (acc 0.950400)
finished training. finished 50 epochs. accuracy 0.9504 topk_dict {'top1': 0.9504}
