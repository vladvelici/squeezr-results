start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806279979646), (30, 0.007531446346547455), (2, 0.007728804950602353), (31, 0.009409212623722851), (34, 0.010633390164002776), (33, 0.010768219362944365), (35, 0.01082665123976767), (32, 0.011131544481031597), (28, 0.012192570953629911), (29, 0.013092639273963869), (26, 0.01327010605018586), (25, 0.014763001934625208), (27, 0.01578354462981224), (24, 0.015805189963430166), (22, 0.015843698172830045), (23, 0.017308010021224618), (39, 0.019983843434602022), (42, 0.020841387333348393), (38, 0.021028662333264947), (14, 0.021516708889976144), (43, 0.021687703439965844), (5, 0.021877117920666933), (41, 0.02212515566498041), (44, 0.022776450030505657), (45, 0.023535518907010555), (40, 0.024229632690548897), (47, 0.024651852203533053), (37, 0.0251739586237818), (49, 0.025184792699292302), (3, 0.02567107114009559), (21, 0.025702943094074726), (50, 0.025765859754756093), (20, 0.027230342850089073), (46, 0.028618558309972286), (17, 0.029949784744530916), (51, 0.031313665676862), (48, 0.03152880142442882), (19, 0.03474585711956024), (16, 0.045105695724487305), (15, 0.04667254677042365), (0, 0.0474615478888154), (6, 0.050394101068377495), (7, 0.05069215688854456), (4, 0.05092597380280495), (10, 0.06328557757660747), (13, 0.06400972791016102), (8, 0.06672556232661009), (52, 0.06828812044113874), (12, 0.07267716806381941), (11, 0.0741947004571557), (9, 0.07928675226867199), (36, 0.3385251834988594), (18, 0.4787600636482239), (53, 0.9074814990162849)]
computing accuracy for after removing block 1 . block score: 0.004111806279979646
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.0075583591824397445), (2, 0.007992399798240513), (31, 0.009376695496030152), (34, 0.010569097939878702), (33, 0.010759366559796035), (35, 0.010833791922777891), (32, 0.011090524261817336), (28, 0.012191424611955881), (29, 0.013140873867087066), (26, 0.013311112183146179), (25, 0.014746290282346308), (24, 0.015801147324964404), (22, 0.015853286604397), (27, 0.01587040233425796), (23, 0.017250196542590857), (39, 0.019925506319850683), (42, 0.02083982713520527), (38, 0.020938864210620522), (5, 0.021410029847174883), (14, 0.021470679668709636), (43, 0.021646991139277816), (41, 0.02209674334153533), (44, 0.022830850444734097), (45, 0.02349419007077813), (40, 0.02426302875392139), (47, 0.0246264326851815), (37, 0.02515707165002823), (49, 0.025184772443026304), (21, 0.025624873116612434), (50, 0.025800991570577025), (3, 0.02626762166619301), (20, 0.0271265406627208), (46, 0.028638297226279974), (17, 0.030022145714610815), (51, 0.031291100196540356), (48, 0.031514890026301146), (19, 0.03466663183644414), (16, 0.04479835694655776), (15, 0.0464080860838294), (0, 0.04746154695749283), (4, 0.05093049444258213), (6, 0.05134963151067495), (7, 0.05156157026067376), (10, 0.06291997712105513), (13, 0.06426404137164354), (52, 0.06817463133484125), (8, 0.0683986721560359), (12, 0.07294023223221302), (11, 0.07450826559215784), (9, 0.0804285891354084), (36, 0.3383275642991066), (18, 0.4787031263113022), (53, 0.9076695814728737)]
computing accuracy for after removing block 30 . block score: 0.0075583591824397445
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992400089278817), (31, 0.009402871364727616), (34, 0.010204410296864808), (35, 0.010435782955028117), (33, 0.010974526987411082), (32, 0.011320484918542206), (28, 0.01219142519403249), (29, 0.013140873634256423), (26, 0.013311112183146179), (25, 0.014746290864422917), (24, 0.01580114709213376), (22, 0.015853286604397), (27, 0.01587040233425796), (23, 0.017250196542590857), (39, 0.01986637688241899), (38, 0.020629742415621877), (42, 0.02069183182902634), (5, 0.021410029847174883), (14, 0.02147067990154028), (43, 0.02183908480219543), (41, 0.02201103768311441), (44, 0.022784787695854902), (45, 0.02333742706105113), (47, 0.024608810199424624), (40, 0.02479364164173603), (49, 0.025005089584738016), (21, 0.025624872418120503), (37, 0.025666436878964305), (50, 0.025765019468963146), (3, 0.026267621433362365), (20, 0.0271265406627208), (46, 0.028450447134673595), (17, 0.03002214664593339), (51, 0.0308925099670887), (48, 0.031455071875825524), (19, 0.03466663137078285), (16, 0.044798356015235186), (15, 0.04640808468684554), (0, 0.047461547423154116), (4, 0.05093049490824342), (6, 0.05134962871670723), (7, 0.051561571191996336), (10, 0.06291997479274869), (13, 0.06426404137164354), (52, 0.0677470751106739), (8, 0.06839866936206818), (12, 0.07294023409485817), (11, 0.07450826372951269), (9, 0.08042858727276325), (36, 0.3417893573641777), (18, 0.4787031076848507), (53, 0.9106026738882065)]
computing accuracy for after removing block 2 . block score: 0.007992400089278817
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.009391384082846344), (34, 0.010356180253438652), (35, 0.010530833853408694), (33, 0.010978628182783723), (32, 0.011285086045973003), (28, 0.012222225544974208), (29, 0.013395004556514323), (26, 0.013411890482529998), (25, 0.014773016097024083), (24, 0.015895847463980317), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (39, 0.01986844907514751), (42, 0.020744004286825657), (38, 0.02075049956329167), (5, 0.021117351250723004), (14, 0.021327618742361665), (43, 0.021792823215946555), (41, 0.021959960460662842), (44, 0.02287760842591524), (45, 0.023284759372472763), (47, 0.02453559497371316), (40, 0.024922656826674938), (49, 0.024976717308163643), (21, 0.025540468515828252), (50, 0.02573660877533257), (37, 0.02574000204913318), (3, 0.02662608423270285), (20, 0.027130910428240895), (46, 0.028354251757264137), (17, 0.030052858870476484), (51, 0.030807055300101638), (48, 0.031364004127681255), (19, 0.034590966533869505), (16, 0.044494171161204576), (15, 0.0461846268735826), (0, 0.047461546026170254), (4, 0.05093384813517332), (7, 0.052482133731245995), (6, 0.053186831064522266), (10, 0.06307358806952834), (13, 0.06417542602866888), (52, 0.06737186666578054), (8, 0.07143167871981859), (12, 0.07294508069753647), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3429318964481354), (18, 0.48187144100666046), (53, 0.9105552956461906)]
computing accuracy for after removing block 31 . block score: 0.009391384082846344
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.010089670540764928), (35, 0.010449821129441261), (33, 0.010985721950419247), (32, 0.011304144747555256), (28, 0.012222225777804852), (29, 0.013395005138590932), (26, 0.01341189059894532), (25, 0.014773016213439405), (24, 0.015895847929641604), (22, 0.015945045510306954), (27, 0.01605706592090428), (23, 0.017187519697472453), (39, 0.01979714771732688), (38, 0.020344304386526346), (42, 0.02058867714367807), (5, 0.021117351949214935), (14, 0.021327617578208447), (43, 0.02176103019155562), (41, 0.021869145799428225), (44, 0.022828260203823447), (45, 0.023396301781758666), (47, 0.02450825716368854), (49, 0.024995684158056974), (40, 0.02505605178885162), (21, 0.025540467584505677), (37, 0.02570135099813342), (50, 0.02590625244192779), (3, 0.02662608423270285), (20, 0.027130909962579608), (46, 0.028551972238346934), (17, 0.03005285863764584), (51, 0.030911056324839592), (48, 0.03148650377988815), (19, 0.03459096699953079), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.047461547423154116), (4, 0.05093384673818946), (7, 0.052482133731245995), (6, 0.05318683059886098), (10, 0.0630735857412219), (13, 0.06417542695999146), (52, 0.06731626018881798), (8, 0.07143167778849602), (12, 0.07294507510960102), (11, 0.07423979043960571), (9, 0.0819232165813446), (36, 0.34496788308024406), (18, 0.48187144100666046), (53, 0.9170897230505943)]
computing accuracy for after removing block 34 . block score: 0.010089670540764928
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.010489318054169416), (33, 0.010985721834003925), (32, 0.011304144747555256), (28, 0.012222225312143564), (29, 0.01339500560425222), (26, 0.013411890715360641), (25, 0.014773015165701509), (24, 0.015895847463980317), (22, 0.015945045510306954), (27, 0.01605706592090428), (23, 0.017187519697472453), (39, 0.01926664123311639), (38, 0.019315700512379408), (42, 0.01967391138896346), (5, 0.02111735101789236), (41, 0.021174799418076873), (43, 0.021180002484470606), (14, 0.021327618276700377), (44, 0.022253610426560044), (45, 0.023224937496706843), (47, 0.02422352065332234), (49, 0.0246623323764652), (40, 0.02475132793188095), (37, 0.025114945834502578), (21, 0.025540468515828252), (50, 0.02563990536145866), (3, 0.026626083767041564), (20, 0.027130910893902183), (46, 0.02807540842331946), (17, 0.03005285933613777), (51, 0.03030704613775015), (48, 0.031094568083062768), (19, 0.03459096606820822), (16, 0.04449417255818844), (15, 0.04618462594226003), (0, 0.04746154509484768), (4, 0.05093384766951203), (7, 0.05248213279992342), (6, 0.05318683246150613), (10, 0.06307358667254448), (13, 0.06417542602866888), (52, 0.06632223725318909), (8, 0.07143167592585087), (12, 0.07294507883489132), (11, 0.07423978857696056), (9, 0.08192321192473173), (36, 0.3418983295559883), (18, 0.48187144100666046), (53, 0.9368007332086563)]
computing accuracy for after removing block 35 . block score: 0.010489318054169416
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.01098572218324989), (32, 0.011304145096801221), (28, 0.012222225777804852), (29, 0.01339500502217561), (26, 0.013411890133284032), (25, 0.014773016097024083), (24, 0.015895847463980317), (22, 0.015945044811815023), (27, 0.016057066153734922), (23, 0.017187519930303097), (38, 0.018365238793194294), (39, 0.01873115892522037), (42, 0.018845457583665848), (41, 0.02022721990942955), (43, 0.02047862485051155), (5, 0.021117351250723004), (14, 0.02132761781103909), (44, 0.02179614081978798), (45, 0.0228491744492203), (47, 0.02364554931409657), (40, 0.02389344177208841), (49, 0.024012630572542548), (37, 0.024080609437078238), (50, 0.025119469966739416), (21, 0.02554046781733632), (3, 0.026626084465533495), (20, 0.027130911126732826), (46, 0.02747296169400215), (51, 0.02944464865140617), (17, 0.03005285863764584), (48, 0.030196278588846326), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.0474615478888154), (4, 0.050933849066495895), (7, 0.052482133731245995), (6, 0.05318683059886098), (10, 0.06307358620688319), (13, 0.06417542230337858), (52, 0.06433123257011175), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423978764563799), (9, 0.08192321378737688), (36, 0.3352629393339157), (18, 0.48187145590782166), (53, 0.9589025378227234)]
computing accuracy for after removing block 33 . block score: 0.01098572218324989
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144747555256), (28, 0.012222225312143564), (29, 0.013395005138590932), (26, 0.013411890482529998), (25, 0.01477301586419344), (24, 0.01589584769681096), (22, 0.015945045743137598), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.017859898041933775), (39, 0.018481213599443436), (42, 0.018494685646146536), (41, 0.019707750994712114), (43, 0.019804098643362522), (5, 0.021117351483553648), (14, 0.021327617345377803), (44, 0.02134113945066929), (45, 0.022757312515750527), (47, 0.022884674137458205), (40, 0.022964164847508073), (49, 0.023509371792897582), (37, 0.02359610889106989), (50, 0.024730789940804243), (21, 0.02554046781733632), (3, 0.026626083767041564), (46, 0.02685158816166222), (20, 0.027130910428240895), (51, 0.028670211788266897), (48, 0.029500650241971016), (17, 0.030052859103307128), (19, 0.034590966533869505), (16, 0.044494171161204576), (15, 0.04618462501093745), (0, 0.047461547423154116), (4, 0.05093384953215718), (7, 0.05248213419690728), (6, 0.05318683013319969), (52, 0.06240901490673423), (10, 0.06307358667254448), (13, 0.06417542602866888), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423979137092829), (9, 0.08192321751266718), (36, 0.330499742180109), (18, 0.48187143355607986), (53, 0.9826682507991791)]
computing accuracy for after removing block 32 . block score: 0.011304144747555256
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012222. All blocks and scores: [(28, 0.012222225544974208), (29, 0.013395005138590932), (26, 0.013411890366114676), (25, 0.014773015747778118), (24, 0.015895847929641604), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.017423493787646294), (42, 0.01785332732833922), (39, 0.01824311213567853), (41, 0.019577455008402467), (43, 0.019590672105550766), (44, 0.02097980328835547), (5, 0.02111735218204558), (14, 0.021327617578208447), (47, 0.022578311385586858), (45, 0.022697478299960494), (37, 0.022853390080854297), (49, 0.0231905160471797), (40, 0.023227871861308813), (50, 0.024362222757190466), (21, 0.025540468050166965), (46, 0.02650547376833856), (3, 0.026626083301380277), (20, 0.02713091135956347), (51, 0.02819360769353807), (48, 0.02943548862822354), (17, 0.030052860034629703), (19, 0.034590966533869505), (16, 0.04449417209252715), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384813517332), (7, 0.052482135128229856), (6, 0.053186831530183554), (52, 0.061633951496332884), (10, 0.06307358713820577), (13, 0.06417542695999146), (8, 0.07143167871981859), (12, 0.0729450797662139), (11, 0.07423978950828314), (9, 0.08192321565002203), (36, 0.3290293738245964), (18, 0.48187144100666046), (53, 0.9939456954598427)]
computing accuracy for after removing block 28 . block score: 0.012222225544974208
removed block 28 current accuracy 0.9988 loss from initial  0.0011999999999999789
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 2 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.013303. All blocks and scores: [(29, 0.013303218758665025), (26, 0.013706894358620048), (25, 0.015274091274477541), (24, 0.01600838592275977), (27, 0.01608367939479649), (22, 0.01627668971195817), (23, 0.01777615025639534), (39, 0.01913510519079864), (42, 0.020008395425975323), (43, 0.020724375499412417), (41, 0.020757191348820925), (38, 0.020789117086678743), (14, 0.02150561148300767), (5, 0.022000275552272797), (44, 0.02204341278411448), (45, 0.022991778561845422), (40, 0.02341576828621328), (47, 0.024401088012382388), (37, 0.024541518650949), (49, 0.02517875307239592), (3, 0.02524822182022035), (50, 0.025363150285556912), (21, 0.025841421680524945), (46, 0.027419846039265394), (20, 0.027795307571068406), (17, 0.030240198830142617), (51, 0.03139452263712883), (48, 0.031495981151238084), (19, 0.035013146698474884), (16, 0.04493155423551798), (15, 0.04638216318562627), (0, 0.04745159251615405), (6, 0.0493737724609673), (4, 0.04987700842320919), (7, 0.049902443774044514), (10, 0.06244421470910311), (13, 0.06416160333901644), (8, 0.06611363682895899), (52, 0.06820749584585428), (12, 0.07211945857852697), (11, 0.07388693001121283), (9, 0.07865002192556858), (36, 0.32394664362072945), (18, 0.478858582675457), (53, 0.8746635094285011)]
computing accuracy for after removing block 29 . block score: 0.013303218758665025
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013707. All blocks and scores: [(26, 0.01370689447503537), (25, 0.015274091507308185), (24, 0.016008385689929128), (27, 0.016083679860457778), (22, 0.016276689944788814), (23, 0.01777615025639534), (39, 0.01890334556810558), (38, 0.019989416701719165), (42, 0.020126964431256056), (41, 0.02059175563044846), (43, 0.02059826417826116), (14, 0.021505611017346382), (44, 0.021545660216361284), (5, 0.022000276250764728), (45, 0.022923288866877556), (40, 0.023631326155737042), (47, 0.024149126140400767), (37, 0.024437093874439597), (49, 0.02474884409457445), (50, 0.025235731387510896), (3, 0.025248221587389708), (21, 0.025841421214863658), (46, 0.02755166683346033), (20, 0.02779530710540712), (17, 0.030240199761465192), (51, 0.0312008298933506), (48, 0.03160706884227693), (19, 0.035013146698474884), (16, 0.04493155376985669), (15, 0.046382163651287556), (0, 0.04745159251615405), (6, 0.049373770132660866), (4, 0.0498770079575479), (7, 0.04990244237706065), (10, 0.06244421470910311), (13, 0.06416160333901644), (8, 0.06611363776028156), (52, 0.06791824102401733), (12, 0.07211945950984955), (11, 0.07388693001121283), (9, 0.07865002006292343), (36, 0.3263620622456074), (18, 0.4788585975766182), (53, 0.8782376423478127)]
computing accuracy for after removing block 26 . block score: 0.01370689447503537
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.015274. All blocks and scores: [(25, 0.015274091623723507), (24, 0.016008385689929128), (22, 0.016276690177619457), (27, 0.016406786162406206), (23, 0.017776150722056627), (39, 0.0184415050316602), (42, 0.019250917714089155), (38, 0.019736074842512608), (43, 0.020150025375187397), (41, 0.020247658248990774), (44, 0.021266834111884236), (14, 0.02150561148300767), (5, 0.022000276250764728), (45, 0.022704994305968285), (40, 0.023138745687901974), (47, 0.023908057482913136), (37, 0.02415187726728618), (49, 0.02448516571894288), (3, 0.025248221354559064), (50, 0.025282119633629918), (21, 0.025841420982033014), (46, 0.026996183209121227), (20, 0.02779530710540712), (17, 0.030240198830142617), (51, 0.030319571495056152), (48, 0.031577706802636385), (19, 0.035013146698474884), (16, 0.04493155423551798), (15, 0.046382163651287556), (0, 0.04745159298181534), (6, 0.04937377059832215), (4, 0.049877009354531765), (7, 0.04990244237706065), (10, 0.06244421377778053), (13, 0.06416160333901644), (8, 0.06611363589763641), (52, 0.06647379137575626), (12, 0.07211945857852697), (11, 0.0738869309425354), (9, 0.07865002006292343), (36, 0.32287822291255), (18, 0.4788585938513279), (53, 0.8979814425110817)]
computing accuracy for after removing block 25 . block score: 0.015274091623723507
removed block 25 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.016008. All blocks and scores: [(24, 0.016008385689929128), (27, 0.016229268396273255), (22, 0.016276690177619457), (23, 0.017776149790734053), (39, 0.017993579618632793), (42, 0.018902622861787677), (38, 0.019460828974843025), (43, 0.020071293227374554), (41, 0.0201297493185848), (44, 0.02111690305173397), (14, 0.02150561078451574), (5, 0.022000276017934084), (45, 0.022377822548151016), (40, 0.022964966483414173), (47, 0.023523371666669846), (37, 0.02363960212096572), (49, 0.02397682354785502), (50, 0.025242338189855218), (3, 0.02524822182022035), (21, 0.025841421680524945), (46, 0.026804642286151648), (20, 0.02779530663974583), (51, 0.02945133321918547), (17, 0.030240198830142617), (48, 0.031070633325725794), (19, 0.035013146698474884), (16, 0.044931554701179266), (15, 0.046382163651287556), (0, 0.04745159298181534), (6, 0.04937377059832215), (4, 0.0498770079575479), (7, 0.04990244237706065), (10, 0.06244421424344182), (13, 0.06416160240769386), (52, 0.06452808994799852), (8, 0.06611363589763641), (12, 0.0721194576472044), (11, 0.07388693001121283), (9, 0.078650020994246), (36, 0.32561634108424187), (18, 0.4788586013019085), (53, 0.9109052121639252)]
computing accuracy for after removing block 24 . block score: 0.016008385689929128
removed block 24 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015612. All blocks and scores: [(27, 0.015611839247867465), (22, 0.01627668971195817), (23, 0.017776150489225984), (39, 0.017911652103066444), (42, 0.018637209199368954), (38, 0.01929330942220986), (43, 0.019917215686291456), (41, 0.01997533510439098), (44, 0.02087489957921207), (14, 0.021505611017346382), (5, 0.02200027578510344), (45, 0.0222309660166502), (40, 0.022704435978084803), (47, 0.023113802075386047), (49, 0.02353748632594943), (37, 0.023941100342199206), (50, 0.02502939011901617), (3, 0.025248222518712282), (21, 0.025841420516371727), (46, 0.026305214036256075), (20, 0.02779530780389905), (51, 0.02870146045461297), (17, 0.03024019836448133), (48, 0.030558846658095717), (19, 0.03501314716413617), (16, 0.04493155376985669), (15, 0.04638216271996498), (0, 0.04745159251615405), (6, 0.04937377152964473), (4, 0.04987701075151563), (7, 0.04990244098007679), (10, 0.06244421377778053), (52, 0.06311974162235856), (13, 0.06416160333901644), (8, 0.06611363869160414), (12, 0.0721194613724947), (11, 0.07388693280518055), (9, 0.07865002006292343), (36, 0.32603078335523605), (18, 0.4788585864007473), (53, 0.9190894067287445)]
computing accuracy for after removing block 27 . block score: 0.015611839247867465
removed block 27 current accuracy 0.9922 loss from initial  0.007800000000000029
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.016277. All blocks and scores: [(22, 0.016276690177619457), (39, 0.01735753519460559), (23, 0.017776150489225984), (42, 0.018226149724796414), (38, 0.018477421486750245), (43, 0.019238066859543324), (41, 0.019545565359294415), (44, 0.020798696670681238), (14, 0.02150561148300767), (45, 0.021963375620543957), (5, 0.022000276250764728), (40, 0.022173608653247356), (47, 0.02244592527858913), (49, 0.022997174179181457), (37, 0.02332976250909269), (50, 0.025195294758304954), (3, 0.02524822228588164), (46, 0.02570815314538777), (21, 0.025841421214863658), (20, 0.027795308269560337), (51, 0.028024779865518212), (48, 0.030198098393157125), (17, 0.030240198830142617), (19, 0.0350131462328136), (16, 0.044931554701179266), (15, 0.046382163651287556), (0, 0.04745159251615405), (6, 0.049373768735677004), (4, 0.04987700842320919), (7, 0.04990244284272194), (52, 0.06179882446303964), (10, 0.06244421470910311), (13, 0.06416160427033901), (8, 0.06611363776028156), (12, 0.0721194576472044), (11, 0.0738869309425354), (9, 0.078650020994246), (36, 0.32133838161826134), (18, 0.4788585938513279), (53, 0.9327199906110764)]
computing accuracy for after removing block 22 . block score: 0.016276690177619457
removed block 22 current accuracy 0.9892 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.017287. All blocks and scores: [(23, 0.017287312541157007), (39, 0.017352759838104248), (42, 0.017412827583029866), (38, 0.018480201484635472), (43, 0.0194264177698642), (41, 0.01961256843060255), (44, 0.020901547512039542), (14, 0.021505611017346382), (40, 0.02153061470016837), (45, 0.022000011056661606), (5, 0.02200027578510344), (47, 0.02204536134377122), (49, 0.02257340122014284), (37, 0.023271293379366398), (50, 0.025229168590158224), (3, 0.025248222751542926), (46, 0.02560618077404797), (21, 0.025841421214863658), (51, 0.027301214169710875), (20, 0.027795307571068406), (48, 0.029636399587616324), (17, 0.030240198597311974), (19, 0.0350131462328136), (16, 0.04493155376985669), (15, 0.04638216271996498), (0, 0.047451590187847614), (6, 0.04937377059832215), (4, 0.04987700888887048), (7, 0.04990244144573808), (52, 0.06073352973908186), (10, 0.062444215174764395), (13, 0.06416160427033901), (8, 0.06611363869160414), (12, 0.07211945671588182), (11, 0.07388693001121283), (9, 0.07865002285689116), (36, 0.32022956758737564), (18, 0.4788585901260376), (53, 0.9466435015201569)]
computing accuracy for after removing block 23 . block score: 0.017287312541157007
removed block 23 current accuracy 0.9816 loss from initial  0.018399999999999972
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.017045. All blocks and scores: [(42, 0.017045005690306425), (39, 0.017071387032046914), (38, 0.01780256861820817), (41, 0.019261642824858427), (43, 0.019460398005321622), (44, 0.020727004623040557), (40, 0.021386984968557954), (47, 0.02149424608796835), (14, 0.02150561148300767), (45, 0.021559166489169), (49, 0.021968126064166427), (5, 0.02200027578510344), (37, 0.022812495240941644), (46, 0.025006469106301665), (50, 0.025019087363034487), (3, 0.025248222053050995), (21, 0.025841421214863658), (51, 0.026523137697950006), (20, 0.027795307338237762), (48, 0.0291947852820158), (17, 0.030240198597311974), (19, 0.03501314530149102), (16, 0.04493155376985669), (15, 0.046382163651287556), (0, 0.047451592050492764), (6, 0.04937377152964473), (4, 0.04987700842320919), (7, 0.04990244284272194), (52, 0.05905523942783475), (10, 0.062444215174764395), (13, 0.06416160427033901), (8, 0.06611363682895899), (12, 0.0721194576472044), (11, 0.0738869309425354), (9, 0.07865002006292343), (36, 0.3227582424879074), (18, 0.4788585975766182), (53, 0.9589846208691597)]
computing accuracy for after removing block 42 . block score: 0.017045005690306425
removed block 42 current accuracy 0.977 loss from initial  0.02300000000000002
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.017071. All blocks and scores: [(39, 0.017071386566385627), (38, 0.01780256861820817), (41, 0.01926164235919714), (43, 0.02089837216772139), (40, 0.021386984270066023), (14, 0.02150561078451574), (47, 0.02153247524984181), (44, 0.021569474134594202), (49, 0.021904808236286044), (5, 0.022000275319442153), (45, 0.02248998684808612), (37, 0.02281249430961907), (50, 0.02497929474338889), (3, 0.025248221587389708), (46, 0.025660603772848845), (51, 0.02580781141296029), (21, 0.025841421680524945), (20, 0.02779530780389905), (48, 0.028745070099830627), (17, 0.03024019836448133), (19, 0.03501314576715231), (16, 0.04493155376985669), (15, 0.046382163651287556), (0, 0.047451591584831476), (6, 0.049373771995306015), (4, 0.049877007491886616), (7, 0.04990244144573808), (52, 0.05671342648565769), (10, 0.06244421377778053), (13, 0.06416160333901644), (8, 0.06611363962292671), (12, 0.0721194576472044), (11, 0.0738869309425354), (9, 0.07865002006292343), (36, 0.3227582424879074), (18, 0.4788586050271988), (53, 0.9857306405901909)]
computing accuracy for after removing block 39 . block score: 0.017071386566385627
removed block 39 current accuracy 0.9696 loss from initial  0.030399999999999983
training start
training epoch 0 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 1 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 2 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 3 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 4 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 5 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 6 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 8 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 9 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 11 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 14 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 15 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 18 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 19 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 21 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 22 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 23 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 25 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 28 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 29 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 30 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 31 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 32 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 41 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 42 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 43 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 44 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 45 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 46 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 48 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 49 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 18
[activation diff]: block to remove picked: 5, with score 0.021247. All blocks and scores: [(5, 0.021247100550681353), (38, 0.021518285386264324), (41, 0.022043496603146195), (14, 0.02226377767510712), (43, 0.02251441148109734), (44, 0.02299898792989552), (45, 0.023153748363256454), (47, 0.02364661148749292), (49, 0.024002200458198786), (50, 0.02410853886976838), (40, 0.02446505823172629), (3, 0.025768696330487728), (37, 0.025947091868147254), (46, 0.027637511724606156), (48, 0.03007440618239343), (51, 0.030591326067224145), (17, 0.031124692410230637), (21, 0.03579283831641078), (20, 0.03679701965302229), (19, 0.04284420236945152), (0, 0.04446833115071058), (16, 0.046795947942882776), (15, 0.04696527495980263), (7, 0.047501340974122286), (6, 0.04817763390019536), (4, 0.048398119397461414), (10, 0.058474902994930744), (13, 0.062833649571985), (8, 0.06400184100493789), (52, 0.06714110635221004), (12, 0.06972111761569977), (11, 0.07226781826466322), (9, 0.07562457770109177), (36, 0.3171428255736828), (18, 0.4579356089234352), (53, 0.8933886587619781)]
computing accuracy for after removing block 5 . block score: 0.021247100550681353
removed block 5 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 14, with score 0.021484. All blocks and scores: [(14, 0.021483836229890585), (38, 0.02207582350820303), (41, 0.022203243570402265), (43, 0.02274834574200213), (44, 0.02327081933617592), (45, 0.023334057768806815), (47, 0.023758908035233617), (49, 0.024101384915411472), (50, 0.024248202797025442), (3, 0.025768696796149015), (40, 0.02620841469615698), (37, 0.027218980016186833), (46, 0.027901202207431197), (17, 0.02986783511005342), (48, 0.030247640563175082), (51, 0.030299626756459475), (21, 0.035038037691265345), (20, 0.03622165648266673), (19, 0.04236516077071428), (0, 0.04446833115071058), (16, 0.04563153302296996), (15, 0.046530450228601694), (6, 0.04785692133009434), (4, 0.048398121260106564), (7, 0.05142219318076968), (10, 0.05854181759059429), (13, 0.06167292594909668), (8, 0.06566975452005863), (52, 0.06661129370331764), (11, 0.0680522546172142), (12, 0.0686997352167964), (9, 0.07558354828506708), (36, 0.32405886054039), (18, 0.4642755426466465), (53, 0.8976368382573128)]
computing accuracy for after removing block 14 . block score: 0.021483836229890585
removed block 14 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.023630. All blocks and scores: [(38, 0.023629880510270596), (45, 0.023884498979896307), (47, 0.024000350385904312), (41, 0.02411016938276589), (50, 0.02416866784915328), (44, 0.024398200679570436), (49, 0.024684513686224818), (43, 0.025440827943384647), (3, 0.025768696796149015), (40, 0.0275343784596771), (37, 0.02777929208241403), (46, 0.02825740142725408), (51, 0.02994308201596141), (48, 0.0301932692527771), (17, 0.031278498005121946), (21, 0.03480821708217263), (20, 0.03692134656012058), (0, 0.04446833115071058), (19, 0.04614096647128463), (16, 0.046521525364369154), (6, 0.04785691946744919), (15, 0.04823634820058942), (4, 0.048398119397461414), (7, 0.051422192715108395), (10, 0.05854181945323944), (13, 0.061672930140048265), (8, 0.06566975358873606), (52, 0.06660948041826487), (11, 0.06805225368589163), (12, 0.06869973335415125), (9, 0.07558354828506708), (36, 0.33365100994706154), (18, 0.4654149264097214), (53, 0.8698668032884598)]
computing accuracy for after removing block 38 . block score: 0.023629880510270596
removed block 38 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.023173. All blocks and scores: [(50, 0.023173425113782287), (47, 0.023570605320855975), (45, 0.023653900483623147), (49, 0.02379539329558611), (41, 0.02459120564162731), (44, 0.02518685767427087), (3, 0.02576869702897966), (43, 0.02580092428252101), (37, 0.027779291616752744), (46, 0.028204901376739144), (51, 0.02846985822543502), (48, 0.029274967266246676), (40, 0.029468914959579706), (17, 0.03127849823795259), (21, 0.03480821754783392), (20, 0.03692134702578187), (0, 0.04446833161637187), (19, 0.04614096553996205), (16, 0.046521525364369154), (6, 0.04785692039877176), (15, 0.048236346803605556), (4, 0.0483981198631227), (7, 0.05142219224944711), (10, 0.058541818987578154), (13, 0.06167292781174183), (52, 0.06439321441575885), (8, 0.06566975265741348), (11, 0.06805225275456905), (12, 0.06869973428547382), (9, 0.07558354642242193), (36, 0.33365100994706154), (18, 0.4654149226844311), (53, 0.8871512785553932)]
computing accuracy for after removing block 50 . block score: 0.023173425113782287
removed block 50 current accuracy 0.9912 loss from initial  0.00880000000000003
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 47, with score 0.023571. All blocks and scores: [(47, 0.023570605320855975), (45, 0.023653901182115078), (49, 0.02379539329558611), (41, 0.024591205175966024), (44, 0.025186858139932156), (3, 0.02576869702897966), (43, 0.02580092498101294), (37, 0.027779290918260813), (46, 0.028204900212585926), (48, 0.029274966567754745), (40, 0.02946891402825713), (51, 0.030305179534479976), (17, 0.031278499169275165), (21, 0.03480821708217263), (20, 0.036921346094459295), (0, 0.04446833161637187), (19, 0.04614096647128463), (16, 0.046521525364369154), (6, 0.04785692039877176), (15, 0.048236348666250706), (4, 0.048398119397461414), (7, 0.05142219318076968), (10, 0.05854181665927172), (13, 0.06167292781174183), (52, 0.06415533367544413), (8, 0.06566975358873606), (11, 0.06805225275456905), (12, 0.06869973428547382), (9, 0.07558355014771223), (36, 0.33365101739764214), (18, 0.4654149152338505), (53, 1.0635776966810226)]
computing accuracy for after removing block 47 . block score: 0.023570605320855975
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.023654. All blocks and scores: [(45, 0.02365390141494572), (41, 0.024591206572949886), (44, 0.02518685720860958), (3, 0.025768696796149015), (43, 0.02580092498101294), (49, 0.02603773190639913), (37, 0.02777929068543017), (46, 0.028204901376739144), (40, 0.029468915658071637), (17, 0.03127849823795259), (51, 0.03135745273903012), (48, 0.03218952682800591), (21, 0.03480821801349521), (20, 0.03692134702578187), (0, 0.04446833161637187), (19, 0.046140966936945915), (16, 0.04652152443304658), (6, 0.0478569190017879), (15, 0.04823634820058942), (4, 0.048398119397461414), (7, 0.05142219318076968), (10, 0.05854181805625558), (13, 0.06167292967438698), (52, 0.06529643665999174), (8, 0.06566975172609091), (11, 0.06805225368589163), (12, 0.06869973335415125), (9, 0.07558354549109936), (36, 0.33365101739764214), (18, 0.4654149115085602), (53, 1.1797253638505936)]
computing accuracy for after removing block 45 . block score: 0.02365390141494572
removed block 45 current accuracy 0.9622 loss from initial  0.037799999999999945
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.024591. All blocks and scores: [(41, 0.0245912061072886), (44, 0.025186857441440225), (3, 0.02576869586482644), (43, 0.02580092428252101), (49, 0.026617210591211915), (37, 0.0277792913839221), (40, 0.029468914261087775), (46, 0.030511584831401706), (51, 0.031005672411993146), (17, 0.031278499169275165), (48, 0.03230563597753644), (21, 0.034808218479156494), (20, 0.03692134656012058), (0, 0.04446833161637187), (19, 0.04614096600562334), (16, 0.046521525364369154), (6, 0.047856919933110476), (15, 0.048236347269266844), (4, 0.04839812032878399), (7, 0.05142219364643097), (10, 0.05854181572794914), (13, 0.061672928743064404), (52, 0.06302660563960671), (8, 0.0656697554513812), (11, 0.06805225275456905), (12, 0.06869973335415125), (9, 0.07558354828506708), (36, 0.33365100622177124), (18, 0.4654149264097214), (53, 1.2779200971126556)]
computing accuracy for after removing block 41 . block score: 0.0245912061072886
removed block 41 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 3, with score 0.025769. All blocks and scores: [(3, 0.025768696097657084), (49, 0.026485920418053865), (44, 0.026512903161346912), (37, 0.02777929068543017), (43, 0.027876810170710087), (40, 0.029468914959579706), (51, 0.029654527083039284), (46, 0.030648799845948815), (17, 0.03127849940210581), (48, 0.032111754175275564), (21, 0.03480821801349521), (20, 0.03692134656012058), (0, 0.044468332547694445), (19, 0.04614096553996205), (16, 0.04652152583003044), (6, 0.04785692086443305), (15, 0.04823634820058942), (4, 0.048398119397461414), (7, 0.05142219411209226), (10, 0.058541818987578154), (52, 0.06102737924084067), (13, 0.06167292967438698), (8, 0.06566975452005863), (11, 0.06805225368589163), (12, 0.06869973428547382), (9, 0.07558354921638966), (36, 0.33365101367235184), (18, 0.4654149077832699), (53, 1.3888972699642181)]
computing accuracy for after removing block 3 . block score: 0.025768696097657084
removed block 3 current accuracy 0.9368 loss from initial  0.06320000000000003
since last training loss: 0.062000000000000055 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.026375. All blocks and scores: [(49, 0.026375173358246684), (44, 0.026513793971389532), (43, 0.027365820482373238), (37, 0.02811151253990829), (51, 0.029217841802164912), (46, 0.02997415792196989), (40, 0.030316830845549703), (17, 0.030909712193533778), (48, 0.03190521523356438), (21, 0.033934690058231354), (20, 0.036331270821392536), (0, 0.04446833208203316), (16, 0.04467896232381463), (19, 0.045014629140496254), (15, 0.047183587215840816), (4, 0.047683516051620245), (7, 0.050897661596536636), (6, 0.05117635661736131), (52, 0.060676305554807186), (13, 0.06101008132100105), (10, 0.06289393315091729), (8, 0.06449261587113142), (12, 0.06652379222214222), (11, 0.0681516882032156), (9, 0.07441871147602797), (36, 0.33104216679930687), (18, 0.4655350483953953), (53, 1.4065567255020142)]
computing accuracy for after removing block 49 . block score: 0.026375173358246684
removed block 49 current accuracy 0.8948 loss from initial  0.10519999999999996
training start
training epoch 0 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best True lr [0.001]
training epoch 1 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 2 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 3 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 4 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 5 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 6 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 7 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 8 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 9 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 10 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 11 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 12 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 13 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 14 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 15 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 16 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 17 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 18 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 19 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 20 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 21 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 22 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 23 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 24 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 25 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 26 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 27 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 28 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 29 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 30 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 31 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 32 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 33 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 34 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 35 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 36 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 37 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 38 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 40 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 41 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 42 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 43 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 44 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 46 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 47 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 48 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 49 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.994400)
finished training. finished 50 epochs. accuracy 0.9944 topk_dict {'top1': 0.9944}
start iteration 27
[activation diff]: block to remove picked: 44, with score 0.026194. All blocks and scores: [(44, 0.026194361969828606), (43, 0.026705472264438868), (37, 0.02855815179646015), (40, 0.028668010141700506), (17, 0.029439417645335197), (46, 0.031435118056833744), (48, 0.034956207033246756), (51, 0.03897591261193156), (20, 0.041408211924135685), (21, 0.04298065975308418), (16, 0.04409290198236704), (0, 0.04458149895071983), (15, 0.04643995175138116), (19, 0.047612184192985296), (6, 0.04797197552397847), (4, 0.04838766250759363), (7, 0.04884487111121416), (10, 0.05770428851246834), (8, 0.06105378223583102), (13, 0.061901749577373266), (12, 0.06688237935304642), (11, 0.07051664404571056), (52, 0.07123156357556581), (9, 0.07433958631008863), (36, 0.27165884524583817), (18, 0.4174953028559685), (53, 0.9598840475082397)]
computing accuracy for after removing block 44 . block score: 0.026194361969828606
removed block 44 current accuracy 0.9818 loss from initial  0.018199999999999994
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 43, with score 0.026705. All blocks and scores: [(43, 0.026705472031608224), (37, 0.028558153193444014), (40, 0.028668009443208575), (17, 0.02943941648118198), (46, 0.034604504238814116), (48, 0.03584782686084509), (51, 0.037527075968682766), (20, 0.04140821099281311), (21, 0.04298065882176161), (16, 0.044092902448028326), (0, 0.044581498485058546), (15, 0.046439952217042446), (19, 0.04761218698695302), (6, 0.04797197552397847), (4, 0.04838766157627106), (7, 0.04884487250819802), (10, 0.05770428851246834), (8, 0.061053783632814884), (13, 0.06190174678340554), (52, 0.0663185017183423), (12, 0.06688237842172384), (11, 0.07051664311438799), (9, 0.07433958817273378), (36, 0.27165884152054787), (18, 0.4174952805042267), (53, 1.0952588468790054)]
computing accuracy for after removing block 43 . block score: 0.026705472031608224
removed block 43 current accuracy 0.9542 loss from initial  0.04579999999999995
since last training loss: 0.0401999999999999 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 37, with score 0.028558. All blocks and scores: [(37, 0.02855815226212144), (40, 0.028668009908869863), (17, 0.02943941648118198), (51, 0.03709517326205969), (48, 0.03800470009446144), (46, 0.039145768620073795), (20, 0.0414082114584744), (21, 0.04298066068440676), (16, 0.044092902448028326), (0, 0.04458149801939726), (15, 0.04643995268270373), (19, 0.047612186055630445), (6, 0.04797197598963976), (4, 0.04838766297325492), (7, 0.048844870645552874), (10, 0.057704288978129625), (8, 0.06105378223583102), (13, 0.06190174724906683), (52, 0.0640510399825871), (12, 0.06688237842172384), (11, 0.07051664311438799), (9, 0.07433958444744349), (36, 0.27165884524583817), (18, 0.4174952879548073), (53, 1.2815492004156113)]
computing accuracy for after removing block 37 . block score: 0.02855815226212144
removed block 37 current accuracy 0.9328 loss from initial  0.06720000000000004
since last training loss: 0.06159999999999999 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 17, with score 0.029439. All blocks and scores: [(17, 0.029439416015520692), (40, 0.03344095824286342), (51, 0.03521294239908457), (48, 0.03724933648481965), (46, 0.04078497551381588), (20, 0.04140821285545826), (21, 0.04298065975308418), (16, 0.044092902448028326), (0, 0.044581498485058546), (15, 0.046439952217042446), (19, 0.047612184658646584), (6, 0.04797197738662362), (4, 0.04838766297325492), (7, 0.04884487111121416), (10, 0.05770428664982319), (52, 0.06064724223688245), (8, 0.06105378223583102), (13, 0.06190174864605069), (12, 0.06688237935304642), (11, 0.07051664497703314), (9, 0.07433958724141121), (36, 0.27165885269641876), (18, 0.4174952879548073), (53, 1.2782227993011475)]
computing accuracy for after removing block 17 . block score: 0.029439416015520692
removed block 17 current accuracy 0.9298 loss from initial  0.07020000000000004
since last training loss: 0.06459999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.032136. All blocks and scores: [(40, 0.032136380672454834), (51, 0.033187683671712875), (48, 0.036484189331531525), (20, 0.038520639296621084), (46, 0.04038294730708003), (21, 0.04164040833711624), (16, 0.04409290384501219), (0, 0.04458149895071983), (15, 0.04643995268270373), (19, 0.04781318875029683), (6, 0.04797197552397847), (4, 0.04838766250759363), (7, 0.04884487157687545), (10, 0.05770428758114576), (52, 0.05904874810948968), (8, 0.061053781770169735), (13, 0.061901749577373266), (12, 0.06688237842172384), (11, 0.07051664404571056), (9, 0.07433958444744349), (36, 0.26345140114426613), (18, 0.4040554091334343), (53, 1.258207231760025)]
computing accuracy for after removing block 40 . block score: 0.032136380672454834
removed block 40 current accuracy 0.8798 loss from initial  0.12019999999999997
since last training loss: 0.11459999999999992 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.034002. All blocks and scores: [(51, 0.034002264495939016), (20, 0.038520639296621084), (48, 0.039109965320676565), (21, 0.04164040880277753), (16, 0.044092902448028326), (0, 0.04458149895071983), (46, 0.04610594594851136), (15, 0.04643995268270373), (19, 0.047813189681619406), (6, 0.047971976455301046), (4, 0.04838766157627106), (7, 0.04884487157687545), (10, 0.05770428851246834), (52, 0.058811808936297894), (8, 0.06105378223583102), (13, 0.061901746317744255), (12, 0.06688237935304642), (11, 0.07051664311438799), (9, 0.07433958817273378), (36, 0.2634514085948467), (18, 0.404055405408144), (53, 1.3297807723283768)]
computing accuracy for after removing block 51 . block score: 0.034002264495939016
removed block 51 current accuracy 0.8002 loss from initial  0.19979999999999998
since last training loss: 0.19419999999999993 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 20, with score 0.038521. All blocks and scores: [(20, 0.03852063976228237), (48, 0.03910996485501528), (21, 0.041640407871454954), (16, 0.04409290291368961), (0, 0.04458149801939726), (46, 0.04610594781115651), (15, 0.04643995175138116), (19, 0.04781318688765168), (6, 0.04797197738662362), (4, 0.048387662041932344), (7, 0.048844870645552874), (10, 0.0577042861841619), (8, 0.0610537831671536), (13, 0.06190174724906683), (12, 0.06688237842172384), (52, 0.06873003207147121), (11, 0.07051664311438799), (9, 0.07433958537876606), (36, 0.2634514048695564), (18, 0.4040554203093052), (53, 1.6809466481208801)]
computing accuracy for after removing block 20 . block score: 0.03852063976228237
removed block 20 current accuracy 0.7538 loss from initial  0.24619999999999997
since last training loss: 0.24059999999999993 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 48, with score 0.036022. All blocks and scores: [(48, 0.03602195577695966), (21, 0.04243833804503083), (46, 0.043769064359366894), (16, 0.0440929033793509), (0, 0.044581497088074684), (15, 0.04643995175138116), (19, 0.047813189681619406), (6, 0.047971976455301046), (4, 0.048387662041932344), (7, 0.048844872042536736), (10, 0.057704288978129625), (8, 0.06105378270149231), (13, 0.06190174911171198), (52, 0.06447621248662472), (12, 0.06688237842172384), (11, 0.07051664497703314), (9, 0.07433958444744349), (36, 0.25690897181630135), (18, 0.4040554203093052), (53, 1.7793262302875519)]
computing accuracy for after removing block 48 . block score: 0.03602195577695966
removed block 48 current accuracy 0.6352 loss from initial  0.3648
since last training loss: 0.35919999999999996 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 21, with score 0.042438. All blocks and scores: [(21, 0.04243833851069212), (46, 0.04376906529068947), (16, 0.044092901051044464), (0, 0.044581500347703695), (15, 0.04643995361402631), (19, 0.047813187818974257), (6, 0.047971976455301046), (4, 0.048387662041932344), (7, 0.04884487297385931), (10, 0.05770428758114576), (8, 0.061053781770169735), (13, 0.06190174911171198), (12, 0.06688237749040127), (52, 0.06750259641557932), (11, 0.07051664497703314), (9, 0.07433958631008863), (36, 0.25690897181630135), (18, 0.4040554165840149), (53, 2.297981172800064)]
computing accuracy for after removing block 21 . block score: 0.04243833851069212
removed block 21 current accuracy 0.5462 loss from initial  0.4538
since last training loss: 0.44819999999999993 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 46, with score 0.040751. All blocks and scores: [(46, 0.040750791784375906), (16, 0.0440929033793509), (0, 0.04458149895071983), (15, 0.04643995268270373), (19, 0.047813189681619406), (6, 0.04797197552397847), (4, 0.048387663904577494), (7, 0.048844872042536736), (10, 0.0577042861841619), (8, 0.06105378223583102), (13, 0.061901748180389404), (52, 0.06482717394828796), (12, 0.06688237842172384), (11, 0.07051664311438799), (9, 0.07433958817273378), (36, 0.24651207402348518), (18, 0.4040554240345955), (53, 2.3834546208381653)]
computing accuracy for after removing block 46 . block score: 0.040750791784375906
removed block 46 current accuracy 0.424 loss from initial  0.5760000000000001
since last training loss: 0.5704 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 16, with score 0.044093. All blocks and scores: [(16, 0.0440929033793509), (0, 0.04458149801939726), (15, 0.046439952217042446), (19, 0.04781318921595812), (6, 0.04797197738662362), (4, 0.04838766297325492), (7, 0.04884487297385931), (10, 0.05770428664982319), (8, 0.061053783632814884), (13, 0.06190174771472812), (12, 0.06688238028436899), (52, 0.06927268579602242), (11, 0.07051664497703314), (9, 0.07433958537876606), (36, 0.24651206843554974), (18, 0.4040554128587246), (53, 2.901205748319626)]
computing accuracy for after removing block 16 . block score: 0.0440929033793509
removed block 16 current accuracy 0.3804 loss from initial  0.6195999999999999
since last training loss: 0.6139999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 0, with score 0.044581. All blocks and scores: [(0, 0.04458149755373597), (15, 0.046439950820058584), (6, 0.04797197738662362), (4, 0.048387662041932344), (7, 0.04884487250819802), (19, 0.05039398605003953), (10, 0.05770428758114576), (8, 0.06105378223583102), (13, 0.06190174724906683), (12, 0.06688237749040127), (52, 0.06837867852300406), (11, 0.07051664497703314), (9, 0.07433958631008863), (36, 0.24435300938785076), (18, 0.39461799710989), (53, 2.8599656522274017)]
computing accuracy for after removing block 0 . block score: 0.04458149755373597
removed block 0 current accuracy 0.3634 loss from initial  0.6366
training start
training epoch 0 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best True lr [0.001]
training epoch 1 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.001]
training epoch 2 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.001]
training epoch 4 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.001]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 6 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.001]
training epoch 7 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 8 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 9 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.001]
training epoch 10 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 11 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 12 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 13 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 14 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 15 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 16 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 17 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 18 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 19 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 20 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 21 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 22 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 23 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 24 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 25 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 26 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 27 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 28 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 29 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 31 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 32 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 33 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 34 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 35 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 37 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 39 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 40 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 41 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 42 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 43 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 44 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 45 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 46 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 47 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 48 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 49 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.932000)
finished training. finished 50 epochs. accuracy 0.932 topk_dict {'top1': 0.932}
