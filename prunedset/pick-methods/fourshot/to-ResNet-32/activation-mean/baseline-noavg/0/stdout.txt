start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055875. All blocks and scores: [(22, 0.055874861776828766), (24, 0.06177143566310406), (21, 0.06496669724583626), (25, 0.06539816409349442), (27, 0.07151609845459461), (20, 0.0722665935754776), (35, 0.07411019410938025), (30, 0.07556094694882631), (23, 0.07561394572257996), (32, 0.07979130558669567), (29, 0.08450872916728258), (31, 0.08690572716295719), (26, 0.08848298899829388), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09050499927252531), (33, 0.10334126185625792), (34, 0.10430913046002388), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14227986335754395), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15326451510190964), (38, 0.16421835497021675), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.1724428366869688), (41, 0.17542804032564163), (42, 0.1755864955484867), (44, 0.18015791475772858), (10, 0.1813554372638464), (4, 0.18203354813158512), (45, 0.18489503115415573), (43, 0.19027204811573029), (46, 0.19319169037044048), (47, 0.20808524079620838), (48, 0.2123200260102749), (9, 0.21280715242028236), (49, 0.214156249538064), (50, 0.22060429491102695), (51, 0.24123229831457138), (17, 0.2635997086763382), (52, 0.2748573273420334), (18, 0.35712291300296783), (36, 0.47951839864254), (53, 0.6427939906716347)]
computing accuracy for after removing block 22 . block score: 0.055874861776828766
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063728. All blocks and scores: [(24, 0.06372843217104673), (21, 0.06496669724583626), (25, 0.06680801045149565), (27, 0.07130979653447866), (20, 0.0722665935754776), (35, 0.07429851219058037), (30, 0.07568530179560184), (23, 0.07636885344982147), (32, 0.07971580140292645), (29, 0.08468191791325808), (31, 0.08691531326621771), (5, 0.08888446353375912), (3, 0.09012125711888075), (26, 0.09025377035140991), (19, 0.09047461114823818), (28, 0.09172139409929514), (33, 0.10357575863599777), (34, 0.10437646694481373), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14291350357234478), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15452100336551666), (11, 0.1649541687220335), (38, 0.16498222388327122), (2, 0.16567634418606758), (40, 0.17307638376951218), (41, 0.17614571005105972), (42, 0.1761545743793249), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.1824799831956625), (45, 0.18450302816927433), (43, 0.19050214625895023), (46, 0.19372878782451153), (47, 0.20627203024923801), (48, 0.2120207268744707), (9, 0.21280715242028236), (49, 0.2143655065447092), (50, 0.22066733054816723), (51, 0.2409748863428831), (17, 0.2635997086763382), (52, 0.27451441809535027), (18, 0.35712291300296783), (36, 0.48188556358218193), (53, 0.6410739421844482)]
computing accuracy for after removing block 24 . block score: 0.06372843217104673
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.064967. All blocks and scores: [(21, 0.06496669724583626), (25, 0.06703743990510702), (27, 0.07013737596571445), (20, 0.0722665935754776), (35, 0.07342808321118355), (30, 0.07471412140876055), (23, 0.07636885344982147), (32, 0.07861070893704891), (29, 0.08317314926534891), (31, 0.08625906892120838), (5, 0.08888446353375912), (26, 0.08973303623497486), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09168458171188831), (34, 0.10268995817750692), (33, 0.10318366531282663), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14301974326372147), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1552681177854538), (38, 0.16453734785318375), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.17422636039555073), (41, 0.17607183754444122), (42, 0.17612144351005554), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18264964036643505), (45, 0.18367482721805573), (43, 0.1899556815624237), (46, 0.19336611777544022), (47, 0.20545421540737152), (48, 0.21146412566304207), (9, 0.21280715242028236), (49, 0.21425769478082657), (50, 0.21967321634292603), (51, 0.2403922826051712), (17, 0.2635997086763382), (52, 0.2743810787796974), (18, 0.35712291300296783), (36, 0.4825970157980919), (53, 0.6408330947160721)]
computing accuracy for after removing block 21 . block score: 0.06496669724583626
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068154. All blocks and scores: [(25, 0.06815383676439524), (27, 0.06980223208665848), (20, 0.0722665935754776), (35, 0.07353036105632782), (30, 0.07382607832551003), (23, 0.0764246741309762), (32, 0.07829320430755615), (29, 0.08308697119355202), (31, 0.08602661546319723), (5, 0.08888446353375912), (26, 0.08915798645466566), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09211605414748192), (34, 0.10230127815157175), (33, 0.10312568210065365), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14325005002319813), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1557087078690529), (38, 0.1647000703960657), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.1755049880594015), (41, 0.17610502615571022), (42, 0.17631095461547375), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18253245949745178), (45, 0.18302420526742935), (43, 0.19044085033237934), (46, 0.19308597594499588), (47, 0.20481226220726967), (48, 0.21083582006394863), (9, 0.21280715242028236), (49, 0.21393285878002644), (50, 0.21925617940723896), (51, 0.23967960476875305), (17, 0.2635997086763382), (52, 0.273654505610466), (18, 0.35712291300296783), (36, 0.48382943123579025), (53, 0.639979712665081)]
computing accuracy for after removing block 25 . block score: 0.06815383676439524
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068811. All blocks and scores: [(27, 0.06881092954427004), (20, 0.0722665935754776), (35, 0.07253072131425142), (30, 0.0731162941083312), (23, 0.0764246741309762), (32, 0.07713543437421322), (29, 0.08107472397387028), (31, 0.08513766340911388), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09101575054228306), (34, 0.10053910687565804), (33, 0.10205675661563873), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14211287535727024), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1547116171568632), (38, 0.1637822836637497), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.1742816288024187), (42, 0.1750345081090927), (40, 0.17540869303047657), (45, 0.18085969612002373), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18211421370506287), (43, 0.18795999139547348), (46, 0.191400196403265), (47, 0.2023499310016632), (48, 0.20854505337774754), (49, 0.21236556582152843), (9, 0.21280715242028236), (50, 0.21730931103229523), (51, 0.23744945600628853), (17, 0.2635997086763382), (52, 0.2733411490917206), (18, 0.35712291300296783), (36, 0.48273831978440285), (53, 0.6374414563179016)]
computing accuracy for after removing block 27 . block score: 0.06881092954427004
removed block 27 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072124. All blocks and scores: [(35, 0.0721236327663064), (20, 0.0722665935754776), (30, 0.07257708720862865), (23, 0.0764246741309762), (32, 0.07654038444161415), (29, 0.08117466047406197), (31, 0.08459337707608938), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09207288548350334), (34, 0.10011614393442869), (33, 0.10208251420408487), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14123038575053215), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1535331755876541), (38, 0.16272037848830223), (11, 0.1649541687220335), (2, 0.16567634418606758), (42, 0.174275454133749), (41, 0.17455543763935566), (40, 0.17537744157016277), (45, 0.17959223687648773), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18369055725634098), (43, 0.18725652806460857), (46, 0.19005939364433289), (47, 0.20008372515439987), (48, 0.20726387202739716), (49, 0.21192682161927223), (9, 0.21280715242028236), (50, 0.21623316779732704), (51, 0.23535941168665886), (17, 0.2635997086763382), (52, 0.2723398506641388), (18, 0.35712291300296783), (36, 0.4819323644042015), (53, 0.6367765739560127)]
computing accuracy for after removing block 35 . block score: 0.0721236327663064
removed block 35 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 20, with score 0.072267. All blocks and scores: [(20, 0.0722665935754776), (30, 0.07257708720862865), (23, 0.0764246741309762), (32, 0.07654038444161415), (29, 0.08117466047406197), (31, 0.08459337707608938), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09207288548350334), (34, 0.10011614393442869), (33, 0.10208251420408487), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.13975277356803417), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15266877226531506), (38, 0.1587308645248413), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17313233949244022), (40, 0.1735091581940651), (42, 0.17351526394486427), (45, 0.17846908420324326), (10, 0.1813554372638464), (44, 0.18180529214441776), (4, 0.18203354813158512), (43, 0.18466809391975403), (46, 0.18799381330609322), (47, 0.1981325838714838), (48, 0.20550396665930748), (49, 0.21049201861023903), (9, 0.21280715242028236), (50, 0.21590297669172287), (51, 0.2348758615553379), (17, 0.2635997086763382), (52, 0.2719504348933697), (18, 0.35712291300296783), (36, 0.48112449422478676), (53, 0.6373795047402382)]
computing accuracy for after removing block 20 . block score: 0.0722665935754776
removed block 20 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 30, with score 0.072471. All blocks and scores: [(30, 0.07247117161750793), (32, 0.07625227980315685), (23, 0.07768272049725056), (29, 0.08184758014976978), (31, 0.0846198545768857), (26, 0.08804163243621588), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.0922315837815404), (34, 0.10024414770305157), (33, 0.10323962476104498), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.1393482480198145), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15060056559741497), (38, 0.15361598692834377), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17073342762887478), (42, 0.1711448933929205), (45, 0.1738788615912199), (40, 0.1745755597949028), (44, 0.17893094941973686), (10, 0.1813554372638464), (4, 0.18203354813158512), (43, 0.18250644207000732), (46, 0.18323267064988613), (47, 0.1950262486934662), (48, 0.2035509143024683), (49, 0.20875819958746433), (9, 0.21280715242028236), (50, 0.21497691608965397), (51, 0.23172142542898655), (17, 0.2635997086763382), (52, 0.26927676796913147), (18, 0.35712291300296783), (36, 0.4742658771574497), (53, 0.6354397609829903)]
computing accuracy for after removing block 30 . block score: 0.07247117161750793
removed block 30 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.075761. All blocks and scores: [(32, 0.0757605042308569), (23, 0.07768272049725056), (29, 0.08184758014976978), (31, 0.08484559506177902), (26, 0.08804163243621588), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.0922315837815404), (34, 0.09961904678493738), (33, 0.10478989686816931), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.13780422136187553), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1513042040169239), (38, 0.1537246610969305), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17053041607141495), (42, 0.17157302983105183), (45, 0.17264624871313572), (40, 0.17659500427544117), (44, 0.1804590057581663), (10, 0.1813554372638464), (43, 0.18187697976827621), (4, 0.18203354813158512), (46, 0.18318604677915573), (47, 0.1952302400022745), (48, 0.20398801378905773), (49, 0.20897031389176846), (9, 0.21280715242028236), (50, 0.21466458588838577), (51, 0.23112696781754494), (17, 0.2635997086763382), (52, 0.2684929072856903), (18, 0.35712291300296783), (36, 0.4795118235051632), (53, 0.6385306268930435)]
computing accuracy for after removing block 32 . block score: 0.0757605042308569
removed block 32 current accuracy 0.9868 loss from initial  0.01319999999999999
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 9 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.087801. All blocks and scores: [(23, 0.08780128508806229), (5, 0.08904614672064781), (3, 0.09098684880882502), (29, 0.09181752987205982), (19, 0.09232042729854584), (31, 0.09625126328319311), (26, 0.09768555406481028), (28, 0.09980935323983431), (34, 0.10722140595316887), (33, 0.10942963697016239), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12975254841148853), (6, 0.13181956484913826), (13, 0.13579700328409672), (15, 0.14020589366555214), (14, 0.1402151808142662), (37, 0.14146077446639538), (7, 0.14434226974844933), (12, 0.14578793197870255), (8, 0.1467937808483839), (39, 0.1519546639174223), (38, 0.16335581243038177), (11, 0.1651626881211996), (2, 0.16641254350543022), (40, 0.17256920598447323), (42, 0.1750847939401865), (41, 0.17563194036483765), (44, 0.1796863041818142), (10, 0.18096136301755905), (4, 0.18298799358308315), (45, 0.18451311998069286), (43, 0.18922209180891514), (46, 0.19382390193641186), (47, 0.20578632317483425), (9, 0.2105638775974512), (48, 0.21260069869458675), (49, 0.2145578097552061), (50, 0.22138126008212566), (51, 0.24052723683416843), (17, 0.26474663615226746), (52, 0.27620354294776917), (18, 0.35550206899642944), (36, 0.4775117076933384), (53, 0.6307614892721176)]
computing accuracy for after removing block 23 . block score: 0.08780128508806229
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 5, with score 0.089046. All blocks and scores: [(5, 0.08904614672064781), (3, 0.09098684880882502), (29, 0.09175579808652401), (19, 0.09232042729854584), (31, 0.09505765605717897), (26, 0.0967023242264986), (28, 0.09952443838119507), (34, 0.10548484232276678), (33, 0.11022950150072575), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12975254841148853), (6, 0.13181956484913826), (13, 0.13579700328409672), (15, 0.14020589366555214), (14, 0.1402151808142662), (37, 0.14270120486617088), (7, 0.14434226974844933), (12, 0.14578793197870255), (8, 0.1467937808483839), (39, 0.15401074662804604), (38, 0.16415312886238098), (11, 0.1651626881211996), (2, 0.16641254350543022), (42, 0.17481426149606705), (40, 0.1749783605337143), (41, 0.1749890949577093), (44, 0.17898207157850266), (10, 0.18096136301755905), (45, 0.18239179998636246), (4, 0.18298799358308315), (43, 0.18810286931693554), (46, 0.19300418347120285), (47, 0.2042485699057579), (9, 0.2105638775974512), (48, 0.21133529022336006), (49, 0.21365747414529324), (50, 0.22016232833266258), (51, 0.23901156708598137), (17, 0.26474663615226746), (52, 0.27518998831510544), (18, 0.35550206899642944), (36, 0.4796331003308296), (53, 0.6277319118380547)]
computing accuracy for after removing block 5 . block score: 0.08904614672064781
removed block 5 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 3, with score 0.090987. All blocks and scores: [(3, 0.09098684880882502), (29, 0.09125984739512205), (19, 0.09249560907483101), (31, 0.09503578301519156), (26, 0.09593140799552202), (28, 0.09958950895816088), (34, 0.10638169106096029), (33, 0.10962802078574896), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12904834933578968), (6, 0.13372013345360756), (13, 0.1359829679131508), (14, 0.14020785316824913), (15, 0.140340069308877), (37, 0.14406169392168522), (7, 0.14546737261116505), (8, 0.1482705995440483), (12, 0.14832851849496365), (39, 0.15300661325454712), (38, 0.16165516152977943), (2, 0.16641254350543022), (11, 0.1672646515071392), (41, 0.1745244823396206), (42, 0.1751826349645853), (40, 0.1760279256850481), (44, 0.17788357101380825), (45, 0.18201886676251888), (4, 0.18298799358308315), (10, 0.18451852910220623), (43, 0.1883238796144724), (46, 0.19245541654527187), (47, 0.2032919805496931), (48, 0.21065820194780827), (49, 0.21418869122862816), (9, 0.21639191545546055), (50, 0.2192607969045639), (51, 0.2386399582028389), (17, 0.2626512423157692), (52, 0.27439796552062035), (18, 0.3543265089392662), (36, 0.47768372669816017), (53, 0.6282552853226662)]
computing accuracy for after removing block 3 . block score: 0.09098684880882502
removed block 3 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 29, with score 0.090734. All blocks and scores: [(29, 0.0907342592254281), (19, 0.0921055730432272), (31, 0.09439610969275236), (26, 0.0946900537237525), (28, 0.0991414487361908), (34, 0.10665855091065168), (33, 0.10883587505668402), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (15, 0.13948817923665047), (7, 0.14756551757454872), (37, 0.1485784947872162), (8, 0.14869350008666515), (12, 0.15121234953403473), (39, 0.151548333466053), (38, 0.15696541219949722), (2, 0.16641254350543022), (11, 0.1671526525169611), (41, 0.1751372292637825), (44, 0.17652190662920475), (42, 0.17676612362265587), (40, 0.18114513158798218), (45, 0.18269549496471882), (4, 0.18622072413563728), (10, 0.18670866452157497), (43, 0.1906053051352501), (46, 0.19390516355633736), (47, 0.20194964855909348), (48, 0.21028007566928864), (49, 0.21688773855566978), (50, 0.21815762110054493), (9, 0.2253690492361784), (51, 0.2388491965830326), (17, 0.26351264119148254), (52, 0.2724184952676296), (18, 0.3531390652060509), (36, 0.4794042147696018), (53, 0.6291842758655548)]
computing accuracy for after removing block 29 . block score: 0.0907342592254281
removed block 29 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.092106. All blocks and scores: [(19, 0.0921055730432272), (31, 0.09356064721941948), (26, 0.0946900537237525), (28, 0.0991414487361908), (34, 0.10602083336561918), (33, 0.10956683102995157), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (15, 0.13948817923665047), (37, 0.14582695625722408), (7, 0.14756551757454872), (8, 0.14869350008666515), (12, 0.15121234953403473), (39, 0.15144474618136883), (38, 0.15471970848739147), (2, 0.16641254350543022), (11, 0.1671526525169611), (41, 0.17249578796327114), (42, 0.17683094926178455), (44, 0.17744595743715763), (45, 0.1806699801236391), (40, 0.18118858337402344), (4, 0.18622072413563728), (10, 0.18670866452157497), (43, 0.18898707069456577), (46, 0.1915733404457569), (47, 0.19899669289588928), (48, 0.2077577281743288), (49, 0.21638868562877178), (50, 0.2166387438774109), (9, 0.2253690492361784), (51, 0.2355656810104847), (17, 0.26351264119148254), (52, 0.27115054801106453), (18, 0.3531390652060509), (36, 0.4793187417089939), (53, 0.6305636316537857)]
computing accuracy for after removing block 19 . block score: 0.0921055730432272
removed block 19 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.092707. All blocks and scores: [(31, 0.09270715620368719), (26, 0.09549852553755045), (28, 0.1004868783056736), (34, 0.10616243164986372), (33, 0.11073180101811886), (1, 0.11472985707223415), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (15, 0.13948817923665047), (37, 0.14646950736641884), (7, 0.14756551757454872), (8, 0.14869350008666515), (39, 0.1499436218291521), (12, 0.15121234953403473), (38, 0.1521920207887888), (2, 0.16641254350543022), (11, 0.1671526525169611), (41, 0.17096634022891521), (44, 0.17348880879580975), (42, 0.17518962360918522), (45, 0.17799303494393826), (40, 0.18174328096210957), (4, 0.18622072413563728), (43, 0.18639126233756542), (10, 0.18670866452157497), (46, 0.18794074095785618), (47, 0.19649419002234936), (48, 0.20478007569909096), (49, 0.21366824209690094), (50, 0.21513057127594948), (9, 0.2253690492361784), (51, 0.2330891750752926), (17, 0.26351264119148254), (52, 0.26948609203100204), (18, 0.3531390652060509), (36, 0.4750896841287613), (53, 0.6318314969539642)]
computing accuracy for after removing block 31 . block score: 0.09270715620368719
removed block 31 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 26, with score 0.095499. All blocks and scores: [(26, 0.09549852553755045), (28, 0.1004868783056736), (34, 0.10625874437391758), (1, 0.11472985707223415), (33, 0.11496048234403133), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (15, 0.13948817923665047), (37, 0.1444993782788515), (7, 0.14756551757454872), (8, 0.14869350008666515), (38, 0.14994684047996998), (39, 0.1503647044301033), (12, 0.15121234953403473), (2, 0.16641254350543022), (11, 0.1671526525169611), (41, 0.1706414893269539), (42, 0.17474038526415825), (44, 0.17504474334418774), (45, 0.17698671109974384), (40, 0.18418835662305355), (43, 0.18560334108769894), (4, 0.18622072413563728), (10, 0.18670866452157497), (46, 0.18804394081234932), (47, 0.1959008164703846), (48, 0.20479105785489082), (49, 0.213787280023098), (50, 0.21511533297598362), (9, 0.2253690492361784), (51, 0.2315580602735281), (17, 0.26351264119148254), (52, 0.2684986814856529), (18, 0.3531390652060509), (36, 0.48294851183891296), (53, 0.6358757019042969)]
computing accuracy for after removing block 26 . block score: 0.09549852553755045
removed block 26 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 34, with score 0.103238. All blocks and scores: [(34, 0.10323833487927914), (28, 0.10380835086107254), (1, 0.11472985707223415), (33, 0.11474687699228525), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (15, 0.13948817923665047), (37, 0.14121885411441326), (38, 0.14627524837851524), (7, 0.14756551757454872), (39, 0.148191025480628), (8, 0.14869350008666515), (12, 0.15121234953403473), (2, 0.16641254350543022), (11, 0.1671526525169611), (41, 0.167374262586236), (45, 0.17233874835073948), (42, 0.17252416536211967), (44, 0.17357969842851162), (43, 0.1816034372895956), (46, 0.18328835628926754), (40, 0.18333011493086815), (4, 0.18622072413563728), (10, 0.18670866452157497), (47, 0.19301499612629414), (48, 0.20119647309184074), (49, 0.21104084327816963), (50, 0.2131497859954834), (9, 0.2253690492361784), (51, 0.2275230549275875), (17, 0.26351264119148254), (52, 0.26603373140096664), (18, 0.3531390652060509), (36, 0.4790366105735302), (53, 0.6358276307582855)]
computing accuracy for after removing block 34 . block score: 0.10323833487927914
removed block 34 current accuracy 0.9678 loss from initial  0.032200000000000006
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 28, with score 0.103808. All blocks and scores: [(28, 0.10380835086107254), (1, 0.11472985707223415), (33, 0.11474687699228525), (0, 0.1261757742613554), (16, 0.12766189500689507), (13, 0.13177755661308765), (6, 0.13261299394071102), (14, 0.1339528150856495), (37, 0.13769094459712505), (15, 0.13948817923665047), (38, 0.14322445914149284), (7, 0.14756551757454872), (8, 0.14869350008666515), (12, 0.15121234953403473), (39, 0.15156038291752338), (41, 0.16516141407191753), (2, 0.16641254350543022), (11, 0.1671526525169611), (45, 0.17003027349710464), (42, 0.17176377959549427), (44, 0.1773417443037033), (43, 0.17996639013290405), (46, 0.18204173259437084), (40, 0.18350357376039028), (4, 0.18622072413563728), (10, 0.18670866452157497), (47, 0.19334212690591812), (48, 0.2022403609007597), (49, 0.21135223656892776), (50, 0.21312502212822437), (51, 0.22401793859899044), (9, 0.2253690492361784), (52, 0.2632739394903183), (17, 0.26351264119148254), (18, 0.3531390652060509), (36, 0.4940502755343914), (53, 0.6378767192363739)]
computing accuracy for after removing block 28 . block score: 0.10380835086107254
removed block 28 current accuracy 0.9494 loss from initial  0.05059999999999998
training start
training epoch 0 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 1 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 2 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 4 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 5 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 6 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 7 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 8 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 9 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 10 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 11 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 14 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 15 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 16 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 18 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 19 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 20 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 21 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 23 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 24 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 25 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 26 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 27 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 29 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 32 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 33 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 34 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 35 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 36 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 37 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 38 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 39 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 41 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 42 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 44 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 45 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 47 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 48 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 49 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
loading model_best from epoch 16 (acc 0.998200)
finished training. finished 50 epochs. accuracy 0.9982 topk_dict {'top1': 0.9982}
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.123305. All blocks and scores: [(1, 0.12330475263297558), (0, 0.12688691541552544), (16, 0.12749157287180424), (13, 0.13247918710112572), (6, 0.1362759042531252), (14, 0.1392042115330696), (33, 0.1415708139538765), (15, 0.1422223299741745), (37, 0.14364092238247395), (7, 0.1455628853291273), (12, 0.14587596617639065), (8, 0.14831879176199436), (39, 0.14973784051835537), (38, 0.15929929912090302), (11, 0.16330939158797264), (40, 0.1699847485870123), (2, 0.17110075242817402), (41, 0.17352869361639023), (42, 0.1738714575767517), (44, 0.17842851765453815), (45, 0.1804914679378271), (10, 0.18067139200866222), (43, 0.18555237725377083), (4, 0.18572144210338593), (46, 0.1908650379627943), (47, 0.20292620919644833), (48, 0.21047699823975563), (49, 0.21224794164299965), (9, 0.2130139395594597), (50, 0.21904649026691914), (51, 0.2388671226799488), (17, 0.25721344724297523), (52, 0.27422284707427025), (18, 0.35553278028964996), (36, 0.4787488654255867), (53, 0.6385361328721046)]
computing accuracy for after removing block 1 . block score: 0.12330475263297558
removed block 1 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 16, with score 0.126590. All blocks and scores: [(16, 0.126590421423316), (0, 0.12688691541552544), (13, 0.12976635806262493), (6, 0.13424229621887207), (14, 0.1364480908960104), (15, 0.13956748135387897), (33, 0.14059691689908504), (12, 0.14429124258458614), (8, 0.14674250595271587), (7, 0.14801839739084244), (39, 0.14937937073409557), (37, 0.15034905262291431), (38, 0.15283753722906113), (11, 0.16300959326326847), (41, 0.1746382936835289), (42, 0.17625118419528008), (40, 0.1765500269830227), (2, 0.1772870048880577), (44, 0.1773554440587759), (45, 0.18223588354885578), (10, 0.18264711275696754), (43, 0.18879800476133823), (4, 0.1891503892838955), (46, 0.19329999946057796), (47, 0.20321219228208065), (9, 0.2112266570329666), (48, 0.21209165453910828), (49, 0.2163080181926489), (50, 0.21923857182264328), (51, 0.24058395065367222), (17, 0.2593132220208645), (52, 0.2730450816452503), (18, 0.3561541177332401), (36, 0.481613464653492), (53, 0.638813428580761)]
computing accuracy for after removing block 16 . block score: 0.126590421423316
removed block 16 current accuracy 0.9916 loss from initial  0.008399999999999963
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 0, with score 0.126887. All blocks and scores: [(0, 0.12688691541552544), (13, 0.12976635806262493), (6, 0.13424229621887207), (14, 0.1364480908960104), (15, 0.13956748135387897), (33, 0.141299057751894), (12, 0.14429124258458614), (38, 0.14623073115944862), (8, 0.14674250595271587), (39, 0.14768579229712486), (7, 0.14801839739084244), (37, 0.15450532734394073), (11, 0.16300959326326847), (44, 0.16960584931075573), (41, 0.17348118871450424), (42, 0.17426312901079655), (40, 0.17465008422732353), (2, 0.1772870048880577), (10, 0.18264711275696754), (45, 0.18431368842720985), (46, 0.18886836245656013), (4, 0.1891503892838955), (43, 0.1896179299801588), (47, 0.1990817729383707), (48, 0.2107578031718731), (49, 0.21116475574672222), (9, 0.2112266570329666), (50, 0.21554412879049778), (17, 0.23159412667155266), (51, 0.2411196492612362), (52, 0.2689785547554493), (18, 0.34862880781292915), (36, 0.4761062525212765), (53, 0.6531943306326866)]
computing accuracy for after removing block 0 . block score: 0.12688691541552544
removed block 0 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.054200000000000026 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.123142. All blocks and scores: [(13, 0.12314219120889902), (14, 0.12704236432909966), (6, 0.12968084029853344), (15, 0.13241875916719437), (38, 0.13419766165316105), (33, 0.13718026876449585), (8, 0.13943463563919067), (39, 0.1420773696154356), (12, 0.14346331544220448), (7, 0.15227149613201618), (11, 0.16069255024194717), (44, 0.161057835444808), (37, 0.16466013714671135), (41, 0.17094174213707447), (42, 0.1733539942651987), (40, 0.17892470583319664), (2, 0.18232963606715202), (45, 0.18307829089462757), (10, 0.1868219431489706), (46, 0.18847843445837498), (47, 0.19230268150568008), (43, 0.1933115478605032), (4, 0.1977837849408388), (48, 0.20525297708809376), (50, 0.20825372822582722), (9, 0.20985183119773865), (49, 0.21082619950175285), (17, 0.2294710222631693), (51, 0.23841825313866138), (52, 0.2592346742749214), (18, 0.3425118625164032), (36, 0.4783983938395977), (53, 0.6584486663341522)]
computing accuracy for after removing block 13 . block score: 0.12314219120889902
removed block 13 current accuracy 0.925 loss from initial  0.07499999999999996
since last training loss: 0.07319999999999993 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 6, with score 0.129681. All blocks and scores: [(6, 0.12968084029853344), (38, 0.13034124486148357), (15, 0.1323324255645275), (14, 0.13342179358005524), (33, 0.13570093922317028), (8, 0.13943463563919067), (39, 0.1414925679564476), (12, 0.14346331544220448), (7, 0.15227149613201618), (44, 0.1542062032967806), (11, 0.16069255024194717), (41, 0.1696621999144554), (37, 0.17021836899220943), (42, 0.172140808776021), (40, 0.1814381256699562), (2, 0.18232963606715202), (45, 0.18260258249938488), (46, 0.1849834006279707), (10, 0.1868219431489706), (47, 0.19244584254920483), (43, 0.1940380409359932), (4, 0.1977837849408388), (48, 0.20249958708882332), (50, 0.20480955205857754), (49, 0.20758524909615517), (9, 0.20985183119773865), (17, 0.22540953010320663), (51, 0.2372653279453516), (52, 0.25505954027175903), (18, 0.34154535830020905), (36, 0.4771781750023365), (53, 0.6629631519317627)]
computing accuracy for after removing block 6 . block score: 0.12968084029853344
removed block 6 current accuracy 0.9068 loss from initial  0.09319999999999995
since last training loss: 0.09139999999999993 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 38, with score 0.125778. All blocks and scores: [(38, 0.1257782308384776), (15, 0.13290805369615555), (33, 0.1333329938352108), (14, 0.13492990657687187), (39, 0.1386165488511324), (8, 0.14224555157124996), (12, 0.1472187228500843), (44, 0.15151915699243546), (7, 0.15383759699761868), (11, 0.1633926946669817), (41, 0.1670636683702469), (42, 0.1709744669497013), (37, 0.17344243079423904), (45, 0.1810362320393324), (40, 0.18132449127733707), (2, 0.18232963606715202), (46, 0.18370873853564262), (47, 0.18993474543094635), (10, 0.19284321926534176), (43, 0.19435122050344944), (4, 0.1977837849408388), (48, 0.1994644869118929), (50, 0.20170530676841736), (49, 0.20766464434564114), (9, 0.21626177616417408), (17, 0.22526745311915874), (51, 0.23501602560281754), (52, 0.25237699784338474), (18, 0.3397767096757889), (36, 0.4756338782608509), (53, 0.6637989208102226)]
computing accuracy for after removing block 38 . block score: 0.1257782308384776
removed block 38 current accuracy 0.8926 loss from initial  0.10740000000000005
since last training loss: 0.10560000000000003 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 15, with score 0.132908. All blocks and scores: [(15, 0.13290805369615555), (33, 0.1333329938352108), (14, 0.13492990657687187), (8, 0.14224555157124996), (39, 0.1442140955477953), (12, 0.1472187228500843), (44, 0.14807389304041862), (7, 0.15383759699761868), (11, 0.1633926946669817), (41, 0.16976058296859264), (42, 0.17129052989184856), (37, 0.17344243079423904), (45, 0.1767669189721346), (2, 0.18232963606715202), (46, 0.18315646797418594), (47, 0.18371811136603355), (40, 0.19052567519247532), (48, 0.19262230582535267), (10, 0.19284321926534176), (43, 0.19572694413363934), (4, 0.1977837849408388), (50, 0.1990108396857977), (49, 0.20280163548886776), (9, 0.21626177616417408), (17, 0.22526745311915874), (51, 0.23261216282844543), (52, 0.2500815633684397), (18, 0.3397767096757889), (36, 0.4756338782608509), (53, 0.6521322578191757)]
computing accuracy for after removing block 15 . block score: 0.13290805369615555
removed block 15 current accuracy 0.8468 loss from initial  0.1532
since last training loss: 0.15139999999999998 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 33, with score 0.128215. All blocks and scores: [(33, 0.12821474857628345), (14, 0.13492990657687187), (8, 0.14224555157124996), (44, 0.14445615001022816), (39, 0.145517872646451), (12, 0.1472187228500843), (7, 0.15383759699761868), (11, 0.1633926946669817), (42, 0.1664399765431881), (41, 0.1664696168154478), (45, 0.17493143863976002), (37, 0.18212580494582653), (2, 0.18232963606715202), (47, 0.18349196761846542), (46, 0.18581716530025005), (40, 0.18772640079259872), (43, 0.19202425330877304), (50, 0.1924382857978344), (10, 0.19284321926534176), (48, 0.19400053843855858), (4, 0.1977837849408388), (49, 0.2003415785729885), (9, 0.21626177616417408), (51, 0.22966530174016953), (52, 0.24528701789677143), (17, 0.2563079856336117), (18, 0.33283688500523567), (36, 0.48044271394610405), (53, 0.6514133736491203)]
computing accuracy for after removing block 33 . block score: 0.12821474857628345
removed block 33 current accuracy 0.8092 loss from initial  0.19079999999999997
since last training loss: 0.18899999999999995 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 14, with score 0.134930. All blocks and scores: [(14, 0.13492990657687187), (8, 0.14224555157124996), (44, 0.14357919059693813), (39, 0.147215086966753), (12, 0.1472187228500843), (7, 0.15383759699761868), (11, 0.1633926946669817), (42, 0.16534386202692986), (41, 0.1683408636599779), (45, 0.17438111267983913), (37, 0.1791272535920143), (2, 0.18232963606715202), (46, 0.18238160014152527), (47, 0.18664391711354256), (43, 0.1905153188854456), (50, 0.19103968143463135), (10, 0.19284321926534176), (48, 0.19582458026707172), (4, 0.1977837849408388), (40, 0.19820497371256351), (49, 0.20004943013191223), (9, 0.21626177616417408), (51, 0.22375485487282276), (52, 0.2431959416717291), (17, 0.2563079856336117), (18, 0.33283688500523567), (36, 0.5046906173229218), (53, 0.6714739724993706)]
computing accuracy for after removing block 14 . block score: 0.13492990657687187
removed block 14 current accuracy 0.7334 loss from initial  0.26659999999999995
training start
training epoch 0 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best True lr [0.001]
training epoch 1 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 2 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 3 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 4 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best True lr [0.001]
training epoch 5 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 6 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 7 val accuracy 0.987 topk_dict {'top1': 0.987} is_best True lr [0.001]
training epoch 8 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 9 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 10 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 11 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 12 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 13 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 14 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 15 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 16 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 17 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 18 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 19 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 20 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 21 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 22 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 23 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 24 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 25 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 26 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 27 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 28 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 29 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 30 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 31 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 32 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 33 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 34 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 35 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 36 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 37 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 38 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 39 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 40 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 41 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 42 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 43 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 44 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 45 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 46 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 47 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 48 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 49 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.992200)
finished training. finished 50 epochs. accuracy 0.9922 topk_dict {'top1': 0.9922}
start iteration 27
[activation mean]: block to remove picked: 8, with score 0.146972. All blocks and scores: [(8, 0.14697173982858658), (37, 0.1504649929702282), (7, 0.15489394776523113), (39, 0.15730321034789085), (12, 0.17007719725370407), (40, 0.17101282440125942), (41, 0.17197422496974468), (42, 0.17369482293725014), (44, 0.17605710215866566), (45, 0.17808958515524864), (11, 0.1794450394809246), (10, 0.17962860502302647), (43, 0.18215164728462696), (2, 0.1835477128624916), (46, 0.1868464108556509), (4, 0.20155318081378937), (47, 0.20166956633329391), (48, 0.2072034478187561), (49, 0.20781351253390312), (9, 0.20869982801377773), (50, 0.21588926203548908), (51, 0.23640038818120956), (17, 0.25557706132531166), (52, 0.27019524946808815), (18, 0.3627232648432255), (36, 0.47525182738900185), (53, 0.6508851870894432)]
computing accuracy for after removing block 8 . block score: 0.14697173982858658
removed block 8 current accuracy 0.9736 loss from initial  0.02639999999999998
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.144537. All blocks and scores: [(39, 0.1445365622639656), (37, 0.14810413122177124), (7, 0.15489394776523113), (12, 0.16150190494954586), (41, 0.16232020780444145), (44, 0.163235891610384), (40, 0.16402020119130611), (42, 0.16794202849268913), (43, 0.17623800970613956), (11, 0.17690848000347614), (45, 0.17698540352284908), (46, 0.1808285042643547), (10, 0.1825553011149168), (2, 0.1835477128624916), (47, 0.1925912257283926), (49, 0.19727996923029423), (48, 0.19804939441382885), (4, 0.20155318081378937), (50, 0.2046025525778532), (9, 0.22369886375963688), (51, 0.23128966614603996), (17, 0.23367131687700748), (52, 0.26546700298786163), (18, 0.34568897262215614), (36, 0.4590090401470661), (53, 0.6662877798080444)]
computing accuracy for after removing block 39 . block score: 0.1445365622639656
removed block 39 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 37, with score 0.148104. All blocks and scores: [(37, 0.14810413122177124), (7, 0.15489394776523113), (44, 0.15867529064416885), (12, 0.16150190494954586), (41, 0.1641157977283001), (40, 0.16772938892245293), (42, 0.16924105398356915), (45, 0.17118833772838116), (43, 0.1751612238585949), (11, 0.17690848000347614), (46, 0.17692706920206547), (10, 0.1825553011149168), (2, 0.1835477128624916), (47, 0.18564452230930328), (48, 0.18990642577409744), (49, 0.19058635085821152), (50, 0.19877368584275246), (4, 0.20155318081378937), (9, 0.22369886375963688), (51, 0.22796102799475193), (17, 0.23367131687700748), (52, 0.2608715184032917), (18, 0.34568897262215614), (36, 0.4590090401470661), (53, 0.6832723915576935)]
computing accuracy for after removing block 37 . block score: 0.14810413122177124
removed block 37 current accuracy 0.9412 loss from initial  0.05879999999999996
since last training loss: 0.050999999999999934 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 44, with score 0.151113. All blocks and scores: [(44, 0.1511130016297102), (7, 0.15489394776523113), (12, 0.16150190494954586), (45, 0.16523535549640656), (41, 0.16659123450517654), (42, 0.16736772283911705), (43, 0.17002063430845737), (46, 0.1703176610171795), (40, 0.1754800695925951), (11, 0.17690848000347614), (47, 0.17972378060221672), (10, 0.1825553011149168), (48, 0.18288399279117584), (2, 0.1835477128624916), (49, 0.18476727791130543), (50, 0.19468956626951694), (4, 0.20155318081378937), (9, 0.22369886375963688), (51, 0.22485453821718693), (17, 0.23367131687700748), (52, 0.25935449451208115), (18, 0.34568897262215614), (36, 0.4590090401470661), (53, 0.6854861974716187)]
computing accuracy for after removing block 44 . block score: 0.1511130016297102
removed block 44 current accuracy 0.9174 loss from initial  0.0826
since last training loss: 0.07479999999999998 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 7, with score 0.154894. All blocks and scores: [(7, 0.15489394776523113), (12, 0.16150190494954586), (41, 0.16659123450517654), (42, 0.16736772283911705), (45, 0.16929181665182114), (43, 0.17002063430845737), (46, 0.17175192199647427), (40, 0.1754800695925951), (11, 0.17690848000347614), (47, 0.17994830571115017), (49, 0.1809959076344967), (48, 0.18238025531172752), (10, 0.1825553011149168), (2, 0.1835477128624916), (50, 0.19215180724859238), (4, 0.20155318081378937), (51, 0.22138842195272446), (9, 0.22369886375963688), (17, 0.23367131687700748), (52, 0.253956887871027), (18, 0.34568897262215614), (36, 0.4590090401470661), (53, 0.7186530977487564)]
computing accuracy for after removing block 7 . block score: 0.15489394776523113
removed block 7 current accuracy 0.8072 loss from initial  0.19279999999999997
since last training loss: 0.18499999999999994 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 12, with score 0.155442. All blocks and scores: [(12, 0.15544228442013264), (41, 0.15666105411946774), (42, 0.16083203069865704), (46, 0.16361496224999428), (45, 0.16715499199926853), (43, 0.17016100883483887), (47, 0.17165535688400269), (48, 0.1756236646324396), (11, 0.17768217623233795), (10, 0.17854474671185017), (49, 0.1799680721014738), (40, 0.18269036151468754), (50, 0.18341048248112202), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.21738544292747974), (17, 0.2220599614083767), (9, 0.2291820663958788), (52, 0.24777289293706417), (18, 0.33337346464395523), (36, 0.4503626562654972), (53, 0.7116191610693932)]
computing accuracy for after removing block 12 . block score: 0.15544228442013264
removed block 12 current accuracy 0.8042 loss from initial  0.19579999999999997
since last training loss: 0.18799999999999994 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 41, with score 0.148760. All blocks and scores: [(41, 0.1487602423876524), (42, 0.1498777773231268), (46, 0.15499102883040905), (43, 0.1571032553911209), (45, 0.15835149958729744), (48, 0.16884884797036648), (47, 0.17043224722146988), (40, 0.17098422534763813), (49, 0.17410197854042053), (50, 0.17710628546774387), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.20931481197476387), (9, 0.2291820663958788), (52, 0.24533214047551155), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.7022341564297676)]
computing accuracy for after removing block 41 . block score: 0.1487602423876524
removed block 41 current accuracy 0.752 loss from initial  0.248
since last training loss: 0.24019999999999997 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 46, with score 0.152778. All blocks and scores: [(46, 0.15277813747525215), (42, 0.15361454896628857), (45, 0.15505623631179333), (43, 0.15691702999174595), (48, 0.1637676004320383), (49, 0.16773241572082043), (47, 0.1691452246159315), (40, 0.17098422534763813), (50, 0.17327414080500603), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.20768532156944275), (9, 0.2291820663958788), (52, 0.24389727227389812), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.7069971710443497)]
computing accuracy for after removing block 46 . block score: 0.15277813747525215
removed block 46 current accuracy 0.717 loss from initial  0.28300000000000003
since last training loss: 0.2752 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 42, with score 0.153615. All blocks and scores: [(42, 0.15361454896628857), (45, 0.15505623631179333), (43, 0.15691702999174595), (48, 0.15791449137032032), (49, 0.16816175915300846), (47, 0.16942943073809147), (40, 0.17098422534763813), (50, 0.17267092503607273), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.20826207287609577), (9, 0.2291820663958788), (52, 0.24173351004719734), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.7462736070156097)]
computing accuracy for after removing block 42 . block score: 0.15361454896628857
removed block 42 current accuracy 0.6636 loss from initial  0.33640000000000003
since last training loss: 0.3286 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 48, with score 0.147606. All blocks and scores: [(48, 0.14760633185505867), (45, 0.14890203438699245), (49, 0.15697281993925571), (43, 0.16182861849665642), (47, 0.16336694173514843), (50, 0.16833321936428547), (40, 0.17098422534763813), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.20363167114555836), (9, 0.2291820663958788), (52, 0.23775948025286198), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.7149977833032608)]
computing accuracy for after removing block 48 . block score: 0.14760633185505867
removed block 48 current accuracy 0.6182 loss from initial  0.38180000000000003
since last training loss: 0.374 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 45, with score 0.148902. All blocks and scores: [(45, 0.14890203438699245), (49, 0.1536414511501789), (43, 0.16182861849665642), (47, 0.16336694173514843), (50, 0.1685016229748726), (40, 0.17098422534763813), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.20385941304266453), (9, 0.2291820663958788), (52, 0.231640063226223), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.8096392676234245)]
computing accuracy for after removing block 45 . block score: 0.14890203438699245
removed block 45 current accuracy 0.5454 loss from initial  0.4546
since last training loss: 0.4468 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 49, with score 0.152323. All blocks and scores: [(49, 0.15232286043465137), (43, 0.16182861849665642), (47, 0.16552866250276566), (50, 0.16871588677167892), (40, 0.17098422534763813), (11, 0.17768217623233795), (10, 0.17854474671185017), (2, 0.1835477128624916), (4, 0.20155318081378937), (51, 0.2043064571917057), (9, 0.2291820663958788), (52, 0.22979676350951195), (17, 0.26249395683407784), (18, 0.3231445625424385), (36, 0.43634477630257607), (53, 0.8633482158184052)]
computing accuracy for after removing block 49 . block score: 0.15232286043465137
removed block 49 current accuracy 0.4884 loss from initial  0.5116
training start
training epoch 0 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.001]
training epoch 1 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 2 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 3 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 4 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 5 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 6 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 7 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 8 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.001]
training epoch 9 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.001]
training epoch 10 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 11 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 12 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 13 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.001]
training epoch 14 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 15 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 16 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.001]
training epoch 17 val accuracy 0.955 topk_dict {'top1': 0.955} is_best False lr [0.001]
training epoch 18 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best True lr [0.001]
training epoch 19 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 20 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best True lr [0.001]
training epoch 21 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 22 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.001]
training epoch 23 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 24 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.001]
training epoch 25 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 26 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.001]
training epoch 27 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best True lr [0.001]
training epoch 28 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.001]
training epoch 29 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.001]
training epoch 30 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.001]
training epoch 31 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 32 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.001]
training epoch 33 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 34 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best False lr [0.001]
training epoch 35 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best True lr [0.001]
training epoch 36 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.001]
training epoch 37 val accuracy 0.9618 topk_dict {'top1': 0.9618} is_best False lr [0.001]
training epoch 38 val accuracy 0.964 topk_dict {'top1': 0.964} is_best True lr [0.001]
training epoch 39 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 40 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 41 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.001]
training epoch 42 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.001]
training epoch 43 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.001]
training epoch 44 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.001]
training epoch 45 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.001]
training epoch 46 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.001]
training epoch 47 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
training epoch 48 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.001]
training epoch 49 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.966200)
finished training. finished 50 epochs. accuracy 0.9662 topk_dict {'top1': 0.9662}
