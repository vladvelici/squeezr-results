start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068702. All blocks and scores: [(26, 0.06870234198868275), (27, 0.0741223581135273), (31, 0.07421684544533491), (35, 0.07685474585741758), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08143280725926161), (24, 0.08224374894052744), (34, 0.08227442763745785), (33, 0.08310604561120272), (23, 0.08412310108542442), (32, 0.08623841684311628), (28, 0.0872054873034358), (22, 0.08930969890207052), (30, 0.09091433975845575), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13720723055303097), (39, 0.13744624331593513), (37, 0.14209549687802792), (38, 0.14290856197476387), (6, 0.14786463603377342), (41, 0.1508424561470747), (42, 0.15258264541625977), (4, 0.15538891777396202), (43, 0.15601677261292934), (44, 0.15883748047053814), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16798720695078373), (2, 0.18457405641674995), (46, 0.18493103049695492), (1, 0.20192440785467625), (47, 0.2080467976629734), (48, 0.21010252088308334), (49, 0.224680308252573), (50, 0.23862904869019985), (51, 0.25924162939190865), (52, 0.28526581451296806), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4550497271120548), (53, 0.6487655118107796)]
computing accuracy for after removing block 26 . block score: 0.06870234198868275
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074250. All blocks and scores: [(31, 0.07425017189234495), (27, 0.07438226789236069), (35, 0.0760756740346551), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08178351167589426), (34, 0.08181511238217354), (24, 0.08224374894052744), (33, 0.08314474113285542), (23, 0.08412310108542442), (32, 0.08550294954329729), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13959151320159435), (39, 0.1399664543569088), (37, 0.14363272115588188), (38, 0.1437524501234293), (6, 0.14786463603377342), (41, 0.15150794386863708), (42, 0.15349512174725533), (4, 0.15538891777396202), (43, 0.15715143270790577), (13, 0.1590876206755638), (44, 0.15911891870200634), (3, 0.16731475666165352), (45, 0.16931429505348206), (2, 0.18457405641674995), (46, 0.186824394389987), (1, 0.20192440785467625), (47, 0.20976067893207073), (48, 0.2109022866934538), (49, 0.2249483335763216), (50, 0.23839633911848068), (51, 0.2592626102268696), (52, 0.2852507643401623), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4592660255730152), (53, 0.6468537002801895)]
computing accuracy for after removing block 31 . block score: 0.07425017189234495
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074382. All blocks and scores: [(27, 0.07438226789236069), (35, 0.07612952496856451), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (34, 0.08106645382940769), (29, 0.08178351167589426), (24, 0.08224374894052744), (33, 0.08338531665503979), (23, 0.08412310108542442), (32, 0.08539257477968931), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14128642156720161), (40, 0.14169061370193958), (39, 0.14174902439117432), (37, 0.14439108967781067), (6, 0.14786463603377342), (41, 0.15143204852938652), (42, 0.15228785201907158), (4, 0.15538891777396202), (43, 0.15636706165969372), (44, 0.15833302028477192), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16788306273519993), (2, 0.18457405641674995), (46, 0.1864120475947857), (1, 0.20192440785467625), (47, 0.20843712612986565), (48, 0.21100311167538166), (49, 0.22473796643316746), (50, 0.23855118453502655), (51, 0.2591783180832863), (52, 0.28372708708047867), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.46568959951400757), (53, 0.6510000601410866)]
computing accuracy for after removing block 27 . block score: 0.07438226789236069
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075854. All blocks and scores: [(35, 0.07585428189486265), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14026966504752636), (39, 0.14322753064334393), (40, 0.14488770440220833), (37, 0.14594712853431702), (6, 0.14786463603377342), (41, 0.15189490653574467), (42, 0.15252277441322803), (4, 0.15538891777396202), (43, 0.15715407766401768), (44, 0.15864605642855167), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.1683814972639084), (2, 0.18457405641674995), (46, 0.18689549528062344), (1, 0.20192440785467625), (47, 0.20870989188551903), (48, 0.21123779565095901), (49, 0.22443696111440659), (50, 0.23874318413436413), (51, 0.2584992125630379), (52, 0.2828393988311291), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4712146706879139), (53, 0.6518600136041641)]
computing accuracy for after removing block 35 . block score: 0.07585428189486265
removed block 35 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076914. All blocks and scores: [(20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1385685559362173), (40, 0.13947991654276848), (39, 0.14093938656151295), (37, 0.14259942434728146), (6, 0.14786463603377342), (41, 0.15029864758253098), (42, 0.15072360262274742), (43, 0.15525723062455654), (44, 0.1552812773734331), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.16552621126174927), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.1869147438555956), (1, 0.20192440785467625), (48, 0.20716596953570843), (47, 0.20739650540053844), (49, 0.22507839649915695), (50, 0.23703056946396828), (51, 0.25911351665854454), (52, 0.28219735622406006), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.47133130580186844), (53, 0.6564537882804871)]
computing accuracy for after removing block 20 . block score: 0.07691387087106705
removed block 20 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079448. All blocks and scores: [(17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08003473933786154), (29, 0.08079283125698566), (21, 0.08103854302316904), (25, 0.08157523907721043), (24, 0.0828929403796792), (33, 0.08348109386861324), (23, 0.08391222264617682), (32, 0.0845849085599184), (28, 0.08620174136012793), (30, 0.088497344404459), (22, 0.09044258669018745), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13876904174685478), (40, 0.14043930359184742), (39, 0.14079759642481804), (37, 0.1433244775980711), (6, 0.14786463603377342), (41, 0.15065929107367992), (42, 0.15136869624257088), (4, 0.15538891777396202), (44, 0.1556632611900568), (43, 0.15633762441575527), (13, 0.1590876206755638), (45, 0.1662806160748005), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18815029971301556), (1, 0.20192440785467625), (48, 0.20721778832376003), (47, 0.208082502707839), (49, 0.22565172612667084), (50, 0.23704500310122967), (51, 0.2587750032544136), (52, 0.28254886716604233), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4735274948179722), (53, 0.6537546589970589)]
computing accuracy for after removing block 17 . block score: 0.07944803778082132
removed block 17 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.077955. All blocks and scores: [(21, 0.07795533165335655), (34, 0.07894970290362835), (29, 0.0790198752656579), (25, 0.07908098585903645), (16, 0.08003389276564121), (33, 0.08208741899579763), (24, 0.08280743844807148), (23, 0.08313068188726902), (32, 0.08349784929305315), (28, 0.08599762804806232), (30, 0.08654309343546629), (22, 0.09004937391728163), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13761902786791325), (37, 0.14218291267752647), (39, 0.14250223897397518), (40, 0.1427330169826746), (6, 0.14786463603377342), (42, 0.149957912042737), (41, 0.15121997334063053), (4, 0.15538891777396202), (44, 0.15583417192101479), (43, 0.1559469159692526), (13, 0.1590876206755638), (45, 0.16489200666546822), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18951294012367725), (1, 0.20192440785467625), (48, 0.20613021031022072), (47, 0.20653356611728668), (49, 0.2261425293982029), (50, 0.23595429211854935), (51, 0.2574720084667206), (52, 0.2808535546064377), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.47553205117583275), (53, 0.6502362936735153)]
computing accuracy for after removing block 21 . block score: 0.07795533165335655
removed block 21 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.077982. All blocks and scores: [(29, 0.07798169739544392), (25, 0.07838128041476011), (34, 0.07839732337743044), (16, 0.08003389276564121), (33, 0.08119457680732012), (23, 0.08126077149063349), (24, 0.0816669063642621), (32, 0.0824327003210783), (28, 0.08386608771979809), (30, 0.0852785985916853), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13711080700159073), (37, 0.14175310172140598), (39, 0.14240100793540478), (40, 0.14322563633322716), (6, 0.14786463603377342), (42, 0.15017673559486866), (41, 0.1524363812059164), (44, 0.1552524920552969), (4, 0.15538891777396202), (43, 0.15651666559278965), (13, 0.1590876206755638), (45, 0.1644004713743925), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.19123134016990662), (1, 0.20192440785467625), (48, 0.20559575967490673), (47, 0.2066254075616598), (49, 0.2266144324094057), (50, 0.23550251685082912), (51, 0.2582874819636345), (52, 0.2810910604894161), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.4777962565422058), (53, 0.651190422475338)]
computing accuracy for after removing block 29 . block score: 0.07798169739544392
removed block 29 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 34, with score 0.078179. All blocks and scores: [(34, 0.07817933894693851), (25, 0.07838128041476011), (16, 0.08003389276564121), (23, 0.08126077149063349), (24, 0.0816669063642621), (33, 0.08192401938140392), (32, 0.08295448962599039), (28, 0.08386608771979809), (30, 0.08506463654339314), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1336296908557415), (37, 0.14201423898339272), (39, 0.14242823980748653), (40, 0.1438832189887762), (6, 0.14786463603377342), (42, 0.1480300221592188), (41, 0.15086989849805832), (44, 0.15249392949044704), (43, 0.15497619286179543), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.1628444753587246), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.19056031480431557), (1, 0.20192440785467625), (48, 0.20341675728559494), (47, 0.20561709441244602), (49, 0.2250166404992342), (50, 0.23460135981440544), (51, 0.25660766288638115), (52, 0.27802200987935066), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.482606153935194), (53, 0.6564268171787262)]
computing accuracy for after removing block 34 . block score: 0.07817933894693851
removed block 34 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 2 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 9
[activation mean]: block to remove picked: 16, with score 0.080982. All blocks and scores: [(16, 0.08098168857395649), (25, 0.08261056989431381), (33, 0.08389695547521114), (23, 0.08811206929385662), (32, 0.08844791073352098), (24, 0.0887298434972763), (28, 0.09107666648924351), (14, 0.09282756503671408), (30, 0.09283292107284069), (22, 0.09493752010166645), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10365384072065353), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (40, 0.13753000646829605), (39, 0.13764330558478832), (37, 0.1411519069224596), (38, 0.14193247817456722), (6, 0.1479438580572605), (41, 0.14810803346335888), (42, 0.1509056631475687), (43, 0.15376331098377705), (4, 0.15550361201167107), (44, 0.15752181224524975), (13, 0.15958097763359547), (45, 0.16617626138031483), (3, 0.16744514741003513), (2, 0.1831244695931673), (46, 0.1849021054804325), (1, 0.20103596150875092), (47, 0.20548088289797306), (48, 0.20876006036996841), (49, 0.22373568266630173), (50, 0.23792953044176102), (51, 0.25805818289518356), (52, 0.282589316368103), (0, 0.31326134502887726), (18, 0.4311896376311779), (36, 0.45100122317671776), (53, 0.6501049548387527)]
computing accuracy for after removing block 16 . block score: 0.08098168857395649
removed block 16 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 25, with score 0.082481. All blocks and scores: [(25, 0.08248084131628275), (33, 0.0828506238758564), (23, 0.08770477958023548), (32, 0.08908502198755741), (24, 0.09062349144369364), (28, 0.09066387731581926), (30, 0.09186641592532396), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (40, 0.13629929535090923), (39, 0.136387150734663), (37, 0.1410235222429037), (38, 0.14251699298620224), (6, 0.1479438580572605), (41, 0.15007774531841278), (42, 0.15033497102558613), (43, 0.15351799502968788), (4, 0.15550361201167107), (44, 0.15771724097430706), (13, 0.15958097763359547), (45, 0.16597377322614193), (3, 0.16744514741003513), (2, 0.1831244695931673), (46, 0.18400230631232262), (1, 0.20103596150875092), (47, 0.2050529159605503), (48, 0.20723311230540276), (49, 0.22298667393624783), (50, 0.23525528609752655), (51, 0.2559903524816036), (52, 0.28058623895049095), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.449984610080719), (53, 0.651194378733635)]
computing accuracy for after removing block 25 . block score: 0.08248084131628275
removed block 25 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 33, with score 0.082735. All blocks and scores: [(33, 0.08273475244641304), (23, 0.08770477958023548), (32, 0.08806798979640007), (28, 0.08980916533619165), (30, 0.09052018169313669), (24, 0.09062349144369364), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (40, 0.13592317514121532), (39, 0.138180211186409), (37, 0.14064712636172771), (38, 0.14128411002457142), (42, 0.1478213258087635), (6, 0.1479438580572605), (41, 0.1499636098742485), (43, 0.15246532671153545), (4, 0.15550361201167107), (44, 0.1574996616691351), (13, 0.15958097763359547), (45, 0.1655978374183178), (3, 0.16744514741003513), (2, 0.1831244695931673), (46, 0.18358800932765007), (1, 0.20103596150875092), (47, 0.204369829967618), (48, 0.20542102493345737), (49, 0.2222139909863472), (50, 0.2333735190331936), (51, 0.2551319822669029), (52, 0.27841341495513916), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.4534521736204624), (53, 0.6497042179107666)]
computing accuracy for after removing block 33 . block score: 0.08273475244641304
removed block 33 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.087705. All blocks and scores: [(23, 0.08770477958023548), (32, 0.08806798979640007), (28, 0.08980916533619165), (30, 0.09052018169313669), (24, 0.09062349144369364), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (40, 0.13120614364743233), (38, 0.1326550617814064), (5, 0.13267778046429157), (39, 0.13273371942341328), (37, 0.1347277332097292), (42, 0.14345605298876762), (41, 0.14477277547121048), (43, 0.14711815677583218), (6, 0.1479438580572605), (44, 0.15177862159907818), (4, 0.15550361201167107), (45, 0.15923240780830383), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.17892811819911003), (2, 0.1831244695931673), (47, 0.19790812022984028), (48, 0.19818911142647266), (1, 0.20103596150875092), (49, 0.22022326104342937), (50, 0.22904754430055618), (51, 0.2524481527507305), (52, 0.27264952659606934), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.44830409437417984), (53, 0.6608125790953636)]
computing accuracy for after removing block 23 . block score: 0.08770477958023548
removed block 23 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.086698. All blocks and scores: [(32, 0.0866978894919157), (28, 0.0885049570351839), (24, 0.08881853707134724), (30, 0.08896772004663944), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (38, 0.13142610155045986), (40, 0.1320547442883253), (5, 0.13267778046429157), (37, 0.13456552661955357), (39, 0.13521090522408485), (42, 0.14237095788121223), (41, 0.1450850758701563), (43, 0.14572742953896523), (6, 0.1479438580572605), (44, 0.15022863820195198), (4, 0.15550361201167107), (45, 0.15738272666931152), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.1788437869399786), (2, 0.1831244695931673), (48, 0.19672014936804771), (47, 0.1972675584256649), (1, 0.20103596150875092), (49, 0.2197838518768549), (50, 0.22755233570933342), (51, 0.2528260201215744), (52, 0.2718256078660488), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.45026304200291634), (53, 0.661608450114727)]
computing accuracy for after removing block 32 . block score: 0.0866978894919157
removed block 32 current accuracy 0.9886 loss from initial  0.011399999999999966
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 28, with score 0.088505. All blocks and scores: [(28, 0.0885049570351839), (24, 0.08881853707134724), (30, 0.08896772004663944), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (38, 0.12592950463294983), (12, 0.1311220470815897), (40, 0.1317606009542942), (5, 0.13267778046429157), (37, 0.13274591229856014), (39, 0.1350233107805252), (42, 0.13999090157449245), (43, 0.14213704131543636), (41, 0.14233623072504997), (44, 0.14650931395590305), (6, 0.1479438580572605), (45, 0.15436150133609772), (4, 0.15550361201167107), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.17748209834098816), (2, 0.1831244695931673), (48, 0.19298039749264717), (47, 0.19526716135442257), (1, 0.20103596150875092), (49, 0.21896056085824966), (50, 0.22482231445610523), (51, 0.2514003701508045), (52, 0.26738153770565987), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.4552547484636307), (53, 0.6684153974056244)]
computing accuracy for after removing block 28 . block score: 0.0885049570351839
removed block 28 current accuracy 0.9758 loss from initial  0.0242
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 30, with score 0.087171. All blocks and scores: [(30, 0.08717118576169014), (24, 0.08881853707134724), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (38, 0.12134215980768204), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (37, 0.13288559950888157), (40, 0.1347518414258957), (42, 0.13802198693156242), (39, 0.1384633481502533), (43, 0.14125242829322815), (41, 0.14204257354140282), (44, 0.1444858480244875), (6, 0.1479438580572605), (45, 0.15441280975937843), (4, 0.15550361201167107), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.1775963120162487), (2, 0.1831244695931673), (48, 0.19059062004089355), (47, 0.19479750469326973), (1, 0.20103596150875092), (49, 0.218051353469491), (50, 0.22377457842230797), (51, 0.25168024376034737), (52, 0.26471349969506264), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.46234065294265747), (53, 0.6731060445308685)]
computing accuracy for after removing block 30 . block score: 0.08717118576169014
removed block 30 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.04600000000000004 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 24, with score 0.088819. All blocks and scores: [(24, 0.08881853707134724), (14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (15, 0.11584774404764175), (7, 0.11704002972692251), (38, 0.1185621740296483), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (37, 0.13397292234003544), (42, 0.13559845462441444), (43, 0.138264125213027), (40, 0.13915862515568733), (41, 0.14165652729570866), (44, 0.1422202568501234), (39, 0.1436287835240364), (6, 0.1479438580572605), (45, 0.15287388861179352), (4, 0.15550361201167107), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.17780311591923237), (2, 0.1831244695931673), (48, 0.18932677060365677), (47, 0.19425911642611027), (1, 0.20103596150875092), (49, 0.21725589781999588), (50, 0.22314906306564808), (51, 0.25147179141640663), (52, 0.2595827169716358), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.4744155555963516), (53, 0.6791927739977837)]
computing accuracy for after removing block 24 . block score: 0.08881853707134724
removed block 24 current accuracy 0.9272 loss from initial  0.07279999999999998
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.092828. All blocks and scores: [(14, 0.09282756503671408), (22, 0.09479087870568037), (9, 0.09702054876834154), (11, 0.10058115236461163), (19, 0.10277256369590759), (8, 0.1068186592310667), (38, 0.11526275053620338), (15, 0.11584774404764175), (7, 0.11704002972692251), (10, 0.1252002865076065), (12, 0.1311220470815897), (5, 0.13267778046429157), (37, 0.13425184041261673), (42, 0.13497371226549149), (43, 0.13904582150280476), (41, 0.1407051682472229), (40, 0.14161543361842632), (44, 0.1423363909125328), (6, 0.1479438580572605), (39, 0.14825942739844322), (45, 0.15242280811071396), (4, 0.15550361201167107), (13, 0.15958097763359547), (3, 0.16744514741003513), (46, 0.17786315456032753), (2, 0.1831244695931673), (48, 0.1880165096372366), (47, 0.19264808110892773), (1, 0.20103596150875092), (49, 0.21691336296498775), (50, 0.22162602469325066), (51, 0.2506500780582428), (52, 0.2569470554590225), (0, 0.31326134502887726), (18, 0.4333336129784584), (36, 0.48384565114974976), (53, 0.6807416304945946)]
computing accuracy for after removing block 14 . block score: 0.09282756503671408
removed block 14 current accuracy 0.9034 loss from initial  0.09660000000000002
training start
training epoch 0 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 1 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 2 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 4 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 5 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 6 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 7 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 8 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 9 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 10 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 11 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 12 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 13 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 14 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 15 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 16 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 20 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 21 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 22 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 23 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 24 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 25 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 26 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 27 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 28 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 29 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 32 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 33 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 34 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 35 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 36 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 39 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 41 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 42 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 43 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 45 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 47 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 48 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 49 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.998400)
finished training. finished 50 epochs. accuracy 0.9984 topk_dict {'top1': 0.9984}
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.100263. All blocks and scores: [(9, 0.10026280954480171), (8, 0.10449844971299171), (11, 0.10505560413002968), (7, 0.11531940754503012), (19, 0.12363726180046797), (10, 0.12444230914115906), (15, 0.1289820335805416), (22, 0.12900759279727936), (12, 0.1296692155301571), (5, 0.13064579293131828), (40, 0.1369944866746664), (39, 0.13714715652167797), (37, 0.1416386142373085), (38, 0.14221790246665478), (41, 0.14589868858456612), (6, 0.1474693827331066), (42, 0.14959112741053104), (43, 0.15308518335223198), (44, 0.15508500300347805), (4, 0.15681542456150055), (3, 0.16417976282536983), (45, 0.16514712572097778), (13, 0.1667076963931322), (2, 0.17967240326106548), (46, 0.18140960857272148), (1, 0.19542897678911686), (47, 0.20343012548983097), (48, 0.20656734704971313), (49, 0.2209918461740017), (50, 0.2359422016888857), (51, 0.2573043741285801), (52, 0.2801693305373192), (0, 0.3046257682144642), (18, 0.42044834420084953), (36, 0.4515727758407593), (53, 0.6509347781538963)]
computing accuracy for after removing block 9 . block score: 0.10026280954480171
removed block 9 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 8, with score 0.104498. All blocks and scores: [(8, 0.10449844971299171), (11, 0.10517894756048918), (7, 0.11531940754503012), (10, 0.12102699652314186), (19, 0.12280676793307066), (15, 0.12638179399073124), (22, 0.12657826952636242), (12, 0.1266986709088087), (5, 0.13064579293131828), (39, 0.13249775022268295), (40, 0.1344704944640398), (37, 0.13929673843085766), (38, 0.14066044613718987), (41, 0.1465169619768858), (42, 0.1470683142542839), (6, 0.1474693827331066), (43, 0.1511298529803753), (44, 0.15392610989511013), (4, 0.15681542456150055), (13, 0.15870368666946888), (45, 0.16358397528529167), (3, 0.16417976282536983), (2, 0.17967240326106548), (46, 0.18005588836967945), (1, 0.19542897678911686), (47, 0.1996099967509508), (48, 0.2039617821574211), (49, 0.21970410086214542), (50, 0.23491414077579975), (51, 0.2555740475654602), (52, 0.2778739295899868), (0, 0.3046257682144642), (18, 0.4130737744271755), (36, 0.4481101334095001), (53, 0.6503144726157188)]
computing accuracy for after removing block 8 . block score: 0.10449844971299171
removed block 8 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 11, with score 0.107491. All blocks and scores: [(11, 0.10749148763716221), (7, 0.11531940754503012), (19, 0.12225662637501955), (10, 0.12337040435522795), (15, 0.12596960738301277), (22, 0.12660416774451733), (12, 0.12743373401463032), (5, 0.13064579293131828), (39, 0.1310841664671898), (40, 0.13365570455789566), (37, 0.13874929957091808), (42, 0.14333073236048222), (38, 0.14370819553732872), (41, 0.14496178552508354), (6, 0.1474693827331066), (44, 0.1511948462575674), (43, 0.15179280377924442), (4, 0.15681542456150055), (45, 0.16082360409200191), (13, 0.16159366257488728), (3, 0.16417976282536983), (2, 0.17967240326106548), (46, 0.18014787323772907), (1, 0.19542897678911686), (47, 0.19975127652287483), (48, 0.20288300327956676), (49, 0.21962523832917213), (50, 0.23363921977579594), (51, 0.25443289056420326), (52, 0.2766179144382477), (0, 0.3046257682144642), (18, 0.412126075476408), (36, 0.4478241205215454), (53, 0.6469285637140274)]
computing accuracy for after removing block 11 . block score: 0.10749148763716221
removed block 11 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 7, with score 0.115319. All blocks and scores: [(7, 0.11531940754503012), (19, 0.12105151079595089), (10, 0.12337040435522795), (22, 0.1250285767018795), (15, 0.12605335377156734), (39, 0.12733255699276924), (12, 0.1287766881287098), (5, 0.13064579293131828), (40, 0.13081337697803974), (37, 0.13622816652059555), (42, 0.14112604223191738), (38, 0.14160762168467045), (41, 0.14442525804042816), (6, 0.1474693827331066), (43, 0.14966905303299427), (44, 0.15091454051434994), (4, 0.15681542456150055), (45, 0.16061525233089924), (13, 0.16125669330358505), (3, 0.16417976282536983), (46, 0.17941865511238575), (2, 0.17967240326106548), (1, 0.19542897678911686), (47, 0.19734960421919823), (48, 0.19871474616229534), (49, 0.21917336992919445), (50, 0.23078304156661034), (51, 0.2525622248649597), (52, 0.2740441672503948), (0, 0.3046257682144642), (18, 0.4072949215769768), (36, 0.44591885060071945), (53, 0.6415214687585831)]
computing accuracy for after removing block 7 . block score: 0.11531940754503012
removed block 7 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 19, with score 0.120591. All blocks and scores: [(19, 0.12059134617447853), (22, 0.12184317130595446), (10, 0.12197588011622429), (39, 0.1229191580787301), (15, 0.12328757159411907), (40, 0.12383398413658142), (12, 0.1302905697375536), (5, 0.13064579293131828), (37, 0.1321688164025545), (42, 0.13777056336402893), (38, 0.13988936692476273), (41, 0.1428089365363121), (43, 0.14603998698294163), (6, 0.1474693827331066), (44, 0.14799945056438446), (4, 0.15681542456150055), (45, 0.15822546370327473), (13, 0.16157089173793793), (3, 0.16417976282536983), (46, 0.17413045465946198), (2, 0.17967240326106548), (48, 0.19249414652585983), (47, 0.19500594213604927), (1, 0.19542897678911686), (49, 0.21528990007936954), (50, 0.22430789098143578), (51, 0.2483225055038929), (52, 0.2684672586619854), (0, 0.3046257682144642), (18, 0.3999359868466854), (36, 0.4394802749156952), (53, 0.6404475942254066)]
computing accuracy for after removing block 19 . block score: 0.12059134617447853
removed block 19 current accuracy 0.9744 loss from initial  0.025599999999999956
since last training loss: 0.02399999999999991 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 22, with score 0.121379. All blocks and scores: [(22, 0.12137906346470118), (10, 0.12197588011622429), (39, 0.1227874206379056), (15, 0.12328757159411907), (40, 0.12902765907347202), (12, 0.1302905697375536), (5, 0.13064579293131828), (37, 0.1344838384538889), (42, 0.139380544424057), (38, 0.14137599244713783), (41, 0.14469130150973797), (6, 0.1474693827331066), (43, 0.14837172999978065), (44, 0.14889131672680378), (4, 0.15681542456150055), (13, 0.16157089173793793), (45, 0.16158125922083855), (3, 0.16417976282536983), (46, 0.17555588856339455), (2, 0.17967240326106548), (48, 0.19219469465315342), (1, 0.19542897678911686), (47, 0.19552516378462315), (49, 0.2150353156030178), (50, 0.22206690162420273), (51, 0.24657423980534077), (52, 0.2655116617679596), (0, 0.3046257682144642), (18, 0.3999359868466854), (36, 0.4542267695069313), (53, 0.6374942362308502)]
computing accuracy for after removing block 22 . block score: 0.12137906346470118
removed block 22 current accuracy 0.9474 loss from initial  0.05259999999999998
since last training loss: 0.050999999999999934 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 10, with score 0.121976. All blocks and scores: [(10, 0.12197588011622429), (15, 0.12328757159411907), (39, 0.12603574246168137), (12, 0.1302905697375536), (5, 0.13064579293131828), (37, 0.13167924992740154), (40, 0.13378140330314636), (42, 0.13641450367867947), (38, 0.1407896913588047), (44, 0.1444020066410303), (43, 0.14464077912271023), (41, 0.14616207778453827), (6, 0.1474693827331066), (4, 0.15681542456150055), (45, 0.1579825673252344), (13, 0.16157089173793793), (3, 0.16417976282536983), (46, 0.1754709705710411), (2, 0.17967240326106548), (48, 0.19093621335923672), (47, 0.19483954273164272), (1, 0.19542897678911686), (49, 0.21493477374315262), (50, 0.2169640213251114), (51, 0.24526451341807842), (52, 0.2597222067415714), (0, 0.3046257682144642), (18, 0.3999359868466854), (36, 0.4679231271147728), (53, 0.6504335254430771)]
computing accuracy for after removing block 10 . block score: 0.12197588011622429
removed block 10 current accuracy 0.9136 loss from initial  0.08640000000000003
since last training loss: 0.08479999999999999 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 39, with score 0.121584. All blocks and scores: [(39, 0.12158432137221098), (15, 0.12524232547730207), (37, 0.12537989392876625), (42, 0.12923666462302208), (5, 0.13064579293131828), (12, 0.13408655673265457), (41, 0.13487293012440205), (40, 0.1352179329842329), (44, 0.14042330905795097), (38, 0.14103159680962563), (43, 0.14406063966453075), (6, 0.1474693827331066), (45, 0.15349976904690266), (4, 0.15681542456150055), (3, 0.16417976282536983), (13, 0.16777287982404232), (2, 0.17967240326106548), (46, 0.1797808390110731), (48, 0.1869129054248333), (47, 0.19100330211222172), (1, 0.19542897678911686), (49, 0.21463370136916637), (50, 0.21603760868310928), (51, 0.24155006743967533), (52, 0.2544354423880577), (0, 0.3046257682144642), (18, 0.4041224643588066), (36, 0.46393169090151787), (53, 0.6424234285950661)]
computing accuracy for after removing block 39 . block score: 0.12158432137221098
removed block 39 current accuracy 0.9076 loss from initial  0.09240000000000004
since last training loss: 0.09079999999999999 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 15, with score 0.125242. All blocks and scores: [(15, 0.12524232547730207), (37, 0.12537989392876625), (42, 0.13013125956058502), (5, 0.13064579293131828), (41, 0.13371522910892963), (12, 0.13408655673265457), (40, 0.13829516619443893), (44, 0.13974185101687908), (38, 0.14103159680962563), (43, 0.14316516555845737), (6, 0.1474693827331066), (45, 0.1530687715858221), (4, 0.15681542456150055), (3, 0.16417976282536983), (13, 0.16777287982404232), (2, 0.17967240326106548), (46, 0.17983337491750717), (48, 0.18444539047777653), (47, 0.18868419341742992), (1, 0.19542897678911686), (49, 0.21385931596159935), (50, 0.2148448470979929), (51, 0.2394796907901764), (52, 0.2516881041228771), (0, 0.3046257682144642), (18, 0.4041224643588066), (36, 0.46393169090151787), (53, 0.6442819312214851)]
computing accuracy for after removing block 15 . block score: 0.12524232547730207
removed block 15 current accuracy 0.8402 loss from initial  0.15980000000000005
training start
training epoch 0 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 1 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best True lr [0.001]
training epoch 2 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 3 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 4 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 5 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 6 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 7 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 8 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 9 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 10 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 11 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 12 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 13 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 14 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 15 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 16 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 17 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 18 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 19 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 20 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 21 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 22 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 23 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 24 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 25 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 26 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 27 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 28 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 29 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 30 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 31 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 32 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 33 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 34 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 35 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 36 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 38 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 39 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 40 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 42 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 43 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 44 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 45 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 46 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 47 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 49 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.994200)
finished training. finished 50 epochs. accuracy 0.9942 topk_dict {'top1': 0.9942}
start iteration 27
[activation mean]: block to remove picked: 40, with score 0.140433. All blocks and scores: [(40, 0.1404333896934986), (37, 0.1471719015389681), (5, 0.14717509225010872), (38, 0.14745181426405907), (41, 0.1479740273207426), (42, 0.15023641102015972), (12, 0.15045268088579178), (43, 0.15256315656006336), (44, 0.15427757240831852), (45, 0.16397758945822716), (3, 0.164167869836092), (4, 0.16451010294258595), (6, 0.16521160304546356), (2, 0.17391052655875683), (46, 0.17909209616482258), (1, 0.18777723237872124), (13, 0.1930164024233818), (47, 0.19928820617496967), (48, 0.20337522588670254), (49, 0.21839565970003605), (50, 0.23362160474061966), (51, 0.2559434287250042), (52, 0.27746041864156723), (0, 0.28443295136094093), (18, 0.4221920780837536), (36, 0.44688771292567253), (53, 0.6609948128461838)]
computing accuracy for after removing block 40 . block score: 0.1404333896934986
removed block 40 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 37, with score 0.147172. All blocks and scores: [(37, 0.1471719015389681), (5, 0.14717509225010872), (38, 0.14745181426405907), (12, 0.15045268088579178), (41, 0.15073657594621181), (42, 0.1531017180532217), (43, 0.15331000834703445), (44, 0.1552834715694189), (45, 0.16386104188859463), (3, 0.164167869836092), (4, 0.16451010294258595), (6, 0.16521160304546356), (2, 0.17391052655875683), (46, 0.18091676197946072), (1, 0.18777723237872124), (13, 0.1930164024233818), (47, 0.19810368865728378), (48, 0.2021491788327694), (49, 0.21842610277235508), (50, 0.23429901152849197), (51, 0.25680501386523247), (52, 0.2765868864953518), (0, 0.28443295136094093), (18, 0.4221920780837536), (36, 0.44688771292567253), (53, 0.6673557311296463)]
computing accuracy for after removing block 37 . block score: 0.1471719015389681
removed block 37 current accuracy 0.9802 loss from initial  0.01980000000000004
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 5, with score 0.147175. All blocks and scores: [(5, 0.14717509225010872), (41, 0.14970784075558186), (44, 0.15040270797908306), (12, 0.15045268088579178), (43, 0.15106059983372688), (38, 0.1530661527067423), (42, 0.1547029446810484), (45, 0.15985086373984814), (3, 0.164167869836092), (4, 0.16451010294258595), (6, 0.16521160304546356), (2, 0.17391052655875683), (46, 0.1779821366071701), (1, 0.18777723237872124), (47, 0.19281971640884876), (13, 0.1930164024233818), (48, 0.19552329368889332), (49, 0.2140323631465435), (50, 0.22853138856589794), (51, 0.25022929534316063), (52, 0.26815175265073776), (0, 0.28443295136094093), (18, 0.4221920780837536), (36, 0.44688771292567253), (53, 0.6815683245658875)]
computing accuracy for after removing block 5 . block score: 0.14717509225010872
removed block 5 current accuracy 0.9586 loss from initial  0.04139999999999999
since last training loss: 0.035599999999999965 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 41, with score 0.139890. All blocks and scores: [(41, 0.13989025354385376), (44, 0.14442189782857895), (42, 0.14567093923687935), (43, 0.1472282111644745), (38, 0.1533834356814623), (12, 0.15444822050631046), (45, 0.15567908808588982), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (46, 0.17875392735004425), (1, 0.18777723237872124), (47, 0.18909768760204315), (48, 0.19144734181463718), (13, 0.19578999653458595), (49, 0.21379682794213295), (50, 0.23019395023584366), (51, 0.2494498584419489), (52, 0.2627265192568302), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.672266386449337)]
computing accuracy for after removing block 41 . block score: 0.13989025354385376
removed block 41 current accuracy 0.9444 loss from initial  0.05559999999999998
since last training loss: 0.049799999999999955 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 43, with score 0.147988. All blocks and scores: [(43, 0.14798822812736034), (44, 0.1484730839729309), (38, 0.1533834356814623), (12, 0.15444822050631046), (42, 0.15541363134980202), (45, 0.15736374631524086), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (46, 0.17793146707117558), (1, 0.18777723237872124), (47, 0.18852484412491322), (48, 0.18937071040272713), (13, 0.19578999653458595), (49, 0.2132940273731947), (50, 0.22964125871658325), (51, 0.24773721396923065), (52, 0.25763460248708725), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.6855226308107376)]
computing accuracy for after removing block 43 . block score: 0.14798822812736034
removed block 43 current accuracy 0.9206 loss from initial  0.07940000000000003
since last training loss: 0.0736 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 44, with score 0.149059. All blocks and scores: [(44, 0.14905850403010845), (38, 0.1533834356814623), (12, 0.15444822050631046), (45, 0.15487085282802582), (42, 0.15541363134980202), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (46, 0.17821428179740906), (48, 0.18506296165287495), (47, 0.18726582266390324), (1, 0.18777723237872124), (13, 0.19578999653458595), (49, 0.2118548694998026), (50, 0.2266407199203968), (51, 0.24504966475069523), (52, 0.25370191782712936), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.7078060582280159)]
computing accuracy for after removing block 44 . block score: 0.14905850403010845
removed block 44 current accuracy 0.8986 loss from initial  0.10140000000000005
since last training loss: 0.09560000000000002 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 38, with score 0.153383. All blocks and scores: [(38, 0.1533834356814623), (12, 0.15444822050631046), (42, 0.15541363134980202), (45, 0.156233886256814), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (46, 0.17929020337760448), (48, 0.18387977592647076), (47, 0.18528833612799644), (1, 0.18777723237872124), (13, 0.19578999653458595), (49, 0.21144131757318974), (50, 0.22632556036114693), (51, 0.244086729362607), (52, 0.24926869943737984), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.7354235202074051)]
computing accuracy for after removing block 38 . block score: 0.1533834356814623
removed block 38 current accuracy 0.8652 loss from initial  0.13480000000000003
since last training loss: 0.129 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 45, with score 0.151704. All blocks and scores: [(45, 0.15170443803071976), (12, 0.15444822050631046), (42, 0.16284532472491264), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (46, 0.17749633826315403), (48, 0.180102052167058), (47, 0.18038302846252918), (1, 0.18777723237872124), (13, 0.19578999653458595), (49, 0.210467291995883), (50, 0.22119922563433647), (51, 0.2400566879659891), (52, 0.24453035555779934), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.7434097304940224)]
computing accuracy for after removing block 45 . block score: 0.15170443803071976
removed block 45 current accuracy 0.8426 loss from initial  0.15739999999999998
since last training loss: 0.15159999999999996 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 12, with score 0.154448. All blocks and scores: [(12, 0.15444822050631046), (42, 0.16284532472491264), (3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (47, 0.1801680140197277), (48, 0.18208889104425907), (46, 0.18437848053872585), (1, 0.18777723237872124), (13, 0.19578999653458595), (49, 0.21153372153639793), (50, 0.2211645543575287), (51, 0.2391743492335081), (52, 0.24104401655495167), (0, 0.28443295136094093), (18, 0.4168488085269928), (36, 0.446539007127285), (53, 0.7714507058262825)]
computing accuracy for after removing block 12 . block score: 0.15444822050631046
removed block 12 current accuracy 0.7596 loss from initial  0.24039999999999995
since last training loss: 0.23459999999999992 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 42, with score 0.160558. All blocks and scores: [(42, 0.16055764444172382), (3, 0.164167869836092), (4, 0.16451010294258595), (48, 0.17331237718462944), (2, 0.17391052655875683), (6, 0.17420146614313126), (47, 0.17760949209332466), (1, 0.18777723237872124), (46, 0.19096042588353157), (50, 0.21314761228859425), (13, 0.2143087536096573), (49, 0.2152350526303053), (51, 0.2262739073485136), (52, 0.2332602348178625), (0, 0.28443295136094093), (18, 0.41584619134664536), (36, 0.45055509731173515), (53, 0.7430855557322502)]
computing accuracy for after removing block 42 . block score: 0.16055764444172382
removed block 42 current accuracy 0.6976 loss from initial  0.3024
since last training loss: 0.2966 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 3, with score 0.164168. All blocks and scores: [(3, 0.164167869836092), (4, 0.16451010294258595), (2, 0.17391052655875683), (6, 0.17420146614313126), (48, 0.1763246599584818), (47, 0.17876220867037773), (1, 0.18777723237872124), (46, 0.19538327492773533), (50, 0.21420586854219437), (13, 0.2143087536096573), (49, 0.2167861294001341), (51, 0.22325128503143787), (52, 0.22778470814228058), (0, 0.28443295136094093), (18, 0.41584619134664536), (36, 0.45055509731173515), (53, 0.7794693931937218)]
computing accuracy for after removing block 3 . block score: 0.164167869836092
removed block 3 current accuracy 0.66 loss from initial  0.33999999999999997
since last training loss: 0.33419999999999994 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 4, with score 0.155689. All blocks and scores: [(4, 0.15568853542208672), (48, 0.16423187032341957), (6, 0.17081518657505512), (47, 0.17165854573249817), (2, 0.17391052655875683), (46, 0.1823426429182291), (1, 0.18777723237872124), (50, 0.20026767067611217), (13, 0.20398056134581566), (49, 0.20788177102804184), (51, 0.21300023794174194), (52, 0.2200466487556696), (0, 0.28443295136094093), (18, 0.394741240888834), (36, 0.4231499247252941), (53, 0.7125926464796066)]
computing accuracy for after removing block 4 . block score: 0.15568853542208672
removed block 4 current accuracy 0.5024 loss from initial  0.49760000000000004
training start
training epoch 0 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 1 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 2 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 3 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 4 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 5 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.001]
training epoch 6 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.001]
training epoch 7 val accuracy 0.956 topk_dict {'top1': 0.956} is_best True lr [0.001]
training epoch 8 val accuracy 0.957 topk_dict {'top1': 0.957} is_best True lr [0.001]
training epoch 9 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.001]
training epoch 10 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.001]
training epoch 11 val accuracy 0.9584 topk_dict {'top1': 0.9584} is_best False lr [0.001]
training epoch 12 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best False lr [0.001]
training epoch 13 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.001]
training epoch 14 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 15 val accuracy 0.961 topk_dict {'top1': 0.961} is_best False lr [0.001]
training epoch 16 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.001]
training epoch 17 val accuracy 0.9614 topk_dict {'top1': 0.9614} is_best False lr [0.001]
training epoch 18 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best False lr [0.001]
training epoch 19 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best True lr [0.001]
training epoch 20 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.001]
training epoch 21 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.001]
training epoch 22 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 23 val accuracy 0.963 topk_dict {'top1': 0.963} is_best False lr [0.001]
training epoch 24 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.001]
training epoch 25 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.001]
training epoch 26 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.001]
training epoch 27 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.001]
training epoch 28 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.001]
training epoch 29 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
training epoch 30 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best False lr [0.001]
training epoch 31 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.001]
training epoch 32 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
training epoch 33 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 34 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
training epoch 35 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.001]
training epoch 36 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.001]
training epoch 37 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.001]
training epoch 38 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.001]
training epoch 39 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 40 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best False lr [0.001]
training epoch 41 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.001]
training epoch 42 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best False lr [0.001]
training epoch 43 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best False lr [0.001]
training epoch 44 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.001]
training epoch 45 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.001]
training epoch 46 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.001]
training epoch 47 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 48 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.001]
training epoch 49 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.968800)
finished training. finished 50 epochs. accuracy 0.9688 topk_dict {'top1': 0.9688}
