start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067571. All blocks and scores: [(32, 0.0675714211538434), (31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07914633490145206), (33, 0.08192148618400097), (28, 0.08897436503320932), (35, 0.09150646720081568), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16807220317423344), (39, 0.17391434125602245), (38, 0.17409800179302692), (40, 0.1747935749590397), (44, 0.17559202574193478), (42, 0.1763687338680029), (2, 0.17818448692560196), (43, 0.18028480000793934), (37, 0.1874171681702137), (45, 0.1913505643606186), (46, 0.19167010858654976), (16, 0.19186081551015377), (47, 0.1938924305140972), (0, 0.2014507930725813), (48, 0.2074642963707447), (49, 0.2087792381644249), (50, 0.2150480169802904), (51, 0.23200893960893154), (5, 0.23247346468269825), (52, 0.24538944847881794), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5694299265742302), (53, 0.5812843516469002)]
computing accuracy for after removing block 32 . block score: 0.0675714211538434
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075980. All blocks and scores: [(31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07963871583342552), (33, 0.08215188421308994), (28, 0.08897436503320932), (35, 0.09255937859416008), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16619791090488434), (38, 0.1706629153341055), (40, 0.17233950085937977), (44, 0.17322266846895218), (39, 0.17388461343944073), (42, 0.17525410652160645), (2, 0.17818448692560196), (43, 0.17904356308281422), (37, 0.18435736000537872), (46, 0.18958506174385548), (45, 0.1906456109136343), (16, 0.19186081551015377), (47, 0.19291129149496555), (0, 0.2014507930725813), (48, 0.2059937696903944), (49, 0.2078111693263054), (50, 0.2136209774762392), (51, 0.2316721361130476), (5, 0.23247346468269825), (52, 0.24407040141522884), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5649380832910538), (53, 0.5846557393670082)]
computing accuracy for after removing block 31 . block score: 0.07598021812736988
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076864. All blocks and scores: [(30, 0.07686383835971355), (34, 0.0803083973005414), (33, 0.0824452992528677), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.0937052397057414), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16335336491465569), (14, 0.16607324592769146), (38, 0.16689680889248848), (40, 0.16941766813397408), (44, 0.17088529095053673), (39, 0.173272417858243), (42, 0.17336755990982056), (2, 0.17818448692560196), (43, 0.17835192382335663), (37, 0.18097997643053532), (46, 0.18729917518794537), (45, 0.189705615863204), (47, 0.19152643717825413), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20431426540017128), (49, 0.20694035664200783), (50, 0.21236521005630493), (51, 0.23184024542570114), (5, 0.23247346468269825), (52, 0.24304170347750187), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5598013773560524), (53, 0.5874009430408478)]
computing accuracy for after removing block 30 . block score: 0.07686383835971355
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079782. All blocks and scores: [(34, 0.07978176791220903), (33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09433686546981335), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16367061622440815), (14, 0.16607324592769146), (38, 0.16689884662628174), (40, 0.1688882727175951), (44, 0.16993452981114388), (39, 0.17342626862227917), (42, 0.17362496629357338), (43, 0.1767871119081974), (2, 0.17818448692560196), (37, 0.18006489984691143), (46, 0.18585865385830402), (45, 0.1900129672139883), (47, 0.19076526165008545), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20426686480641365), (49, 0.20699637196958065), (50, 0.2116481103003025), (51, 0.23162324354052544), (5, 0.23247346468269825), (52, 0.24221924878656864), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5604959651827812), (53, 0.5873366072773933)]
computing accuracy for after removing block 34 . block score: 0.07978176791220903
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.082971. All blocks and scores: [(33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09587994497269392), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.1610505860298872), (38, 0.1633784919977188), (14, 0.16607324592769146), (40, 0.1664226781576872), (44, 0.1675016302615404), (39, 0.16972871869802475), (42, 0.17223737947642803), (43, 0.17614286206662655), (37, 0.17686635814607143), (2, 0.17818448692560196), (46, 0.1853218786418438), (45, 0.18889996781945229), (47, 0.18968128971755505), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20193634182214737), (49, 0.20599747449159622), (50, 0.21036292426288128), (51, 0.23076499067246914), (5, 0.23247346468269825), (52, 0.24034381844103336), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5582085475325584), (53, 0.5918786898255348)]
computing accuracy for after removing block 33 . block score: 0.08297098055481911
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088974. All blocks and scores: [(28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09792979713529348), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16093394719064236), (38, 0.16253862343728542), (40, 0.16475909017026424), (44, 0.1657320111989975), (14, 0.16607324592769146), (39, 0.17084676586091518), (42, 0.17239164374768734), (37, 0.1755716409534216), (43, 0.1766559574753046), (2, 0.17818448692560196), (46, 0.18369029462337494), (47, 0.1886796187609434), (45, 0.1887859608978033), (16, 0.19186081551015377), (48, 0.200510635972023), (0, 0.2014507930725813), (49, 0.20520283095538616), (50, 0.21048511005938053), (51, 0.23036987893283367), (5, 0.23247346468269825), (52, 0.2400742694735527), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5590175092220306), (53, 0.5941508710384369)]
computing accuracy for after removing block 28 . block score: 0.08897436503320932
removed block 28 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 29, with score 0.092993. All blocks and scores: [(29, 0.09299347456544638), (35, 0.09727451764047146), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (41, 0.1584145911037922), (38, 0.15931538119912148), (19, 0.16048101894557476), (40, 0.16139849461615086), (44, 0.1630945522338152), (14, 0.16607324592769146), (39, 0.16803736239671707), (42, 0.1694429162889719), (37, 0.17234843783080578), (43, 0.1741682682186365), (2, 0.17818448692560196), (46, 0.1812481377273798), (47, 0.18659634701907635), (45, 0.18721414916217327), (16, 0.19186081551015377), (48, 0.19773288257420063), (0, 0.2014507930725813), (49, 0.20365827158093452), (50, 0.20795450173318386), (51, 0.23072483390569687), (5, 0.23247346468269825), (52, 0.23914798349142075), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5534715801477432), (53, 0.5960394591093063)]
computing accuracy for after removing block 29 . block score: 0.09299347456544638
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 35, with score 0.097640. All blocks and scores: [(35, 0.09764033649116755), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (38, 0.15758545510470867), (41, 0.15850874595344067), (40, 0.15992066822946072), (19, 0.16048101894557476), (44, 0.16160862147808075), (14, 0.16607324592769146), (39, 0.16751116327941418), (42, 0.16799712739884853), (37, 0.17121368274092674), (43, 0.17230449058115482), (2, 0.17818448692560196), (46, 0.17956542409956455), (47, 0.18491259962320328), (45, 0.18708676286041737), (16, 0.19186081551015377), (48, 0.19660854898393154), (0, 0.2014507930725813), (49, 0.2031768523156643), (50, 0.2063173335045576), (51, 0.23135396651923656), (5, 0.23247346468269825), (52, 0.23885141499340534), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.553212895989418), (53, 0.5974615514278412)]
computing accuracy for after removing block 35 . block score: 0.09764033649116755
removed block 35 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.101230. All blocks and scores: [(7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (38, 0.15101215615868568), (12, 0.15166371688246727), (41, 0.15334330312907696), (9, 0.15344819612801075), (40, 0.1535834725946188), (20, 0.15513315983116627), (44, 0.15793277882039547), (39, 0.16038253344595432), (19, 0.16048101894557476), (42, 0.16383183747529984), (37, 0.1655605472624302), (14, 0.16607324592769146), (43, 0.16824672184884548), (46, 0.17675554379820824), (2, 0.17818448692560196), (47, 0.18043082021176815), (45, 0.18366640619933605), (48, 0.19039705023169518), (16, 0.19186081551015377), (49, 0.20057832263410091), (0, 0.2014507930725813), (50, 0.20306908525526524), (51, 0.22989932633936405), (5, 0.23247346468269825), (52, 0.23640884272754192), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5447516441345215), (53, 0.6041152253746986)]
computing accuracy for after removing block 7 . block score: 0.10122980084270239
removed block 7 current accuracy 0.9968 loss from initial  0.0031999999999999806
training start
training epoch 0 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 1 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 5 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 9
[activation mean]: block to remove picked: 8, with score 0.104459. All blocks and scores: [(8, 0.10445850435644388), (26, 0.10503296367824078), (6, 0.10997952427715063), (27, 0.11050623748451471), (25, 0.11307507660239935), (24, 0.1156278196722269), (23, 0.12042741850018501), (22, 0.12201852444559336), (11, 0.1259626504033804), (21, 0.1262211985886097), (4, 0.1270172530785203), (10, 0.12820925004780293), (13, 0.1332852840423584), (3, 0.14025522582232952), (1, 0.14234929345548153), (9, 0.15231466479599476), (12, 0.1524179968982935), (15, 0.15286962315440178), (20, 0.157014274969697), (19, 0.1613543163985014), (14, 0.1670234277844429), (41, 0.16784312576055527), (38, 0.171281598508358), (39, 0.17202652618288994), (40, 0.17327404581010342), (44, 0.17445899732410908), (42, 0.17604942433536053), (43, 0.1783947329968214), (2, 0.1794896498322487), (37, 0.1865990199148655), (45, 0.19002933613955975), (46, 0.19144565798342228), (16, 0.19165943935513496), (47, 0.19397583603858948), (0, 0.1989768072962761), (48, 0.2085474207997322), (49, 0.21037833765149117), (50, 0.21702812425792217), (5, 0.23141026310622692), (51, 0.23381096683442593), (52, 0.2469918690621853), (17, 0.31715379655361176), (18, 0.5304887294769287), (36, 0.5601129829883575), (53, 0.5662102922797203)]
computing accuracy for after removing block 8 . block score: 0.10445850435644388
removed block 8 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 26, with score 0.104773. All blocks and scores: [(26, 0.1047734310850501), (27, 0.1086144968867302), (6, 0.10997952427715063), (25, 0.11139801423996687), (24, 0.11273879464715719), (23, 0.11755013186484575), (22, 0.1204113932326436), (21, 0.12302321940660477), (4, 0.1270172530785203), (11, 0.12721742875874043), (10, 0.1280763428658247), (13, 0.13381854444742203), (3, 0.14025522582232952), (1, 0.14234929345548153), (12, 0.15184315480291843), (9, 0.15199013613164425), (15, 0.15266035683453083), (20, 0.15540947951376438), (19, 0.15860910713672638), (14, 0.16533153504133224), (41, 0.16541520319879055), (38, 0.1669660285115242), (39, 0.169600922614336), (40, 0.16984261758625507), (44, 0.1735083255916834), (42, 0.17491755075752735), (43, 0.17607907764613628), (2, 0.1794896498322487), (37, 0.18451047129929066), (45, 0.18807321228086948), (46, 0.18946628831326962), (16, 0.18971054069697857), (47, 0.19244898483157158), (0, 0.1989768072962761), (48, 0.20624740235507488), (49, 0.20992238260805607), (50, 0.21602430567145348), (5, 0.23141026310622692), (51, 0.23375924304127693), (52, 0.24651839584112167), (17, 0.3109767735004425), (18, 0.5228433981537819), (36, 0.554562009871006), (53, 0.5647976621985435)]
computing accuracy for after removing block 26 . block score: 0.1047734310850501
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 27, with score 0.106319. All blocks and scores: [(27, 0.1063188835978508), (6, 0.10997952427715063), (25, 0.11139801423996687), (24, 0.11273879464715719), (23, 0.11755013186484575), (22, 0.1204113932326436), (21, 0.12302321940660477), (4, 0.1270172530785203), (11, 0.12721742875874043), (10, 0.1280763428658247), (13, 0.13381854444742203), (3, 0.14025522582232952), (1, 0.14234929345548153), (12, 0.15184315480291843), (9, 0.15199013613164425), (15, 0.15266035683453083), (20, 0.15540947951376438), (19, 0.15860910713672638), (38, 0.16262405924499035), (41, 0.16358241252601147), (14, 0.16533153504133224), (40, 0.1660397257655859), (39, 0.1662796027958393), (44, 0.16975362598896027), (42, 0.1729215271770954), (43, 0.17323391884565353), (2, 0.1794896498322487), (37, 0.18004546500742435), (45, 0.18587525747716427), (46, 0.18623830191791058), (47, 0.18960370123386383), (16, 0.18971054069697857), (0, 0.1989768072962761), (48, 0.2016381323337555), (49, 0.2075848262757063), (50, 0.21362482756376266), (5, 0.23141026310622692), (51, 0.2335425764322281), (52, 0.24502885341644287), (17, 0.3109767735004425), (18, 0.5228433981537819), (36, 0.5528058707714081), (53, 0.5687090754508972)]
computing accuracy for after removing block 27 . block score: 0.1063188835978508
removed block 27 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.109980. All blocks and scores: [(6, 0.10997952427715063), (25, 0.11139801423996687), (24, 0.11273879464715719), (23, 0.11755013186484575), (22, 0.1204113932326436), (21, 0.12302321940660477), (4, 0.1270172530785203), (11, 0.12721742875874043), (10, 0.1280763428658247), (13, 0.13381854444742203), (3, 0.14025522582232952), (1, 0.14234929345548153), (12, 0.15184315480291843), (9, 0.15199013613164425), (15, 0.15266035683453083), (20, 0.15540947951376438), (38, 0.15822578966617584), (19, 0.15860910713672638), (41, 0.15989208221435547), (39, 0.16126376576721668), (40, 0.16249265894293785), (44, 0.16505550779402256), (14, 0.16533153504133224), (42, 0.16966057382524014), (43, 0.17003333568572998), (37, 0.17532906495034695), (2, 0.1794896498322487), (45, 0.18321444280445576), (46, 0.18406638503074646), (47, 0.18738522939383984), (16, 0.18971054069697857), (48, 0.19740072637796402), (0, 0.1989768072962761), (49, 0.20454984344542027), (50, 0.21006982773542404), (5, 0.23141026310622692), (51, 0.23278372548520565), (52, 0.24238044954836369), (17, 0.3109767735004425), (18, 0.5228433981537819), (36, 0.5461713075637817), (53, 0.5795023515820503)]
computing accuracy for after removing block 6 . block score: 0.10997952427715063
removed block 6 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.108792. All blocks and scores: [(24, 0.10879228729754686), (25, 0.1091586509719491), (23, 0.1136497175320983), (22, 0.11839519254863262), (21, 0.12021350208669901), (4, 0.1270172530785203), (11, 0.13008529506623745), (10, 0.1329061444848776), (13, 0.13860929757356644), (3, 0.14025522582232952), (1, 0.14234929345548153), (12, 0.15295687690377235), (20, 0.15335078164935112), (15, 0.1541900560259819), (9, 0.1547563634812832), (19, 0.1554243192076683), (38, 0.15630781091749668), (40, 0.15896783582866192), (41, 0.15915332920849323), (39, 0.15921175852417946), (44, 0.1641191989183426), (43, 0.1664087325334549), (42, 0.16737615875899792), (14, 0.16820343025028706), (37, 0.17386477068066597), (2, 0.1794896498322487), (45, 0.1809980794787407), (46, 0.18198784813284874), (47, 0.18456350080668926), (16, 0.18932783603668213), (48, 0.19466162472963333), (0, 0.1989768072962761), (49, 0.20324510894715786), (50, 0.20904737152159214), (5, 0.23141026310622692), (51, 0.2333054058253765), (52, 0.2419861201196909), (17, 0.3100201077759266), (18, 0.5156507641077042), (36, 0.5397390574216843), (53, 0.5770788565278053)]
computing accuracy for after removing block 24 . block score: 0.10879228729754686
removed block 24 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.109473. All blocks and scores: [(25, 0.10947331879287958), (23, 0.1136497175320983), (22, 0.11839519254863262), (21, 0.12021350208669901), (4, 0.1270172530785203), (11, 0.13008529506623745), (10, 0.1329061444848776), (13, 0.13860929757356644), (3, 0.14025522582232952), (1, 0.14234929345548153), (12, 0.15295687690377235), (20, 0.15335078164935112), (15, 0.1541900560259819), (38, 0.15419930592179298), (9, 0.1547563634812832), (19, 0.1554243192076683), (39, 0.1558055393397808), (41, 0.1559855006635189), (40, 0.1560258138924837), (44, 0.16080780141055584), (43, 0.1636668313294649), (42, 0.16460563801229), (14, 0.16820343025028706), (37, 0.17106397449970245), (45, 0.17882457002997398), (2, 0.1794896498322487), (46, 0.18023549020290375), (47, 0.18161889910697937), (16, 0.18932783603668213), (48, 0.19163803383708), (0, 0.1989768072962761), (49, 0.20093784667551517), (50, 0.20638121291995049), (5, 0.23141026310622692), (51, 0.2329177726060152), (52, 0.24016893468797207), (17, 0.3100201077759266), (18, 0.5156507641077042), (36, 0.5381095707416534), (53, 0.581471674144268)]
computing accuracy for after removing block 25 . block score: 0.10947331879287958
removed block 25 current accuracy 0.9922 loss from initial  0.007800000000000029
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.113650. All blocks and scores: [(23, 0.1136497175320983), (22, 0.11839519254863262), (21, 0.12021350208669901), (4, 0.1270172530785203), (11, 0.13008529506623745), (10, 0.1329061444848776), (13, 0.13860929757356644), (3, 0.14025522582232952), (1, 0.14234929345548153), (38, 0.14914245903491974), (39, 0.15075534209609032), (41, 0.1518653854727745), (40, 0.15193230472505093), (12, 0.15295687690377235), (20, 0.15335078164935112), (15, 0.1541900560259819), (9, 0.1547563634812832), (19, 0.1554243192076683), (44, 0.15781412459909916), (43, 0.1615928504616022), (42, 0.1618329919874668), (37, 0.16662412323057652), (14, 0.16820343025028706), (45, 0.1775191705673933), (46, 0.17823612317442894), (47, 0.17924488335847855), (2, 0.1794896498322487), (48, 0.18790526688098907), (16, 0.18932783603668213), (49, 0.19873307086527348), (0, 0.1989768072962761), (50, 0.2037225142121315), (5, 0.23141026310622692), (51, 0.23311458714306355), (52, 0.23897323571145535), (17, 0.3100201077759266), (18, 0.5156507641077042), (36, 0.5320902317762375), (53, 0.5842674374580383)]
computing accuracy for after removing block 23 . block score: 0.1136497175320983
removed block 23 current accuracy 0.9876 loss from initial  0.012399999999999967
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.118395. All blocks and scores: [(22, 0.11839519254863262), (21, 0.12021350208669901), (4, 0.1270172530785203), (11, 0.13008529506623745), (10, 0.1329061444848776), (13, 0.13860929757356644), (3, 0.14025522582232952), (1, 0.14234929345548153), (38, 0.1490126345306635), (41, 0.1504796538501978), (39, 0.15069441311061382), (40, 0.15090468898415565), (12, 0.15295687690377235), (20, 0.15335078164935112), (15, 0.1541900560259819), (9, 0.1547563634812832), (19, 0.1554243192076683), (44, 0.15633930265903473), (43, 0.15964565984904766), (42, 0.161368815228343), (37, 0.16667845286428928), (14, 0.16820343025028706), (46, 0.1761252749711275), (45, 0.17691759765148163), (47, 0.17725082859396935), (2, 0.1794896498322487), (48, 0.1863938570022583), (16, 0.18932783603668213), (49, 0.1974396463483572), (0, 0.1989768072962761), (50, 0.20301972143352032), (5, 0.23141026310622692), (51, 0.2332091871649027), (52, 0.23803852126002312), (17, 0.3100201077759266), (18, 0.5156507641077042), (36, 0.5313836112618446), (53, 0.5818050354719162)]
computing accuracy for after removing block 22 . block score: 0.11839519254863262
removed block 22 current accuracy 0.9806 loss from initial  0.019399999999999973
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.120214. All blocks and scores: [(21, 0.12021350208669901), (4, 0.1270172530785203), (11, 0.13008529506623745), (10, 0.1329061444848776), (13, 0.13860929757356644), (3, 0.14025522582232952), (1, 0.14234929345548153), (41, 0.1458448302000761), (38, 0.14605183713138103), (40, 0.14608533307909966), (39, 0.14686520025134087), (44, 0.15279774367809296), (12, 0.15295687690377235), (20, 0.15335078164935112), (15, 0.1541900560259819), (9, 0.1547563634812832), (19, 0.1554243192076683), (42, 0.1561255156993866), (43, 0.15657961927354336), (37, 0.16269045695662498), (14, 0.16820343025028706), (46, 0.17314313165843487), (47, 0.173383466899395), (45, 0.17404806800186634), (2, 0.1794896498322487), (48, 0.18079872988164425), (16, 0.18932783603668213), (49, 0.1941006500273943), (0, 0.1989768072962761), (50, 0.20091496407985687), (5, 0.23141026310622692), (51, 0.2336142659187317), (52, 0.2360579688102007), (17, 0.3100201077759266), (18, 0.5156507641077042), (36, 0.5213102400302887), (53, 0.5800345316529274)]
computing accuracy for after removing block 21 . block score: 0.12021350208669901
removed block 21 current accuracy 0.9674 loss from initial  0.03259999999999996
training start
training epoch 0 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 1 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 2 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 3 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 4 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 5 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 6 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 7 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 8 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 9 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 10 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 11 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 12 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 13 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 14 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 15 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 16 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 17 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 18 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 19 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 20 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 21 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 22 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 23 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 24 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 25 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 26 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 27 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 28 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 29 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 31 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 32 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 33 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 34 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 35 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 36 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 37 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 38 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 39 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 40 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 41 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 42 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 43 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 44 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 45 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 46 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 47 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 48 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 49 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.997600)
finished training. finished 50 epochs. accuracy 0.9976 topk_dict {'top1': 0.9976}
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.128684. All blocks and scores: [(11, 0.1286839973181486), (4, 0.13232588209211826), (10, 0.13379162922501564), (1, 0.13569039106369019), (13, 0.13667595572769642), (3, 0.14505047351121902), (9, 0.14974143728613853), (12, 0.15750776417553425), (15, 0.1590724103152752), (41, 0.16762049682438374), (14, 0.1723084356635809), (39, 0.1723969504237175), (38, 0.17304011434316635), (44, 0.17326027527451515), (42, 0.1738339066505432), (40, 0.17415594682097435), (43, 0.1769008208066225), (2, 0.17774109169840813), (37, 0.18658938817679882), (45, 0.18895559757947922), (19, 0.18964669108390808), (20, 0.1898992396891117), (0, 0.19070437364280224), (46, 0.19129091687500477), (47, 0.19329730980098248), (16, 0.19357195124030113), (48, 0.2085789479315281), (49, 0.20887518487870693), (50, 0.21551517397165298), (51, 0.23194634914398193), (5, 0.23377575911581516), (52, 0.24549468234181404), (17, 0.31350603699684143), (18, 0.5236289575695992), (36, 0.5655737966299057), (53, 0.5774487033486366)]
computing accuracy for after removing block 11 . block score: 0.1286839973181486
removed block 11 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 4, with score 0.132326. All blocks and scores: [(4, 0.13232588209211826), (10, 0.13379162922501564), (1, 0.13569039106369019), (13, 0.14133747853338718), (3, 0.14505047351121902), (9, 0.14974143728613853), (12, 0.15940785966813564), (15, 0.16235882975161076), (41, 0.16607937961816788), (38, 0.16680367663502693), (40, 0.16869739070534706), (39, 0.17046712338924408), (42, 0.17078028433024883), (44, 0.17288570664823055), (14, 0.1739865466952324), (43, 0.1744454000145197), (2, 0.17774109169840813), (37, 0.18241500481963158), (19, 0.1848101858049631), (45, 0.18514011055231094), (20, 0.18629803881049156), (46, 0.18711638823151588), (0, 0.19070437364280224), (47, 0.19248518161475658), (16, 0.19672862067818642), (48, 0.20572823099792004), (49, 0.20652700029313564), (50, 0.21420792490243912), (51, 0.2318834699690342), (5, 0.23377575911581516), (52, 0.24447541497647762), (17, 0.31045183911919594), (18, 0.5176148638129234), (36, 0.5624116957187653), (53, 0.5814691781997681)]
computing accuracy for after removing block 4 . block score: 0.13232588209211826
removed block 4 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 10, with score 0.134476. All blocks and scores: [(10, 0.13447633758187294), (1, 0.13569039106369019), (13, 0.14239019341766834), (3, 0.14505047351121902), (9, 0.14661617018282413), (12, 0.16086577996611595), (38, 0.16149921715259552), (15, 0.16229147091507912), (41, 0.1628070343285799), (40, 0.1663521397858858), (39, 0.16851860284805298), (42, 0.1690803449600935), (43, 0.17020133696496487), (44, 0.17283953726291656), (14, 0.17381357587873936), (37, 0.17765111476182938), (2, 0.17774109169840813), (19, 0.1809268221259117), (20, 0.1824590526521206), (45, 0.18274266086518764), (46, 0.18600350245833397), (0, 0.19070437364280224), (47, 0.19119421020150185), (16, 0.19611473754048347), (48, 0.20324606448411942), (49, 0.20527550391852856), (50, 0.21108331345021725), (51, 0.2311879638582468), (5, 0.2342727780342102), (52, 0.24215492606163025), (17, 0.3082747794687748), (18, 0.5123739168047905), (36, 0.554874561727047), (53, 0.5846657976508141)]
computing accuracy for after removing block 10 . block score: 0.13447633758187294
removed block 10 current accuracy 0.9892 loss from initial  0.010800000000000032
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 1, with score 0.135690. All blocks and scores: [(1, 0.13569039106369019), (13, 0.13992219045758247), (3, 0.14505047351121902), (9, 0.14661617018282413), (38, 0.15264244377613068), (41, 0.1572955958545208), (40, 0.15806535258889198), (12, 0.16158133372664452), (39, 0.16309930942952633), (42, 0.16464127600193024), (15, 0.16472477838397026), (43, 0.1649304162710905), (44, 0.16861148923635483), (37, 0.17004629969596863), (19, 0.17322582378983498), (14, 0.17371704801917076), (20, 0.17686637304723263), (45, 0.1775356288999319), (2, 0.17774109169840813), (46, 0.18210803717374802), (47, 0.18738338351249695), (0, 0.19070437364280224), (16, 0.19482695311307907), (48, 0.19725420325994492), (49, 0.2017288263887167), (50, 0.20750590600073338), (51, 0.23084001056849957), (5, 0.2342727780342102), (52, 0.23990998230874538), (17, 0.30296919494867325), (18, 0.5028631836175919), (36, 0.5390775129199028), (53, 0.5884574055671692)]
computing accuracy for after removing block 1 . block score: 0.13569039106369019
removed block 1 current accuracy 0.9866 loss from initial  0.013399999999999967
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 13, with score 0.144071. All blocks and scores: [(13, 0.1440706867724657), (3, 0.1465687844902277), (9, 0.14725990034639835), (38, 0.1499280035495758), (41, 0.15353356301784515), (40, 0.1562732309103012), (39, 0.1605497021228075), (12, 0.1622729729861021), (43, 0.1631119716912508), (42, 0.16333139687776566), (15, 0.16536257974803448), (44, 0.16710579209029675), (37, 0.1672919038683176), (19, 0.17119021527469158), (20, 0.17306395061314106), (14, 0.17379946447908878), (45, 0.17620321922004223), (2, 0.17774003371596336), (46, 0.18142425268888474), (47, 0.18696242943406105), (0, 0.19070437364280224), (16, 0.19373933039605618), (48, 0.1951945535838604), (49, 0.20196115784347057), (50, 0.20644926093518734), (51, 0.2305746916681528), (5, 0.23221122846007347), (52, 0.23837293684482574), (17, 0.29961349815130234), (18, 0.49624738842248917), (36, 0.5331881269812584), (53, 0.5915175974369049)]
computing accuracy for after removing block 13 . block score: 0.1440706867724657
removed block 13 current accuracy 0.975 loss from initial  0.025000000000000022
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 3, with score 0.146569. All blocks and scores: [(3, 0.1465687844902277), (38, 0.147103201597929), (9, 0.14725990034639835), (41, 0.14989560842514038), (40, 0.15243124403059483), (39, 0.15815855003893375), (43, 0.16044832579791546), (42, 0.1607031412422657), (12, 0.1622729729861021), (37, 0.16441581770777702), (44, 0.16612124629318714), (15, 0.16784785315394402), (19, 0.1684933379292488), (20, 0.16913317702710629), (45, 0.1724864412099123), (2, 0.17774003371596336), (14, 0.17873580753803253), (46, 0.1788428220897913), (47, 0.1838429719209671), (48, 0.19010525569319725), (0, 0.19070437364280224), (16, 0.19809735752642155), (49, 0.19831402599811554), (50, 0.20386620610952377), (51, 0.23035171069204807), (5, 0.23221122846007347), (52, 0.23588638380169868), (17, 0.3018764890730381), (18, 0.49105605110526085), (36, 0.5294846892356873), (53, 0.5938353985548019)]
computing accuracy for after removing block 3 . block score: 0.1465687844902277
removed block 3 current accuracy 0.94 loss from initial  0.06000000000000005
since last training loss: 0.057600000000000096 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 41, with score 0.140776. All blocks and scores: [(41, 0.140776377171278), (38, 0.14161823131144047), (40, 0.14471939951181412), (9, 0.14599332213401794), (39, 0.15024080872535706), (43, 0.15131687559187412), (42, 0.15373042225837708), (37, 0.15679156966507435), (12, 0.1610571350902319), (44, 0.16127729043364525), (20, 0.16129533015191555), (19, 0.16145551949739456), (45, 0.1658372264355421), (15, 0.17021569050848484), (46, 0.17421233840286732), (2, 0.17774003371596336), (47, 0.1780271902680397), (14, 0.18033180572092533), (48, 0.1810441929847002), (0, 0.19070437364280224), (49, 0.19443094357848167), (16, 0.19587728939950466), (50, 0.19914915226399899), (51, 0.22816103138029575), (52, 0.230268195271492), (5, 0.23481006547808647), (17, 0.29287947714328766), (18, 0.47714410349726677), (36, 0.5112817510962486), (53, 0.5983378738164902)]
computing accuracy for after removing block 41 . block score: 0.140776377171278
removed block 41 current accuracy 0.9298 loss from initial  0.07020000000000004
since last training loss: 0.06780000000000008 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 38, with score 0.141618. All blocks and scores: [(38, 0.14161823131144047), (40, 0.14471939951181412), (9, 0.14599332213401794), (43, 0.14666534028947353), (42, 0.14865518733859062), (39, 0.15024080872535706), (44, 0.1561531461775303), (37, 0.15679156966507435), (45, 0.16008410416543484), (12, 0.1610571350902319), (20, 0.16129533015191555), (19, 0.16145551949739456), (15, 0.17021569050848484), (46, 0.17233427427709103), (47, 0.17434638366103172), (48, 0.176908103749156), (2, 0.17774003371596336), (14, 0.18033180572092533), (49, 0.18972452357411385), (0, 0.19070437364280224), (50, 0.19541138596832752), (16, 0.19587728939950466), (51, 0.22535556368529797), (52, 0.22680891677737236), (5, 0.23481006547808647), (17, 0.29287947714328766), (18, 0.47714410349726677), (36, 0.5112817510962486), (53, 0.6253236308693886)]
computing accuracy for after removing block 38 . block score: 0.14161823131144047
removed block 38 current accuracy 0.9116 loss from initial  0.08840000000000003
since last training loss: 0.08600000000000008 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.143001. All blocks and scores: [(40, 0.14300082810223103), (43, 0.14381918497383595), (42, 0.14556101523339748), (9, 0.14599332213401794), (44, 0.1465351488441229), (39, 0.14786195196211338), (45, 0.1548283938318491), (37, 0.15679156966507435), (12, 0.1610571350902319), (20, 0.16129533015191555), (19, 0.16145551949739456), (46, 0.16798334009945393), (15, 0.17021569050848484), (47, 0.17112966813147068), (48, 0.17119577527046204), (2, 0.17774003371596336), (14, 0.18033180572092533), (49, 0.18566764518618584), (0, 0.19070437364280224), (50, 0.19101217575371265), (16, 0.19587728939950466), (52, 0.22277757711708546), (51, 0.22549883648753166), (5, 0.23481006547808647), (17, 0.29287947714328766), (18, 0.47714410349726677), (36, 0.5112817510962486), (53, 0.6242020651698112)]
computing accuracy for after removing block 40 . block score: 0.14300082810223103
removed block 40 current accuracy 0.8854 loss from initial  0.11460000000000004
training start
training epoch 0 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 1 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 2 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 3 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
training epoch 4 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best False lr [0.001]
training epoch 5 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 6 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 7 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 8 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 9 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 10 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 11 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 12 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 13 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 14 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 15 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 16 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 17 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 18 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 19 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 20 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 22 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 23 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 24 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 25 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 26 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 27 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 28 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 29 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 30 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 32 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 33 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 34 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 35 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 36 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 37 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 38 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 39 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 40 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 41 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 42 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 43 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 44 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 45 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 46 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 47 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 48 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 49 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.993600)
finished training. finished 50 epochs. accuracy 0.9936 topk_dict {'top1': 0.9936}
start iteration 27
[activation mean]: block to remove picked: 15, with score 0.162118. All blocks and scores: [(15, 0.16211813874542713), (9, 0.1639949306845665), (12, 0.1699875146150589), (14, 0.1710248813033104), (44, 0.17469664476811886), (43, 0.18128161132335663), (42, 0.1816210076212883), (16, 0.18574092723429203), (39, 0.18705055862665176), (45, 0.1887081228196621), (46, 0.1910182312130928), (0, 0.1915296670049429), (47, 0.19373693503439426), (2, 0.19396882504224777), (37, 0.2006609309464693), (19, 0.20617001689970493), (48, 0.20676255226135254), (49, 0.20871303416788578), (20, 0.20926408097147942), (50, 0.2135448195040226), (51, 0.23058700934052467), (52, 0.24319100379943848), (5, 0.24923206493258476), (17, 0.29034654796123505), (18, 0.5078482255339622), (36, 0.5528031885623932), (53, 0.5909248813986778)]
computing accuracy for after removing block 15 . block score: 0.16211813874542713
removed block 15 current accuracy 0.9856 loss from initial  0.014399999999999968
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 9, with score 0.163995. All blocks and scores: [(9, 0.1639949306845665), (44, 0.16810770891606808), (12, 0.1699875146150589), (14, 0.1710248813033104), (43, 0.1755293495953083), (42, 0.1761972289532423), (39, 0.17663702927529812), (45, 0.18231059983372688), (47, 0.1832626312971115), (46, 0.18465188704431057), (37, 0.18911807239055634), (0, 0.1915296670049429), (2, 0.19396882504224777), (48, 0.1965288333594799), (19, 0.19846280477941036), (20, 0.2020096629858017), (16, 0.20242249593138695), (49, 0.20330817252397537), (50, 0.20522350259125233), (51, 0.2290090061724186), (52, 0.23895697109401226), (5, 0.24923206493258476), (17, 0.2905518636107445), (18, 0.49162662774324417), (36, 0.5393429398536682), (53, 0.5881641060113907)]
computing accuracy for after removing block 9 . block score: 0.1639949306845665
removed block 9 current accuracy 0.968 loss from initial  0.03200000000000003
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 44, with score 0.159943. All blocks and scores: [(44, 0.1599432285875082), (14, 0.16599896363914013), (43, 0.1669182926416397), (39, 0.16835033521056175), (42, 0.17096804827451706), (45, 0.1729296687990427), (12, 0.17394446581602097), (46, 0.1759470533579588), (47, 0.17672625370323658), (37, 0.1798427551984787), (48, 0.1842909175902605), (20, 0.18480894155800343), (19, 0.1863914653658867), (16, 0.18849505484104156), (0, 0.1915296670049429), (2, 0.19396882504224777), (50, 0.1994204092770815), (49, 0.2012387253344059), (51, 0.22699296846985817), (52, 0.23397301509976387), (5, 0.24923206493258476), (17, 0.26675114780664444), (18, 0.4753207378089428), (36, 0.5313478857278824), (53, 0.5962705239653587)]
computing accuracy for after removing block 44 . block score: 0.1599432285875082
removed block 44 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 14, with score 0.165999. All blocks and scores: [(14, 0.16599896363914013), (43, 0.1669182926416397), (39, 0.16835033521056175), (45, 0.16838640347123146), (42, 0.17096804827451706), (46, 0.17305382154881954), (12, 0.17394446581602097), (47, 0.17640750110149384), (37, 0.1798427551984787), (48, 0.18200206197798252), (20, 0.18480894155800343), (19, 0.1863914653658867), (16, 0.18849505484104156), (0, 0.1915296670049429), (2, 0.19396882504224777), (50, 0.19779540598392487), (49, 0.1992230098694563), (51, 0.22472592815756798), (52, 0.23146195895969868), (5, 0.24923206493258476), (17, 0.26675114780664444), (18, 0.4753207378089428), (36, 0.5313478857278824), (53, 0.6286318749189377)]
computing accuracy for after removing block 14 . block score: 0.16599896363914013
removed block 14 current accuracy 0.8686 loss from initial  0.13139999999999996
since last training loss: 0.125 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 43, with score 0.161188. All blocks and scores: [(43, 0.16118806414306164), (45, 0.1612858958542347), (39, 0.16221887432038784), (42, 0.16275600530207157), (47, 0.1653939988464117), (48, 0.1689909566193819), (46, 0.16926896944642067), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (16, 0.18884550407528877), (0, 0.1915296670049429), (50, 0.19303682819008827), (49, 0.19395592994987965), (2, 0.19396882504224777), (51, 0.2226187326014042), (52, 0.22753926552832127), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.6148838251829147)]
computing accuracy for after removing block 43 . block score: 0.16118806414306164
removed block 43 current accuracy 0.8374 loss from initial  0.16259999999999997
since last training loss: 0.1562 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 45, with score 0.154259. All blocks and scores: [(45, 0.15425938554108143), (47, 0.1621821578592062), (39, 0.16221887432038784), (42, 0.16275600530207157), (48, 0.16684855334460735), (46, 0.16854791529476643), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (16, 0.18884550407528877), (50, 0.18939824402332306), (0, 0.1915296670049429), (49, 0.19200588390231133), (2, 0.19396882504224777), (51, 0.21996955573558807), (52, 0.22282420098781586), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.6538203656673431)]
computing accuracy for after removing block 45 . block score: 0.15425938554108143
removed block 45 current accuracy 0.7862 loss from initial  0.2138
since last training loss: 0.20740000000000003 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 47, with score 0.159274. All blocks and scores: [(47, 0.1592742409557104), (46, 0.16213826090097427), (39, 0.16221887432038784), (42, 0.16275600530207157), (48, 0.16475635580718517), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (50, 0.18657817505300045), (16, 0.18884550407528877), (49, 0.18981731124222279), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.21633555553853512), (52, 0.21959864161908627), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.6944385841488838)]
computing accuracy for after removing block 47 . block score: 0.1592742409557104
removed block 47 current accuracy 0.7388 loss from initial  0.2612
since last training loss: 0.2548 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 46, with score 0.162138. All blocks and scores: [(46, 0.16213826090097427), (39, 0.16221887432038784), (42, 0.16275600530207157), (48, 0.16355807520449162), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (50, 0.18590676970779896), (16, 0.18884550407528877), (49, 0.1895597819238901), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.21154391393065453), (52, 0.21751857548952103), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.7548106610774994)]
computing accuracy for after removing block 46 . block score: 0.16213826090097427
removed block 46 current accuracy 0.677 loss from initial  0.32299999999999995
since last training loss: 0.3166 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 48, with score 0.159693. All blocks and scores: [(48, 0.15969265438616276), (39, 0.16221887432038784), (42, 0.16275600530207157), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (50, 0.18152786046266556), (49, 0.18611755035817623), (16, 0.18884550407528877), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.20841746404767036), (52, 0.21426876448094845), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.8277493342757225)]
computing accuracy for after removing block 48 . block score: 0.15969265438616276
removed block 48 current accuracy 0.5836 loss from initial  0.4164
since last training loss: 0.41000000000000003 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 39, with score 0.162219. All blocks and scores: [(39, 0.16221887432038784), (42, 0.16275600530207157), (20, 0.17218106612563133), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (50, 0.17642179690301418), (49, 0.18204008042812347), (16, 0.18884550407528877), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.2064807377755642), (52, 0.21149461530148983), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.9219396337866783)]
computing accuracy for after removing block 39 . block score: 0.16221887432038784
removed block 39 current accuracy 0.5108 loss from initial  0.48919999999999997
since last training loss: 0.4828 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 42, with score 0.163585. All blocks and scores: [(42, 0.16358504816889763), (20, 0.17218106612563133), (50, 0.1735012587159872), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (49, 0.17946326546370983), (16, 0.18884550407528877), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.2053216528147459), (52, 0.20845473557710648), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 0.9570124000310898)]
computing accuracy for after removing block 42 . block score: 0.16358504816889763
removed block 42 current accuracy 0.4338 loss from initial  0.5662
since last training loss: 0.5598000000000001 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 20, with score 0.172181. All blocks and scores: [(20, 0.17218106612563133), (50, 0.17267761565744877), (12, 0.17394446581602097), (37, 0.1751385573297739), (19, 0.17630484141409397), (49, 0.17665509320795536), (16, 0.18884550407528877), (0, 0.1915296670049429), (2, 0.19396882504224777), (51, 0.2033054120838642), (52, 0.20566445961594582), (5, 0.24923206493258476), (17, 0.2628231532871723), (18, 0.45960813760757446), (36, 0.5251103863120079), (53, 1.0641106963157654)]
computing accuracy for after removing block 20 . block score: 0.17218106612563133
removed block 20 current accuracy 0.3758 loss from initial  0.6242
training start
training epoch 0 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 1 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 2 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 3 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 4 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 5 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 6 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 7 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 8 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 9 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 10 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 12 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 13 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 14 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.001]
training epoch 15 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.001]
training epoch 16 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 17 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 18 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best True lr [0.001]
training epoch 19 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 20 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 21 val accuracy 0.956 topk_dict {'top1': 0.956} is_best True lr [0.001]
training epoch 22 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 23 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.001]
training epoch 24 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.001]
training epoch 25 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.001]
training epoch 26 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.001]
training epoch 27 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.001]
training epoch 28 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 29 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.001]
training epoch 30 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.001]
training epoch 31 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best True lr [0.001]
training epoch 32 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best False lr [0.001]
training epoch 33 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best False lr [0.001]
training epoch 34 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.001]
training epoch 35 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.001]
training epoch 36 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.001]
training epoch 37 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.001]
training epoch 38 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.001]
training epoch 39 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 40 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.001]
training epoch 41 val accuracy 0.9596 topk_dict {'top1': 0.9596} is_best False lr [0.001]
training epoch 42 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 43 val accuracy 0.9572 topk_dict {'top1': 0.9572} is_best False lr [0.001]
training epoch 44 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.001]
training epoch 45 val accuracy 0.958 topk_dict {'top1': 0.958} is_best False lr [0.001]
training epoch 46 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best True lr [0.001]
training epoch 47 val accuracy 0.959 topk_dict {'top1': 0.959} is_best False lr [0.001]
training epoch 48 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best False lr [0.001]
training epoch 49 val accuracy 0.9598 topk_dict {'top1': 0.9598} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.960600)
finished training. finished 50 epochs. accuracy 0.9606 topk_dict {'top1': 0.9606}
