start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 14 . block score: 0.041135866194963455
removed block 14 current accuracy 0.9892 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 1 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 3 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (21, 0.042286552488803864), (22, 0.04320579580962658), (24, 0.041739555075764656), (27, 0.04288004711270332), (28, 0.04460081830620766), (29, 0.04215801693499088), (30, 0.04119028337299824), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (39, 0.04192705452442169), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 30 . block score: 0.04119028337299824
removed block 30 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (21, 0.042286552488803864), (22, 0.04320579580962658), (24, 0.041739555075764656), (27, 0.04288004711270332), (28, 0.04460081830620766), (29, 0.04215801693499088), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (39, 0.04192705452442169), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 24 . block score: 0.041739555075764656
removed block 24 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (21, 0.042286552488803864), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (29, 0.04215801693499088), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (39, 0.04192705452442169), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 39 . block score: 0.04192705452442169
removed block 39 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (21, 0.042286552488803864), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (29, 0.04215801693499088), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 29 . block score: 0.04215801693499088
removed block 29 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (21, 0.042286552488803864), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 21 . block score: 0.042286552488803864
removed block 21 current accuracy 0.9832 loss from initial  0.016800000000000037
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (38, 0.042328130453825), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 38 . block score: 0.042328130453825
removed block 38 current accuracy 0.9762 loss from initial  0.023800000000000043
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (40, 0.04257964342832565), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 40 . block score: 0.04257964342832565
removed block 40 current accuracy 0.9676 loss from initial  0.032399999999999984
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (19, 0.042842186987400055), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 19 . block score: 0.042842186987400055
removed block 19 current accuracy 0.9602 loss from initial  0.03979999999999995
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09961752966046333), (1, 0.07690957561135292), (2, 0.09128319099545479), (3, 0.08159225434064865), (4, 0.07531822845339775), (5, 0.07022538781166077), (6, 0.07726943120360374), (7, 0.06110876239836216), (8, 0.05758648365736008), (9, 0.062201352789998055), (10, 0.0627991147339344), (11, 0.05197411775588989), (12, 0.06421051733195782), (13, 0.06734931655228138), (15, 0.06073184683918953), (16, 0.05038299225270748), (17, 0.0526315625756979), (18, 0.2097112201154232), (22, 0.04320579580962658), (27, 0.04288004711270332), (28, 0.04460081830620766), (33, 0.04284477047622204), (36, 0.1597321517765522), (37, 0.04316447675228119), (41, 0.043087245896458626), (42, 0.04431580752134323), (43, 0.04485156200826168), (44, 0.04417935572564602), (45, 0.04624631628394127), (46, 0.049001339823007584), (47, 0.05076947808265686), (48, 0.04801534675061703), (49, 0.04977915436029434), (50, 0.04738780856132507), (51, 0.04511077515780926), (52, 0.04383425414562225), (53, 0.05194658786058426)]
computing accuracy for after removing block 33 . block score: 0.04284477047622204
removed block 33 current accuracy 0.9484 loss from initial  0.05159999999999998
training start
training epoch 0 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 1 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 2 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 3 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 4 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 5 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 6 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 7 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 8 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 9 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 10 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 11 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 12 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 13 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 14 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 15 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 16 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 17 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 18 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 19 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 20 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 21 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 22 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 23 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 24 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 25 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 26 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 27 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 28 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 29 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 30 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 31 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 32 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 33 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 34 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 35 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 36 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 37 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 38 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 39 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 40 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 41 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 42 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 43 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 44 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 45 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 46 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 47 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 48 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 49 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (22, 0.042635057121515274), (27, 0.04230801947414875), (28, 0.04407171718776226), (36, 0.15722611919045448), (37, 0.04252489656209946), (41, 0.04244883917272091), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (52, 0.0432027205824852), (53, 0.05116980895400047)]
computing accuracy for after removing block 27 . block score: 0.04230801947414875
removed block 27 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (22, 0.042635057121515274), (28, 0.04407171718776226), (36, 0.15722611919045448), (37, 0.04252489656209946), (41, 0.04244883917272091), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (52, 0.0432027205824852), (53, 0.05116980895400047)]
computing accuracy for after removing block 41 . block score: 0.04244883917272091
removed block 41 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (22, 0.042635057121515274), (28, 0.04407171718776226), (36, 0.15722611919045448), (37, 0.04252489656209946), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (52, 0.0432027205824852), (53, 0.05116980895400047)]
computing accuracy for after removing block 37 . block score: 0.04252489656209946
removed block 37 current accuracy 0.9836 loss from initial  0.01639999999999997
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (22, 0.042635057121515274), (28, 0.04407171718776226), (36, 0.15722611919045448), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (52, 0.0432027205824852), (53, 0.05116980895400047)]
computing accuracy for after removing block 22 . block score: 0.042635057121515274
removed block 22 current accuracy 0.9628 loss from initial  0.03720000000000001
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (28, 0.04407171718776226), (36, 0.15722611919045448), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (52, 0.0432027205824852), (53, 0.05116980895400047)]
computing accuracy for after removing block 52 . block score: 0.0432027205824852
removed block 52 current accuracy 0.9232 loss from initial  0.07679999999999998
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (28, 0.04407171718776226), (36, 0.15722611919045448), (42, 0.043683331459760666), (43, 0.04419675096869469), (44, 0.043544938787817955), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (53, 0.05116980895400047)]
computing accuracy for after removing block 44 . block score: 0.043544938787817955
removed block 44 current accuracy 0.905 loss from initial  0.09499999999999997
since last training loss: 0.09360000000000002 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (28, 0.04407171718776226), (36, 0.15722611919045448), (42, 0.043683331459760666), (43, 0.04419675096869469), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (53, 0.05116980895400047)]
computing accuracy for after removing block 42 . block score: 0.043683331459760666
removed block 42 current accuracy 0.8726 loss from initial  0.12739999999999996
since last training loss: 0.126 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (28, 0.04407171718776226), (36, 0.15722611919045448), (43, 0.04419675096869469), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (53, 0.05116980895400047)]
computing accuracy for after removing block 28 . block score: 0.04407171718776226
removed block 28 current accuracy 0.783 loss from initial  0.21699999999999997
since last training loss: 0.2156 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09819430112838745), (1, 0.07579800114035606), (2, 0.08999014273285866), (3, 0.08040915802121162), (4, 0.0742785632610321), (5, 0.06922250613570213), (6, 0.07612296938896179), (7, 0.06028147041797638), (8, 0.05676577053964138), (9, 0.06133643165230751), (10, 0.0619024783372879), (11, 0.0512385256588459), (12, 0.06333117187023163), (13, 0.0664728619158268), (15, 0.05991381034255028), (16, 0.04979342222213745), (17, 0.05201268196105957), (18, 0.20654341205954552), (36, 0.15722611919045448), (43, 0.04419675096869469), (45, 0.045578258112072945), (46, 0.048290107399225235), (47, 0.050039609894156456), (48, 0.047328345477581024), (49, 0.04907546378672123), (50, 0.04669867642223835), (51, 0.04445277899503708), (53, 0.05116980895400047)]
computing accuracy for after removing block 43 . block score: 0.04419675096869469
removed block 43 current accuracy 0.7402 loss from initial  0.25980000000000003
training start
training epoch 0 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.001]
training epoch 1 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.001]
training epoch 2 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.001]
training epoch 3 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best True lr [0.001]
training epoch 4 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.001]
training epoch 5 val accuracy 0.968 topk_dict {'top1': 0.968} is_best True lr [0.001]
training epoch 6 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.001]
training epoch 7 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.001]
training epoch 8 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best True lr [0.001]
training epoch 9 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.001]
training epoch 10 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 11 val accuracy 0.971 topk_dict {'top1': 0.971} is_best True lr [0.001]
training epoch 12 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.001]
training epoch 13 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best True lr [0.001]
training epoch 14 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.001]
training epoch 15 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 16 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 17 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best True lr [0.001]
training epoch 18 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 19 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 20 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 21 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.001]
training epoch 22 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best True lr [0.001]
training epoch 23 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.001]
training epoch 24 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.001]
training epoch 25 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best True lr [0.001]
training epoch 26 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.001]
training epoch 27 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 28 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 29 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.001]
training epoch 30 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 32 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 33 val accuracy 0.977 topk_dict {'top1': 0.977} is_best True lr [0.001]
training epoch 34 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 35 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 36 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 37 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 38 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 39 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 40 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 41 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 42 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 43 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 44 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 45 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 46 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 47 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 48 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 49 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.977000)
finished training. finished 50 epochs. accuracy 0.977 topk_dict {'top1': 0.977}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (45, 0.04520203731954098), (46, 0.04786710627377033), (47, 0.04962829686701298), (48, 0.04694233648478985), (49, 0.048651207238435745), (50, 0.04630072042346001), (51, 0.04410135932266712), (53, 0.050655074417591095)]
computing accuracy for after removing block 51 . block score: 0.04410135932266712
removed block 51 current accuracy 0.951 loss from initial  0.049000000000000044
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (45, 0.04520203731954098), (46, 0.04786710627377033), (47, 0.04962829686701298), (48, 0.04694233648478985), (49, 0.048651207238435745), (50, 0.04630072042346001), (53, 0.050655074417591095)]
computing accuracy for after removing block 45 . block score: 0.04520203731954098
removed block 45 current accuracy 0.9232 loss from initial  0.07679999999999998
since last training loss: 0.05379999999999996 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (46, 0.04786710627377033), (47, 0.04962829686701298), (48, 0.04694233648478985), (49, 0.048651207238435745), (50, 0.04630072042346001), (53, 0.050655074417591095)]
computing accuracy for after removing block 50 . block score: 0.04630072042346001
removed block 50 current accuracy 0.8708 loss from initial  0.12919999999999998
since last training loss: 0.10619999999999996 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (46, 0.04786710627377033), (47, 0.04962829686701298), (48, 0.04694233648478985), (49, 0.048651207238435745), (53, 0.050655074417591095)]
computing accuracy for after removing block 48 . block score: 0.04694233648478985
removed block 48 current accuracy 0.7712 loss from initial  0.2288
since last training loss: 0.20579999999999998 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (46, 0.04786710627377033), (47, 0.04962829686701298), (49, 0.048651207238435745), (53, 0.050655074417591095)]
computing accuracy for after removing block 46 . block score: 0.04786710627377033
removed block 46 current accuracy 0.6516 loss from initial  0.34840000000000004
since last training loss: 0.3254 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (47, 0.04962829686701298), (49, 0.048651207238435745), (53, 0.050655074417591095)]
computing accuracy for after removing block 49 . block score: 0.048651207238435745
removed block 49 current accuracy 0.5628 loss from initial  0.43720000000000003
since last training loss: 0.4142 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (47, 0.04962829686701298), (53, 0.050655074417591095)]
computing accuracy for after removing block 47 . block score: 0.04962829686701298
removed block 47 current accuracy 0.4454 loss from initial  0.5546
since last training loss: 0.5316 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (16, 0.04979441687464714), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (53, 0.050655074417591095)]
computing accuracy for after removing block 16 . block score: 0.04979441687464714
removed block 16 current accuracy 0.4256 loss from initial  0.5744
since last training loss: 0.5514 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788), (53, 0.050655074417591095)]
computing accuracy for after removing block 53 . block score: 0.050655074417591095
removed block 53 current accuracy 0.3474 loss from initial  0.6526000000000001
since last training loss: 0.6295999999999999 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (11, 0.05078386515378952), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788)]
computing accuracy for after removing block 11 . block score: 0.05078386515378952
removed block 11 current accuracy 0.345 loss from initial  0.655
since last training loss: 0.632 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (17, 0.051846494898200035), (18, 0.20452606678009033), (36, 0.1556040607392788)]
computing accuracy for after removing block 17 . block score: 0.051846494898200035
removed block 17 current accuracy 0.3324 loss from initial  0.6676
since last training loss: 0.6446000000000001 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(0, 0.09738633409142494), (1, 0.07519784197211266), (2, 0.08912292495369911), (3, 0.0796620100736618), (4, 0.07369119673967361), (5, 0.06854089722037315), (6, 0.07547246292233467), (7, 0.05976952239871025), (8, 0.056253984570503235), (9, 0.06085476651787758), (10, 0.061376241967082024), (12, 0.0628746934235096), (13, 0.06599932163953781), (15, 0.05949276685714722), (18, 0.20452606678009033), (36, 0.1556040607392788)]
computing accuracy for after removing block 8 . block score: 0.056253984570503235
removed block 8 current accuracy 0.3344 loss from initial  0.6656
training start
training epoch 0 val accuracy 0.5632 topk_dict {'top1': 0.5632} is_best True lr [0.001]
training epoch 1 val accuracy 0.6054 topk_dict {'top1': 0.6054} is_best True lr [0.001]
training epoch 2 val accuracy 0.6346 topk_dict {'top1': 0.6346} is_best True lr [0.001]
training epoch 3 val accuracy 0.6546 topk_dict {'top1': 0.6546} is_best True lr [0.001]
training epoch 4 val accuracy 0.6636 topk_dict {'top1': 0.6636} is_best True lr [0.001]
training epoch 5 val accuracy 0.6884 topk_dict {'top1': 0.6884} is_best True lr [0.001]
training epoch 6 val accuracy 0.6964 topk_dict {'top1': 0.6964} is_best True lr [0.001]
training epoch 7 val accuracy 0.7042 topk_dict {'top1': 0.7042} is_best True lr [0.001]
training epoch 8 val accuracy 0.7158 topk_dict {'top1': 0.7158} is_best True lr [0.001]
training epoch 9 val accuracy 0.7244 topk_dict {'top1': 0.7244} is_best True lr [0.001]
training epoch 10 val accuracy 0.7294 topk_dict {'top1': 0.7294} is_best True lr [0.001]
training epoch 11 val accuracy 0.7406 topk_dict {'top1': 0.7406} is_best True lr [0.001]
training epoch 12 val accuracy 0.7448 topk_dict {'top1': 0.7448} is_best True lr [0.001]
training epoch 13 val accuracy 0.7466 topk_dict {'top1': 0.7466} is_best True lr [0.001]
training epoch 14 val accuracy 0.755 topk_dict {'top1': 0.755} is_best True lr [0.001]
training epoch 15 val accuracy 0.7548 topk_dict {'top1': 0.7548} is_best False lr [0.001]
training epoch 16 val accuracy 0.7674 topk_dict {'top1': 0.7674} is_best True lr [0.001]
training epoch 17 val accuracy 0.7524 topk_dict {'top1': 0.7524} is_best False lr [0.001]
training epoch 18 val accuracy 0.767 topk_dict {'top1': 0.767} is_best False lr [0.001]
training epoch 19 val accuracy 0.7744 topk_dict {'top1': 0.7744} is_best True lr [0.001]
training epoch 20 val accuracy 0.7734 topk_dict {'top1': 0.7734} is_best False lr [0.001]
training epoch 21 val accuracy 0.778 topk_dict {'top1': 0.778} is_best True lr [0.001]
training epoch 22 val accuracy 0.7852 topk_dict {'top1': 0.7852} is_best True lr [0.001]
training epoch 23 val accuracy 0.7928 topk_dict {'top1': 0.7928} is_best True lr [0.001]
training epoch 24 val accuracy 0.7708 topk_dict {'top1': 0.7708} is_best False lr [0.001]
training epoch 25 val accuracy 0.7894 topk_dict {'top1': 0.7894} is_best False lr [0.001]
training epoch 26 val accuracy 0.8034 topk_dict {'top1': 0.8034} is_best True lr [0.001]
training epoch 27 val accuracy 0.7906 topk_dict {'top1': 0.7906} is_best False lr [0.001]
training epoch 28 val accuracy 0.7894 topk_dict {'top1': 0.7894} is_best False lr [0.001]
training epoch 29 val accuracy 0.7826 topk_dict {'top1': 0.7826} is_best False lr [0.001]
training epoch 30 val accuracy 0.7972 topk_dict {'top1': 0.7972} is_best False lr [0.001]
training epoch 31 val accuracy 0.8028 topk_dict {'top1': 0.8028} is_best False lr [0.001]
training epoch 32 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best True lr [0.001]
training epoch 33 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best False lr [0.001]
training epoch 34 val accuracy 0.8038 topk_dict {'top1': 0.8038} is_best False lr [0.001]
training epoch 35 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best False lr [0.001]
training epoch 36 val accuracy 0.8004 topk_dict {'top1': 0.8004} is_best False lr [0.001]
training epoch 37 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best False lr [0.001]
training epoch 38 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best True lr [0.001]
training epoch 39 val accuracy 0.8104 topk_dict {'top1': 0.8104} is_best False lr [0.001]
training epoch 40 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best True lr [0.001]
training epoch 41 val accuracy 0.8036 topk_dict {'top1': 0.8036} is_best False lr [0.001]
training epoch 42 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best False lr [0.001]
training epoch 43 val accuracy 0.8158 topk_dict {'top1': 0.8158} is_best False lr [0.001]
training epoch 44 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best False lr [0.001]
training epoch 45 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best False lr [0.001]
training epoch 46 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best False lr [0.001]
training epoch 47 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best False lr [0.001]
training epoch 48 val accuracy 0.8124 topk_dict {'top1': 0.8124} is_best False lr [0.001]
training epoch 49 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.819400)
finished training. finished 50 epochs. accuracy 0.8194 topk_dict {'top1': 0.8194}
