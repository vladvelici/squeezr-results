start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 39 . block score: 0.043051496148109436
removed block 39 current accuracy 0.9988 loss from initial  0.0011999999999999789
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 7 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (26, 0.04361966997385025), (27, 0.0518401637673378), (28, 0.044554203748703), (29, 0.04406009614467621), (36, 0.17116805166006088), (37, 0.047323526814579964), (38, 0.04418100789189339), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (51, 0.04566679336130619), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 26 . block score: 0.04361966997385025
removed block 26 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (28, 0.044554203748703), (29, 0.04406009614467621), (36, 0.17116805166006088), (37, 0.047323526814579964), (38, 0.04418100789189339), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (51, 0.04566679336130619), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 29 . block score: 0.04406009614467621
removed block 29 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (28, 0.044554203748703), (36, 0.17116805166006088), (37, 0.047323526814579964), (38, 0.04418100789189339), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (51, 0.04566679336130619), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 38 . block score: 0.04418100789189339
removed block 38 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (28, 0.044554203748703), (36, 0.17116805166006088), (37, 0.047323526814579964), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (51, 0.04566679336130619), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 28 . block score: 0.044554203748703
removed block 28 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (36, 0.17116805166006088), (37, 0.047323526814579964), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (51, 0.04566679336130619), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 51 . block score: 0.04566679336130619
removed block 51 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (36, 0.17116805166006088), (37, 0.047323526814579964), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (50, 0.04615764878690243), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 50 . block score: 0.04615764878690243
removed block 50 current accuracy 0.9856 loss from initial  0.014399999999999968
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (36, 0.17116805166006088), (37, 0.047323526814579964), (40, 0.046438513323664665), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 40 . block score: 0.046438513323664665
removed block 40 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (36, 0.17116805166006088), (37, 0.047323526814579964), (41, 0.04788490757346153), (42, 0.04693488962948322), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 42 . block score: 0.04693488962948322
removed block 42 current accuracy 0.973 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05469539947807789), (3, 0.04778681881725788), (4, 0.06688212975859642), (5, 0.055326199159026146), (6, 0.07429741322994232), (7, 0.08870862796902657), (8, 0.0936359204351902), (9, 0.09698562324047089), (10, 0.0913083367049694), (11, 0.09360628202557564), (12, 0.10776347294449806), (13, 0.08975483104586601), (14, 0.07697879150509834), (15, 0.08730688318610191), (16, 0.08566441386938095), (17, 0.07678543031215668), (18, 0.2589704059064388), (19, 0.06899870932102203), (20, 0.06368502974510193), (21, 0.06415178440511227), (22, 0.057679835706949234), (23, 0.053813835605978966), (24, 0.054061150178313255), (25, 0.05193512327969074), (27, 0.0518401637673378), (36, 0.17116805166006088), (37, 0.047323526814579964), (41, 0.04788490757346153), (43, 0.04732697829604149), (44, 0.04894660413265228), (45, 0.05024227872490883), (46, 0.05217819847166538), (47, 0.050149260088801384), (48, 0.05087275058031082), (49, 0.04823057912290096), (52, 0.04784742556512356), (53, 0.05565025471150875)]
computing accuracy for after removing block 37 . block score: 0.047323526814579964
removed block 37 current accuracy 0.9638 loss from initial  0.03620000000000001
training start
training epoch 0 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best True lr [0.001]
training epoch 1 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 2 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 3 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 4 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 5 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 6 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 7 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 8 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 9 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 10 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 11 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 12 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 13 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 14 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 15 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 16 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 18 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 19 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 21 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 22 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 23 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 25 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 26 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 27 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 28 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 29 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 30 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 31 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 32 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 33 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 34 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 35 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 36 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 37 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 38 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 39 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 40 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 41 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 42 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 43 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 44 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 45 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 46 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 47 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 48 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 49 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
loading model_best from epoch 26 (acc 0.997400)
finished training. finished 50 epochs. accuracy 0.9974 topk_dict {'top1': 0.9974}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (3, 0.04739544913172722), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (41, 0.047482432797551155), (43, 0.04693511687219143), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (49, 0.047841377556324005), (52, 0.04745902866125107), (53, 0.05519302003085613)]
computing accuracy for after removing block 43 . block score: 0.04693511687219143
removed block 43 current accuracy 0.9916 loss from initial  0.008399999999999963
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (3, 0.04739544913172722), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (41, 0.047482432797551155), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (49, 0.047841377556324005), (52, 0.04745902866125107), (53, 0.05519302003085613)]
computing accuracy for after removing block 3 . block score: 0.04739544913172722
removed block 3 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (41, 0.047482432797551155), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (49, 0.047841377556324005), (52, 0.04745902866125107), (53, 0.05519302003085613)]
computing accuracy for after removing block 52 . block score: 0.04745902866125107
removed block 52 current accuracy 0.928 loss from initial  0.07199999999999995
since last training loss: 0.0693999999999999 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (41, 0.047482432797551155), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (49, 0.047841377556324005), (53, 0.05519302003085613)]
computing accuracy for after removing block 41 . block score: 0.047482432797551155
removed block 41 current accuracy 0.9162 loss from initial  0.08379999999999999
since last training loss: 0.08119999999999994 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (49, 0.047841377556324005), (53, 0.05519302003085613)]
computing accuracy for after removing block 49 . block score: 0.047841377556324005
removed block 49 current accuracy 0.8802 loss from initial  0.11980000000000002
since last training loss: 0.11719999999999997 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (44, 0.04856543056666851), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (53, 0.05519302003085613)]
computing accuracy for after removing block 44 . block score: 0.04856543056666851
removed block 44 current accuracy 0.821 loss from initial  0.17900000000000005
since last training loss: 0.1764 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (45, 0.04983479902148247), (46, 0.05175354331731796), (47, 0.049746258184313774), (48, 0.05046628601849079), (53, 0.05519302003085613)]
computing accuracy for after removing block 47 . block score: 0.049746258184313774
removed block 47 current accuracy 0.7362 loss from initial  0.26380000000000003
since last training loss: 0.2612 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (45, 0.04983479902148247), (46, 0.05175354331731796), (48, 0.05046628601849079), (53, 0.05519302003085613)]
computing accuracy for after removing block 45 . block score: 0.04983479902148247
removed block 45 current accuracy 0.6388 loss from initial  0.36119999999999997
since last training loss: 0.3585999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05431928113102913), (4, 0.06649437174201012), (5, 0.0548767801374197), (6, 0.07375459000468254), (7, 0.08801255747675896), (8, 0.09287765622138977), (9, 0.09614092111587524), (10, 0.0905931107699871), (11, 0.09282828494906425), (12, 0.10687138512730598), (13, 0.08902151137590408), (14, 0.07635696977376938), (15, 0.08659971877932549), (16, 0.08502952009439468), (17, 0.0761825405061245), (18, 0.2567902281880379), (19, 0.06841789558529854), (20, 0.06318136118352413), (21, 0.0636302437633276), (22, 0.05718536116182804), (23, 0.053352002054452896), (24, 0.053624728694558144), (25, 0.05150594003498554), (27, 0.05144263617694378), (36, 0.16983476281166077), (46, 0.05175354331731796), (48, 0.05046628601849079), (53, 0.05519302003085613)]
computing accuracy for after removing block 48 . block score: 0.05046628601849079
removed block 48 current accuracy 0.5576 loss from initial  0.4424
training start
training epoch 0 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.001]
training epoch 1 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 2 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 3 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 4 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 5 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 6 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 7 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 8 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 9 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 21 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 23 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 24 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 25 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 26 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 27 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 28 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 31 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 32 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 33 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 34 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 35 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.001]
training epoch 36 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 37 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.001]
training epoch 38 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 39 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 40 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 41 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 42 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 43 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 44 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 45 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 46 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 47 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 48 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 49 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.953600)
finished training. finished 50 epochs. accuracy 0.9536 topk_dict {'top1': 0.9536}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (23, 0.052943723276257515), (24, 0.05322056636214256), (25, 0.05108726769685745), (27, 0.051150063052773476), (36, 0.16795513778924942), (46, 0.051432326436042786), (53, 0.05458293668925762)]
computing accuracy for after removing block 25 . block score: 0.05108726769685745
removed block 25 current accuracy 0.9432 loss from initial  0.05679999999999996
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (23, 0.052943723276257515), (24, 0.05322056636214256), (27, 0.051150063052773476), (36, 0.16795513778924942), (46, 0.051432326436042786), (53, 0.05458293668925762)]
computing accuracy for after removing block 27 . block score: 0.051150063052773476
removed block 27 current accuracy 0.9296 loss from initial  0.07040000000000002
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (23, 0.052943723276257515), (24, 0.05322056636214256), (36, 0.16795513778924942), (46, 0.051432326436042786), (53, 0.05458293668925762)]
computing accuracy for after removing block 46 . block score: 0.051432326436042786
removed block 46 current accuracy 0.7966 loss from initial  0.20340000000000003
since last training loss: 0.15700000000000003 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (23, 0.052943723276257515), (24, 0.05322056636214256), (36, 0.16795513778924942), (53, 0.05458293668925762)]
computing accuracy for after removing block 23 . block score: 0.052943723276257515
removed block 23 current accuracy 0.7462 loss from initial  0.2538
since last training loss: 0.20740000000000003 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (24, 0.05322056636214256), (36, 0.16795513778924942), (53, 0.05458293668925762)]
computing accuracy for after removing block 24 . block score: 0.05322056636214256
removed block 24 current accuracy 0.7036 loss from initial  0.2964
since last training loss: 0.25 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.05379859358072281), (4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (36, 0.16795513778924942), (53, 0.05458293668925762)]
computing accuracy for after removing block 0 . block score: 0.05379859358072281
removed block 0 current accuracy 0.7134 loss from initial  0.28659999999999997
since last training loss: 0.24019999999999997 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (5, 0.05441783182322979), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (36, 0.16795513778924942), (53, 0.05458293668925762)]
computing accuracy for after removing block 5 . block score: 0.05441783182322979
removed block 5 current accuracy 0.6932 loss from initial  0.30679999999999996
since last training loss: 0.26039999999999996 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (36, 0.16795513778924942), (53, 0.05458293668925762)]
computing accuracy for after removing block 53 . block score: 0.05458293668925762
removed block 53 current accuracy 0.3424 loss from initial  0.6576
since last training loss: 0.6112 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (22, 0.05660194903612137), (36, 0.16795513778924942)]
computing accuracy for after removing block 22 . block score: 0.05660194903612137
removed block 22 current accuracy 0.3302 loss from initial  0.6698
since last training loss: 0.6234 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (20, 0.0625715684145689), (21, 0.06294086016714573), (36, 0.16795513778924942)]
computing accuracy for after removing block 20 . block score: 0.0625715684145689
removed block 20 current accuracy 0.2994 loss from initial  0.7006
since last training loss: 0.6542 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (21, 0.06294086016714573), (36, 0.16795513778924942)]
computing accuracy for after removing block 21 . block score: 0.06294086016714573
removed block 21 current accuracy 0.2826 loss from initial  0.7174
since last training loss: 0.671 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.06624080240726471), (6, 0.07316983863711357), (7, 0.08710189536213875), (8, 0.09193344786763191), (9, 0.09496632590889931), (10, 0.08963548764586449), (11, 0.091685451567173), (12, 0.10581402108073235), (13, 0.08805609494447708), (14, 0.07558128610253334), (15, 0.08569588884711266), (16, 0.08413831517100334), (17, 0.07541822269558907), (18, 0.2538109980523586), (19, 0.06769729778170586), (36, 0.16795513778924942)]
computing accuracy for after removing block 4 . block score: 0.06624080240726471
removed block 4 current accuracy 0.2428 loss from initial  0.7572
training start
training epoch 0 val accuracy 0.5796 topk_dict {'top1': 0.5796} is_best True lr [0.001]
training epoch 1 val accuracy 0.6286 topk_dict {'top1': 0.6286} is_best True lr [0.001]
training epoch 2 val accuracy 0.655 topk_dict {'top1': 0.655} is_best True lr [0.001]
training epoch 3 val accuracy 0.675 topk_dict {'top1': 0.675} is_best True lr [0.001]
training epoch 4 val accuracy 0.6932 topk_dict {'top1': 0.6932} is_best True lr [0.001]
training epoch 5 val accuracy 0.7036 topk_dict {'top1': 0.7036} is_best True lr [0.001]
training epoch 6 val accuracy 0.7152 topk_dict {'top1': 0.7152} is_best True lr [0.001]
training epoch 7 val accuracy 0.7254 topk_dict {'top1': 0.7254} is_best True lr [0.001]
training epoch 8 val accuracy 0.736 topk_dict {'top1': 0.736} is_best True lr [0.001]
training epoch 9 val accuracy 0.7432 topk_dict {'top1': 0.7432} is_best True lr [0.001]
training epoch 10 val accuracy 0.7524 topk_dict {'top1': 0.7524} is_best True lr [0.001]
training epoch 11 val accuracy 0.7578 topk_dict {'top1': 0.7578} is_best True lr [0.001]
training epoch 12 val accuracy 0.7682 topk_dict {'top1': 0.7682} is_best True lr [0.001]
training epoch 13 val accuracy 0.774 topk_dict {'top1': 0.774} is_best True lr [0.001]
training epoch 14 val accuracy 0.7802 topk_dict {'top1': 0.7802} is_best True lr [0.001]
training epoch 15 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best True lr [0.001]
training epoch 16 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best True lr [0.001]
training epoch 17 val accuracy 0.7978 topk_dict {'top1': 0.7978} is_best True lr [0.001]
training epoch 18 val accuracy 0.8004 topk_dict {'top1': 0.8004} is_best True lr [0.001]
training epoch 19 val accuracy 0.804 topk_dict {'top1': 0.804} is_best True lr [0.001]
training epoch 20 val accuracy 0.807 topk_dict {'top1': 0.807} is_best True lr [0.001]
training epoch 21 val accuracy 0.807 topk_dict {'top1': 0.807} is_best False lr [0.001]
training epoch 22 val accuracy 0.8126 topk_dict {'top1': 0.8126} is_best True lr [0.001]
training epoch 23 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best True lr [0.001]
training epoch 24 val accuracy 0.8202 topk_dict {'top1': 0.8202} is_best True lr [0.001]
training epoch 25 val accuracy 0.824 topk_dict {'top1': 0.824} is_best True lr [0.001]
training epoch 26 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.001]
training epoch 27 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best False lr [0.001]
training epoch 28 val accuracy 0.828 topk_dict {'top1': 0.828} is_best True lr [0.001]
training epoch 29 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 30 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best True lr [0.001]
training epoch 31 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best False lr [0.001]
training epoch 32 val accuracy 0.827 topk_dict {'top1': 0.827} is_best False lr [0.001]
training epoch 33 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best True lr [0.001]
training epoch 34 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best True lr [0.001]
training epoch 35 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best True lr [0.001]
training epoch 36 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best False lr [0.001]
training epoch 37 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.001]
training epoch 38 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.001]
training epoch 39 val accuracy 0.843 topk_dict {'top1': 0.843} is_best True lr [0.001]
training epoch 40 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.001]
training epoch 41 val accuracy 0.841 topk_dict {'top1': 0.841} is_best False lr [0.001]
training epoch 42 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.001]
training epoch 43 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.001]
training epoch 44 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best True lr [0.001]
training epoch 45 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.001]
training epoch 46 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best True lr [0.001]
training epoch 47 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.001]
training epoch 48 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.001]
training epoch 49 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.847800)
finished training. finished 50 epochs. accuracy 0.8478 topk_dict {'top1': 0.8478}
