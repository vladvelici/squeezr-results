start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9908 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9862 loss from initial  0.013800000000000034
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 35 . block score: 0.043665528297424316
removed block 35 current accuracy 0.9842 loss from initial  0.015800000000000036
training start
training epoch 0 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 1 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 2 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 7 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 9 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 21 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (29, 0.046466218307614326), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (46, 0.04673735983669758), (47, 0.0450325645506382), (48, 0.044672971591353416), (49, 0.04395618289709091), (53, 0.05057372897863388)]
computing accuracy for after removing block 49 . block score: 0.04395618289709091
removed block 49 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (29, 0.046466218307614326), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (46, 0.04673735983669758), (47, 0.0450325645506382), (48, 0.044672971591353416), (53, 0.05057372897863388)]
computing accuracy for after removing block 48 . block score: 0.044672971591353416
removed block 48 current accuracy 0.9918 loss from initial  0.008199999999999985
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (29, 0.046466218307614326), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (46, 0.04673735983669758), (47, 0.0450325645506382), (53, 0.05057372897863388)]
computing accuracy for after removing block 47 . block score: 0.0450325645506382
removed block 47 current accuracy 0.9758 loss from initial  0.0242
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (29, 0.046466218307614326), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (46, 0.04673735983669758), (53, 0.05057372897863388)]
computing accuracy for after removing block 29 . block score: 0.046466218307614326
removed block 29 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (46, 0.04673735983669758), (53, 0.05057372897863388)]
computing accuracy for after removing block 46 . block score: 0.04673735983669758
removed block 46 current accuracy 0.9386 loss from initial  0.06140000000000001
since last training loss: 0.06120000000000003 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (28, 0.046867648139595985), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (53, 0.05057372897863388)]
computing accuracy for after removing block 28 . block score: 0.046867648139595985
removed block 28 current accuracy 0.9364 loss from initial  0.06359999999999999
since last training loss: 0.06340000000000001 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (44, 0.05003156326711178), (45, 0.051096294075250626), (53, 0.05057372897863388)]
computing accuracy for after removing block 44 . block score: 0.05003156326711178
removed block 44 current accuracy 0.8918 loss from initial  0.10819999999999996
since last training loss: 0.10799999999999998 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (45, 0.051096294075250626), (53, 0.05057372897863388)]
computing accuracy for after removing block 53 . block score: 0.05057372897863388
removed block 53 current accuracy 0.58 loss from initial  0.42000000000000004
since last training loss: 0.41980000000000006 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06608199700713158), (1, 0.05604584701359272), (2, 0.07485276833176613), (3, 0.07811573892831802), (4, 0.0616825595498085), (5, 0.09424614533782005), (6, 0.059534188359975815), (7, 0.06034590303897858), (8, 0.06668553873896599), (9, 0.08046649768948555), (10, 0.07990219071507454), (11, 0.06860515102744102), (12, 0.08223354816436768), (13, 0.07506632059812546), (14, 0.08547267690300941), (15, 0.08843930065631866), (16, 0.10476116836071014), (17, 0.1236070841550827), (18, 0.272026177495718), (19, 0.07037049531936646), (20, 0.06851852312684059), (21, 0.06332817487418652), (22, 0.061565784737467766), (23, 0.05833037756383419), (24, 0.05771126598119736), (25, 0.05757112614810467), (26, 0.05126531422138214), (27, 0.055813439190387726), (36, 0.18151600286364555), (37, 0.05512998811900616), (38, 0.05390423908829689), (39, 0.05484994873404503), (40, 0.05365665443241596), (41, 0.05081302113831043), (42, 0.05340192839503288), (43, 0.05169941112399101), (45, 0.051096294075250626)]
computing accuracy for after removing block 41 . block score: 0.05081302113831043
removed block 41 current accuracy 0.5816 loss from initial  0.4184
training start
training epoch 0 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best True lr [0.001]
training epoch 1 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.001]
training epoch 2 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 3 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 4 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 5 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 6 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 7 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 8 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 9 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 10 val accuracy 0.9586 topk_dict {'top1': 0.9586} is_best True lr [0.001]
training epoch 11 val accuracy 0.9616 topk_dict {'top1': 0.9616} is_best True lr [0.001]
training epoch 12 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best True lr [0.001]
training epoch 13 val accuracy 0.9644 topk_dict {'top1': 0.9644} is_best False lr [0.001]
training epoch 14 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.001]
training epoch 15 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best True lr [0.001]
training epoch 16 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best True lr [0.001]
training epoch 17 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best True lr [0.001]
training epoch 18 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 19 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 20 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 21 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 22 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best True lr [0.001]
training epoch 23 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best True lr [0.001]
training epoch 24 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 25 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 26 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best True lr [0.001]
training epoch 27 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 28 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 29 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 30 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 31 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 32 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 33 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 34 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 35 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 36 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 37 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 38 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 39 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 40 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 41 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 42 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 43 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 44 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 45 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 46 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 47 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 48 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 49 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.982600)
finished training. finished 50 epochs. accuracy 0.9826 topk_dict {'top1': 0.9826}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (26, 0.050705837085843086), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074), (40, 0.05293404683470726), (42, 0.052652740851044655), (43, 0.05097826011478901), (45, 0.05040965974330902)]
computing accuracy for after removing block 45 . block score: 0.05040965974330902
removed block 45 current accuracy 0.9494 loss from initial  0.05059999999999998
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (26, 0.050705837085843086), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074), (40, 0.05293404683470726), (42, 0.052652740851044655), (43, 0.05097826011478901)]
computing accuracy for after removing block 26 . block score: 0.050705837085843086
removed block 26 current accuracy 0.941 loss from initial  0.05900000000000005
since last training loss: 0.04160000000000008 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074), (40, 0.05293404683470726), (42, 0.052652740851044655), (43, 0.05097826011478901)]
computing accuracy for after removing block 43 . block score: 0.05097826011478901
removed block 43 current accuracy 0.8724 loss from initial  0.12760000000000005
since last training loss: 0.11020000000000008 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074), (40, 0.05293404683470726), (42, 0.052652740851044655)]
computing accuracy for after removing block 42 . block score: 0.052652740851044655
removed block 42 current accuracy 0.817 loss from initial  0.18300000000000005
since last training loss: 0.16560000000000008 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074), (40, 0.05293404683470726)]
computing accuracy for after removing block 40 . block score: 0.05293404683470726
removed block 40 current accuracy 0.7352 loss from initial  0.26480000000000004
since last training loss: 0.24740000000000006 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (38, 0.053201042115688324), (39, 0.054119961336255074)]
computing accuracy for after removing block 38 . block score: 0.053201042115688324
removed block 38 current accuracy 0.7 loss from initial  0.30000000000000004
since last training loss: 0.2826000000000001 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186), (39, 0.054119961336255074)]
computing accuracy for after removing block 39 . block score: 0.054119961336255074
removed block 39 current accuracy 0.6102 loss from initial  0.38980000000000004
since last training loss: 0.37240000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756), (37, 0.05444381944835186)]
computing accuracy for after removing block 37 . block score: 0.05444381944835186
removed block 37 current accuracy 0.575 loss from initial  0.42500000000000004
since last training loss: 0.4076000000000001 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.065225750207901), (1, 0.055494481697678566), (2, 0.07390563189983368), (3, 0.07716226205229759), (4, 0.06097367964684963), (5, 0.09315590187907219), (6, 0.05882151052355766), (7, 0.05966834910213947), (8, 0.06599227339029312), (9, 0.07937079295516014), (10, 0.0789206475019455), (11, 0.06790044903755188), (12, 0.08113288506865501), (13, 0.07424978539347649), (14, 0.08439638838171959), (15, 0.08746714144945145), (16, 0.10348238423466682), (17, 0.12201493233442307), (18, 0.26839011907577515), (19, 0.06953844428062439), (20, 0.06767920404672623), (21, 0.06253405846655369), (22, 0.06080855242908001), (23, 0.05765513516962528), (24, 0.0570954829454422), (25, 0.05690098740160465), (27, 0.05522193945944309), (36, 0.17928918078541756)]
computing accuracy for after removing block 27 . block score: 0.05522193945944309
removed block 27 current accuracy 0.519 loss from initial  0.481
training start
training epoch 0 val accuracy 0.733 topk_dict {'top1': 0.733} is_best True lr [0.001]
training epoch 1 val accuracy 0.7636 topk_dict {'top1': 0.7636} is_best True lr [0.001]
training epoch 2 val accuracy 0.7892 topk_dict {'top1': 0.7892} is_best True lr [0.001]
training epoch 3 val accuracy 0.8086 topk_dict {'top1': 0.8086} is_best True lr [0.001]
training epoch 4 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best True lr [0.001]
training epoch 5 val accuracy 0.833 topk_dict {'top1': 0.833} is_best True lr [0.001]
training epoch 6 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best True lr [0.001]
training epoch 7 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best True lr [0.001]
training epoch 8 val accuracy 0.86 topk_dict {'top1': 0.86} is_best True lr [0.001]
training epoch 9 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.001]
training epoch 10 val accuracy 0.87 topk_dict {'top1': 0.87} is_best True lr [0.001]
training epoch 11 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.001]
training epoch 12 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.001]
training epoch 13 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.001]
training epoch 14 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.001]
training epoch 15 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.001]
training epoch 16 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.001]
training epoch 17 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 18 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 19 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 20 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.001]
training epoch 21 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 22 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.001]
training epoch 23 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 24 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.001]
training epoch 25 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.001]
training epoch 26 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 27 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.001]
training epoch 28 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 29 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.001]
training epoch 30 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 32 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 33 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 34 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.001]
training epoch 35 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.001]
training epoch 36 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 37 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.001]
training epoch 38 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 39 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 40 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 41 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 42 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.001]
training epoch 43 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.001]
training epoch 44 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 45 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 46 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 47 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 48 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.001]
training epoch 49 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9064 topk_dict {'top1': 0.9064}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (1, 0.05547471344470978), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (6, 0.05802011303603649), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (23, 0.0584004744887352), (24, 0.058800121769309044), (25, 0.05831722170114517), (36, 0.17674466595053673)]
computing accuracy for after removing block 1 . block score: 0.05547471344470978
removed block 1 current accuracy 0.9068 loss from initial  0.09319999999999995
since last training loss: -0.00040000000000006697 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (6, 0.05802011303603649), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (23, 0.0584004744887352), (24, 0.058800121769309044), (25, 0.05831722170114517), (36, 0.17674466595053673)]
computing accuracy for after removing block 6 . block score: 0.05802011303603649
removed block 6 current accuracy 0.9036 loss from initial  0.09640000000000004
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (23, 0.0584004744887352), (24, 0.058800121769309044), (25, 0.05831722170114517), (36, 0.17674466595053673)]
computing accuracy for after removing block 25 . block score: 0.05831722170114517
removed block 25 current accuracy 0.819 loss from initial  0.18100000000000005
since last training loss: 0.08740000000000003 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (23, 0.0584004744887352), (24, 0.058800121769309044), (36, 0.17674466595053673)]
computing accuracy for after removing block 23 . block score: 0.0584004744887352
removed block 23 current accuracy 0.7362 loss from initial  0.26380000000000003
since last training loss: 0.17020000000000002 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (24, 0.058800121769309044), (36, 0.17674466595053673)]
computing accuracy for after removing block 24 . block score: 0.058800121769309044
removed block 24 current accuracy 0.551 loss from initial  0.44899999999999995
since last training loss: 0.35539999999999994 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (7, 0.05902191624045372), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (36, 0.17674466595053673)]
computing accuracy for after removing block 7 . block score: 0.05902191624045372
removed block 7 current accuracy 0.5308 loss from initial  0.46919999999999995
since last training loss: 0.37559999999999993 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (4, 0.060156021267175674), (5, 0.09208565205335617), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (36, 0.17674466595053673)]
computing accuracy for after removing block 4 . block score: 0.060156021267175674
removed block 4 current accuracy 0.5108 loss from initial  0.48919999999999997
since last training loss: 0.39559999999999995 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (5, 0.09208565205335617), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (22, 0.06087682396173477), (36, 0.17674466595053673)]
computing accuracy for after removing block 22 . block score: 0.06087682396173477
removed block 22 current accuracy 0.4544 loss from initial  0.5456
since last training loss: 0.45199999999999996 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (5, 0.09208565205335617), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (21, 0.06264447048306465), (36, 0.17674466595053673)]
computing accuracy for after removing block 21 . block score: 0.06264447048306465
removed block 21 current accuracy 0.336 loss from initial  0.6639999999999999
since last training loss: 0.5704 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.06436094641685486), (2, 0.07289218157529831), (3, 0.07609838992357254), (5, 0.09208565205335617), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (36, 0.17674466595053673)]
computing accuracy for after removing block 0 . block score: 0.06436094641685486
removed block 0 current accuracy 0.2718 loss from initial  0.7282
since last training loss: 0.6346 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07289218157529831), (3, 0.07609838992357254), (5, 0.09208565205335617), (8, 0.06529227644205093), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (36, 0.17674466595053673)]
computing accuracy for after removing block 8 . block score: 0.06529227644205093
removed block 8 current accuracy 0.221 loss from initial  0.779
since last training loss: 0.6854 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07289218157529831), (3, 0.07609838992357254), (5, 0.09208565205335617), (9, 0.0783253125846386), (10, 0.0778309740126133), (11, 0.06726712360978127), (12, 0.07993116602301598), (13, 0.07340622320771217), (14, 0.08318101987242699), (15, 0.08640778064727783), (16, 0.1021195687353611), (17, 0.12050207704305649), (18, 0.2649606131017208), (19, 0.0689319595694542), (20, 0.06722044572234154), (36, 0.17674466595053673)]
computing accuracy for after removing block 20 . block score: 0.06722044572234154
removed block 20 current accuracy 0.1714 loss from initial  0.8286
training start
training epoch 0 val accuracy 0.728 topk_dict {'top1': 0.728} is_best True lr [0.001]
training epoch 1 val accuracy 0.7586 topk_dict {'top1': 0.7586} is_best True lr [0.001]
training epoch 2 val accuracy 0.7746 topk_dict {'top1': 0.7746} is_best True lr [0.001]
training epoch 3 val accuracy 0.7858 topk_dict {'top1': 0.7858} is_best True lr [0.001]
training epoch 4 val accuracy 0.7904 topk_dict {'top1': 0.7904} is_best True lr [0.001]
training epoch 5 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best True lr [0.001]
training epoch 6 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.001]
training epoch 7 val accuracy 0.8072 topk_dict {'top1': 0.8072} is_best False lr [0.001]
training epoch 8 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best True lr [0.001]
training epoch 9 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best True lr [0.001]
training epoch 10 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best True lr [0.001]
training epoch 11 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.001]
training epoch 12 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 13 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best False lr [0.001]
training epoch 14 val accuracy 0.83 topk_dict {'top1': 0.83} is_best True lr [0.001]
training epoch 15 val accuracy 0.836 topk_dict {'top1': 0.836} is_best True lr [0.001]
training epoch 16 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.001]
training epoch 17 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best True lr [0.001]
training epoch 18 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best False lr [0.001]
training epoch 19 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.001]
training epoch 20 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.001]
training epoch 21 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best True lr [0.001]
training epoch 22 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.001]
training epoch 23 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.001]
training epoch 24 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.001]
training epoch 25 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best True lr [0.001]
training epoch 26 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.001]
training epoch 27 val accuracy 0.849 topk_dict {'top1': 0.849} is_best True lr [0.001]
training epoch 28 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.001]
training epoch 29 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.001]
training epoch 30 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best True lr [0.001]
training epoch 31 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.001]
training epoch 32 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.001]
training epoch 33 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best True lr [0.001]
training epoch 34 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.001]
training epoch 35 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.001]
training epoch 36 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.001]
training epoch 37 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.001]
training epoch 38 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.001]
training epoch 39 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.001]
training epoch 40 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.001]
training epoch 41 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.001]
training epoch 42 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.001]
training epoch 43 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.001]
training epoch 44 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.001]
training epoch 45 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.001]
training epoch 46 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.001]
training epoch 47 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.001]
training epoch 48 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.001]
training epoch 49 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8634 topk_dict {'top1': 0.8634}
