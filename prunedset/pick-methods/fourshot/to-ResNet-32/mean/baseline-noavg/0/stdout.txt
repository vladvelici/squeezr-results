start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 19 . block score: 0.03394944407045841
removed block 19 current accuracy 0.991 loss from initial  0.009000000000000008
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 5 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.03418498486280441), (2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (23, 0.0381743498146534), (25, 0.035528650507330894), (26, 0.04476276971399784), (27, 0.038371240720152855), (28, 0.041825490072369576), (29, 0.04035828821361065), (30, 0.0372207211330533), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 0 . block score: 0.03418498486280441
removed block 0 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (23, 0.0381743498146534), (25, 0.035528650507330894), (26, 0.04476276971399784), (27, 0.038371240720152855), (28, 0.041825490072369576), (29, 0.04035828821361065), (30, 0.0372207211330533), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 25 . block score: 0.035528650507330894
removed block 25 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (23, 0.0381743498146534), (26, 0.04476276971399784), (27, 0.038371240720152855), (28, 0.041825490072369576), (29, 0.04035828821361065), (30, 0.0372207211330533), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 30 . block score: 0.0372207211330533
removed block 30 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (23, 0.0381743498146534), (26, 0.04476276971399784), (27, 0.038371240720152855), (28, 0.041825490072369576), (29, 0.04035828821361065), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 23 . block score: 0.0381743498146534
removed block 23 current accuracy 0.9906 loss from initial  0.009399999999999964
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (26, 0.04476276971399784), (27, 0.038371240720152855), (28, 0.041825490072369576), (29, 0.04035828821361065), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 27 . block score: 0.038371240720152855
removed block 27 current accuracy 0.986 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (26, 0.04476276971399784), (28, 0.041825490072369576), (29, 0.04035828821361065), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (35, 0.039598649367690086), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 35 . block score: 0.039598649367690086
removed block 35 current accuracy 0.982 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (26, 0.04476276971399784), (28, 0.041825490072369576), (29, 0.04035828821361065), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 29 . block score: 0.04035828821361065
removed block 29 current accuracy 0.9744 loss from initial  0.025599999999999956
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (8, 0.04094816371798515), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (26, 0.04476276971399784), (28, 0.041825490072369576), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 8 . block score: 0.04094816371798515
removed block 8 current accuracy 0.9572 loss from initial  0.04279999999999995
since last training loss: 0.04279999999999995 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.0420038066804409), (4, 0.05314955860376358), (7, 0.04149579629302025), (9, 0.06639237329363823), (10, 0.06229031831026077), (11, 0.05489661172032356), (12, 0.06202278845012188), (13, 0.05070612020790577), (14, 0.06607495248317719), (15, 0.07053402811288834), (16, 0.059932226315140724), (17, 0.09397168457508087), (18, 0.1909191645681858), (26, 0.04476276971399784), (28, 0.041825490072369576), (31, 0.04221349023282528), (32, 0.042436299845576286), (33, 0.04570975340902805), (34, 0.046477049589157104), (36, 0.16053565964102745), (37, 0.04164472222328186), (38, 0.04495236091315746), (39, 0.047225603833794594), (40, 0.05059674195945263), (41, 0.051171621307730675), (42, 0.05258939415216446), (43, 0.053870679810643196), (44, 0.05152741074562073), (45, 0.051192887127399445), (46, 0.05113563872873783), (47, 0.04883046634495258), (48, 0.0465406347066164), (49, 0.0450596883893013), (50, 0.04476504027843475), (51, 0.04397170804440975), (52, 0.04329928383231163), (53, 0.05074354074895382)]
computing accuracy for after removing block 7 . block score: 0.04149579629302025
removed block 7 current accuracy 0.8942 loss from initial  0.1058
training start
training epoch 0 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 1 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 2 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 3 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 4 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 5 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 7 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 9 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 15 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 16 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 17 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 19 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 20 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 21 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.041678087785840034), (4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (28, 0.04125974327325821), (31, 0.041632240638136864), (32, 0.04183826223015785), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (37, 0.041053442284464836), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 37 . block score: 0.041053442284464836
removed block 37 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.041678087785840034), (4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (28, 0.04125974327325821), (31, 0.041632240638136864), (32, 0.04183826223015785), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 28 . block score: 0.04125974327325821
removed block 28 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.041678087785840034), (4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (31, 0.041632240638136864), (32, 0.04183826223015785), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 31 . block score: 0.041632240638136864
removed block 31 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(2, 0.041678087785840034), (4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (32, 0.04183826223015785), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 2 . block score: 0.041678087785840034
removed block 2 current accuracy 0.9686 loss from initial  0.031399999999999983
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (32, 0.04183826223015785), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 32 . block score: 0.04183826223015785
removed block 32 current accuracy 0.9542 loss from initial  0.04579999999999995
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (52, 0.04268990829586983), (53, 0.05001735873520374)]
computing accuracy for after removing block 52 . block score: 0.04268990829586983
removed block 52 current accuracy 0.945 loss from initial  0.05500000000000005
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (51, 0.04334916174411774), (53, 0.05001735873520374)]
computing accuracy for after removing block 51 . block score: 0.04334916174411774
removed block 51 current accuracy 0.926 loss from initial  0.07399999999999995
since last training loss: 0.07379999999999998 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (50, 0.044133832678198814), (53, 0.05001735873520374)]
computing accuracy for after removing block 50 . block score: 0.044133832678198814
removed block 50 current accuracy 0.9028 loss from initial  0.09719999999999995
since last training loss: 0.09699999999999998 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.052777012810111046), (9, 0.06559732928872108), (10, 0.06147412024438381), (11, 0.054059598594903946), (12, 0.06116796098649502), (13, 0.050029972568154335), (14, 0.06522734649479389), (15, 0.06956706196069717), (16, 0.05906314216554165), (17, 0.09264218807220459), (18, 0.18811745941638947), (26, 0.04418587684631348), (33, 0.04510568641126156), (34, 0.045842574909329414), (36, 0.15836044028401375), (38, 0.044320834800601006), (39, 0.04655481316149235), (40, 0.04988054744899273), (41, 0.05044844187796116), (42, 0.05184425227344036), (43, 0.053113142028450966), (44, 0.050801923498511314), (45, 0.05047478340566158), (46, 0.050412435084581375), (47, 0.04814072512090206), (48, 0.04588361456990242), (49, 0.04442870430648327), (53, 0.05001735873520374)]
computing accuracy for after removing block 26 . block score: 0.04418587684631348
removed block 26 current accuracy 0.871 loss from initial  0.129
training start
training epoch 0 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 1 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 2 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 3 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 4 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 5 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 6 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 7 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 8 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 9 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 10 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 11 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 12 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 13 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 15 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 16 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 17 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 18 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 19 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 21 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 22 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 23 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 24 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 26 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 27 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 28 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 29 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 30 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 31 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 32 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 33 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 34 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 35 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 36 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 37 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 38 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 39 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 40 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 41 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 42 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 43 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 44 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 45 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 46 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 47 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 49 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (33, 0.04472632706165314), (34, 0.04544466361403465), (36, 0.15632889419794083), (38, 0.04373891465365887), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (48, 0.04528546333312988), (49, 0.043857548385858536), (53, 0.04928120598196983)]
computing accuracy for after removing block 38 . block score: 0.04373891465365887
removed block 38 current accuracy 0.9888 loss from initial  0.011199999999999988
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (33, 0.04472632706165314), (34, 0.04544466361403465), (36, 0.15632889419794083), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (48, 0.04528546333312988), (49, 0.043857548385858536), (53, 0.04928120598196983)]
computing accuracy for after removing block 49 . block score: 0.043857548385858536
removed block 49 current accuracy 0.9772 loss from initial  0.022800000000000042
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (33, 0.04472632706165314), (34, 0.04544466361403465), (36, 0.15632889419794083), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (48, 0.04528546333312988), (53, 0.04928120598196983)]
computing accuracy for after removing block 33 . block score: 0.04472632706165314
removed block 33 current accuracy 0.9456 loss from initial  0.054400000000000004
since last training loss: 0.050799999999999956 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (34, 0.04544466361403465), (36, 0.15632889419794083), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (48, 0.04528546333312988), (53, 0.04928120598196983)]
computing accuracy for after removing block 48 . block score: 0.04528546333312988
removed block 48 current accuracy 0.9212 loss from initial  0.07879999999999998
since last training loss: 0.07519999999999993 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (34, 0.04544466361403465), (36, 0.15632889419794083), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (53, 0.04928120598196983)]
computing accuracy for after removing block 34 . block score: 0.04544466361403465
removed block 34 current accuracy 0.8534 loss from initial  0.14659999999999995
since last training loss: 0.1429999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (39, 0.04593373090028763), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (53, 0.04928120598196983)]
computing accuracy for after removing block 39 . block score: 0.04593373090028763
removed block 39 current accuracy 0.8166 loss from initial  0.1834
since last training loss: 0.17979999999999996 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (47, 0.047510432079434395), (53, 0.04928120598196983)]
computing accuracy for after removing block 47 . block score: 0.047510432079434395
removed block 47 current accuracy 0.7348 loss from initial  0.2652
since last training loss: 0.26159999999999994 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (40, 0.04922072775661945), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (53, 0.04928120598196983)]
computing accuracy for after removing block 40 . block score: 0.04922072775661945
removed block 40 current accuracy 0.6568 loss from initial  0.34319999999999995
since last training loss: 0.3395999999999999 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885), (53, 0.04928120598196983)]
computing accuracy for after removing block 53 . block score: 0.04928120598196983
removed block 53 current accuracy 0.4502 loss from initial  0.5498000000000001
since last training loss: 0.5462 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (13, 0.04933125339448452), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885)]
computing accuracy for after removing block 13 . block score: 0.04933125339448452
removed block 13 current accuracy 0.4324 loss from initial  0.5676
since last training loss: 0.564 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844), (46, 0.049737147986888885)]
computing accuracy for after removing block 46 . block score: 0.049737147986888885
removed block 46 current accuracy 0.3364 loss from initial  0.6636
since last training loss: 0.6599999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.0524262934923172), (9, 0.06502794101834297), (10, 0.06079554185271263), (11, 0.05342698097229004), (12, 0.060373853892087936), (14, 0.06447015143930912), (15, 0.06859327480196953), (16, 0.05828764662146568), (17, 0.09137338399887085), (18, 0.18566375598311424), (36, 0.15632889419794083), (41, 0.04977743327617645), (42, 0.051159922033548355), (43, 0.05241612158715725), (44, 0.05013347417116165), (45, 0.04981633834540844)]
computing accuracy for after removing block 41 . block score: 0.04977743327617645
removed block 41 current accuracy 0.2936 loss from initial  0.7063999999999999
training start
training epoch 0 val accuracy 0.6758 topk_dict {'top1': 0.6758} is_best True lr [0.001]
training epoch 1 val accuracy 0.73 topk_dict {'top1': 0.73} is_best True lr [0.001]
training epoch 2 val accuracy 0.7712 topk_dict {'top1': 0.7712} is_best True lr [0.001]
training epoch 3 val accuracy 0.7986 topk_dict {'top1': 0.7986} is_best True lr [0.001]
training epoch 4 val accuracy 0.8202 topk_dict {'top1': 0.8202} is_best True lr [0.001]
training epoch 5 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best True lr [0.001]
training epoch 6 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best True lr [0.001]
training epoch 7 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.001]
training epoch 8 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.001]
training epoch 9 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.001]
training epoch 10 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.001]
training epoch 11 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best True lr [0.001]
training epoch 12 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.001]
training epoch 13 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.001]
training epoch 14 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.001]
training epoch 15 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 16 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.001]
training epoch 17 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 18 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.001]
training epoch 19 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.001]
training epoch 20 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.001]
training epoch 21 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 22 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.001]
training epoch 23 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 24 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.001]
training epoch 25 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 26 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 27 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.001]
training epoch 28 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 29 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 30 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 31 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.001]
training epoch 32 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 33 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 34 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 35 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 36 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 37 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 38 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 39 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 40 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.001]
training epoch 41 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 42 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 43 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.001]
training epoch 44 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 45 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 46 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 47 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 48 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 49 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9218 topk_dict {'top1': 0.9218}
