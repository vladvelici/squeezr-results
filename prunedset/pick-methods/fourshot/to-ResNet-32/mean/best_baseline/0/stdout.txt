start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9886 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 49 . block score: 0.0467995535582304
removed block 49 current accuracy 0.9724 loss from initial  0.027599999999999958
training start
training epoch 0 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 1 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 2 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 3 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 4 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 5 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 7 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 8 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 9 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 10 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 12 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 15 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 16 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 17 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 19 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 24 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 26 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 31 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 36 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (29, 0.04666627384722233), (35, 0.047165002673864365), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (43, 0.04831630550324917), (44, 0.05022198148071766), (45, 0.048465101048350334), (46, 0.04804742708802223), (47, 0.04988166689872742), (51, 0.046637484803795815), (53, 0.05310052074491978)]
computing accuracy for after removing block 51 . block score: 0.046637484803795815
removed block 51 current accuracy 0.981 loss from initial  0.019000000000000017
since last training loss: 0.01860000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (29, 0.04666627384722233), (35, 0.047165002673864365), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (43, 0.04831630550324917), (44, 0.05022198148071766), (45, 0.048465101048350334), (46, 0.04804742708802223), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 29 . block score: 0.04666627384722233
removed block 29 current accuracy 0.9774 loss from initial  0.022599999999999953
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (35, 0.047165002673864365), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (43, 0.04831630550324917), (44, 0.05022198148071766), (45, 0.048465101048350334), (46, 0.04804742708802223), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 35 . block score: 0.047165002673864365
removed block 35 current accuracy 0.9734 loss from initial  0.026599999999999957
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (43, 0.04831630550324917), (44, 0.05022198148071766), (45, 0.048465101048350334), (46, 0.04804742708802223), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 46 . block score: 0.04804742708802223
removed block 46 current accuracy 0.9602 loss from initial  0.03979999999999995
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (43, 0.04831630550324917), (44, 0.05022198148071766), (45, 0.048465101048350334), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 43 . block score: 0.04831630550324917
removed block 43 current accuracy 0.947 loss from initial  0.05300000000000005
since last training loss: 0.05260000000000009 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (44, 0.05022198148071766), (45, 0.048465101048350334), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 45 . block score: 0.048465101048350334
removed block 45 current accuracy 0.9248 loss from initial  0.07520000000000004
since last training loss: 0.07480000000000009 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (41, 0.0493182297796011), (42, 0.04959635250270367), (44, 0.05022198148071766), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 41 . block score: 0.0493182297796011
removed block 41 current accuracy 0.9086 loss from initial  0.09140000000000004
since last training loss: 0.09100000000000008 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (42, 0.04959635250270367), (44, 0.05022198148071766), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 42 . block score: 0.04959635250270367
removed block 42 current accuracy 0.8876 loss from initial  0.11240000000000006
since last training loss: 0.1120000000000001 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05675211362540722), (1, 0.07319032400846481), (2, 0.07816803455352783), (3, 0.09290897846221924), (4, 0.07434997335076332), (5, 0.0980973057448864), (6, 0.08971554040908813), (7, 0.07967988401651382), (8, 0.08113285899162292), (9, 0.09428452327847481), (10, 0.09445157274603844), (11, 0.07604025304317474), (12, 0.10114340856671333), (13, 0.08648059517145157), (14, 0.07601193338632584), (15, 0.06775980070233345), (16, 0.08194203302264214), (17, 0.07378353551030159), (18, 0.2597055472433567), (19, 0.06530427187681198), (20, 0.06558757647871971), (21, 0.06608149781823158), (22, 0.06489245593547821), (23, 0.060431696474552155), (24, 0.06404660269618034), (25, 0.05890462175011635), (26, 0.05331665463745594), (27, 0.0530569851398468), (28, 0.052902702242136), (36, 0.18162916973233223), (37, 0.05608706921339035), (38, 0.05552343465387821), (39, 0.0557930413633585), (40, 0.05034344270825386), (44, 0.05022198148071766), (47, 0.04988166689872742), (53, 0.05310052074491978)]
computing accuracy for after removing block 47 . block score: 0.04988166689872742
removed block 47 current accuracy 0.7922 loss from initial  0.20779999999999998
training start
training epoch 0 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 1 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.001]
training epoch 2 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.001]
training epoch 3 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.001]
training epoch 4 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best True lr [0.001]
training epoch 5 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best True lr [0.001]
training epoch 6 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 7 val accuracy 0.976 topk_dict {'top1': 0.976} is_best True lr [0.001]
training epoch 8 val accuracy 0.977 topk_dict {'top1': 0.977} is_best True lr [0.001]
training epoch 9 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best True lr [0.001]
training epoch 10 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 11 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 12 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 13 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 14 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 15 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 16 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 17 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 18 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 19 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 20 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 21 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 22 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 23 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 24 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 25 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 26 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 27 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 28 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 29 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 30 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 31 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 32 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best True lr [0.001]
training epoch 33 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 34 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 35 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 36 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 37 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 38 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 39 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 40 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 41 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 42 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 43 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 44 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 45 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
training epoch 46 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 47 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 48 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 49 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.987400)
finished training. finished 50 epochs. accuracy 0.9874 topk_dict {'top1': 0.9874}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (27, 0.05234568007290363), (28, 0.05214355140924454), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564), (40, 0.04961707256734371), (44, 0.049511853605508804), (53, 0.05231058783829212)]
computing accuracy for after removing block 44 . block score: 0.049511853605508804
removed block 44 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (27, 0.05234568007290363), (28, 0.05214355140924454), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564), (40, 0.04961707256734371), (53, 0.05231058783829212)]
computing accuracy for after removing block 40 . block score: 0.04961707256734371
removed block 40 current accuracy 0.908 loss from initial  0.09199999999999997
since last training loss: 0.07940000000000003 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (27, 0.05234568007290363), (28, 0.05214355140924454), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564), (53, 0.05231058783829212)]
computing accuracy for after removing block 28 . block score: 0.05214355140924454
removed block 28 current accuracy 0.8998 loss from initial  0.10019999999999996
since last training loss: 0.08760000000000001 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (27, 0.05234568007290363), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564), (53, 0.05231058783829212)]
computing accuracy for after removing block 53 . block score: 0.05231058783829212
removed block 53 current accuracy 0.6046 loss from initial  0.3954
since last training loss: 0.38280000000000003 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (27, 0.05234568007290363), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564)]
computing accuracy for after removing block 27 . block score: 0.05234568007290363
removed block 27 current accuracy 0.5982 loss from initial  0.40180000000000005
since last training loss: 0.3892000000000001 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (26, 0.05251134745776653), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564)]
computing accuracy for after removing block 26 . block score: 0.05251134745776653
removed block 26 current accuracy 0.578 loss from initial  0.42200000000000004
since last training loss: 0.4094000000000001 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (36, 0.17892488092184067), (37, 0.05523913539946079), (38, 0.054746219888329506), (39, 0.054975807666778564)]
computing accuracy for after removing block 38 . block score: 0.054746219888329506
removed block 38 current accuracy 0.5352 loss from initial  0.4648
since last training loss: 0.45220000000000005 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (36, 0.17892488092184067), (37, 0.05523913539946079), (39, 0.054975807666778564)]
computing accuracy for after removing block 39 . block score: 0.054975807666778564
removed block 39 current accuracy 0.443 loss from initial  0.5569999999999999
since last training loss: 0.5444 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.055952347815036774), (1, 0.07211427018046379), (2, 0.07699578255414963), (3, 0.09153186529874802), (4, 0.07320203632116318), (5, 0.09677236154675484), (6, 0.0884302444756031), (7, 0.07856730744242668), (8, 0.07990983501076698), (9, 0.09290141612291336), (10, 0.09313157200813293), (11, 0.07496803253889084), (12, 0.09963778406381607), (13, 0.08525428175926208), (14, 0.07498527690768242), (15, 0.06685511767864227), (16, 0.08074154704809189), (17, 0.07277329079806805), (18, 0.25569865852594376), (19, 0.06434531137347221), (20, 0.06464772298932076), (21, 0.06511262990534306), (22, 0.06391118839383125), (23, 0.05953352153301239), (24, 0.06313130632042885), (25, 0.05803953297436237), (36, 0.17892488092184067), (37, 0.05523913539946079)]
computing accuracy for after removing block 37 . block score: 0.05523913539946079
removed block 37 current accuracy 0.4248 loss from initial  0.5751999999999999
training start
training epoch 0 val accuracy 0.6818 topk_dict {'top1': 0.6818} is_best True lr [0.001]
training epoch 1 val accuracy 0.7256 topk_dict {'top1': 0.7256} is_best True lr [0.001]
training epoch 2 val accuracy 0.7494 topk_dict {'top1': 0.7494} is_best True lr [0.001]
training epoch 3 val accuracy 0.7696 topk_dict {'top1': 0.7696} is_best True lr [0.001]
training epoch 4 val accuracy 0.7872 topk_dict {'top1': 0.7872} is_best True lr [0.001]
training epoch 5 val accuracy 0.802 topk_dict {'top1': 0.802} is_best True lr [0.001]
training epoch 6 val accuracy 0.8144 topk_dict {'top1': 0.8144} is_best True lr [0.001]
training epoch 7 val accuracy 0.8252 topk_dict {'top1': 0.8252} is_best True lr [0.001]
training epoch 8 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best True lr [0.001]
training epoch 9 val accuracy 0.84 topk_dict {'top1': 0.84} is_best True lr [0.001]
training epoch 10 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.001]
training epoch 11 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best True lr [0.001]
training epoch 12 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best True lr [0.001]
training epoch 13 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.001]
training epoch 14 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
training epoch 15 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.001]
training epoch 16 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.001]
training epoch 17 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.001]
training epoch 18 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.001]
training epoch 19 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 20 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.001]
training epoch 21 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.001]
training epoch 22 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.001]
training epoch 23 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.001]
training epoch 24 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 25 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.001]
training epoch 26 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.001]
training epoch 27 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.001]
training epoch 28 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 30 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 31 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 32 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.001]
training epoch 33 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 34 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 35 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.001]
training epoch 36 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.001]
training epoch 38 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.001]
training epoch 39 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 40 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 41 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 42 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.001]
training epoch 43 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 44 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.001]
training epoch 45 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 46 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
training epoch 47 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.001]
training epoch 48 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 49 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.910600)
finished training. finished 50 epochs. accuracy 0.9106 topk_dict {'top1': 0.9106}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05548243410885334), (1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (22, 0.06356910429894924), (23, 0.059724899008870125), (24, 0.06310345977544785), (25, 0.058692462742328644), (36, 0.17654887586832047)]
computing accuracy for after removing block 0 . block score: 0.05548243410885334
removed block 0 current accuracy 0.893 loss from initial  0.10699999999999998
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (22, 0.06356910429894924), (23, 0.059724899008870125), (24, 0.06310345977544785), (25, 0.058692462742328644), (36, 0.17654887586832047)]
computing accuracy for after removing block 25 . block score: 0.058692462742328644
removed block 25 current accuracy 0.7512 loss from initial  0.24880000000000002
since last training loss: 0.1594 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (22, 0.06356910429894924), (23, 0.059724899008870125), (24, 0.06310345977544785), (36, 0.17654887586832047)]
computing accuracy for after removing block 23 . block score: 0.059724899008870125
removed block 23 current accuracy 0.6136 loss from initial  0.38639999999999997
since last training loss: 0.29699999999999993 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (22, 0.06356910429894924), (24, 0.06310345977544785), (36, 0.17654887586832047)]
computing accuracy for after removing block 24 . block score: 0.06310345977544785
removed block 24 current accuracy 0.4238 loss from initial  0.5762
since last training loss: 0.48679999999999995 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (22, 0.06356910429894924), (36, 0.17654887586832047)]
computing accuracy for after removing block 22 . block score: 0.06356910429894924
removed block 22 current accuracy 0.3174 loss from initial  0.6826
since last training loss: 0.5932 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (19, 0.06388246640563011), (20, 0.06415473110973835), (21, 0.06465374492108822), (36, 0.17654887586832047)]
computing accuracy for after removing block 19 . block score: 0.06388246640563011
removed block 19 current accuracy 0.2502 loss from initial  0.7498
since last training loss: 0.6604 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (20, 0.06415473110973835), (21, 0.06465374492108822), (36, 0.17654887586832047)]
computing accuracy for after removing block 20 . block score: 0.06415473110973835
removed block 20 current accuracy 0.194 loss from initial  0.806
since last training loss: 0.7165999999999999 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (21, 0.06465374492108822), (36, 0.17654887586832047)]
computing accuracy for after removing block 21 . block score: 0.06465374492108822
removed block 21 current accuracy 0.182 loss from initial  0.8180000000000001
since last training loss: 0.7285999999999999 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (15, 0.06662037037312984), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (36, 0.17654887586832047)]
computing accuracy for after removing block 15 . block score: 0.06662037037312984
removed block 15 current accuracy 0.1566 loss from initial  0.8434
since last training loss: 0.754 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(1, 0.07128723338246346), (2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (36, 0.17654887586832047)]
computing accuracy for after removing block 1 . block score: 0.07128723338246346
removed block 1 current accuracy 0.1242 loss from initial  0.8758
since last training loss: 0.7864 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07600248605012894), (3, 0.0903739221394062), (4, 0.07231728732585907), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (36, 0.17654887586832047)]
computing accuracy for after removing block 4 . block score: 0.07231728732585907
removed block 4 current accuracy 0.1238 loss from initial  0.8762
since last training loss: 0.7867999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07600248605012894), (3, 0.0903739221394062), (5, 0.09586083143949509), (6, 0.08752341940999031), (7, 0.07759278640151024), (8, 0.07887480035424232), (9, 0.09168331697583199), (10, 0.09215499833226204), (11, 0.07418473809957504), (12, 0.09858566522598267), (13, 0.08417538180947304), (14, 0.0746903195977211), (16, 0.07982897758483887), (17, 0.0724429078400135), (18, 0.25251738727092743), (36, 0.17654887586832047)]
computing accuracy for after removing block 17 . block score: 0.0724429078400135
removed block 17 current accuracy 0.143 loss from initial  0.857
training start
training epoch 0 val accuracy 0.666 topk_dict {'top1': 0.666} is_best True lr [0.001]
training epoch 1 val accuracy 0.6976 topk_dict {'top1': 0.6976} is_best True lr [0.001]
training epoch 2 val accuracy 0.7238 topk_dict {'top1': 0.7238} is_best True lr [0.001]
training epoch 3 val accuracy 0.7358 topk_dict {'top1': 0.7358} is_best True lr [0.001]
training epoch 4 val accuracy 0.7502 topk_dict {'top1': 0.7502} is_best True lr [0.001]
training epoch 5 val accuracy 0.7584 topk_dict {'top1': 0.7584} is_best True lr [0.001]
training epoch 6 val accuracy 0.7616 topk_dict {'top1': 0.7616} is_best True lr [0.001]
training epoch 7 val accuracy 0.7694 topk_dict {'top1': 0.7694} is_best True lr [0.001]
training epoch 8 val accuracy 0.7692 topk_dict {'top1': 0.7692} is_best False lr [0.001]
training epoch 9 val accuracy 0.7704 topk_dict {'top1': 0.7704} is_best True lr [0.001]
training epoch 10 val accuracy 0.7864 topk_dict {'top1': 0.7864} is_best True lr [0.001]
training epoch 11 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best True lr [0.001]
training epoch 12 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best True lr [0.001]
training epoch 13 val accuracy 0.7984 topk_dict {'top1': 0.7984} is_best True lr [0.001]
training epoch 14 val accuracy 0.8026 topk_dict {'top1': 0.8026} is_best True lr [0.001]
training epoch 15 val accuracy 0.8046 topk_dict {'top1': 0.8046} is_best True lr [0.001]
training epoch 16 val accuracy 0.8088 topk_dict {'top1': 0.8088} is_best True lr [0.001]
training epoch 17 val accuracy 0.8046 topk_dict {'top1': 0.8046} is_best False lr [0.001]
training epoch 18 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best True lr [0.001]
training epoch 19 val accuracy 0.8084 topk_dict {'top1': 0.8084} is_best False lr [0.001]
training epoch 20 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best True lr [0.001]
training epoch 21 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best True lr [0.001]
training epoch 22 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best False lr [0.001]
training epoch 23 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.001]
training epoch 24 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.001]
training epoch 25 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 26 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.001]
training epoch 27 val accuracy 0.8254 topk_dict {'top1': 0.8254} is_best True lr [0.001]
training epoch 28 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best True lr [0.001]
training epoch 29 val accuracy 0.8292 topk_dict {'top1': 0.8292} is_best True lr [0.001]
training epoch 30 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best True lr [0.001]
training epoch 31 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.001]
training epoch 32 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.001]
training epoch 33 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best True lr [0.001]
training epoch 34 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best True lr [0.001]
training epoch 35 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best False lr [0.001]
training epoch 36 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best False lr [0.001]
training epoch 37 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.001]
training epoch 38 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.001]
training epoch 39 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best False lr [0.001]
training epoch 40 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.001]
training epoch 41 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best True lr [0.001]
training epoch 42 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.001]
training epoch 43 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.001]
training epoch 44 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.001]
training epoch 45 val accuracy 0.841 topk_dict {'top1': 0.841} is_best False lr [0.001]
training epoch 46 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.001]
training epoch 47 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.001]
training epoch 48 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.001]
training epoch 49 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.843800)
finished training. finished 50 epochs. accuracy 0.8438 topk_dict {'top1': 0.8438}
