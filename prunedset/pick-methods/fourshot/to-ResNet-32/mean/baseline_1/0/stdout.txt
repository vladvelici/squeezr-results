start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 21 . block score: 0.04090827330946922
removed block 21 current accuracy 0.9954 loss from initial  0.0046000000000000485
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 5 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (20, 0.04168568179011345), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (30, 0.04359159246087074), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (42, 0.043262045830488205), (43, 0.04268786124885082), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (47, 0.04438243806362152), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 20 . block score: 0.04168568179011345
removed block 20 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (30, 0.04359159246087074), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (42, 0.043262045830488205), (43, 0.04268786124885082), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (47, 0.04438243806362152), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 43 . block score: 0.04268786124885082
removed block 43 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (30, 0.04359159246087074), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (42, 0.043262045830488205), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (47, 0.04438243806362152), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 42 . block score: 0.043262045830488205
removed block 42 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (30, 0.04359159246087074), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (47, 0.04438243806362152), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 30 . block score: 0.04359159246087074
removed block 30 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (47, 0.04438243806362152), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 47 . block score: 0.04438243806362152
removed block 47 current accuracy 0.9888 loss from initial  0.011199999999999988
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (44, 0.04460378736257553), (45, 0.0467030331492424), (46, 0.044813286513090134), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 44 . block score: 0.04460378736257553
removed block 44 current accuracy 0.984 loss from initial  0.016000000000000014
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (26, 0.044673264026641846), (28, 0.04629369266331196), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (45, 0.0467030331492424), (46, 0.044813286513090134), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 26 . block score: 0.044673264026641846
removed block 26 current accuracy 0.9772 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (28, 0.04629369266331196), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (45, 0.0467030331492424), (46, 0.044813286513090134), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 46 . block score: 0.044813286513090134
removed block 46 current accuracy 0.9692 loss from initial  0.03080000000000005
since last training loss: 0.03080000000000005 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06301482394337654), (1, 0.10506685450673103), (2, 0.0841127373278141), (3, 0.09119027107954025), (4, 0.08393528312444687), (5, 0.08869926631450653), (6, 0.09315629675984383), (7, 0.08276422694325447), (8, 0.08306034654378891), (9, 0.06327207945287228), (10, 0.054768215864896774), (11, 0.06309182569384575), (12, 0.060321688652038574), (13, 0.052027229219675064), (14, 0.06508823484182358), (15, 0.07312433421611786), (16, 0.07099050655961037), (17, 0.06614014692604542), (18, 0.2163488306105137), (22, 0.049524495378136635), (23, 0.05079074390232563), (24, 0.04488433711230755), (25, 0.04712635092437267), (28, 0.04629369266331196), (36, 0.16358428448438644), (37, 0.04751504212617874), (38, 0.04641188494861126), (39, 0.044832680374383926), (40, 0.04527896083891392), (41, 0.04526557959616184), (45, 0.0467030331492424), (48, 0.04511761665344238), (49, 0.04643477313220501), (50, 0.04760070703923702), (51, 0.04879644326865673), (52, 0.049617694690823555), (53, 0.05186543054878712)]
computing accuracy for after removing block 39 . block score: 0.044832680374383926
removed block 39 current accuracy 0.9588 loss from initial  0.041200000000000014
training start
training epoch 0 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 1 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 2 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 3 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 4 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 5 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 6 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 7 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 8 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 9 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 10 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 11 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 12 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 13 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 14 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 15 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 16 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 17 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 18 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 19 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 20 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 21 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 23 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 24 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 25 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 27 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 28 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 29 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 32 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 33 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 34 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 35 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 36 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 37 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 39 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 40 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 41 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 42 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 43 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 44 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 45 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 46 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 47 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 49 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.998200)
finished training. finished 50 epochs. accuracy 0.9982 topk_dict {'top1': 0.9982}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (24, 0.04440637305378914), (25, 0.046608442440629005), (28, 0.04579894430935383), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (40, 0.04474136047065258), (41, 0.0447306502610445), (45, 0.04614709131419659), (48, 0.044598452746868134), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 24 . block score: 0.04440637305378914
removed block 24 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (28, 0.04579894430935383), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (40, 0.04474136047065258), (41, 0.0447306502610445), (45, 0.04614709131419659), (48, 0.044598452746868134), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 48 . block score: 0.044598452746868134
removed block 48 current accuracy 0.9822 loss from initial  0.017800000000000038
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (28, 0.04579894430935383), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (40, 0.04474136047065258), (41, 0.0447306502610445), (45, 0.04614709131419659), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 41 . block score: 0.0447306502610445
removed block 41 current accuracy 0.9674 loss from initial  0.03259999999999996
since last training loss: 0.03079999999999994 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (28, 0.04579894430935383), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (40, 0.04474136047065258), (45, 0.04614709131419659), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 40 . block score: 0.04474136047065258
removed block 40 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (28, 0.04579894430935383), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (45, 0.04614709131419659), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 28 . block score: 0.04579894430935383
removed block 28 current accuracy 0.9268 loss from initial  0.07320000000000004
since last training loss: 0.07140000000000002 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (36, 0.16171294823288918), (37, 0.04695667512714863), (38, 0.045852646231651306), (45, 0.04614709131419659), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 38 . block score: 0.045852646231651306
removed block 38 current accuracy 0.8954 loss from initial  0.10460000000000003
since last training loss: 0.1028 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (36, 0.16171294823288918), (37, 0.04695667512714863), (45, 0.04614709131419659), (49, 0.04588688164949417), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 49 . block score: 0.04588688164949417
removed block 49 current accuracy 0.8348 loss from initial  0.1652
since last training loss: 0.1634 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (36, 0.16171294823288918), (37, 0.04695667512714863), (45, 0.04614709131419659), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 45 . block score: 0.04614709131419659
removed block 45 current accuracy 0.7786 loss from initial  0.22140000000000004
since last training loss: 0.21960000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06229180656373501), (1, 0.10382544249296188), (2, 0.0831385999917984), (3, 0.09012849628925323), (4, 0.08292706683278084), (5, 0.08765347301959991), (6, 0.09205569699406624), (7, 0.08177958056330681), (8, 0.08208932727575302), (9, 0.06250149011611938), (10, 0.05416097119450569), (11, 0.06235793046653271), (12, 0.059612905606627464), (13, 0.05145292729139328), (14, 0.06432030349969864), (15, 0.0723600909113884), (16, 0.07022477313876152), (17, 0.06548546068370342), (18, 0.2138606645166874), (22, 0.04897533543407917), (23, 0.05023803934454918), (25, 0.046608442440629005), (36, 0.16171294823288918), (37, 0.04695667512714863), (50, 0.047043461352586746), (51, 0.04822678118944168), (52, 0.04904058761894703), (53, 0.05124858766794205)]
computing accuracy for after removing block 25 . block score: 0.046608442440629005
removed block 25 current accuracy 0.726 loss from initial  0.274
training start
training epoch 0 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 1 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 2 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.001]
training epoch 3 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.001]
training epoch 4 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.001]
training epoch 5 val accuracy 0.9608 topk_dict {'top1': 0.9608} is_best True lr [0.001]
training epoch 6 val accuracy 0.9606 topk_dict {'top1': 0.9606} is_best False lr [0.001]
training epoch 7 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.001]
training epoch 8 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 9 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.001]
training epoch 10 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.001]
training epoch 11 val accuracy 0.9672 topk_dict {'top1': 0.9672} is_best True lr [0.001]
training epoch 12 val accuracy 0.966 topk_dict {'top1': 0.966} is_best False lr [0.001]
training epoch 13 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.001]
training epoch 14 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.001]
training epoch 15 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.001]
training epoch 16 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best True lr [0.001]
training epoch 17 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.001]
training epoch 18 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.001]
training epoch 19 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 20 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.001]
training epoch 21 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best True lr [0.001]
training epoch 22 val accuracy 0.967 topk_dict {'top1': 0.967} is_best False lr [0.001]
training epoch 23 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.001]
training epoch 24 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.001]
training epoch 25 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 26 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.001]
training epoch 27 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.001]
training epoch 28 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best True lr [0.001]
training epoch 29 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.001]
training epoch 30 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.001]
training epoch 31 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best True lr [0.001]
training epoch 32 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best True lr [0.001]
training epoch 33 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 34 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.001]
training epoch 35 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best True lr [0.001]
training epoch 36 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
training epoch 37 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.001]
training epoch 38 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.001]
training epoch 39 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.001]
training epoch 40 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.001]
training epoch 41 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
training epoch 42 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 43 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 44 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
training epoch 45 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 46 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 48 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 49 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.973400)
finished training. finished 50 epochs. accuracy 0.9734 topk_dict {'top1': 0.9734}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (22, 0.04870571568608284), (23, 0.04988875985145569), (36, 0.15954815968871117), (37, 0.046488476917147636), (50, 0.046598633751273155), (51, 0.04772818088531494), (52, 0.04847893863916397), (53, 0.05051675997674465)]
computing accuracy for after removing block 37 . block score: 0.046488476917147636
removed block 37 current accuracy 0.924 loss from initial  0.07599999999999996
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (22, 0.04870571568608284), (23, 0.04988875985145569), (36, 0.15954815968871117), (50, 0.046598633751273155), (51, 0.04772818088531494), (52, 0.04847893863916397), (53, 0.05051675997674465)]
computing accuracy for after removing block 50 . block score: 0.046598633751273155
removed block 50 current accuracy 0.8388 loss from initial  0.1612
since last training loss: 0.13460000000000005 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (22, 0.04870571568608284), (23, 0.04988875985145569), (36, 0.15954815968871117), (51, 0.04772818088531494), (52, 0.04847893863916397), (53, 0.05051675997674465)]
computing accuracy for after removing block 51 . block score: 0.04772818088531494
removed block 51 current accuracy 0.6922 loss from initial  0.30779999999999996
since last training loss: 0.2812 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (22, 0.04870571568608284), (23, 0.04988875985145569), (36, 0.15954815968871117), (52, 0.04847893863916397), (53, 0.05051675997674465)]
computing accuracy for after removing block 52 . block score: 0.04847893863916397
removed block 52 current accuracy 0.4566 loss from initial  0.5434
since last training loss: 0.5168 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (22, 0.04870571568608284), (23, 0.04988875985145569), (36, 0.15954815968871117), (53, 0.05051675997674465)]
computing accuracy for after removing block 22 . block score: 0.04870571568608284
removed block 22 current accuracy 0.422 loss from initial  0.5780000000000001
since last training loss: 0.5514000000000001 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (23, 0.04988875985145569), (36, 0.15954815968871117), (53, 0.05051675997674465)]
computing accuracy for after removing block 23 . block score: 0.04988875985145569
removed block 23 current accuracy 0.3772 loss from initial  0.6228
since last training loss: 0.5962000000000001 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117), (53, 0.05051675997674465)]
computing accuracy for after removing block 53 . block score: 0.05051675997674465
removed block 53 current accuracy 0.3222 loss from initial  0.6778
since last training loss: 0.6512 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (13, 0.050889695063233376), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117)]
computing accuracy for after removing block 13 . block score: 0.050889695063233376
removed block 13 current accuracy 0.3216 loss from initial  0.6784
since last training loss: 0.6518 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (10, 0.053467972204089165), (11, 0.061585111543536186), (12, 0.058932699263095856), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117)]
computing accuracy for after removing block 10 . block score: 0.053467972204089165
removed block 10 current accuracy 0.317 loss from initial  0.683
since last training loss: 0.6564000000000001 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (11, 0.061585111543536186), (12, 0.058932699263095856), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117)]
computing accuracy for after removing block 12 . block score: 0.058932699263095856
removed block 12 current accuracy 0.3294 loss from initial  0.6706
since last training loss: 0.644 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.061525553464889526), (1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (11, 0.061585111543536186), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117)]
computing accuracy for after removing block 0 . block score: 0.061525553464889526
removed block 0 current accuracy 0.3396 loss from initial  0.6604
since last training loss: 0.6338 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(1, 0.1023298054933548), (2, 0.08214479684829712), (3, 0.08896291255950928), (4, 0.08187934011220932), (5, 0.08649152889847755), (6, 0.090778898447752), (7, 0.08077579364180565), (8, 0.08111388236284256), (9, 0.061821579933166504), (11, 0.061585111543536186), (14, 0.06345679983496666), (15, 0.0716836117208004), (16, 0.06941664032638073), (17, 0.06487109139561653), (18, 0.21130765974521637), (36, 0.15954815968871117)]
computing accuracy for after removing block 11 . block score: 0.061585111543536186
removed block 11 current accuracy 0.3454 loss from initial  0.6546000000000001
training start
training epoch 0 val accuracy 0.5538 topk_dict {'top1': 0.5538} is_best True lr [0.001]
training epoch 1 val accuracy 0.5974 topk_dict {'top1': 0.5974} is_best True lr [0.001]
training epoch 2 val accuracy 0.6294 topk_dict {'top1': 0.6294} is_best True lr [0.001]
training epoch 3 val accuracy 0.6584 topk_dict {'top1': 0.6584} is_best True lr [0.001]
training epoch 4 val accuracy 0.6776 topk_dict {'top1': 0.6776} is_best True lr [0.001]
training epoch 5 val accuracy 0.691 topk_dict {'top1': 0.691} is_best True lr [0.001]
training epoch 6 val accuracy 0.7028 topk_dict {'top1': 0.7028} is_best True lr [0.001]
training epoch 7 val accuracy 0.7176 topk_dict {'top1': 0.7176} is_best True lr [0.001]
training epoch 8 val accuracy 0.7294 topk_dict {'top1': 0.7294} is_best True lr [0.001]
training epoch 9 val accuracy 0.7348 topk_dict {'top1': 0.7348} is_best True lr [0.001]
training epoch 10 val accuracy 0.7458 topk_dict {'top1': 0.7458} is_best True lr [0.001]
training epoch 11 val accuracy 0.7488 topk_dict {'top1': 0.7488} is_best True lr [0.001]
training epoch 12 val accuracy 0.757 topk_dict {'top1': 0.757} is_best True lr [0.001]
training epoch 13 val accuracy 0.759 topk_dict {'top1': 0.759} is_best True lr [0.001]
training epoch 14 val accuracy 0.7566 topk_dict {'top1': 0.7566} is_best False lr [0.001]
training epoch 15 val accuracy 0.7648 topk_dict {'top1': 0.7648} is_best True lr [0.001]
training epoch 16 val accuracy 0.7806 topk_dict {'top1': 0.7806} is_best True lr [0.001]
training epoch 17 val accuracy 0.7792 topk_dict {'top1': 0.7792} is_best False lr [0.001]
training epoch 18 val accuracy 0.7828 topk_dict {'top1': 0.7828} is_best True lr [0.001]
training epoch 19 val accuracy 0.791 topk_dict {'top1': 0.791} is_best True lr [0.001]
training epoch 20 val accuracy 0.7918 topk_dict {'top1': 0.7918} is_best True lr [0.001]
training epoch 21 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 22 val accuracy 0.7942 topk_dict {'top1': 0.7942} is_best False lr [0.001]
training epoch 23 val accuracy 0.797 topk_dict {'top1': 0.797} is_best True lr [0.001]
training epoch 24 val accuracy 0.7996 topk_dict {'top1': 0.7996} is_best True lr [0.001]
training epoch 25 val accuracy 0.8012 topk_dict {'top1': 0.8012} is_best True lr [0.001]
training epoch 26 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best False lr [0.001]
training epoch 27 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best True lr [0.001]
training epoch 28 val accuracy 0.801 topk_dict {'top1': 0.801} is_best False lr [0.001]
training epoch 29 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.001]
training epoch 30 val accuracy 0.813 topk_dict {'top1': 0.813} is_best True lr [0.001]
training epoch 31 val accuracy 0.792 topk_dict {'top1': 0.792} is_best False lr [0.001]
training epoch 32 val accuracy 0.814 topk_dict {'top1': 0.814} is_best True lr [0.001]
training epoch 33 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best True lr [0.001]
training epoch 34 val accuracy 0.8168 topk_dict {'top1': 0.8168} is_best True lr [0.001]
training epoch 35 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best False lr [0.001]
training epoch 36 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.001]
training epoch 37 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best True lr [0.001]
training epoch 38 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best True lr [0.001]
training epoch 39 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.001]
training epoch 40 val accuracy 0.7986 topk_dict {'top1': 0.7986} is_best False lr [0.001]
training epoch 41 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best True lr [0.001]
training epoch 42 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best False lr [0.001]
training epoch 43 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best True lr [0.001]
training epoch 44 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.001]
training epoch 45 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.001]
training epoch 46 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best True lr [0.001]
training epoch 47 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.001]
training epoch 48 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best False lr [0.001]
training epoch 49 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.835200)
finished training. finished 50 epochs. accuracy 0.8352 topk_dict {'top1': 0.8352}
