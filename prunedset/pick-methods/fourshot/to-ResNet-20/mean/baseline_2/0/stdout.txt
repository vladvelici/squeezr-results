start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 14 . block score: 0.041135866194963455
removed block 14 current accuracy 0.9892 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 30 . block score: 0.04124109633266926
removed block 30 current accuracy 0.975 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 24 . block score: 0.04178864695131779
removed block 24 current accuracy 0.9622 loss from initial  0.037799999999999945
training start
training epoch 0 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 33 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (21, 0.04189456254243851), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (29, 0.041770873591303825), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (38, 0.04193687252700329), (39, 0.04154208116233349), (40, 0.042182451114058495), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 39 . block score: 0.04154208116233349
removed block 39 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (21, 0.04189456254243851), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (29, 0.041770873591303825), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (38, 0.04193687252700329), (40, 0.042182451114058495), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 29 . block score: 0.041770873591303825
removed block 29 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (21, 0.04189456254243851), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (38, 0.04193687252700329), (40, 0.042182451114058495), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 21 . block score: 0.04189456254243851
removed block 21 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (38, 0.04193687252700329), (40, 0.042182451114058495), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 38 . block score: 0.04193687252700329
removed block 38 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (40, 0.042182451114058495), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 40 . block score: 0.042182451114058495
removed block 40 current accuracy 0.9874 loss from initial  0.012599999999999945
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (33, 0.042441653087735176), (36, 0.15823157131671906), (37, 0.0427665114402771), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 33 . block score: 0.042441653087735176
removed block 33 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.01880000000000004 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (19, 0.04244250804185867), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (36, 0.15823157131671906), (37, 0.0427665114402771), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 19 . block score: 0.04244250804185867
removed block 19 current accuracy 0.9748 loss from initial  0.0252
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (22, 0.04280264116823673), (27, 0.042475517839193344), (28, 0.04421199671924114), (36, 0.15823157131671906), (37, 0.0427665114402771), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 27 . block score: 0.042475517839193344
removed block 27 current accuracy 0.9604 loss from initial  0.03959999999999997
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (22, 0.04280264116823673), (28, 0.04421199671924114), (36, 0.15823157131671906), (37, 0.0427665114402771), (41, 0.042687470093369484), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 41 . block score: 0.042687470093369484
removed block 41 current accuracy 0.9446 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (22, 0.04280264116823673), (28, 0.04421199671924114), (36, 0.15823157131671906), (37, 0.0427665114402771), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 37 . block score: 0.0427665114402771
removed block 37 current accuracy 0.9288 loss from initial  0.07120000000000004
since last training loss: 0.07120000000000004 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09869411215186119), (1, 0.07617232948541641), (2, 0.09043772518634796), (3, 0.08084507659077644), (4, 0.07462669536471367), (5, 0.06957414001226425), (6, 0.07654578983783722), (7, 0.06055811420083046), (8, 0.0570466760545969), (9, 0.061640942469239235), (10, 0.062229469418525696), (11, 0.051509957760572433), (12, 0.06362209282815456), (13, 0.06674734130501747), (15, 0.060168977826833725), (16, 0.049942076206207275), (17, 0.052181920036673546), (18, 0.20776381343603134), (22, 0.04280264116823673), (28, 0.04421199671924114), (36, 0.15823157131671906), (42, 0.04390777833759785), (43, 0.04443293623626232), (44, 0.04377031698822975), (45, 0.04581553302705288), (46, 0.048547254875302315), (47, 0.050296470522880554), (48, 0.047573087736964226), (49, 0.04932006075978279), (50, 0.04694472253322601), (51, 0.044693075120449066), (52, 0.04342890717089176), (53, 0.05145721882581711)]
computing accuracy for after removing block 22 . block score: 0.04280264116823673
removed block 22 current accuracy 0.8988 loss from initial  0.10119999999999996
training start
training epoch 0 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 1 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 2 val accuracy 0.987 topk_dict {'top1': 0.987} is_best True lr [0.001]
training epoch 3 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 4 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 5 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 6 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 7 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 8 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 9 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best True lr [0.001]
training epoch 10 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 11 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 12 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 13 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 14 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 15 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 16 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 17 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 18 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 19 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 20 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 21 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 22 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 23 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 24 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 25 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 26 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 27 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 28 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 29 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 30 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 31 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 32 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 33 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 34 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 35 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 36 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 37 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 38 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 39 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 40 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 42 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 43 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 45 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 46 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 47 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 48 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 49 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.994600)
finished training. finished 50 epochs. accuracy 0.9946 topk_dict {'top1': 0.9946}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (28, 0.04398545250296593), (36, 0.15591491386294365), (42, 0.04335111752152443), (43, 0.04385543055832386), (44, 0.04321571812033653), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (52, 0.04286438412964344), (53, 0.05075322650372982)]
computing accuracy for after removing block 52 . block score: 0.04286438412964344
removed block 52 current accuracy 0.9844 loss from initial  0.015599999999999947
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (28, 0.04398545250296593), (36, 0.15591491386294365), (42, 0.04335111752152443), (43, 0.04385543055832386), (44, 0.04321571812033653), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (53, 0.05075322650372982)]
computing accuracy for after removing block 44 . block score: 0.04321571812033653
removed block 44 current accuracy 0.9698 loss from initial  0.030200000000000005
since last training loss: 0.024800000000000044 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (28, 0.04398545250296593), (36, 0.15591491386294365), (42, 0.04335111752152443), (43, 0.04385543055832386), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (53, 0.05075322650372982)]
computing accuracy for after removing block 42 . block score: 0.04335111752152443
removed block 42 current accuracy 0.95 loss from initial  0.050000000000000044
since last training loss: 0.044600000000000084 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (28, 0.04398545250296593), (36, 0.15591491386294365), (43, 0.04385543055832386), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (53, 0.05075322650372982)]
computing accuracy for after removing block 43 . block score: 0.04385543055832386
removed block 43 current accuracy 0.9184 loss from initial  0.0816
since last training loss: 0.07620000000000005 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (28, 0.04398545250296593), (36, 0.15591491386294365), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (53, 0.05075322650372982)]
computing accuracy for after removing block 28 . block score: 0.04398545250296593
removed block 28 current accuracy 0.8288 loss from initial  0.17120000000000002
since last training loss: 0.16580000000000006 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (51, 0.044112103059887886), (53, 0.05075322650372982)]
computing accuracy for after removing block 51 . block score: 0.044112103059887886
removed block 51 current accuracy 0.7414 loss from initial  0.25860000000000005
since last training loss: 0.2532000000000001 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (45, 0.045232925564050674), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (53, 0.05075322650372982)]
computing accuracy for after removing block 45 . block score: 0.045232925564050674
removed block 45 current accuracy 0.7084 loss from initial  0.29159999999999997
since last training loss: 0.2862 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (50, 0.04632750526070595), (53, 0.05075322650372982)]
computing accuracy for after removing block 50 . block score: 0.04632750526070595
removed block 50 current accuracy 0.6266 loss from initial  0.37339999999999995
since last training loss: 0.368 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (46, 0.0479135625064373), (47, 0.04964442178606987), (48, 0.04697728715837002), (49, 0.048694832250475883), (53, 0.05075322650372982)]
computing accuracy for after removing block 48 . block score: 0.04697728715837002
removed block 48 current accuracy 0.57 loss from initial  0.43000000000000005
since last training loss: 0.4246000000000001 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (46, 0.0479135625064373), (47, 0.04964442178606987), (49, 0.048694832250475883), (53, 0.05075322650372982)]
computing accuracy for after removing block 46 . block score: 0.0479135625064373
removed block 46 current accuracy 0.4968 loss from initial  0.5032
since last training loss: 0.4978 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09742745012044907), (1, 0.07523013651371002), (2, 0.08927842229604721), (3, 0.07977687567472458), (4, 0.07371411845088005), (5, 0.06866035610437393), (6, 0.07554133981466293), (7, 0.05984644964337349), (8, 0.056345852091908455), (9, 0.060891347005963326), (10, 0.06149356812238693), (11, 0.05087089166045189), (12, 0.06285740993916988), (13, 0.06599413231015205), (15, 0.05951925925910473), (16, 0.04948882944881916), (17, 0.051679860800504684), (18, 0.20501961559057236), (36, 0.15591491386294365), (47, 0.04964442178606987), (49, 0.048694832250475883), (53, 0.05075322650372982)]
computing accuracy for after removing block 49 . block score: 0.048694832250475883
removed block 49 current accuracy 0.3626 loss from initial  0.6374
training start
training epoch 0 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.001]
training epoch 1 val accuracy 0.858 topk_dict {'top1': 0.858} is_best True lr [0.001]
training epoch 2 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.001]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.001]
training epoch 4 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.001]
training epoch 5 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.001]
training epoch 6 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 7 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 8 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.001]
training epoch 9 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 10 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.001]
training epoch 11 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 12 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
training epoch 13 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.001]
training epoch 14 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.001]
training epoch 15 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 16 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 17 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 18 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 19 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 20 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 21 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 22 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 23 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 24 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 25 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 26 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 27 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 28 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 29 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 30 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 31 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 32 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 33 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 34 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 35 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 36 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 37 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 38 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 39 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 40 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 41 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 42 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 43 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 44 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 45 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 46 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 47 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 48 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 49 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.929800)
finished training. finished 50 epochs. accuracy 0.9298 topk_dict {'top1': 0.9298}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (11, 0.050640540197491646), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (16, 0.050568027421832085), (17, 0.052585944533348083), (18, 0.2029338851571083), (36, 0.15449364855885506), (47, 0.050107698887586594), (53, 0.050452372059226036)]
computing accuracy for after removing block 47 . block score: 0.050107698887586594
removed block 47 current accuracy 0.707 loss from initial  0.29300000000000004
since last training loss: 0.2228 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (11, 0.050640540197491646), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (16, 0.050568027421832085), (17, 0.052585944533348083), (18, 0.2029338851571083), (36, 0.15449364855885506), (53, 0.050452372059226036)]
computing accuracy for after removing block 53 . block score: 0.050452372059226036
removed block 53 current accuracy 0.3652 loss from initial  0.6348
since last training loss: 0.5646 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (11, 0.050640540197491646), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (16, 0.050568027421832085), (17, 0.052585944533348083), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 16 . block score: 0.050568027421832085
removed block 16 current accuracy 0.3566 loss from initial  0.6434
since last training loss: 0.5731999999999999 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (11, 0.050640540197491646), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (17, 0.052585944533348083), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 11 . block score: 0.050640540197491646
removed block 11 current accuracy 0.3492 loss from initial  0.6508
since last training loss: 0.5806 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (17, 0.052585944533348083), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 17 . block score: 0.052585944533348083
removed block 17 current accuracy 0.3438 loss from initial  0.6562
since last training loss: 0.586 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (8, 0.055967068299651146), (9, 0.060716018080711365), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 8 . block score: 0.055967068299651146
removed block 8 current accuracy 0.3504 loss from initial  0.6496
since last training loss: 0.5793999999999999 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (7, 0.059435609728097916), (9, 0.060716018080711365), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 7 . block score: 0.059435609728097916
removed block 7 current accuracy 0.3338 loss from initial  0.6662
since last training loss: 0.596 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (9, 0.060716018080711365), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (15, 0.05963548831641674), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 15 . block score: 0.05963548831641674
removed block 15 current accuracy 0.318 loss from initial  0.6819999999999999
since last training loss: 0.6117999999999999 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (9, 0.060716018080711365), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 9 . block score: 0.060716018080711365
removed block 9 current accuracy 0.287 loss from initial  0.7130000000000001
since last training loss: 0.6428 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (10, 0.061054764315485954), (12, 0.06259854696691036), (13, 0.06567089259624481), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 10 . block score: 0.061054764315485954
removed block 10 current accuracy 0.247 loss from initial  0.753
since last training loss: 0.6828 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (12, 0.06259854696691036), (13, 0.06567089259624481), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 12 . block score: 0.06259854696691036
removed block 12 current accuracy 0.1946 loss from initial  0.8054
since last training loss: 0.7352 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(0, 0.09669133648276329), (1, 0.07458589226007462), (2, 0.08814216032624245), (3, 0.07878057658672333), (4, 0.07299578934907913), (5, 0.06786403432488441), (6, 0.07488256320357323), (13, 0.06567089259624481), (18, 0.2029338851571083), (36, 0.15449364855885506)]
computing accuracy for after removing block 13 . block score: 0.06567089259624481
removed block 13 current accuracy 0.164 loss from initial  0.836
training start
training epoch 0 val accuracy 0.5388 topk_dict {'top1': 0.5388} is_best True lr [0.001]
training epoch 1 val accuracy 0.582 topk_dict {'top1': 0.582} is_best True lr [0.001]
training epoch 2 val accuracy 0.6104 topk_dict {'top1': 0.6104} is_best True lr [0.001]
training epoch 3 val accuracy 0.6418 topk_dict {'top1': 0.6418} is_best True lr [0.001]
training epoch 4 val accuracy 0.6604 topk_dict {'top1': 0.6604} is_best True lr [0.001]
training epoch 5 val accuracy 0.676 topk_dict {'top1': 0.676} is_best True lr [0.001]
training epoch 6 val accuracy 0.6876 topk_dict {'top1': 0.6876} is_best True lr [0.001]
training epoch 7 val accuracy 0.6982 topk_dict {'top1': 0.6982} is_best True lr [0.001]
training epoch 8 val accuracy 0.7066 topk_dict {'top1': 0.7066} is_best True lr [0.001]
training epoch 9 val accuracy 0.72 topk_dict {'top1': 0.72} is_best True lr [0.001]
training epoch 10 val accuracy 0.7238 topk_dict {'top1': 0.7238} is_best True lr [0.001]
training epoch 11 val accuracy 0.723 topk_dict {'top1': 0.723} is_best False lr [0.001]
training epoch 12 val accuracy 0.7364 topk_dict {'top1': 0.7364} is_best True lr [0.001]
training epoch 13 val accuracy 0.7416 topk_dict {'top1': 0.7416} is_best True lr [0.001]
training epoch 14 val accuracy 0.7356 topk_dict {'top1': 0.7356} is_best False lr [0.001]
training epoch 15 val accuracy 0.7394 topk_dict {'top1': 0.7394} is_best False lr [0.001]
training epoch 16 val accuracy 0.754 topk_dict {'top1': 0.754} is_best True lr [0.001]
training epoch 17 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best True lr [0.001]
training epoch 18 val accuracy 0.7654 topk_dict {'top1': 0.7654} is_best True lr [0.001]
training epoch 19 val accuracy 0.7688 topk_dict {'top1': 0.7688} is_best True lr [0.001]
training epoch 20 val accuracy 0.777 topk_dict {'top1': 0.777} is_best True lr [0.001]
training epoch 21 val accuracy 0.7684 topk_dict {'top1': 0.7684} is_best False lr [0.001]
training epoch 22 val accuracy 0.7788 topk_dict {'top1': 0.7788} is_best True lr [0.001]
training epoch 23 val accuracy 0.7798 topk_dict {'top1': 0.7798} is_best True lr [0.001]
training epoch 24 val accuracy 0.7824 topk_dict {'top1': 0.7824} is_best True lr [0.001]
training epoch 25 val accuracy 0.7904 topk_dict {'top1': 0.7904} is_best True lr [0.001]
training epoch 26 val accuracy 0.7864 topk_dict {'top1': 0.7864} is_best False lr [0.001]
training epoch 27 val accuracy 0.787 topk_dict {'top1': 0.787} is_best False lr [0.001]
training epoch 28 val accuracy 0.7986 topk_dict {'top1': 0.7986} is_best True lr [0.001]
training epoch 29 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best False lr [0.001]
training epoch 30 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best False lr [0.001]
training epoch 31 val accuracy 0.7968 topk_dict {'top1': 0.7968} is_best False lr [0.001]
training epoch 32 val accuracy 0.795 topk_dict {'top1': 0.795} is_best False lr [0.001]
training epoch 33 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best False lr [0.001]
training epoch 34 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best True lr [0.001]
training epoch 35 val accuracy 0.803 topk_dict {'top1': 0.803} is_best True lr [0.001]
training epoch 36 val accuracy 0.7938 topk_dict {'top1': 0.7938} is_best False lr [0.001]
training epoch 37 val accuracy 0.808 topk_dict {'top1': 0.808} is_best True lr [0.001]
training epoch 38 val accuracy 0.8036 topk_dict {'top1': 0.8036} is_best False lr [0.001]
training epoch 39 val accuracy 0.8046 topk_dict {'top1': 0.8046} is_best False lr [0.001]
training epoch 40 val accuracy 0.8054 topk_dict {'top1': 0.8054} is_best False lr [0.001]
training epoch 41 val accuracy 0.8052 topk_dict {'top1': 0.8052} is_best False lr [0.001]
training epoch 42 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best True lr [0.001]
training epoch 43 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best False lr [0.001]
training epoch 44 val accuracy 0.8082 topk_dict {'top1': 0.8082} is_best False lr [0.001]
training epoch 45 val accuracy 0.804 topk_dict {'top1': 0.804} is_best False lr [0.001]
training epoch 46 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.001]
training epoch 47 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best True lr [0.001]
training epoch 48 val accuracy 0.8162 topk_dict {'top1': 0.8162} is_best False lr [0.001]
training epoch 49 val accuracy 0.8118 topk_dict {'top1': 0.8118} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.817200)
finished training. finished 50 epochs. accuracy 0.8172 topk_dict {'top1': 0.8172}
