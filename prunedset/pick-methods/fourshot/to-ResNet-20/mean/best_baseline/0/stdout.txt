start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9886 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 49 . block score: 0.0467995535582304
removed block 49 current accuracy 0.9724 loss from initial  0.027599999999999958
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 51 . block score: 0.04713763669133186
removed block 51 current accuracy 0.9276 loss from initial  0.07240000000000002
since last training loss: 0.07240000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 29 . block score: 0.04715948365628719
removed block 29 current accuracy 0.9168 loss from initial  0.08320000000000005
training start
training epoch 0 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 1 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 2 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 3 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 4 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 5 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 6 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 7 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 8 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 9 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 10 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 11 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 12 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 13 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 14 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 15 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 16 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 20 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 21 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 23 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 24 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 25 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 28 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 29 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 32 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 33 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 34 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 35 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 37 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 41 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 43 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 45 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 46 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 47 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 48 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 49 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
loading model_best from epoch 19 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (35, 0.047372713685035706), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (41, 0.049532199278473854), (42, 0.04981228709220886), (43, 0.048525748774409294), (44, 0.05044778436422348), (45, 0.04867284931242466), (46, 0.04825301468372345), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 35 . block score: 0.047372713685035706
removed block 35 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (41, 0.049532199278473854), (42, 0.04981228709220886), (43, 0.048525748774409294), (44, 0.05044778436422348), (45, 0.04867284931242466), (46, 0.04825301468372345), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 46 . block score: 0.04825301468372345
removed block 46 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (41, 0.049532199278473854), (42, 0.04981228709220886), (43, 0.048525748774409294), (44, 0.05044778436422348), (45, 0.04867284931242466), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 43 . block score: 0.048525748774409294
removed block 43 current accuracy 0.9878 loss from initial  0.012199999999999989
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (41, 0.049532199278473854), (42, 0.04981228709220886), (44, 0.05044778436422348), (45, 0.04867284931242466), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 45 . block score: 0.04867284931242466
removed block 45 current accuracy 0.973 loss from initial  0.027000000000000024
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (41, 0.049532199278473854), (42, 0.04981228709220886), (44, 0.05044778436422348), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 41 . block score: 0.049532199278473854
removed block 41 current accuracy 0.9616 loss from initial  0.03839999999999999
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (42, 0.04981228709220886), (44, 0.05044778436422348), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 42 . block score: 0.04981228709220886
removed block 42 current accuracy 0.9388 loss from initial  0.06120000000000003
since last training loss: 0.059800000000000075 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (44, 0.05044778436422348), (47, 0.05009916052222252), (53, 0.05333570018410683)]
computing accuracy for after removing block 47 . block score: 0.05009916052222252
removed block 47 current accuracy 0.8622 loss from initial  0.13780000000000003
since last training loss: 0.13640000000000008 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (44, 0.05044778436422348), (53, 0.05333570018410683)]
computing accuracy for after removing block 44 . block score: 0.05044778436422348
removed block 44 current accuracy 0.7972 loss from initial  0.20279999999999998
since last training loss: 0.20140000000000002 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (40, 0.050560176372528076), (53, 0.05333570018410683)]
computing accuracy for after removing block 40 . block score: 0.050560176372528076
removed block 40 current accuracy 0.7616 loss from initial  0.23839999999999995
since last training loss: 0.237 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (28, 0.05314009077847004), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (53, 0.05333570018410683)]
computing accuracy for after removing block 28 . block score: 0.05314009077847004
removed block 28 current accuracy 0.7502 loss from initial  0.24980000000000002
since last training loss: 0.24840000000000007 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05700306035578251), (1, 0.07351353019475937), (2, 0.07850805297493935), (3, 0.09330128878355026), (4, 0.0746801495552063), (5, 0.09852755442261696), (6, 0.0900990217924118), (7, 0.08003490045666695), (8, 0.08146501705050468), (9, 0.09470734372735023), (10, 0.09485676139593124), (11, 0.07637692242860794), (12, 0.10158425197005272), (13, 0.08685300871729851), (14, 0.07634167745709419), (15, 0.06804962456226349), (16, 0.08229005336761475), (17, 0.07409564591944218), (18, 0.26081033051013947), (19, 0.06558650359511375), (20, 0.06588005647063255), (21, 0.06636855937540531), (22, 0.06517416425049305), (23, 0.06068682670593262), (24, 0.06432919763028622), (25, 0.059162918478250504), (26, 0.053547607734799385), (27, 0.05328652076423168), (36, 0.18243075162172318), (37, 0.056332582607865334), (38, 0.05577136017382145), (39, 0.056041864678263664), (53, 0.05333570018410683)]
computing accuracy for after removing block 27 . block score: 0.05328652076423168
removed block 27 current accuracy 0.734 loss from initial  0.266
training start
training epoch 0 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 1 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 2 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 3 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 4 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 5 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 6 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 7 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.001]
training epoch 8 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.001]
training epoch 9 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.001]
training epoch 10 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.001]
training epoch 11 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.001]
training epoch 12 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.001]
training epoch 13 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.001]
training epoch 14 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.001]
training epoch 15 val accuracy 0.9638 topk_dict {'top1': 0.9638} is_best True lr [0.001]
training epoch 16 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.001]
training epoch 17 val accuracy 0.967 topk_dict {'top1': 0.967} is_best True lr [0.001]
training epoch 18 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.001]
training epoch 19 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.001]
training epoch 20 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.001]
training epoch 21 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 22 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.001]
training epoch 23 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.001]
training epoch 24 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.001]
training epoch 25 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.001]
training epoch 26 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.001]
training epoch 27 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.001]
training epoch 28 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 29 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 30 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.001]
training epoch 31 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 32 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.001]
training epoch 33 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.001]
training epoch 34 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.001]
training epoch 35 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.001]
training epoch 36 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 37 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best True lr [0.001]
training epoch 38 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 39 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.001]
training epoch 40 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 41 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 42 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best False lr [0.001]
training epoch 43 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 44 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.001]
training epoch 45 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 46 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 47 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 48 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 49 val accuracy 0.976 topk_dict {'top1': 0.976} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.976 topk_dict {'top1': 0.976}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (26, 0.05282162129878998), (36, 0.1798982247710228), (37, 0.05549526587128639), (38, 0.055036578327417374), (39, 0.055305689573287964), (53, 0.05261575989425182)]
computing accuracy for after removing block 53 . block score: 0.05261575989425182
removed block 53 current accuracy 0.6832 loss from initial  0.31679999999999997
since last training loss: 0.29279999999999995 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (26, 0.05282162129878998), (36, 0.1798982247710228), (37, 0.05549526587128639), (38, 0.055036578327417374), (39, 0.055305689573287964)]
computing accuracy for after removing block 26 . block score: 0.05282162129878998
removed block 26 current accuracy 0.6542 loss from initial  0.3458
since last training loss: 0.3218 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (36, 0.1798982247710228), (37, 0.05549526587128639), (38, 0.055036578327417374), (39, 0.055305689573287964)]
computing accuracy for after removing block 38 . block score: 0.055036578327417374
removed block 38 current accuracy 0.5994 loss from initial  0.40059999999999996
since last training loss: 0.37659999999999993 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (36, 0.1798982247710228), (37, 0.05549526587128639), (39, 0.055305689573287964)]
computing accuracy for after removing block 39 . block score: 0.055305689573287964
removed block 39 current accuracy 0.464 loss from initial  0.536
since last training loss: 0.512 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (36, 0.1798982247710228), (37, 0.05549526587128639)]
computing accuracy for after removing block 37 . block score: 0.05549526587128639
removed block 37 current accuracy 0.4426 loss from initial  0.5574
since last training loss: 0.5334 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05627582222223282), (1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (36, 0.1798982247710228)]
computing accuracy for after removing block 0 . block score: 0.05627582222223282
removed block 0 current accuracy 0.4246 loss from initial  0.5754
since last training loss: 0.5514 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (25, 0.0583751667290926), (36, 0.1798982247710228)]
computing accuracy for after removing block 25 . block score: 0.0583751667290926
removed block 25 current accuracy 0.4224 loss from initial  0.5776
since last training loss: 0.5536 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (23, 0.05981611832976341), (24, 0.06342089176177979), (36, 0.1798982247710228)]
computing accuracy for after removing block 23 . block score: 0.05981611832976341
removed block 23 current accuracy 0.4156 loss from initial  0.5844
since last training loss: 0.5604 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (24, 0.06342089176177979), (36, 0.1798982247710228)]
computing accuracy for after removing block 24 . block score: 0.06342089176177979
removed block 24 current accuracy 0.392 loss from initial  0.608
since last training loss: 0.584 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (22, 0.06422287225723267), (36, 0.1798982247710228)]
computing accuracy for after removing block 22 . block score: 0.06422287225723267
removed block 22 current accuracy 0.3768 loss from initial  0.6232
since last training loss: 0.5992 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.07253590226173401), (2, 0.0773543119430542), (3, 0.0918867401778698), (4, 0.0735696367919445), (5, 0.09723256900906563), (6, 0.08888739719986916), (7, 0.07892652601003647), (8, 0.0803116075694561), (9, 0.09330970048904419), (10, 0.09354295209050179), (11, 0.0753149688243866), (12, 0.10013671591877937), (13, 0.08565974235534668), (14, 0.07534371688961983), (15, 0.06722067855298519), (16, 0.08112102746963501), (17, 0.07311903312802315), (18, 0.25691595673561096), (19, 0.06464951485395432), (20, 0.06496483832597733), (21, 0.06543982774019241), (36, 0.1798982247710228)]
computing accuracy for after removing block 19 . block score: 0.06464951485395432
removed block 19 current accuracy 0.3718 loss from initial  0.6282
training start
training epoch 0 val accuracy 0.6148 topk_dict {'top1': 0.6148} is_best True lr [0.001]
training epoch 1 val accuracy 0.6552 topk_dict {'top1': 0.6552} is_best True lr [0.001]
training epoch 2 val accuracy 0.6812 topk_dict {'top1': 0.6812} is_best True lr [0.001]
training epoch 3 val accuracy 0.702 topk_dict {'top1': 0.702} is_best True lr [0.001]
training epoch 4 val accuracy 0.7238 topk_dict {'top1': 0.7238} is_best True lr [0.001]
training epoch 5 val accuracy 0.731 topk_dict {'top1': 0.731} is_best True lr [0.001]
training epoch 6 val accuracy 0.742 topk_dict {'top1': 0.742} is_best True lr [0.001]
training epoch 7 val accuracy 0.7522 topk_dict {'top1': 0.7522} is_best True lr [0.001]
training epoch 8 val accuracy 0.7618 topk_dict {'top1': 0.7618} is_best True lr [0.001]
training epoch 9 val accuracy 0.7658 topk_dict {'top1': 0.7658} is_best True lr [0.001]
training epoch 10 val accuracy 0.7798 topk_dict {'top1': 0.7798} is_best True lr [0.001]
training epoch 11 val accuracy 0.7894 topk_dict {'top1': 0.7894} is_best True lr [0.001]
training epoch 12 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best True lr [0.001]
training epoch 13 val accuracy 0.8 topk_dict {'top1': 0.8} is_best True lr [0.001]
training epoch 14 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best True lr [0.001]
training epoch 15 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best True lr [0.001]
training epoch 16 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best True lr [0.001]
training epoch 17 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best True lr [0.001]
training epoch 18 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best False lr [0.001]
training epoch 19 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best True lr [0.001]
training epoch 20 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best True lr [0.001]
training epoch 21 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best True lr [0.001]
training epoch 22 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best True lr [0.001]
training epoch 23 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best True lr [0.001]
training epoch 24 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best True lr [0.001]
training epoch 25 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best True lr [0.001]
training epoch 26 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.001]
training epoch 27 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.001]
training epoch 28 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best True lr [0.001]
training epoch 29 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.001]
training epoch 30 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.001]
training epoch 31 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best True lr [0.001]
training epoch 32 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best True lr [0.001]
training epoch 33 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.001]
training epoch 34 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.001]
training epoch 35 val accuracy 0.861 topk_dict {'top1': 0.861} is_best True lr [0.001]
training epoch 36 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.001]
training epoch 37 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.001]
training epoch 38 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.001]
training epoch 39 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.001]
training epoch 40 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.001]
training epoch 41 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.001]
training epoch 42 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.001]
training epoch 43 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.001]
training epoch 44 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.001]
training epoch 45 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.001]
training epoch 46 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.001]
training epoch 47 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.001]
training epoch 48 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.001]
training epoch 49 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8736 topk_dict {'top1': 0.8736}
start iteration 33
(cache recomputed : MEAN) score log [(1, 0.07157738134264946), (2, 0.0763898715376854), (3, 0.09079932793974876), (4, 0.07281263917684555), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (15, 0.06819231994450092), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (20, 0.06622940301895142), (21, 0.06616098247468472), (36, 0.17744581028819084)]
computing accuracy for after removing block 21 . block score: 0.06616098247468472
removed block 21 current accuracy 0.6166 loss from initial  0.38339999999999996
since last training loss: 0.257 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(1, 0.07157738134264946), (2, 0.0763898715376854), (3, 0.09079932793974876), (4, 0.07281263917684555), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (15, 0.06819231994450092), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (20, 0.06622940301895142), (36, 0.17744581028819084)]
computing accuracy for after removing block 20 . block score: 0.06622940301895142
removed block 20 current accuracy 0.3972 loss from initial  0.6028
since last training loss: 0.47640000000000005 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(1, 0.07157738134264946), (2, 0.0763898715376854), (3, 0.09079932793974876), (4, 0.07281263917684555), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (15, 0.06819231994450092), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 15 . block score: 0.06819231994450092
removed block 15 current accuracy 0.3794 loss from initial  0.6206
since last training loss: 0.49420000000000003 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(1, 0.07157738134264946), (2, 0.0763898715376854), (3, 0.09079932793974876), (4, 0.07281263917684555), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 1 . block score: 0.07157738134264946
removed block 1 current accuracy 0.3286 loss from initial  0.6714
since last training loss: 0.545 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.0763898715376854), (3, 0.09079932793974876), (4, 0.07281263917684555), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 4 . block score: 0.07281263917684555
removed block 4 current accuracy 0.303 loss from initial  0.6970000000000001
since last training loss: 0.5706 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.0763898715376854), (3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (16, 0.08085539564490318), (17, 0.07317771762609482), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 17 . block score: 0.07317771762609482
removed block 17 current accuracy 0.3076 loss from initial  0.6924
since last training loss: 0.5660000000000001 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(2, 0.0763898715376854), (3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (11, 0.074399184435606), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 11 . block score: 0.074399184435606
removed block 11 current accuracy 0.2778 loss from initial  0.7222
since last training loss: 0.5958000000000001 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(2, 0.0763898715376854), (3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (12, 0.09883979335427284), (13, 0.08480311185121536), (14, 0.07578666508197784), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 14 . block score: 0.07578666508197784
removed block 14 current accuracy 0.2612 loss from initial  0.7388
since last training loss: 0.6124 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(2, 0.0763898715376854), (3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (12, 0.09883979335427284), (13, 0.08480311185121536), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 2 . block score: 0.0763898715376854
removed block 2 current accuracy 0.2342 loss from initial  0.7658
since last training loss: 0.6394000000000001 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (7, 0.0778888426721096), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (12, 0.09883979335427284), (13, 0.08480311185121536), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 7 . block score: 0.0778888426721096
removed block 7 current accuracy 0.2216 loss from initial  0.7784
since last training loss: 0.652 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (8, 0.07945534586906433), (9, 0.09229512512683868), (10, 0.09276776388287544), (12, 0.09883979335427284), (13, 0.08480311185121536), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 8 . block score: 0.07945534586906433
removed block 8 current accuracy 0.1924 loss from initial  0.8076
since last training loss: 0.6812 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(3, 0.09079932793974876), (5, 0.09655273705720901), (6, 0.08835333213210106), (9, 0.09229512512683868), (10, 0.09276776388287544), (12, 0.09883979335427284), (13, 0.08480311185121536), (16, 0.08085539564490318), (18, 0.2542010545730591), (36, 0.17744581028819084)]
computing accuracy for after removing block 16 . block score: 0.08085539564490318
removed block 16 current accuracy 0.1628 loss from initial  0.8371999999999999
training start
training epoch 0 val accuracy 0.688 topk_dict {'top1': 0.688} is_best True lr [0.001]
training epoch 1 val accuracy 0.7194 topk_dict {'top1': 0.7194} is_best True lr [0.001]
training epoch 2 val accuracy 0.7384 topk_dict {'top1': 0.7384} is_best True lr [0.001]
training epoch 3 val accuracy 0.749 topk_dict {'top1': 0.749} is_best True lr [0.001]
training epoch 4 val accuracy 0.7568 topk_dict {'top1': 0.7568} is_best True lr [0.001]
training epoch 5 val accuracy 0.7666 topk_dict {'top1': 0.7666} is_best True lr [0.001]
training epoch 6 val accuracy 0.7672 topk_dict {'top1': 0.7672} is_best True lr [0.001]
training epoch 7 val accuracy 0.773 topk_dict {'top1': 0.773} is_best True lr [0.001]
training epoch 8 val accuracy 0.7806 topk_dict {'top1': 0.7806} is_best True lr [0.001]
training epoch 9 val accuracy 0.7882 topk_dict {'top1': 0.7882} is_best True lr [0.001]
training epoch 10 val accuracy 0.792 topk_dict {'top1': 0.792} is_best True lr [0.001]
training epoch 11 val accuracy 0.793 topk_dict {'top1': 0.793} is_best True lr [0.001]
training epoch 12 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 13 val accuracy 0.7958 topk_dict {'top1': 0.7958} is_best True lr [0.001]
training epoch 14 val accuracy 0.7996 topk_dict {'top1': 0.7996} is_best True lr [0.001]
training epoch 15 val accuracy 0.8002 topk_dict {'top1': 0.8002} is_best True lr [0.001]
training epoch 16 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best False lr [0.001]
training epoch 17 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best True lr [0.001]
training epoch 18 val accuracy 0.8096 topk_dict {'top1': 0.8096} is_best True lr [0.001]
training epoch 19 val accuracy 0.81 topk_dict {'top1': 0.81} is_best True lr [0.001]
training epoch 20 val accuracy 0.8124 topk_dict {'top1': 0.8124} is_best True lr [0.001]
training epoch 21 val accuracy 0.8096 topk_dict {'top1': 0.8096} is_best False lr [0.001]
training epoch 22 val accuracy 0.813 topk_dict {'top1': 0.813} is_best True lr [0.001]
training epoch 23 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best True lr [0.001]
training epoch 24 val accuracy 0.8186 topk_dict {'top1': 0.8186} is_best False lr [0.001]
training epoch 25 val accuracy 0.8242 topk_dict {'top1': 0.8242} is_best True lr [0.001]
training epoch 26 val accuracy 0.815 topk_dict {'top1': 0.815} is_best False lr [0.001]
training epoch 27 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 28 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best False lr [0.001]
training epoch 29 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.001]
training epoch 30 val accuracy 0.82 topk_dict {'top1': 0.82} is_best False lr [0.001]
training epoch 31 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best True lr [0.001]
training epoch 32 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 33 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best True lr [0.001]
training epoch 34 val accuracy 0.8308 topk_dict {'top1': 0.8308} is_best False lr [0.001]
training epoch 35 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best False lr [0.001]
training epoch 36 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.001]
training epoch 37 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.001]
training epoch 38 val accuracy 0.828 topk_dict {'top1': 0.828} is_best False lr [0.001]
training epoch 39 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best False lr [0.001]
training epoch 40 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best True lr [0.001]
training epoch 41 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best True lr [0.001]
training epoch 42 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.001]
training epoch 43 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.001]
training epoch 44 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best False lr [0.001]
training epoch 45 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.001]
training epoch 46 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best False lr [0.001]
training epoch 47 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.001]
training epoch 48 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.001]
training epoch 49 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.839800)
finished training. finished 50 epochs. accuracy 0.8398 topk_dict {'top1': 0.8398}
