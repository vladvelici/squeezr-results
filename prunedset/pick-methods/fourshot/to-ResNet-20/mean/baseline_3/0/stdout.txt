start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9908 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9862 loss from initial  0.013800000000000034
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 35 . block score: 0.043665528297424316
removed block 35 current accuracy 0.9842 loss from initial  0.015800000000000036
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 49 . block score: 0.044245341792702675
removed block 49 current accuracy 0.9642 loss from initial  0.035800000000000054
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (53, 0.05094906687736511)]
computing accuracy for after removing block 48 . block score: 0.04497492499649525
removed block 48 current accuracy 0.9436 loss from initial  0.056400000000000006
training start
training epoch 0 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 1 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 2 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 3 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 4 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 5 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 6 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 7 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 8 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 9 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 10 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 11 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 12 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 14 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 18 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 20 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 21 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 22 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 23 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 24 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 25 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 26 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 27 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 28 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 30 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 31 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 32 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 35 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 36 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 37 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 40 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 41 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 42 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 44 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 45 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 48 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 49 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.999200)
finished training. finished 50 epochs. accuracy 0.9992 topk_dict {'top1': 0.9992}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (28, 0.0465954914689064), (29, 0.04620574600994587), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (44, 0.0497369896620512), (45, 0.05080011859536171), (46, 0.04644610732793808), (47, 0.04475383087992668), (53, 0.05026237852871418)]
computing accuracy for after removing block 47 . block score: 0.04475383087992668
removed block 47 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (28, 0.0465954914689064), (29, 0.04620574600994587), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (44, 0.0497369896620512), (45, 0.05080011859536171), (46, 0.04644610732793808), (53, 0.05026237852871418)]
computing accuracy for after removing block 29 . block score: 0.04620574600994587
removed block 29 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (28, 0.0465954914689064), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (44, 0.0497369896620512), (45, 0.05080011859536171), (46, 0.04644610732793808), (53, 0.05026237852871418)]
computing accuracy for after removing block 46 . block score: 0.04644610732793808
removed block 46 current accuracy 0.9822 loss from initial  0.017800000000000038
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (28, 0.0465954914689064), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (44, 0.0497369896620512), (45, 0.05080011859536171), (53, 0.05026237852871418)]
computing accuracy for after removing block 28 . block score: 0.0465954914689064
removed block 28 current accuracy 0.9794 loss from initial  0.02059999999999995
since last training loss: 0.01979999999999993 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (44, 0.0497369896620512), (45, 0.05080011859536171), (53, 0.05026237852871418)]
computing accuracy for after removing block 44 . block score: 0.0497369896620512
removed block 44 current accuracy 0.9546 loss from initial  0.045399999999999996
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (45, 0.05080011859536171), (53, 0.05026237852871418)]
computing accuracy for after removing block 53 . block score: 0.05026237852871418
removed block 53 current accuracy 0.6528 loss from initial  0.34719999999999995
since last training loss: 0.34639999999999993 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (41, 0.05052040331065655), (42, 0.05308159068226814), (43, 0.051399802789092064), (45, 0.05080011859536171)]
computing accuracy for after removing block 41 . block score: 0.05052040331065655
removed block 41 current accuracy 0.6428 loss from initial  0.35719999999999996
since last training loss: 0.35639999999999994 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (42, 0.05308159068226814), (43, 0.051399802789092064), (45, 0.05080011859536171)]
computing accuracy for after removing block 45 . block score: 0.05080011859536171
removed block 45 current accuracy 0.4896 loss from initial  0.5104
since last training loss: 0.5096 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (26, 0.0509684719145298), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (42, 0.05308159068226814), (43, 0.051399802789092064)]
computing accuracy for after removing block 26 . block score: 0.0509684719145298
removed block 26 current accuracy 0.4608 loss from initial  0.5392
since last training loss: 0.5384 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (42, 0.05308159068226814), (43, 0.051399802789092064)]
computing accuracy for after removing block 43 . block score: 0.051399802789092064
removed block 43 current accuracy 0.4146 loss from initial  0.5853999999999999
since last training loss: 0.5846 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06566820666193962), (1, 0.055731797590851784), (2, 0.07442149519920349), (3, 0.07767525687813759), (4, 0.0613311268389225), (5, 0.09369237720966339), (6, 0.05920332111418247), (7, 0.05999967269599438), (8, 0.066302340477705), (9, 0.07996105030179024), (10, 0.07943810895085335), (11, 0.0682288222014904), (12, 0.08174435421824455), (13, 0.07461724057793617), (14, 0.08497722446918488), (15, 0.0879320316016674), (16, 0.1041405238211155), (17, 0.12286794185638428), (18, 0.2703372724354267), (19, 0.06997446343302727), (20, 0.06811181455850601), (21, 0.06295140087604523), (22, 0.061201125383377075), (23, 0.05798688717186451), (24, 0.05737440288066864), (25, 0.05723475478589535), (27, 0.05549845099449158), (36, 0.18044376373291016), (37, 0.0548117458820343), (38, 0.053590599447488785), (39, 0.054530706256628036), (40, 0.05334453471004963), (42, 0.05308159068226814)]
computing accuracy for after removing block 42 . block score: 0.05308159068226814
removed block 42 current accuracy 0.4256 loss from initial  0.5744
training start
training epoch 0 val accuracy 0.7704 topk_dict {'top1': 0.7704} is_best True lr [0.001]
training epoch 1 val accuracy 0.8028 topk_dict {'top1': 0.8028} is_best True lr [0.001]
training epoch 2 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best True lr [0.001]
training epoch 3 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.001]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.001]
training epoch 5 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.001]
training epoch 6 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.001]
training epoch 7 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 8 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 9 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.001]
training epoch 10 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.001]
training epoch 11 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 12 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 13 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 14 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 15 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 16 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 17 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 27 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 29 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 30 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.001]
training epoch 31 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 32 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 33 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 34 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 35 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 36 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 37 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 38 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 39 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 40 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 41 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 42 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 43 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 44 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 45 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.001]
training epoch 46 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 47 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best True lr [0.001]
training epoch 48 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.001]
training epoch 49 val accuracy 0.9582 topk_dict {'top1': 0.9582} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9582 topk_dict {'top1': 0.9582}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (27, 0.055008646100759506), (36, 0.17789899557828903), (37, 0.05401170812547207), (38, 0.052791353315114975), (39, 0.05370389111340046), (40, 0.05256278999149799)]
computing accuracy for after removing block 40 . block score: 0.05256278999149799
removed block 40 current accuracy 0.9242 loss from initial  0.07579999999999998
since last training loss: 0.03400000000000003 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (27, 0.055008646100759506), (36, 0.17789899557828903), (37, 0.05401170812547207), (38, 0.052791353315114975), (39, 0.05370389111340046)]
computing accuracy for after removing block 38 . block score: 0.052791353315114975
removed block 38 current accuracy 0.881 loss from initial  0.119
since last training loss: 0.07720000000000005 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (27, 0.055008646100759506), (36, 0.17789899557828903), (37, 0.05401170812547207), (39, 0.05370389111340046)]
computing accuracy for after removing block 39 . block score: 0.05370389111340046
removed block 39 current accuracy 0.7874 loss from initial  0.2126
since last training loss: 0.17080000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (27, 0.055008646100759506), (36, 0.17789899557828903), (37, 0.05401170812547207)]
computing accuracy for after removing block 37 . block score: 0.05401170812547207
removed block 37 current accuracy 0.7126 loss from initial  0.2874
since last training loss: 0.24560000000000004 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (27, 0.055008646100759506), (36, 0.17789899557828903)]
computing accuracy for after removing block 27 . block score: 0.055008646100759506
removed block 27 current accuracy 0.6334 loss from initial  0.36660000000000004
since last training loss: 0.3248000000000001 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (1, 0.05545008182525635), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (36, 0.17789899557828903)]
computing accuracy for after removing block 1 . block score: 0.05545008182525635
removed block 1 current accuracy 0.604 loss from initial  0.396
since last training loss: 0.35420000000000007 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (25, 0.056625209748744965), (36, 0.17789899557828903)]
computing accuracy for after removing block 25 . block score: 0.056625209748744965
removed block 25 current accuracy 0.5486 loss from initial  0.4514
since last training loss: 0.4096000000000001 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (24, 0.05687403120100498), (36, 0.17789899557828903)]
computing accuracy for after removing block 24 . block score: 0.05687403120100498
removed block 24 current accuracy 0.5038 loss from initial  0.4962
since last training loss: 0.4544 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (23, 0.05733276903629303), (36, 0.17789899557828903)]
computing accuracy for after removing block 23 . block score: 0.05733276903629303
removed block 23 current accuracy 0.4652 loss from initial  0.5347999999999999
since last training loss: 0.49300000000000005 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (6, 0.05843023397028446), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (36, 0.17789899557828903)]
computing accuracy for after removing block 6 . block score: 0.05843023397028446
removed block 6 current accuracy 0.4682 loss from initial  0.5318
since last training loss: 0.49000000000000005 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06477829441428185), (2, 0.07338058575987816), (3, 0.07659916207194328), (4, 0.0605356153100729), (5, 0.09246081486344337), (7, 0.05928798206150532), (8, 0.06543417274951935), (9, 0.07874904200434685), (10, 0.07829927280545235), (11, 0.06753949448466301), (12, 0.08046924695372581), (13, 0.073807492852211), (14, 0.0837252177298069), (15, 0.086821548640728), (16, 0.10274403542280197), (17, 0.12116957828402519), (18, 0.26618774235248566), (19, 0.06903709843754768), (20, 0.06717927753925323), (21, 0.062130989506840706), (22, 0.06037779338657856), (36, 0.17789899557828903)]
computing accuracy for after removing block 7 . block score: 0.05928798206150532
removed block 7 current accuracy 0.453 loss from initial  0.5469999999999999
training start
training epoch 0 val accuracy 0.7296 topk_dict {'top1': 0.7296} is_best True lr [0.001]
training epoch 1 val accuracy 0.7576 topk_dict {'top1': 0.7576} is_best True lr [0.001]
training epoch 2 val accuracy 0.7772 topk_dict {'top1': 0.7772} is_best True lr [0.001]
training epoch 3 val accuracy 0.791 topk_dict {'top1': 0.791} is_best True lr [0.001]
training epoch 4 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best True lr [0.001]
training epoch 5 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best True lr [0.001]
training epoch 6 val accuracy 0.822 topk_dict {'top1': 0.822} is_best True lr [0.001]
training epoch 7 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.001]
training epoch 8 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.001]
training epoch 9 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best True lr [0.001]
training epoch 10 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best True lr [0.001]
training epoch 11 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best True lr [0.001]
training epoch 12 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.001]
training epoch 13 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best True lr [0.001]
training epoch 14 val accuracy 0.867 topk_dict {'top1': 0.867} is_best True lr [0.001]
training epoch 15 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.001]
training epoch 16 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.001]
training epoch 17 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 18 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.001]
training epoch 19 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.001]
training epoch 20 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best True lr [0.001]
training epoch 21 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.001]
training epoch 22 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best True lr [0.001]
training epoch 23 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.001]
training epoch 24 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.001]
training epoch 25 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best True lr [0.001]
training epoch 26 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.001]
training epoch 27 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.001]
training epoch 28 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.001]
training epoch 29 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.001]
training epoch 30 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.001]
training epoch 31 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.001]
training epoch 32 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.001]
training epoch 33 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.001]
training epoch 34 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.001]
training epoch 35 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.001]
training epoch 36 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.001]
training epoch 37 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.001]
training epoch 38 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.001]
training epoch 39 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.001]
training epoch 40 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.001]
training epoch 41 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.001]
training epoch 42 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.001]
training epoch 43 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.001]
training epoch 44 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.001]
training epoch 45 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.001]
training epoch 46 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.001]
training epoch 47 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.001]
training epoch 48 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.001]
training epoch 49 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.889400)
finished training. finished 50 epochs. accuracy 0.8894 topk_dict {'top1': 0.8894}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06409095972776413), (2, 0.07254299148917198), (3, 0.07561709731817245), (4, 0.0598263218998909), (5, 0.09171754494309425), (8, 0.06475212052464485), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (21, 0.06394141353666782), (22, 0.06198476441204548), (36, 0.17530492693185806)]
computing accuracy for after removing block 4 . block score: 0.0598263218998909
removed block 4 current accuracy 0.8822 loss from initial  0.11780000000000002
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06409095972776413), (2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (8, 0.06475212052464485), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (21, 0.06394141353666782), (22, 0.06198476441204548), (36, 0.17530492693185806)]
computing accuracy for after removing block 22 . block score: 0.06198476441204548
removed block 22 current accuracy 0.7658 loss from initial  0.23419999999999996
since last training loss: 0.12359999999999993 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06409095972776413), (2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (8, 0.06475212052464485), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (21, 0.06394141353666782), (36, 0.17530492693185806)]
computing accuracy for after removing block 21 . block score: 0.06394141353666782
removed block 21 current accuracy 0.5498 loss from initial  0.45020000000000004
since last training loss: 0.3396 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.06409095972776413), (2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (8, 0.06475212052464485), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (36, 0.17530492693185806)]
computing accuracy for after removing block 0 . block score: 0.06409095972776413
removed block 0 current accuracy 0.4924 loss from initial  0.5076
since last training loss: 0.39699999999999996 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (8, 0.06475212052464485), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (36, 0.17530492693185806)]
computing accuracy for after removing block 8 . block score: 0.06475212052464485
removed block 8 current accuracy 0.4748 loss from initial  0.5252
since last training loss: 0.41459999999999997 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (11, 0.06704141199588776), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (36, 0.17530492693185806)]
computing accuracy for after removing block 11 . block score: 0.06704141199588776
removed block 11 current accuracy 0.4442 loss from initial  0.5558000000000001
since last training loss: 0.4452 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (20, 0.0676664412021637), (36, 0.17530492693185806)]
computing accuracy for after removing block 20 . block score: 0.0676664412021637
removed block 20 current accuracy 0.2878 loss from initial  0.7121999999999999
since last training loss: 0.6015999999999999 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (19, 0.06900380924344063), (36, 0.17530492693185806)]
computing accuracy for after removing block 19 . block score: 0.06900380924344063
removed block 19 current accuracy 0.2656 loss from initial  0.7343999999999999
since last training loss: 0.6237999999999999 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(2, 0.07254299148917198), (3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (36, 0.17530492693185806)]
computing accuracy for after removing block 2 . block score: 0.07254299148917198
removed block 2 current accuracy 0.1772 loss from initial  0.8228
since last training loss: 0.7121999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (13, 0.07338777557015419), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (36, 0.17530492693185806)]
computing accuracy for after removing block 13 . block score: 0.07338777557015419
removed block 13 current accuracy 0.144 loss from initial  0.856
since last training loss: 0.7454 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(3, 0.07561709731817245), (5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (36, 0.17530492693185806)]
computing accuracy for after removing block 3 . block score: 0.07561709731817245
removed block 3 current accuracy 0.1238 loss from initial  0.8762
since last training loss: 0.7656 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(5, 0.09171754494309425), (9, 0.07791197672486305), (10, 0.07744675874710083), (12, 0.07933151349425316), (14, 0.08276749402284622), (15, 0.08592944964766502), (16, 0.10156038403511047), (17, 0.11964351311326027), (18, 0.2627074792981148), (36, 0.17530492693185806)]
computing accuracy for after removing block 10 . block score: 0.07744675874710083
removed block 10 current accuracy 0.1152 loss from initial  0.8848
training start
training epoch 0 val accuracy 0.6528 topk_dict {'top1': 0.6528} is_best True lr [0.001]
training epoch 1 val accuracy 0.6896 topk_dict {'top1': 0.6896} is_best True lr [0.001]
training epoch 2 val accuracy 0.7144 topk_dict {'top1': 0.7144} is_best True lr [0.001]
training epoch 3 val accuracy 0.732 topk_dict {'top1': 0.732} is_best True lr [0.001]
training epoch 4 val accuracy 0.7424 topk_dict {'top1': 0.7424} is_best True lr [0.001]
training epoch 5 val accuracy 0.7522 topk_dict {'top1': 0.7522} is_best True lr [0.001]
training epoch 6 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best True lr [0.001]
training epoch 7 val accuracy 0.7642 topk_dict {'top1': 0.7642} is_best True lr [0.001]
training epoch 8 val accuracy 0.7718 topk_dict {'top1': 0.7718} is_best True lr [0.001]
training epoch 9 val accuracy 0.7702 topk_dict {'top1': 0.7702} is_best False lr [0.001]
training epoch 10 val accuracy 0.7792 topk_dict {'top1': 0.7792} is_best True lr [0.001]
training epoch 11 val accuracy 0.7852 topk_dict {'top1': 0.7852} is_best True lr [0.001]
training epoch 12 val accuracy 0.7812 topk_dict {'top1': 0.7812} is_best False lr [0.001]
training epoch 13 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 14 val accuracy 0.7924 topk_dict {'top1': 0.7924} is_best False lr [0.001]
training epoch 15 val accuracy 0.7954 topk_dict {'top1': 0.7954} is_best True lr [0.001]
training epoch 16 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best True lr [0.001]
training epoch 17 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.001]
training epoch 18 val accuracy 0.801 topk_dict {'top1': 0.801} is_best False lr [0.001]
training epoch 19 val accuracy 0.8016 topk_dict {'top1': 0.8016} is_best False lr [0.001]
training epoch 20 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best False lr [0.001]
training epoch 21 val accuracy 0.81 topk_dict {'top1': 0.81} is_best True lr [0.001]
training epoch 22 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best False lr [0.001]
training epoch 23 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best True lr [0.001]
training epoch 24 val accuracy 0.8146 topk_dict {'top1': 0.8146} is_best False lr [0.001]
training epoch 25 val accuracy 0.8102 topk_dict {'top1': 0.8102} is_best False lr [0.001]
training epoch 26 val accuracy 0.8136 topk_dict {'top1': 0.8136} is_best False lr [0.001]
training epoch 27 val accuracy 0.815 topk_dict {'top1': 0.815} is_best True lr [0.001]
training epoch 28 val accuracy 0.818 topk_dict {'top1': 0.818} is_best True lr [0.001]
training epoch 29 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best False lr [0.001]
training epoch 30 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best True lr [0.001]
training epoch 31 val accuracy 0.8198 topk_dict {'top1': 0.8198} is_best True lr [0.001]
training epoch 32 val accuracy 0.8218 topk_dict {'top1': 0.8218} is_best True lr [0.001]
training epoch 33 val accuracy 0.8254 topk_dict {'top1': 0.8254} is_best True lr [0.001]
training epoch 34 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best False lr [0.001]
training epoch 35 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best False lr [0.001]
training epoch 36 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best True lr [0.001]
training epoch 37 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best False lr [0.001]
training epoch 38 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best True lr [0.001]
training epoch 39 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 40 val accuracy 0.8224 topk_dict {'top1': 0.8224} is_best False lr [0.001]
training epoch 41 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best True lr [0.001]
training epoch 42 val accuracy 0.828 topk_dict {'top1': 0.828} is_best False lr [0.001]
training epoch 43 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best True lr [0.001]
training epoch 44 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.001]
training epoch 45 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.001]
training epoch 46 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.001]
training epoch 47 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.001]
training epoch 48 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.001]
training epoch 49 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8348 topk_dict {'top1': 0.8348}
