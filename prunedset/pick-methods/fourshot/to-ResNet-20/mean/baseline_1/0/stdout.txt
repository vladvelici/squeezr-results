start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 21 . block score: 0.04090827330946922
removed block 21 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 20 . block score: 0.04176427610218525
removed block 20 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 43 . block score: 0.04276760295033455
removed block 43 current accuracy 0.988 loss from initial  0.01200000000000001
training start
training epoch 0 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 1 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 35 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (26, 0.04407990910112858), (28, 0.045677825808525085), (30, 0.04301189072430134), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (42, 0.0426716934889555), (44, 0.04400034435093403), (45, 0.04607327654957771), (46, 0.044201068580150604), (47, 0.04378005489706993), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 42 . block score: 0.0426716934889555
removed block 42 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (26, 0.04407990910112858), (28, 0.045677825808525085), (30, 0.04301189072430134), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (44, 0.04400034435093403), (45, 0.04607327654957771), (46, 0.044201068580150604), (47, 0.04378005489706993), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 30 . block score: 0.04301189072430134
removed block 30 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (26, 0.04407990910112858), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (44, 0.04400034435093403), (45, 0.04607327654957771), (46, 0.044201068580150604), (47, 0.04378005489706993), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 47 . block score: 0.04378005489706993
removed block 47 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (26, 0.04407990910112858), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (44, 0.04400034435093403), (45, 0.04607327654957771), (46, 0.044201068580150604), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 44 . block score: 0.04400034435093403
removed block 44 current accuracy 0.9888 loss from initial  0.011199999999999988
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (26, 0.04407990910112858), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (46, 0.044201068580150604), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 26 . block score: 0.04407990910112858
removed block 26 current accuracy 0.9838 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (46, 0.044201068580150604), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 46 . block score: 0.044201068580150604
removed block 46 current accuracy 0.9792 loss from initial  0.02080000000000004
since last training loss: 0.02080000000000004 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (39, 0.04422262869775295), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 39 . block score: 0.04422262869775295
removed block 39 current accuracy 0.9734 loss from initial  0.026599999999999957
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (24, 0.04429127275943756), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 24 . block score: 0.04429127275943756
removed block 24 current accuracy 0.9646 loss from initial  0.03539999999999999
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (48, 0.04450538009405136), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 48 . block score: 0.04450538009405136
removed block 48 current accuracy 0.934 loss from initial  0.06599999999999995
since last training loss: 0.06599999999999995 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (40, 0.04466010816395283), (41, 0.04465153627097607), (45, 0.04607327654957771), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 41 . block score: 0.04465153627097607
removed block 41 current accuracy 0.9058 loss from initial  0.09419999999999995
since last training loss: 0.09419999999999995 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06215723790228367), (1, 0.10363119468092918), (2, 0.08297944813966751), (3, 0.0899730697274208), (4, 0.08281470462679863), (5, 0.08749276399612427), (6, 0.0918995589017868), (7, 0.081650760024786), (8, 0.08195242285728455), (9, 0.06241662986576557), (10, 0.054042914882302284), (11, 0.06224464997649193), (12, 0.05950692854821682), (13, 0.05133881792426109), (14, 0.06420434638857841), (15, 0.07218760624527931), (16, 0.07007280178368092), (17, 0.06529372185468674), (18, 0.2135600559413433), (22, 0.0488566979765892), (23, 0.05011093616485596), (25, 0.04650026932358742), (28, 0.045677825808525085), (36, 0.16139399632811546), (37, 0.046864744275808334), (38, 0.04578102193772793), (40, 0.04466010816395283), (45, 0.04607327654957771), (49, 0.04580548219382763), (50, 0.046954208984971046), (51, 0.048136161640286446), (52, 0.04894203506410122), (53, 0.051155831664800644)]
computing accuracy for after removing block 40 . block score: 0.04466010816395283
removed block 40 current accuracy 0.8716 loss from initial  0.12839999999999996
training start
training epoch 0 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best True lr [0.001]
training epoch 1 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best True lr [0.001]
training epoch 2 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 3 val accuracy 0.983 topk_dict {'top1': 0.983} is_best True lr [0.001]
training epoch 4 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 5 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 6 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 7 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 8 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 9 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best True lr [0.001]
training epoch 10 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 11 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 12 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 13 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 14 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best False lr [0.001]
training epoch 15 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 16 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 17 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 18 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 19 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 20 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 21 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 22 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 23 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 24 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 25 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 26 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 27 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 28 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 29 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 30 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 31 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 32 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 33 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 34 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 35 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 36 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 37 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 38 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 39 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 40 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 41 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 42 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 43 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 44 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 45 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 46 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 47 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 48 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 49 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9918 topk_dict {'top1': 0.9918}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (25, 0.045870887115597725), (28, 0.04511553421616554), (36, 0.15901096910238266), (37, 0.046180132776498795), (38, 0.045119261369109154), (45, 0.04541245102882385), (49, 0.045160556212067604), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 28 . block score: 0.04511553421616554
removed block 28 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (25, 0.045870887115597725), (36, 0.15901096910238266), (37, 0.046180132776498795), (38, 0.045119261369109154), (45, 0.04541245102882385), (49, 0.045160556212067604), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 38 . block score: 0.045119261369109154
removed block 38 current accuracy 0.9662 loss from initial  0.03380000000000005
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (25, 0.045870887115597725), (36, 0.15901096910238266), (37, 0.046180132776498795), (45, 0.04541245102882385), (49, 0.045160556212067604), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 49 . block score: 0.045160556212067604
removed block 49 current accuracy 0.9346 loss from initial  0.06540000000000001
since last training loss: 0.05720000000000003 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (25, 0.045870887115597725), (36, 0.15901096910238266), (37, 0.046180132776498795), (45, 0.04541245102882385), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 45 . block score: 0.04541245102882385
removed block 45 current accuracy 0.8864 loss from initial  0.11360000000000003
since last training loss: 0.10540000000000005 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (25, 0.045870887115597725), (36, 0.15901096910238266), (37, 0.046180132776498795), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 25 . block score: 0.045870887115597725
removed block 25 current accuracy 0.8462 loss from initial  0.15380000000000005
since last training loss: 0.14560000000000006 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (36, 0.15901096910238266), (37, 0.046180132776498795), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 37 . block score: 0.046180132776498795
removed block 37 current accuracy 0.7778 loss from initial  0.22219999999999995
since last training loss: 0.21399999999999997 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (36, 0.15901096910238266), (50, 0.04628116451203823), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 50 . block score: 0.04628116451203823
removed block 50 current accuracy 0.6854 loss from initial  0.3146
since last training loss: 0.3064 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (36, 0.15901096910238266), (51, 0.04745788499712944), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 51 . block score: 0.04745788499712944
removed block 51 current accuracy 0.4794 loss from initial  0.5206
since last training loss: 0.5124 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (22, 0.048227665945887566), (23, 0.04948866553604603), (36, 0.15901096910238266), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 22 . block score: 0.048227665945887566
removed block 22 current accuracy 0.4238 loss from initial  0.5762
since last training loss: 0.5680000000000001 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (23, 0.04948866553604603), (36, 0.15901096910238266), (52, 0.04823540896177292), (53, 0.050365978851914406)]
computing accuracy for after removing block 52 . block score: 0.04823540896177292
removed block 52 current accuracy 0.3478 loss from initial  0.6522
since last training loss: 0.644 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.061294374987483025), (1, 0.10206679627299309), (2, 0.0817485898733139), (3, 0.08870936185121536), (4, 0.08156606554985046), (5, 0.08618292585015297), (6, 0.09052005410194397), (7, 0.08045992255210876), (8, 0.08076318725943565), (9, 0.06155378185212612), (10, 0.053291695192456245), (11, 0.061371635645627975), (12, 0.05864584259688854), (13, 0.05067192204296589), (14, 0.06323866918683052), (15, 0.07124009169638157), (16, 0.06906184554100037), (17, 0.06446022354066372), (18, 0.21056949719786644), (23, 0.04948866553604603), (36, 0.15901096910238266), (53, 0.050365978851914406)]
computing accuracy for after removing block 23 . block score: 0.04948866553604603
removed block 23 current accuracy 0.3138 loss from initial  0.6861999999999999
training start
training epoch 0 val accuracy 0.7892 topk_dict {'top1': 0.7892} is_best True lr [0.001]
training epoch 1 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best True lr [0.001]
training epoch 2 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best True lr [0.001]
training epoch 3 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best True lr [0.001]
training epoch 4 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.001]
training epoch 5 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best True lr [0.001]
training epoch 6 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.001]
training epoch 7 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.001]
training epoch 8 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.001]
training epoch 9 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.001]
training epoch 10 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.001]
training epoch 11 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.001]
training epoch 12 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.001]
training epoch 13 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best True lr [0.001]
training epoch 14 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 15 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.001]
training epoch 16 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.001]
training epoch 17 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
training epoch 18 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 19 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.001]
training epoch 20 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.001]
training epoch 21 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 22 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.001]
training epoch 23 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.001]
training epoch 24 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.001]
training epoch 25 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.001]
training epoch 26 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 27 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.001]
training epoch 28 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.001]
training epoch 29 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.001]
training epoch 30 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.001]
training epoch 31 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.001]
training epoch 32 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 33 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 34 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.001]
training epoch 35 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 36 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.001]
training epoch 37 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 38 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 39 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.001]
training epoch 40 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.001]
training epoch 41 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.001]
training epoch 42 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.001]
training epoch 43 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.001]
training epoch 44 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 45 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 46 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 47 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 48 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9068 topk_dict {'top1': 0.9068}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06063591130077839), (1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (10, 0.053129494190216064), (11, 0.06143093295395374), (12, 0.05864780768752098), (13, 0.051415372639894485), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379), (53, 0.05057648755609989)]
computing accuracy for after removing block 53 . block score: 0.05057648755609989
removed block 53 current accuracy 0.3772 loss from initial  0.6228
since last training loss: 0.5296000000000001 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06063591130077839), (1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (10, 0.053129494190216064), (11, 0.06143093295395374), (12, 0.05864780768752098), (13, 0.051415372639894485), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 13 . block score: 0.051415372639894485
removed block 13 current accuracy 0.3512 loss from initial  0.6488
since last training loss: 0.5556000000000001 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06063591130077839), (1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (10, 0.053129494190216064), (11, 0.06143093295395374), (12, 0.05864780768752098), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 10 . block score: 0.053129494190216064
removed block 10 current accuracy 0.342 loss from initial  0.6579999999999999
since last training loss: 0.5648 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.06063591130077839), (1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (11, 0.06143093295395374), (12, 0.05864780768752098), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 12 . block score: 0.05864780768752098
removed block 12 current accuracy 0.32 loss from initial  0.6799999999999999
since last training loss: 0.5868 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.06063591130077839), (1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (11, 0.06143093295395374), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 0 . block score: 0.06063591130077839
removed block 0 current accuracy 0.3088 loss from initial  0.6912
since last training loss: 0.5980000000000001 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (11, 0.06143093295395374), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 11 . block score: 0.06143093295395374
removed block 11 current accuracy 0.2982 loss from initial  0.7018
since last training loss: 0.6086 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (9, 0.06165333837270737), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 9 . block score: 0.06165333837270737
removed block 9 current accuracy 0.2774 loss from initial  0.7226
since last training loss: 0.6294000000000001 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (14, 0.06318080425262451), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 14 . block score: 0.06318080425262451
removed block 14 current accuracy 0.2578 loss from initial  0.7422
since last training loss: 0.649 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (15, 0.0717764850705862), (16, 0.06914380565285683), (17, 0.06486475840210915), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 17 . block score: 0.06486475840210915
removed block 17 current accuracy 0.2378 loss from initial  0.7622
since last training loss: 0.669 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (15, 0.0717764850705862), (16, 0.06914380565285683), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 16 . block score: 0.06914380565285683
removed block 16 current accuracy 0.2038 loss from initial  0.7962
since last training loss: 0.7030000000000001 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (15, 0.0717764850705862), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 15 . block score: 0.0717764850705862
removed block 15 current accuracy 0.2024 loss from initial  0.7976
since last training loss: 0.7044 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(1, 0.100828867405653), (2, 0.08112160116434097), (3, 0.08805197477340698), (4, 0.08063655346632004), (5, 0.0855085514485836), (6, 0.0896008089184761), (7, 0.08001559600234032), (8, 0.08037469163537025), (18, 0.2097265161573887), (36, 0.15747848898172379)]
computing accuracy for after removing block 7 . block score: 0.08001559600234032
removed block 7 current accuracy 0.1856 loss from initial  0.8144
training start
training epoch 0 val accuracy 0.566 topk_dict {'top1': 0.566} is_best True lr [0.001]
training epoch 1 val accuracy 0.6062 topk_dict {'top1': 0.6062} is_best True lr [0.001]
training epoch 2 val accuracy 0.6384 topk_dict {'top1': 0.6384} is_best True lr [0.001]
training epoch 3 val accuracy 0.6594 topk_dict {'top1': 0.6594} is_best True lr [0.001]
training epoch 4 val accuracy 0.6824 topk_dict {'top1': 0.6824} is_best True lr [0.001]
training epoch 5 val accuracy 0.6956 topk_dict {'top1': 0.6956} is_best True lr [0.001]
training epoch 6 val accuracy 0.7116 topk_dict {'top1': 0.7116} is_best True lr [0.001]
training epoch 7 val accuracy 0.7192 topk_dict {'top1': 0.7192} is_best True lr [0.001]
training epoch 8 val accuracy 0.7264 topk_dict {'top1': 0.7264} is_best True lr [0.001]
training epoch 9 val accuracy 0.7358 topk_dict {'top1': 0.7358} is_best True lr [0.001]
training epoch 10 val accuracy 0.7404 topk_dict {'top1': 0.7404} is_best True lr [0.001]
training epoch 11 val accuracy 0.7568 topk_dict {'top1': 0.7568} is_best True lr [0.001]
training epoch 12 val accuracy 0.7642 topk_dict {'top1': 0.7642} is_best True lr [0.001]
training epoch 13 val accuracy 0.756 topk_dict {'top1': 0.756} is_best False lr [0.001]
training epoch 14 val accuracy 0.7706 topk_dict {'top1': 0.7706} is_best True lr [0.001]
training epoch 15 val accuracy 0.764 topk_dict {'top1': 0.764} is_best False lr [0.001]
training epoch 16 val accuracy 0.7846 topk_dict {'top1': 0.7846} is_best True lr [0.001]
training epoch 17 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best True lr [0.001]
training epoch 18 val accuracy 0.7702 topk_dict {'top1': 0.7702} is_best False lr [0.001]
training epoch 19 val accuracy 0.7816 topk_dict {'top1': 0.7816} is_best False lr [0.001]
training epoch 20 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best True lr [0.001]
training epoch 21 val accuracy 0.7982 topk_dict {'top1': 0.7982} is_best True lr [0.001]
training epoch 22 val accuracy 0.797 topk_dict {'top1': 0.797} is_best False lr [0.001]
training epoch 23 val accuracy 0.7974 topk_dict {'top1': 0.7974} is_best False lr [0.001]
training epoch 24 val accuracy 0.8006 topk_dict {'top1': 0.8006} is_best True lr [0.001]
training epoch 25 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best True lr [0.001]
training epoch 26 val accuracy 0.804 topk_dict {'top1': 0.804} is_best True lr [0.001]
training epoch 27 val accuracy 0.7962 topk_dict {'top1': 0.7962} is_best False lr [0.001]
training epoch 28 val accuracy 0.8026 topk_dict {'top1': 0.8026} is_best False lr [0.001]
training epoch 29 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best True lr [0.001]
training epoch 30 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best False lr [0.001]
training epoch 31 val accuracy 0.811 topk_dict {'top1': 0.811} is_best True lr [0.001]
training epoch 32 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best True lr [0.001]
training epoch 33 val accuracy 0.8162 topk_dict {'top1': 0.8162} is_best True lr [0.001]
training epoch 34 val accuracy 0.806 topk_dict {'top1': 0.806} is_best False lr [0.001]
training epoch 35 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best False lr [0.001]
training epoch 36 val accuracy 0.815 topk_dict {'top1': 0.815} is_best False lr [0.001]
training epoch 37 val accuracy 0.8114 topk_dict {'top1': 0.8114} is_best False lr [0.001]
training epoch 38 val accuracy 0.82 topk_dict {'top1': 0.82} is_best True lr [0.001]
training epoch 39 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.001]
training epoch 40 val accuracy 0.8236 topk_dict {'top1': 0.8236} is_best True lr [0.001]
training epoch 41 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.001]
training epoch 42 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best True lr [0.001]
training epoch 43 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best True lr [0.001]
training epoch 44 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.001]
training epoch 45 val accuracy 0.8248 topk_dict {'top1': 0.8248} is_best False lr [0.001]
training epoch 46 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.001]
training epoch 47 val accuracy 0.8278 topk_dict {'top1': 0.8278} is_best False lr [0.001]
training epoch 48 val accuracy 0.8246 topk_dict {'top1': 0.8246} is_best False lr [0.001]
training epoch 49 val accuracy 0.832 topk_dict {'top1': 0.832} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.832 topk_dict {'top1': 0.832}
