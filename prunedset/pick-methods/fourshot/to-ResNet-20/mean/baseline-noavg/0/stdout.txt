start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 19 . block score: 0.03394944407045841
removed block 19 current accuracy 0.991 loss from initial  0.009000000000000008
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 0 . block score: 0.034245140850543976
removed block 0 current accuracy 0.9208 loss from initial  0.07920000000000005
since last training loss: 0.07920000000000005 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 25 . block score: 0.03559616953134537
removed block 25 current accuracy 0.9204 loss from initial  0.0796
training start
training epoch 0 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 6 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (23, 0.038166509941220284), (26, 0.04475007578730583), (27, 0.03836533799767494), (28, 0.04181516915559769), (29, 0.04035719484090805), (30, 0.037211074493825436), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (35, 0.03958721458911896), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 30 . block score: 0.037211074493825436
removed block 30 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (23, 0.038166509941220284), (26, 0.04475007578730583), (27, 0.03836533799767494), (28, 0.04181516915559769), (29, 0.04035719484090805), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (35, 0.03958721458911896), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 23 . block score: 0.038166509941220284
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (27, 0.03836533799767494), (28, 0.04181516915559769), (29, 0.04035719484090805), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (35, 0.03958721458911896), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 27 . block score: 0.03836533799767494
removed block 27 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (29, 0.04035719484090805), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (35, 0.03958721458911896), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 35 . block score: 0.03958721458911896
removed block 35 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (29, 0.04035719484090805), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 29 . block score: 0.04035719484090805
removed block 29 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (8, 0.04094375669956207), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 8 . block score: 0.04094375669956207
removed block 8 current accuracy 0.983 loss from initial  0.017000000000000015
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (7, 0.04150187596678734), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 7 . block score: 0.04150187596678734
removed block 7 current accuracy 0.9524 loss from initial  0.047599999999999976
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (37, 0.04162870906293392), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 37 . block score: 0.04162870906293392
removed block 37 current accuracy 0.9406 loss from initial  0.05940000000000001
since last training loss: 0.05940000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (28, 0.04181516915559769), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 28 . block score: 0.04181516915559769
removed block 28 current accuracy 0.925 loss from initial  0.07499999999999996
since last training loss: 0.07499999999999996 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.042002297937870026), (4, 0.053169745951890945), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 2 . block score: 0.042002297937870026
removed block 2 current accuracy 0.8068 loss from initial  0.19320000000000004
since last training loss: 0.19320000000000004 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.053169745951890945), (9, 0.06640870124101639), (10, 0.06228339858353138), (11, 0.054890334606170654), (12, 0.06201210245490074), (13, 0.05068846978247166), (14, 0.06606400571763515), (15, 0.07051696255803108), (16, 0.059915946796536446), (17, 0.09396325796842575), (18, 0.19078554585576057), (26, 0.04475007578730583), (31, 0.04220394045114517), (32, 0.04241598956286907), (33, 0.045697277411818504), (34, 0.04647420533001423), (36, 0.16048062220215797), (38, 0.04493936896324158), (39, 0.047210657969117165), (40, 0.05058017186820507), (41, 0.051156576722860336), (42, 0.05257115885615349), (43, 0.05385453812777996), (44, 0.051509181037545204), (45, 0.05117742344737053), (46, 0.05112081952393055), (47, 0.04881592281162739), (48, 0.046526312828063965), (49, 0.04504724591970444), (50, 0.04475266486406326), (51, 0.043958790600299835), (52, 0.043285664170980453), (53, 0.050725182518363)]
computing accuracy for after removing block 31 . block score: 0.04220394045114517
removed block 31 current accuracy 0.7936 loss from initial  0.20640000000000003
training start
training epoch 0 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 2 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 3 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 4 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 5 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 6 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 7 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 8 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 9 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 10 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 11 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 12 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 13 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 15 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 16 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 17 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 18 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 19 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 20 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 21 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 24 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 25 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 28 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 29 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 32 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 33 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 34 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 37 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 38 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 41 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 42 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 43 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 44 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 45 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 46 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 47 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 48 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 49 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.999000)
finished training. finished 50 epochs. accuracy 0.999 topk_dict {'top1': 0.999}
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (26, 0.044189367443323135), (32, 0.04182336665689945), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (50, 0.044096363708376884), (51, 0.04331980273127556), (52, 0.04265659302473068), (53, 0.04996994137763977)]
computing accuracy for after removing block 32 . block score: 0.04182336665689945
removed block 32 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (26, 0.044189367443323135), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (50, 0.044096363708376884), (51, 0.04331980273127556), (52, 0.04265659302473068), (53, 0.04996994137763977)]
computing accuracy for after removing block 52 . block score: 0.04265659302473068
removed block 52 current accuracy 0.9864 loss from initial  0.013599999999999945
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (26, 0.044189367443323135), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (50, 0.044096363708376884), (51, 0.04331980273127556), (53, 0.04996994137763977)]
computing accuracy for after removing block 51 . block score: 0.04331980273127556
removed block 51 current accuracy 0.9806 loss from initial  0.019399999999999973
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (26, 0.044189367443323135), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (50, 0.044096363708376884), (53, 0.04996994137763977)]
computing accuracy for after removing block 50 . block score: 0.044096363708376884
removed block 50 current accuracy 0.966 loss from initial  0.03400000000000003
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (26, 0.044189367443323135), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (53, 0.04996994137763977)]
computing accuracy for after removing block 26 . block score: 0.044189367443323135
removed block 26 current accuracy 0.9428 loss from initial  0.05720000000000003
since last training loss: 0.05620000000000003 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (38, 0.044285232201218605), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (53, 0.04996994137763977)]
computing accuracy for after removing block 38 . block score: 0.044285232201218605
removed block 38 current accuracy 0.9386 loss from initial  0.06140000000000001
since last training loss: 0.06040000000000001 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (49, 0.04439500719308853), (53, 0.04996994137763977)]
computing accuracy for after removing block 49 . block score: 0.04439500719308853
removed block 49 current accuracy 0.9152 loss from initial  0.08479999999999999
since last training loss: 0.08379999999999999 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (33, 0.04513850249350071), (34, 0.045862916857004166), (36, 0.15825199708342552), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (53, 0.04996994137763977)]
computing accuracy for after removing block 33 . block score: 0.04513850249350071
removed block 33 current accuracy 0.8586 loss from initial  0.14139999999999997
since last training loss: 0.14039999999999997 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (34, 0.045862916857004166), (36, 0.15825199708342552), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (48, 0.04585004225373268), (53, 0.04996994137763977)]
computing accuracy for after removing block 48 . block score: 0.04585004225373268
removed block 48 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.18279999999999996 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (34, 0.045862916857004166), (36, 0.15825199708342552), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (53, 0.04996994137763977)]
computing accuracy for after removing block 34 . block score: 0.045862916857004166
removed block 34 current accuracy 0.727 loss from initial  0.273
since last training loss: 0.272 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.05283624492585659), (9, 0.06568997725844383), (10, 0.06149396672844887), (11, 0.05407329089939594), (12, 0.061088522896170616), (13, 0.04996069334447384), (14, 0.06522563844919205), (15, 0.06945544481277466), (16, 0.05899224802851677), (17, 0.09256970509886742), (18, 0.1878417357802391), (36, 0.15825199708342552), (39, 0.04652087762951851), (40, 0.04984169453382492), (41, 0.05041055753827095), (42, 0.05180281028151512), (43, 0.05308050476014614), (44, 0.05075616203248501), (45, 0.05043935589492321), (46, 0.05037698522210121), (47, 0.04811233840882778), (53, 0.04996994137763977)]
computing accuracy for after removing block 39 . block score: 0.04652087762951851
removed block 39 current accuracy 0.6658 loss from initial  0.33420000000000005
training start
training epoch 0 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 1 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.001]
training epoch 2 val accuracy 0.9592 topk_dict {'top1': 0.9592} is_best True lr [0.001]
training epoch 3 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.001]
training epoch 4 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best True lr [0.001]
training epoch 5 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 6 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 7 val accuracy 0.972 topk_dict {'top1': 0.972} is_best True lr [0.001]
training epoch 8 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 9 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best True lr [0.001]
training epoch 10 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best True lr [0.001]
training epoch 11 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best True lr [0.001]
training epoch 12 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 13 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 14 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 15 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 16 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 17 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 18 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 19 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 20 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 21 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 22 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 23 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 24 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 25 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 26 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 27 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 28 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 29 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 30 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 31 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 32 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 33 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 34 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 35 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 36 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 37 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 38 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 39 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 40 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 41 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 42 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 43 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 44 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 45 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 46 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 47 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 48 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 49 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.981000)
finished training. finished 50 epochs. accuracy 0.981 topk_dict {'top1': 0.981}
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (13, 0.04950684867799282), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (40, 0.04939975589513779), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236), (46, 0.049935292452573776), (47, 0.047717778012156487), (53, 0.04946120269596577)]
computing accuracy for after removing block 47 . block score: 0.047717778012156487
removed block 47 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (13, 0.04950684867799282), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (40, 0.04939975589513779), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236), (46, 0.049935292452573776), (53, 0.04946120269596577)]
computing accuracy for after removing block 40 . block score: 0.04939975589513779
removed block 40 current accuracy 0.9054 loss from initial  0.09460000000000002
since last training loss: 0.0756 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (13, 0.04950684867799282), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236), (46, 0.049935292452573776), (53, 0.04946120269596577)]
computing accuracy for after removing block 53 . block score: 0.04946120269596577
removed block 53 current accuracy 0.591 loss from initial  0.40900000000000003
since last training loss: 0.39 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (13, 0.04950684867799282), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236), (46, 0.049935292452573776)]
computing accuracy for after removing block 13 . block score: 0.04950684867799282
removed block 13 current accuracy 0.5554 loss from initial  0.4446
since last training loss: 0.4256 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236), (46, 0.049935292452573776)]
computing accuracy for after removing block 46 . block score: 0.049935292452573776
removed block 46 current accuracy 0.4664 loss from initial  0.5336000000000001
since last training loss: 0.5146 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (41, 0.04996468685567379), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236)]
computing accuracy for after removing block 41 . block score: 0.04996468685567379
removed block 41 current accuracy 0.4204 loss from initial  0.5796
since last training loss: 0.5606 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033), (45, 0.05001478269696236)]
computing accuracy for after removing block 45 . block score: 0.05001478269696236
removed block 45 current accuracy 0.3582 loss from initial  0.6417999999999999
since last training loss: 0.6228 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (42, 0.051351772621273994), (43, 0.05262656882405281), (44, 0.05034533329308033)]
computing accuracy for after removing block 44 . block score: 0.05034533329308033
removed block 44 current accuracy 0.3476 loss from initial  0.6524
since last training loss: 0.6334 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (42, 0.051351772621273994), (43, 0.05262656882405281)]
computing accuracy for after removing block 42 . block score: 0.051351772621273994
removed block 42 current accuracy 0.3198 loss from initial  0.6802
since last training loss: 0.6612 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814), (43, 0.05262656882405281)]
computing accuracy for after removing block 43 . block score: 0.05262656882405281
removed block 43 current accuracy 0.3042 loss from initial  0.6958
since last training loss: 0.6768 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(4, 0.05271482467651367), (9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814)]
computing accuracy for after removing block 4 . block score: 0.05271482467651367
removed block 4 current accuracy 0.221 loss from initial  0.779
since last training loss: 0.76 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(9, 0.0655256062746048), (10, 0.06131691113114357), (11, 0.05374591238796711), (12, 0.060662658885121346), (14, 0.06490418687462807), (15, 0.06894989497959614), (16, 0.05856041982769966), (17, 0.09172230958938599), (18, 0.1867544688284397), (36, 0.1569783203303814)]
computing accuracy for after removing block 11 . block score: 0.05374591238796711
removed block 11 current accuracy 0.206 loss from initial  0.794
training start
training epoch 0 val accuracy 0.5074 topk_dict {'top1': 0.5074} is_best True lr [0.001]
training epoch 1 val accuracy 0.551 topk_dict {'top1': 0.551} is_best True lr [0.001]
training epoch 2 val accuracy 0.5796 topk_dict {'top1': 0.5796} is_best True lr [0.001]
training epoch 3 val accuracy 0.5992 topk_dict {'top1': 0.5992} is_best True lr [0.001]
training epoch 4 val accuracy 0.615 topk_dict {'top1': 0.615} is_best True lr [0.001]
training epoch 5 val accuracy 0.6342 topk_dict {'top1': 0.6342} is_best True lr [0.001]
training epoch 6 val accuracy 0.643 topk_dict {'top1': 0.643} is_best True lr [0.001]
training epoch 7 val accuracy 0.653 topk_dict {'top1': 0.653} is_best True lr [0.001]
training epoch 8 val accuracy 0.6596 topk_dict {'top1': 0.6596} is_best True lr [0.001]
training epoch 9 val accuracy 0.6634 topk_dict {'top1': 0.6634} is_best True lr [0.001]
training epoch 10 val accuracy 0.6738 topk_dict {'top1': 0.6738} is_best True lr [0.001]
training epoch 11 val accuracy 0.6874 topk_dict {'top1': 0.6874} is_best True lr [0.001]
training epoch 12 val accuracy 0.679 topk_dict {'top1': 0.679} is_best False lr [0.001]
training epoch 13 val accuracy 0.6886 topk_dict {'top1': 0.6886} is_best True lr [0.001]
training epoch 14 val accuracy 0.7 topk_dict {'top1': 0.7} is_best True lr [0.001]
training epoch 15 val accuracy 0.7 topk_dict {'top1': 0.7} is_best False lr [0.001]
training epoch 16 val accuracy 0.6852 topk_dict {'top1': 0.6852} is_best False lr [0.001]
training epoch 17 val accuracy 0.7132 topk_dict {'top1': 0.7132} is_best True lr [0.001]
training epoch 18 val accuracy 0.717 topk_dict {'top1': 0.717} is_best True lr [0.001]
training epoch 19 val accuracy 0.7158 topk_dict {'top1': 0.7158} is_best False lr [0.001]
training epoch 20 val accuracy 0.727 topk_dict {'top1': 0.727} is_best True lr [0.001]
training epoch 21 val accuracy 0.731 topk_dict {'top1': 0.731} is_best True lr [0.001]
training epoch 22 val accuracy 0.7316 topk_dict {'top1': 0.7316} is_best True lr [0.001]
training epoch 23 val accuracy 0.7304 topk_dict {'top1': 0.7304} is_best False lr [0.001]
training epoch 24 val accuracy 0.7392 topk_dict {'top1': 0.7392} is_best True lr [0.001]
training epoch 25 val accuracy 0.7422 topk_dict {'top1': 0.7422} is_best True lr [0.001]
training epoch 26 val accuracy 0.7428 topk_dict {'top1': 0.7428} is_best True lr [0.001]
training epoch 27 val accuracy 0.7528 topk_dict {'top1': 0.7528} is_best True lr [0.001]
training epoch 28 val accuracy 0.7308 topk_dict {'top1': 0.7308} is_best False lr [0.001]
training epoch 29 val accuracy 0.7518 topk_dict {'top1': 0.7518} is_best False lr [0.001]
training epoch 30 val accuracy 0.7604 topk_dict {'top1': 0.7604} is_best True lr [0.001]
training epoch 31 val accuracy 0.7608 topk_dict {'top1': 0.7608} is_best True lr [0.001]
training epoch 32 val accuracy 0.7626 topk_dict {'top1': 0.7626} is_best True lr [0.001]
training epoch 33 val accuracy 0.7664 topk_dict {'top1': 0.7664} is_best True lr [0.001]
training epoch 34 val accuracy 0.76 topk_dict {'top1': 0.76} is_best False lr [0.001]
training epoch 35 val accuracy 0.7616 topk_dict {'top1': 0.7616} is_best False lr [0.001]
training epoch 36 val accuracy 0.7544 topk_dict {'top1': 0.7544} is_best False lr [0.001]
training epoch 37 val accuracy 0.7492 topk_dict {'top1': 0.7492} is_best False lr [0.001]
training epoch 38 val accuracy 0.7614 topk_dict {'top1': 0.7614} is_best False lr [0.001]
training epoch 39 val accuracy 0.7546 topk_dict {'top1': 0.7546} is_best False lr [0.001]
training epoch 40 val accuracy 0.7636 topk_dict {'top1': 0.7636} is_best False lr [0.001]
training epoch 41 val accuracy 0.7732 topk_dict {'top1': 0.7732} is_best True lr [0.001]
training epoch 42 val accuracy 0.7734 topk_dict {'top1': 0.7734} is_best True lr [0.001]
training epoch 43 val accuracy 0.7758 topk_dict {'top1': 0.7758} is_best True lr [0.001]
training epoch 44 val accuracy 0.768 topk_dict {'top1': 0.768} is_best False lr [0.001]
training epoch 45 val accuracy 0.7594 topk_dict {'top1': 0.7594} is_best False lr [0.001]
training epoch 46 val accuracy 0.7762 topk_dict {'top1': 0.7762} is_best True lr [0.001]
training epoch 47 val accuracy 0.779 topk_dict {'top1': 0.779} is_best True lr [0.001]
training epoch 48 val accuracy 0.7704 topk_dict {'top1': 0.7704} is_best False lr [0.001]
training epoch 49 val accuracy 0.786 topk_dict {'top1': 0.786} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.786 topk_dict {'top1': 0.786}
