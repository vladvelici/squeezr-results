start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 39 . block score: 0.043051496148109436
removed block 39 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 26 . block score: 0.04373127222061157
removed block 26 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 29 . block score: 0.044168151915073395
removed block 29 current accuracy 0.9958 loss from initial  0.0041999999999999815
training start
training epoch 0 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 6 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 11 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (28, 0.04449187405407429), (36, 0.1709192916750908), (37, 0.04726572521030903), (38, 0.044127440080046654), (40, 0.04637975990772247), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (50, 0.046102043241262436), (51, 0.045608362182974815), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 38 . block score: 0.044127440080046654
removed block 38 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (28, 0.04449187405407429), (36, 0.1709192916750908), (37, 0.04726572521030903), (40, 0.04637975990772247), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (50, 0.046102043241262436), (51, 0.045608362182974815), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 28 . block score: 0.04449187405407429
removed block 28 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (37, 0.04726572521030903), (40, 0.04637975990772247), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (50, 0.046102043241262436), (51, 0.045608362182974815), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 51 . block score: 0.045608362182974815
removed block 51 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (37, 0.04726572521030903), (40, 0.04637975990772247), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (50, 0.046102043241262436), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 50 . block score: 0.046102043241262436
removed block 50 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (37, 0.04726572521030903), (40, 0.04637975990772247), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 40 . block score: 0.04637975990772247
removed block 40 current accuracy 0.9866 loss from initial  0.013399999999999967
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (37, 0.04726572521030903), (41, 0.047826046124100685), (42, 0.04687914252281189), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 42 . block score: 0.04687914252281189
removed block 42 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (37, 0.04726572521030903), (41, 0.047826046124100685), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 37 . block score: 0.04726572521030903
removed block 37 current accuracy 0.9682 loss from initial  0.03180000000000005
since last training loss: 0.03180000000000005 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (41, 0.047826046124100685), (43, 0.047269461676478386), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 43 . block score: 0.047269461676478386
removed block 43 current accuracy 0.9606 loss from initial  0.03939999999999999
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (3, 0.047729603946208954), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (41, 0.047826046124100685), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 3 . block score: 0.047729603946208954
removed block 3 current accuracy 0.952 loss from initial  0.04800000000000004
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (41, 0.047826046124100685), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (52, 0.04778864234685898), (53, 0.05558110028505325)]
computing accuracy for after removing block 52 . block score: 0.04778864234685898
removed block 52 current accuracy 0.8646 loss from initial  0.13539999999999996
since last training loss: 0.13539999999999996 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05463236942887306), (4, 0.06681165099143982), (5, 0.05524819158017635), (6, 0.07421471551060677), (7, 0.08860784769058228), (8, 0.09351681172847748), (9, 0.09686536714434624), (10, 0.09121303632855415), (11, 0.09348852932453156), (12, 0.10764492303133011), (13, 0.08964601531624794), (14, 0.07689409703016281), (15, 0.08719760924577713), (16, 0.08557957783341408), (17, 0.07669511064887047), (18, 0.2586476355791092), (19, 0.0689113698899746), (20, 0.0636069979518652), (21, 0.06406670995056629), (22, 0.05759882368147373), (23, 0.05374442972242832), (24, 0.05399114266037941), (25, 0.05186348594725132), (27, 0.05177374742925167), (36, 0.1709192916750908), (41, 0.047826046124100685), (44, 0.04888803884387016), (45, 0.05018142983317375), (46, 0.05211147665977478), (47, 0.05009003169834614), (48, 0.050810663029551506), (49, 0.04817153140902519), (53, 0.05558110028505325)]
computing accuracy for after removing block 41 . block score: 0.047826046124100685
removed block 41 current accuracy 0.84 loss from initial  0.16000000000000003
training start
training epoch 0 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.001]
training epoch 1 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 2 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 3 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 4 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 5 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best True lr [0.001]
training epoch 6 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best True lr [0.001]
training epoch 7 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 8 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 9 val accuracy 0.986 topk_dict {'top1': 0.986} is_best True lr [0.001]
training epoch 10 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 11 val accuracy 0.987 topk_dict {'top1': 0.987} is_best True lr [0.001]
training epoch 12 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
training epoch 13 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 14 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best True lr [0.001]
training epoch 15 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 16 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 17 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 18 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
training epoch 19 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best False lr [0.001]
training epoch 20 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best False lr [0.001]
training epoch 21 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 22 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 23 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 24 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 25 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best True lr [0.001]
training epoch 26 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 27 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 28 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 29 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 30 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 31 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 32 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 33 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 34 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 35 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 36 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 37 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 38 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 39 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 40 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 41 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 42 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 43 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 44 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 45 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 46 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 47 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 48 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 49 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.990000)
finished training. finished 50 epochs. accuracy 0.99 topk_dict {'top1': 0.99}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (44, 0.04840638488531113), (45, 0.04966689832508564), (46, 0.0515850018709898), (47, 0.049603791907429695), (48, 0.05031087435781956), (49, 0.04771776683628559), (53, 0.05497457832098007)]
computing accuracy for after removing block 49 . block score: 0.04771776683628559
removed block 49 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.018199999999999994 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (44, 0.04840638488531113), (45, 0.04966689832508564), (46, 0.0515850018709898), (47, 0.049603791907429695), (48, 0.05031087435781956), (53, 0.05497457832098007)]
computing accuracy for after removing block 44 . block score: 0.04840638488531113
removed block 44 current accuracy 0.9492 loss from initial  0.050799999999999956
since last training loss: 0.04079999999999995 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (45, 0.04966689832508564), (46, 0.0515850018709898), (47, 0.049603791907429695), (48, 0.05031087435781956), (53, 0.05497457832098007)]
computing accuracy for after removing block 47 . block score: 0.049603791907429695
removed block 47 current accuracy 0.885 loss from initial  0.11499999999999999
since last training loss: 0.10499999999999998 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (45, 0.04966689832508564), (46, 0.0515850018709898), (48, 0.05031087435781956), (53, 0.05497457832098007)]
computing accuracy for after removing block 45 . block score: 0.04966689832508564
removed block 45 current accuracy 0.7918 loss from initial  0.20820000000000005
since last training loss: 0.19820000000000004 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (46, 0.0515850018709898), (48, 0.05031087435781956), (53, 0.05497457832098007)]
computing accuracy for after removing block 48 . block score: 0.05031087435781956
removed block 48 current accuracy 0.684 loss from initial  0.31599999999999995
since last training loss: 0.30599999999999994 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (27, 0.05131184123456478), (36, 0.16927268728613853), (46, 0.0515850018709898), (53, 0.05497457832098007)]
computing accuracy for after removing block 27 . block score: 0.05131184123456478
removed block 27 current accuracy 0.6838 loss from initial  0.31620000000000004
since last training loss: 0.3062 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (25, 0.05134192667901516), (36, 0.16927268728613853), (46, 0.0515850018709898), (53, 0.05497457832098007)]
computing accuracy for after removing block 25 . block score: 0.05134192667901516
removed block 25 current accuracy 0.6642 loss from initial  0.3358
since last training loss: 0.3258 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (36, 0.16927268728613853), (46, 0.0515850018709898), (53, 0.05497457832098007)]
computing accuracy for after removing block 46 . block score: 0.0515850018709898
removed block 46 current accuracy 0.5784 loss from initial  0.4216
since last training loss: 0.41159999999999997 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (23, 0.053207358345389366), (24, 0.05348416604101658), (36, 0.16927268728613853), (53, 0.05497457832098007)]
computing accuracy for after removing block 23 . block score: 0.053207358345389366
removed block 23 current accuracy 0.5222 loss from initial  0.4778
since last training loss: 0.4678 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (24, 0.05348416604101658), (36, 0.16927268728613853), (53, 0.05497457832098007)]
computing accuracy for after removing block 24 . block score: 0.05348416604101658
removed block 24 current accuracy 0.4966 loss from initial  0.5034000000000001
since last training loss: 0.4934 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.054155848920345306), (4, 0.06640932336449623), (5, 0.05473034642636776), (6, 0.07357129827141762), (7, 0.08777090534567833), (8, 0.09261733666062355), (9, 0.09583184495568275), (10, 0.09031803160905838), (11, 0.09248441457748413), (12, 0.10658379271626472), (13, 0.08873825520277023), (14, 0.0760946236550808), (15, 0.0862942673265934), (16, 0.08475743234157562), (17, 0.07593774795532227), (18, 0.2559289261698723), (19, 0.06820399686694145), (20, 0.06298163160681725), (21, 0.06344085186719894), (22, 0.05698977783322334), (36, 0.16927268728613853), (53, 0.05497457832098007)]
computing accuracy for after removing block 0 . block score: 0.054155848920345306
removed block 0 current accuracy 0.4868 loss from initial  0.5132
training start
training epoch 0 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best True lr [0.001]
training epoch 1 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.001]
training epoch 2 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.001]
training epoch 3 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.001]
training epoch 4 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.001]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 6 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 7 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.001]
training epoch 8 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 9 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 10 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 11 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 12 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 13 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 14 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 15 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 16 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.001]
training epoch 17 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 18 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 19 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 20 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 21 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 22 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 23 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 24 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.001]
training epoch 25 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 26 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.001]
training epoch 27 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 28 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 29 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 30 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 31 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 32 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 33 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 34 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 35 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 36 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 37 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 38 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 39 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 40 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 41 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 42 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 43 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 44 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 45 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 46 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 47 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 48 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 49 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.928000)
finished training. finished 50 epochs. accuracy 0.928 topk_dict {'top1': 0.928}
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (5, 0.05453944951295853), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (20, 0.06254756078124046), (21, 0.06305738538503647), (22, 0.056971682235598564), (36, 0.16735216975212097), (53, 0.05462395027279854)]
computing accuracy for after removing block 5 . block score: 0.05453944951295853
removed block 5 current accuracy 0.9208 loss from initial  0.07920000000000005
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (20, 0.06254756078124046), (21, 0.06305738538503647), (22, 0.056971682235598564), (36, 0.16735216975212097), (53, 0.05462395027279854)]
computing accuracy for after removing block 53 . block score: 0.05462395027279854
removed block 53 current accuracy 0.3658 loss from initial  0.6342
since last training loss: 0.5622 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (20, 0.06254756078124046), (21, 0.06305738538503647), (22, 0.056971682235598564), (36, 0.16735216975212097)]
computing accuracy for after removing block 22 . block score: 0.056971682235598564
removed block 22 current accuracy 0.361 loss from initial  0.639
since last training loss: 0.5670000000000001 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (20, 0.06254756078124046), (21, 0.06305738538503647), (36, 0.16735216975212097)]
computing accuracy for after removing block 20 . block score: 0.06254756078124046
removed block 20 current accuracy 0.3194 loss from initial  0.6806
since last training loss: 0.6086 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (21, 0.06305738538503647), (36, 0.16735216975212097)]
computing accuracy for after removing block 21 . block score: 0.06305738538503647
removed block 21 current accuracy 0.2982 loss from initial  0.7018
since last training loss: 0.6298 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.06658671423792839), (6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (36, 0.16735216975212097)]
computing accuracy for after removing block 4 . block score: 0.06658671423792839
removed block 4 current accuracy 0.2464 loss from initial  0.7536
since last training loss: 0.6816 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (19, 0.06758049130439758), (36, 0.16735216975212097)]
computing accuracy for after removing block 19 . block score: 0.06758049130439758
removed block 19 current accuracy 0.253 loss from initial  0.747
since last training loss: 0.675 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(6, 0.07322918251156807), (7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (36, 0.16735216975212097)]
computing accuracy for after removing block 6 . block score: 0.07322918251156807
removed block 6 current accuracy 0.1908 loss from initial  0.8092
since last training loss: 0.7372000000000001 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (17, 0.07542302086949348), (18, 0.25325512886047363), (36, 0.16735216975212097)]
computing accuracy for after removing block 17 . block score: 0.07542302086949348
removed block 17 current accuracy 0.208 loss from initial  0.792
since last training loss: 0.7200000000000001 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (14, 0.07548633217811584), (15, 0.0856088288128376), (16, 0.08389361575245857), (18, 0.25325512886047363), (36, 0.16735216975212097)]
computing accuracy for after removing block 14 . block score: 0.07548633217811584
removed block 14 current accuracy 0.237 loss from initial  0.763
since last training loss: 0.6910000000000001 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (15, 0.0856088288128376), (16, 0.08389361575245857), (18, 0.25325512886047363), (36, 0.16735216975212097)]
computing accuracy for after removing block 16 . block score: 0.08389361575245857
removed block 16 current accuracy 0.2206 loss from initial  0.7794
since last training loss: 0.7074 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(7, 0.0867859311401844), (8, 0.09187645092606544), (9, 0.09465208649635315), (10, 0.0892891101539135), (11, 0.09134439751505852), (12, 0.10533127188682556), (13, 0.08768999949097633), (15, 0.0856088288128376), (18, 0.25325512886047363), (36, 0.16735216975212097)]
computing accuracy for after removing block 15 . block score: 0.0856088288128376
removed block 15 current accuracy 0.1644 loss from initial  0.8356
training start
training epoch 0 val accuracy 0.5366 topk_dict {'top1': 0.5366} is_best True lr [0.001]
training epoch 1 val accuracy 0.5752 topk_dict {'top1': 0.5752} is_best True lr [0.001]
training epoch 2 val accuracy 0.602 topk_dict {'top1': 0.602} is_best True lr [0.001]
training epoch 3 val accuracy 0.628 topk_dict {'top1': 0.628} is_best True lr [0.001]
training epoch 4 val accuracy 0.6486 topk_dict {'top1': 0.6486} is_best True lr [0.001]
training epoch 5 val accuracy 0.6636 topk_dict {'top1': 0.6636} is_best True lr [0.001]
training epoch 6 val accuracy 0.6718 topk_dict {'top1': 0.6718} is_best True lr [0.001]
training epoch 7 val accuracy 0.6902 topk_dict {'top1': 0.6902} is_best True lr [0.001]
training epoch 8 val accuracy 0.6942 topk_dict {'top1': 0.6942} is_best True lr [0.001]
training epoch 9 val accuracy 0.7064 topk_dict {'top1': 0.7064} is_best True lr [0.001]
training epoch 10 val accuracy 0.715 topk_dict {'top1': 0.715} is_best True lr [0.001]
training epoch 11 val accuracy 0.7238 topk_dict {'top1': 0.7238} is_best True lr [0.001]
training epoch 12 val accuracy 0.731 topk_dict {'top1': 0.731} is_best True lr [0.001]
training epoch 13 val accuracy 0.7362 topk_dict {'top1': 0.7362} is_best True lr [0.001]
training epoch 14 val accuracy 0.7414 topk_dict {'top1': 0.7414} is_best True lr [0.001]
training epoch 15 val accuracy 0.7442 topk_dict {'top1': 0.7442} is_best True lr [0.001]
training epoch 16 val accuracy 0.744 topk_dict {'top1': 0.744} is_best False lr [0.001]
training epoch 17 val accuracy 0.7582 topk_dict {'top1': 0.7582} is_best True lr [0.001]
training epoch 18 val accuracy 0.7584 topk_dict {'top1': 0.7584} is_best True lr [0.001]
training epoch 19 val accuracy 0.765 topk_dict {'top1': 0.765} is_best True lr [0.001]
training epoch 20 val accuracy 0.7614 topk_dict {'top1': 0.7614} is_best False lr [0.001]
training epoch 21 val accuracy 0.7654 topk_dict {'top1': 0.7654} is_best True lr [0.001]
training epoch 22 val accuracy 0.7708 topk_dict {'top1': 0.7708} is_best True lr [0.001]
training epoch 23 val accuracy 0.7732 topk_dict {'top1': 0.7732} is_best True lr [0.001]
training epoch 24 val accuracy 0.7812 topk_dict {'top1': 0.7812} is_best True lr [0.001]
training epoch 25 val accuracy 0.7794 topk_dict {'top1': 0.7794} is_best False lr [0.001]
training epoch 26 val accuracy 0.7828 topk_dict {'top1': 0.7828} is_best True lr [0.001]
training epoch 27 val accuracy 0.7864 topk_dict {'top1': 0.7864} is_best True lr [0.001]
training epoch 28 val accuracy 0.7858 topk_dict {'top1': 0.7858} is_best False lr [0.001]
training epoch 29 val accuracy 0.7966 topk_dict {'top1': 0.7966} is_best True lr [0.001]
training epoch 30 val accuracy 0.7932 topk_dict {'top1': 0.7932} is_best False lr [0.001]
training epoch 31 val accuracy 0.7946 topk_dict {'top1': 0.7946} is_best False lr [0.001]
training epoch 32 val accuracy 0.7882 topk_dict {'top1': 0.7882} is_best False lr [0.001]
training epoch 33 val accuracy 0.792 topk_dict {'top1': 0.792} is_best False lr [0.001]
training epoch 34 val accuracy 0.7994 topk_dict {'top1': 0.7994} is_best True lr [0.001]
training epoch 35 val accuracy 0.7974 topk_dict {'top1': 0.7974} is_best False lr [0.001]
training epoch 36 val accuracy 0.8014 topk_dict {'top1': 0.8014} is_best True lr [0.001]
training epoch 37 val accuracy 0.805 topk_dict {'top1': 0.805} is_best True lr [0.001]
training epoch 38 val accuracy 0.811 topk_dict {'top1': 0.811} is_best True lr [0.001]
training epoch 39 val accuracy 0.8074 topk_dict {'top1': 0.8074} is_best False lr [0.001]
training epoch 40 val accuracy 0.8124 topk_dict {'top1': 0.8124} is_best True lr [0.001]
training epoch 41 val accuracy 0.8106 topk_dict {'top1': 0.8106} is_best False lr [0.001]
training epoch 42 val accuracy 0.8068 topk_dict {'top1': 0.8068} is_best False lr [0.001]
training epoch 43 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best False lr [0.001]
training epoch 44 val accuracy 0.816 topk_dict {'top1': 0.816} is_best True lr [0.001]
training epoch 45 val accuracy 0.81 topk_dict {'top1': 0.81} is_best False lr [0.001]
training epoch 46 val accuracy 0.819 topk_dict {'top1': 0.819} is_best True lr [0.001]
training epoch 47 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best False lr [0.001]
training epoch 48 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.001]
training epoch 49 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8208 topk_dict {'top1': 0.8208}
