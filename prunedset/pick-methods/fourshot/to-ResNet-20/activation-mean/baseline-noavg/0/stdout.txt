start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055875. All blocks and scores: [(22, 0.055874861776828766), (24, 0.06177143566310406), (21, 0.06496669724583626), (25, 0.06539816409349442), (27, 0.07151609845459461), (20, 0.0722665935754776), (35, 0.07411019410938025), (30, 0.07556094694882631), (23, 0.07561394572257996), (32, 0.07979130558669567), (29, 0.08450872916728258), (31, 0.08690572716295719), (26, 0.08848298899829388), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09050499927252531), (33, 0.10334126185625792), (34, 0.10430913046002388), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14227986335754395), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15326451510190964), (38, 0.16421835497021675), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.1724428366869688), (41, 0.17542804032564163), (42, 0.1755864955484867), (44, 0.18015791475772858), (10, 0.1813554372638464), (4, 0.18203354813158512), (45, 0.18489503115415573), (43, 0.19027204811573029), (46, 0.19319169037044048), (47, 0.20808524079620838), (48, 0.2123200260102749), (9, 0.21280715242028236), (49, 0.214156249538064), (50, 0.22060429491102695), (51, 0.24123229831457138), (17, 0.2635997086763382), (52, 0.2748573273420334), (18, 0.35712291300296783), (36, 0.47951839864254), (53, 0.6427939906716347)]
computing accuracy for after removing block 22 . block score: 0.055874861776828766
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063728. All blocks and scores: [(24, 0.06372843217104673), (21, 0.06496669724583626), (25, 0.06680801045149565), (27, 0.07130979653447866), (20, 0.0722665935754776), (35, 0.07429851219058037), (30, 0.07568530179560184), (23, 0.07636885344982147), (32, 0.07971580140292645), (29, 0.08468191791325808), (31, 0.08691531326621771), (5, 0.08888446353375912), (3, 0.09012125711888075), (26, 0.09025377035140991), (19, 0.09047461114823818), (28, 0.09172139409929514), (33, 0.10357575863599777), (34, 0.10437646694481373), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14291350357234478), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15452100336551666), (11, 0.1649541687220335), (38, 0.16498222388327122), (2, 0.16567634418606758), (40, 0.17307638376951218), (41, 0.17614571005105972), (42, 0.1761545743793249), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.1824799831956625), (45, 0.18450302816927433), (43, 0.19050214625895023), (46, 0.19372878782451153), (47, 0.20627203024923801), (48, 0.2120207268744707), (9, 0.21280715242028236), (49, 0.2143655065447092), (50, 0.22066733054816723), (51, 0.2409748863428831), (17, 0.2635997086763382), (52, 0.27451441809535027), (18, 0.35712291300296783), (36, 0.48188556358218193), (53, 0.6410739421844482)]
computing accuracy for after removing block 24 . block score: 0.06372843217104673
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.064967. All blocks and scores: [(21, 0.06496669724583626), (25, 0.06703743990510702), (27, 0.07013737596571445), (20, 0.0722665935754776), (35, 0.07342808321118355), (30, 0.07471412140876055), (23, 0.07636885344982147), (32, 0.07861070893704891), (29, 0.08317314926534891), (31, 0.08625906892120838), (5, 0.08888446353375912), (26, 0.08973303623497486), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09168458171188831), (34, 0.10268995817750692), (33, 0.10318366531282663), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14301974326372147), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1552681177854538), (38, 0.16453734785318375), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.17422636039555073), (41, 0.17607183754444122), (42, 0.17612144351005554), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18264964036643505), (45, 0.18367482721805573), (43, 0.1899556815624237), (46, 0.19336611777544022), (47, 0.20545421540737152), (48, 0.21146412566304207), (9, 0.21280715242028236), (49, 0.21425769478082657), (50, 0.21967321634292603), (51, 0.2403922826051712), (17, 0.2635997086763382), (52, 0.2743810787796974), (18, 0.35712291300296783), (36, 0.4825970157980919), (53, 0.6408330947160721)]
computing accuracy for after removing block 21 . block score: 0.06496669724583626
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068154. All blocks and scores: [(25, 0.06815383676439524), (27, 0.06980223208665848), (20, 0.0722665935754776), (35, 0.07353036105632782), (30, 0.07382607832551003), (23, 0.0764246741309762), (32, 0.07829320430755615), (29, 0.08308697119355202), (31, 0.08602661546319723), (5, 0.08888446353375912), (26, 0.08915798645466566), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09211605414748192), (34, 0.10230127815157175), (33, 0.10312568210065365), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14325005002319813), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1557087078690529), (38, 0.1647000703960657), (11, 0.1649541687220335), (2, 0.16567634418606758), (40, 0.1755049880594015), (41, 0.17610502615571022), (42, 0.17631095461547375), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18253245949745178), (45, 0.18302420526742935), (43, 0.19044085033237934), (46, 0.19308597594499588), (47, 0.20481226220726967), (48, 0.21083582006394863), (9, 0.21280715242028236), (49, 0.21393285878002644), (50, 0.21925617940723896), (51, 0.23967960476875305), (17, 0.2635997086763382), (52, 0.273654505610466), (18, 0.35712291300296783), (36, 0.48382943123579025), (53, 0.639979712665081)]
computing accuracy for after removing block 25 . block score: 0.06815383676439524
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068811. All blocks and scores: [(27, 0.06881092954427004), (20, 0.0722665935754776), (35, 0.07253072131425142), (30, 0.0731162941083312), (23, 0.0764246741309762), (32, 0.07713543437421322), (29, 0.08107472397387028), (31, 0.08513766340911388), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09101575054228306), (34, 0.10053910687565804), (33, 0.10205675661563873), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14211287535727024), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1547116171568632), (38, 0.1637822836637497), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.1742816288024187), (42, 0.1750345081090927), (40, 0.17540869303047657), (45, 0.18085969612002373), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18211421370506287), (43, 0.18795999139547348), (46, 0.191400196403265), (47, 0.2023499310016632), (48, 0.20854505337774754), (49, 0.21236556582152843), (9, 0.21280715242028236), (50, 0.21730931103229523), (51, 0.23744945600628853), (17, 0.2635997086763382), (52, 0.2733411490917206), (18, 0.35712291300296783), (36, 0.48273831978440285), (53, 0.6374414563179016)]
computing accuracy for after removing block 27 . block score: 0.06881092954427004
removed block 27 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072124. All blocks and scores: [(35, 0.0721236327663064), (20, 0.0722665935754776), (30, 0.07257708720862865), (23, 0.0764246741309762), (32, 0.07654038444161415), (29, 0.08117466047406197), (31, 0.08459337707608938), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09207288548350334), (34, 0.10011614393442869), (33, 0.10208251420408487), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (37, 0.14123038575053215), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1535331755876541), (38, 0.16272037848830223), (11, 0.1649541687220335), (2, 0.16567634418606758), (42, 0.174275454133749), (41, 0.17455543763935566), (40, 0.17537744157016277), (45, 0.17959223687648773), (10, 0.1813554372638464), (4, 0.18203354813158512), (44, 0.18369055725634098), (43, 0.18725652806460857), (46, 0.19005939364433289), (47, 0.20008372515439987), (48, 0.20726387202739716), (49, 0.21192682161927223), (9, 0.21280715242028236), (50, 0.21623316779732704), (51, 0.23535941168665886), (17, 0.2635997086763382), (52, 0.2723398506641388), (18, 0.35712291300296783), (36, 0.4819323644042015), (53, 0.6367765739560127)]
computing accuracy for after removing block 35 . block score: 0.0721236327663064
removed block 35 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 20, with score 0.072267. All blocks and scores: [(20, 0.0722665935754776), (30, 0.07257708720862865), (23, 0.0764246741309762), (32, 0.07654038444161415), (29, 0.08117466047406197), (31, 0.08459337707608938), (26, 0.088622210547328), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09207288548350334), (34, 0.10011614393442869), (33, 0.10208251420408487), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.13975277356803417), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15266877226531506), (38, 0.1587308645248413), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17313233949244022), (40, 0.1735091581940651), (42, 0.17351526394486427), (45, 0.17846908420324326), (10, 0.1813554372638464), (44, 0.18180529214441776), (4, 0.18203354813158512), (43, 0.18466809391975403), (46, 0.18799381330609322), (47, 0.1981325838714838), (48, 0.20550396665930748), (49, 0.21049201861023903), (9, 0.21280715242028236), (50, 0.21590297669172287), (51, 0.2348758615553379), (17, 0.2635997086763382), (52, 0.2719504348933697), (18, 0.35712291300296783), (36, 0.48112449422478676), (53, 0.6373795047402382)]
computing accuracy for after removing block 20 . block score: 0.0722665935754776
removed block 20 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 30, with score 0.072471. All blocks and scores: [(30, 0.07247117161750793), (32, 0.07625227980315685), (23, 0.07768272049725056), (29, 0.08184758014976978), (31, 0.0846198545768857), (26, 0.08804163243621588), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.0922315837815404), (34, 0.10024414770305157), (33, 0.10323962476104498), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.1393482480198145), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15060056559741497), (38, 0.15361598692834377), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17073342762887478), (42, 0.1711448933929205), (45, 0.1738788615912199), (40, 0.1745755597949028), (44, 0.17893094941973686), (10, 0.1813554372638464), (4, 0.18203354813158512), (43, 0.18250644207000732), (46, 0.18323267064988613), (47, 0.1950262486934662), (48, 0.2035509143024683), (49, 0.20875819958746433), (9, 0.21280715242028236), (50, 0.21497691608965397), (51, 0.23172142542898655), (17, 0.2635997086763382), (52, 0.26927676796913147), (18, 0.35712291300296783), (36, 0.4742658771574497), (53, 0.6354397609829903)]
computing accuracy for after removing block 30 . block score: 0.07247117161750793
removed block 30 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.075761. All blocks and scores: [(32, 0.0757605042308569), (23, 0.07768272049725056), (29, 0.08184758014976978), (31, 0.08484559506177902), (26, 0.08804163243621588), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.0922315837815404), (34, 0.09961904678493738), (33, 0.10478989686816931), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.13780422136187553), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1513042040169239), (38, 0.1537246610969305), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17053041607141495), (42, 0.17157302983105183), (45, 0.17264624871313572), (40, 0.17659500427544117), (44, 0.1804590057581663), (10, 0.1813554372638464), (43, 0.18187697976827621), (4, 0.18203354813158512), (46, 0.18318604677915573), (47, 0.1952302400022745), (48, 0.20398801378905773), (49, 0.20897031389176846), (9, 0.21280715242028236), (50, 0.21466458588838577), (51, 0.23112696781754494), (17, 0.2635997086763382), (52, 0.2684929072856903), (18, 0.35712291300296783), (36, 0.4795118235051632), (53, 0.6385306268930435)]
computing accuracy for after removing block 32 . block score: 0.0757605042308569
removed block 32 current accuracy 0.9868 loss from initial  0.01319999999999999
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.077683. All blocks and scores: [(23, 0.07768272049725056), (29, 0.08184758014976978), (31, 0.08484559506177902), (26, 0.08804163243621588), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.0922315837815404), (34, 0.09931742120534182), (33, 0.10639280546456575), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (13, 0.13598485849797726), (37, 0.13599098846316338), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.15193320997059345), (38, 0.1541181467473507), (11, 0.1649541687220335), (2, 0.16567634418606758), (41, 0.17138488590717316), (45, 0.17160541750490665), (42, 0.17181690968573093), (40, 0.17934654094278812), (10, 0.1813554372638464), (43, 0.18177739344537258), (4, 0.18203354813158512), (46, 0.18248875625431538), (44, 0.18305239267647266), (47, 0.1956153456121683), (48, 0.2053513564169407), (49, 0.20944731123745441), (9, 0.21280715242028236), (50, 0.21479325741529465), (51, 0.23030897602438927), (17, 0.2635997086763382), (52, 0.2672784812748432), (18, 0.35712291300296783), (36, 0.48884374275803566), (53, 0.6405513137578964)]
computing accuracy for after removing block 23 . block score: 0.07768272049725056
removed block 23 current accuracy 0.981 loss from initial  0.019000000000000017
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.082807. All blocks and scores: [(29, 0.08280743844807148), (31, 0.0844151834025979), (26, 0.08742997422814369), (5, 0.08888446353375912), (3, 0.09012125711888075), (19, 0.09047461114823818), (28, 0.09232090599834919), (34, 0.09935691766440868), (33, 0.10806246660649776), (1, 0.1137560335919261), (0, 0.12683702819049358), (16, 0.13045308366417885), (6, 0.133095545694232), (37, 0.1359530258923769), (13, 0.13598485849797726), (15, 0.13986125774681568), (14, 0.1405086349695921), (12, 0.1444785874336958), (7, 0.14519078843295574), (8, 0.14819741435348988), (39, 0.1539351511746645), (38, 0.1541147120296955), (11, 0.1649541687220335), (2, 0.16567634418606758), (45, 0.17084915190935135), (41, 0.1713754739612341), (42, 0.17186039127409458), (40, 0.18047209829092026), (44, 0.180881192907691), (10, 0.1813554372638464), (46, 0.18177111446857452), (43, 0.1820179708302021), (4, 0.18203354813158512), (47, 0.19347479566931725), (48, 0.20352869294583797), (49, 0.20763852074742317), (9, 0.21280715242028236), (50, 0.2135214600712061), (51, 0.22902475856244564), (17, 0.2635997086763382), (52, 0.2656911350786686), (18, 0.35712291300296783), (36, 0.49319426715373993), (53, 0.640310674905777)]
computing accuracy for after removing block 29 . block score: 0.08280743844807148
removed block 29 current accuracy 0.9752 loss from initial  0.024800000000000044
training start
training epoch 0 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 1 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 3 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 5 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 6 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 8 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 16 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 12 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 11
[activation mean]: block to remove picked: 5, with score 0.089004. All blocks and scores: [(5, 0.08900386281311512), (3, 0.09174412954598665), (19, 0.09455086104571819), (31, 0.09992654249072075), (28, 0.10235224198549986), (26, 0.10356095619499683), (34, 0.10876933392137289), (33, 0.1120989304035902), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.1293658446520567), (6, 0.1327829398214817), (13, 0.1353571992367506), (14, 0.13962357677519321), (15, 0.14090468361973763), (37, 0.14188896864652634), (12, 0.14418023638427258), (7, 0.14459693990647793), (8, 0.14622257463634014), (39, 0.15118437819182873), (38, 0.16186795383691788), (11, 0.1641346924006939), (2, 0.16943851485848427), (40, 0.1709674969315529), (41, 0.17456659488379955), (42, 0.17467730678617954), (44, 0.17776897177100182), (10, 0.17806223593652248), (4, 0.18176384270191193), (45, 0.18331194669008255), (43, 0.18741796910762787), (46, 0.19200847297906876), (47, 0.20501084439456463), (9, 0.21093368530273438), (48, 0.21176654659211636), (49, 0.21439186483621597), (50, 0.21992514096200466), (51, 0.23955553956329823), (17, 0.26348958536982536), (52, 0.2761591710150242), (18, 0.35476192459464073), (36, 0.4760270118713379), (53, 0.6303106546401978)]
computing accuracy for after removing block 5 . block score: 0.08900386281311512
removed block 5 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.000200000000000089 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 3, with score 0.091744. All blocks and scores: [(3, 0.09174412954598665), (19, 0.0946635939180851), (31, 0.0997903486713767), (28, 0.10228581633418798), (26, 0.10259941127151251), (34, 0.1096471594646573), (33, 0.11151997372508049), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.128503929823637), (6, 0.1346585862338543), (13, 0.1354149654507637), (14, 0.1395125314593315), (15, 0.14091712422668934), (37, 0.14332708157598972), (7, 0.14568107575178146), (12, 0.1467865090817213), (8, 0.14767366088926792), (39, 0.15019941702485085), (38, 0.159346055239439), (11, 0.16625969484448433), (2, 0.16943851485848427), (40, 0.17196196131408215), (41, 0.17412018030881882), (42, 0.1749902218580246), (44, 0.17681670375168324), (10, 0.18151210993528366), (4, 0.18176384270191193), (45, 0.18292924389243126), (43, 0.1876430045813322), (46, 0.19145824201405048), (47, 0.20394687354564667), (48, 0.2111172378063202), (49, 0.21500900946557522), (9, 0.2166622430086136), (50, 0.21905221231281757), (51, 0.23917340487241745), (17, 0.2611573785543442), (52, 0.27534817159175873), (18, 0.35345490649342537), (36, 0.4739096015691757), (53, 0.6309318840503693)]
computing accuracy for after removing block 3 . block score: 0.09174412954598665
removed block 3 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.094145. All blocks and scores: [(19, 0.09414481557905674), (31, 0.09918536432087421), (26, 0.10140818450599909), (28, 0.10173665266484022), (34, 0.10991291236132383), (33, 0.11083175707608461), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (15, 0.14001189731061459), (7, 0.14780442602932453), (37, 0.14809506386518478), (8, 0.14827066473662853), (39, 0.1486924234777689), (12, 0.14965197630226612), (38, 0.154540304094553), (11, 0.166329026222229), (2, 0.16943851485848427), (41, 0.17465126886963844), (44, 0.17587213404476643), (42, 0.17642740719020367), (40, 0.1767117902636528), (45, 0.1836007796227932), (10, 0.1836229544132948), (4, 0.18494311720132828), (43, 0.19002420455217361), (46, 0.19293777830898762), (47, 0.20275473967194557), (48, 0.21092409640550613), (49, 0.21788106858730316), (50, 0.21803619340062141), (9, 0.22628222964704037), (51, 0.23950554803013802), (17, 0.2620463967323303), (52, 0.2734198570251465), (18, 0.35225748270750046), (36, 0.475886519998312), (53, 0.6321275606751442)]
computing accuracy for after removing block 19 . block score: 0.09414481557905674
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.098035. All blocks and scores: [(31, 0.09803532995283604), (26, 0.10197351314127445), (28, 0.10294090211391449), (34, 0.11026061791926622), (33, 0.11164015252143145), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (15, 0.14001189731061459), (39, 0.14731729589402676), (7, 0.14780442602932453), (8, 0.14827066473662853), (37, 0.1486251875758171), (12, 0.14965197630226612), (38, 0.15210763737559319), (11, 0.166329026222229), (2, 0.16943851485848427), (44, 0.17222810350358486), (41, 0.17289788462221622), (42, 0.1743974331766367), (40, 0.1774084698408842), (45, 0.1806801985949278), (10, 0.1836229544132948), (4, 0.18494311720132828), (43, 0.1867690607905388), (46, 0.18910966627299786), (47, 0.19996250979602337), (48, 0.2074850145727396), (49, 0.21488196961581707), (50, 0.21642463095486164), (9, 0.22628222964704037), (51, 0.23693596944212914), (17, 0.2620463967323303), (52, 0.271618764847517), (18, 0.35225748270750046), (36, 0.4719442166388035), (53, 0.633370652794838)]
computing accuracy for after removing block 31 . block score: 0.09803532995283604
removed block 31 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 26, with score 0.101974. All blocks and scores: [(26, 0.10197351314127445), (28, 0.10294090211391449), (34, 0.11067453864961863), (33, 0.11554993502795696), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (15, 0.14001189731061459), (37, 0.14676497876644135), (39, 0.14775051549077034), (7, 0.14780442602932453), (8, 0.14827066473662853), (12, 0.14965197630226612), (38, 0.1506026405841112), (11, 0.166329026222229), (2, 0.16943851485848427), (41, 0.17255868390202522), (42, 0.17404064908623695), (44, 0.17417567782104015), (45, 0.17916160076856613), (40, 0.18006565235555172), (10, 0.1836229544132948), (4, 0.18494311720132828), (43, 0.185402637347579), (46, 0.18866201490163803), (47, 0.19953574612736702), (48, 0.2070409506559372), (49, 0.21508227474987507), (50, 0.2161797732114792), (9, 0.22628222964704037), (51, 0.23492698930203915), (17, 0.2620463967323303), (52, 0.27066515013575554), (18, 0.35225748270750046), (36, 0.47842471674084663), (53, 0.6379244551062584)]
computing accuracy for after removing block 26 . block score: 0.10197351314127445
removed block 26 current accuracy 0.991 loss from initial  0.009000000000000008
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 28, with score 0.106419. All blocks and scores: [(28, 0.10641922894865274), (34, 0.1072150943800807), (33, 0.11504824552685022), (1, 0.11564252618700266), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (15, 0.14001189731061459), (37, 0.143793486058712), (39, 0.1455561611801386), (38, 0.14731967821717262), (7, 0.14780442602932453), (8, 0.14827066473662853), (12, 0.14965197630226612), (11, 0.166329026222229), (41, 0.16895996406674385), (2, 0.16943851485848427), (42, 0.17128471098840237), (44, 0.1731903161853552), (45, 0.1741358619183302), (40, 0.17978697456419468), (43, 0.1810128353536129), (10, 0.1836229544132948), (46, 0.18382500857114792), (4, 0.18494311720132828), (47, 0.19641348533332348), (48, 0.20305905304849148), (49, 0.21204813569784164), (50, 0.21381601504981518), (9, 0.22628222964704037), (51, 0.23062517493963242), (17, 0.2620463967323303), (52, 0.26801537722349167), (18, 0.35225748270750046), (36, 0.4743155650794506), (53, 0.6372547373175621)]
computing accuracy for after removing block 28 . block score: 0.10641922894865274
removed block 28 current accuracy 0.9824 loss from initial  0.01759999999999995
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 34, with score 0.105472. All blocks and scores: [(34, 0.1054723747074604), (1, 0.11564252618700266), (33, 0.11801388766616583), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (37, 0.13923774845898151), (15, 0.14001189731061459), (39, 0.14130623824894428), (38, 0.14152561873197556), (7, 0.14780442602932453), (8, 0.14827066473662853), (12, 0.14965197630226612), (41, 0.16515385918319225), (11, 0.166329026222229), (45, 0.1686789784580469), (42, 0.16879471763968468), (2, 0.16943851485848427), (44, 0.1698803137987852), (43, 0.17537975683808327), (46, 0.1782885491847992), (40, 0.17875275015830994), (10, 0.1836229544132948), (4, 0.18494311720132828), (47, 0.1938970945775509), (48, 0.19749269261956215), (49, 0.20689131878316402), (50, 0.20973040722310543), (51, 0.22563988901674747), (9, 0.22628222964704037), (17, 0.2620463967323303), (52, 0.26557258144021034), (18, 0.35225748270750046), (36, 0.4737609885632992), (53, 0.6435656473040581)]
computing accuracy for after removing block 34 . block score: 0.1054723747074604
removed block 34 current accuracy 0.9628 loss from initial  0.03720000000000001
since last training loss: 0.036800000000000055 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.115643. All blocks and scores: [(1, 0.11564252618700266), (33, 0.11801388766616583), (0, 0.126067616045475), (16, 0.12717397883534431), (13, 0.1310828235000372), (14, 0.13334925286471844), (6, 0.133554270491004), (37, 0.13642252422869205), (38, 0.13916133344173431), (15, 0.14001189731061459), (39, 0.14439030177891254), (7, 0.14780442602932453), (8, 0.14827066473662853), (12, 0.14965197630226612), (41, 0.16329536773264408), (11, 0.166329026222229), (45, 0.16665398515760899), (42, 0.16727286390960217), (2, 0.16943851485848427), (44, 0.172438383102417), (43, 0.17407537624239922), (46, 0.17730772867798805), (40, 0.18025699630379677), (10, 0.1836229544132948), (4, 0.18494311720132828), (47, 0.1940542683005333), (48, 0.19866900146007538), (49, 0.20708249881863594), (50, 0.20912304520606995), (51, 0.22192046977579594), (9, 0.22628222964704037), (17, 0.2620463967323303), (52, 0.26250024884939194), (18, 0.35225748270750046), (36, 0.489747516810894), (53, 0.6448605507612228)]
computing accuracy for after removing block 1 . block score: 0.11564252618700266
removed block 1 current accuracy 0.9506 loss from initial  0.0494
since last training loss: 0.049000000000000044 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 33, with score 0.116828. All blocks and scores: [(33, 0.11682833638042212), (0, 0.126067616045475), (16, 0.12727525271475315), (13, 0.12809283658862114), (6, 0.13184470683336258), (14, 0.13192793726921082), (38, 0.13422930240631104), (15, 0.13714461214840412), (37, 0.14412339217960835), (39, 0.14510759338736534), (8, 0.14718070439994335), (12, 0.14734944514930248), (7, 0.1499639842659235), (41, 0.1653592549264431), (11, 0.1655281949788332), (45, 0.16896536201238632), (44, 0.16930262371897697), (42, 0.16985472105443478), (2, 0.17438870295882225), (43, 0.17930712178349495), (46, 0.18002408556640148), (10, 0.18726924434304237), (4, 0.1891759019345045), (40, 0.1900077909231186), (47, 0.1934710144996643), (48, 0.19938009232282639), (50, 0.20889407210052013), (49, 0.21053886972367764), (51, 0.22232427261769772), (9, 0.22539978101849556), (52, 0.2606613487005234), (17, 0.2654908187687397), (18, 0.35234304144978523), (36, 0.5007668919861317), (53, 0.6437300369143486)]
computing accuracy for after removing block 33 . block score: 0.11682833638042212
removed block 33 current accuracy 0.9088 loss from initial  0.09119999999999995
since last training loss: 0.09079999999999999 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 0, with score 0.126068. All blocks and scores: [(0, 0.126067616045475), (16, 0.12727525271475315), (13, 0.12809283658862114), (6, 0.13184470683336258), (14, 0.13192793726921082), (38, 0.13302113488316536), (15, 0.13714461214840412), (37, 0.13947642594575882), (39, 0.14490254782140255), (8, 0.14718070439994335), (12, 0.14734944514930248), (7, 0.1499639842659235), (41, 0.1621470432728529), (44, 0.16505698300898075), (45, 0.16523394733667374), (11, 0.1655281949788332), (42, 0.1658933460712433), (43, 0.17381435446441174), (2, 0.17438870295882225), (46, 0.17502537928521633), (10, 0.18726924434304237), (4, 0.1891759019345045), (47, 0.19058748334646225), (40, 0.19315780885517597), (48, 0.19627544470131397), (50, 0.2063334509730339), (49, 0.2078352551907301), (51, 0.21684318408370018), (9, 0.22539978101849556), (52, 0.2570483051240444), (17, 0.2654908187687397), (18, 0.35234304144978523), (36, 0.5164131671190262), (53, 0.6508933454751968)]
computing accuracy for after removing block 0 . block score: 0.126067616045475
removed block 0 current accuracy 0.8326 loss from initial  0.1674
since last training loss: 0.16700000000000004 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.122383. All blocks and scores: [(13, 0.1223831232637167), (38, 0.12422848585993052), (14, 0.1267898567020893), (16, 0.1270340047776699), (6, 0.12809458374977112), (15, 0.13138418272137642), (8, 0.1404373086988926), (12, 0.14526953361928463), (39, 0.14759871177375317), (7, 0.15345410257577896), (44, 0.15748216956853867), (37, 0.15768797509372234), (11, 0.16464057750999928), (41, 0.1669747643172741), (42, 0.1694154292345047), (45, 0.17171312868595123), (2, 0.17901652865111828), (46, 0.1809370405972004), (43, 0.18530479073524475), (47, 0.1873938012868166), (10, 0.1938389539718628), (4, 0.19662325643002987), (48, 0.1970553006976843), (50, 0.2035499159246683), (40, 0.21284584514796734), (49, 0.21299305371940136), (51, 0.21454700082540512), (9, 0.22558272071182728), (52, 0.2505963630974293), (17, 0.2645142152905464), (18, 0.3472259044647217), (36, 0.5416177660226822), (53, 0.6443216875195503)]
computing accuracy for after removing block 13 . block score: 0.1223831232637167
removed block 13 current accuracy 0.8038 loss from initial  0.19620000000000004
training start
training epoch 0 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 1 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best True lr [0.001]
training epoch 2 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best True lr [0.001]
training epoch 3 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 4 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 5 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 6 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 7 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 8 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 9 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 10 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 11 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 12 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 13 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 14 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 15 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 16 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 17 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 18 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 20 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 21 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 22 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 23 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 24 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 25 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 26 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 27 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 28 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 29 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 31 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 32 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 33 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 34 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 35 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 36 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 37 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 38 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 39 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 40 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 41 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 42 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 43 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 44 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 45 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 46 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 47 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 48 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 49 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
loading model_best from epoch 26 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 22
[activation mean]: block to remove picked: 16, with score 0.128870. All blocks and scores: [(16, 0.12886987999081612), (14, 0.1381827164441347), (6, 0.14007759280502796), (15, 0.14220512099564075), (37, 0.14595529437065125), (8, 0.1463321316987276), (7, 0.14905010163784027), (39, 0.15199577063322067), (12, 0.15424502082169056), (38, 0.1588178053498268), (11, 0.16693752817809582), (40, 0.1695715095847845), (42, 0.17272670567035675), (41, 0.17343873530626297), (44, 0.17728526704013348), (10, 0.1785049755126238), (45, 0.18040228821337223), (2, 0.1805573683232069), (43, 0.1849109809845686), (46, 0.18989629298448563), (4, 0.19644230045378208), (47, 0.2020189482718706), (48, 0.20863672718405724), (49, 0.21029898151755333), (9, 0.2135803997516632), (50, 0.21913274005055428), (51, 0.23957381956279278), (17, 0.25254370644688606), (52, 0.272189412266016), (18, 0.364653829485178), (36, 0.4837469197809696), (53, 0.645569272339344)]
computing accuracy for after removing block 16 . block score: 0.12886987999081612
removed block 16 current accuracy 0.9872 loss from initial  0.012800000000000034
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 14, with score 0.138183. All blocks and scores: [(14, 0.1381827164441347), (6, 0.14007759280502796), (15, 0.14220512099564075), (8, 0.1463321316987276), (7, 0.14905010163784027), (38, 0.15022254548966885), (37, 0.15076493844389915), (39, 0.15077686309814453), (12, 0.15424502082169056), (11, 0.16693752817809582), (40, 0.16754727065563202), (44, 0.16832961328327656), (41, 0.17013852298259735), (42, 0.1706940084695816), (10, 0.1785049755126238), (2, 0.1805573683232069), (45, 0.1821779552847147), (43, 0.18387595005333424), (46, 0.18523065000772476), (4, 0.19644230045378208), (47, 0.19775980710983276), (49, 0.20463800802826881), (48, 0.20662401616573334), (9, 0.2135803997516632), (50, 0.21504732593894005), (17, 0.22579769417643547), (51, 0.24012817442417145), (52, 0.26807331666350365), (18, 0.3537287972867489), (36, 0.4737015441060066), (53, 0.661031685769558)]
computing accuracy for after removing block 14 . block score: 0.1381827164441347
removed block 14 current accuracy 0.9746 loss from initial  0.025399999999999978
since last training loss: 0.02179999999999993 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 6, with score 0.140078. All blocks and scores: [(6, 0.14007759280502796), (38, 0.1450593452900648), (15, 0.14614163897931576), (8, 0.1463321316987276), (7, 0.14905010163784027), (39, 0.14956996403634548), (12, 0.15424502082169056), (37, 0.15562956780195236), (44, 0.16087091527879238), (11, 0.16693752817809582), (41, 0.16909856721758842), (40, 0.1707262434065342), (42, 0.1713536251336336), (10, 0.1785049755126238), (2, 0.1805573683232069), (46, 0.18495614640414715), (45, 0.1849959660321474), (43, 0.1856794487684965), (4, 0.19644230045378208), (47, 0.20070428773760796), (49, 0.20341350883245468), (48, 0.20788859762251377), (9, 0.2135803997516632), (50, 0.2137267366051674), (17, 0.22937511838972569), (51, 0.24138429574668407), (52, 0.26424532383680344), (18, 0.3530968129634857), (36, 0.476367324590683), (53, 0.6653841212391853)]
computing accuracy for after removing block 6 . block score: 0.14007759280502796
removed block 6 current accuracy 0.9654 loss from initial  0.034599999999999964
since last training loss: 0.030999999999999917 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 38, with score 0.135976. All blocks and scores: [(38, 0.1359759010374546), (39, 0.1470507513731718), (15, 0.14859968051314354), (8, 0.14877080917358398), (7, 0.15140881575644016), (44, 0.15815656632184982), (37, 0.16006184183061123), (12, 0.1604155134409666), (41, 0.1664406582713127), (11, 0.1705236453562975), (42, 0.1705387830734253), (40, 0.1735776662826538), (2, 0.1805573683232069), (45, 0.183314960449934), (10, 0.1837841086089611), (46, 0.1848647426813841), (43, 0.18632188066840172), (4, 0.19644230045378208), (47, 0.19953646697103977), (49, 0.20553371496498585), (48, 0.20709387212991714), (50, 0.2106715328991413), (9, 0.21970535814762115), (17, 0.2285994365811348), (51, 0.24028745852410793), (52, 0.2614803686738014), (18, 0.35212263464927673), (36, 0.47364964708685875), (53, 0.6677016168832779)]
computing accuracy for after removing block 38 . block score: 0.1359759010374546
removed block 38 current accuracy 0.955 loss from initial  0.04500000000000004
since last training loss: 0.04139999999999999 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 15, with score 0.148600. All blocks and scores: [(15, 0.14859968051314354), (8, 0.14877080917358398), (7, 0.15140881575644016), (39, 0.15397708304226398), (44, 0.1547728031873703), (37, 0.16006184183061123), (12, 0.1604155134409666), (41, 0.16844334453344345), (11, 0.1705236453562975), (42, 0.17097913660109043), (45, 0.17937317863106728), (40, 0.18009178154170513), (2, 0.1805573683232069), (10, 0.1837841086089611), (46, 0.183892659842968), (43, 0.18747824244201183), (47, 0.19429045170545578), (4, 0.19644230045378208), (49, 0.20112475007772446), (48, 0.20168405584990978), (50, 0.20818206295371056), (9, 0.21970535814762115), (17, 0.2285994365811348), (51, 0.23882363922894), (52, 0.25871317833662033), (18, 0.35212263464927673), (36, 0.47364964708685875), (53, 0.6677913814783096)]
computing accuracy for after removing block 15 . block score: 0.14859968051314354
removed block 15 current accuracy 0.8984 loss from initial  0.10160000000000002
since last training loss: 0.09799999999999998 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 8, with score 0.148771. All blocks and scores: [(8, 0.14877080917358398), (44, 0.14942269027233124), (7, 0.15140881575644016), (39, 0.15442459657788277), (12, 0.1604155134409666), (42, 0.16384080983698368), (41, 0.16592970117926598), (37, 0.16653102450072765), (11, 0.1705236453562975), (45, 0.1768612340092659), (40, 0.17933722212910652), (2, 0.1805573683232069), (43, 0.18200979568064213), (10, 0.1837841086089611), (46, 0.18552648648619652), (47, 0.19479512609541416), (49, 0.19619202986359596), (4, 0.19644230045378208), (50, 0.2001819983124733), (48, 0.20254357159137726), (9, 0.21970535814762115), (51, 0.23495715856552124), (52, 0.25070288963615894), (17, 0.2627752795815468), (18, 0.3447713293135166), (36, 0.48194214701652527), (53, 0.6746527850627899)]
computing accuracy for after removing block 8 . block score: 0.14877080917358398
removed block 8 current accuracy 0.824 loss from initial  0.17600000000000005
since last training loss: 0.1724 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 44, with score 0.138917. All blocks and scores: [(44, 0.1389165110886097), (39, 0.1410908456891775), (7, 0.15140881575644016), (12, 0.1516984086483717), (41, 0.15659306570887566), (42, 0.1571640819311142), (37, 0.16320372931659222), (11, 0.16952593624591827), (40, 0.17205701023340225), (45, 0.176207285374403), (46, 0.1787210162729025), (43, 0.18004948273301125), (2, 0.1805573683232069), (10, 0.18603042140603065), (50, 0.18711625039577484), (49, 0.18903662636876106), (47, 0.18942215479910374), (48, 0.191195547580719), (4, 0.19644230045378208), (51, 0.22591874934732914), (9, 0.2376420460641384), (17, 0.24339081905782223), (52, 0.24716263264417648), (18, 0.32993701845407486), (36, 0.4647335410118103), (53, 0.6847400143742561)]
computing accuracy for after removing block 44 . block score: 0.1389165110886097
removed block 44 current accuracy 0.7776 loss from initial  0.22240000000000004
since last training loss: 0.2188 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 39, with score 0.141091. All blocks and scores: [(39, 0.1410908456891775), (7, 0.15140881575644016), (12, 0.1516984086483717), (41, 0.15659306570887566), (42, 0.1571640819311142), (37, 0.16320372931659222), (11, 0.16952593624591827), (40, 0.17205701023340225), (46, 0.1783405002206564), (43, 0.18004948273301125), (2, 0.1805573683232069), (45, 0.18314249068498611), (50, 0.18556546792387962), (10, 0.18603042140603065), (49, 0.18657474778592587), (47, 0.19038137793540955), (48, 0.193455271422863), (4, 0.19644230045378208), (51, 0.223851278424263), (9, 0.2376420460641384), (52, 0.24261513352394104), (17, 0.24339081905782223), (18, 0.32993701845407486), (36, 0.4647335410118103), (53, 0.709195502102375)]
computing accuracy for after removing block 39 . block score: 0.1410908456891775
removed block 39 current accuracy 0.7548 loss from initial  0.24519999999999997
since last training loss: 0.24159999999999993 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 7, with score 0.151409. All blocks and scores: [(7, 0.15140881575644016), (12, 0.1516984086483717), (42, 0.15670860931277275), (41, 0.15811357088387012), (37, 0.16320372931659222), (11, 0.16952593624591827), (46, 0.17379777692258358), (40, 0.17520307749509811), (43, 0.17726130038499832), (45, 0.17774102091789246), (2, 0.1805573683232069), (47, 0.18225418590009212), (50, 0.18288084119558334), (49, 0.18355974555015564), (10, 0.18603042140603065), (48, 0.18904575519263744), (4, 0.19644230045378208), (51, 0.22295471280813217), (9, 0.2376420460641384), (52, 0.24129264429211617), (17, 0.24339081905782223), (18, 0.32993701845407486), (36, 0.4647335410118103), (53, 0.7045118361711502)]
computing accuracy for after removing block 7 . block score: 0.15140881575644016
removed block 7 current accuracy 0.5672 loss from initial  0.43279999999999996
since last training loss: 0.4291999999999999 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 12, with score 0.147685. All blocks and scores: [(12, 0.147684745490551), (42, 0.15200939401984215), (41, 0.15724260918796062), (11, 0.1711923610419035), (46, 0.171448964625597), (47, 0.17169944569468498), (50, 0.17502498626708984), (40, 0.1804264411330223), (10, 0.1805048454552889), (2, 0.1805573683232069), (37, 0.1818394884467125), (45, 0.1832768302410841), (48, 0.1867368072271347), (43, 0.1885553915053606), (49, 0.19060286320745945), (4, 0.19644230045378208), (51, 0.2134707160294056), (17, 0.23174437694251537), (52, 0.23545628786087036), (9, 0.24452534690499306), (18, 0.31640036404132843), (36, 0.4739040844142437), (53, 0.6740517690777779)]
computing accuracy for after removing block 12 . block score: 0.147684745490551
removed block 12 current accuracy 0.4822 loss from initial  0.5178
since last training loss: 0.5142 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 42, with score 0.142050. All blocks and scores: [(42, 0.14204969443380833), (41, 0.1573495790362358), (40, 0.16566915810108185), (47, 0.16783066280186176), (50, 0.16860643215477467), (46, 0.17002642154693604), (11, 0.1711923610419035), (45, 0.17830931767821312), (10, 0.1805048454552889), (2, 0.1805573683232069), (48, 0.1819054763764143), (37, 0.1839525606483221), (43, 0.18539362214505672), (49, 0.1905959527939558), (4, 0.19644230045378208), (51, 0.20656855031847954), (52, 0.23270058631896973), (9, 0.24452534690499306), (17, 0.25399283319711685), (18, 0.30568069219589233), (36, 0.4774778485298157), (53, 0.6490399464964867)]
computing accuracy for after removing block 42 . block score: 0.14204969443380833
removed block 42 current accuracy 0.4418 loss from initial  0.5582
training start
training epoch 0 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.001]
training epoch 1 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 2 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best True lr [0.001]
training epoch 3 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 4 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 5 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 6 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 7 val accuracy 0.983 topk_dict {'top1': 0.983} is_best True lr [0.001]
training epoch 8 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 9 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 10 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 11 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 12 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 13 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best True lr [0.001]
training epoch 14 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 15 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 16 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 17 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 18 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 19 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 20 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 21 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 22 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 23 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 24 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 25 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 26 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 27 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 28 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 29 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 30 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 31 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 32 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 33 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 34 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 35 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 36 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 37 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 38 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 39 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 40 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 41 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 42 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 43 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 44 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 45 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best False lr [0.001]
training epoch 46 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best True lr [0.001]
training epoch 47 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 48 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
training epoch 49 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.988400)
finished training. finished 50 epochs. accuracy 0.9884 topk_dict {'top1': 0.9884}
start iteration 33
[activation mean]: block to remove picked: 37, with score 0.166869. All blocks and scores: [(37, 0.1668692659586668), (45, 0.18371916562318802), (2, 0.18384194374084473), (40, 0.18745917081832886), (41, 0.18879112973809242), (10, 0.18932827189564705), (46, 0.19000161439180374), (11, 0.19719235599040985), (43, 0.19787105917930603), (47, 0.20102441869676113), (48, 0.2075910996645689), (49, 0.2095834743231535), (9, 0.21388613060116768), (4, 0.2171362340450287), (50, 0.21823177114129066), (51, 0.23705867491662502), (17, 0.25989124923944473), (52, 0.26797115057706833), (18, 0.3722836375236511), (36, 0.47057583555579185), (53, 0.6605377793312073)]
computing accuracy for after removing block 37 . block score: 0.1668692659586668
removed block 37 current accuracy 0.9758 loss from initial  0.0242
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 45, with score 0.177101. All blocks and scores: [(45, 0.17710131034255028), (46, 0.18344874121248722), (2, 0.18384194374084473), (10, 0.18932827189564705), (41, 0.19117984920740128), (47, 0.19430899061262608), (43, 0.19486823305487633), (11, 0.19719235599040985), (40, 0.1977501567453146), (48, 0.1993042677640915), (49, 0.2023650575429201), (50, 0.21304410696029663), (9, 0.21388613060116768), (4, 0.2171362340450287), (51, 0.23195838928222656), (17, 0.25989124923944473), (52, 0.2648204639554024), (18, 0.3722836375236511), (36, 0.47057583555579185), (53, 0.6725084111094475)]
computing accuracy for after removing block 45 . block score: 0.17710131034255028
removed block 45 current accuracy 0.957 loss from initial  0.04300000000000004
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 46, with score 0.182974. All blocks and scores: [(46, 0.18297413364052773), (2, 0.18384194374084473), (10, 0.18932827189564705), (41, 0.19117984920740128), (47, 0.19261017814278603), (48, 0.19450602121651173), (43, 0.19486823305487633), (11, 0.19719235599040985), (49, 0.19748765602707863), (40, 0.1977501567453146), (50, 0.20665227994322777), (9, 0.21388613060116768), (4, 0.2171362340450287), (51, 0.2276578638702631), (52, 0.2552677243947983), (17, 0.25989124923944473), (18, 0.3722836375236511), (36, 0.47057583555579185), (53, 0.7353627979755402)]
computing accuracy for after removing block 46 . block score: 0.18297413364052773
removed block 46 current accuracy 0.9342 loss from initial  0.06579999999999997
since last training loss: 0.054199999999999915 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 2, with score 0.183842. All blocks and scores: [(2, 0.18384194374084473), (48, 0.18865383230149746), (10, 0.18932827189564705), (41, 0.19117984920740128), (47, 0.19356839172542095), (49, 0.19468777626752853), (43, 0.19486823305487633), (11, 0.19719235599040985), (40, 0.1977501567453146), (50, 0.20601855404675007), (9, 0.21388613060116768), (4, 0.2171362340450287), (51, 0.22855360805988312), (52, 0.24938470125198364), (17, 0.25989124923944473), (18, 0.3722836375236511), (36, 0.47057583555579185), (53, 0.804504044353962)]
computing accuracy for after removing block 2 . block score: 0.18384194374084473
removed block 2 current accuracy 0.8146 loss from initial  0.1854
since last training loss: 0.17379999999999995 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 41, with score 0.176994. All blocks and scores: [(41, 0.17699393443763256), (47, 0.17965137772262096), (11, 0.1857791393995285), (48, 0.1859018411487341), (10, 0.1860454250127077), (50, 0.19005459174513817), (43, 0.1980525478720665), (49, 0.20247654803097248), (40, 0.20738976448774338), (9, 0.22137426771223545), (51, 0.2276250757277012), (52, 0.23853549547493458), (4, 0.2390222456306219), (17, 0.26039037108421326), (18, 0.36491822451353073), (36, 0.4669881723821163), (53, 0.821315586566925)]
computing accuracy for after removing block 41 . block score: 0.17699393443763256
removed block 41 current accuracy 0.7486 loss from initial  0.25139999999999996
since last training loss: 0.2397999999999999 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 47, with score 0.179991. All blocks and scores: [(47, 0.17999080382287502), (48, 0.18045814707875252), (50, 0.18495037965476513), (11, 0.1857791393995285), (10, 0.1860454250127077), (49, 0.19599113054573536), (43, 0.20549839176237583), (40, 0.20738976448774338), (9, 0.22137426771223545), (51, 0.22593039087951183), (52, 0.2353616002947092), (4, 0.2390222456306219), (17, 0.26039037108421326), (18, 0.36491822451353073), (36, 0.4669881723821163), (53, 0.8567827418446541)]
computing accuracy for after removing block 47 . block score: 0.17999080382287502
removed block 47 current accuracy 0.6976 loss from initial  0.3024
since last training loss: 0.29079999999999995 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 48, with score 0.180790. All blocks and scores: [(48, 0.180790226906538), (50, 0.1833073329180479), (11, 0.1857791393995285), (10, 0.1860454250127077), (49, 0.19531933031976223), (43, 0.20549839176237583), (40, 0.20738976448774338), (9, 0.22137426771223545), (51, 0.22612428478896618), (52, 0.22900360077619553), (4, 0.2390222456306219), (17, 0.26039037108421326), (18, 0.36491822451353073), (36, 0.4669881723821163), (53, 0.979607105255127)]
computing accuracy for after removing block 48 . block score: 0.180790226906538
removed block 48 current accuracy 0.6112 loss from initial  0.38880000000000003
since last training loss: 0.3772 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 50, with score 0.182645. All blocks and scores: [(50, 0.18264508247375488), (11, 0.1857791393995285), (10, 0.1860454250127077), (49, 0.18750044703483582), (43, 0.20549839176237583), (40, 0.20738976448774338), (9, 0.22137426771223545), (52, 0.2264460287988186), (51, 0.2292715348303318), (4, 0.2390222456306219), (17, 0.26039037108421326), (18, 0.36491822451353073), (36, 0.4669881723821163), (53, 1.1346973925828934)]
computing accuracy for after removing block 50 . block score: 0.18264508247375488
removed block 50 current accuracy 0.5484 loss from initial  0.4516
since last training loss: 0.43999999999999995 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 11, with score 0.185779. All blocks and scores: [(11, 0.1857791393995285), (10, 0.1860454250127077), (49, 0.18750044703483582), (43, 0.20549839176237583), (40, 0.20738976448774338), (9, 0.22137426771223545), (51, 0.22498611360788345), (52, 0.22739076241850853), (4, 0.2390222456306219), (17, 0.26039037108421326), (18, 0.36491822451353073), (36, 0.4669881723821163), (53, 1.262355476617813)]
computing accuracy for after removing block 11 . block score: 0.1857791393995285
removed block 11 current accuracy 0.3956 loss from initial  0.6044
since last training loss: 0.5928 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 49, with score 0.167735. All blocks and scores: [(49, 0.16773458383977413), (43, 0.1806042566895485), (10, 0.1860454250127077), (40, 0.19556585885584354), (51, 0.2124916836619377), (9, 0.22137426771223545), (52, 0.22350834123790264), (4, 0.2390222456306219), (17, 0.24370959401130676), (18, 0.3294621668756008), (36, 0.4500970207154751), (53, 1.2902334183454514)]
computing accuracy for after removing block 49 . block score: 0.16773458383977413
removed block 49 current accuracy 0.3574 loss from initial  0.6426000000000001
since last training loss: 0.631 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 43, with score 0.180604. All blocks and scores: [(43, 0.1806042566895485), (10, 0.1860454250127077), (40, 0.19556585885584354), (51, 0.2070653736591339), (9, 0.22137426771223545), (52, 0.2261073011904955), (4, 0.2390222456306219), (17, 0.24370959401130676), (18, 0.3294621668756008), (36, 0.4500970207154751), (53, 1.397424653172493)]
computing accuracy for after removing block 43 . block score: 0.1806042566895485
removed block 43 current accuracy 0.3444 loss from initial  0.6556
since last training loss: 0.6439999999999999 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 10, with score 0.186045. All blocks and scores: [(10, 0.1860454250127077), (40, 0.19556585885584354), (51, 0.21038909628987312), (9, 0.22137426771223545), (52, 0.22950402833521366), (4, 0.2390222456306219), (17, 0.24370959401130676), (18, 0.3294621668756008), (36, 0.4500970207154751), (53, 1.448404237627983)]
computing accuracy for after removing block 10 . block score: 0.1860454250127077
removed block 10 current accuracy 0.268 loss from initial  0.732
training start
training epoch 0 val accuracy 0.8346 topk_dict {'top1': 0.8346} is_best True lr [0.001]
training epoch 1 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.001]
training epoch 2 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.001]
training epoch 3 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 4 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.001]
training epoch 5 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.001]
training epoch 6 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 8 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 9 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 10 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 11 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 12 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.001]
training epoch 13 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 14 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 15 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.001]
training epoch 16 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 17 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 18 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 19 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 20 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 21 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 22 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 23 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 24 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 25 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 26 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 28 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 29 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 30 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 31 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 32 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 33 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 34 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 35 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 37 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 38 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 39 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 41 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 42 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 43 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 44 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 45 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 46 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 47 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.932200)
finished training. finished 50 epochs. accuracy 0.9322 topk_dict {'top1': 0.9322}
