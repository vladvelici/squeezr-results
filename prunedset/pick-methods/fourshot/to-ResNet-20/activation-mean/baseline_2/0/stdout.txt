start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068702. All blocks and scores: [(26, 0.06870234198868275), (27, 0.0741223581135273), (31, 0.07421684544533491), (35, 0.07685474585741758), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08143280725926161), (24, 0.08224374894052744), (34, 0.08227442763745785), (33, 0.08310604561120272), (23, 0.08412310108542442), (32, 0.08623841684311628), (28, 0.0872054873034358), (22, 0.08930969890207052), (30, 0.09091433975845575), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13720723055303097), (39, 0.13744624331593513), (37, 0.14209549687802792), (38, 0.14290856197476387), (6, 0.14786463603377342), (41, 0.1508424561470747), (42, 0.15258264541625977), (4, 0.15538891777396202), (43, 0.15601677261292934), (44, 0.15883748047053814), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16798720695078373), (2, 0.18457405641674995), (46, 0.18493103049695492), (1, 0.20192440785467625), (47, 0.2080467976629734), (48, 0.21010252088308334), (49, 0.224680308252573), (50, 0.23862904869019985), (51, 0.25924162939190865), (52, 0.28526581451296806), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4550497271120548), (53, 0.6487655118107796)]
computing accuracy for after removing block 26 . block score: 0.06870234198868275
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074250. All blocks and scores: [(31, 0.07425017189234495), (27, 0.07438226789236069), (35, 0.0760756740346551), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08178351167589426), (34, 0.08181511238217354), (24, 0.08224374894052744), (33, 0.08314474113285542), (23, 0.08412310108542442), (32, 0.08550294954329729), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13959151320159435), (39, 0.1399664543569088), (37, 0.14363272115588188), (38, 0.1437524501234293), (6, 0.14786463603377342), (41, 0.15150794386863708), (42, 0.15349512174725533), (4, 0.15538891777396202), (43, 0.15715143270790577), (13, 0.1590876206755638), (44, 0.15911891870200634), (3, 0.16731475666165352), (45, 0.16931429505348206), (2, 0.18457405641674995), (46, 0.186824394389987), (1, 0.20192440785467625), (47, 0.20976067893207073), (48, 0.2109022866934538), (49, 0.2249483335763216), (50, 0.23839633911848068), (51, 0.2592626102268696), (52, 0.2852507643401623), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4592660255730152), (53, 0.6468537002801895)]
computing accuracy for after removing block 31 . block score: 0.07425017189234495
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074382. All blocks and scores: [(27, 0.07438226789236069), (35, 0.07612952496856451), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (34, 0.08106645382940769), (29, 0.08178351167589426), (24, 0.08224374894052744), (33, 0.08338531665503979), (23, 0.08412310108542442), (32, 0.08539257477968931), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14128642156720161), (40, 0.14169061370193958), (39, 0.14174902439117432), (37, 0.14439108967781067), (6, 0.14786463603377342), (41, 0.15143204852938652), (42, 0.15228785201907158), (4, 0.15538891777396202), (43, 0.15636706165969372), (44, 0.15833302028477192), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16788306273519993), (2, 0.18457405641674995), (46, 0.1864120475947857), (1, 0.20192440785467625), (47, 0.20843712612986565), (48, 0.21100311167538166), (49, 0.22473796643316746), (50, 0.23855118453502655), (51, 0.2591783180832863), (52, 0.28372708708047867), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.46568959951400757), (53, 0.6510000601410866)]
computing accuracy for after removing block 27 . block score: 0.07438226789236069
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075854. All blocks and scores: [(35, 0.07585428189486265), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14026966504752636), (39, 0.14322753064334393), (40, 0.14488770440220833), (37, 0.14594712853431702), (6, 0.14786463603377342), (41, 0.15189490653574467), (42, 0.15252277441322803), (4, 0.15538891777396202), (43, 0.15715407766401768), (44, 0.15864605642855167), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.1683814972639084), (2, 0.18457405641674995), (46, 0.18689549528062344), (1, 0.20192440785467625), (47, 0.20870989188551903), (48, 0.21123779565095901), (49, 0.22443696111440659), (50, 0.23874318413436413), (51, 0.2584992125630379), (52, 0.2828393988311291), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4712146706879139), (53, 0.6518600136041641)]
computing accuracy for after removing block 35 . block score: 0.07585428189486265
removed block 35 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076914. All blocks and scores: [(20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1385685559362173), (40, 0.13947991654276848), (39, 0.14093938656151295), (37, 0.14259942434728146), (6, 0.14786463603377342), (41, 0.15029864758253098), (42, 0.15072360262274742), (43, 0.15525723062455654), (44, 0.1552812773734331), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.16552621126174927), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.1869147438555956), (1, 0.20192440785467625), (48, 0.20716596953570843), (47, 0.20739650540053844), (49, 0.22507839649915695), (50, 0.23703056946396828), (51, 0.25911351665854454), (52, 0.28219735622406006), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.47133130580186844), (53, 0.6564537882804871)]
computing accuracy for after removing block 20 . block score: 0.07691387087106705
removed block 20 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079448. All blocks and scores: [(17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08003473933786154), (29, 0.08079283125698566), (21, 0.08103854302316904), (25, 0.08157523907721043), (24, 0.0828929403796792), (33, 0.08348109386861324), (23, 0.08391222264617682), (32, 0.0845849085599184), (28, 0.08620174136012793), (30, 0.088497344404459), (22, 0.09044258669018745), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13876904174685478), (40, 0.14043930359184742), (39, 0.14079759642481804), (37, 0.1433244775980711), (6, 0.14786463603377342), (41, 0.15065929107367992), (42, 0.15136869624257088), (4, 0.15538891777396202), (44, 0.1556632611900568), (43, 0.15633762441575527), (13, 0.1590876206755638), (45, 0.1662806160748005), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18815029971301556), (1, 0.20192440785467625), (48, 0.20721778832376003), (47, 0.208082502707839), (49, 0.22565172612667084), (50, 0.23704500310122967), (51, 0.2587750032544136), (52, 0.28254886716604233), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4735274948179722), (53, 0.6537546589970589)]
computing accuracy for after removing block 17 . block score: 0.07944803778082132
removed block 17 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.077955. All blocks and scores: [(21, 0.07795533165335655), (34, 0.07894970290362835), (29, 0.0790198752656579), (25, 0.07908098585903645), (16, 0.08003389276564121), (33, 0.08208741899579763), (24, 0.08280743844807148), (23, 0.08313068188726902), (32, 0.08349784929305315), (28, 0.08599762804806232), (30, 0.08654309343546629), (22, 0.09004937391728163), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13761902786791325), (37, 0.14218291267752647), (39, 0.14250223897397518), (40, 0.1427330169826746), (6, 0.14786463603377342), (42, 0.149957912042737), (41, 0.15121997334063053), (4, 0.15538891777396202), (44, 0.15583417192101479), (43, 0.1559469159692526), (13, 0.1590876206755638), (45, 0.16489200666546822), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18951294012367725), (1, 0.20192440785467625), (48, 0.20613021031022072), (47, 0.20653356611728668), (49, 0.2261425293982029), (50, 0.23595429211854935), (51, 0.2574720084667206), (52, 0.2808535546064377), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.47553205117583275), (53, 0.6502362936735153)]
computing accuracy for after removing block 21 . block score: 0.07795533165335655
removed block 21 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.077982. All blocks and scores: [(29, 0.07798169739544392), (25, 0.07838128041476011), (34, 0.07839732337743044), (16, 0.08003389276564121), (33, 0.08119457680732012), (23, 0.08126077149063349), (24, 0.0816669063642621), (32, 0.0824327003210783), (28, 0.08386608771979809), (30, 0.0852785985916853), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13711080700159073), (37, 0.14175310172140598), (39, 0.14240100793540478), (40, 0.14322563633322716), (6, 0.14786463603377342), (42, 0.15017673559486866), (41, 0.1524363812059164), (44, 0.1552524920552969), (4, 0.15538891777396202), (43, 0.15651666559278965), (13, 0.1590876206755638), (45, 0.1644004713743925), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.19123134016990662), (1, 0.20192440785467625), (48, 0.20559575967490673), (47, 0.2066254075616598), (49, 0.2266144324094057), (50, 0.23550251685082912), (51, 0.2582874819636345), (52, 0.2810910604894161), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.4777962565422058), (53, 0.651190422475338)]
computing accuracy for after removing block 29 . block score: 0.07798169739544392
removed block 29 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 34, with score 0.078179. All blocks and scores: [(34, 0.07817933894693851), (25, 0.07838128041476011), (16, 0.08003389276564121), (23, 0.08126077149063349), (24, 0.0816669063642621), (33, 0.08192401938140392), (32, 0.08295448962599039), (28, 0.08386608771979809), (30, 0.08506463654339314), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1336296908557415), (37, 0.14201423898339272), (39, 0.14242823980748653), (40, 0.1438832189887762), (6, 0.14786463603377342), (42, 0.1480300221592188), (41, 0.15086989849805832), (44, 0.15249392949044704), (43, 0.15497619286179543), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.1628444753587246), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.19056031480431557), (1, 0.20192440785467625), (48, 0.20341675728559494), (47, 0.20561709441244602), (49, 0.2250166404992342), (50, 0.23460135981440544), (51, 0.25660766288638115), (52, 0.27802200987935066), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.482606153935194), (53, 0.6564268171787262)]
computing accuracy for after removing block 34 . block score: 0.07817933894693851
removed block 34 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.078381. All blocks and scores: [(25, 0.07838128041476011), (16, 0.08003389276564121), (23, 0.08126077149063349), (24, 0.0816669063642621), (33, 0.08192401938140392), (32, 0.08295448962599039), (28, 0.08386608771979809), (30, 0.08506463654339314), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (38, 0.13075140304863453), (12, 0.13088013418018818), (5, 0.1332902405411005), (37, 0.14148205146193504), (40, 0.14237396977841854), (39, 0.14330174028873444), (6, 0.14786463603377342), (42, 0.14919706992805004), (44, 0.15018645860254765), (41, 0.15130622126162052), (43, 0.152807941660285), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.16038896702229977), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18873972073197365), (48, 0.20094766840338707), (1, 0.20192440785467625), (47, 0.20465246215462685), (49, 0.22550316341221333), (50, 0.23279774375259876), (51, 0.2562355659902096), (52, 0.27564891055226326), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.49000105261802673), (53, 0.6627136692404747)]
computing accuracy for after removing block 25 . block score: 0.07838128041476011
removed block 25 current accuracy 0.986 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 16, with score 0.080034. All blocks and scores: [(16, 0.08003389276564121), (23, 0.08126077149063349), (24, 0.0816669063642621), (33, 0.0826033903285861), (32, 0.0829209377989173), (28, 0.08351065963506699), (30, 0.08443948440253735), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (38, 0.13017247430980206), (12, 0.13088013418018818), (5, 0.1332902405411005), (37, 0.14174464531242847), (40, 0.14347879774868488), (39, 0.1464582122862339), (42, 0.14688407815992832), (6, 0.14786463603377342), (44, 0.15011774748563766), (41, 0.15132753737270832), (43, 0.15172603726387024), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.15990902855992317), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18828969076275826), (48, 0.1994687132537365), (1, 0.20192440785467625), (47, 0.20382625423371792), (49, 0.22474531829357147), (50, 0.23089139722287655), (51, 0.25529883429408073), (52, 0.272567480802536), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.494920514523983), (53, 0.6618703752756119)]
computing accuracy for after removing block 16 . block score: 0.08003389276564121
removed block 16 current accuracy 0.9822 loss from initial  0.017800000000000038
training start
training epoch 0 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 1 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 2 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 3 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 4 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 5 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 8 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 11
[activation mean]: block to remove picked: 33, with score 0.085239. All blocks and scores: [(33, 0.08523857034742832), (23, 0.08894319925457239), (32, 0.08927036076784134), (24, 0.09143818356096745), (28, 0.0916378777474165), (14, 0.09382538590580225), (30, 0.09596517495810986), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (10, 0.12569398619234562), (12, 0.13041122257709503), (5, 0.1320917047560215), (40, 0.13718897104263306), (39, 0.1372248027473688), (37, 0.14106685668230057), (38, 0.14232907071709633), (41, 0.14817259646952152), (6, 0.14843597635626793), (42, 0.15036731213331223), (43, 0.15409403294324875), (4, 0.15608461014926434), (44, 0.15735245309770107), (13, 0.16143040359020233), (45, 0.16595164500176907), (3, 0.16706296056509018), (46, 0.1835674624890089), (2, 0.1836961731314659), (1, 0.2010724563151598), (47, 0.20571624860167503), (48, 0.20965486951172352), (49, 0.22381671890616417), (50, 0.23871163092553616), (51, 0.2609620988368988), (52, 0.2854311615228653), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4492286965250969), (53, 0.6452778354287148)]
computing accuracy for after removing block 33 . block score: 0.08523857034742832
removed block 33 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.088943. All blocks and scores: [(23, 0.08894319925457239), (32, 0.08927036076784134), (24, 0.09143818356096745), (28, 0.0916378777474165), (14, 0.09382538590580225), (30, 0.09596517495810986), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (10, 0.12569398619234562), (12, 0.13041122257709503), (39, 0.131549172103405), (5, 0.1320917047560215), (40, 0.13218684867024422), (38, 0.13360628858208656), (37, 0.13509814999997616), (41, 0.14319612830877304), (42, 0.14565902017056942), (6, 0.14843597635626793), (43, 0.1487287487834692), (44, 0.15124885737895966), (4, 0.15608461014926434), (45, 0.1588171422481537), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17886854149401188), (2, 0.1836961731314659), (47, 0.1986236907541752), (1, 0.2010724563151598), (48, 0.20226961933076382), (49, 0.2215793263167143), (50, 0.23396900296211243), (51, 0.2578512839972973), (52, 0.2792186364531517), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4442698769271374), (53, 0.657546654343605)]
computing accuracy for after removing block 23 . block score: 0.08894319925457239
removed block 23 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.087767. All blocks and scores: [(32, 0.08776659891009331), (24, 0.08982184249907732), (28, 0.09028489422053099), (14, 0.09382538590580225), (30, 0.09447035007178783), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (10, 0.12569398619234562), (12, 0.13041122257709503), (5, 0.1320917047560215), (38, 0.13225574232637882), (40, 0.13262020237743855), (39, 0.13386384770274162), (37, 0.13460569083690643), (41, 0.14319444075226784), (42, 0.14415565691888332), (43, 0.14711802825331688), (6, 0.14843597635626793), (44, 0.14945419877767563), (4, 0.15608461014926434), (45, 0.15662100911140442), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17898943834006786), (2, 0.1836961731314659), (47, 0.1978775318711996), (48, 0.20066236145794392), (1, 0.2010724563151598), (49, 0.22142993845045567), (50, 0.2325858324766159), (51, 0.25852226838469505), (52, 0.2789298892021179), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4460880719125271), (53, 0.6582202017307281)]
computing accuracy for after removing block 32 . block score: 0.08776659891009331
removed block 32 current accuracy 0.9946 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.089822. All blocks and scores: [(24, 0.08982184249907732), (28, 0.09028489422053099), (14, 0.09382538590580225), (30, 0.09447035007178783), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (10, 0.12569398619234562), (38, 0.12688659504055977), (12, 0.13041122257709503), (40, 0.1318400427699089), (5, 0.1320917047560215), (37, 0.13231045752763748), (39, 0.13312904722988605), (41, 0.14085077494382858), (42, 0.14178176410496235), (43, 0.1438960898667574), (44, 0.14601305685937405), (6, 0.14843597635626793), (45, 0.1534929946064949), (4, 0.15608461014926434), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17782252095639706), (2, 0.1836961731314659), (47, 0.19536704756319523), (48, 0.19702432118356228), (1, 0.2010724563151598), (49, 0.22067608498036861), (50, 0.2296967152506113), (51, 0.2571737617254257), (52, 0.27470334246754646), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.45098936185240746), (53, 0.6650476902723312)]
computing accuracy for after removing block 24 . block score: 0.08982184249907732
removed block 24 current accuracy 0.9882 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 28, with score 0.088975. All blocks and scores: [(28, 0.08897511661052704), (30, 0.09192423056811094), (14, 0.09382538590580225), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (38, 0.12437016516923904), (10, 0.12569398619234562), (12, 0.13041122257709503), (37, 0.13199789635837078), (5, 0.1320917047560215), (40, 0.13278544694185257), (39, 0.13577798008918762), (41, 0.14047521352767944), (42, 0.14152066968381405), (43, 0.14417174085974693), (44, 0.14595982804894447), (6, 0.14843597635626793), (45, 0.15311766974627972), (4, 0.15608461014926434), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17835448682308197), (2, 0.1836961731314659), (47, 0.19467725232243538), (48, 0.19576316326856613), (1, 0.2010724563151598), (49, 0.2209044173359871), (50, 0.22808150947093964), (51, 0.2569732554256916), (52, 0.2733997628092766), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4567655697464943), (53, 0.664689265191555)]
computing accuracy for after removing block 28 . block score: 0.08897511661052704
removed block 28 current accuracy 0.9738 loss from initial  0.0262
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 30, with score 0.089926. All blocks and scores: [(30, 0.08992628660053015), (14, 0.09382538590580225), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (7, 0.1169786574319005), (15, 0.11778328102082014), (38, 0.11939956992864609), (10, 0.12569398619234562), (12, 0.13041122257709503), (37, 0.13181866519153118), (5, 0.1320917047560215), (40, 0.13608846068382263), (42, 0.1391605343669653), (39, 0.13961881957948208), (41, 0.13965469412505627), (43, 0.14360977336764336), (44, 0.14400510489940643), (6, 0.14843597635626793), (45, 0.1530339289456606), (4, 0.15608461014926434), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17828763462603092), (2, 0.1836961731314659), (48, 0.19362949766218662), (47, 0.19404005259275436), (1, 0.2010724563151598), (49, 0.2199233341962099), (50, 0.2269117534160614), (51, 0.2569092847406864), (52, 0.27032047137618065), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4659697972238064), (53, 0.6711637899279594)]
computing accuracy for after removing block 30 . block score: 0.08992628660053015
removed block 30 current accuracy 0.9416 loss from initial  0.05840000000000001
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.093825. All blocks and scores: [(14, 0.09382538590580225), (22, 0.09722528140991926), (9, 0.09837417304515839), (11, 0.10241569392383099), (19, 0.10475466679781675), (8, 0.10622985567897558), (38, 0.11607179511338472), (7, 0.1169786574319005), (15, 0.11778328102082014), (10, 0.12569398619234562), (12, 0.13041122257709503), (5, 0.1320917047560215), (37, 0.13246284425258636), (42, 0.1360886562615633), (41, 0.13838028721511364), (43, 0.1403532512485981), (40, 0.14070197008550167), (44, 0.14126359671354294), (39, 0.145564628764987), (6, 0.14843597635626793), (45, 0.15095822140574455), (4, 0.15608461014926434), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.1782380659133196), (2, 0.1836961731314659), (48, 0.19276200234889984), (47, 0.19292020238935947), (1, 0.2010724563151598), (49, 0.21910802088677883), (50, 0.22599720768630505), (51, 0.2565958574414253), (52, 0.2644931562244892), (0, 0.31303343549370766), (18, 0.4249267317354679), (36, 0.4805152378976345), (53, 0.6800461560487747)]
computing accuracy for after removing block 14 . block score: 0.09382538590580225
removed block 14 current accuracy 0.925 loss from initial  0.07499999999999996
since last training loss: 0.07499999999999996 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 22, with score 0.097092. All blocks and scores: [(22, 0.09709224011749029), (9, 0.09837417304515839), (19, 0.10207086522132158), (11, 0.10241569392383099), (8, 0.10622985567897558), (38, 0.11503241490572691), (7, 0.1169786574319005), (15, 0.1222951915115118), (10, 0.12569398619234562), (12, 0.13041122257709503), (5, 0.1320917047560215), (37, 0.13505668938159943), (42, 0.1358520481735468), (43, 0.13885275647044182), (41, 0.13938786461949348), (44, 0.1417400725185871), (6, 0.14843597635626793), (40, 0.14870323799550533), (45, 0.15036498755216599), (39, 0.15410984866321087), (4, 0.15608461014926434), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17853937484323978), (2, 0.1836961731314659), (48, 0.189749576151371), (47, 0.19102794490754604), (1, 0.2010724563151598), (49, 0.2187582291662693), (50, 0.22320145554840565), (51, 0.25446124374866486), (52, 0.2589137591421604), (0, 0.31303343549370766), (18, 0.43245138600468636), (36, 0.4876460023224354), (53, 0.6768417805433273)]
computing accuracy for after removing block 22 . block score: 0.09709224011749029
removed block 22 current accuracy 0.8876 loss from initial  0.11240000000000006
since last training loss: 0.11240000000000006 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 9, with score 0.098374. All blocks and scores: [(9, 0.09837417304515839), (19, 0.10207086522132158), (11, 0.10241569392383099), (8, 0.10622985567897558), (38, 0.11435720138251781), (7, 0.1169786574319005), (15, 0.1222951915115118), (10, 0.12569398619234562), (12, 0.13041122257709503), (5, 0.1320917047560215), (42, 0.13404463417828083), (37, 0.1344814896583557), (43, 0.13592211715877056), (44, 0.13873973488807678), (41, 0.13984143361449242), (45, 0.14768689312040806), (6, 0.14843597635626793), (40, 0.15003382973372936), (4, 0.15608461014926434), (39, 0.15743131563067436), (13, 0.16143040359020233), (3, 0.16706296056509018), (46, 0.17737052589654922), (2, 0.1836961731314659), (47, 0.19002343714237213), (48, 0.19015880674123764), (1, 0.2010724563151598), (49, 0.21816646307706833), (50, 0.2197167668491602), (51, 0.2539234198629856), (52, 0.2549992874264717), (0, 0.31303343549370766), (18, 0.43245138600468636), (36, 0.4937737286090851), (53, 0.6863463446497917)]
computing accuracy for after removing block 9 . block score: 0.09837417304515839
removed block 9 current accuracy 0.875 loss from initial  0.125
since last training loss: 0.125 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 19, with score 0.101954. All blocks and scores: [(19, 0.10195375233888626), (11, 0.10255094710737467), (8, 0.10622985567897558), (38, 0.11330906301736832), (7, 0.1169786574319005), (15, 0.11922008264809847), (10, 0.12166023347526789), (12, 0.12750923074781895), (37, 0.13123231753706932), (5, 0.1320917047560215), (43, 0.1336193084716797), (42, 0.13419326394796371), (44, 0.13812697492539883), (41, 0.14193042181432247), (45, 0.1458316184580326), (6, 0.14843597635626793), (40, 0.14875097759068012), (13, 0.1525725107640028), (39, 0.15377175621688366), (4, 0.15608461014926434), (3, 0.16706296056509018), (46, 0.17678468115627766), (2, 0.1836961731314659), (47, 0.18554441072046757), (48, 0.18805036507546902), (1, 0.2010724563151598), (49, 0.2172130774706602), (50, 0.21909545734524727), (51, 0.2523323930799961), (52, 0.25243303552269936), (0, 0.31303343549370766), (18, 0.4264937601983547), (36, 0.49234069138765335), (53, 0.6857329905033112)]
computing accuracy for after removing block 19 . block score: 0.10195375233888626
removed block 19 current accuracy 0.8474 loss from initial  0.15259999999999996
since last training loss: 0.15259999999999996 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 11, with score 0.102551. All blocks and scores: [(11, 0.10255094710737467), (8, 0.10622985567897558), (38, 0.1143978787586093), (7, 0.1169786574319005), (15, 0.11922008264809847), (10, 0.12166023347526789), (12, 0.12750923074781895), (5, 0.1320917047560215), (37, 0.13263203762471676), (43, 0.13567228242754936), (42, 0.13778723403811455), (44, 0.13977446034550667), (41, 0.14333121292293072), (45, 0.14834490418434143), (6, 0.14843597635626793), (13, 0.1525725107640028), (40, 0.15557757578790188), (4, 0.15608461014926434), (39, 0.156612578779459), (3, 0.16706296056509018), (46, 0.17813812382519245), (2, 0.1836961731314659), (47, 0.1860981583595276), (48, 0.19011958315968513), (1, 0.2010724563151598), (50, 0.21819278225302696), (49, 0.2191392406821251), (52, 0.2498865257948637), (51, 0.2513829153031111), (0, 0.31303343549370766), (18, 0.4264937601983547), (36, 0.5084928870201111), (53, 0.689167208969593)]
computing accuracy for after removing block 11 . block score: 0.10255094710737467
removed block 11 current accuracy 0.8188 loss from initial  0.18120000000000003
training start
training epoch 0 val accuracy 0.987 topk_dict {'top1': 0.987} is_best True lr [0.001]
training epoch 1 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 2 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 3 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 4 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 5 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 6 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 7 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 8 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 9 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 10 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 11 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 12 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 13 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 14 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 15 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 17 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 18 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 19 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 21 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 22 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 23 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 24 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 25 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 26 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 27 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 28 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 29 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 30 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 31 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 32 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 33 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 34 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 35 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 37 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 38 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 39 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 41 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 42 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 43 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 44 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 45 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 46 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 47 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 48 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 49 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 22
[activation mean]: block to remove picked: 8, with score 0.111268. All blocks and scores: [(8, 0.1112675303593278), (7, 0.12290151137858629), (5, 0.13201289623975754), (10, 0.1322727259248495), (15, 0.13493750244379044), (12, 0.1367842461913824), (40, 0.13746800273656845), (39, 0.1374969445168972), (37, 0.1422884836792946), (38, 0.142462695017457), (41, 0.14647958613932133), (42, 0.14918792247772217), (6, 0.1502511128783226), (43, 0.1516489740461111), (44, 0.15531150065362453), (4, 0.1599090788513422), (3, 0.16217358224093914), (45, 0.1654007900506258), (13, 0.17311039194464684), (2, 0.17799417860805988), (46, 0.18040130101144314), (1, 0.19204072654247284), (47, 0.20264864899218082), (48, 0.20802699029445648), (49, 0.22199328429996967), (50, 0.23591599240899086), (51, 0.25757741555571556), (52, 0.2807358615100384), (0, 0.2977319657802582), (18, 0.4318930432200432), (36, 0.4511539451777935), (53, 0.65391406416893)]
computing accuracy for after removing block 8 . block score: 0.1112675303593278
removed block 8 current accuracy 0.9928 loss from initial  0.007199999999999984
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 7, with score 0.122902. All blocks and scores: [(7, 0.12290151137858629), (5, 0.13201289623975754), (15, 0.1342974789440632), (10, 0.13444404304027557), (12, 0.13542872667312622), (40, 0.13609438203275204), (39, 0.1362678650766611), (37, 0.14116353169083595), (42, 0.1463067326694727), (41, 0.1469247303903103), (38, 0.14784745313227177), (6, 0.1502511128783226), (43, 0.15273267775774002), (44, 0.15301121212542057), (4, 0.1599090788513422), (3, 0.16217358224093914), (45, 0.16397352144122124), (13, 0.17610693909227848), (2, 0.17799417860805988), (46, 0.18093961291015148), (1, 0.19204072654247284), (47, 0.2037329152226448), (48, 0.2069749440997839), (49, 0.2219790406525135), (50, 0.23360999301075935), (51, 0.2557964622974396), (52, 0.2796594128012657), (0, 0.2977319657802582), (18, 0.4290994927287102), (36, 0.4510689899325371), (53, 0.6483632624149323)]
computing accuracy for after removing block 7 . block score: 0.12290151137858629
removed block 7 current accuracy 0.9876 loss from initial  0.012399999999999967
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.128306. All blocks and scores: [(40, 0.12830624170601368), (15, 0.13097365386784077), (39, 0.1315911766141653), (10, 0.1317787915468216), (5, 0.13201289623975754), (12, 0.1347712967544794), (37, 0.13533557020127773), (42, 0.1428302451968193), (41, 0.1463774237781763), (38, 0.1484485063701868), (43, 0.14897998981177807), (6, 0.1502511128783226), (44, 0.1504818107932806), (4, 0.1599090788513422), (3, 0.16217358224093914), (45, 0.16224813647568226), (13, 0.17596858739852905), (46, 0.17681920155882835), (2, 0.17799417860805988), (1, 0.19204072654247284), (48, 0.20133810117840767), (47, 0.20159791596233845), (49, 0.2184992041438818), (50, 0.226826511323452), (51, 0.2516448013484478), (52, 0.2747892923653126), (0, 0.2977319657802582), (18, 0.4200100675225258), (36, 0.4431629367172718), (53, 0.6464186459779739)]
computing accuracy for after removing block 40 . block score: 0.12830624170601368
removed block 40 current accuracy 0.9828 loss from initial  0.017199999999999993
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 15, with score 0.130974. All blocks and scores: [(15, 0.13097365386784077), (39, 0.1315911766141653), (10, 0.1317787915468216), (5, 0.13201289623975754), (12, 0.1347712967544794), (37, 0.13533557020127773), (42, 0.14317878521978855), (41, 0.14821388013660908), (38, 0.1484485063701868), (43, 0.14858992584049702), (6, 0.1502511128783226), (44, 0.15070470422506332), (4, 0.1599090788513422), (45, 0.1611517034471035), (3, 0.16217358224093914), (13, 0.17596858739852905), (46, 0.1766630858182907), (2, 0.17799417860805988), (1, 0.19204072654247284), (48, 0.1991733219474554), (47, 0.19922862760722637), (49, 0.21761240996420383), (50, 0.22625159285962582), (51, 0.2518394701182842), (52, 0.27277306467294693), (0, 0.2977319657802582), (18, 0.4200100675225258), (36, 0.4431629367172718), (53, 0.6547277197241783)]
computing accuracy for after removing block 15 . block score: 0.13097365386784077
removed block 15 current accuracy 0.9636 loss from initial  0.03639999999999999
since last training loss: 0.03279999999999994 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 37, with score 0.130828. All blocks and scores: [(37, 0.13082822784781456), (10, 0.1317787915468216), (5, 0.13201289623975754), (39, 0.13351125828921795), (12, 0.1347712967544794), (42, 0.14136294648051262), (38, 0.14680425450205803), (43, 0.148130152374506), (41, 0.149503942579031), (6, 0.1502511128783226), (44, 0.15044457092881203), (45, 0.1578877717256546), (4, 0.1599090788513422), (3, 0.16217358224093914), (13, 0.17596858739852905), (46, 0.17770986258983612), (2, 0.17799417860805988), (1, 0.19204072654247284), (47, 0.19441622868180275), (48, 0.19499165192246437), (49, 0.21685202047228813), (50, 0.2218260020017624), (51, 0.2473344411700964), (52, 0.2658581770956516), (0, 0.2977319657802582), (18, 0.4290207736194134), (36, 0.4493257999420166), (53, 0.6530594453215599)]
computing accuracy for after removing block 37 . block score: 0.13082822784781456
removed block 37 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.04619999999999991 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 10, with score 0.131779. All blocks and scores: [(10, 0.1317787915468216), (5, 0.13201289623975754), (39, 0.13471391797065735), (12, 0.1347712967544794), (42, 0.14008905552327633), (43, 0.14587979204952717), (44, 0.14689691364765167), (41, 0.14740204252302647), (6, 0.1502511128783226), (38, 0.15210054442286491), (45, 0.15468895807862282), (4, 0.1599090788513422), (3, 0.16217358224093914), (46, 0.17487248219549656), (13, 0.17596858739852905), (2, 0.17799417860805988), (48, 0.18972928076982498), (47, 0.19001857936382294), (1, 0.19204072654247284), (49, 0.21211966313421726), (50, 0.21703443489968777), (51, 0.2417109403759241), (52, 0.2584215812385082), (0, 0.2977319657802582), (18, 0.4290207736194134), (36, 0.4493257999420166), (53, 0.6618458777666092)]
computing accuracy for after removing block 10 . block score: 0.1317787915468216
removed block 10 current accuracy 0.8976 loss from initial  0.10240000000000005
since last training loss: 0.0988 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.128525. All blocks and scores: [(39, 0.1285247653722763), (5, 0.13201289623975754), (42, 0.13339883089065552), (41, 0.13757392391562462), (12, 0.13970783352851868), (44, 0.1444941759109497), (43, 0.14876791648566723), (6, 0.1502511128783226), (45, 0.15248540975153446), (38, 0.1542795766144991), (4, 0.1599090788513422), (3, 0.16217358224093914), (2, 0.17799417860805988), (46, 0.17959853447973728), (13, 0.1849492248147726), (47, 0.18571574613451958), (48, 0.18579215556383133), (1, 0.19204072654247284), (49, 0.2128457110375166), (50, 0.21650653891265392), (51, 0.237338213250041), (52, 0.2524748295545578), (0, 0.2977319657802582), (18, 0.43505143001675606), (36, 0.44915953278541565), (53, 0.6569846794009209)]
computing accuracy for after removing block 39 . block score: 0.1285247653722763
removed block 39 current accuracy 0.8838 loss from initial  0.11619999999999997
since last training loss: 0.11259999999999992 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 5, with score 0.132013. All blocks and scores: [(5, 0.13201289623975754), (42, 0.13534147664904594), (41, 0.13779796101152897), (12, 0.13970783352851868), (44, 0.1436803974211216), (43, 0.14801529981195927), (6, 0.1502511128783226), (45, 0.1523127518594265), (38, 0.1542795766144991), (4, 0.1599090788513422), (3, 0.16217358224093914), (2, 0.17799417860805988), (46, 0.18051233887672424), (48, 0.18366674706339836), (47, 0.18379409238696098), (13, 0.1849492248147726), (1, 0.19204072654247284), (49, 0.212583240121603), (50, 0.21535893715918064), (51, 0.23517493717372417), (52, 0.25048731453716755), (0, 0.2977319657802582), (18, 0.43505143001675606), (36, 0.44915953278541565), (53, 0.6614672318100929)]
computing accuracy for after removing block 5 . block score: 0.13201289623975754
removed block 5 current accuracy 0.7992 loss from initial  0.20079999999999998
since last training loss: 0.19719999999999993 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 41, with score 0.122502. All blocks and scores: [(41, 0.12250177934765816), (42, 0.1269572377204895), (43, 0.13938357681035995), (44, 0.14054017513990402), (12, 0.14354953169822693), (45, 0.15017645619809628), (38, 0.15469104796648026), (6, 0.15489424392580986), (4, 0.1599090788513422), (3, 0.16217358224093914), (2, 0.17799417860805988), (48, 0.1798033956438303), (46, 0.18071726895868778), (47, 0.18135263212025166), (13, 0.1818096935749054), (1, 0.19204072654247284), (49, 0.21182532608509064), (50, 0.2149402853101492), (51, 0.23156253807246685), (52, 0.24165694043040276), (0, 0.2977319657802582), (18, 0.4345863461494446), (36, 0.45481398329138756), (53, 0.6590227857232094)]
computing accuracy for after removing block 41 . block score: 0.12250177934765816
removed block 41 current accuracy 0.7744 loss from initial  0.22560000000000002
since last training loss: 0.22199999999999998 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 42, with score 0.131779. All blocks and scores: [(42, 0.13177859224379063), (43, 0.1392977461218834), (44, 0.14320198073983192), (12, 0.14354953169822693), (45, 0.15147765539586544), (38, 0.15469104796648026), (6, 0.15489424392580986), (4, 0.1599090788513422), (3, 0.16217358224093914), (48, 0.17685028351843357), (2, 0.17799417860805988), (46, 0.17835764959454536), (47, 0.1792539581656456), (13, 0.1818096935749054), (1, 0.19204072654247284), (49, 0.21102995611727238), (50, 0.21400298923254013), (51, 0.22956731915473938), (52, 0.23895026743412018), (0, 0.2977319657802582), (18, 0.4345863461494446), (36, 0.45481398329138756), (53, 0.6670461446046829)]
computing accuracy for after removing block 42 . block score: 0.13177859224379063
removed block 42 current accuracy 0.745 loss from initial  0.255
since last training loss: 0.25139999999999996 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 43, with score 0.142698. All blocks and scores: [(43, 0.14269846864044666), (12, 0.14354953169822693), (44, 0.1453162580728531), (45, 0.15204018540680408), (38, 0.15469104796648026), (6, 0.15489424392580986), (4, 0.1599090788513422), (3, 0.16217358224093914), (48, 0.17726675793528557), (46, 0.17794092185795307), (2, 0.17799417860805988), (47, 0.17822290025651455), (13, 0.1818096935749054), (1, 0.19204072654247284), (49, 0.21105434000492096), (50, 0.21298915147781372), (51, 0.22645508497953415), (52, 0.23503504320979118), (0, 0.2977319657802582), (18, 0.4345863461494446), (36, 0.45481398329138756), (53, 0.6815261766314507)]
computing accuracy for after removing block 43 . block score: 0.14269846864044666
removed block 43 current accuracy 0.6914 loss from initial  0.3086
training start
training epoch 0 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best True lr [0.001]
training epoch 1 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.001]
training epoch 2 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 3 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 4 val accuracy 0.976 topk_dict {'top1': 0.976} is_best True lr [0.001]
training epoch 5 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 6 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 7 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 8 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 9 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 10 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 11 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 12 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 13 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 14 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 15 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 16 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 17 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 18 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 19 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 20 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 21 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 22 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 23 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 24 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 25 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 26 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 27 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 28 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 29 val accuracy 0.984 topk_dict {'top1': 0.984} is_best True lr [0.001]
training epoch 30 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 31 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 32 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 33 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 34 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 35 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 36 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best False lr [0.001]
training epoch 37 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 38 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 39 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 40 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 41 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 42 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 43 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 44 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 45 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 46 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 47 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 48 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 49 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.984400)
finished training. finished 50 epochs. accuracy 0.9844 topk_dict {'top1': 0.9844}
start iteration 33
[activation mean]: block to remove picked: 12, with score 0.163470. All blocks and scores: [(12, 0.16346973553299904), (3, 0.16666698269546032), (44, 0.172121899202466), (4, 0.17435512132942677), (2, 0.17516749538481236), (45, 0.17723958753049374), (6, 0.17791705392301083), (38, 0.1838108543306589), (1, 0.1861911676824093), (46, 0.18645917624235153), (47, 0.2048590276390314), (13, 0.20618383400142193), (48, 0.20942809991538525), (49, 0.21890376135706902), (50, 0.23572965152561665), (51, 0.2577362097799778), (0, 0.27606623992323875), (52, 0.2781299836933613), (18, 0.43843841180205345), (36, 0.4461223781108856), (53, 0.6714975982904434)]
computing accuracy for after removing block 12 . block score: 0.16346973553299904
removed block 12 current accuracy 0.9586 loss from initial  0.04139999999999999
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 3, with score 0.166667. All blocks and scores: [(3, 0.16666698269546032), (4, 0.17435512132942677), (2, 0.17516749538481236), (45, 0.17641495913267136), (44, 0.17661902867257595), (6, 0.17791705392301083), (1, 0.1861911676824093), (38, 0.18639195710420609), (46, 0.1898852027952671), (47, 0.1999075710773468), (48, 0.20033369958400726), (49, 0.2221264149993658), (13, 0.229650117456913), (50, 0.22994867525994778), (51, 0.24751442298293114), (52, 0.2656491696834564), (0, 0.27606623992323875), (18, 0.4384108781814575), (36, 0.4498182609677315), (53, 0.660079263150692)]
computing accuracy for after removing block 3 . block score: 0.16666698269546032
removed block 3 current accuracy 0.9228 loss from initial  0.07720000000000005
since last training loss: 0.0616000000000001 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 44, with score 0.166407. All blocks and scores: [(44, 0.16640733554959297), (4, 0.16713151149451733), (45, 0.17062950693070889), (2, 0.17516749538481236), (6, 0.17671075835824013), (46, 0.17852255329489708), (38, 0.1814129650592804), (48, 0.18552827276289463), (1, 0.1861911676824093), (47, 0.19260829500854015), (49, 0.2122700084000826), (13, 0.2187991589307785), (50, 0.21885711327195168), (51, 0.23866732604801655), (52, 0.2542177326977253), (0, 0.27606623992323875), (18, 0.41454049944877625), (36, 0.423806756734848), (53, 0.6600964069366455)]
computing accuracy for after removing block 44 . block score: 0.16640733554959297
removed block 44 current accuracy 0.909 loss from initial  0.09099999999999997
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 4, with score 0.167132. All blocks and scores: [(4, 0.16713151149451733), (2, 0.17516749538481236), (6, 0.17671075835824013), (45, 0.1777320597320795), (46, 0.1807323433458805), (38, 0.1814129650592804), (48, 0.18357121385633945), (1, 0.1861911676824093), (47, 0.19065113551914692), (49, 0.21048084273934364), (50, 0.21739445440471172), (13, 0.2187991589307785), (51, 0.23461386188864708), (52, 0.2445739582180977), (0, 0.27606623992323875), (18, 0.41454049944877625), (36, 0.423806756734848), (53, 0.6836244240403175)]
computing accuracy for after removing block 4 . block score: 0.16713151149451733
removed block 4 current accuracy 0.7718 loss from initial  0.22819999999999996
since last training loss: 0.2126 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 45, with score 0.163688. All blocks and scores: [(45, 0.16368815302848816), (38, 0.16474497132003307), (48, 0.16772520169615746), (47, 0.17436450719833374), (6, 0.17446862533688545), (2, 0.17516749538481236), (46, 0.17828959599137306), (1, 0.1861911676824093), (49, 0.2050964366644621), (13, 0.20909668691456318), (50, 0.2117141503840685), (52, 0.22638787515461445), (51, 0.2264010701328516), (0, 0.27606623992323875), (18, 0.4056859128177166), (36, 0.4149133898317814), (53, 0.6646726578474045)]
computing accuracy for after removing block 45 . block score: 0.16368815302848816
removed block 45 current accuracy 0.721 loss from initial  0.279
since last training loss: 0.2634000000000001 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 38, with score 0.164745. All blocks and scores: [(38, 0.16474497132003307), (48, 0.1705099493265152), (6, 0.17446862533688545), (2, 0.17516749538481236), (47, 0.17776556313037872), (1, 0.1861911676824093), (46, 0.18672705814242363), (49, 0.2074645534157753), (13, 0.20909668691456318), (50, 0.213245315477252), (52, 0.2209169939160347), (51, 0.22401056997478008), (0, 0.27606623992323875), (18, 0.4056859128177166), (36, 0.4149133898317814), (53, 0.6932157129049301)]
computing accuracy for after removing block 38 . block score: 0.16474497132003307
removed block 38 current accuracy 0.6852 loss from initial  0.31479999999999997
since last training loss: 0.2992 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 48, with score 0.167218. All blocks and scores: [(48, 0.16721780598163605), (47, 0.1717057041823864), (6, 0.17446862533688545), (2, 0.17516749538481236), (1, 0.1861911676824093), (46, 0.1917384285479784), (50, 0.2079161163419485), (13, 0.20909668691456318), (49, 0.2124311439692974), (51, 0.21458019688725471), (52, 0.21861113607883453), (0, 0.27606623992323875), (18, 0.4056859128177166), (36, 0.4149133898317814), (53, 0.6738662347197533)]
computing accuracy for after removing block 48 . block score: 0.16721780598163605
removed block 48 current accuracy 0.5864 loss from initial  0.41359999999999997
since last training loss: 0.398 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 47, with score 0.171706. All blocks and scores: [(47, 0.1717057041823864), (6, 0.17446862533688545), (2, 0.17516749538481236), (1, 0.1861911676824093), (46, 0.1917384285479784), (13, 0.20909668691456318), (50, 0.21206010319292545), (52, 0.21324837021529675), (51, 0.21448599360883236), (49, 0.22267954424023628), (0, 0.27606623992323875), (18, 0.4056859128177166), (36, 0.4149133898317814), (53, 0.7554388791322708)]
computing accuracy for after removing block 47 . block score: 0.1717057041823864
removed block 47 current accuracy 0.4858 loss from initial  0.5142
since last training loss: 0.49860000000000004 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 6, with score 0.174469. All blocks and scores: [(6, 0.17446862533688545), (2, 0.17516749538481236), (1, 0.1861911676824093), (46, 0.1917384285479784), (13, 0.20909668691456318), (52, 0.21045656688511372), (51, 0.21337312646210194), (50, 0.21432766690850258), (49, 0.22408990375697613), (0, 0.27606623992323875), (18, 0.4056859128177166), (36, 0.4149133898317814), (53, 0.8492636904120445)]
computing accuracy for after removing block 6 . block score: 0.17446862533688545
removed block 6 current accuracy 0.3264 loss from initial  0.6736
since last training loss: 0.658 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 2, with score 0.175167. All blocks and scores: [(2, 0.17516749538481236), (1, 0.1861911676824093), (46, 0.19697882421314716), (52, 0.20527591183781624), (51, 0.20950994826853275), (50, 0.2125335093587637), (13, 0.21641303785145283), (49, 0.22685136087238789), (0, 0.27606623992323875), (18, 0.4185480363667011), (36, 0.4214116558432579), (53, 0.774132028222084)]
computing accuracy for after removing block 2 . block score: 0.17516749538481236
removed block 2 current accuracy 0.1536 loss from initial  0.8464
since last training loss: 0.8308000000000001 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 1, with score 0.186191. All blocks and scores: [(1, 0.1861911676824093), (46, 0.1955932378768921), (52, 0.2045100349932909), (13, 0.20928113348782063), (51, 0.2131619118154049), (50, 0.2219079788774252), (49, 0.23396649956703186), (0, 0.27606623992323875), (36, 0.43443991988897324), (18, 0.4354964643716812), (53, 0.7878832295536995)]
computing accuracy for after removing block 1 . block score: 0.1861911676824093
removed block 1 current accuracy 0.11 loss from initial  0.89
since last training loss: 0.8744000000000001 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 52, with score 0.208170. All blocks and scores: [(52, 0.20817039534449577), (13, 0.21337295696139336), (51, 0.23320348747074604), (46, 0.24175329878926277), (50, 0.24176018126308918), (49, 0.27496421709656715), (0, 0.27606623992323875), (18, 0.4654012769460678), (36, 0.4908728450536728), (53, 0.9201807677745819)]
computing accuracy for after removing block 52 . block score: 0.20817039534449577
removed block 52 current accuracy 0.1136 loss from initial  0.8864
training start
training epoch 0 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.001]
training epoch 1 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 2 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 3 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 4 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 5 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 6 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 7 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 8 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 9 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 14 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 24 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 29 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 30 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 32 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 33 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 38 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 48 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
