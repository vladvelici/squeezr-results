start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067571. All blocks and scores: [(32, 0.0675714211538434), (31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07914633490145206), (33, 0.08192148618400097), (28, 0.08897436503320932), (35, 0.09150646720081568), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16807220317423344), (39, 0.17391434125602245), (38, 0.17409800179302692), (40, 0.1747935749590397), (44, 0.17559202574193478), (42, 0.1763687338680029), (2, 0.17818448692560196), (43, 0.18028480000793934), (37, 0.1874171681702137), (45, 0.1913505643606186), (46, 0.19167010858654976), (16, 0.19186081551015377), (47, 0.1938924305140972), (0, 0.2014507930725813), (48, 0.2074642963707447), (49, 0.2087792381644249), (50, 0.2150480169802904), (51, 0.23200893960893154), (5, 0.23247346468269825), (52, 0.24538944847881794), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5694299265742302), (53, 0.5812843516469002)]
computing accuracy for after removing block 32 . block score: 0.0675714211538434
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075980. All blocks and scores: [(31, 0.07598021812736988), (30, 0.07686383835971355), (34, 0.07963871583342552), (33, 0.08215188421308994), (28, 0.08897436503320932), (35, 0.09255937859416008), (29, 0.09340742137283087), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (14, 0.16607324592769146), (41, 0.16619791090488434), (38, 0.1706629153341055), (40, 0.17233950085937977), (44, 0.17322266846895218), (39, 0.17388461343944073), (42, 0.17525410652160645), (2, 0.17818448692560196), (43, 0.17904356308281422), (37, 0.18435736000537872), (46, 0.18958506174385548), (45, 0.1906456109136343), (16, 0.19186081551015377), (47, 0.19291129149496555), (0, 0.2014507930725813), (48, 0.2059937696903944), (49, 0.2078111693263054), (50, 0.2136209774762392), (51, 0.2316721361130476), (5, 0.23247346468269825), (52, 0.24407040141522884), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5649380832910538), (53, 0.5846557393670082)]
computing accuracy for after removing block 31 . block score: 0.07598021812736988
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076864. All blocks and scores: [(30, 0.07686383835971355), (34, 0.0803083973005414), (33, 0.0824452992528677), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.0937052397057414), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16335336491465569), (14, 0.16607324592769146), (38, 0.16689680889248848), (40, 0.16941766813397408), (44, 0.17088529095053673), (39, 0.173272417858243), (42, 0.17336755990982056), (2, 0.17818448692560196), (43, 0.17835192382335663), (37, 0.18097997643053532), (46, 0.18729917518794537), (45, 0.189705615863204), (47, 0.19152643717825413), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20431426540017128), (49, 0.20694035664200783), (50, 0.21236521005630493), (51, 0.23184024542570114), (5, 0.23247346468269825), (52, 0.24304170347750187), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5598013773560524), (53, 0.5874009430408478)]
computing accuracy for after removing block 30 . block score: 0.07686383835971355
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079782. All blocks and scores: [(34, 0.07978176791220903), (33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09433686546981335), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16367061622440815), (14, 0.16607324592769146), (38, 0.16689884662628174), (40, 0.1688882727175951), (44, 0.16993452981114388), (39, 0.17342626862227917), (42, 0.17362496629357338), (43, 0.1767871119081974), (2, 0.17818448692560196), (37, 0.18006489984691143), (46, 0.18585865385830402), (45, 0.1900129672139883), (47, 0.19076526165008545), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20426686480641365), (49, 0.20699637196958065), (50, 0.2116481103003025), (51, 0.23162324354052544), (5, 0.23247346468269825), (52, 0.24221924878656864), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5604959651827812), (53, 0.5873366072773933)]
computing accuracy for after removing block 34 . block score: 0.07978176791220903
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.082971. All blocks and scores: [(33, 0.08297098055481911), (28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09587994497269392), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.1610505860298872), (38, 0.1633784919977188), (14, 0.16607324592769146), (40, 0.1664226781576872), (44, 0.1675016302615404), (39, 0.16972871869802475), (42, 0.17223737947642803), (43, 0.17614286206662655), (37, 0.17686635814607143), (2, 0.17818448692560196), (46, 0.1853218786418438), (45, 0.18889996781945229), (47, 0.18968128971755505), (16, 0.19186081551015377), (0, 0.2014507930725813), (48, 0.20193634182214737), (49, 0.20599747449159622), (50, 0.21036292426288128), (51, 0.23076499067246914), (5, 0.23247346468269825), (52, 0.24034381844103336), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5582085475325584), (53, 0.5918786898255348)]
computing accuracy for after removing block 33 . block score: 0.08297098055481911
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088974. All blocks and scores: [(28, 0.08897436503320932), (29, 0.09340742137283087), (35, 0.09792979713529348), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (19, 0.16048101894557476), (41, 0.16093394719064236), (38, 0.16253862343728542), (40, 0.16475909017026424), (44, 0.1657320111989975), (14, 0.16607324592769146), (39, 0.17084676586091518), (42, 0.17239164374768734), (37, 0.1755716409534216), (43, 0.1766559574753046), (2, 0.17818448692560196), (46, 0.18369029462337494), (47, 0.1886796187609434), (45, 0.1887859608978033), (16, 0.19186081551015377), (48, 0.200510635972023), (0, 0.2014507930725813), (49, 0.20520283095538616), (50, 0.21048511005938053), (51, 0.23036987893283367), (5, 0.23247346468269825), (52, 0.2400742694735527), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5590175092220306), (53, 0.5941508710384369)]
computing accuracy for after removing block 28 . block score: 0.08897436503320932
removed block 28 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 29, with score 0.092993. All blocks and scores: [(29, 0.09299347456544638), (35, 0.09727451764047146), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (41, 0.1584145911037922), (38, 0.15931538119912148), (19, 0.16048101894557476), (40, 0.16139849461615086), (44, 0.1630945522338152), (14, 0.16607324592769146), (39, 0.16803736239671707), (42, 0.1694429162889719), (37, 0.17234843783080578), (43, 0.1741682682186365), (2, 0.17818448692560196), (46, 0.1812481377273798), (47, 0.18659634701907635), (45, 0.18721414916217327), (16, 0.19186081551015377), (48, 0.19773288257420063), (0, 0.2014507930725813), (49, 0.20365827158093452), (50, 0.20795450173318386), (51, 0.23072483390569687), (5, 0.23247346468269825), (52, 0.23914798349142075), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5534715801477432), (53, 0.5960394591093063)]
computing accuracy for after removing block 29 . block score: 0.09299347456544638
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 35, with score 0.097640. All blocks and scores: [(35, 0.09764033649116755), (7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (12, 0.15166371688246727), (9, 0.15344819612801075), (20, 0.15513315983116627), (38, 0.15758545510470867), (41, 0.15850874595344067), (40, 0.15992066822946072), (19, 0.16048101894557476), (44, 0.16160862147808075), (14, 0.16607324592769146), (39, 0.16751116327941418), (42, 0.16799712739884853), (37, 0.17121368274092674), (43, 0.17230449058115482), (2, 0.17818448692560196), (46, 0.17956542409956455), (47, 0.18491259962320328), (45, 0.18708676286041737), (16, 0.19186081551015377), (48, 0.19660854898393154), (0, 0.2014507930725813), (49, 0.2031768523156643), (50, 0.2063173335045576), (51, 0.23135396651923656), (5, 0.23247346468269825), (52, 0.23885141499340534), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.553212895989418), (53, 0.5974615514278412)]
computing accuracy for after removing block 35 . block score: 0.09764033649116755
removed block 35 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.101230. All blocks and scores: [(7, 0.10122980084270239), (26, 0.10338725335896015), (8, 0.10454359091818333), (27, 0.10839739814400673), (6, 0.10910437442362309), (25, 0.11085516214370728), (24, 0.11405961308628321), (23, 0.11833162512630224), (22, 0.12097707856446505), (21, 0.12530910782516003), (11, 0.1274298783391714), (4, 0.12796432711184025), (10, 0.12842166982591152), (13, 0.13331163302063942), (3, 0.13975655660033226), (1, 0.1424863040447235), (15, 0.14993730932474136), (38, 0.15101215615868568), (12, 0.15166371688246727), (41, 0.15334330312907696), (9, 0.15344819612801075), (40, 0.1535834725946188), (20, 0.15513315983116627), (44, 0.15793277882039547), (39, 0.16038253344595432), (19, 0.16048101894557476), (42, 0.16383183747529984), (37, 0.1655605472624302), (14, 0.16607324592769146), (43, 0.16824672184884548), (46, 0.17675554379820824), (2, 0.17818448692560196), (47, 0.18043082021176815), (45, 0.18366640619933605), (48, 0.19039705023169518), (16, 0.19186081551015377), (49, 0.20057832263410091), (0, 0.2014507930725813), (50, 0.20306908525526524), (51, 0.22989932633936405), (5, 0.23247346468269825), (52, 0.23640884272754192), (17, 0.32043424621224403), (18, 0.535814993083477), (36, 0.5447516441345215), (53, 0.6041152253746986)]
computing accuracy for after removing block 7 . block score: 0.10122980084270239
removed block 7 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.103371. All blocks and scores: [(26, 0.10337131470441818), (8, 0.10644879005849361), (27, 0.10684240702539682), (25, 0.10887186601758003), (6, 0.10910437442362309), (24, 0.11201080307364464), (23, 0.11445026006549597), (22, 0.11969489883631468), (21, 0.12236787099391222), (11, 0.1271140780299902), (4, 0.12796432711184025), (10, 0.12851480580866337), (13, 0.13286480493843555), (3, 0.13975655660033226), (1, 0.1424863040447235), (38, 0.14797311089932919), (15, 0.14892002195119858), (40, 0.1499129105359316), (12, 0.1504655834287405), (41, 0.15120677277445793), (20, 0.15233486704528332), (9, 0.15325894951820374), (44, 0.15758012980222702), (19, 0.1576475165784359), (39, 0.15788141265511513), (42, 0.16204843670129776), (37, 0.16337201371788979), (14, 0.1643100008368492), (43, 0.16500438563525677), (46, 0.17492828331887722), (2, 0.17818448692560196), (47, 0.1786921340972185), (45, 0.18179143778979778), (48, 0.18856476619839668), (16, 0.18878598883748055), (49, 0.19999698735773563), (0, 0.2014507930725813), (50, 0.20184027031064034), (51, 0.22998498566448689), (5, 0.23247346468269825), (52, 0.23608645610511303), (17, 0.3133290819823742), (18, 0.5268815457820892), (36, 0.5389474630355835), (53, 0.6034829542040825)]
computing accuracy for after removing block 26 . block score: 0.10337131470441818
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 27, with score 0.104636. All blocks and scores: [(27, 0.10463632084429264), (8, 0.10644879005849361), (25, 0.10887186601758003), (6, 0.10910437442362309), (24, 0.11201080307364464), (23, 0.11445026006549597), (22, 0.11969489883631468), (21, 0.12236787099391222), (11, 0.1271140780299902), (4, 0.12796432711184025), (10, 0.12851480580866337), (13, 0.13286480493843555), (3, 0.13975655660033226), (1, 0.1424863040447235), (38, 0.14482695050537586), (40, 0.14683871157467365), (15, 0.14892002195119858), (41, 0.15001942962408066), (12, 0.1504655834287405), (20, 0.15233486704528332), (9, 0.15325894951820374), (44, 0.15481911227107048), (39, 0.15542856976389885), (19, 0.1576475165784359), (37, 0.16035087779164314), (42, 0.16073323786258698), (43, 0.1627457942813635), (14, 0.1643100008368492), (46, 0.17230014503002167), (47, 0.17650548741221428), (2, 0.17818448692560196), (45, 0.18002819456160069), (48, 0.1851070411503315), (16, 0.18878598883748055), (49, 0.19851218536496162), (50, 0.20038525760173798), (0, 0.2014507930725813), (51, 0.22964354045689106), (5, 0.23247346468269825), (52, 0.23497425019741058), (17, 0.3133290819823742), (18, 0.5268815457820892), (36, 0.5391092896461487), (53, 0.6073457226157188)]
computing accuracy for after removing block 27 . block score: 0.10463632084429264
removed block 27 current accuracy 0.9906 loss from initial  0.009399999999999964
training start
training epoch 0 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 1 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 3 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 4 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 5 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 9 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 12 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 11
[activation mean]: block to remove picked: 8, with score 0.105107. All blocks and scores: [(8, 0.10510742012411356), (6, 0.11058925557881594), (25, 0.11843580938875675), (24, 0.11961822398006916), (22, 0.1252431096509099), (23, 0.12593627162277699), (11, 0.1261543296277523), (10, 0.12868293188512325), (4, 0.12886221334338188), (21, 0.13116078451275826), (13, 0.13335069455206394), (3, 0.14094786532223225), (1, 0.141732107847929), (9, 0.15209613554179668), (12, 0.15260200947523117), (15, 0.15356140211224556), (20, 0.15960634127259254), (19, 0.16354499757289886), (14, 0.1676478423178196), (41, 0.16810850985348225), (38, 0.1718948297202587), (39, 0.1722733099013567), (40, 0.17383204586803913), (44, 0.17507336474955082), (42, 0.17564180493354797), (2, 0.177725687623024), (43, 0.17907952144742012), (37, 0.18703601323068142), (45, 0.19044842943549156), (46, 0.1913979109376669), (16, 0.19245687127113342), (47, 0.19464772939682007), (0, 0.1980811506509781), (48, 0.20776121318340302), (49, 0.20922905765473843), (50, 0.21541930548846722), (5, 0.2322220765054226), (51, 0.2324928715825081), (52, 0.24502150528132915), (17, 0.31678617745637894), (18, 0.5296557247638702), (36, 0.5640518292784691), (53, 0.5744885876774788)]
computing accuracy for after removing block 8 . block score: 0.10510742012411356
removed block 8 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.110589. All blocks and scores: [(6, 0.11058925557881594), (25, 0.1164438296109438), (24, 0.11644610483199358), (23, 0.12277967669069767), (22, 0.12335538305342197), (11, 0.1274147555232048), (21, 0.12756724655628204), (10, 0.12855038046836853), (4, 0.12886221334338188), (13, 0.13392030261456966), (3, 0.14094786532223225), (1, 0.141732107847929), (12, 0.1520252861082554), (9, 0.152043916285038), (15, 0.1533023901283741), (20, 0.15770932845771313), (19, 0.16054900363087654), (41, 0.16570383496582508), (14, 0.16590828821063042), (38, 0.16740689240396023), (39, 0.16978007927536964), (40, 0.17025138065218925), (44, 0.17416652664542198), (42, 0.17461752705276012), (43, 0.1767645888030529), (2, 0.177725687623024), (37, 0.18476669676601887), (45, 0.18845520541071892), (46, 0.1892737541347742), (16, 0.19035692512989044), (47, 0.1930428072810173), (0, 0.1980811506509781), (48, 0.2054293304681778), (49, 0.20875695161521435), (50, 0.21446136571466923), (5, 0.2322220765054226), (51, 0.23245877400040627), (52, 0.24467241577804089), (17, 0.31022027507424355), (18, 0.521594949066639), (36, 0.5584092736244202), (53, 0.5725499019026756)]
computing accuracy for after removing block 6 . block score: 0.11058925557881594
removed block 6 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.112376. All blocks and scores: [(24, 0.11237563751637936), (25, 0.11404606979340315), (23, 0.1186511879786849), (22, 0.12120594549924135), (21, 0.12455118633806705), (4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (12, 0.15316914580762386), (15, 0.15475566685199738), (9, 0.15490458346903324), (20, 0.15563820488750935), (19, 0.15727620385587215), (41, 0.16485527716577053), (38, 0.16527924127876759), (40, 0.16687564924359322), (39, 0.16745634004473686), (14, 0.16881015338003635), (42, 0.1722722053527832), (43, 0.1729852631688118), (44, 0.17307428643107414), (2, 0.177725687623024), (37, 0.18291998468339443), (45, 0.1860709823668003), (46, 0.18690486438572407), (47, 0.18987715803086758), (16, 0.18994247540831566), (0, 0.1980811506509781), (48, 0.20221166871488094), (49, 0.20698884688317776), (50, 0.21296077780425549), (5, 0.2322220765054226), (51, 0.23264161683619022), (52, 0.24384209886193275), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5519187599420547), (53, 0.5708125829696655)]
computing accuracy for after removing block 24 . block score: 0.11237563751637936
removed block 24 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.114219. All blocks and scores: [(25, 0.11421910114586353), (23, 0.1186511879786849), (22, 0.12120594549924135), (21, 0.12455118633806705), (4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (12, 0.15316914580762386), (15, 0.15475566685199738), (9, 0.15490458346903324), (20, 0.15563820488750935), (19, 0.15727620385587215), (41, 0.16087948717176914), (38, 0.16220100037753582), (39, 0.16307242028415203), (40, 0.16323516704142094), (42, 0.16875511035323143), (14, 0.16881015338003635), (44, 0.1688574142754078), (43, 0.16967114433646202), (2, 0.177725687623024), (37, 0.17894980683922768), (45, 0.18333587609231472), (46, 0.1845670584589243), (47, 0.1861834041774273), (16, 0.18994247540831566), (0, 0.1980811506509781), (48, 0.19845756515860558), (49, 0.20403121784329414), (50, 0.2096269577741623), (51, 0.23211293295025826), (5, 0.2322220765054226), (52, 0.24152017198503017), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5489960759878159), (53, 0.5759996697306633)]
computing accuracy for after removing block 25 . block score: 0.11421910114586353
removed block 25 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.118651. All blocks and scores: [(23, 0.1186511879786849), (22, 0.12120594549924135), (21, 0.12455118633806705), (4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (12, 0.15316914580762386), (15, 0.15475566685199738), (9, 0.15490458346903324), (38, 0.15559246949851513), (41, 0.1556305792182684), (20, 0.15563820488750935), (39, 0.15669776313006878), (19, 0.15727620385587215), (40, 0.1581517606973648), (44, 0.16479125060141087), (42, 0.1651207972317934), (43, 0.16709566488862038), (14, 0.16881015338003635), (37, 0.17298281751573086), (2, 0.177725687623024), (45, 0.18130303174257278), (46, 0.18182758800685406), (47, 0.18317412957549095), (16, 0.18994247540831566), (48, 0.19356359355151653), (0, 0.1980811506509781), (49, 0.20095394738018513), (50, 0.20602060109376907), (51, 0.23203539662063122), (5, 0.2322220765054226), (52, 0.23957444168627262), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5412882566452026), (53, 0.5806915760040283)]
computing accuracy for after removing block 23 . block score: 0.1186511879786849
removed block 23 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008200000000000096 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.121206. All blocks and scores: [(22, 0.12120594549924135), (21, 0.12455118633806705), (4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (12, 0.15316914580762386), (41, 0.15391491912305355), (15, 0.15475566685199738), (9, 0.15490458346903324), (38, 0.15519862063229084), (20, 0.15563820488750935), (39, 0.15641245990991592), (40, 0.15690947324037552), (19, 0.15727620385587215), (44, 0.16285008937120438), (42, 0.1642275471240282), (43, 0.16486617177724838), (14, 0.16881015338003635), (37, 0.1726492065936327), (2, 0.177725687623024), (46, 0.1794326100498438), (45, 0.18047392554581165), (47, 0.18058443814516068), (16, 0.18994247540831566), (48, 0.1915729846805334), (0, 0.1980811506509781), (49, 0.19915845058858395), (50, 0.20490366034209728), (51, 0.23208152875304222), (5, 0.2322220765054226), (52, 0.2383262813091278), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5401516854763031), (53, 0.5785099044442177)]
computing accuracy for after removing block 22 . block score: 0.12120594549924135
removed block 22 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.124551. All blocks and scores: [(21, 0.12455118633806705), (4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (41, 0.1486119944602251), (40, 0.15158451162278652), (38, 0.15169946290552616), (39, 0.15203830413520336), (12, 0.15316914580762386), (15, 0.15475566685199738), (9, 0.15490458346903324), (20, 0.15563820488750935), (19, 0.15727620385587215), (42, 0.15821002796292305), (44, 0.1587878167629242), (43, 0.161516847088933), (37, 0.16818814724683762), (14, 0.16881015338003635), (46, 0.17594571597874165), (47, 0.1761416159570217), (45, 0.17729388922452927), (2, 0.177725687623024), (48, 0.18526887148618698), (16, 0.18994247540831566), (49, 0.1951786745339632), (0, 0.1980811506509781), (50, 0.20214926078915596), (5, 0.2322220765054226), (51, 0.23236182145774364), (52, 0.23575888946652412), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5297574773430824), (53, 0.5775938481092453)]
computing accuracy for after removing block 21 . block score: 0.12455118633806705
removed block 21 current accuracy 0.9764 loss from initial  0.023599999999999954
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 4, with score 0.128862. All blocks and scores: [(4, 0.12886221334338188), (11, 0.13031858205795288), (10, 0.1333935223519802), (13, 0.13880642876029015), (3, 0.14094786532223225), (1, 0.141732107847929), (41, 0.14344527758657932), (40, 0.14592211693525314), (38, 0.14595434069633484), (39, 0.14723256044089794), (12, 0.15316914580762386), (44, 0.15408073738217354), (15, 0.15475566685199738), (42, 0.1548393201082945), (9, 0.15490458346903324), (20, 0.15563820488750935), (19, 0.15727620385587215), (43, 0.1580414269119501), (37, 0.1629474852234125), (14, 0.16881015338003635), (47, 0.17240088991820812), (46, 0.1728665679693222), (45, 0.1742926947772503), (2, 0.177725687623024), (48, 0.17827977798879147), (16, 0.18994247540831566), (49, 0.1919386126101017), (0, 0.1980811506509781), (50, 0.2000404465943575), (51, 0.2320604920387268), (5, 0.2322220765054226), (52, 0.23334809206426144), (17, 0.3093234449625015), (18, 0.5143482685089111), (36, 0.5214710906147957), (53, 0.5763044208288193)]
computing accuracy for after removing block 4 . block score: 0.12886221334338188
removed block 4 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.027800000000000047 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 11, with score 0.128569. All blocks and scores: [(11, 0.12856861762702465), (10, 0.1346389576792717), (13, 0.14070059917867184), (41, 0.14073175750672817), (3, 0.14094786532223225), (1, 0.141732107847929), (38, 0.14255195297300816), (40, 0.14428044483065605), (39, 0.14549976587295532), (20, 0.15212484262883663), (42, 0.1527549847960472), (9, 0.15294246189296246), (43, 0.15372368320822716), (44, 0.15434222482144833), (15, 0.15447227656841278), (12, 0.15466106869280338), (19, 0.1548544354736805), (37, 0.15977581031620502), (14, 0.168239401653409), (47, 0.1713481955230236), (46, 0.1716335229575634), (45, 0.17183480970561504), (48, 0.17623017355799675), (2, 0.177725687623024), (16, 0.18960963748395443), (49, 0.19068280421197414), (0, 0.1980811506509781), (50, 0.19848795793950558), (52, 0.2311866655945778), (51, 0.23176214285194874), (5, 0.23333031684160233), (17, 0.30701465904712677), (18, 0.5096201673150063), (36, 0.5167011395096779), (53, 0.5768744498491287)]
computing accuracy for after removing block 11 . block score: 0.12856861762702465
removed block 11 current accuracy 0.96 loss from initial  0.040000000000000036
since last training loss: 0.03960000000000008 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 10, with score 0.134639. All blocks and scores: [(10, 0.1346389576792717), (41, 0.1354646496474743), (38, 0.13676709681749344), (40, 0.13709815591573715), (3, 0.14094786532223225), (39, 0.14100017212331295), (1, 0.141732107847929), (42, 0.1460045613348484), (13, 0.14645561575889587), (43, 0.14928464218974113), (44, 0.15050716698169708), (20, 0.15132924914360046), (19, 0.1520663108676672), (9, 0.15294246189296246), (37, 0.15469704009592533), (12, 0.157594732940197), (15, 0.15840698219835758), (45, 0.1655215360224247), (46, 0.16622380912303925), (47, 0.16833730973303318), (14, 0.17011031322181225), (48, 0.17220615968108177), (2, 0.177725687623024), (49, 0.18684189021587372), (16, 0.19393746182322502), (50, 0.1961089763790369), (0, 0.1980811506509781), (52, 0.22882194258272648), (51, 0.23229427449405193), (5, 0.23333031684160233), (17, 0.3027816340327263), (18, 0.5043780505657196), (36, 0.5084000155329704), (53, 0.5743806213140488)]
computing accuracy for after removing block 10 . block score: 0.1346389576792717
removed block 10 current accuracy 0.939 loss from initial  0.061000000000000054
since last training loss: 0.0606000000000001 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 40, with score 0.129806. All blocks and scores: [(40, 0.12980621308088303), (41, 0.13016384467482567), (38, 0.13201570510864258), (39, 0.1352082509547472), (3, 0.14094786532223225), (42, 0.14114882610738277), (1, 0.141732107847929), (43, 0.14242196641862392), (13, 0.14376272074878216), (44, 0.1456256303936243), (19, 0.1474087368696928), (20, 0.1476085390895605), (37, 0.14930614084005356), (9, 0.15294246189296246), (12, 0.15898210182785988), (45, 0.1595540437847376), (15, 0.16003041341900826), (46, 0.16240871138870716), (47, 0.16456145979464054), (48, 0.16720362566411495), (14, 0.16981681063771248), (2, 0.177725687623024), (49, 0.18294448032975197), (16, 0.19265645556151867), (50, 0.19416862353682518), (0, 0.1980811506509781), (52, 0.22658232413232327), (51, 0.23253756761550903), (5, 0.23333031684160233), (17, 0.29794134199619293), (36, 0.4939952455461025), (18, 0.49834074452519417), (53, 0.5682800710201263)]
computing accuracy for after removing block 40 . block score: 0.12980621308088303
removed block 40 current accuracy 0.925 loss from initial  0.07499999999999996
training start
training epoch 0 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 1 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 2 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 3 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 4 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 5 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 6 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 7 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 8 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 9 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 10 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 11 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 12 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 13 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 14 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 15 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 16 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 17 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 18 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 19 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 20 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 21 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 22 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 23 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 24 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 25 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 26 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 27 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 28 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 29 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 30 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 31 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 32 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 33 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 34 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 35 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 36 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 37 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 38 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 40 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 41 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 42 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 43 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 44 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 46 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 47 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 49 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.996400)
finished training. finished 50 epochs. accuracy 0.9964 topk_dict {'top1': 0.9964}
start iteration 22
[activation mean]: block to remove picked: 1, with score 0.134934. All blocks and scores: [(1, 0.1349342279136181), (13, 0.14241214469075203), (3, 0.15410428680479527), (9, 0.1553994920104742), (15, 0.1606658324599266), (12, 0.1630303654819727), (14, 0.1705504059791565), (41, 0.1715101394802332), (44, 0.17396549694240093), (38, 0.1751766949892044), (42, 0.17692935094237328), (39, 0.17855760641396046), (2, 0.17883079312741756), (43, 0.17931314930319786), (0, 0.18781078793108463), (37, 0.18839939311146736), (45, 0.1897987723350525), (16, 0.19142884947359562), (46, 0.1919983346015215), (47, 0.1950870230793953), (19, 0.19785689003765583), (20, 0.19849134795367718), (48, 0.2096044309437275), (49, 0.2103725280612707), (50, 0.2163291983306408), (51, 0.23061665147542953), (5, 0.24057591706514359), (52, 0.24537325836718082), (17, 0.3043999560177326), (18, 0.5131784602999687), (36, 0.5587045103311539), (53, 0.5754582807421684)]
computing accuracy for after removing block 1 . block score: 0.1349342279136181
removed block 1 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0007999999999999119 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 13, with score 0.145677. All blocks and scores: [(13, 0.14567656256258488), (3, 0.1558481864631176), (9, 0.1571289785206318), (15, 0.16120105795562267), (12, 0.16219007410109043), (41, 0.1667547058314085), (38, 0.17040914669632912), (14, 0.17077021673321724), (44, 0.17226178757846355), (42, 0.1754243541508913), (39, 0.17592322826385498), (43, 0.1778066623955965), (2, 0.17978685535490513), (37, 0.1854508090764284), (0, 0.18781078793108463), (45, 0.189150158315897), (16, 0.1904810220003128), (46, 0.19201463647186756), (20, 0.19495093449950218), (47, 0.19532659836113453), (19, 0.19540945068001747), (48, 0.20812864042818546), (49, 0.21138175204396248), (50, 0.21549961902201176), (51, 0.2304656244814396), (5, 0.2383779175579548), (52, 0.24443024396896362), (17, 0.3023310638964176), (18, 0.509392224252224), (36, 0.5520522594451904), (53, 0.57781583070755)]
computing accuracy for after removing block 13 . block score: 0.14567656256258488
removed block 13 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 3, with score 0.155848. All blocks and scores: [(3, 0.1558481864631176), (9, 0.1571289785206318), (12, 0.16219007410109043), (15, 0.1638956442475319), (41, 0.1646063681691885), (38, 0.16768291220068932), (44, 0.17316429503262043), (39, 0.17483291402459145), (42, 0.17492693848907948), (14, 0.17551972717046738), (43, 0.17711946181952953), (2, 0.17978685535490513), (37, 0.18552172556519508), (45, 0.18648663349449635), (0, 0.18781078793108463), (46, 0.1908559836447239), (20, 0.19320907443761826), (19, 0.1933350134640932), (16, 0.1943881083279848), (47, 0.19554774835705757), (48, 0.20558026246726513), (49, 0.20877964235842228), (50, 0.21394026838243008), (51, 0.22961785085499287), (5, 0.2383779175579548), (52, 0.24232203140854836), (17, 0.30243121832609177), (18, 0.5059643909335136), (36, 0.5523128882050514), (53, 0.5798863247036934)]
computing accuracy for after removing block 3 . block score: 0.1558481864631176
removed block 3 current accuracy 0.9822 loss from initial  0.017800000000000038
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 41, with score 0.153008. All blocks and scores: [(41, 0.15300770290195942), (38, 0.1543518416583538), (9, 0.15596027299761772), (12, 0.16052813827991486), (39, 0.16373328864574432), (15, 0.16529764235019684), (43, 0.16567491553723812), (44, 0.165907459333539), (42, 0.16622057370841503), (37, 0.17380240745842457), (14, 0.17561032064259052), (2, 0.17978685535490513), (45, 0.1809961088001728), (19, 0.18156085349619389), (20, 0.183699619024992), (46, 0.1851622797548771), (0, 0.18781078793108463), (47, 0.1890507210046053), (16, 0.19172922149300575), (48, 0.19615975581109524), (49, 0.20645153149962425), (50, 0.20752894692122936), (51, 0.22730618342757225), (52, 0.23761990666389465), (5, 0.24076435342431068), (17, 0.2922835536301136), (18, 0.4865068383514881), (36, 0.526894710958004), (53, 0.5850051641464233)]
computing accuracy for after removing block 41 . block score: 0.15300770290195942
removed block 41 current accuracy 0.9788 loss from initial  0.021199999999999997
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 38, with score 0.154352. All blocks and scores: [(38, 0.1543518416583538), (9, 0.15596027299761772), (42, 0.16016815975308418), (12, 0.16052813827991486), (44, 0.16147353313863277), (43, 0.16179097816348076), (39, 0.16373328864574432), (15, 0.16529764235019684), (37, 0.17380240745842457), (45, 0.17525501362979412), (14, 0.17561032064259052), (2, 0.17978685535490513), (19, 0.18156085349619389), (46, 0.1821770891547203), (20, 0.183699619024992), (47, 0.18453296087682247), (0, 0.18781078793108463), (48, 0.19078677333891392), (16, 0.19172922149300575), (49, 0.20083567313849926), (50, 0.20174449682235718), (51, 0.2236201222985983), (52, 0.2321496307849884), (5, 0.24076435342431068), (17, 0.2922835536301136), (18, 0.4865068383514881), (36, 0.526894710958004), (53, 0.6207478940486908)]
computing accuracy for after removing block 38 . block score: 0.1543518416583538
removed block 38 current accuracy 0.9652 loss from initial  0.03480000000000005
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 44, with score 0.152259. All blocks and scores: [(44, 0.15225905179977417), (9, 0.15596027299761772), (42, 0.15838134288787842), (43, 0.15933968499302864), (12, 0.16052813827991486), (39, 0.16427836939692497), (15, 0.16529764235019684), (45, 0.16868203692138195), (37, 0.17380240745842457), (14, 0.17561032064259052), (46, 0.17643769457936287), (2, 0.17978685535490513), (47, 0.1798579804599285), (19, 0.18156085349619389), (48, 0.1828567087650299), (20, 0.183699619024992), (0, 0.18781078793108463), (16, 0.19172922149300575), (49, 0.1955581195652485), (50, 0.19583959877490997), (51, 0.22219919227063656), (52, 0.22624723799526691), (5, 0.24076435342431068), (17, 0.2922835536301136), (18, 0.4865068383514881), (36, 0.526894710958004), (53, 0.6468071341514587)]
computing accuracy for after removing block 44 . block score: 0.15225905179977417
removed block 44 current accuracy 0.952 loss from initial  0.04800000000000004
since last training loss: 0.044399999999999995 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 9, with score 0.155960. All blocks and scores: [(9, 0.15596027299761772), (42, 0.15838134288787842), (43, 0.15933968499302864), (12, 0.16052813827991486), (39, 0.16427836939692497), (15, 0.16529764235019684), (45, 0.16551386937499046), (37, 0.17380240745842457), (46, 0.17495408654212952), (14, 0.17561032064259052), (2, 0.17978685535490513), (47, 0.18044624291360378), (48, 0.181330393999815), (19, 0.18156085349619389), (20, 0.183699619024992), (0, 0.18781078793108463), (16, 0.19172922149300575), (49, 0.19419190846383572), (50, 0.19492920860648155), (51, 0.22039043717086315), (52, 0.223801014944911), (5, 0.24076435342431068), (17, 0.2922835536301136), (18, 0.4865068383514881), (36, 0.526894710958004), (53, 0.6804254353046417)]
computing accuracy for after removing block 9 . block score: 0.15596027299761772
removed block 9 current accuracy 0.8948 loss from initial  0.10519999999999996
since last training loss: 0.10159999999999991 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 43, with score 0.151387. All blocks and scores: [(43, 0.15138749592006207), (42, 0.1522595677524805), (39, 0.15727303363382816), (45, 0.15791397728025913), (12, 0.16430195420980453), (37, 0.16491185873746872), (15, 0.16612825728952885), (14, 0.16882343590259552), (20, 0.16926386952400208), (46, 0.17065995931625366), (48, 0.1716005764901638), (19, 0.17309831455349922), (47, 0.17796938307583332), (2, 0.17978685535490513), (16, 0.18213252164423466), (0, 0.18781078793108463), (49, 0.19226615875959396), (50, 0.19272876903414726), (52, 0.2195870466530323), (51, 0.22046199440956116), (5, 0.24076435342431068), (17, 0.27001164481043816), (18, 0.473161980509758), (36, 0.5207695662975311), (53, 0.6824842989444733)]
computing accuracy for after removing block 43 . block score: 0.15138749592006207
removed block 43 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.1352 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 45, with score 0.151263. All blocks and scores: [(45, 0.15126297436654568), (42, 0.1522595677524805), (39, 0.15727303363382816), (12, 0.16430195420980453), (37, 0.16491185873746872), (15, 0.16612825728952885), (14, 0.16882343590259552), (46, 0.1688878145068884), (20, 0.16926386952400208), (48, 0.17045805975794792), (19, 0.17309831455349922), (47, 0.17511768639087677), (2, 0.17978685535490513), (16, 0.18213252164423466), (0, 0.18781078793108463), (50, 0.18947564996778965), (49, 0.19058687798678875), (52, 0.21539120562374592), (51, 0.21794927306473255), (5, 0.24076435342431068), (17, 0.27001164481043816), (18, 0.473161980509758), (36, 0.5207695662975311), (53, 0.7246055528521538)]
computing accuracy for after removing block 45 . block score: 0.15126297436654568
removed block 45 current accuracy 0.8152 loss from initial  0.18479999999999996
since last training loss: 0.18119999999999992 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 42, with score 0.152260. All blocks and scores: [(42, 0.1522595677524805), (39, 0.15727303363382816), (12, 0.16430195420980453), (46, 0.16483077593147755), (37, 0.16491185873746872), (15, 0.16612825728952885), (14, 0.16882343590259552), (20, 0.16926386952400208), (48, 0.16945547610521317), (19, 0.17309831455349922), (47, 0.17476623877882957), (2, 0.17978685535490513), (16, 0.18213252164423466), (50, 0.18728056736290455), (0, 0.18781078793108463), (49, 0.18938243575394154), (52, 0.21172036044299603), (51, 0.21375856176018715), (5, 0.24076435342431068), (17, 0.27001164481043816), (18, 0.473161980509758), (36, 0.5207695662975311), (53, 0.7675700038671494)]
computing accuracy for after removing block 42 . block score: 0.1522595677524805
removed block 42 current accuracy 0.7476 loss from initial  0.25239999999999996
since last training loss: 0.2487999999999999 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 39, with score 0.157273. All blocks and scores: [(39, 0.15727303363382816), (12, 0.16430195420980453), (37, 0.16491185873746872), (46, 0.1659361645579338), (15, 0.16612825728952885), (14, 0.16882343590259552), (20, 0.16926386952400208), (48, 0.16981546394526958), (47, 0.17189866676926613), (19, 0.17309831455349922), (2, 0.17978685535490513), (16, 0.18213252164423466), (50, 0.18663687445223331), (49, 0.18690943717956543), (0, 0.18781078793108463), (52, 0.20890341512858868), (51, 0.2118025328963995), (5, 0.24076435342431068), (17, 0.27001164481043816), (18, 0.473161980509758), (36, 0.5207695662975311), (53, 0.8116912618279457)]
computing accuracy for after removing block 39 . block score: 0.15727303363382816
removed block 39 current accuracy 0.6846 loss from initial  0.3154
training start
training epoch 0 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 1 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 2 val accuracy 0.96 topk_dict {'top1': 0.96} is_best True lr [0.001]
training epoch 3 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best True lr [0.001]
training epoch 4 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.001]
training epoch 5 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 6 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
training epoch 7 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 8 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best True lr [0.001]
training epoch 9 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 10 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 11 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best True lr [0.001]
training epoch 12 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 13 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best True lr [0.001]
training epoch 14 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 15 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 16 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 17 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best True lr [0.001]
training epoch 18 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 19 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 20 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 21 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 22 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best True lr [0.001]
training epoch 23 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 24 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 25 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 26 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 27 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 28 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 29 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 30 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 31 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 32 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 33 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 34 val accuracy 0.983 topk_dict {'top1': 0.983} is_best True lr [0.001]
training epoch 35 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 37 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 38 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 39 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 40 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 41 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 42 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 43 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 44 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 45 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 46 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 47 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 48 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best False lr [0.001]
training epoch 49 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.983000)
finished training. finished 50 epochs. accuracy 0.983 topk_dict {'top1': 0.983}
start iteration 33
[activation mean]: block to remove picked: 15, with score 0.166969. All blocks and scores: [(15, 0.16696852818131447), (14, 0.18000409938395023), (12, 0.18622701987624168), (16, 0.1887892372906208), (0, 0.19433337822556496), (2, 0.20000538975000381), (47, 0.21124207973480225), (46, 0.2122486364096403), (49, 0.22053018398582935), (48, 0.22097179852426052), (50, 0.22347559221088886), (19, 0.22762793116271496), (20, 0.2329507004469633), (51, 0.2370660901069641), (37, 0.23760993778705597), (52, 0.2504439502954483), (5, 0.26943106949329376), (17, 0.28773216530680656), (18, 0.50208405777812), (36, 0.534241758286953), (53, 0.60039471834898)]
computing accuracy for after removing block 15 . block score: 0.16696852818131447
removed block 15 current accuracy 0.97 loss from initial  0.030000000000000027
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 14, with score 0.180004. All blocks and scores: [(14, 0.18000409938395023), (12, 0.18622701987624168), (0, 0.19433337822556496), (47, 0.19833815284073353), (2, 0.20000538975000381), (46, 0.20318847335875034), (48, 0.20853023789823055), (16, 0.20904980599880219), (50, 0.21325740963220596), (49, 0.2145635075867176), (19, 0.2181265912950039), (37, 0.22384754195809364), (20, 0.22462322376668453), (51, 0.23343210108578205), (52, 0.24620366841554642), (5, 0.26943106949329376), (17, 0.2869814373552799), (18, 0.4879516400396824), (36, 0.5222804918885231), (53, 0.598382942378521)]
computing accuracy for after removing block 14 . block score: 0.18000409938395023
removed block 14 current accuracy 0.9282 loss from initial  0.07179999999999997
since last training loss: 0.05479999999999996 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 12, with score 0.186227. All blocks and scores: [(12, 0.18622701987624168), (47, 0.18733828701078892), (0, 0.19433337822556496), (48, 0.1951715238392353), (46, 0.19518103636801243), (2, 0.20000538975000381), (19, 0.2054617516696453), (50, 0.20705031976103783), (16, 0.20732899755239487), (20, 0.21186506375670433), (49, 0.21190050430595875), (37, 0.2161063700914383), (51, 0.2312932126224041), (52, 0.24261087365448475), (5, 0.26943106949329376), (17, 0.2773576080799103), (18, 0.4722790755331516), (36, 0.5116646960377693), (53, 0.591830775141716)]
computing accuracy for after removing block 12 . block score: 0.18622701987624168
removed block 12 current accuracy 0.823 loss from initial  0.17700000000000005
since last training loss: 0.16000000000000003 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 48, with score 0.180533. All blocks and scores: [(48, 0.1805332936346531), (47, 0.1840475220233202), (20, 0.18511734902858734), (19, 0.185283487662673), (46, 0.18913282826542854), (0, 0.19433337822556496), (37, 0.19571475125849247), (16, 0.19634809158742428), (2, 0.20000538975000381), (50, 0.20254971459507942), (49, 0.20716789923608303), (51, 0.23106713220477104), (52, 0.2390465848147869), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.48735813423991203), (53, 0.5841707810759544)]
computing accuracy for after removing block 48 . block score: 0.1805332936346531
removed block 48 current accuracy 0.77 loss from initial  0.22999999999999998
since last training loss: 0.21299999999999997 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 47, with score 0.184048. All blocks and scores: [(47, 0.1840475220233202), (20, 0.18511734902858734), (19, 0.185283487662673), (46, 0.18913282826542854), (0, 0.19433337822556496), (37, 0.19571475125849247), (16, 0.19634809158742428), (2, 0.20000538975000381), (50, 0.20113977044820786), (49, 0.2065286971628666), (51, 0.2304533589631319), (52, 0.2382500935345888), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.48735813423991203), (53, 0.638581782579422)]
computing accuracy for after removing block 47 . block score: 0.1840475220233202
removed block 47 current accuracy 0.7248 loss from initial  0.2752
since last training loss: 0.2582 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 20, with score 0.185117. All blocks and scores: [(20, 0.18511734902858734), (19, 0.185283487662673), (46, 0.18913282826542854), (0, 0.19433337822556496), (37, 0.19571475125849247), (16, 0.19634809158742428), (50, 0.19714116491377354), (2, 0.20000538975000381), (49, 0.20779857970774174), (51, 0.22517920099198818), (52, 0.23489962704479694), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.48735813423991203), (53, 0.7055522054433823)]
computing accuracy for after removing block 20 . block score: 0.18511734902858734
removed block 20 current accuracy 0.6604 loss from initial  0.3396
since last training loss: 0.3226 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 46, with score 0.175982. All blocks and scores: [(46, 0.1759820207953453), (37, 0.17638118751347065), (19, 0.185283487662673), (49, 0.19214424304664135), (50, 0.19221166521310806), (0, 0.19433337822556496), (16, 0.19634809158742428), (2, 0.20000538975000381), (51, 0.22194784693419933), (52, 0.2286180965602398), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.45744333788752556), (53, 0.6699628010392189)]
computing accuracy for after removing block 46 . block score: 0.1759820207953453
removed block 46 current accuracy 0.5676 loss from initial  0.4324
since last training loss: 0.4154 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 37, with score 0.176381. All blocks and scores: [(37, 0.17638118751347065), (49, 0.18242195062339306), (19, 0.185283487662673), (50, 0.18650691583752632), (0, 0.19433337822556496), (16, 0.19634809158742428), (2, 0.20000538975000381), (51, 0.21940581314265728), (52, 0.22431335598230362), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.45744333788752556), (53, 0.7857573851943016)]
computing accuracy for after removing block 37 . block score: 0.17638118751347065
removed block 37 current accuracy 0.5158 loss from initial  0.48419999999999996
since last training loss: 0.46719999999999995 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 50, with score 0.183999. All blocks and scores: [(50, 0.18399890698492527), (19, 0.185283487662673), (49, 0.19404694624245167), (0, 0.19433337822556496), (16, 0.19634809158742428), (2, 0.20000538975000381), (51, 0.2155930995941162), (52, 0.21985860168933868), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.45744333788752556), (53, 0.7560134157538414)]
computing accuracy for after removing block 50 . block score: 0.18399890698492527
removed block 50 current accuracy 0.387 loss from initial  0.613
since last training loss: 0.596 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 19, with score 0.185283. All blocks and scores: [(19, 0.185283487662673), (49, 0.19404694624245167), (0, 0.19433337822556496), (16, 0.19634809158742428), (2, 0.20000538975000381), (51, 0.20394706167280674), (52, 0.21363508515059948), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.45744333788752556), (53, 0.9245741367340088)]
computing accuracy for after removing block 19 . block score: 0.185283487662673
removed block 19 current accuracy 0.3638 loss from initial  0.6362
since last training loss: 0.6192 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 49, with score 0.187692. All blocks and scores: [(49, 0.187692042440176), (0, 0.19433337822556496), (16, 0.19634809158742428), (2, 0.20000538975000381), (51, 0.20461497828364372), (52, 0.2094917967915535), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.4484263211488724), (53, 0.7710179761052132)]
computing accuracy for after removing block 49 . block score: 0.187692042440176
removed block 49 current accuracy 0.271 loss from initial  0.729
since last training loss: 0.712 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 0, with score 0.194333. All blocks and scores: [(0, 0.19433337822556496), (16, 0.19634809158742428), (51, 0.19815197959542274), (2, 0.20000538975000381), (52, 0.20545276440680027), (17, 0.2626841738820076), (5, 0.26943106949329376), (18, 0.44418608769774437), (36, 0.4484263211488724), (53, 0.986478753387928)]
computing accuracy for after removing block 0 . block score: 0.19433337822556496
removed block 0 current accuracy 0.2084 loss from initial  0.7916
training start
training epoch 0 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best True lr [0.001]
training epoch 1 val accuracy 0.833 topk_dict {'top1': 0.833} is_best True lr [0.001]
training epoch 2 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.001]
training epoch 3 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best True lr [0.001]
training epoch 4 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best True lr [0.001]
training epoch 5 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.001]
training epoch 6 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.001]
training epoch 7 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.001]
training epoch 8 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.001]
training epoch 9 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 10 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.001]
training epoch 11 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 12 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 13 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.001]
training epoch 14 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 15 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 16 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.001]
training epoch 17 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.001]
training epoch 18 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 19 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 20 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 21 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 22 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 23 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 24 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 25 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 26 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 27 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 28 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 29 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 30 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 31 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 32 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 33 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 34 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 35 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 36 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
training epoch 37 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 38 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 39 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 40 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 41 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 42 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 43 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 44 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 45 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 46 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 47 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 48 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 49 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.914200)
finished training. finished 50 epochs. accuracy 0.9142 topk_dict {'top1': 0.9142}
