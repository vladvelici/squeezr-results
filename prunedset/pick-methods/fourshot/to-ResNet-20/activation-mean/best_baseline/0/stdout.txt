start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062186. All blocks and scores: [(33, 0.062185654416680336), (31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08460694830864668), (29, 0.08930057473480701), (35, 0.09068185184150934), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.15793540328741074), (41, 0.1598859392106533), (40, 0.16328190825879574), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (13, 0.17231429554522038), (16, 0.17250859178602695), (42, 0.173072362318635), (3, 0.17561711743474007), (44, 0.17696543596684933), (39, 0.18027342669665813), (46, 0.18065034598112106), (45, 0.18211421370506287), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.1851444821804762), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20122026838362217), (48, 0.20766260288655758), (47, 0.21044609509408474), (10, 0.21198169328272343), (49, 0.21626885049045086), (12, 0.2171211950480938), (50, 0.2270798273384571), (5, 0.24775297567248344), (51, 0.25931933149695396), (52, 0.27953876554965973), (18, 0.562093511223793), (36, 0.5809764266014099), (53, 0.6345704793930054)]
computing accuracy for after removing block 33 . block score: 0.062185654416680336
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075665. All blocks and scores: [(31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08419696148484945), (29, 0.08930057473480701), (35, 0.09093761537224054), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.1572423968464136), (41, 0.157970754429698), (40, 0.16252249106764793), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.1718137189745903), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17635269090533257), (46, 0.17947880178689957), (39, 0.1794979516416788), (45, 0.18079246766865253), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18429154343903065), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20149224624037743), (48, 0.20621014572679996), (47, 0.2088273111730814), (10, 0.21198169328272343), (49, 0.21557523868978024), (12, 0.2171211950480938), (50, 0.2254290860146284), (5, 0.24775297567248344), (51, 0.2583659961819649), (52, 0.2788151502609253), (18, 0.562093511223793), (36, 0.5792211890220642), (53, 0.6342398598790169)]
computing accuracy for after removing block 31 . block score: 0.07566479779779911
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077217. All blocks and scores: [(32, 0.0772171588614583), (30, 0.08002207893878222), (34, 0.08413633890450001), (29, 0.08930057473480701), (35, 0.0912106977775693), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.15681212209165096), (9, 0.15687535144388676), (41, 0.1570850908756256), (40, 0.161650612950325), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17076795920729637), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17494448646903038), (3, 0.17561711743474007), (46, 0.17894328385591507), (39, 0.1794340517371893), (45, 0.18090466037392616), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.184414841234684), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20150442980229855), (48, 0.2049737572669983), (47, 0.2079013716429472), (10, 0.21198169328272343), (49, 0.2145967148244381), (12, 0.2171211950480938), (50, 0.22419615276157856), (5, 0.24775297567248344), (51, 0.2574971169233322), (52, 0.27774784341454506), (18, 0.562093511223793), (36, 0.578696958720684), (53, 0.6368038207292557)]
computing accuracy for after removing block 32 . block score: 0.0772171588614583
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080022. All blocks and scores: [(30, 0.08002207893878222), (34, 0.08331287186592817), (29, 0.08930057473480701), (35, 0.09091351181268692), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.1567240171134472), (9, 0.15687535144388676), (41, 0.15688308142125607), (40, 0.16149466298520565), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17011075653135777), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.1743054185062647), (3, 0.17561711743474007), (39, 0.17930877394974232), (46, 0.1793159805238247), (45, 0.1810449492186308), (11, 0.18289094977080822), (38, 0.18401959165930748), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20230499655008316), (48, 0.20458471588790417), (47, 0.20751793310046196), (10, 0.21198169328272343), (49, 0.21405635960400105), (12, 0.2171211950480938), (50, 0.22361480072140694), (5, 0.24775297567248344), (51, 0.2571289539337158), (52, 0.2768261544406414), (18, 0.562093511223793), (36, 0.5805345475673676), (53, 0.6388764828443527)]
computing accuracy for after removing block 30 . block score: 0.08002207893878222
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082327. All blocks and scores: [(34, 0.0823270846158266), (29, 0.08930057473480701), (35, 0.09074232261627913), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (41, 0.15666824020445347), (43, 0.1568149123340845), (9, 0.15687535144388676), (40, 0.16184155084192753), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.16879690065979958), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17466101422905922), (3, 0.17561711743474007), (46, 0.17866099812090397), (39, 0.17968248948454857), (45, 0.1809448804706335), (11, 0.18289094977080822), (38, 0.18364996276795864), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.20370880514383316), (37, 0.20395098999142647), (47, 0.20615417696535587), (10, 0.21198169328272343), (49, 0.21362591721117496), (12, 0.2171211950480938), (50, 0.22279280424118042), (5, 0.24775297567248344), (51, 0.2562031261622906), (52, 0.2757616192102432), (18, 0.562093511223793), (36, 0.5833301842212677), (53, 0.6426545828580856)]
computing accuracy for after removing block 34 . block score: 0.0823270846158266
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.089301. All blocks and scores: [(29, 0.08930057473480701), (35, 0.09233403950929642), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (41, 0.15786897018551826), (43, 0.15851951949298382), (40, 0.16382364183664322), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17144694924354553), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17642127722501755), (46, 0.1792240459471941), (39, 0.18195353262126446), (45, 0.1821158267557621), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18651140667498112), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.2036153506487608), (47, 0.20668456703424454), (37, 0.20811929553747177), (10, 0.21198169328272343), (49, 0.21409878507256508), (12, 0.2171211950480938), (50, 0.2226774599403143), (5, 0.24775297567248344), (51, 0.25564805790781975), (52, 0.2756016328930855), (18, 0.562093511223793), (36, 0.5907158851623535), (53, 0.6423948332667351)]
computing accuracy for after removing block 29 . block score: 0.08930057473480701
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.091657. All blocks and scores: [(35, 0.09165653120726347), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (41, 0.15495886653661728), (43, 0.1564184371381998), (9, 0.15687535144388676), (40, 0.16190743818879128), (4, 0.1638463642448187), (14, 0.1646636202931404), (42, 0.1678131129592657), (6, 0.16876995004713535), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.1750869434326887), (3, 0.17561711743474007), (46, 0.17751540057361126), (45, 0.180727431550622), (39, 0.1812782883644104), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.1843508444726467), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.20150871388614178), (47, 0.20382969826459885), (37, 0.20588894188404083), (10, 0.21198169328272343), (49, 0.21254768408834934), (12, 0.2171211950480938), (50, 0.22045584954321384), (5, 0.24775297567248344), (51, 0.25385941937565804), (52, 0.27405693009495735), (18, 0.562093511223793), (36, 0.5876752510666847), (53, 0.6453233808279037)]
computing accuracy for after removing block 35 . block score: 0.09165653120726347
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.102849. All blocks and scores: [(26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (41, 0.14814221300184727), (43, 0.15043681487441063), (19, 0.15310418419539928), (9, 0.15687535144388676), (40, 0.15760448575019836), (42, 0.16072314977645874), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (44, 0.1713014841079712), (13, 0.17231429554522038), (46, 0.17232048697769642), (16, 0.17250859178602695), (3, 0.17561711743474007), (39, 0.17583631351590157), (45, 0.17609016224741936), (38, 0.17979468032717705), (11, 0.18289094977080822), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (48, 0.1943671703338623), (37, 0.1972644105553627), (47, 0.20038395375013351), (1, 0.20094968006014824), (49, 0.2090973649173975), (10, 0.21198169328272343), (50, 0.21475619822740555), (12, 0.2171211950480938), (5, 0.24775297567248344), (51, 0.2506211008876562), (52, 0.2706872373819351), (18, 0.562093511223793), (36, 0.5786933302879333), (53, 0.6560840830206871)]
computing accuracy for after removing block 26 . block score: 0.10284937918186188
removed block 26 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.103910. All blocks and scores: [(28, 0.10390998888760805), (27, 0.11537433974444866), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (41, 0.14521292969584465), (17, 0.1462525948882103), (43, 0.14835144020617008), (19, 0.15310418419539928), (40, 0.1555494088679552), (42, 0.15658129937946796), (9, 0.15687535144388676), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (44, 0.16996589861810207), (46, 0.17047489620745182), (13, 0.17231429554522038), (16, 0.17250859178602695), (39, 0.1739969439804554), (45, 0.17424485459923744), (3, 0.17561711743474007), (38, 0.17698232270777225), (11, 0.18289094977080822), (8, 0.18417140655219555), (2, 0.18877310492098331), (48, 0.19148584455251694), (0, 0.19188890047371387), (37, 0.19508465193212032), (47, 0.19795764796435833), (1, 0.20094968006014824), (49, 0.20763599127531052), (10, 0.21198169328272343), (50, 0.21215908229351044), (12, 0.2171211950480938), (5, 0.24775297567248344), (51, 0.2486923709511757), (52, 0.2689184211194515), (18, 0.562093511223793), (36, 0.5748701021075249), (53, 0.6624525040388107)]
computing accuracy for after removing block 28 . block score: 0.10390998888760805
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.115374. All blocks and scores: [(27, 0.11537433974444866), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (41, 0.14249353483319283), (43, 0.14606720209121704), (17, 0.1462525948882103), (19, 0.15310418419539928), (42, 0.153189392760396), (40, 0.15365483053028584), (9, 0.15687535144388676), (4, 0.1638463642448187), (14, 0.1646636202931404), (46, 0.16766207106411457), (44, 0.1681983917951584), (6, 0.16876995004713535), (45, 0.17146105878055096), (39, 0.17206012830138206), (13, 0.17231429554522038), (16, 0.17250859178602695), (38, 0.1740078367292881), (3, 0.17561711743474007), (11, 0.18289094977080822), (8, 0.18417140655219555), (48, 0.1883855927735567), (2, 0.18877310492098331), (0, 0.19188890047371387), (37, 0.19309917278587818), (47, 0.19475034065544605), (1, 0.20094968006014824), (49, 0.2053353115916252), (50, 0.21015555039048195), (10, 0.21198169328272343), (12, 0.2171211950480938), (51, 0.24731113202869892), (5, 0.24775297567248344), (52, 0.26764777675271034), (18, 0.562093511223793), (36, 0.5719055980443954), (53, 0.6653143018484116)]
computing accuracy for after removing block 27 . block score: 0.11537433974444866
removed block 27 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.121824. All blocks and scores: [(23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (41, 0.13952884823083878), (43, 0.14368636719882488), (17, 0.1462525948882103), (42, 0.15014228783547878), (40, 0.15076275914907455), (19, 0.15310418419539928), (9, 0.15687535144388676), (4, 0.1638463642448187), (14, 0.1646636202931404), (44, 0.16544372588396072), (46, 0.16565500013530254), (6, 0.16876995004713535), (39, 0.1695840246975422), (45, 0.1696939691901207), (38, 0.1708164196461439), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (11, 0.18289094977080822), (8, 0.18417140655219555), (48, 0.18538032285869122), (2, 0.18877310492098331), (37, 0.19070417061448097), (47, 0.1918278932571411), (0, 0.19188890047371387), (1, 0.20094968006014824), (49, 0.20358254946768284), (50, 0.20776433125138283), (10, 0.21198169328272343), (12, 0.2171211950480938), (51, 0.24563466012477875), (5, 0.24775297567248344), (52, 0.2660658061504364), (18, 0.562093511223793), (36, 0.5675752386450768), (53, 0.6674327328801155)]
computing accuracy for after removing block 23 . block score: 0.12182437721639872
removed block 23 current accuracy 0.9854 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 1 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 2 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 3 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 5 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 8 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 10 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 16 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 35 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.135701. All blocks and scores: [(25, 0.13570071384310722), (7, 0.13629505969583988), (15, 0.1390446312725544), (21, 0.1407878864556551), (24, 0.14085008576512337), (22, 0.14244689233601093), (20, 0.14543558470904827), (17, 0.14852838590741158), (9, 0.1568719930946827), (43, 0.1573803573846817), (19, 0.1577555574476719), (41, 0.1580889541655779), (4, 0.16210071742534637), (40, 0.1621446292847395), (14, 0.1644265465438366), (6, 0.1686386838555336), (42, 0.1705070436000824), (13, 0.1711943969130516), (16, 0.17284115590155125), (3, 0.1761770285665989), (44, 0.17769012227654457), (39, 0.178519481793046), (46, 0.17990810051560402), (11, 0.18127833865582943), (45, 0.1816688384860754), (38, 0.18210722133517265), (8, 0.18338547088205814), (2, 0.18773184902966022), (0, 0.19170900993049145), (37, 0.1978251114487648), (1, 0.19990596733987331), (48, 0.20781193487346172), (47, 0.20960756950080395), (10, 0.21173775382339954), (12, 0.21582468785345554), (49, 0.21733797155320644), (50, 0.22700312733650208), (5, 0.246112409979105), (51, 0.260500755161047), (52, 0.28102511540055275), (18, 0.5535585507750511), (36, 0.5734143033623695), (53, 0.6254291012883186)]
computing accuracy for after removing block 25 . block score: 0.13570071384310722
removed block 25 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 7, with score 0.136295. All blocks and scores: [(7, 0.13629505969583988), (15, 0.1390446312725544), (21, 0.1407878864556551), (24, 0.14085008576512337), (22, 0.14244689233601093), (20, 0.14543558470904827), (17, 0.14852838590741158), (43, 0.1524860244244337), (41, 0.15401593409478664), (9, 0.1568719930946827), (19, 0.1577555574476719), (40, 0.1587498001754284), (4, 0.16210071742534637), (14, 0.1644265465438366), (42, 0.16470632702112198), (6, 0.1686386838555336), (13, 0.1711943969130516), (16, 0.17284115590155125), (44, 0.17387974448502064), (46, 0.1748522948473692), (3, 0.1761770285665989), (39, 0.17696662433445454), (45, 0.17798607051372528), (38, 0.17829562537372112), (11, 0.18127833865582943), (8, 0.18338547088205814), (2, 0.18773184902966022), (0, 0.19170900993049145), (37, 0.19392242468893528), (1, 0.19990596733987331), (48, 0.20286689326167107), (47, 0.20509865693747997), (10, 0.21173775382339954), (49, 0.21311151795089245), (12, 0.21582468785345554), (50, 0.22199946641921997), (5, 0.246112409979105), (51, 0.257165290415287), (52, 0.27800581231713295), (18, 0.5535585507750511), (36, 0.5663321986794472), (53, 0.632128044962883)]
computing accuracy for after removing block 7 . block score: 0.13629505969583988
removed block 7 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.135522. All blocks and scores: [(24, 0.13552196323871613), (15, 0.13768207281827927), (22, 0.13842088170349598), (17, 0.14043983444571495), (21, 0.140566261485219), (20, 0.14329738914966583), (41, 0.1458517163991928), (43, 0.14741001091897488), (19, 0.15630675666034222), (40, 0.15648027881979942), (9, 0.15826566703617573), (14, 0.15906126238405704), (42, 0.16006601974368095), (13, 0.16151911206543446), (4, 0.16210071742534637), (16, 0.16775616072118282), (6, 0.1686386838555336), (46, 0.16985218785703182), (44, 0.172471571713686), (45, 0.17496769316494465), (39, 0.17547118477523327), (3, 0.1761770285665989), (11, 0.17632851377129555), (38, 0.17791893519461155), (8, 0.1808882113546133), (2, 0.18773184902966022), (37, 0.1891390923410654), (0, 0.19170900993049145), (48, 0.19704904407262802), (1, 0.19990596733987331), (47, 0.20299251563847065), (12, 0.2092459723353386), (49, 0.21135248988866806), (10, 0.21188296377658844), (50, 0.21847717836499214), (5, 0.246112409979105), (51, 0.25553999096155167), (52, 0.27680404484272003), (18, 0.549381859600544), (36, 0.5563898682594299), (53, 0.6395734772086143)]
computing accuracy for after removing block 24 . block score: 0.13552196323871613
removed block 24 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 15, with score 0.137682. All blocks and scores: [(15, 0.13768207281827927), (41, 0.1377134844660759), (22, 0.13842088170349598), (17, 0.14043983444571495), (21, 0.140566261485219), (43, 0.14141011983156204), (20, 0.14329738914966583), (40, 0.1510558556765318), (42, 0.15234314277768135), (19, 0.15630675666034222), (9, 0.15826566703617573), (14, 0.15906126238405704), (13, 0.16151911206543446), (4, 0.16210071742534637), (46, 0.16360868886113167), (44, 0.1659400686621666), (16, 0.16775616072118282), (6, 0.1686386838555336), (45, 0.17075803503394127), (39, 0.17274662293493748), (38, 0.1745313797146082), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (37, 0.1862334031611681), (2, 0.18773184902966022), (48, 0.19027936086058617), (0, 0.19170900993049145), (47, 0.19834045879542828), (1, 0.19990596733987331), (49, 0.20702672563493252), (12, 0.2092459723353386), (10, 0.21188296377658844), (50, 0.2123201433569193), (5, 0.246112409979105), (51, 0.25076155364513397), (52, 0.2717455290257931), (36, 0.5475133880972862), (18, 0.549381859600544), (53, 0.6485845968127251)]
computing accuracy for after removing block 15 . block score: 0.13768207281827927
removed block 15 current accuracy 0.989 loss from initial  0.01100000000000001
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 22, with score 0.134307. All blocks and scores: [(22, 0.13430725038051605), (21, 0.13586669601500034), (41, 0.13622978329658508), (20, 0.13908169604837894), (17, 0.1420539002865553), (43, 0.14340471662580967), (40, 0.1489221714437008), (42, 0.15037638694047928), (19, 0.15701483935117722), (9, 0.15826566703617573), (14, 0.15906126238405704), (13, 0.16151911206543446), (4, 0.16210071742534637), (44, 0.1636519767343998), (46, 0.16621188074350357), (6, 0.1686386838555336), (45, 0.17077021300792694), (39, 0.17129517532885075), (16, 0.17302608862519264), (38, 0.17583666928112507), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (37, 0.18756560795009136), (2, 0.18773184902966022), (48, 0.19131168350577354), (0, 0.19170900993049145), (47, 0.1994614340364933), (1, 0.19990596733987331), (49, 0.20691236667335033), (12, 0.2092459723353386), (10, 0.21188296377658844), (50, 0.21306898817420006), (5, 0.246112409979105), (51, 0.2513104509562254), (52, 0.2727341987192631), (18, 0.546143613755703), (36, 0.5463085770606995), (53, 0.6473730951547623)]
computing accuracy for after removing block 22 . block score: 0.13430725038051605
removed block 22 current accuracy 0.9792 loss from initial  0.02080000000000004
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 41, with score 0.130826. All blocks and scores: [(41, 0.13082632049918175), (21, 0.13586669601500034), (20, 0.13908169604837894), (43, 0.14018557779490948), (17, 0.1420539002865553), (42, 0.14467073418200016), (40, 0.14573504216969013), (19, 0.15701483935117722), (44, 0.15794740058481693), (9, 0.15826566703617573), (14, 0.15906126238405704), (46, 0.1597862932831049), (13, 0.16151911206543446), (4, 0.16210071742534637), (45, 0.16675538942217827), (39, 0.16861896216869354), (6, 0.1686386838555336), (16, 0.17302608862519264), (38, 0.1739321369677782), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (48, 0.18449607864022255), (37, 0.18748733773827553), (2, 0.18773184902966022), (0, 0.19170900993049145), (47, 0.1942522432655096), (1, 0.19990596733987331), (49, 0.2028890624642372), (50, 0.2078625187277794), (12, 0.2092459723353386), (10, 0.21188296377658844), (5, 0.246112409979105), (51, 0.24812044389545918), (52, 0.2694893591105938), (36, 0.5423354506492615), (18, 0.546143613755703), (53, 0.6491648554801941)]
computing accuracy for after removing block 41 . block score: 0.13082632049918175
removed block 41 current accuracy 0.9746 loss from initial  0.025399999999999978
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.135867. All blocks and scores: [(21, 0.13586669601500034), (43, 0.13887271098792553), (20, 0.13908169604837894), (17, 0.1420539002865553), (42, 0.14419719204306602), (40, 0.14573504216969013), (46, 0.15598301962018013), (19, 0.15701483935117722), (44, 0.1577413324266672), (9, 0.15826566703617573), (14, 0.15906126238405704), (13, 0.16151911206543446), (4, 0.16210071742534637), (45, 0.16521427780389786), (39, 0.16861896216869354), (6, 0.1686386838555336), (16, 0.17302608862519264), (38, 0.1739321369677782), (3, 0.1761770285665989), (11, 0.17632851377129555), (48, 0.17936854250729084), (8, 0.1808882113546133), (37, 0.18748733773827553), (2, 0.18773184902966022), (0, 0.19170900993049145), (47, 0.19413317367434502), (1, 0.19990596733987331), (49, 0.20029707252979279), (50, 0.2043051030486822), (12, 0.2092459723353386), (10, 0.21188296377658844), (51, 0.24539031647145748), (5, 0.246112409979105), (52, 0.26685868203639984), (36, 0.5423354506492615), (18, 0.546143613755703), (53, 0.6650611385703087)]
computing accuracy for after removing block 21 . block score: 0.13586669601500034
removed block 21 current accuracy 0.9574 loss from initial  0.04259999999999997
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 43, with score 0.137115. All blocks and scores: [(43, 0.13711498491466045), (20, 0.13908169604837894), (42, 0.140073049813509), (17, 0.1420539002865553), (40, 0.1435202620923519), (46, 0.15232337452471256), (44, 0.1529984287917614), (19, 0.15701483935117722), (9, 0.15826566703617573), (14, 0.15906126238405704), (13, 0.16151911206543446), (45, 0.16205117665231228), (4, 0.16210071742534637), (39, 0.1669806893914938), (6, 0.1686386838555336), (38, 0.1706397496163845), (16, 0.17302608862519264), (48, 0.17503971233963966), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (37, 0.18611585907638073), (2, 0.18773184902966022), (47, 0.19080650806427002), (0, 0.19170900993049145), (49, 0.19782056845724583), (1, 0.19990596733987331), (50, 0.20019487291574478), (12, 0.2092459723353386), (10, 0.21188296377658844), (51, 0.24344614706933498), (5, 0.246112409979105), (52, 0.26382865756750107), (36, 0.5371119603514671), (18, 0.546143613755703), (53, 0.6625408679246902)]
computing accuracy for after removing block 43 . block score: 0.13711498491466045
removed block 43 current accuracy 0.9506 loss from initial  0.0494
since last training loss: 0.04920000000000002 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 20, with score 0.139082. All blocks and scores: [(20, 0.13908169604837894), (42, 0.140073049813509), (17, 0.1420539002865553), (40, 0.1435202620923519), (46, 0.1503826193511486), (44, 0.15266814082860947), (19, 0.15701483935117722), (9, 0.15826566703617573), (14, 0.15906126238405704), (13, 0.16151911206543446), (4, 0.16210071742534637), (45, 0.16218492574989796), (39, 0.1669806893914938), (6, 0.1686386838555336), (38, 0.1706397496163845), (16, 0.17302608862519264), (48, 0.17452283762395382), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (37, 0.18611585907638073), (2, 0.18773184902966022), (47, 0.18983770348131657), (0, 0.19170900993049145), (49, 0.19533767364919186), (50, 0.1980757750570774), (1, 0.19990596733987331), (12, 0.2092459723353386), (10, 0.21188296377658844), (51, 0.24124877899885178), (5, 0.246112409979105), (52, 0.2605886496603489), (36, 0.5371119603514671), (18, 0.546143613755703), (53, 0.6793167367577553)]
computing accuracy for after removing block 20 . block score: 0.13908169604837894
removed block 20 current accuracy 0.9324 loss from initial  0.0676
since last training loss: 0.06740000000000002 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.137522. All blocks and scores: [(42, 0.13752187974750996), (17, 0.1420539002865553), (40, 0.14384430833160877), (46, 0.1469099447131157), (44, 0.15199945122003555), (19, 0.15701483935117722), (9, 0.15826566703617573), (14, 0.15906126238405704), (45, 0.16071095503866673), (13, 0.16151911206543446), (4, 0.16210071742534637), (39, 0.1651105061173439), (6, 0.1686386838555336), (38, 0.17006177455186844), (48, 0.17235852219164371), (16, 0.17302608862519264), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (47, 0.1872224025428295), (2, 0.18773184902966022), (37, 0.19078481942415237), (0, 0.19170900993049145), (49, 0.1937569435685873), (50, 0.19545460119843483), (1, 0.19990596733987331), (12, 0.2092459723353386), (10, 0.21188296377658844), (51, 0.23892047628760338), (5, 0.246112409979105), (52, 0.2575843557715416), (36, 0.5434110313653946), (18, 0.546143613755703), (53, 0.6713708862662315)]
computing accuracy for after removing block 42 . block score: 0.13752187974750996
removed block 42 current accuracy 0.9178 loss from initial  0.08220000000000005
since last training loss: 0.08200000000000007 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 17, with score 0.142054. All blocks and scores: [(17, 0.1420539002865553), (40, 0.14384430833160877), (46, 0.14665710553526878), (44, 0.15090930461883545), (19, 0.15701483935117722), (9, 0.15826566703617573), (14, 0.15906126238405704), (45, 0.160970626398921), (13, 0.16151911206543446), (4, 0.16210071742534637), (39, 0.1651105061173439), (6, 0.1686386838555336), (38, 0.17006177455186844), (48, 0.17092044465243816), (16, 0.17302608862519264), (3, 0.1761770285665989), (11, 0.17632851377129555), (8, 0.1808882113546133), (47, 0.1834797691553831), (2, 0.18773184902966022), (37, 0.19078481942415237), (49, 0.19116869382560253), (0, 0.19170900993049145), (50, 0.19307052716612816), (1, 0.19990596733987331), (12, 0.2092459723353386), (10, 0.21188296377658844), (51, 0.23498239740729332), (5, 0.246112409979105), (52, 0.25318560004234314), (36, 0.5434110313653946), (18, 0.546143613755703), (53, 0.6796084493398666)]
computing accuracy for after removing block 17 . block score: 0.1420539002865553
removed block 17 current accuracy 0.8986 loss from initial  0.10140000000000005
training start
training epoch 0 val accuracy 0.978 topk_dict {'top1': 0.978} is_best True lr [0.001]
training epoch 1 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 2 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 3 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 4 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 5 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 6 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 7 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 8 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 9 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 10 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 11 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 12 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 13 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 14 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best False lr [0.001]
training epoch 15 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 16 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 17 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 18 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 19 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 20 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 21 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 22 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 23 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 24 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 25 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 26 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 27 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 28 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 30 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 31 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 32 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 33 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 34 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 36 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 37 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 39 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 40 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 41 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 42 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 43 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 45 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 46 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 47 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 48 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 49 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.993200)
finished training. finished 50 epochs. accuracy 0.9932 topk_dict {'top1': 0.9932}
start iteration 22
[activation mean]: block to remove picked: 9, with score 0.158166. All blocks and scores: [(9, 0.1581662893295288), (4, 0.1595293339341879), (6, 0.17005357705056667), (40, 0.17078249529004097), (3, 0.1714700385928154), (13, 0.17254201881587505), (14, 0.17450261674821377), (16, 0.17945533245801926), (2, 0.17949670180678368), (8, 0.17996856942772865), (44, 0.18123929388821125), (11, 0.1814712267369032), (46, 0.18217039667069912), (0, 0.18291186913847923), (45, 0.1831222102046013), (39, 0.1854097917675972), (38, 0.18734262324869633), (1, 0.1927612405270338), (37, 0.20245476439595222), (19, 0.20546419732272625), (48, 0.2084517665207386), (47, 0.20873340405523777), (10, 0.2143042664974928), (49, 0.2161801364272833), (12, 0.21976087614893913), (50, 0.22695647738873959), (5, 0.2437952384352684), (51, 0.25801392644643784), (52, 0.2787395417690277), (18, 0.544669434428215), (36, 0.5619012489914894), (53, 0.6386560872197151)]
computing accuracy for after removing block 9 . block score: 0.1581662893295288
removed block 9 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 4, with score 0.159529. All blocks and scores: [(4, 0.1595293339341879), (40, 0.16535972617566586), (16, 0.16847775876522064), (13, 0.16994952596724033), (6, 0.17005357705056667), (3, 0.1714700385928154), (14, 0.1727693360298872), (44, 0.175001734867692), (46, 0.17519903182983398), (11, 0.17535918205976486), (2, 0.17949670180678368), (8, 0.17996856942772865), (45, 0.18081470392644405), (0, 0.18291186913847923), (39, 0.18378339521586895), (38, 0.18445202335715294), (37, 0.1895993873476982), (1, 0.1927612405270338), (48, 0.19929886609315872), (19, 0.20375366136431694), (47, 0.20870068669319153), (12, 0.20901923812925816), (49, 0.21319469064474106), (10, 0.21383801102638245), (50, 0.22081119753420353), (5, 0.2437952384352684), (51, 0.2549500875174999), (52, 0.27572454139590263), (18, 0.5385278612375259), (36, 0.5473360270261765), (53, 0.649236835539341)]
computing accuracy for after removing block 4 . block score: 0.1595293339341879
removed block 4 current accuracy 0.982 loss from initial  0.018000000000000016
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 16, with score 0.161786. All blocks and scores: [(16, 0.16178563237190247), (40, 0.16724074631929398), (13, 0.16939483396708965), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (44, 0.17442609556019306), (46, 0.17640693485736847), (6, 0.1765288207679987), (2, 0.17949670180678368), (45, 0.1811926569789648), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18366557359695435), (38, 0.1841458473354578), (1, 0.1927612405270338), (37, 0.1942494586110115), (48, 0.19896826148033142), (47, 0.20629926770925522), (19, 0.2069692499935627), (12, 0.20865966752171516), (49, 0.21181085146963596), (10, 0.21634828113019466), (50, 0.21878735534846783), (5, 0.25047437474131584), (51, 0.2540501579642296), (52, 0.27475937083363533), (18, 0.5435868725180626), (36, 0.5519775301218033), (53, 0.6491871401667595)]
computing accuracy for after removing block 16 . block score: 0.16178563237190247
removed block 16 current accuracy 0.966 loss from initial  0.03400000000000003
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 40, with score 0.160481. All blocks and scores: [(40, 0.16048136912286282), (44, 0.16466788575053215), (13, 0.16939483396708965), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (6, 0.1765288207679987), (2, 0.17949670180678368), (45, 0.1801716759800911), (46, 0.180209556594491), (38, 0.1810834463685751), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18365889973938465), (37, 0.19178777001798153), (1, 0.1927612405270338), (48, 0.1974783018231392), (47, 0.20463805831968784), (49, 0.20588179863989353), (19, 0.20693589560687542), (12, 0.20865966752171516), (10, 0.21634828113019466), (50, 0.21685628406703472), (5, 0.25047437474131584), (51, 0.2509477846324444), (52, 0.27175329998135567), (18, 0.5314253643155098), (36, 0.532335065305233), (53, 0.6467220857739449)]
computing accuracy for after removing block 40 . block score: 0.16048136912286282
removed block 40 current accuracy 0.9556 loss from initial  0.044399999999999995
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 44, with score 0.163799. All blocks and scores: [(44, 0.16379931010305882), (13, 0.16939483396708965), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (46, 0.1748451367020607), (6, 0.1765288207679987), (45, 0.17674322053790092), (2, 0.17949670180678368), (38, 0.1810834463685751), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18365889973938465), (48, 0.19078288041055202), (37, 0.19178777001798153), (1, 0.1927612405270338), (49, 0.2030187789350748), (47, 0.20427088625729084), (19, 0.20693589560687542), (12, 0.20865966752171516), (50, 0.21074935793876648), (10, 0.21634828113019466), (51, 0.2483521644026041), (5, 0.25047437474131584), (52, 0.2676023207604885), (18, 0.5314253643155098), (36, 0.532335065305233), (53, 0.6762329563498497)]
computing accuracy for after removing block 44 . block score: 0.16379931010305882
removed block 44 current accuracy 0.9398 loss from initial  0.06020000000000003
since last training loss: 0.0534 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 45, with score 0.168669. All blocks and scores: [(45, 0.16866884380578995), (13, 0.16939483396708965), (46, 0.1696708332747221), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (6, 0.1765288207679987), (2, 0.17949670180678368), (38, 0.1810834463685751), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18365889973938465), (48, 0.18459245190024376), (37, 0.19178777001798153), (1, 0.1927612405270338), (49, 0.19767444394528866), (47, 0.20283176563680172), (50, 0.20618623681366444), (19, 0.20693589560687542), (12, 0.20865966752171516), (10, 0.21634828113019466), (51, 0.2428018692880869), (5, 0.25047437474131584), (52, 0.2628721185028553), (18, 0.5314253643155098), (36, 0.532335065305233), (53, 0.7169748395681381)]
computing accuracy for after removing block 45 . block score: 0.16866884380578995
removed block 45 current accuracy 0.9178 loss from initial  0.08220000000000005
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 46, with score 0.163249. All blocks and scores: [(46, 0.16324948519468307), (13, 0.16939483396708965), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (6, 0.1765288207679987), (2, 0.17949670180678368), (48, 0.18026883341372013), (38, 0.1810834463685751), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18365889973938465), (37, 0.19178777001798153), (1, 0.1927612405270338), (49, 0.19377601891756058), (50, 0.20190715044736862), (47, 0.20230422914028168), (19, 0.20693589560687542), (12, 0.20865966752171516), (10, 0.21634828113019466), (51, 0.23612888529896736), (5, 0.25047437474131584), (52, 0.2575303241610527), (18, 0.5314253643155098), (36, 0.532335065305233), (53, 0.7766571491956711)]
computing accuracy for after removing block 46 . block score: 0.16324948519468307
removed block 46 current accuracy 0.8974 loss from initial  0.10260000000000002
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 13, with score 0.169395. All blocks and scores: [(13, 0.16939483396708965), (11, 0.17072836495935917), (14, 0.17102178372442722), (3, 0.1714700385928154), (6, 0.1765288207679987), (48, 0.1786040011793375), (2, 0.17949670180678368), (38, 0.1810834463685751), (8, 0.1825933139771223), (0, 0.18291186913847923), (39, 0.18365889973938465), (49, 0.19042352586984634), (37, 0.19178777001798153), (1, 0.1927612405270338), (47, 0.19637701846659184), (50, 0.1993898991495371), (19, 0.20693589560687542), (12, 0.20865966752171516), (10, 0.21634828113019466), (51, 0.2296171449124813), (5, 0.25047437474131584), (52, 0.25151207111775875), (18, 0.5314253643155098), (36, 0.532335065305233), (53, 0.831796757876873)]
computing accuracy for after removing block 13 . block score: 0.16939483396708965
removed block 13 current accuracy 0.8206 loss from initial  0.1794
since last training loss: 0.17259999999999998 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 11, with score 0.170728. All blocks and scores: [(11, 0.17072836495935917), (3, 0.1714700385928154), (6, 0.1765288207679987), (2, 0.17949670180678368), (48, 0.17970826663076878), (38, 0.18180818669497967), (39, 0.18212925642728806), (8, 0.1825933139771223), (0, 0.18291186913847923), (14, 0.18676732853055), (49, 0.18757140263915062), (47, 0.19082916900515556), (1, 0.1927612405270338), (50, 0.1982533074915409), (37, 0.20115556754171848), (12, 0.20865966752171516), (19, 0.2098413985222578), (10, 0.21634828113019466), (51, 0.22667456418275833), (52, 0.24940259754657745), (5, 0.25047437474131584), (36, 0.5343155488371849), (18, 0.5357451066374779), (53, 0.8368249237537384)]
computing accuracy for after removing block 11 . block score: 0.17072836495935917
removed block 11 current accuracy 0.7736 loss from initial  0.22640000000000005
since last training loss: 0.21960000000000002 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 3, with score 0.171470. All blocks and scores: [(3, 0.1714700385928154), (6, 0.1765288207679987), (48, 0.1772773414850235), (2, 0.17949670180678368), (39, 0.18089227937161922), (8, 0.1825933139771223), (0, 0.18291186913847923), (38, 0.1834172084927559), (49, 0.18756686337292194), (14, 0.19081906788051128), (1, 0.1927612405270338), (47, 0.1955938246101141), (50, 0.19627041183412075), (12, 0.19655531831085682), (37, 0.19877132773399353), (10, 0.21634828113019466), (19, 0.21743577532470226), (51, 0.2271082904189825), (52, 0.2486698403954506), (5, 0.25047437474131584), (36, 0.5392103865742683), (18, 0.5457717776298523), (53, 0.8431762382388115)]
computing accuracy for after removing block 3 . block score: 0.1714700385928154
removed block 3 current accuracy 0.668 loss from initial  0.33199999999999996
since last training loss: 0.32519999999999993 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 48, with score 0.172708. All blocks and scores: [(48, 0.17270848900079727), (39, 0.17359191551804543), (2, 0.17949670180678368), (6, 0.1795303151011467), (38, 0.17956073954701424), (8, 0.18022959306836128), (14, 0.18218290619552135), (49, 0.18229963444173336), (0, 0.18291186913847923), (47, 0.18586214445531368), (50, 0.18952410854399204), (1, 0.1927612405270338), (12, 0.19618678838014603), (37, 0.20158134400844574), (19, 0.21426886320114136), (51, 0.22166495583951473), (10, 0.22255375795066357), (52, 0.24409281462430954), (5, 0.2556467615067959), (18, 0.5355343371629715), (36, 0.5375037640333176), (53, 0.87509685754776)]
computing accuracy for after removing block 48 . block score: 0.17270848900079727
removed block 48 current accuracy 0.6 loss from initial  0.4
training start
training epoch 0 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best True lr [0.001]
training epoch 1 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best True lr [0.001]
training epoch 2 val accuracy 0.9664 topk_dict {'top1': 0.9664} is_best False lr [0.001]
training epoch 3 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.001]
training epoch 4 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best True lr [0.001]
training epoch 5 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best True lr [0.001]
training epoch 6 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best True lr [0.001]
training epoch 7 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 8 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 9 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best True lr [0.001]
training epoch 10 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 11 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 12 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 13 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 14 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 15 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best True lr [0.001]
training epoch 16 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 17 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 18 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 19 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 20 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 21 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 22 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 23 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 24 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 25 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 26 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 27 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 28 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 29 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 30 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 31 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 32 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 33 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 34 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 35 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 36 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 37 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 38 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 39 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best False lr [0.001]
training epoch 40 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 41 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 42 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 43 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 44 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 45 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 46 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 47 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 48 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 49 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.984400)
finished training. finished 50 epochs. accuracy 0.9844 topk_dict {'top1': 0.9844}
start iteration 33
[activation mean]: block to remove picked: 0, with score 0.175999. All blocks and scores: [(0, 0.1759993378072977), (2, 0.1841158326715231), (14, 0.18975303322076797), (6, 0.1910600233823061), (1, 0.19126569665968418), (8, 0.20803295448422432), (38, 0.21221712417900562), (39, 0.2149827927350998), (37, 0.22229108214378357), (12, 0.2280900925397873), (10, 0.22885475121438503), (49, 0.23214193992316723), (47, 0.23311990313231945), (50, 0.24128702096641064), (19, 0.24274227395653725), (5, 0.25315209850668907), (51, 0.2682034447789192), (52, 0.28642336651682854), (18, 0.5196255296468735), (36, 0.5256513059139252), (53, 0.6573586910963058)]
computing accuracy for after removing block 0 . block score: 0.1759993378072977
removed block 0 current accuracy 0.9706 loss from initial  0.02939999999999998
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 6, with score 0.186710. All blocks and scores: [(6, 0.18670991994440556), (14, 0.19223077781498432), (2, 0.19444860890507698), (8, 0.20358170196413994), (1, 0.20367636531591415), (38, 0.21187689900398254), (39, 0.21548451483249664), (37, 0.22155661694705486), (10, 0.22353739477694035), (12, 0.22797776758670807), (49, 0.2304193414747715), (47, 0.23210282437503338), (50, 0.23807039111852646), (19, 0.24135190807282925), (5, 0.2453297283500433), (51, 0.2624916322529316), (52, 0.2836439907550812), (36, 0.5214147120714188), (18, 0.5262342244386673), (53, 0.6667095646262169)]
computing accuracy for after removing block 6 . block score: 0.18670991994440556
removed block 6 current accuracy 0.9404 loss from initial  0.059599999999999986
since last training loss: 0.04400000000000004 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 14, with score 0.182641. All blocks and scores: [(14, 0.1826410572975874), (2, 0.19444860890507698), (1, 0.20367636531591415), (8, 0.20573258213698864), (38, 0.20752381347119808), (39, 0.21004253067076206), (37, 0.21560559794306755), (12, 0.22221527621150017), (49, 0.22329984419047832), (47, 0.22780740819871426), (10, 0.23030493594706059), (50, 0.23118886165320873), (19, 0.23708032816648483), (5, 0.2453297283500433), (51, 0.2556229569017887), (52, 0.2769654728472233), (36, 0.5144139975309372), (18, 0.5172551721334457), (53, 0.6725725457072258)]
computing accuracy for after removing block 14 . block score: 0.1826410572975874
removed block 14 current accuracy 0.8498 loss from initial  0.1502
since last training loss: 0.13460000000000005 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 2, with score 0.194449. All blocks and scores: [(2, 0.19444860890507698), (39, 0.20101883634924889), (1, 0.20367636531591415), (38, 0.20441925525665283), (8, 0.20573258213698864), (37, 0.2098952978849411), (49, 0.21748971566557884), (50, 0.21969533152878284), (12, 0.22221527621150017), (10, 0.23030493594706059), (47, 0.23058555275201797), (19, 0.23566716723144054), (5, 0.2453297283500433), (51, 0.25164826959371567), (52, 0.2725784108042717), (36, 0.5115930438041687), (18, 0.5249538570642471), (53, 0.6857951581478119)]
computing accuracy for after removing block 2 . block score: 0.19444860890507698
removed block 2 current accuracy 0.7806 loss from initial  0.21940000000000004
since last training loss: 0.2038000000000001 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 37, with score 0.192108. All blocks and scores: [(37, 0.19210758432745934), (39, 0.19302788190543652), (38, 0.1948818303644657), (1, 0.20367636531591415), (50, 0.20606187917292118), (8, 0.20672296732664108), (49, 0.20881417952477932), (12, 0.21267100237309933), (47, 0.22775769233703613), (19, 0.2286700624972582), (10, 0.23902591690421104), (51, 0.24710148945450783), (5, 0.2482684012502432), (52, 0.2648634761571884), (36, 0.49415817111730576), (18, 0.5040346086025238), (53, 0.6927082762122154)]
computing accuracy for after removing block 37 . block score: 0.19210758432745934
removed block 37 current accuracy 0.7248 loss from initial  0.2752
since last training loss: 0.25960000000000005 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 39, with score 0.191814. All blocks and scores: [(39, 0.19181367941200733), (50, 0.19920730590820312), (49, 0.20267155580222607), (1, 0.20367636531591415), (8, 0.20672296732664108), (12, 0.21267100237309933), (38, 0.21348875015974045), (47, 0.22152480483055115), (19, 0.2286700624972582), (10, 0.23902591690421104), (51, 0.2465271521359682), (5, 0.2482684012502432), (52, 0.2607336491346359), (36, 0.49415817111730576), (18, 0.5040346086025238), (53, 0.6916760727763176)]
computing accuracy for after removing block 39 . block score: 0.19181367941200733
removed block 39 current accuracy 0.6142 loss from initial  0.38580000000000003
since last training loss: 0.3702000000000001 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 50, with score 0.195031. All blocks and scores: [(50, 0.19503080658614635), (49, 0.19994257390499115), (1, 0.20367636531591415), (8, 0.20672296732664108), (12, 0.21267100237309933), (38, 0.21348875015974045), (47, 0.22133359871804714), (19, 0.2286700624972582), (10, 0.23902591690421104), (51, 0.2434951327741146), (5, 0.2482684012502432), (52, 0.2549651116132736), (36, 0.49415817111730576), (18, 0.5040346086025238), (53, 0.7260772883892059)]
computing accuracy for after removing block 50 . block score: 0.19503080658614635
removed block 50 current accuracy 0.5576 loss from initial  0.4424
since last training loss: 0.42680000000000007 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 49, with score 0.199943. All blocks and scores: [(49, 0.19994257390499115), (1, 0.20367636531591415), (8, 0.20672296732664108), (12, 0.21267100237309933), (38, 0.21348875015974045), (47, 0.22133359871804714), (19, 0.2286700624972582), (51, 0.2361200898885727), (10, 0.23902591690421104), (5, 0.2482684012502432), (52, 0.25354090332984924), (36, 0.49415817111730576), (18, 0.5040346086025238), (53, 0.8570913374423981)]
computing accuracy for after removing block 49 . block score: 0.19994257390499115
removed block 49 current accuracy 0.4602 loss from initial  0.5398000000000001
since last training loss: 0.5242 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 1, with score 0.203676. All blocks and scores: [(1, 0.20367636531591415), (8, 0.20672296732664108), (12, 0.21267100237309933), (38, 0.21348875015974045), (51, 0.218984954059124), (47, 0.22133359871804714), (19, 0.2286700624972582), (10, 0.23902591690421104), (5, 0.2482684012502432), (52, 0.24921302683651447), (36, 0.49415817111730576), (18, 0.5040346086025238), (53, 0.9966378733515739)]
computing accuracy for after removing block 1 . block score: 0.20367636531591415
removed block 1 current accuracy 0.2698 loss from initial  0.7302
since last training loss: 0.7146000000000001 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 8, with score 0.199457. All blocks and scores: [(8, 0.19945680908858776), (12, 0.2087100949138403), (38, 0.21173230931162834), (51, 0.21953623183071613), (19, 0.22305757738649845), (47, 0.22512132301926613), (10, 0.23663060553371906), (5, 0.24291293695569038), (52, 0.24415398389101028), (36, 0.5012524388730526), (18, 0.5181690752506256), (53, 1.0876374542713165)]
computing accuracy for after removing block 8 . block score: 0.19945680908858776
removed block 8 current accuracy 0.2038 loss from initial  0.7962
since last training loss: 0.7806000000000001 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 47, with score 0.205071. All blocks and scores: [(47, 0.20507105067372322), (51, 0.21750542148947716), (38, 0.21969305351376534), (12, 0.23121121525764465), (19, 0.23951164819300175), (5, 0.24291293695569038), (52, 0.2564990036189556), (10, 0.2761493809521198), (36, 0.5179276540875435), (18, 0.5474818423390388), (53, 1.1583686023950577)]
computing accuracy for after removing block 47 . block score: 0.20507105067372322
removed block 47 current accuracy 0.1816 loss from initial  0.8184
since last training loss: 0.8028000000000001 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 51, with score 0.210717. All blocks and scores: [(51, 0.21071711741387844), (38, 0.21969305351376534), (12, 0.23121121525764465), (19, 0.23951164819300175), (5, 0.24291293695569038), (52, 0.27062444761395454), (10, 0.2761493809521198), (36, 0.5179276540875435), (18, 0.5474818423390388), (53, 1.222929060459137)]
computing accuracy for after removing block 51 . block score: 0.21071711741387844
removed block 51 current accuracy 0.1432 loss from initial  0.8568
training start
training epoch 0 val accuracy 0.8396 topk_dict {'top1': 0.8396} is_best True lr [0.001]
training epoch 1 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.001]
training epoch 2 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.001]
training epoch 3 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 4 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.001]
training epoch 5 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 6 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 7 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 8 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 9 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.001]
training epoch 10 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 11 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 12 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 13 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 14 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 15 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 16 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 17 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 18 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 19 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 20 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 21 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 22 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 23 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 24 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 25 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 26 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 27 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 29 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 30 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 31 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 33 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 35 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 38 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 39 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 40 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 41 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 42 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 44 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 45 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 46 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 47 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 48 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.932800)
finished training. finished 50 epochs. accuracy 0.9328 topk_dict {'top1': 0.9328}
