start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451975252479315), (20, 0.00869624805636704), (27, 0.00919829506892711), (31, 0.00967550405766815), (29, 0.010030421079136431), (22, 0.010588386212475598), (23, 0.010651617893017828), (21, 0.01072535093408078), (28, 0.011828800081275403), (24, 0.012058728374540806), (17, 0.012199450400657952), (19, 0.013177948771044612), (33, 0.013279787148348987), (35, 0.013483816524967551), (25, 0.013839342398568988), (11, 0.013912908965721726), (32, 0.013956585200503469), (16, 0.014766237698495388), (30, 0.01549160503782332), (9, 0.015547690447419882), (40, 0.015986334532499313), (34, 0.016656321939080954), (39, 0.017517176689580083), (44, 0.018641566624864936), (37, 0.01879900461062789), (43, 0.018935034750029445), (42, 0.0195143383461982), (41, 0.019590020878240466), (45, 0.019901464693248272), (38, 0.02000095834955573), (14, 0.020047535188496113), (8, 0.021667920518666506), (7, 0.021806211210787296), (15, 0.024833296658471227), (46, 0.02521279128268361), (10, 0.02590036136098206), (49, 0.027116775745525956), (48, 0.027511440683156252), (47, 0.02782087866216898), (50, 0.0287232450209558), (51, 0.03178879711776972), (12, 0.03298327047377825), (5, 0.03333624359220266), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.04374718386679888), (52, 0.052534043323248625), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.2727429270744324), (18, 0.30386047810316086), (53, 0.8891633003950119)]
computing accuracy for after removing block 26 . block score: 0.007451975252479315
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.00869624805636704), (27, 0.009569327346980572), (31, 0.009736894629895687), (29, 0.010370098403654993), (22, 0.010588386445306242), (23, 0.010651617893017828), (21, 0.010725351050496101), (24, 0.012058728141710162), (28, 0.012067585834302008), (17, 0.012199450633488595), (19, 0.013177948305383325), (33, 0.013200338347814977), (35, 0.013297738856635988), (32, 0.013540125917643309), (25, 0.013839341816492379), (11, 0.013912909547798336), (16, 0.014766237582080066), (30, 0.015476006898097694), (9, 0.015547690447419882), (34, 0.01633565337397158), (40, 0.016489707864820957), (39, 0.01815172960050404), (44, 0.018809265457093716), (43, 0.019272045698016882), (37, 0.019370622467249632), (41, 0.019797630375251174), (42, 0.019846386974677444), (14, 0.020047535421326756), (38, 0.02020833152346313), (45, 0.02028216910548508), (8, 0.021667920285835862), (7, 0.021806209813803434), (15, 0.024833297124132514), (46, 0.025710681220516562), (10, 0.02590036136098206), (49, 0.02717575617134571), (48, 0.027807614067569375), (47, 0.028269683476537466), (50, 0.028723404742777348), (51, 0.03195985872298479), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.03804349433630705), (3, 0.04374718386679888), (52, 0.05266197444871068), (13, 0.054503359366208315), (2, 0.06120603624731302), (1, 0.07061250880360603), (0, 0.14636892266571522), (36, 0.2777215614914894), (18, 0.30386047810316086), (53, 0.8825649991631508)]
computing accuracy for after removing block 20 . block score: 0.00869624805636704
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.00924707145895809), (31, 0.0094903550343588), (29, 0.0101414694217965), (23, 0.010720769292674959), (21, 0.010873694671317935), (22, 0.010951439966447651), (28, 0.011602518148720264), (17, 0.012199450633488595), (24, 0.012428545043803751), (33, 0.013006685650907457), (32, 0.013030687579885125), (35, 0.013141493545845151), (19, 0.013177949003875256), (11, 0.013912908965721726), (25, 0.014337054686620831), (30, 0.014731099014170468), (16, 0.014766237582080066), (9, 0.01554769033100456), (34, 0.01595074194483459), (40, 0.016676967265084386), (39, 0.018123318906873465), (44, 0.019042733358219266), (43, 0.019525704672560096), (37, 0.01953594759106636), (41, 0.020023913588374853), (42, 0.020024611614644527), (14, 0.020047535886988044), (38, 0.020229951245710254), (45, 0.020495346747338772), (8, 0.02166792075149715), (7, 0.02180621027946472), (15, 0.024833296658471227), (10, 0.02590036136098206), (46, 0.02600882132537663), (49, 0.027358209947124124), (48, 0.02794406423345208), (47, 0.02855871245265007), (50, 0.02887403196655214), (51, 0.03197578340768814), (12, 0.03298327000811696), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.03804349433630705), (3, 0.043747182469815016), (52, 0.05319312773644924), (13, 0.05450336029753089), (2, 0.061206035781651735), (1, 0.07061250600963831), (0, 0.14636891894042492), (36, 0.27894822880625725), (18, 0.30386047810316086), (53, 0.874676525592804)]
computing accuracy for after removing block 27 . block score: 0.00924707145895809
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703439893200994), (29, 0.01040199410635978), (23, 0.01072076940909028), (21, 0.010873694671317935), (22, 0.010951439617201686), (28, 0.011904270271770656), (17, 0.012199451331980526), (24, 0.01242854492738843), (33, 0.012989282491616905), (35, 0.013032012851908803), (32, 0.013032321468926966), (19, 0.013177948887459934), (11, 0.013912908732891083), (25, 0.014337054220959544), (30, 0.014530949643813074), (16, 0.014766237582080066), (34, 0.015523916110396385), (9, 0.01554769033100456), (40, 0.017428283812478185), (39, 0.01863569999113679), (44, 0.019323375774547458), (43, 0.01989502157084644), (14, 0.0200475356541574), (37, 0.020162817556411028), (38, 0.020197829697281122), (42, 0.020295765018090606), (41, 0.020331317326053977), (45, 0.02073849458247423), (8, 0.02166792075149715), (7, 0.021806210512295365), (15, 0.024833296425640583), (10, 0.025900361128151417), (46, 0.026298312237486243), (49, 0.027372206561267376), (48, 0.02811374608427286), (47, 0.02882404252886772), (50, 0.029082485707476735), (51, 0.032043973449617624), (12, 0.03298327047377825), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718479812145), (52, 0.053347038105130196), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250880360603), (0, 0.14636891894042492), (36, 0.2865508459508419), (18, 0.30386047437787056), (53, 0.873922660946846)]
computing accuracy for after removing block 31 . block score: 0.009703439893200994
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401993989944458), (23, 0.01072076940909028), (21, 0.0108736950205639), (22, 0.010951439617201686), (28, 0.011904270155355334), (17, 0.012199450749903917), (24, 0.012428545043803751), (33, 0.01307527325116098), (19, 0.013177948538213968), (32, 0.013221941189840436), (35, 0.013311224873177707), (11, 0.01391290919855237), (25, 0.014337054919451475), (30, 0.014530949876643717), (16, 0.01476623781491071), (34, 0.015109014348126948), (9, 0.015547690563835204), (40, 0.017963847843930125), (44, 0.019172759959474206), (39, 0.019229266792535782), (38, 0.0196272493340075), (43, 0.01977342227473855), (42, 0.020014989655464888), (14, 0.02004753495566547), (41, 0.020369443111121655), (45, 0.020458239829167724), (37, 0.020535161951556802), (8, 0.021667920518666506), (7, 0.02180621027946472), (15, 0.024833296425640583), (10, 0.025900360895320773), (46, 0.026439890265464783), (49, 0.027319708839058876), (48, 0.028306722873821855), (47, 0.02865198301151395), (50, 0.0292887045070529), (51, 0.032143964897841215), (12, 0.032983269076794386), (5, 0.03333624452352524), (6, 0.03351968387141824), (4, 0.0380434924736619), (3, 0.04374718386679888), (52, 0.05252913758158684), (13, 0.05450336169451475), (2, 0.06120603531599045), (1, 0.07061250507831573), (0, 0.14636892080307007), (36, 0.29571831226348877), (18, 0.30386047437787056), (53, 0.8852703869342804)]
computing accuracy for after removing block 29 . block score: 0.010401993989944458
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.010720769059844315), (21, 0.010873694671317935), (22, 0.01095143985003233), (28, 0.011904270038940012), (17, 0.01219945086631924), (24, 0.012428545276634395), (33, 0.013095533824525774), (19, 0.013177948305383325), (32, 0.013331791153177619), (35, 0.013342681690119207), (11, 0.013912908849306405), (25, 0.014337054803036153), (16, 0.014766237931326032), (34, 0.01478062616661191), (30, 0.014848081511445343), (9, 0.01554769033100456), (40, 0.017947440268471837), (44, 0.018570147920399904), (38, 0.018818871583789587), (39, 0.01928418455645442), (42, 0.01955016772262752), (43, 0.019667527172714472), (41, 0.020019967341795564), (14, 0.02004753495566547), (45, 0.02014507818967104), (37, 0.020778113743290305), (8, 0.021667921217158437), (7, 0.021806211676448584), (15, 0.02483329689130187), (10, 0.02590036136098206), (46, 0.026351965265348554), (49, 0.026999606285244226), (48, 0.027823996962979436), (47, 0.028508094139397144), (50, 0.02933459240011871), (51, 0.032171768601983786), (12, 0.03298326954245567), (5, 0.03333624266088009), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.04374718340113759), (52, 0.05190546531230211), (13, 0.0545033598318696), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636891894042492), (36, 0.299510408192873), (18, 0.30386047065258026), (53, 0.896213985979557)]
computing accuracy for after removing block 23 . block score: 0.010720769059844315
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.010873694787733257), (22, 0.01095143985003233), (28, 0.011454624123871326), (24, 0.011984122917056084), (17, 0.01219945086631924), (35, 0.013001650921069086), (32, 0.013018106226809323), (33, 0.013115601381286979), (19, 0.01317794865462929), (25, 0.013824696419760585), (11, 0.013912908500060439), (30, 0.014240248245187104), (34, 0.014703377382829785), (16, 0.014766237698495388), (9, 0.015547690214589238), (40, 0.018065203446894884), (44, 0.01830046600662172), (38, 0.018600984243676066), (42, 0.019345170818269253), (43, 0.019551129080355167), (39, 0.019822366070002317), (45, 0.019911038223654032), (41, 0.020028739469125867), (14, 0.020047535886988044), (37, 0.020847720094025135), (8, 0.021667920984327793), (7, 0.02180621074512601), (15, 0.024833297124132514), (10, 0.02590036136098206), (46, 0.026478100568056107), (49, 0.026978093199431896), (48, 0.027518168091773987), (47, 0.028530239826068282), (50, 0.02908505918458104), (51, 0.03238660283386707), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.033519684337079525), (4, 0.03804349293932319), (3, 0.04374718479812145), (52, 0.05187077587470412), (13, 0.05450336076319218), (2, 0.06120603671297431), (1, 0.07061250973492861), (0, 0.14636892080307007), (36, 0.3020646683871746), (18, 0.30386047437787056), (53, 0.8938302919268608)]
computing accuracy for after removing block 21 . block score: 0.010873694787733257
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718231438659132), (22, 0.011124414973892272), (24, 0.011734541854821146), (17, 0.012199450167827308), (32, 0.012339044129475951), (35, 0.012350354576483369), (33, 0.012773356051184237), (19, 0.013177948887459934), (30, 0.013385719619691372), (25, 0.013581673614680767), (11, 0.013912909547798336), (34, 0.014493828755803406), (16, 0.01476623781491071), (9, 0.015547690563835204), (40, 0.018178854137659073), (44, 0.018340062815696), (38, 0.01862968597561121), (42, 0.019575109239667654), (43, 0.01972984056919813), (39, 0.019833360565826297), (14, 0.020047535886988044), (45, 0.0200941888615489), (41, 0.02073429198935628), (37, 0.020795797929167747), (8, 0.02166792075149715), (7, 0.021806210046634078), (15, 0.024833296425640583), (10, 0.02590036136098206), (46, 0.027196240611374378), (49, 0.027292133308947086), (48, 0.02760020410642028), (47, 0.0289066256955266), (50, 0.029168642358854413), (51, 0.03279080893844366), (12, 0.03298326954245567), (5, 0.03333624452352524), (6, 0.03351968294009566), (4, 0.03804349293932319), (3, 0.04374718479812145), (52, 0.052345536183565855), (13, 0.0545033598318696), (2, 0.06120603485032916), (1, 0.07061250600963831), (0, 0.14636892080307007), (18, 0.30386047810316086), (36, 0.304229024797678), (53, 0.8967952877283096)]
computing accuracy for after removing block 28 . block score: 0.010718231438659132
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 5 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.012272. All blocks and scores: [(22, 0.012272489839233458), (17, 0.012404666165821254), (24, 0.01353867829311639), (33, 0.013658269075676799), (19, 0.013814246747642756), (11, 0.01387299585621804), (35, 0.01423407660331577), (25, 0.014258366893045604), (16, 0.014586719800718129), (32, 0.01510828931350261), (9, 0.015552886528894305), (40, 0.016146832145750523), (30, 0.017273859353736043), (39, 0.01753137423656881), (34, 0.01777127245441079), (43, 0.01858136709779501), (44, 0.018619044683873653), (37, 0.01862754230387509), (41, 0.019036119105294347), (42, 0.01916647609323263), (45, 0.01958186225965619), (38, 0.01985524268820882), (14, 0.01997542683966458), (8, 0.021777695510536432), (7, 0.021873892983421683), (15, 0.025139249162748456), (46, 0.025397328194230795), (10, 0.02629879442974925), (49, 0.026936066104099154), (47, 0.027384038781747222), (48, 0.027495315298438072), (50, 0.029023868963122368), (51, 0.031041920417919755), (5, 0.032820303458720446), (12, 0.03309058537706733), (6, 0.03367235464975238), (4, 0.0383609589189291), (3, 0.04364506481215358), (52, 0.050067595206201077), (13, 0.05478418571874499), (2, 0.05970461340621114), (1, 0.06998803652822971), (0, 0.1448554564267397), (36, 0.2691277228295803), (18, 0.301427461206913), (53, 0.8851554840803146)]
computing accuracy for after removing block 22 . block score: 0.012272489839233458
removed block 22 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 17, with score 0.012405. All blocks and scores: [(17, 0.01240466651506722), (24, 0.012478015036322176), (33, 0.013161159353330731), (35, 0.013569376314990222), (25, 0.01374772994313389), (32, 0.01375040807761252), (19, 0.013814247213304043), (11, 0.01387299585621804), (16, 0.014586720266379416), (9, 0.015552886528894305), (40, 0.016120255226269364), (30, 0.016251784283667803), (34, 0.017083083977922797), (39, 0.017726252786815166), (44, 0.01818900043144822), (43, 0.018192502669990063), (37, 0.018368498887866735), (42, 0.018834353890269995), (45, 0.01926987082697451), (41, 0.01928062434308231), (38, 0.01951103867031634), (14, 0.019975427072495222), (8, 0.021777695044875145), (7, 0.021873892983421683), (15, 0.025139248929917812), (46, 0.02552417805418372), (10, 0.02629879442974925), (49, 0.02707515354268253), (48, 0.027501052245497704), (47, 0.027608680771663785), (50, 0.028815065510571003), (51, 0.031317732064053416), (5, 0.03282030252739787), (12, 0.0330905863083899), (6, 0.03367235464975238), (4, 0.03836095938459039), (3, 0.04364506481215358), (52, 0.050199808552861214), (13, 0.05478418432176113), (2, 0.059704613871872425), (1, 0.06998803745955229), (0, 0.1448554527014494), (36, 0.26728853955864906), (18, 0.3014274649322033), (53, 0.8938969895243645)]
computing accuracy for after removing block 17 . block score: 0.01240466651506722
removed block 17 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 24, with score 0.012435. All blocks and scores: [(24, 0.012434921110980213), (33, 0.012696516467258334), (19, 0.012762396247126162), (25, 0.01293638814240694), (35, 0.013378426898270845), (32, 0.013548213406465948), (11, 0.013872996089048684), (16, 0.014586719451472163), (30, 0.015303428168408573), (9, 0.015552886528894305), (34, 0.016228314489126205), (40, 0.01653897506184876), (43, 0.018033312167972326), (39, 0.018094185506924987), (44, 0.018247614381834865), (37, 0.018349668942391872), (42, 0.018383880145847797), (45, 0.018962294328957796), (38, 0.019160420168191195), (41, 0.019522014539688826), (14, 0.019975427305325866), (8, 0.021777695743367076), (7, 0.021873893681913614), (15, 0.02513924869708717), (46, 0.02578778169117868), (10, 0.026298794662579894), (49, 0.02711966005153954), (47, 0.02729016146622598), (48, 0.027406467823311687), (50, 0.02857366483658552), (51, 0.03074013441801071), (5, 0.03282030299305916), (12, 0.033090585842728615), (6, 0.03367235558107495), (4, 0.0383609589189291), (3, 0.043645063880831), (52, 0.0493359905667603), (13, 0.05478418665006757), (2, 0.05970461340621114), (1, 0.06998803652822971), (0, 0.1448554527014494), (36, 0.27141693234443665), (18, 0.30815570428967476), (53, 0.8816864714026451)]
computing accuracy for after removing block 24 . block score: 0.012434921110980213
removed block 24 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 33, with score 0.012458. All blocks and scores: [(33, 0.012457701377570629), (32, 0.01267176796682179), (25, 0.012723042629659176), (19, 0.012762396479956806), (35, 0.012921652058139443), (11, 0.01387299585621804), (30, 0.014206542866304517), (16, 0.014586719102226198), (9, 0.015552886412478983), (34, 0.015751182450912893), (40, 0.01679094205610454), (43, 0.0183901556301862), (42, 0.018449721857905388), (44, 0.018459146609529853), (38, 0.01851098402403295), (37, 0.018594000721350312), (39, 0.018773414893075824), (45, 0.018973048077896237), (41, 0.019707394763827324), (14, 0.019975427072495222), (8, 0.021777695044875145), (7, 0.021873892983421683), (15, 0.02513924869708717), (46, 0.025976849952712655), (10, 0.02629879373125732), (49, 0.026934639317914844), (48, 0.02719693980179727), (47, 0.02719705179333687), (50, 0.028223928529769182), (51, 0.030643603298813105), (5, 0.03282030299305916), (12, 0.03309058444574475), (6, 0.033672355115413666), (4, 0.0383609589189291), (3, 0.04364506434649229), (52, 0.04850218445062637), (13, 0.05478418618440628), (2, 0.05970461294054985), (1, 0.06998803466558456), (0, 0.1448554527014494), (36, 0.27649274095892906), (18, 0.30815570428967476), (53, 0.8801731839776039)]
computing accuracy for after removing block 33 . block score: 0.012457701377570629
removed block 33 current accuracy 0.9906 loss from initial  0.009399999999999964
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 32, with score 0.012672. All blocks and scores: [(32, 0.01267176796682179), (25, 0.01272304228041321), (19, 0.012762396363541484), (35, 0.013685582438483834), (11, 0.013872995739802718), (30, 0.01420654309913516), (16, 0.014586719451472163), (34, 0.015454153879545629), (9, 0.015552885713987052), (40, 0.016185784712433815), (38, 0.016690852819010615), (43, 0.01731229107826948), (37, 0.017472850624471903), (44, 0.017513466766104102), (42, 0.017758908914402127), (45, 0.017910888884216547), (39, 0.01803036662749946), (41, 0.018796264193952084), (14, 0.019975427305325866), (8, 0.021777695743367076), (7, 0.021873892983421683), (15, 0.0251392493955791), (46, 0.0251607159152627), (47, 0.02623572526499629), (48, 0.026279172161594033), (10, 0.026298794662579894), (49, 0.02673116698861122), (50, 0.02761036017909646), (51, 0.03019869071431458), (5, 0.032820302061736584), (12, 0.033090585842728615), (6, 0.033672353718429804), (4, 0.038360959850251675), (3, 0.04364506434649229), (52, 0.04646905371919274), (13, 0.05478418478742242), (2, 0.059704612009227276), (1, 0.06998803839087486), (0, 0.14485545456409454), (36, 0.2735934928059578), (18, 0.30815570801496506), (53, 0.9093348905444145)]
computing accuracy for after removing block 32 . block score: 0.01267176796682179
removed block 32 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.012723. All blocks and scores: [(25, 0.012723042629659176), (19, 0.012762396479956806), (11, 0.013872996554709971), (30, 0.014206542749889195), (16, 0.014586719451472163), (35, 0.014615151449106634), (34, 0.015271987300366163), (9, 0.015552886412478983), (38, 0.015750283026136458), (40, 0.016336187487468123), (43, 0.016882706666365266), (44, 0.016886887373402715), (37, 0.017101830570027232), (42, 0.01740918681025505), (45, 0.017580764601007104), (39, 0.018068132689222693), (41, 0.0183586273342371), (14, 0.01997542683966458), (8, 0.02177769527770579), (7, 0.02187389275059104), (15, 0.025139249162748456), (46, 0.025192302884534), (48, 0.02610134775750339), (47, 0.026227589696645737), (10, 0.026298794196918607), (49, 0.026622232981026173), (50, 0.027311398182064295), (51, 0.029881033347919583), (5, 0.032820303458720446), (12, 0.0330905863083899), (6, 0.03367235418409109), (4, 0.038360959850251675), (3, 0.043645063880831), (52, 0.04493099870160222), (13, 0.054784185253083706), (2, 0.05970461247488856), (1, 0.06998803745955229), (0, 0.1448554527014494), (36, 0.2799932062625885), (18, 0.30815569683909416), (53, 0.9292202815413475)]
computing accuracy for after removing block 25 . block score: 0.012723042629659176
removed block 25 current accuracy 0.9644 loss from initial  0.035599999999999965
since last training loss: 0.035599999999999965 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 19, with score 0.012762. All blocks and scores: [(19, 0.012762396945618093), (11, 0.013872995739802718), (30, 0.014101124135777354), (35, 0.014169101137667894), (16, 0.014586719800718129), (34, 0.015161182847805321), (38, 0.015371936606243253), (9, 0.015552886412478983), (40, 0.016840552911162376), (43, 0.016892382176592946), (42, 0.01689677289687097), (44, 0.016915131825953722), (37, 0.017611465184018016), (45, 0.017739878967404366), (41, 0.018525433028116822), (39, 0.019451444502919912), (14, 0.019975428003817797), (8, 0.021777695044875145), (7, 0.021873893914744258), (46, 0.02486132550984621), (15, 0.025139248464256525), (48, 0.026069013634696603), (47, 0.026138025801628828), (10, 0.02629879442974925), (49, 0.026473959675058722), (50, 0.026656337780877948), (51, 0.02951919799670577), (5, 0.03282030392438173), (12, 0.0330905863083899), (6, 0.033672355115413666), (4, 0.038360959850251675), (52, 0.04288705252110958), (3, 0.04364506434649229), (13, 0.05478418758139014), (2, 0.05970461247488856), (1, 0.06998803745955229), (0, 0.1448554564267397), (36, 0.29076095670461655), (18, 0.30815570801496506), (53, 0.9275700375437737)]
computing accuracy for after removing block 19 . block score: 0.012762396945618093
removed block 19 current accuracy 0.9512 loss from initial  0.048799999999999955
since last training loss: 0.048799999999999955 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 30, with score 0.013842. All blocks and scores: [(30, 0.013842420652508736), (11, 0.013872996321879327), (35, 0.014239715761505067), (16, 0.014586719567887485), (34, 0.01479075604584068), (38, 0.015384871046990156), (9, 0.015552886063233018), (44, 0.017082195496186614), (43, 0.01725469809025526), (42, 0.017377468524500728), (40, 0.017685106955468655), (37, 0.017845498863607645), (45, 0.01829601195640862), (41, 0.018870503408834338), (39, 0.019802798982709646), (14, 0.019975427072495222), (8, 0.021777695510536432), (7, 0.02187389275059104), (46, 0.02502449252642691), (15, 0.025139248464256525), (10, 0.026298794196918607), (48, 0.02639580308459699), (47, 0.02647393522784114), (49, 0.026650101179257035), (50, 0.026684742886573076), (51, 0.029579700902104378), (5, 0.032820303458720446), (12, 0.033090585842728615), (6, 0.033672355115413666), (4, 0.03836096031591296), (52, 0.04230240313336253), (3, 0.04364506574347615), (13, 0.05478418432176113), (2, 0.0597046110779047), (1, 0.06998803745955229), (0, 0.14485545083880424), (36, 0.30314937233924866), (18, 0.30815570428967476), (53, 0.928649976849556)]
computing accuracy for after removing block 30 . block score: 0.013842420652508736
removed block 30 current accuracy 0.9054 loss from initial  0.09460000000000002
training start
training epoch 0 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 1 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 2 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 3 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 4 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 5 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 6 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 7 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 8 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 9 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 10 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 11 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 12 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 15 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 16 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 17 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 19 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 20 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 21 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 24 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 25 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 26 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 27 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 28 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 30 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 32 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 33 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 34 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 35 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 36 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 37 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 38 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 39 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 40 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 41 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 42 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 43 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 44 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 45 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 46 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 47 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 48 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 49 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.999000)
finished training. finished 50 epochs. accuracy 0.999 topk_dict {'top1': 0.999}
start iteration 16
[activation diff]: block to remove picked: 11, with score 0.014605. All blocks and scores: [(11, 0.014604896656237543), (9, 0.015710953157395124), (40, 0.016203398816287518), (16, 0.017052690032869577), (39, 0.01760061038658023), (44, 0.018118380568921566), (43, 0.018225058680400252), (41, 0.01869973447173834), (42, 0.019001354463398457), (37, 0.019037218298763037), (45, 0.01942582498304546), (14, 0.01960546476766467), (38, 0.02020988496951759), (7, 0.02050458057783544), (8, 0.020842347061261535), (35, 0.022798188030719757), (46, 0.024130982579663396), (34, 0.024842635728418827), (49, 0.026300211437046528), (10, 0.026323418132960796), (47, 0.026685392949730158), (48, 0.026814625831320882), (15, 0.027793890796601772), (50, 0.02825088193640113), (51, 0.030664222314953804), (12, 0.03167525678873062), (5, 0.03177958959713578), (6, 0.03290957631543279), (4, 0.0381064061075449), (3, 0.04211925296112895), (52, 0.050354731269180775), (13, 0.054621031042188406), (2, 0.059612552635371685), (1, 0.06510118767619133), (0, 0.1392405740916729), (36, 0.26660555228590965), (18, 0.28911755979061127), (53, 0.8805363550782204)]
computing accuracy for after removing block 11 . block score: 0.014604896656237543
removed block 11 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 9, with score 0.015711. All blocks and scores: [(9, 0.015710953390225768), (40, 0.015963707817718387), (39, 0.017033219104632735), (16, 0.017485330579802394), (43, 0.017864475958049297), (44, 0.018097470747306943), (42, 0.018444691319018602), (37, 0.01850576465949416), (14, 0.018687762320041656), (41, 0.01880658441223204), (45, 0.019627782981842756), (38, 0.01990544470027089), (7, 0.02050457987934351), (8, 0.02084234682843089), (35, 0.022178993094712496), (34, 0.023992955219000578), (46, 0.02409400697797537), (48, 0.026249903487041593), (10, 0.026323418132960796), (47, 0.026378477457910776), (49, 0.026422482449561357), (15, 0.027771103894338012), (50, 0.027903527952730656), (12, 0.030083033023402095), (51, 0.030339043820276856), (5, 0.03177959006279707), (6, 0.0329095758497715), (4, 0.0381064061075449), (3, 0.042119253892451525), (52, 0.04980058781802654), (13, 0.052745632361620665), (2, 0.0596125521697104), (1, 0.0651011886075139), (0, 0.13924057222902775), (36, 0.26401932165026665), (18, 0.2816353403031826), (53, 0.8656767457723618)]
computing accuracy for after removing block 9 . block score: 0.015710953390225768
removed block 9 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 40, with score 0.015301. All blocks and scores: [(40, 0.015300840372219682), (39, 0.016115732956677675), (16, 0.016229094238951802), (14, 0.01716601406224072), (43, 0.01719359797425568), (37, 0.017624115804210305), (44, 0.017754425294697285), (42, 0.01781607326120138), (41, 0.019170412560924888), (45, 0.0192416338250041), (38, 0.01931606885045767), (7, 0.020504580112174153), (35, 0.020617952337488532), (8, 0.020842346595600247), (34, 0.023117756005376577), (46, 0.02365835034288466), (10, 0.024909403873607516), (48, 0.025440537137910724), (47, 0.025556011125445366), (49, 0.025926833739504218), (15, 0.027343405410647392), (50, 0.027477899100631475), (12, 0.029378316830843687), (51, 0.029559876769781113), (5, 0.03177959052845836), (6, 0.0329095758497715), (4, 0.038106406573206186), (3, 0.04211925435811281), (52, 0.04792684782296419), (13, 0.04838318470865488), (2, 0.05961255496367812), (1, 0.06510118674486876), (0, 0.13924057595431805), (36, 0.2577015124261379), (18, 0.27044468000531197), (53, 0.8703217431902885)]
computing accuracy for after removing block 40 . block score: 0.015300840372219682
removed block 40 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.016116. All blocks and scores: [(39, 0.016115733422338963), (16, 0.01622909470461309), (14, 0.01716601406224072), (37, 0.01762411603704095), (43, 0.017755991779267788), (44, 0.0182176623493433), (42, 0.018664679722860456), (45, 0.019307940965518355), (38, 0.01931606885045767), (7, 0.020504580112174153), (35, 0.020617953035980463), (41, 0.020753505174070597), (8, 0.02084234729409218), (34, 0.02311775740236044), (46, 0.024164437083527446), (10, 0.02490940294228494), (48, 0.02513173664920032), (47, 0.025599488522857428), (49, 0.0263427363242954), (15, 0.027343405410647392), (50, 0.028118242509663105), (12, 0.029378316132351756), (51, 0.030033630086109042), (5, 0.03177959006279707), (6, 0.032909574918448925), (4, 0.038106406573206186), (3, 0.04211925296112895), (52, 0.04744571913033724), (13, 0.048383185639977455), (2, 0.05961255310103297), (1, 0.06510118767619133), (0, 0.13924057222902775), (36, 0.2577015087008476), (18, 0.27044467255473137), (53, 0.8871970400214195)]
computing accuracy for after removing block 39 . block score: 0.016115733422338963
removed block 39 current accuracy 0.9884 loss from initial  0.011600000000000055
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 16, with score 0.016229. All blocks and scores: [(16, 0.016229094471782446), (14, 0.017166014295071363), (37, 0.01762411557137966), (43, 0.017848867690190673), (44, 0.018299278104677796), (38, 0.01931606885045767), (45, 0.01934755966067314), (42, 0.02017605910077691), (7, 0.02050457987934351), (35, 0.020617953035980463), (8, 0.020842346362769604), (41, 0.021544850431382656), (34, 0.023117755772545934), (46, 0.024428253760561347), (48, 0.02463405393064022), (10, 0.02490940340794623), (47, 0.025326233124360442), (49, 0.026510345982387662), (15, 0.027343406109139323), (50, 0.0279081747867167), (51, 0.029347764560952783), (12, 0.02937831706367433), (5, 0.03177959006279707), (6, 0.03290957631543279), (4, 0.038106406573206186), (3, 0.04211925435811281), (52, 0.04721069661900401), (13, 0.04838318703696132), (2, 0.059612554498016834), (1, 0.06510118767619133), (0, 0.13924057222902775), (36, 0.2577015049755573), (18, 0.27044467628002167), (53, 0.886464849114418)]
computing accuracy for after removing block 16 . block score: 0.016229094471782446
removed block 16 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 14, with score 0.017166. All blocks and scores: [(14, 0.017166014527902007), (37, 0.017376328352838755), (43, 0.017720432952046394), (44, 0.018308832542970777), (45, 0.01924260752275586), (38, 0.019370981957763433), (42, 0.01978870644234121), (35, 0.020009715110063553), (7, 0.02050457987934351), (8, 0.020842347061261535), (34, 0.02259360090829432), (41, 0.022873791167512536), (46, 0.023504768731072545), (48, 0.023945079650729895), (47, 0.02490758430212736), (10, 0.024909403873607516), (49, 0.025874997256323695), (50, 0.02699757949449122), (15, 0.02734340517781675), (51, 0.02809213474392891), (12, 0.02937831706367433), (5, 0.03177958959713578), (6, 0.03290957538411021), (4, 0.038106406573206186), (3, 0.04211925342679024), (52, 0.04508439777418971), (13, 0.04838318610563874), (2, 0.05961255403235555), (1, 0.0651011886075139), (0, 0.13924057595431805), (36, 0.25585877150297165), (18, 0.27479542791843414), (53, 0.8950993567705154)]
computing accuracy for after removing block 14 . block score: 0.017166014527902007
removed block 14 current accuracy 0.9612 loss from initial  0.038799999999999946
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 37, with score 0.017608. All blocks and scores: [(37, 0.017608100082725286), (43, 0.017646753462031484), (38, 0.018584073521196842), (44, 0.01892764843069017), (45, 0.019420595606788993), (42, 0.019524937262758613), (35, 0.019623879110440612), (7, 0.020504579646512866), (8, 0.020842346362769604), (34, 0.021547206677496433), (48, 0.023083331529051065), (41, 0.023374819429591298), (46, 0.023724454455077648), (47, 0.024235893273726106), (10, 0.024909403175115585), (49, 0.02586705074645579), (50, 0.02648243703879416), (51, 0.02721909456886351), (15, 0.02932473528198898), (12, 0.029378316830843687), (5, 0.03177958959713578), (6, 0.03290957538411021), (4, 0.038106406573206186), (3, 0.04211925249546766), (52, 0.042716088239103556), (13, 0.048383185639977455), (2, 0.05961255403235555), (1, 0.06510118674486876), (0, 0.1392405740916729), (36, 0.2672927565872669), (18, 0.289852786809206), (53, 0.8775651752948761)]
computing accuracy for after removing block 37 . block score: 0.017608100082725286
removed block 37 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05300000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 43, with score 0.017322. All blocks and scores: [(43, 0.017321954714134336), (44, 0.018193997908383608), (45, 0.01854575634934008), (35, 0.019623878877609968), (38, 0.019772518193349242), (42, 0.019836938939988613), (7, 0.020504580112174153), (8, 0.020842346595600247), (34, 0.021547206677496433), (48, 0.02175630978308618), (46, 0.02314159576781094), (47, 0.02324109384790063), (41, 0.023846245370805264), (49, 0.024612228153273463), (10, 0.02490940340794623), (50, 0.02503772242926061), (51, 0.025297452928498387), (15, 0.029324734350666404), (12, 0.029378316830843687), (5, 0.031779589131474495), (6, 0.0329095758497715), (4, 0.03810640750452876), (52, 0.03820815263316035), (3, 0.04211925435811281), (13, 0.048383185639977455), (2, 0.05961255496367812), (1, 0.06510118674486876), (0, 0.13924057222902775), (36, 0.2672927491366863), (18, 0.2898527830839157), (53, 0.9025383293628693)]
computing accuracy for after removing block 43 . block score: 0.017321954714134336
removed block 43 current accuracy 0.925 loss from initial  0.07499999999999996
training start
training epoch 0 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 1 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 2 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 3 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 4 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 5 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 6 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 7 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 8 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 9 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 10 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 11 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 12 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 13 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 14 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 15 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 16 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 17 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 18 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 19 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 20 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 21 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 22 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 23 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 25 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 26 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 27 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 28 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 29 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 30 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 31 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 32 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 33 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 34 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 35 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 36 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 37 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 38 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 39 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 40 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 41 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 42 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 43 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 44 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 45 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 46 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 47 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 48 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 49 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.997400)
finished training. finished 50 epochs. accuracy 0.9974 topk_dict {'top1': 0.9974}
start iteration 24
[activation diff]: block to remove picked: 44, with score 0.020921. All blocks and scores: [(44, 0.0209206179715693), (45, 0.021342046558856964), (7, 0.02192623377777636), (8, 0.02286102157086134), (42, 0.02302517113275826), (41, 0.023143709171563387), (46, 0.024960123235359788), (38, 0.0254128344822675), (35, 0.02557742432691157), (49, 0.02561261528171599), (48, 0.026537297060713172), (10, 0.026786541333422065), (47, 0.026908335741609335), (50, 0.027497606119140983), (34, 0.029118434293195605), (15, 0.02953374176286161), (51, 0.029842922696843743), (5, 0.03185308026149869), (12, 0.03248453699052334), (6, 0.03249185858294368), (4, 0.03917093761265278), (3, 0.040439882315695286), (52, 0.04998737806454301), (13, 0.0550844962708652), (2, 0.057977020274847746), (1, 0.0621106019243598), (0, 0.12958338297903538), (36, 0.25267959758639336), (18, 0.2732812613248825), (53, 0.905843660235405)]
computing accuracy for after removing block 44 . block score: 0.0209206179715693
removed block 44 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.021926. All blocks and scores: [(7, 0.021926233312115073), (8, 0.02286102157086134), (42, 0.02302517113275826), (41, 0.02314370940439403), (45, 0.023216419387608767), (38, 0.025412834249436855), (35, 0.025577424094080925), (49, 0.025852292543277144), (46, 0.026412123814225197), (48, 0.026671333936974406), (10, 0.026786540169268847), (47, 0.027431385358795524), (50, 0.027516677975654602), (34, 0.029118433594703674), (15, 0.029533741297200322), (51, 0.029553505359217525), (5, 0.03185308026149869), (12, 0.03248453792184591), (6, 0.03249185997992754), (4, 0.03917093621566892), (3, 0.040439881850034), (52, 0.047510862816125154), (13, 0.0550844962708652), (2, 0.057977018877863884), (1, 0.06211060006171465), (0, 0.12958338484168053), (36, 0.25267959386110306), (18, 0.2732812538743019), (53, 0.9749311208724976)]
computing accuracy for after removing block 7 . block score: 0.021926233312115073
removed block 7 current accuracy 0.9892 loss from initial  0.010800000000000032
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.021589. All blocks and scores: [(42, 0.021588581381365657), (8, 0.0222534432541579), (45, 0.0229615424759686), (41, 0.023399406112730503), (35, 0.024348950246348977), (38, 0.024516487726941705), (46, 0.02486847573891282), (49, 0.02504838234744966), (48, 0.025456855772063136), (10, 0.025808738311752677), (50, 0.026228227419778705), (47, 0.02668140479363501), (34, 0.0282572815194726), (15, 0.02844612067565322), (51, 0.028517174301669), (12, 0.030689535662531853), (5, 0.03185308026149869), (6, 0.03249185811728239), (4, 0.03917093621566892), (3, 0.04043988324701786), (52, 0.04537008423358202), (13, 0.05527728796005249), (2, 0.057977020274847746), (1, 0.062110599130392075), (0, 0.12958338670432568), (36, 0.2433867733925581), (18, 0.26231682673096657), (53, 0.9702036827802658)]
computing accuracy for after removing block 42 . block score: 0.021588581381365657
removed block 42 current accuracy 0.9816 loss from initial  0.018399999999999972
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 8, with score 0.022253. All blocks and scores: [(8, 0.022253443486988544), (45, 0.023232015315443277), (41, 0.02339940657839179), (35, 0.024348950712010264), (38, 0.02451648865826428), (46, 0.024821691447868943), (48, 0.025106048909947276), (49, 0.025168547872453928), (10, 0.025808738078922033), (50, 0.02616584929637611), (47, 0.027571255108341575), (51, 0.027649887604638934), (34, 0.028257282450795174), (15, 0.02844612067565322), (12, 0.030689535662531853), (5, 0.03185308072715998), (6, 0.03249186044558883), (4, 0.039170936681330204), (3, 0.040439881850034), (52, 0.04188152635470033), (13, 0.0552772874943912), (2, 0.05797701980918646), (1, 0.06211060285568237), (0, 0.12958338484168053), (36, 0.24338677525520325), (18, 0.26231682673096657), (53, 1.0686123073101044)]
computing accuracy for after removing block 8 . block score: 0.022253443486988544
removed block 8 current accuracy 0.9744 loss from initial  0.025599999999999956
since last training loss: 0.02299999999999991 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 45, with score 0.023120. All blocks and scores: [(45, 0.023119507590308785), (35, 0.02326980559155345), (41, 0.02340820152312517), (48, 0.024773375829681754), (46, 0.02481525857001543), (49, 0.025044457288458943), (50, 0.02527959761209786), (38, 0.025695443619042635), (51, 0.026769557502120733), (10, 0.026924118865281343), (47, 0.027748377760872245), (34, 0.028162041446194053), (15, 0.028695205692201853), (12, 0.031532119028270245), (5, 0.03185308165848255), (6, 0.032491859048604965), (4, 0.039170936681330204), (52, 0.04043679451569915), (3, 0.04043988138437271), (13, 0.05793610541149974), (2, 0.05797701980918646), (1, 0.06211059959605336), (0, 0.12958338484168053), (36, 0.24034111015498638), (18, 0.2603891007602215), (53, 1.0318161696195602)]
computing accuracy for after removing block 45 . block score: 0.023119507590308785
removed block 45 current accuracy 0.9572 loss from initial  0.04279999999999995
since last training loss: 0.0401999999999999 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 35, with score 0.023270. All blocks and scores: [(35, 0.02326980559155345), (41, 0.023408201755955815), (38, 0.025695444317534566), (50, 0.025977252051234245), (49, 0.026142729679122567), (48, 0.026275342097505927), (10, 0.026924118166789412), (51, 0.027051334735006094), (34, 0.02816204191185534), (46, 0.028382861521095037), (15, 0.02869520615786314), (47, 0.03026226069778204), (12, 0.03153211949393153), (5, 0.031853081192821264), (6, 0.032491859048604965), (4, 0.039170936681330204), (52, 0.039298735093325377), (3, 0.040439881850034), (13, 0.05793610634282231), (2, 0.05797701934352517), (1, 0.06211060285568237), (0, 0.12958338297903538), (36, 0.24034110270440578), (18, 0.2603891007602215), (53, 1.1203140765428543)]
computing accuracy for after removing block 35 . block score: 0.02326980559155345
removed block 35 current accuracy 0.9268 loss from initial  0.07320000000000004
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 41, with score 0.022709. All blocks and scores: [(41, 0.022708660224452615), (38, 0.02294550626538694), (50, 0.024617061018943787), (48, 0.024767621653154492), (51, 0.02580011636018753), (49, 0.02636748948134482), (10, 0.026924118865281343), (46, 0.02782864635810256), (34, 0.028162041679024696), (47, 0.028292008442804217), (15, 0.028695206623524427), (12, 0.03153211949393153), (5, 0.031853081192821264), (6, 0.032491859048604965), (52, 0.03447829745709896), (4, 0.039170936681330204), (3, 0.040439881850034), (13, 0.05793610541149974), (2, 0.05797702074050903), (1, 0.06211060332134366), (0, 0.12958338670432568), (36, 0.24495349265635014), (18, 0.2603890933096409), (53, 1.1846437901258469)]
computing accuracy for after removing block 41 . block score: 0.022708660224452615
removed block 41 current accuracy 0.8956 loss from initial  0.10440000000000005
since last training loss: 0.1018 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 38, with score 0.022946. All blocks and scores: [(38, 0.022945506032556295), (50, 0.02486352645792067), (48, 0.025035206926986575), (51, 0.025777533184736967), (10, 0.026924118399620056), (49, 0.027240462601184845), (34, 0.028162041446194053), (46, 0.028428434627130628), (15, 0.02869520732201636), (47, 0.028923883568495512), (12, 0.03153211995959282), (5, 0.03185308072715998), (52, 0.03232573764398694), (6, 0.03249185951426625), (4, 0.03917093621566892), (3, 0.04043988324701786), (13, 0.05793610634282231), (2, 0.05797702120617032), (1, 0.06211060285568237), (0, 0.12958338670432568), (36, 0.24495350010693073), (18, 0.2603890933096409), (53, 1.2700486481189728)]
computing accuracy for after removing block 38 . block score: 0.022945506032556295
removed block 38 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.1362 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 50, with score 0.023549. All blocks and scores: [(50, 0.023549407022073865), (48, 0.023931768257170916), (51, 0.024288253393024206), (10, 0.0269241186324507), (49, 0.02704549441114068), (47, 0.028003057232126594), (34, 0.02816204261034727), (15, 0.028695207089185715), (52, 0.02952647302299738), (46, 0.030072945170104504), (12, 0.03153211949393153), (5, 0.03185308072715998), (6, 0.03249185858294368), (4, 0.03917093575000763), (3, 0.040439882315695286), (13, 0.0579361068084836), (2, 0.05797701980918646), (1, 0.062110600527375937), (0, 0.12958338297903538), (36, 0.24495349824428558), (18, 0.2603891007602215), (53, 1.2980239689350128)]
computing accuracy for after removing block 50 . block score: 0.023549407022073865
removed block 50 current accuracy 0.8134 loss from initial  0.1866
training start
training epoch 0 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 1 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 2 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.001]
training epoch 3 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best True lr [0.001]
training epoch 4 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 5 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.001]
training epoch 6 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 7 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 8 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.001]
training epoch 9 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.001]
training epoch 10 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.001]
training epoch 11 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best True lr [0.001]
training epoch 12 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 13 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.001]
training epoch 14 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 15 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.001]
training epoch 16 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 17 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 18 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 19 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best True lr [0.001]
training epoch 20 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 21 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 22 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 23 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 24 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 25 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 26 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 27 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 28 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best True lr [0.001]
training epoch 29 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 30 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 31 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 32 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 33 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 34 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 35 val accuracy 0.9746 topk_dict {'top1': 0.9746} is_best False lr [0.001]
training epoch 36 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 37 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 38 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 39 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 40 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 41 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 42 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 43 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 44 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 45 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 46 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 47 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 48 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 49 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.977600)
finished training. finished 50 epochs. accuracy 0.9776 topk_dict {'top1': 0.9776}
