start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.008455109200440347), (30, 0.009703245712444186), (33, 0.01111594308167696), (34, 0.011622709571383893), (31, 0.012275203363969922), (28, 0.012290219543501735), (29, 0.014791248482652009), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.01825959258712828), (7, 0.018379185814410448), (8, 0.01953245303593576), (25, 0.019648709800094366), (35, 0.019787947181612253), (24, 0.020829484099522233), (22, 0.021021660417318344), (23, 0.02157451375387609), (47, 0.022546384716406465), (44, 0.02384215872734785), (41, 0.024168547010049224), (46, 0.024651075713336468), (6, 0.02466858015395701), (21, 0.025249343132600188), (43, 0.02580355410464108), (10, 0.026363695971667767), (42, 0.026426069205626845), (4, 0.026659545954316854), (45, 0.026823592837899923), (39, 0.026881904806941748), (40, 0.02689355332404375), (49, 0.02785642584785819), (48, 0.02849160344339907), (50, 0.028780476190149784), (11, 0.029002359602600336), (38, 0.02966292086057365), (3, 0.03227203991264105), (13, 0.033336535561829805), (37, 0.03576205810531974), (20, 0.036463219206780195), (12, 0.03799272095784545), (9, 0.03963937144726515), (51, 0.03964210767298937), (19, 0.04421887453645468), (52, 0.04580832691863179), (15, 0.04691674839705229), (14, 0.049041638150811195), (2, 0.05722745740786195), (0, 0.058882574550807476), (16, 0.0622522896155715), (5, 0.09379573632031679), (17, 0.25432228669524193), (36, 0.41727547720074654), (18, 0.4852069318294525), (53, 0.7453346699476242)]
computing accuracy for after removing block 32 . block score: 0.008455109200440347
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.009703245712444186), (33, 0.011199889821000397), (34, 0.01193780917674303), (31, 0.012275203363969922), (28, 0.012290219427086413), (29, 0.014791249297559261), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.018259592819958925), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.01964871073141694), (35, 0.020431341603398323), (24, 0.02082948386669159), (22, 0.021021661115810275), (23, 0.021574513521045446), (47, 0.02226210874505341), (44, 0.023293233010917902), (41, 0.02379581518471241), (46, 0.024043596116825938), (6, 0.024668580619618297), (21, 0.025249343365430832), (43, 0.02552505722269416), (42, 0.026236766716465354), (40, 0.026315772673115134), (10, 0.026363696437329054), (4, 0.026659545255824924), (45, 0.026667137863114476), (39, 0.026886870618909597), (49, 0.027327025309205055), (48, 0.027911514742299914), (50, 0.02820870582945645), (38, 0.028610609006136656), (11, 0.02900235983543098), (3, 0.0322720417752862), (13, 0.03333653602749109), (37, 0.03469931473955512), (20, 0.036463219206780195), (12, 0.03799272142350674), (51, 0.039370250422507524), (9, 0.03963937098160386), (19, 0.04421887546777725), (52, 0.04512502206489444), (15, 0.046916747931391), (14, 0.049041638150811195), (2, 0.05722745694220066), (0, 0.058882576413452625), (16, 0.062252288684248924), (5, 0.09379573911428452), (17, 0.25432227924466133), (36, 0.4077852889895439), (18, 0.4852069318294525), (53, 0.7581149116158485)]
computing accuracy for after removing block 30 . block score: 0.009703245712444186
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006312310696), (34, 0.011887529050000012), (28, 0.012290219543501735), (31, 0.012499805889092386), (29, 0.014791248366236687), (27, 0.016729247989133), (26, 0.01744490349665284), (1, 0.018259592354297638), (7, 0.018379185581579804), (8, 0.01953245303593576), (25, 0.019648710498586297), (35, 0.020717003382742405), (24, 0.020829484798014164), (22, 0.02102166088297963), (23, 0.021574513288214803), (47, 0.022107099182903767), (44, 0.023113693576306105), (46, 0.023742159130051732), (41, 0.02392919920384884), (6, 0.024668579688295722), (21, 0.025249343365430832), (43, 0.02526492695324123), (40, 0.026247451081871986), (10, 0.02636369620449841), (42, 0.02652742387726903), (4, 0.026659546652808785), (45, 0.02671260992065072), (39, 0.027034528786316514), (49, 0.02733851340599358), (48, 0.02790993917733431), (50, 0.02795650949701667), (38, 0.028708982514217496), (11, 0.02900235913693905), (3, 0.03227204084396362), (13, 0.03333653463050723), (37, 0.03434832626953721), (20, 0.03646321967244148), (12, 0.03799272095784545), (51, 0.039133232552558184), (9, 0.03963937098160386), (19, 0.04421887453645468), (52, 0.04478001920506358), (15, 0.04691674932837486), (14, 0.04904163721948862), (2, 0.05722745694220066), (0, 0.05888257501646876), (16, 0.06225228821858764), (5, 0.09379573725163937), (17, 0.25432227179408073), (36, 0.40603338927030563), (18, 0.4852069281041622), (53, 0.7581836432218552)]
computing accuracy for after removing block 33 . block score: 0.011317006312310696
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.01224008237477392), (28, 0.012290219310671091), (31, 0.012499805423431098), (29, 0.014791248948313296), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.01825959258712828), (7, 0.018379185814410448), (8, 0.01953245303593576), (25, 0.019648710498586297), (24, 0.020829484332352877), (22, 0.021021660650148988), (35, 0.021477246191352606), (23, 0.021574512822553515), (47, 0.021933730226010084), (44, 0.022819967940449715), (46, 0.02339849714189768), (41, 0.024046601494774222), (6, 0.024668580386787653), (21, 0.025249344762414694), (43, 0.025404764339327812), (40, 0.026019647484645247), (10, 0.026363695971667767), (4, 0.026659546419978142), (42, 0.02675018087029457), (45, 0.026783813489601016), (49, 0.02706983359530568), (39, 0.027496121125295758), (48, 0.02757457015104592), (50, 0.02794637018814683), (38, 0.028736303793266416), (11, 0.02900235983543098), (3, 0.03227204084396362), (13, 0.03333653509616852), (37, 0.03405904909595847), (20, 0.03646321874111891), (12, 0.03799272095784545), (51, 0.03880898095667362), (9, 0.039639370515942574), (19, 0.04421887546777725), (52, 0.044503949116915464), (15, 0.046916747931391), (14, 0.04904163861647248), (2, 0.057227456010878086), (0, 0.05888257501646876), (16, 0.06225228821858764), (5, 0.09379573725163937), (17, 0.25432228669524193), (36, 0.40450604259967804), (18, 0.4852069281041622), (53, 0.7641193121671677)]
computing accuracy for after removing block 34 . block score: 0.01224008237477392
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.012290219310671091), (31, 0.012499805307015777), (29, 0.01479124859906733), (27, 0.016729248221963644), (26, 0.01744490349665284), (1, 0.01825959258712828), (7, 0.01837918534874916), (8, 0.019532452570274472), (25, 0.019648710964247584), (24, 0.020829483633860946), (22, 0.02102166088297963), (23, 0.021574513521045446), (35, 0.0217086561024189), (47, 0.021801755763590336), (44, 0.022438113810494542), (46, 0.023336909012869), (41, 0.023686284199357033), (6, 0.024668580386787653), (21, 0.025249343365430832), (43, 0.025404839543625712), (40, 0.025569377234205604), (10, 0.02636369620449841), (42, 0.026551801711320877), (39, 0.02658287389203906), (49, 0.02664924249984324), (4, 0.026659545255824924), (45, 0.026776784332469106), (48, 0.026865946827456355), (50, 0.02756645088084042), (38, 0.02782911853864789), (11, 0.029002359369769692), (3, 0.03227203991264105), (37, 0.03319811960682273), (13, 0.033336535561829805), (20, 0.03646321967244148), (12, 0.03799272095784545), (51, 0.038059926591813564), (9, 0.039639370050281286), (52, 0.04353108024224639), (19, 0.04421887453645468), (15, 0.04691674979403615), (14, 0.049041638150811195), (2, 0.05722745833918452), (0, 0.0588825773447752), (16, 0.06225229101255536), (5, 0.09379573818296194), (17, 0.2543222885578871), (36, 0.3958275243639946), (18, 0.4852069318294525), (53, 0.7794358655810356)]
computing accuracy for after removing block 28 . block score: 0.012290219310671091
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645599164069), (29, 0.014790621120482683), (27, 0.016729248221963644), (26, 0.01744490396231413), (1, 0.018259592819958925), (7, 0.01837918604724109), (8, 0.019532452803105116), (25, 0.019648710964247584), (24, 0.020829484332352877), (22, 0.021021660417318344), (47, 0.02134651760570705), (23, 0.021574513288214803), (35, 0.02159673278219998), (44, 0.021918716840445995), (46, 0.022734675090759993), (41, 0.023228028556331992), (6, 0.024668579921126366), (40, 0.024839136051014066), (43, 0.024858605582267046), (21, 0.025249343132600188), (39, 0.025966263376176357), (48, 0.025971463648602366), (42, 0.025991314323619008), (49, 0.026064811274409294), (10, 0.026363696437329054), (45, 0.026453919941559434), (4, 0.026659546187147498), (50, 0.02668012911453843), (38, 0.027020082343369722), (11, 0.02900235913693905), (37, 0.032236403319984674), (3, 0.032272040378302336), (13, 0.03333653463050723), (20, 0.03646321827545762), (51, 0.03758792532607913), (12, 0.03799272095784545), (9, 0.039639370050281286), (52, 0.04288490116596222), (19, 0.04421887639909983), (15, 0.04691674932837486), (14, 0.04904163721948862), (2, 0.05722745647653937), (0, 0.05888257594779134), (16, 0.062252288684248924), (5, 0.09379573725163937), (17, 0.25432228669524193), (36, 0.3858989179134369), (18, 0.4852069318294525), (53, 0.788181945681572)]
computing accuracy for after removing block 31 . block score: 0.011874645599164069
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.014790620654821396), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.018259593285620213), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.019648711197078228), (24, 0.020829483401030302), (47, 0.02093204646371305), (22, 0.021021660650148988), (44, 0.021379180951043963), (23, 0.021574513521045446), (46, 0.022063189884647727), (35, 0.02244045026600361), (41, 0.022648891899734735), (40, 0.02413078211247921), (43, 0.024664207827299833), (6, 0.024668580386787653), (21, 0.025249344063922763), (48, 0.02525039715692401), (49, 0.0255158101208508), (42, 0.02562687173485756), (39, 0.025647579925134778), (38, 0.025854782201349735), (50, 0.025972344912588596), (45, 0.026165933813899755), (10, 0.026363695738837123), (4, 0.026659545954316854), (11, 0.029002358904108405), (37, 0.03128928877413273), (3, 0.032272040378302336), (13, 0.033336535561829805), (20, 0.03646321967244148), (51, 0.037289760541170835), (12, 0.03799272095784545), (9, 0.039639370515942574), (52, 0.04199218424037099), (19, 0.044218875002115965), (15, 0.04691674979403615), (14, 0.04904163861647248), (2, 0.057227456010878086), (0, 0.05888257548213005), (16, 0.06225228914991021), (5, 0.09379573818296194), (17, 0.25432228296995163), (36, 0.3760596998035908), (18, 0.4852069318294525), (53, 0.8019541129469872)]
computing accuracy for after removing block 29 . block score: 0.014790620654821396
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729247989133), (26, 0.01744490349665284), (1, 0.018259592354297638), (7, 0.018379185581579804), (8, 0.01953245303593576), (25, 0.01964871142990887), (47, 0.020515700336545706), (24, 0.020829483633860946), (44, 0.020975132239982486), (22, 0.021021660650148988), (23, 0.02157451375387609), (46, 0.021652452182024717), (41, 0.022661817725747824), (35, 0.022723623318597674), (40, 0.023883074754849076), (43, 0.024189722957089543), (6, 0.02466858015395701), (48, 0.024881582707166672), (49, 0.025212352629750967), (42, 0.025229300372302532), (21, 0.025249344063922763), (38, 0.025457143783569336), (50, 0.025512879714369774), (39, 0.025584626942873), (45, 0.026210954412817955), (10, 0.026363696437329054), (4, 0.026659545954316854), (11, 0.029002358904108405), (37, 0.03110239445231855), (3, 0.03227204130962491), (13, 0.033336535561829805), (20, 0.03646321874111891), (51, 0.037521738559007645), (12, 0.03799272049218416), (9, 0.039639371912926435), (52, 0.04157667141407728), (19, 0.04421887593343854), (15, 0.04691674839705229), (14, 0.04904163768514991), (2, 0.0572274555452168), (0, 0.05888257594779134), (16, 0.06225228775292635), (5, 0.09379574004560709), (17, 0.25432228296995163), (36, 0.3744278959929943), (18, 0.4852069094777107), (53, 0.8058174178004265)]
computing accuracy for after removing block 27 . block score: 0.016729247989133
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 4 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 6 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 7 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 14 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017557. All blocks and scores: [(26, 0.017557421000674367), (1, 0.017969993641600013), (7, 0.018647812772542238), (8, 0.01944930385798216), (25, 0.02112877764739096), (22, 0.02152690035291016), (24, 0.021954888477921486), (47, 0.022097370820119977), (35, 0.022214405238628387), (23, 0.02292654477059841), (44, 0.023377709789201617), (41, 0.023980159778147936), (46, 0.024273948511108756), (6, 0.024925991659983993), (43, 0.025197374867275357), (21, 0.025780750438570976), (10, 0.026010697474703193), (42, 0.026130164740607142), (40, 0.02617592946626246), (45, 0.026192010613158345), (4, 0.026375132612884045), (39, 0.026405241573229432), (49, 0.02738099335692823), (48, 0.02826822968199849), (11, 0.02858924795873463), (38, 0.02890822826884687), (50, 0.028925276128575206), (3, 0.03216508263722062), (13, 0.03323073824867606), (37, 0.035406099166721106), (20, 0.03706436837092042), (12, 0.03747275657951832), (9, 0.039259233977645636), (51, 0.03972245380282402), (19, 0.0450503914617002), (52, 0.04652125434949994), (15, 0.04739899979904294), (14, 0.048906083684414625), (2, 0.0567797115072608), (0, 0.057995112147182226), (16, 0.06267610564827919), (5, 0.0921834409236908), (17, 0.24965471774339676), (36, 0.4067200981080532), (18, 0.4774894192814827), (53, 0.7237185090780258)]
computing accuracy for after removing block 26 . block score: 0.017557421000674367
removed block 26 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.017970. All blocks and scores: [(1, 0.017969994340091944), (7, 0.01864781347103417), (8, 0.01944930385798216), (25, 0.02112877811305225), (47, 0.02138696634210646), (22, 0.021526899887248874), (35, 0.021666778484359384), (24, 0.021954889176413417), (44, 0.02256370661780238), (23, 0.022926544304937124), (46, 0.023509932216256857), (41, 0.023629178758710623), (43, 0.024558222852647305), (6, 0.024925991194322705), (40, 0.025315801380202174), (42, 0.025579650420695543), (45, 0.025634964695200324), (39, 0.025669148890301585), (21, 0.02578075067140162), (10, 0.02601069724187255), (49, 0.026270624483004212), (4, 0.026375133078545332), (48, 0.026501466752961278), (38, 0.027688045287504792), (50, 0.02802601014263928), (11, 0.0285892472602427), (3, 0.032165083568543196), (13, 0.03323073731735349), (37, 0.034259007312357426), (20, 0.037064369302242994), (12, 0.03747275611385703), (51, 0.03893137630075216), (9, 0.03925923351198435), (19, 0.04505039332434535), (52, 0.04533470468595624), (15, 0.04739899979904294), (14, 0.048906083684414625), (2, 0.05677970824763179), (0, 0.057995114009827375), (16, 0.06267610471695662), (5, 0.09218344371765852), (17, 0.24965471774339676), (36, 0.39812833815813065), (18, 0.4774894118309021), (53, 0.7391804680228233)]
computing accuracy for after removing block 1 . block score: 0.017969994340091944
removed block 1 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.018128. All blocks and scores: [(7, 0.01812785631045699), (8, 0.01862120209261775), (25, 0.020526159554719925), (24, 0.020783137530088425), (35, 0.020834163995459676), (22, 0.020855794427916408), (47, 0.021389270201325417), (44, 0.022163474699482322), (23, 0.02243627142161131), (41, 0.022924329852685332), (46, 0.023431286914274096), (43, 0.024140672758221626), (6, 0.024326717481017113), (40, 0.024700845358893275), (39, 0.024835418676957488), (21, 0.024885858641937375), (42, 0.025268592406064272), (45, 0.0255241843406111), (10, 0.02560127852484584), (48, 0.02597662713378668), (49, 0.02639933698810637), (38, 0.026492869248613715), (11, 0.027638980885967612), (50, 0.027695179684087634), (4, 0.028379196766763926), (3, 0.03227150812745094), (13, 0.03316087555140257), (37, 0.033181844279170036), (20, 0.03578563779592514), (12, 0.03661877568811178), (9, 0.038262249901890755), (51, 0.03911572461947799), (19, 0.044360180385410786), (52, 0.04500121949240565), (15, 0.04785183072090149), (14, 0.04806519253179431), (2, 0.05680993292480707), (0, 0.057995112612843513), (16, 0.06125948764383793), (5, 0.09069789294153452), (17, 0.24633661657571793), (36, 0.38221481814980507), (18, 0.46158717945218086), (53, 0.7466607093811035)]
computing accuracy for after removing block 7 . block score: 0.01812785631045699
removed block 7 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.019623. All blocks and scores: [(35, 0.019622528925538063), (25, 0.019679336808621883), (8, 0.019969860091805458), (24, 0.02000122214667499), (22, 0.020364498253911734), (47, 0.020720786415040493), (23, 0.020976260537281632), (44, 0.021984842140227556), (41, 0.022370984544977546), (46, 0.022744856541976333), (43, 0.023319575237110257), (40, 0.023481376469135284), (21, 0.023749857442453504), (39, 0.02414607908576727), (6, 0.0243267179466784), (42, 0.02486824826337397), (45, 0.024879807606339455), (48, 0.02508106571622193), (38, 0.025271958205848932), (10, 0.02575885015539825), (49, 0.02608869271352887), (50, 0.02700757677666843), (11, 0.027706365566700697), (4, 0.028379196301102638), (37, 0.032008292619138956), (3, 0.03227150859311223), (13, 0.03278023237362504), (20, 0.03465893166139722), (12, 0.03633303428068757), (51, 0.038728711660951376), (9, 0.03902730159461498), (19, 0.04272536654025316), (52, 0.04410206386819482), (15, 0.04684618907049298), (14, 0.04731400916352868), (2, 0.056809935718774796), (0, 0.0579951130785048), (16, 0.05980679718777537), (5, 0.09069789201021194), (17, 0.2339160516858101), (36, 0.3691798783838749), (18, 0.4474353641271591), (53, 0.7492560222744942)]
computing accuracy for after removing block 35 . block score: 0.019622528925538063
removed block 35 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 47, with score 0.019654. All blocks and scores: [(47, 0.019654491916298866), (25, 0.019679336808621883), (8, 0.01996986079029739), (24, 0.02000122214667499), (22, 0.020364498253911734), (23, 0.020976260537281632), (44, 0.021209041588008404), (41, 0.021290296223014593), (46, 0.021915527991950512), (40, 0.02200820646248758), (39, 0.02236109529621899), (43, 0.0225500229280442), (48, 0.022982825292274356), (38, 0.023402568185701966), (21, 0.023749856976792216), (42, 0.02375009562820196), (45, 0.02393946936354041), (6, 0.024326717713847756), (49, 0.024742660811170936), (50, 0.025491248117759824), (10, 0.025758849224075675), (11, 0.027706366730853915), (4, 0.028379197465255857), (37, 0.030185712035745382), (3, 0.03227150812745094), (13, 0.03278023237362504), (20, 0.034658930730074644), (12, 0.03633303474634886), (51, 0.036924026906490326), (9, 0.03902730252593756), (52, 0.04205560963600874), (19, 0.042725364211946726), (15, 0.04684618953615427), (14, 0.04731400916352868), (2, 0.056809935718774796), (0, 0.05799511447548866), (16, 0.05980679718777537), (5, 0.09069789480417967), (17, 0.23391604982316494), (36, 0.3525133728981018), (18, 0.4474353566765785), (53, 0.7786011770367622)]
computing accuracy for after removing block 47 . block score: 0.019654491916298866
removed block 47 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.019679. All blocks and scores: [(25, 0.01967933657579124), (8, 0.01996986079029739), (24, 0.02000122214667499), (22, 0.02036449802108109), (23, 0.0209762598387897), (44, 0.021209041122347116), (41, 0.021290297154337168), (46, 0.02191552775911987), (40, 0.022008206229656935), (39, 0.02236109576188028), (43, 0.022550023160874844), (48, 0.023189667146652937), (38, 0.023402567952871323), (21, 0.023749856976792216), (42, 0.023750096326693892), (45, 0.023939468199387193), (6, 0.024326717481017113), (49, 0.025514692068099976), (10, 0.025758849689736962), (50, 0.026265493594110012), (11, 0.027706366032361984), (4, 0.028379197232425213), (37, 0.030185712268576026), (3, 0.03227150859311223), (13, 0.03278023190796375), (20, 0.034658932127058506), (12, 0.03633303660899401), (51, 0.03688417375087738), (9, 0.03902730206027627), (52, 0.04149516951292753), (19, 0.042725364211946726), (15, 0.04684618907049298), (14, 0.04731401056051254), (2, 0.05680993618443608), (0, 0.0579951130785048), (16, 0.05980679718777537), (5, 0.09069789480417967), (17, 0.2339160479605198), (36, 0.3525133728981018), (18, 0.4474353492259979), (53, 0.8584104403853416)]
computing accuracy for after removing block 25 . block score: 0.01967933657579124
removed block 25 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 8, with score 0.019970. All blocks and scores: [(8, 0.019969861023128033), (24, 0.020001222379505634), (22, 0.020364497788250446), (41, 0.02065626229159534), (44, 0.020812455331906676), (23, 0.020976261235773563), (40, 0.021321023115888238), (39, 0.021477985894307494), (46, 0.021480888593941927), (48, 0.022323064738884568), (38, 0.022331938846036792), (43, 0.02235085377469659), (42, 0.023287692107260227), (21, 0.023749856743961573), (45, 0.02385340933687985), (6, 0.0243267179466784), (49, 0.024697687476873398), (50, 0.0253604082390666), (10, 0.025758848758414388), (11, 0.02770636649802327), (4, 0.028379198163747787), (37, 0.029240270145237446), (3, 0.03227150859311223), (13, 0.03278023283928633), (20, 0.03465893119573593), (12, 0.03633303474634886), (51, 0.03641449520364404), (9, 0.03902730345726013), (52, 0.04064142610877752), (19, 0.04272536467760801), (15, 0.04684618953615427), (14, 0.047314008232206106), (2, 0.056809935718774796), (0, 0.05799511447548866), (16, 0.05980679811909795), (5, 0.09069789294153452), (17, 0.23391604237258434), (36, 0.3419695571064949), (18, 0.4474353715777397), (53, 0.8677848279476166)]
computing accuracy for after removing block 8 . block score: 0.019969861023128033
removed block 8 current accuracy 0.9914 loss from initial  0.008600000000000052
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.018981. All blocks and scores: [(24, 0.01898092869669199), (22, 0.019812601851299405), (23, 0.01990614994429052), (41, 0.020371015649288893), (44, 0.020658523542806506), (40, 0.02067982661537826), (39, 0.021032377379015088), (46, 0.021042615408077836), (38, 0.021661041071638465), (48, 0.021830367390066385), (43, 0.021938680205494165), (21, 0.022701629204675555), (42, 0.023040961707010865), (45, 0.02339383214712143), (6, 0.024326717481017113), (49, 0.024621044052764773), (50, 0.024960120674222708), (10, 0.026187116047367454), (4, 0.028379197232425213), (37, 0.028841370018199086), (11, 0.02939644572325051), (3, 0.03227150905877352), (13, 0.03364963550120592), (20, 0.03394075622782111), (51, 0.036115508526563644), (12, 0.037099421955645084), (9, 0.03953869920223951), (52, 0.04001279594376683), (19, 0.04119194159284234), (15, 0.04598504910245538), (14, 0.04613283462822437), (2, 0.05680993711575866), (0, 0.05799511447548866), (16, 0.05901660397648811), (5, 0.09069789201021194), (17, 0.2240400668233633), (36, 0.3329516388475895), (18, 0.4320885017514229), (53, 0.8661914616823196)]
computing accuracy for after removing block 24 . block score: 0.01898092869669199
removed block 24 current accuracy 0.9842 loss from initial  0.015800000000000036
training start
training epoch 0 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 1 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 2 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 3 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 4 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 5 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 6 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 7 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 8 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 9 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 10 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 11 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 12 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 13 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 15 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 16 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 17 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 19 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 20 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 25 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 26 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 27 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 28 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 30 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 31 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 32 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 33 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 34 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 35 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 36 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 37 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 40 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 41 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 42 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 45 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 46 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 47 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 48 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 49 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
loading model_best from epoch 21 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.022956. All blocks and scores: [(44, 0.022956179920583963), (46, 0.023785916157066822), (41, 0.023838163120672107), (43, 0.024525746935978532), (22, 0.02559684426523745), (45, 0.02566241519525647), (39, 0.025862989714369178), (42, 0.025881947251036763), (40, 0.026141934795305133), (6, 0.026374071603640914), (10, 0.02698004595004022), (23, 0.027373594231903553), (11, 0.027640867978334427), (38, 0.028150391997769475), (49, 0.028186072129756212), (48, 0.029145817505195737), (4, 0.029174810275435448), (50, 0.029367268551141024), (21, 0.031058432068675756), (13, 0.033057473599910736), (3, 0.03357624774798751), (37, 0.03436919767409563), (9, 0.03722483990713954), (12, 0.03767153760418296), (51, 0.039852630347013474), (20, 0.040360738057643175), (52, 0.046655834186822176), (19, 0.04753838665783405), (14, 0.04773764964193106), (15, 0.048511013854295015), (0, 0.05571848060935736), (2, 0.05820415448397398), (16, 0.06108167115598917), (5, 0.09050715994089842), (17, 0.23418059945106506), (36, 0.3971611298620701), (18, 0.45619991421699524), (53, 0.7401911094784737)]
computing accuracy for after removing block 44 . block score: 0.022956179920583963
removed block 44 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.023838. All blocks and scores: [(41, 0.023838162422180176), (43, 0.024525746703147888), (46, 0.024609963409602642), (22, 0.025596844498068094), (39, 0.025862989714369178), (42, 0.025881947251036763), (45, 0.026037556817755103), (40, 0.026141935493797064), (6, 0.026374071603640914), (10, 0.026980045018717647), (23, 0.02737359469756484), (11, 0.027640868909657), (49, 0.027683110674843192), (38, 0.02815039176493883), (4, 0.029174810741096735), (48, 0.029226670041680336), (50, 0.029585763346403837), (21, 0.03105843160301447), (13, 0.03305747406557202), (3, 0.03357624867931008), (37, 0.034369196742773056), (9, 0.037224840838462114), (12, 0.03767153853550553), (51, 0.0396544705145061), (20, 0.04036073666065931), (52, 0.04579749284312129), (19, 0.04753838665783405), (14, 0.04773765057325363), (15, 0.048511013854295015), (0, 0.055718481075018644), (2, 0.058204155415296555), (16, 0.061081668362021446), (5, 0.09050716087222099), (17, 0.2341806050390005), (36, 0.3971611298620701), (18, 0.45619992539286613), (53, 0.8017167076468468)]
computing accuracy for after removing block 41 . block score: 0.023838162422180176
removed block 41 current accuracy 0.9946 loss from initial  0.00539999999999996
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.024379. All blocks and scores: [(46, 0.024378731613978744), (43, 0.02438754215836525), (42, 0.0250325845554471), (45, 0.02546522906050086), (22, 0.02559684496372938), (39, 0.025862989481538534), (40, 0.026141934795305133), (49, 0.026217243634164333), (6, 0.0263740720693022), (10, 0.026980045018717647), (23, 0.02737359399907291), (11, 0.02764086821116507), (48, 0.028150061145424843), (38, 0.028150391299277544), (50, 0.028155862586572766), (4, 0.029174811439588666), (21, 0.03105843160301447), (13, 0.03305747313424945), (3, 0.03357624774798751), (37, 0.03436919720843434), (9, 0.037224840838462114), (12, 0.037671538069844246), (51, 0.038268671836704016), (20, 0.04036073759198189), (52, 0.043938837479799986), (19, 0.04753838712349534), (14, 0.04773764964193106), (15, 0.048511011991649866), (0, 0.05571848060935736), (2, 0.05820415588095784), (16, 0.06108167162165046), (5, 0.09050716087222099), (17, 0.2341806050390005), (36, 0.3971611447632313), (18, 0.45619991049170494), (53, 0.8924903944134712)]
computing accuracy for after removing block 46 . block score: 0.024378731613978744
removed block 46 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.024388. All blocks and scores: [(43, 0.02438754285685718), (42, 0.02503258502110839), (45, 0.025465228594839573), (22, 0.025596844498068094), (39, 0.02586298994719982), (40, 0.026141935493797064), (6, 0.026374071836471558), (49, 0.02664441941305995), (10, 0.02698004525154829), (23, 0.02737359330058098), (11, 0.02764086821116507), (50, 0.028067557606846094), (38, 0.028150391299277544), (48, 0.02842353587038815), (4, 0.029174811206758022), (21, 0.0310584323015064), (13, 0.03305747313424945), (3, 0.03357624774798751), (37, 0.03436919813975692), (9, 0.0372248413041234), (12, 0.03767153900116682), (51, 0.03904240112751722), (20, 0.04036073852330446), (52, 0.044388928450644016), (19, 0.04753838758915663), (14, 0.04773764964193106), (15, 0.04851101338863373), (0, 0.055718481075018644), (2, 0.05820415588095784), (16, 0.061081670224666595), (5, 0.09050716087222099), (17, 0.23418061062693596), (36, 0.3971611298620701), (18, 0.45619990676641464), (53, 0.9749214351177216)]
computing accuracy for after removing block 43 . block score: 0.02438754285685718
removed block 43 current accuracy 0.971 loss from initial  0.029000000000000026
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.025033. All blocks and scores: [(42, 0.025032584322616458), (45, 0.025451847817748785), (22, 0.025596843799576163), (39, 0.025862989481538534), (40, 0.02614193526096642), (6, 0.0263740720693022), (49, 0.026790577452629805), (10, 0.026980045717209578), (23, 0.027373594231903553), (50, 0.02749377186410129), (11, 0.027640867745503783), (48, 0.02805734728462994), (38, 0.02815039223060012), (4, 0.029174810741096735), (21, 0.03105843160301447), (13, 0.03305747266858816), (3, 0.03357624728232622), (37, 0.03436919767409563), (9, 0.03722483990713954), (12, 0.03767153853550553), (51, 0.03830498084425926), (20, 0.04036073852330446), (52, 0.04278163658455014), (19, 0.04753838665783405), (14, 0.047737651504576206), (15, 0.04851101338863373), (0, 0.055718479212373495), (2, 0.058204155415296555), (16, 0.06108166975900531), (5, 0.09050716087222099), (17, 0.2341806050390005), (36, 0.3971611373126507), (18, 0.45619990676641464), (53, 1.0931542068719864)]
computing accuracy for after removing block 42 . block score: 0.025032584322616458
removed block 42 current accuracy 0.9456 loss from initial  0.054400000000000004
since last training loss: 0.05379999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.025597. All blocks and scores: [(22, 0.025596844730898738), (45, 0.02578836609609425), (39, 0.025862989714369178), (49, 0.02613375661894679), (40, 0.02614193526096642), (6, 0.026374072767794132), (10, 0.026980046648532152), (23, 0.027373593766242266), (50, 0.02741635264828801), (11, 0.027640867279842496), (38, 0.028150391997769475), (48, 0.02842588908970356), (4, 0.029174811206758022), (21, 0.0310584323015064), (13, 0.03305747313424945), (3, 0.03357624728232622), (37, 0.03436919720843434), (9, 0.03722483990713954), (51, 0.03750933101400733), (12, 0.037671538069844246), (20, 0.04036073945462704), (52, 0.04219561396166682), (19, 0.047538388054817915), (14, 0.04773765057325363), (15, 0.048511013854295015), (0, 0.05571848060935736), (2, 0.05820415401831269), (16, 0.06108167115598917), (5, 0.09050715900957584), (17, 0.23418060317635536), (36, 0.3971611373126507), (18, 0.45619991794228554), (53, 1.2138586342334747)]
computing accuracy for after removing block 22 . block score: 0.025596844730898738
removed block 22 current accuracy 0.9364 loss from initial  0.06359999999999999
since last training loss: 0.06299999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.024459. All blocks and scores: [(49, 0.024459251668304205), (45, 0.024538528406992555), (40, 0.024562213802710176), (39, 0.024595230352133512), (23, 0.02508637961000204), (48, 0.02590761100873351), (50, 0.02602645754814148), (6, 0.026374071603640914), (38, 0.02686600130982697), (10, 0.02698004595004022), (11, 0.027640867745503783), (4, 0.029174810741096735), (21, 0.031058431370183825), (37, 0.03285077586770058), (13, 0.033057473599910736), (3, 0.03357624728232622), (51, 0.03644163627177477), (9, 0.03722483990713954), (12, 0.03767153946682811), (20, 0.040360738057643175), (52, 0.040613772347569466), (19, 0.04753838758915663), (14, 0.04773764917626977), (15, 0.04851101292297244), (0, 0.05571847967803478), (2, 0.058204155415296555), (16, 0.06108167162165046), (5, 0.09050716087222099), (17, 0.2341806050390005), (36, 0.376702181994915), (18, 0.45619991049170494), (53, 1.2213650047779083)]
computing accuracy for after removing block 49 . block score: 0.024459251668304205
removed block 49 current accuracy 0.9172 loss from initial  0.08279999999999998
since last training loss: 0.08219999999999994 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.024539. All blocks and scores: [(45, 0.0245385286398232), (40, 0.024562213569879532), (39, 0.024595229886472225), (23, 0.025086379144340754), (48, 0.025907611241564155), (6, 0.026374070905148983), (50, 0.0267420606687665), (38, 0.02686600061133504), (10, 0.026980045717209578), (11, 0.027640868443995714), (4, 0.02917481097392738), (21, 0.03105843160301447), (37, 0.03285077540203929), (13, 0.033057473599910736), (3, 0.033576248213648796), (9, 0.0372248413041234), (12, 0.037671538069844246), (51, 0.03938318323343992), (20, 0.040360738057643175), (52, 0.04241976095363498), (19, 0.04753838572651148), (14, 0.04773765057325363), (15, 0.04851101338863373), (0, 0.05571848060935736), (2, 0.058204155415296555), (16, 0.06108166975900531), (5, 0.09050716087222099), (17, 0.23418060317635536), (36, 0.376702181994915), (18, 0.45619991794228554), (53, 1.3614701926708221)]
computing accuracy for after removing block 45 . block score: 0.0245385286398232
removed block 45 current accuracy 0.8808 loss from initial  0.11919999999999997
training start
training epoch 0 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best True lr [0.001]
training epoch 1 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best True lr [0.001]
training epoch 2 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 3 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best True lr [0.001]
training epoch 4 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 5 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 6 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best True lr [0.001]
training epoch 7 val accuracy 0.986 topk_dict {'top1': 0.986} is_best True lr [0.001]
training epoch 8 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 9 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 10 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 11 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 12 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 13 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 14 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 15 val accuracy 0.988 topk_dict {'top1': 0.988} is_best False lr [0.001]
training epoch 16 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 17 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 18 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 19 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 20 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 21 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 22 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 23 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 24 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 25 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 26 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 27 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 28 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 29 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 30 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 31 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 32 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 33 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 34 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 35 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 36 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 37 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 38 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 39 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 40 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 42 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 43 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 44 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 45 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 46 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 47 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 48 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 49 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.992800)
finished training. finished 50 epochs. accuracy 0.9928 topk_dict {'top1': 0.9928}
start iteration 24
[activation diff]: block to remove picked: 6, with score 0.025819. All blocks and scores: [(6, 0.02581861591897905), (10, 0.028329569147899747), (4, 0.02867424301803112), (11, 0.029401120962575078), (39, 0.03056792402639985), (38, 0.031178655102849007), (40, 0.032057606149464846), (13, 0.03282674727961421), (3, 0.034685855731368065), (37, 0.03471122216433287), (12, 0.03738019289448857), (9, 0.037676991894841194), (23, 0.03858763258904219), (50, 0.039683808106929064), (48, 0.0425645406357944), (21, 0.043933783657848835), (51, 0.04566151788458228), (14, 0.04743460053578019), (15, 0.047538470942527056), (20, 0.049538298044353724), (52, 0.05351324751973152), (19, 0.05424788920208812), (0, 0.055459688417613506), (2, 0.05804952513426542), (16, 0.05840351665392518), (5, 0.09016985166817904), (17, 0.23003306984901428), (36, 0.3373849056661129), (18, 0.4195801764726639), (53, 0.7885235399007797)]
computing accuracy for after removing block 6 . block score: 0.02581861591897905
removed block 6 current accuracy 0.991 loss from initial  0.009000000000000008
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 4, with score 0.028674. All blocks and scores: [(4, 0.028674243483692408), (39, 0.02999307122081518), (38, 0.03026579087600112), (10, 0.03084228467196226), (40, 0.03100276947952807), (11, 0.03139985189773142), (37, 0.03387870918959379), (3, 0.03468585526570678), (23, 0.03642411204054952), (13, 0.03661770327016711), (12, 0.0373081685975194), (50, 0.03902025334537029), (9, 0.040813242085278034), (48, 0.04098577797412872), (21, 0.0422060783021152), (51, 0.04497124720364809), (20, 0.048255239613354206), (15, 0.04916537832468748), (14, 0.04965163953602314), (19, 0.051774630788713694), (52, 0.052905404940247536), (0, 0.055459690280258656), (2, 0.058049523271620274), (16, 0.05832297308370471), (5, 0.09016984980553389), (17, 0.229966651648283), (36, 0.3302242122590542), (18, 0.411776140332222), (53, 0.7853544428944588)]
computing accuracy for after removing block 4 . block score: 0.028674243483692408
removed block 4 current accuracy 0.9876 loss from initial  0.012399999999999967
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.028603. All blocks and scores: [(38, 0.028603482991456985), (39, 0.02967368741519749), (11, 0.02988359145820141), (40, 0.0301696362439543), (10, 0.031234331196174026), (37, 0.03235905058681965), (23, 0.034544756170362234), (3, 0.034685855731368065), (13, 0.03750711912289262), (50, 0.0378157221712172), (12, 0.03792739100754261), (48, 0.039727078285068274), (9, 0.040053995326161385), (21, 0.040266324300318956), (51, 0.044779800809919834), (20, 0.045989048667252064), (15, 0.04829198960214853), (14, 0.048944972455501556), (19, 0.0494445594958961), (52, 0.05168108223006129), (0, 0.05545968934893608), (2, 0.058049526065588), (16, 0.058741283137351274), (5, 0.09257497731596231), (17, 0.22676110453903675), (36, 0.31732528284192085), (18, 0.4067591615021229), (53, 0.7976075783371925)]
computing accuracy for after removing block 38 . block score: 0.028603482991456985
removed block 38 current accuracy 0.977 loss from initial  0.02300000000000002
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 11, with score 0.029884. All blocks and scores: [(11, 0.029883591225370765), (40, 0.03078639623709023), (10, 0.031234331661835313), (37, 0.03235905058681965), (39, 0.03242009365931153), (23, 0.034544757567346096), (3, 0.034685855731368065), (50, 0.03534984169527888), (48, 0.03697724360972643), (13, 0.03750712005421519), (12, 0.037927391938865185), (9, 0.04005399392917752), (21, 0.040266324765980244), (51, 0.041977586690336466), (20, 0.04598904913291335), (52, 0.04777712607756257), (15, 0.04829199146479368), (14, 0.048944972455501556), (19, 0.04944455809891224), (0, 0.055459688417613506), (2, 0.058049524668604136), (16, 0.0587412822060287), (5, 0.09257497731596231), (17, 0.22676110453903675), (36, 0.31732528656721115), (18, 0.4067591652274132), (53, 0.8925314992666245)]
computing accuracy for after removing block 11 . block score: 0.029883591225370765
removed block 11 current accuracy 0.9656 loss from initial  0.034399999999999986
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 40, with score 0.029303. All blocks and scores: [(40, 0.029303310671821237), (37, 0.03107313346117735), (39, 0.031170492991805077), (10, 0.031234330032020807), (23, 0.032250755466520786), (50, 0.0341522810049355), (3, 0.03468585526570678), (48, 0.035915802232921124), (21, 0.03728787740692496), (12, 0.03903351351618767), (9, 0.04005399253219366), (51, 0.040671445429325104), (13, 0.04239141661673784), (20, 0.04463741974905133), (52, 0.04614189686253667), (19, 0.0473053315654397), (14, 0.04896687716245651), (15, 0.049273050390183926), (0, 0.05545968981459737), (2, 0.05804952420294285), (16, 0.06261766282841563), (5, 0.09257497824728489), (17, 0.21544203534722328), (36, 0.30842623859643936), (18, 0.39498257637023926), (53, 0.898173451423645)]
computing accuracy for after removing block 40 . block score: 0.029303310671821237
removed block 40 current accuracy 0.93 loss from initial  0.06999999999999995
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 37, with score 0.031073. All blocks and scores: [(37, 0.03107313415966928), (39, 0.03117049322463572), (10, 0.03123433026485145), (50, 0.03222481394186616), (23, 0.0322507550008595), (3, 0.034685855731368065), (48, 0.03577862959355116), (21, 0.03728787787258625), (51, 0.03800165466964245), (12, 0.039033513981848955), (9, 0.040053993463516235), (13, 0.042391419410705566), (52, 0.04413126315921545), (20, 0.04463741974905133), (19, 0.0473053315654397), (14, 0.048966876696795225), (15, 0.049273050390183926), (0, 0.05545968934893608), (2, 0.058049523271620274), (16, 0.06261766329407692), (5, 0.09257497824728489), (17, 0.21544204279780388), (36, 0.30842624232172966), (18, 0.39498256891965866), (53, 1.0268585085868835)]
computing accuracy for after removing block 37 . block score: 0.03107313415966928
removed block 37 current accuracy 0.8798 loss from initial  0.12019999999999997
since last training loss: 0.11299999999999999 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 50, with score 0.030273. All blocks and scores: [(50, 0.03027297300286591), (10, 0.031234331196174026), (23, 0.032250755932182074), (48, 0.03402708936482668), (51, 0.034456262830644846), (3, 0.03468585526570678), (39, 0.035067320335656404), (21, 0.03728787647560239), (12, 0.03903351351618767), (9, 0.04005399206653237), (52, 0.04163787281140685), (13, 0.042391418013721704), (20, 0.04463741974905133), (19, 0.0473053315654397), (14, 0.04896687623113394), (15, 0.04927304945886135), (0, 0.05545969074591994), (2, 0.05804952373728156), (16, 0.0626176642253995), (5, 0.09257497638463974), (17, 0.21544205024838448), (36, 0.30842623859643936), (18, 0.39498259127140045), (53, 1.1027906686067581)]
computing accuracy for after removing block 50 . block score: 0.03027297300286591
removed block 50 current accuracy 0.84 loss from initial  0.16000000000000003
since last training loss: 0.15280000000000005 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 10, with score 0.031234. All blocks and scores: [(10, 0.031234331196174026), (23, 0.032250755466520786), (48, 0.03402708936482668), (3, 0.03468585526570678), (39, 0.035067322198301554), (21, 0.037287876941263676), (51, 0.037500886246562004), (12, 0.03903351351618767), (9, 0.04005399206653237), (13, 0.04239141847938299), (52, 0.044511922635138035), (20, 0.04463742068037391), (19, 0.047305330634117126), (14, 0.04896687716245651), (15, 0.04927304992452264), (0, 0.055459688883274794), (2, 0.05804952559992671), (16, 0.0626176642253995), (5, 0.09257497917860746), (17, 0.21544203720986843), (36, 0.30842623487114906), (18, 0.39498257264494896), (53, 1.3497070372104645)]
computing accuracy for after removing block 10 . block score: 0.031234331196174026
removed block 10 current accuracy 0.806 loss from initial  0.19399999999999995
since last training loss: 0.18679999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 23, with score 0.029046. All blocks and scores: [(23, 0.02904620347544551), (48, 0.03162903944030404), (39, 0.03298865258693695), (21, 0.03375184442847967), (51, 0.03460086788982153), (3, 0.03468585526570678), (9, 0.0400539948605001), (12, 0.04048203630372882), (13, 0.041032928973436356), (52, 0.04155919328331947), (20, 0.04261385416612029), (19, 0.04356494918465614), (14, 0.048075033351778984), (15, 0.048993328120559454), (0, 0.055459690280258656), (2, 0.05804952420294285), (16, 0.06277744611725211), (5, 0.09257497824728489), (17, 0.2076647449284792), (36, 0.28532859310507774), (18, 0.3774419464170933), (53, 1.3355821073055267)]
computing accuracy for after removing block 23 . block score: 0.02904620347544551
removed block 23 current accuracy 0.7812 loss from initial  0.2188
training start
training epoch 0 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 1 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 2 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 3 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.001]
training epoch 4 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.001]
training epoch 5 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.001]
training epoch 6 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.001]
training epoch 7 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.001]
training epoch 8 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.001]
training epoch 9 val accuracy 0.964 topk_dict {'top1': 0.964} is_best False lr [0.001]
training epoch 10 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 11 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best True lr [0.001]
training epoch 12 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.001]
training epoch 13 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best False lr [0.001]
training epoch 14 val accuracy 0.967 topk_dict {'top1': 0.967} is_best True lr [0.001]
training epoch 15 val accuracy 0.965 topk_dict {'top1': 0.965} is_best False lr [0.001]
training epoch 16 val accuracy 0.9656 topk_dict {'top1': 0.9656} is_best False lr [0.001]
training epoch 17 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.001]
training epoch 18 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.001]
training epoch 19 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best False lr [0.001]
training epoch 20 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best True lr [0.001]
training epoch 21 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.001]
training epoch 22 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.001]
training epoch 23 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.001]
training epoch 24 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.001]
training epoch 25 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.001]
training epoch 26 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.001]
training epoch 27 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.001]
training epoch 28 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.001]
training epoch 29 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.001]
training epoch 30 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.001]
training epoch 31 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.001]
training epoch 32 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best True lr [0.001]
training epoch 33 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best False lr [0.001]
training epoch 34 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.001]
training epoch 35 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best False lr [0.001]
training epoch 36 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 37 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.001]
training epoch 38 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.001]
training epoch 39 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.001]
training epoch 40 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.001]
training epoch 41 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.001]
training epoch 42 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 43 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
training epoch 44 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.001]
training epoch 45 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.001]
training epoch 46 val accuracy 0.972 topk_dict {'top1': 0.972} is_best True lr [0.001]
training epoch 47 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.001]
training epoch 48 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.001]
training epoch 49 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.972000)
finished training. finished 50 epochs. accuracy 0.972 topk_dict {'top1': 0.972}
