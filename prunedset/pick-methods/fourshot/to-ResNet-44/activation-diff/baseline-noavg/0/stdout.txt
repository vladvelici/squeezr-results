start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005787. All blocks and scores: [(22, 0.005787101807072759), (24, 0.006592476740479469), (25, 0.007601776160299778), (21, 0.008612961508333683), (27, 0.008965069777332246), (5, 0.009674609522335231), (23, 0.011229233001358807), (19, 0.011454987921752036), (35, 0.011519728694111109), (32, 0.013281174353323877), (29, 0.014178815414197743), (20, 0.014508438878692687), (31, 0.014615893829613924), (3, 0.014681300264783204), (26, 0.014724894892424345), (30, 0.01491536048706621), (7, 0.015097478055395186), (28, 0.016234831186011434), (37, 0.018546362640336156), (33, 0.021617852384224534), (39, 0.02187628811225295), (6, 0.022251417161896825), (50, 0.022445981856435537), (34, 0.022565887309610844), (49, 0.02260288712568581), (8, 0.023474456276744604), (38, 0.02385126263834536), (41, 0.024523035157471895), (40, 0.024661971954628825), (1, 0.025388095527887344), (46, 0.02624473161995411), (45, 0.026683185482397676), (48, 0.026970997685566545), (44, 0.028061731019988656), (51, 0.02873983862809837), (42, 0.028769566910341382), (43, 0.03079548478126526), (47, 0.031195558607578278), (0, 0.0327165094204247), (13, 0.03601942025125027), (15, 0.043151278514415026), (14, 0.04341263696551323), (16, 0.0443306602537632), (12, 0.049656884744763374), (4, 0.05115430802106857), (11, 0.05217862082645297), (52, 0.05327532859519124), (2, 0.05518383253365755), (10, 0.06016709841787815), (9, 0.08553026430308819), (17, 0.18986638449132442), (18, 0.2766866236925125), (36, 0.2898172214627266), (53, 0.8816948086023331)]
computing accuracy for after removing block 22 . block score: 0.005787101807072759
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006947. All blocks and scores: [(24, 0.006946946436073631), (25, 0.007925601792521775), (21, 0.00861296127550304), (27, 0.008884541573934257), (5, 0.009674609289504588), (19, 0.011454987688921392), (23, 0.01149947417434305), (35, 0.011587338638491929), (32, 0.013315335963852704), (29, 0.014122492633759975), (20, 0.014508438995108008), (31, 0.01453536655753851), (3, 0.014681299682706594), (30, 0.01495350175537169), (7, 0.01509747828822583), (26, 0.015386729617603123), (28, 0.016657372005283833), (37, 0.018698561703786254), (33, 0.02183614973910153), (6, 0.022251417161896825), (39, 0.02227854309603572), (50, 0.022396721877157688), (34, 0.022579425014555454), (49, 0.022588349413126707), (8, 0.02347445604391396), (38, 0.02401084848679602), (41, 0.024710635421797633), (40, 0.024832447059452534), (1, 0.025388095527887344), (46, 0.026328841922804713), (45, 0.026519648265093565), (48, 0.026865347754210234), (51, 0.028594731353223324), (44, 0.02869078260846436), (42, 0.028934542555361986), (47, 0.030598992248997092), (43, 0.030889177694916725), (0, 0.03271650895476341), (13, 0.03601941931992769), (15, 0.04315127804875374), (14, 0.04341263556852937), (16, 0.0443306602537632), (12, 0.04965688521042466), (4, 0.05115430802106857), (11, 0.052178621757775545), (52, 0.0527448202483356), (2, 0.05518383486196399), (10, 0.06016709841787815), (9, 0.08553026616573334), (17, 0.18986639194190502), (18, 0.2766866311430931), (36, 0.29418329522013664), (53, 0.8765672594308853)]
computing accuracy for after removing block 24 . block score: 0.006946946436073631
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007965. All blocks and scores: [(25, 0.00796479161363095), (27, 0.008502037031576037), (21, 0.008612961624749005), (5, 0.009674609638750553), (35, 0.01112444803584367), (19, 0.011454987921752036), (23, 0.011499473708681762), (32, 0.012667875387705863), (29, 0.01361895480658859), (31, 0.014255343470722437), (30, 0.014440408791415393), (20, 0.014508438995108008), (3, 0.01468130003195256), (7, 0.015097478404641151), (26, 0.015341691090725362), (28, 0.016541524790227413), (37, 0.018848978681489825), (34, 0.021491800900548697), (33, 0.021746610989794135), (50, 0.022144784219563007), (6, 0.022251417161896825), (49, 0.022573676193132997), (39, 0.022594625828787684), (8, 0.02347445674240589), (38, 0.023919350700452924), (41, 0.02473141113296151), (40, 0.02521214378066361), (1, 0.025388094829395413), (45, 0.026285272324457765), (46, 0.026299893856048584), (48, 0.026813949458301067), (51, 0.028448978438973427), (44, 0.028867241693660617), (42, 0.028876986354589462), (47, 0.030472576385363936), (43, 0.03083793236874044), (0, 0.0327165094204247), (13, 0.03601942025125027), (15, 0.04315127898007631), (14, 0.04341263696551323), (16, 0.0443306602537632), (12, 0.0496568838134408), (4, 0.05115430802106857), (11, 0.05217862315475941), (52, 0.05221219174563885), (2, 0.055183833464980125), (10, 0.060167099349200726), (9, 0.08553026616573334), (17, 0.18986638449132442), (18, 0.2766866274178028), (36, 0.2956240698695183), (53, 0.8761104345321655)]
computing accuracy for after removing block 25 . block score: 0.00796479161363095
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008207. All blocks and scores: [(27, 0.008207484032027423), (21, 0.00861296127550304), (5, 0.00967460940591991), (35, 0.010663896100595593), (19, 0.011454987805336714), (23, 0.011499474057927728), (32, 0.012014233274385333), (29, 0.012787629035301507), (31, 0.013865676242858171), (30, 0.013961306307464838), (20, 0.014508438878692687), (3, 0.014681299682706594), (26, 0.01491980126593262), (7, 0.015097478637471795), (28, 0.015723921358585358), (37, 0.018793187802657485), (34, 0.02036181092262268), (33, 0.021328615257516503), (50, 0.021633303724229336), (49, 0.02223234553821385), (6, 0.022251416463404894), (39, 0.02252841927111149), (8, 0.02347445674240589), (38, 0.02384312590584159), (41, 0.024403041228652), (40, 0.025254084262996912), (1, 0.025388095760717988), (45, 0.02569323405623436), (46, 0.02590800402686), (48, 0.026390639366582036), (51, 0.02774876286275685), (42, 0.028475591680034995), (44, 0.028856614604592323), (47, 0.02979940176010132), (43, 0.030201827874407172), (0, 0.032716508489102125), (13, 0.03601941931992769), (15, 0.0431512794457376), (14, 0.04341263463720679), (16, 0.044330660719424486), (12, 0.0496568838134408), (52, 0.050796682480722666), (4, 0.05115430802106857), (11, 0.05217862315475941), (2, 0.05518383299931884), (10, 0.060167099349200726), (9, 0.08553026616573334), (17, 0.18986639194190502), (18, 0.2766866199672222), (36, 0.2947889715433121), (53, 0.869580864906311)]
computing accuracy for after removing block 27 . block score: 0.008207484032027423
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008613. All blocks and scores: [(21, 0.008612961391918361), (5, 0.009674609871581197), (35, 0.01048718485981226), (19, 0.011454987921752036), (23, 0.01149947417434305), (32, 0.011747056501917541), (29, 0.012900045374408364), (31, 0.013738625450059772), (30, 0.013831985997967422), (20, 0.014508438762277365), (3, 0.014681299799121916), (26, 0.014919801382347941), (7, 0.01509747828822583), (28, 0.016265673097223043), (37, 0.018666349118575454), (34, 0.020145454443991184), (50, 0.021326792892068624), (33, 0.021582858171314), (49, 0.02211856422945857), (6, 0.02225141692906618), (39, 0.022289566695690155), (8, 0.02347445674240589), (38, 0.023616680642589927), (41, 0.024516037665307522), (40, 0.025366824585944414), (45, 0.02536774054169655), (1, 0.025388095062226057), (46, 0.025604827562347054), (48, 0.02612509415484965), (51, 0.027203567326068878), (42, 0.028293345822021365), (44, 0.02932620607316494), (47, 0.02935170498676598), (43, 0.030030403053388), (0, 0.0327165094204247), (13, 0.03601941931992769), (15, 0.04315127991139889), (14, 0.04341263649985194), (16, 0.044330660719424486), (12, 0.04965688334777951), (52, 0.050038255751132965), (4, 0.05115430895239115), (11, 0.05217862268909812), (2, 0.05518383393064141), (10, 0.06016709888353944), (9, 0.08553026523441076), (17, 0.18986638449132442), (18, 0.2766866311430931), (36, 0.29525746032595634), (53, 0.8683890998363495)]
computing accuracy for after removing block 21 . block score: 0.008612961391918361
removed block 21 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009675. All blocks and scores: [(5, 0.009674609522335231), (35, 0.010542472009547055), (19, 0.011454988038167357), (23, 0.011545548914000392), (32, 0.011696714675053954), (29, 0.013034458039328456), (30, 0.013541992870159447), (31, 0.013661347446031868), (20, 0.014508438296616077), (26, 0.014561282470822334), (3, 0.014681299915537238), (7, 0.01509747828822583), (28, 0.016272222623229027), (37, 0.018855378264561296), (34, 0.020170693984255195), (50, 0.021195361856371164), (33, 0.021736358292400837), (49, 0.022025791462510824), (6, 0.022251417161896825), (39, 0.022593395318835974), (8, 0.02347445674240589), (38, 0.023794722044840455), (41, 0.02448631334118545), (45, 0.02517408598214388), (1, 0.02538809599354863), (46, 0.02559636766090989), (40, 0.02570292423479259), (48, 0.02593583008274436), (51, 0.026903111720457673), (42, 0.028371038613840938), (47, 0.029131256975233555), (44, 0.029263162752613425), (43, 0.03027651901356876), (0, 0.0327165094204247), (13, 0.03601942025125027), (15, 0.04315127804875374), (14, 0.04341263649985194), (16, 0.04433065978810191), (52, 0.049492979887872934), (12, 0.04965688521042466), (4, 0.05115430802106857), (11, 0.05217862222343683), (2, 0.0551838343963027), (10, 0.06016709888353944), (9, 0.08553026430308819), (17, 0.18986638821661472), (18, 0.2766866199672222), (36, 0.2977275848388672), (53, 0.8672097846865654)]
computing accuracy for after removing block 5 . block score: 0.009674609522335231
removed block 5 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010497. All blocks and scores: [(35, 0.010497342678718269), (19, 0.01136433391366154), (23, 0.011454001301899552), (32, 0.011731749982573092), (29, 0.01297837623860687), (30, 0.013561801169998944), (31, 0.01381281134672463), (20, 0.014028266537934542), (26, 0.014234644477255642), (3, 0.014681299915537238), (28, 0.01640962902456522), (37, 0.019115549745038152), (7, 0.01932149240747094), (34, 0.020494532072916627), (50, 0.02102655451744795), (33, 0.021409297129139304), (49, 0.022096335887908936), (39, 0.022289574844762683), (38, 0.023183459881693125), (41, 0.024258682504296303), (6, 0.0250028595328331), (8, 0.025038711028173566), (45, 0.025084450840950012), (46, 0.025368364993482828), (1, 0.0253880952950567), (48, 0.025792344473302364), (40, 0.026035186368972063), (51, 0.0268554356880486), (42, 0.028462825110182166), (44, 0.028849951224401593), (47, 0.02911300305277109), (43, 0.030238439794629812), (0, 0.03271650895476341), (13, 0.036061248276382685), (15, 0.04305667895823717), (16, 0.04365199012681842), (14, 0.043659396935254335), (52, 0.04937674105167389), (4, 0.05115430802106857), (12, 0.051509722135961056), (11, 0.05406309058889747), (2, 0.05518383299931884), (10, 0.062402029521763325), (9, 0.08971724659204483), (17, 0.18636955507099628), (18, 0.27677176892757416), (36, 0.29570789262652397), (53, 0.8705098479986191)]
computing accuracy for after removing block 35 . block score: 0.010497342678718269
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011364. All blocks and scores: [(19, 0.011364334146492183), (23, 0.011454001069068909), (32, 0.011731750331819057), (29, 0.012978376471437514), (30, 0.013561801169998944), (31, 0.013812811695970595), (20, 0.014028266654349864), (26, 0.014234645059332252), (3, 0.01468130003195256), (28, 0.01640962902456522), (37, 0.01887263939715922), (7, 0.019321493105962873), (34, 0.020494531374424696), (50, 0.021021219668909907), (33, 0.02140929689630866), (49, 0.021970301866531372), (39, 0.0222410352434963), (38, 0.022285724757239223), (41, 0.024062653072178364), (45, 0.024892093846574426), (46, 0.024894545087590814), (6, 0.025002859300002456), (8, 0.02503871195949614), (1, 0.025388095760717988), (48, 0.025495541049167514), (40, 0.0256039013620466), (51, 0.026838496793061495), (42, 0.028305645333603024), (44, 0.028504314133897424), (47, 0.028528794180601835), (43, 0.029594503110274673), (0, 0.03271650895476341), (13, 0.036061248276382685), (15, 0.04305667942389846), (16, 0.043651989195495844), (14, 0.043659398797899485), (52, 0.04860273469239473), (4, 0.051154307555407286), (12, 0.05150972167029977), (11, 0.05406309198588133), (2, 0.05518383253365755), (10, 0.06240202859044075), (9, 0.08971724286675453), (17, 0.1863695476204157), (18, 0.27677175775170326), (36, 0.29528703913092613), (53, 0.8746362999081612)]
computing accuracy for after removing block 19 . block score: 0.011364334146492183
removed block 19 current accuracy 0.9978 loss from initial  0.0021999999999999797
training start
training epoch 0 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 6 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 8 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 9 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 10 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 38 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.013828. All blocks and scores: [(32, 0.01382779877167195), (23, 0.014179330551996827), (29, 0.014371297787874937), (3, 0.014532861998304725), (26, 0.014981160406023264), (31, 0.015014649601653218), (20, 0.015215820516459644), (30, 0.015415651258081198), (28, 0.016773439245298505), (7, 0.017283566296100616), (37, 0.01783129433169961), (39, 0.02095045172609389), (34, 0.021568203810602427), (33, 0.021691315341740847), (50, 0.02170450845733285), (49, 0.021744444267824292), (38, 0.02302651316858828), (41, 0.023541713366284966), (6, 0.02386827883310616), (8, 0.02402693615294993), (40, 0.02403916255570948), (1, 0.02443696092814207), (46, 0.025528011145070195), (45, 0.025533490581437945), (48, 0.02600114536471665), (44, 0.02714466815814376), (42, 0.02755554928444326), (51, 0.027767251944169402), (43, 0.029655962018296123), (47, 0.030341740231961012), (0, 0.03097685589455068), (13, 0.03403903730213642), (14, 0.041804264299571514), (15, 0.0419944548048079), (16, 0.04407665506005287), (12, 0.048846736550331116), (4, 0.05009629437699914), (11, 0.05087260343134403), (52, 0.05210902541875839), (2, 0.05417251726612449), (10, 0.05906171863898635), (9, 0.08211997896432877), (17, 0.18902903236448765), (18, 0.2684990167617798), (36, 0.2825135737657547), (53, 0.8695385530591011)]
computing accuracy for after removing block 32 . block score: 0.01382779877167195
removed block 32 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.014179. All blocks and scores: [(23, 0.014179329853504896), (29, 0.014371297555044293), (3, 0.01453286164905876), (26, 0.014981160871684551), (31, 0.015014649368822575), (20, 0.015215820982120931), (30, 0.01541565137449652), (28, 0.016773438546806574), (7, 0.01728356583043933), (37, 0.017709662206470966), (39, 0.0211828772444278), (34, 0.021289754193276167), (50, 0.02182787051424384), (49, 0.021953275660052896), (33, 0.02245111484080553), (38, 0.022529817651957273), (41, 0.023673353483900428), (6, 0.023868278367444873), (8, 0.024026935920119286), (1, 0.02443696092814207), (40, 0.02479319297708571), (45, 0.025442895479500294), (46, 0.02556027309037745), (48, 0.026422765105962753), (51, 0.02766515640541911), (42, 0.02786477073095739), (44, 0.028117324225604534), (43, 0.029841662384569645), (47, 0.030715611996129155), (0, 0.030976855661720037), (13, 0.03403903776779771), (14, 0.041804265696555376), (15, 0.041994454339146614), (16, 0.04407665506005287), (12, 0.04884673608466983), (4, 0.05009629484266043), (11, 0.05087260389700532), (52, 0.051727195270359516), (2, 0.0541725168004632), (10, 0.05906172236427665), (9, 0.08211997989565134), (17, 0.1890290342271328), (18, 0.2684990167617798), (36, 0.2913876920938492), (53, 0.8756121024489403)]
computing accuracy for after removing block 23 . block score: 0.014179329853504896
removed block 23 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.014317. All blocks and scores: [(26, 0.014317309716716409), (3, 0.014532861881889403), (31, 0.01455652341246605), (29, 0.014605700969696045), (30, 0.014988841023296118), (20, 0.01521582086570561), (28, 0.01663751807063818), (7, 0.017283566296100616), (37, 0.018104895250871778), (34, 0.02074657496996224), (50, 0.02153672743588686), (49, 0.02170614432543516), (39, 0.0219337644521147), (38, 0.02303034206852317), (33, 0.023517046822234988), (41, 0.02355763642117381), (6, 0.02386827999725938), (8, 0.024026935687288642), (1, 0.024436961393803358), (45, 0.025107984896749258), (40, 0.025365363573655486), (46, 0.025454741902649403), (48, 0.02632909268140793), (51, 0.0271901935338974), (42, 0.027935193153098226), (44, 0.02795924572274089), (43, 0.029981798958033323), (47, 0.03046940895728767), (0, 0.03097685519605875), (13, 0.03403903637081385), (14, 0.0418042647652328), (15, 0.04199445387348533), (16, 0.04407665506005287), (12, 0.04884673561900854), (4, 0.05009629623964429), (52, 0.050121037289500237), (11, 0.05087260389700532), (2, 0.05417252006009221), (10, 0.059061720967292786), (9, 0.08211997989565134), (17, 0.18902903236448765), (18, 0.2684990242123604), (36, 0.2939722277224064), (53, 0.8718752413988113)]
computing accuracy for after removing block 26 . block score: 0.014317309716716409
removed block 26 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.014024. All blocks and scores: [(31, 0.014024498173967004), (29, 0.014084144029766321), (30, 0.014397098799236119), (3, 0.014532861765474081), (20, 0.015215820982120931), (7, 0.017283565597608685), (37, 0.017553278477862477), (28, 0.018389170290902257), (34, 0.019022601190954447), (50, 0.02107421960681677), (49, 0.02128935046494007), (39, 0.02158034290187061), (38, 0.022097323555499315), (41, 0.022769787115976214), (33, 0.023560381028801203), (6, 0.02386827883310616), (45, 0.023904108675196767), (8, 0.024026936385780573), (46, 0.024329507490620017), (1, 0.024436960695311427), (40, 0.025156863732263446), (48, 0.02554848580621183), (51, 0.026251277420669794), (42, 0.02721153455786407), (44, 0.027850423008203506), (43, 0.02891132910735905), (47, 0.02971733035519719), (0, 0.030976856127381325), (13, 0.03403903730213642), (14, 0.041804264299571514), (15, 0.041994454339146614), (16, 0.04407665552571416), (52, 0.0478216209448874), (12, 0.048846736550331116), (4, 0.050096295308321714), (11, 0.05087260436266661), (2, 0.05417251959443092), (10, 0.0590617205016315), (9, 0.08211997803300619), (17, 0.1890290379524231), (18, 0.2684990204870701), (36, 0.28670768439769745), (53, 0.8765682652592659)]
computing accuracy for after removing block 31 . block score: 0.014024498173967004
removed block 31 current accuracy 0.9934 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 29, with score 0.014084. All blocks and scores: [(29, 0.014084144379012287), (30, 0.014397099148482084), (3, 0.014532861765474081), (20, 0.015215820982120931), (7, 0.01728356583043933), (37, 0.01738871680572629), (28, 0.01838916982524097), (34, 0.018867006758227944), (50, 0.021234611980617046), (49, 0.0215106257237494), (39, 0.02195415901951492), (38, 0.02210302953608334), (41, 0.022895193425938487), (45, 0.023866857634857297), (6, 0.02386827883310616), (8, 0.024026935687288642), (1, 0.024436961160972714), (46, 0.024734297301620245), (48, 0.025716110365465283), (40, 0.025899279862642288), (51, 0.02600754424929619), (33, 0.02603448205627501), (42, 0.027326774084940553), (44, 0.028625188628211617), (43, 0.028908766340464354), (47, 0.02990509639494121), (0, 0.03097685589455068), (13, 0.034039036836475134), (14, 0.04180426523089409), (15, 0.04199445340782404), (16, 0.04407665552571416), (52, 0.04740249505266547), (12, 0.04884673608466983), (4, 0.050096295773983), (11, 0.05087260436266661), (2, 0.05417251819744706), (10, 0.0590617205016315), (9, 0.08211997989565134), (17, 0.1890290379524231), (18, 0.2684990242123604), (36, 0.2976493537425995), (53, 0.881860226392746)]
computing accuracy for after removing block 29 . block score: 0.014084144379012287
removed block 29 current accuracy 0.9874 loss from initial  0.012599999999999945
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 30, with score 0.014508. All blocks and scores: [(30, 0.014507669489830732), (3, 0.014532861416228116), (20, 0.015215821214951575), (37, 0.017081135883927345), (7, 0.01728356652893126), (28, 0.018389170058071613), (34, 0.018918760120868683), (50, 0.020943490555509925), (49, 0.02149511151947081), (38, 0.022163324989378452), (39, 0.022366678807884455), (41, 0.022583496291190386), (45, 0.023514820728451014), (6, 0.023868279298767447), (8, 0.024026935920119286), (46, 0.024427736410871148), (1, 0.024436961160972714), (51, 0.02518242970108986), (48, 0.025415739975869656), (40, 0.026241583982482553), (42, 0.027400135761126876), (33, 0.027658761711791158), (43, 0.02872227202169597), (47, 0.029189044144004583), (44, 0.029254927998408675), (0, 0.03097685589455068), (13, 0.034039036836475134), (14, 0.0418042647652328), (15, 0.041994454339146614), (16, 0.04407665552571416), (52, 0.04605383472517133), (12, 0.04884673561900854), (4, 0.05009629623964429), (11, 0.050872604828327894), (2, 0.05417252006009221), (10, 0.0590617205016315), (9, 0.08211998082697392), (17, 0.18902903608977795), (18, 0.2684990130364895), (36, 0.30333834886550903), (53, 0.8817706927657127)]
computing accuracy for after removing block 30 . block score: 0.014507669489830732
removed block 30 current accuracy 0.9802 loss from initial  0.01980000000000004
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 3, with score 0.014533. All blocks and scores: [(3, 0.014532861765474081), (20, 0.015215820982120931), (37, 0.01692952960729599), (7, 0.017283566296100616), (28, 0.01838916982524097), (34, 0.018824161728844047), (50, 0.020739397266879678), (49, 0.021679407684132457), (38, 0.02248414373025298), (41, 0.02263662382028997), (39, 0.02286411775276065), (45, 0.02342762891203165), (6, 0.023868279764428735), (8, 0.024026935920119286), (1, 0.02443696092814207), (46, 0.024718376342207193), (51, 0.024851090973243117), (48, 0.025541944662109017), (40, 0.02723577246069908), (42, 0.027625669492408633), (43, 0.028837974881753325), (47, 0.029195151524618268), (33, 0.029795213835313916), (44, 0.029864101437851787), (0, 0.030976855428889394), (13, 0.034039036836475134), (14, 0.0418042647652328), (15, 0.04199445527046919), (16, 0.044076654594391584), (52, 0.04492850927636027), (12, 0.048846736550331116), (4, 0.05009629623964429), (11, 0.05087260389700532), (2, 0.054172517731785774), (10, 0.05906172189861536), (9, 0.08211997803300619), (17, 0.1890290379524231), (18, 0.2684990204870701), (36, 0.31508518010377884), (53, 0.8874276876449585)]
computing accuracy for after removing block 3 . block score: 0.014532861765474081
removed block 3 current accuracy 0.9808 loss from initial  0.019199999999999995
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 20, with score 0.014568. All blocks and scores: [(20, 0.014568258891813457), (37, 0.01826809160411358), (28, 0.01843008236028254), (34, 0.01909179938957095), (7, 0.02030624309554696), (50, 0.020675749983638525), (38, 0.021205136086791754), (49, 0.022343307500705123), (39, 0.022892450215294957), (41, 0.023092239862307906), (6, 0.02339821867644787), (45, 0.023764122743159533), (1, 0.024436961626634), (8, 0.02477934048511088), (46, 0.024901377502828836), (51, 0.025232888059690595), (48, 0.02585885557346046), (42, 0.028146873461082578), (33, 0.029175788862630725), (44, 0.0292093672323972), (47, 0.0293064727447927), (40, 0.029523282777518034), (43, 0.029677226906642318), (0, 0.030976856127381325), (13, 0.03167026722803712), (14, 0.03753320034593344), (15, 0.04151472309604287), (16, 0.042644827626645565), (52, 0.04527251562103629), (11, 0.05092681618407369), (12, 0.05096728587523103), (4, 0.05382649740204215), (2, 0.05417251866310835), (10, 0.0611306382343173), (9, 0.08560002315789461), (17, 0.18960802629590034), (18, 0.26695217192173004), (36, 0.3219086155295372), (53, 0.884695440530777)]
computing accuracy for after removing block 20 . block score: 0.014568258891813457
removed block 20 current accuracy 0.9654 loss from initial  0.034599999999999964
training start
training epoch 0 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 1 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 2 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 3 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 4 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 5 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 6 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 8 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 9 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 10 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 11 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 12 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 13 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 14 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 17 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 18 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 19 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 20 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 21 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 22 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 23 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 24 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 25 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 26 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 27 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 28 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 29 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 31 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 32 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 33 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 34 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 37 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 38 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 39 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 40 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 41 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 42 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 43 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 44 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 45 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 46 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 49 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
loading model_best from epoch 10 (acc 0.998800)
finished training. finished 50 epochs. accuracy 0.9988 topk_dict {'top1': 0.9988}
start iteration 16
[activation diff]: block to remove picked: 37, with score 0.017896. All blocks and scores: [(37, 0.017895931378006935), (7, 0.019301642896607518), (28, 0.020297925919294357), (39, 0.020754541037604213), (49, 0.02166828326880932), (50, 0.021740364143624902), (38, 0.022231979994103312), (34, 0.0232395485509187), (41, 0.023604190908372402), (40, 0.024112595012411475), (8, 0.024613036075606942), (1, 0.024776343256235123), (46, 0.025252953870221972), (45, 0.025468456791713834), (6, 0.025701952632516623), (48, 0.02631860156543553), (33, 0.02678368054330349), (44, 0.027112880488857627), (51, 0.027377332095056772), (42, 0.027462969068437815), (43, 0.029290581587702036), (47, 0.029756295960396528), (0, 0.031057925429195166), (13, 0.03387422580271959), (14, 0.04186294134706259), (15, 0.04240502370521426), (16, 0.04257524386048317), (12, 0.04951965715736151), (4, 0.05080701922997832), (11, 0.05084715085104108), (52, 0.051792146638035774), (2, 0.05423546023666859), (10, 0.05656867893412709), (9, 0.08177133183926344), (17, 0.1858142353594303), (18, 0.2627427838742733), (36, 0.2838175520300865), (53, 0.852826215326786)]
computing accuracy for after removing block 37 . block score: 0.017895931378006935
removed block 37 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 7, with score 0.019302. All blocks and scores: [(7, 0.019301642896607518), (28, 0.020297925220802426), (49, 0.02044279337860644), (50, 0.021047194488346577), (39, 0.021100844722241163), (34, 0.0232395485509187), (41, 0.023520878050476313), (38, 0.02353335521183908), (46, 0.023902366403490305), (40, 0.02410461870022118), (45, 0.024227446177974343), (8, 0.024613036308437586), (1, 0.024776343256235123), (48, 0.02489909832365811), (44, 0.02521260268986225), (6, 0.02570195239968598), (51, 0.026342671364545822), (42, 0.026521687395870686), (33, 0.026783680776134133), (43, 0.027232830179855227), (47, 0.028236807323992252), (0, 0.031057924265041947), (13, 0.033874225337058306), (14, 0.041862939950078726), (15, 0.04240502463653684), (16, 0.04257524339482188), (52, 0.049375352915376425), (12, 0.04951965715736151), (4, 0.05080701969563961), (11, 0.05084715178236365), (2, 0.0542354597710073), (10, 0.05656867800280452), (9, 0.08177132904529572), (17, 0.18581423722207546), (18, 0.2627427875995636), (36, 0.2838175520300865), (53, 0.8772924989461899)]
computing accuracy for after removing block 7 . block score: 0.019301642896607518
removed block 7 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 28, with score 0.018602. All blocks and scores: [(28, 0.018602327210828662), (39, 0.01954411412589252), (49, 0.02002642839215696), (38, 0.020081689581274986), (50, 0.020103983348235488), (34, 0.021635133773088455), (41, 0.022731324192136526), (44, 0.023117084987461567), (46, 0.023187826620414853), (40, 0.02388706523925066), (45, 0.024076736764982343), (48, 0.024223849643021822), (1, 0.02477634302340448), (33, 0.024910825304687023), (6, 0.025701952865347266), (42, 0.025817314395681024), (51, 0.02607191842980683), (43, 0.026429150719195604), (47, 0.02724057575687766), (8, 0.029984467662870884), (0, 0.031057924032211304), (13, 0.03210106585174799), (14, 0.03762140031903982), (15, 0.04073778074234724), (16, 0.04138507042080164), (12, 0.046390390023589134), (52, 0.048390711192041636), (11, 0.04932095017284155), (4, 0.050807020626962185), (2, 0.05423545837402344), (10, 0.055148000828921795), (9, 0.08320946525782347), (17, 0.1677765641361475), (18, 0.2514189723879099), (36, 0.27018552273511887), (53, 0.8977113962173462)]
computing accuracy for after removing block 28 . block score: 0.018602327210828662
removed block 28 current accuracy 0.9886 loss from initial  0.011399999999999966
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 38, with score 0.018424. All blocks and scores: [(38, 0.018423572182655334), (39, 0.01886498974636197), (49, 0.019383677281439304), (50, 0.019401407102122903), (34, 0.01993461069650948), (41, 0.02196079376153648), (46, 0.02237578947097063), (44, 0.022783667780458927), (45, 0.0228546098805964), (48, 0.02321117022074759), (40, 0.02409685216844082), (1, 0.024776343256235123), (51, 0.02493555680848658), (42, 0.02534068818204105), (43, 0.025390520226210356), (6, 0.025701952632516623), (33, 0.02615216444246471), (47, 0.02653354383073747), (8, 0.02998446812853217), (0, 0.031057924265041947), (13, 0.03210106585174799), (14, 0.03762140031903982), (15, 0.040737781673669815), (16, 0.041385069489479065), (52, 0.04569927090778947), (12, 0.046390388160943985), (11, 0.049320952501147985), (4, 0.050807018764317036), (2, 0.05423545790836215), (10, 0.05514800315722823), (9, 0.08320946618914604), (17, 0.1677765678614378), (18, 0.25141897797584534), (36, 0.2673373147845268), (53, 0.9163639545440674)]
computing accuracy for after removing block 38 . block score: 0.018423572182655334
removed block 38 current accuracy 0.9814 loss from initial  0.01859999999999995
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 49, with score 0.018490. All blocks and scores: [(49, 0.018489987356588244), (50, 0.018675697036087513), (34, 0.01993461069650948), (39, 0.021427282132208347), (48, 0.021490965504199266), (44, 0.021585253765806556), (46, 0.021726532140746713), (45, 0.021737771341577172), (41, 0.02244815486483276), (51, 0.023978583281859756), (47, 0.024432139471173286), (1, 0.024776342790573835), (42, 0.025134507566690445), (43, 0.02528533455915749), (6, 0.025701952865347266), (40, 0.026022528763860464), (33, 0.026152165373787284), (8, 0.02998446812853217), (0, 0.031057925429195166), (13, 0.03210106585174799), (14, 0.03762139892205596), (15, 0.040737781673669815), (16, 0.041385071352124214), (52, 0.042685119435191154), (12, 0.04639038955792785), (11, 0.049320950638502836), (4, 0.05080701969563961), (2, 0.054235458839684725), (10, 0.05514800036326051), (9, 0.08320946525782347), (17, 0.1677765715867281), (18, 0.25141897052526474), (36, 0.2673373185098171), (53, 0.9183550626039505)]
computing accuracy for after removing block 49 . block score: 0.018489987356588244
removed block 49 current accuracy 0.9772 loss from initial  0.022800000000000042
since last training loss: 0.021600000000000064 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 34, with score 0.019935. All blocks and scores: [(34, 0.019934610929340124), (50, 0.02073940122500062), (39, 0.021427281899377704), (48, 0.021490965969860554), (44, 0.0215852539986372), (46, 0.021726531209424138), (45, 0.021737771341577172), (41, 0.022448154632002115), (47, 0.024432138772681355), (1, 0.024776342790573835), (42, 0.025134506868198514), (43, 0.025285334326326847), (6, 0.02570195239968598), (51, 0.025752549525350332), (40, 0.026022528996691108), (33, 0.02615216444246471), (8, 0.02998446812853217), (0, 0.031057925196364522), (13, 0.032101064920425415), (14, 0.03762139938771725), (15, 0.04073778074234724), (16, 0.04138507088646293), (52, 0.045099339447915554), (12, 0.046390390023589134), (11, 0.04932094970718026), (4, 0.050807016901671886), (2, 0.05423545930534601), (10, 0.05514799989759922), (9, 0.08320946618914604), (17, 0.16777656599879265), (18, 0.25141896307468414), (36, 0.2673373147845268), (53, 1.1340146660804749)]
computing accuracy for after removing block 34 . block score: 0.019934610929340124
removed block 34 current accuracy 0.9562 loss from initial  0.04379999999999995
since last training loss: 0.04259999999999997 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 50, with score 0.020660. All blocks and scores: [(50, 0.02065986185334623), (45, 0.02132003358565271), (46, 0.021861142478883266), (41, 0.022175263380631804), (48, 0.022280401084572077), (39, 0.02251215814612806), (44, 0.023163648322224617), (1, 0.024776343256235123), (51, 0.024866592371836305), (42, 0.02514370414428413), (47, 0.02518888027407229), (43, 0.025430901674553752), (6, 0.02570195239968598), (33, 0.026152164675295353), (40, 0.02696245233528316), (8, 0.029984467662870884), (0, 0.031057924032211304), (13, 0.0321010653860867), (14, 0.03762139892205596), (15, 0.040737779811024666), (16, 0.04138507088646293), (52, 0.04359734524041414), (12, 0.04639039095491171), (11, 0.04932095017284155), (4, 0.0508070201613009), (2, 0.05423545930534601), (10, 0.05514800129458308), (9, 0.08320946712046862), (17, 0.1677765641361475), (18, 0.2514189723879099), (36, 0.2846885919570923), (53, 1.1557839065790176)]
computing accuracy for after removing block 50 . block score: 0.02065986185334623
removed block 50 current accuracy 0.9354 loss from initial  0.06459999999999999
since last training loss: 0.06340000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.021320. All blocks and scores: [(45, 0.02132003311999142), (46, 0.021861142246052623), (41, 0.022175263613462448), (48, 0.022280401550233364), (39, 0.022512157913297415), (44, 0.023163648322224617), (1, 0.024776343256235123), (42, 0.025143703445792198), (47, 0.02518888097256422), (43, 0.025430901674553752), (6, 0.02570195239968598), (33, 0.02615216444246471), (40, 0.026962451869621873), (51, 0.02725045313127339), (8, 0.029984467662870884), (0, 0.031057924265041947), (13, 0.032101064920425415), (14, 0.03762139938771725), (15, 0.040737781673669815), (16, 0.04138506995514035), (52, 0.04617008753120899), (12, 0.04639038862660527), (11, 0.04932095296680927), (4, 0.0508070201613009), (2, 0.054235456977039576), (10, 0.05514799989759922), (9, 0.08320947084575891), (17, 0.16777656599879265), (18, 0.25141897425055504), (36, 0.2846886068582535), (53, 1.4269753247499466)]
computing accuracy for after removing block 45 . block score: 0.02132003311999142
removed block 45 current accuracy 0.9116 loss from initial  0.08840000000000003
training start
training epoch 0 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best True lr [0.001]
training epoch 1 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 2 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best False lr [0.001]
training epoch 3 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best True lr [0.001]
training epoch 4 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best True lr [0.001]
training epoch 5 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 6 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 7 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 8 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 9 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 10 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 11 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 12 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 14 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 15 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 16 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 17 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 18 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 19 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 20 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 21 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 22 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 23 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 24 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 25 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 26 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 27 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 28 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 29 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 30 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 31 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 32 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 33 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 34 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 35 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 36 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 38 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 39 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 40 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 41 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 42 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 43 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 44 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 45 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 46 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 47 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 48 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 49 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
loading model_best from epoch 23 (acc 0.994200)
finished training. finished 50 epochs. accuracy 0.9942 topk_dict {'top1': 0.9942}
start iteration 24
[activation diff]: block to remove picked: 39, with score 0.024587. All blocks and scores: [(39, 0.02458686428144574), (41, 0.025096707744523883), (46, 0.025973531883209944), (48, 0.02598420949652791), (40, 0.02630315162241459), (1, 0.02698386530391872), (6, 0.027237874921411276), (44, 0.027490820502862334), (42, 0.027924270601943135), (8, 0.028167002135887742), (47, 0.02933062263764441), (43, 0.029572461498901248), (0, 0.03106879978440702), (51, 0.03187224268913269), (13, 0.03355282265692949), (16, 0.039386316668242216), (14, 0.040606056340038776), (15, 0.042629566974937916), (33, 0.04361114278435707), (12, 0.04987752251327038), (11, 0.051125362515449524), (10, 0.05598341301083565), (52, 0.05619047675281763), (4, 0.056329246144741774), (2, 0.05797107703983784), (9, 0.0840282766148448), (17, 0.17697762325406075), (18, 0.2585097402334213), (36, 0.26577626541256905), (53, 0.8942254036664963)]
computing accuracy for after removing block 39 . block score: 0.02458686428144574
removed block 39 current accuracy 0.9872 loss from initial  0.012800000000000034
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.024347. All blocks and scores: [(48, 0.024346891790628433), (46, 0.025823801988735795), (1, 0.026983865769580007), (44, 0.02699895529076457), (6, 0.027237875387072563), (41, 0.02731291437521577), (47, 0.028120697243139148), (8, 0.0281670019030571), (42, 0.029057508567348123), (40, 0.02974670217372477), (43, 0.029955767560750246), (51, 0.030920430785045028), (0, 0.03106879978440702), (13, 0.03355282312259078), (16, 0.03938631573691964), (14, 0.04060605587437749), (15, 0.04262956837192178), (33, 0.043611141853034496), (12, 0.04987752251327038), (11, 0.051125360652804375), (52, 0.05173359252512455), (10, 0.055983411613851786), (4, 0.056329246144741774), (2, 0.05797107657417655), (9, 0.08402827568352222), (17, 0.1769776213914156), (18, 0.2585097402334213), (36, 0.26577627286314964), (53, 0.9674505293369293)]
computing accuracy for after removing block 48 . block score: 0.024346891790628433
removed block 48 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.025824. All blocks and scores: [(46, 0.025823801523074508), (1, 0.026983865071088076), (44, 0.026998955756425858), (6, 0.02723787445574999), (41, 0.027312914142385125), (47, 0.028120696544647217), (8, 0.028167002135887742), (42, 0.029057508567348123), (40, 0.029746701940894127), (43, 0.02995576593093574), (0, 0.031068800715729594), (13, 0.03355282265692949), (51, 0.03482566541060805), (16, 0.039386316668242216), (14, 0.040606056805700064), (15, 0.04262956790626049), (33, 0.04361114138737321), (12, 0.04987752391025424), (11, 0.05112536111846566), (52, 0.05353488167747855), (10, 0.05598341207951307), (4, 0.05632924707606435), (2, 0.05797107657417655), (9, 0.08402827382087708), (17, 0.1769776251167059), (18, 0.258509736508131), (36, 0.26577625796198845), (53, 1.2048081755638123)]
computing accuracy for after removing block 46 . block score: 0.025823801523074508
removed block 46 current accuracy 0.9496 loss from initial  0.0504
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 1, with score 0.026984. All blocks and scores: [(1, 0.02698386600241065), (44, 0.026998955756425858), (6, 0.027237874921411276), (41, 0.027312914608046412), (8, 0.0281670019030571), (42, 0.029057508567348123), (40, 0.029746702406555414), (43, 0.029955766862258315), (0, 0.03106879978440702), (47, 0.03157644090242684), (13, 0.03355282265692949), (51, 0.03617331990972161), (16, 0.039386315271258354), (14, 0.040606056805700064), (15, 0.04262956790626049), (33, 0.04361114138737321), (12, 0.049877522978931665), (11, 0.05112536111846566), (52, 0.051941308192908764), (10, 0.05598341301083565), (4, 0.0563292452134192), (2, 0.05797107657417655), (9, 0.08402827475219965), (17, 0.17697762325406075), (18, 0.25850973278284073), (36, 0.26577626168727875), (53, 1.4166672378778458)]
computing accuracy for after removing block 1 . block score: 0.02698386600241065
removed block 1 current accuracy 0.9484 loss from initial  0.05159999999999998
since last training loss: 0.04579999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 6, with score 0.024697. All blocks and scores: [(6, 0.024696534732356668), (44, 0.0266346822027117), (41, 0.027417293284088373), (8, 0.028326066210865974), (42, 0.02929356601089239), (43, 0.03029740834608674), (0, 0.03106880048289895), (47, 0.031433560186997056), (13, 0.0320521229878068), (40, 0.03212627116590738), (51, 0.036836700048297644), (16, 0.037932618986815214), (14, 0.038731847889721394), (15, 0.04040792444720864), (33, 0.042451745364815), (12, 0.04822471272200346), (52, 0.0523526044562459), (11, 0.052487777546048164), (10, 0.05868749553337693), (4, 0.06047715712338686), (2, 0.06457336898893118), (9, 0.07922540605068207), (17, 0.1785978004336357), (18, 0.2560272105038166), (36, 0.26990826800465584), (53, 1.4177197217941284)]
computing accuracy for after removing block 6 . block score: 0.024696534732356668
removed block 6 current accuracy 0.9344 loss from initial  0.06559999999999999
since last training loss: 0.059799999999999964 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 44, with score 0.025045. All blocks and scores: [(44, 0.025044741574674845), (41, 0.025337401311844587), (42, 0.028550497954711318), (43, 0.029236780246719718), (47, 0.02957679471001029), (0, 0.031068799318745732), (13, 0.031365969916805625), (40, 0.03197359060868621), (8, 0.035025013610720634), (51, 0.035906501580029726), (16, 0.03656783979386091), (33, 0.039225650019943714), (14, 0.03933793632313609), (15, 0.04201497370377183), (52, 0.05075686937198043), (12, 0.05216740211471915), (11, 0.05493432795628905), (10, 0.05924140755087137), (4, 0.060477155726403), (2, 0.0645733680576086), (9, 0.08080410119146109), (17, 0.17207058519124985), (18, 0.2569996304810047), (36, 0.25974060222506523), (53, 1.425086110830307)]
computing accuracy for after removing block 44 . block score: 0.025044741574674845
removed block 44 current accuracy 0.8824 loss from initial  0.11760000000000004
since last training loss: 0.11180000000000001 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 41, with score 0.025337. All blocks and scores: [(41, 0.02533740154467523), (42, 0.02855049935169518), (43, 0.029236780013889074), (0, 0.031068799551576376), (13, 0.03136596945114434), (47, 0.03186663752421737), (40, 0.03197359154000878), (8, 0.035025013610720634), (51, 0.036104979924857616), (16, 0.03656783979386091), (33, 0.03922564908862114), (14, 0.039337935857474804), (15, 0.04201497370377183), (52, 0.049837626516819), (12, 0.05216740258038044), (11, 0.054934329353272915), (10, 0.05924140848219395), (4, 0.06047715526074171), (2, 0.06457336898893118), (9, 0.08080409932881594), (17, 0.1720705796033144), (18, 0.2569996193051338), (36, 0.25974060222506523), (53, 1.5618746429681778)]
computing accuracy for after removing block 41 . block score: 0.02533740154467523
removed block 41 current accuracy 0.8306 loss from initial  0.1694
since last training loss: 0.16359999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 0, with score 0.031069. All blocks and scores: [(0, 0.03106879978440702), (42, 0.031211300985887647), (13, 0.03136596945114434), (43, 0.031596566550433636), (40, 0.03197359154000878), (47, 0.032760122790932655), (8, 0.03502501454204321), (51, 0.035028448794037104), (16, 0.036567839328199625), (33, 0.03922564955428243), (14, 0.039337935857474804), (15, 0.04201497370377183), (52, 0.048426191322505474), (12, 0.05216740211471915), (11, 0.05493432795628905), (10, 0.059241408947855234), (4, 0.06047715526074171), (2, 0.06457336712628603), (9, 0.08080410026013851), (17, 0.1720705833286047), (18, 0.2569996155798435), (36, 0.25974059849977493), (53, 1.7179315835237503)]
computing accuracy for after removing block 0 . block score: 0.03106879978440702
removed block 0 current accuracy 0.7222 loss from initial  0.27780000000000005
since last training loss: 0.272 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.028057. All blocks and scores: [(13, 0.028056856710463762), (47, 0.029443027917295694), (42, 0.029858249938115478), (8, 0.03294715518131852), (51, 0.03344722604379058), (43, 0.0334694292396307), (14, 0.03398995427414775), (16, 0.035531210247427225), (15, 0.035956698935478926), (40, 0.03633932489901781), (33, 0.03700124332681298), (52, 0.04710173839703202), (12, 0.05133601417765021), (11, 0.055157232098281384), (10, 0.06538781337440014), (4, 0.06747301481664181), (2, 0.07047712616622448), (9, 0.07794561237096786), (17, 0.1723147500306368), (18, 0.25315790995955467), (36, 0.2695367969572544), (53, 1.6785699278116226)]
computing accuracy for after removing block 13 . block score: 0.028056856710463762
removed block 13 current accuracy 0.7006 loss from initial  0.2994
training start
training epoch 0 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 1 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best True lr [0.001]
training epoch 2 val accuracy 0.959 topk_dict {'top1': 0.959} is_best True lr [0.001]
training epoch 3 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.001]
training epoch 4 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.001]
training epoch 5 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.001]
training epoch 6 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best True lr [0.001]
training epoch 7 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.001]
training epoch 8 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.001]
training epoch 9 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 10 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best True lr [0.001]
training epoch 11 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best True lr [0.001]
training epoch 12 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.001]
training epoch 13 val accuracy 0.972 topk_dict {'top1': 0.972} is_best True lr [0.001]
training epoch 14 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best True lr [0.001]
training epoch 15 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best True lr [0.001]
training epoch 16 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best True lr [0.001]
training epoch 17 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 18 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 19 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best True lr [0.001]
training epoch 20 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.001]
training epoch 21 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best True lr [0.001]
training epoch 22 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.001]
training epoch 23 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 24 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 25 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best False lr [0.001]
training epoch 26 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best True lr [0.001]
training epoch 27 val accuracy 0.977 topk_dict {'top1': 0.977} is_best True lr [0.001]
training epoch 28 val accuracy 0.975 topk_dict {'top1': 0.975} is_best False lr [0.001]
training epoch 29 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 30 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 31 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 32 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best True lr [0.001]
training epoch 33 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 34 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 35 val accuracy 0.9756 topk_dict {'top1': 0.9756} is_best False lr [0.001]
training epoch 36 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 37 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 38 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best True lr [0.001]
training epoch 39 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 40 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 41 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best True lr [0.001]
training epoch 42 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 43 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 44 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 45 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 46 val accuracy 0.978 topk_dict {'top1': 0.978} is_best True lr [0.001]
training epoch 47 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 48 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 49 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.979200)
finished training. finished 50 epochs. accuracy 0.9792 topk_dict {'top1': 0.9792}
