start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004112. All blocks and scores: [(1, 0.004111806279979646), (30, 0.007531445822678506), (2, 0.007728804717771709), (31, 0.009409212740138173), (34, 0.010633390513248742), (33, 0.010768219130113721), (35, 0.010826651123352349), (32, 0.011131544597446918), (28, 0.012192571070045233), (29, 0.013092639856040478), (26, 0.013270106515847147), (25, 0.014763001585379243), (27, 0.01578354462981224), (24, 0.01580518949776888), (22, 0.015843698638491333), (23, 0.01730801025405526), (39, 0.01998384390026331), (42, 0.02084138710051775), (38, 0.02102866256609559), (14, 0.0215167086571455), (43, 0.0216877032071352), (5, 0.02187711838632822), (41, 0.022125155432149768), (44, 0.022776450961828232), (45, 0.023535518208518624), (40, 0.024229632457718253), (47, 0.02465185197070241), (37, 0.02517395932227373), (49, 0.02518479316495359), (3, 0.02567107114009559), (21, 0.0257029440253973), (50, 0.025765859289094806), (20, 0.027230343082919717), (46, 0.028618559008464217), (17, 0.029949785210192204), (51, 0.03131366614252329), (48, 0.03152880095876753), (19, 0.034745858050882816), (16, 0.04510569479316473), (15, 0.04667254723608494), (0, 0.04746154695749283), (6, 0.05039409967139363), (7, 0.05069215735420585), (4, 0.05092597519978881), (10, 0.06328557478263974), (13, 0.06400972791016102), (8, 0.06672555953264236), (52, 0.06828812137246132), (12, 0.07267716992646456), (11, 0.07419469766318798), (9, 0.07928675133734941), (36, 0.3385251797735691), (18, 0.4787600636482239), (53, 0.9074815139174461)]
computing accuracy for after removing block 1 . block score: 0.004111806279979646
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007558. All blocks and scores: [(30, 0.0075583591824397445), (2, 0.007992399856448174), (31, 0.00937669596169144), (34, 0.01056909840553999), (33, 0.010759366792626679), (35, 0.010833792155608535), (32, 0.011090524261817336), (28, 0.012191424728371203), (29, 0.013140873867087066), (26, 0.013311112183146179), (25, 0.014746290864422917), (24, 0.015801147324964404), (22, 0.015853286604397), (27, 0.015870402101427317), (23, 0.017250196309760213), (39, 0.019925505621358752), (42, 0.02083982666954398), (38, 0.020938864443451166), (5, 0.021410030080005527), (14, 0.021470680367201567), (43, 0.02164699137210846), (41, 0.022096744505688548), (44, 0.022830850444734097), (45, 0.023494189605116844), (40, 0.02426302875392139), (47, 0.024626431986689568), (37, 0.02515707165002823), (49, 0.025184772675856948), (21, 0.025624872418120503), (50, 0.025800991337746382), (3, 0.026267620967701077), (20, 0.027126540895551443), (46, 0.02863829699344933), (17, 0.030022146413102746), (51, 0.031291100429371), (48, 0.03151489142328501), (19, 0.03466663183644414), (16, 0.04479835694655776), (15, 0.04640808515250683), (0, 0.04746154695749283), (4, 0.050930495373904705), (6, 0.05134963057935238), (7, 0.05156157026067376), (10, 0.06291997572407126), (13, 0.06426404230296612), (52, 0.0681746331974864), (8, 0.0683986684307456), (12, 0.07294023409485817), (11, 0.07450826652348042), (9, 0.08042858727276325), (36, 0.3383275642991066), (18, 0.4787031188607216), (53, 0.9076696112751961)]
computing accuracy for after removing block 30 . block score: 0.0075583591824397445
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.007992. All blocks and scores: [(2, 0.007992399740032852), (31, 0.009402871248312294), (34, 0.010204410180449486), (35, 0.010435783420689404), (33, 0.010974526521749794), (32, 0.01132048515137285), (28, 0.012191424961201847), (29, 0.013140873750671744), (26, 0.013311112066730857), (25, 0.014746290864422917), (24, 0.015801146859303117), (22, 0.015853286837227643), (27, 0.015870402567088604), (23, 0.017250196542590857), (39, 0.019866376649588346), (38, 0.020629742182791233), (42, 0.020691831363365054), (5, 0.02141003031283617), (14, 0.021470679668709636), (43, 0.021839084336534142), (41, 0.02201103698462248), (44, 0.02278478699736297), (45, 0.023337426595389843), (47, 0.024608810432255268), (40, 0.02479364164173603), (49, 0.02500508981756866), (21, 0.025624872418120503), (37, 0.025666437344625592), (50, 0.025765020167455077), (3, 0.026267620734870434), (20, 0.02712653996422887), (46, 0.028450447134673595), (17, 0.03002214664593339), (51, 0.030892510432749987), (48, 0.031455071875825524), (19, 0.03466663137078285), (16, 0.04479835694655776), (15, 0.04640808468684554), (0, 0.04746154695749283), (4, 0.05093049397692084), (6, 0.05134962918236852), (7, 0.05156157072633505), (10, 0.06291997479274869), (13, 0.06426404323428869), (52, 0.0677470751106739), (8, 0.06839867029339075), (12, 0.07294023409485817), (11, 0.07450826652348042), (9, 0.08042859006673098), (36, 0.3417893536388874), (18, 0.4787031151354313), (53, 0.9106026887893677)]
computing accuracy for after removing block 2 . block score: 0.007992399740032852
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009391. All blocks and scores: [(31, 0.009391383500769734), (34, 0.010356180369853973), (35, 0.01053083362057805), (33, 0.010978628532029688), (32, 0.011285086162388325), (28, 0.01222222566138953), (29, 0.01339500502217561), (26, 0.013411890366114676), (25, 0.014773015631362796), (24, 0.015895847463980317), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (39, 0.01986844907514751), (42, 0.020744004985317588), (38, 0.020750499796122313), (5, 0.021117351250723004), (14, 0.02132761781103909), (43, 0.021792823681607842), (41, 0.021959960460662842), (44, 0.022877607261762023), (45, 0.023284759372472763), (47, 0.024535594042390585), (40, 0.024922655895352364), (49, 0.024976717308163643), (21, 0.025540467351675034), (50, 0.025736609008163214), (37, 0.025740002281963825), (3, 0.026626083999872208), (20, 0.027130910428240895), (46, 0.02835425129160285), (17, 0.03005285933613777), (51, 0.030807055300101638), (48, 0.0313640043605119), (19, 0.03459096746519208), (16, 0.04449417209252715), (15, 0.046184624545276165), (0, 0.04746154835447669), (4, 0.05093384953215718), (7, 0.05248213326558471), (6, 0.053186831530183554), (10, 0.0630735894665122), (13, 0.0641754250973463), (52, 0.06737186759710312), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.3429318964481354), (18, 0.48187144100666046), (53, 0.9105552807450294)]
computing accuracy for after removing block 31 . block score: 0.009391383500769734
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.010090. All blocks and scores: [(34, 0.01008967007510364), (35, 0.010449821245856583), (33, 0.010985722299665213), (32, 0.011304144863970578), (28, 0.012222225777804852), (29, 0.013395004789344966), (26, 0.013411890366114676), (25, 0.01477301586419344), (24, 0.015895847231149673), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.01718752016313374), (39, 0.01979714771732688), (38, 0.02034430461935699), (42, 0.02058867714367807), (5, 0.021117352414876223), (14, 0.021327618276700377), (43, 0.02176103019155562), (41, 0.021869145799428225), (44, 0.022828259970992804), (45, 0.023396300617605448), (47, 0.024508256930857897), (49, 0.02499568462371826), (40, 0.025056052254512906), (21, 0.025540468515828252), (37, 0.025701351929455996), (50, 0.02590625174343586), (3, 0.02662608353421092), (20, 0.027130910428240895), (46, 0.028551972238346934), (17, 0.030052858404815197), (51, 0.03091105679050088), (48, 0.031486503314226866), (19, 0.03459096606820822), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.0474615478888154), (4, 0.050933847203850746), (7, 0.052482135593891144), (6, 0.053186831064522266), (10, 0.06307358900085092), (13, 0.06417542416602373), (52, 0.06731626018881798), (8, 0.07143167871981859), (12, 0.07294507883489132), (11, 0.07423979137092829), (9, 0.08192321565002203), (36, 0.34496788680553436), (18, 0.48187142610549927), (53, 0.9170897081494331)]
computing accuracy for after removing block 34 . block score: 0.01008967007510364
removed block 34 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010489. All blocks and scores: [(35, 0.01048931828700006), (33, 0.010985722299665213), (32, 0.011304144514724612), (28, 0.012222225544974208), (29, 0.013395005138590932), (26, 0.01341189059894532), (25, 0.014773015980608761), (24, 0.015895847231149673), (22, 0.015945045510306954), (27, 0.016057065688073635), (23, 0.017187519930303097), (39, 0.0192666407674551), (38, 0.01931570004671812), (42, 0.019673911854624748), (5, 0.021117351483553648), (41, 0.021174798952415586), (43, 0.02118000271730125), (14, 0.02132761781103909), (44, 0.022253611125051975), (45, 0.0232249372638762), (47, 0.024223519721999764), (49, 0.02466233097948134), (40, 0.02475132793188095), (37, 0.025114945601671934), (21, 0.025540468050166965), (50, 0.02563990536145866), (3, 0.02662608423270285), (20, 0.02713091066107154), (46, 0.02807540795765817), (17, 0.030052858171984553), (51, 0.03030704613775015), (48, 0.031094569014385343), (19, 0.03459096699953079), (16, 0.044494171626865864), (15, 0.046184624545276165), (0, 0.04746154695749283), (4, 0.05093384766951203), (7, 0.05248213419690728), (6, 0.05318683013319969), (10, 0.0630735857412219), (13, 0.0641754250973463), (52, 0.06632223818451166), (8, 0.07143167685717344), (12, 0.07294507790356874), (11, 0.07423979043960571), (9, 0.08192321471869946), (36, 0.3418983183801174), (18, 0.48187142610549927), (53, 0.9368007630109787)]
computing accuracy for after removing block 35 . block score: 0.01048931828700006
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010986. All blocks and scores: [(33, 0.010985722299665213), (32, 0.0113041449803859), (28, 0.012222225544974208), (29, 0.013395005138590932), (26, 0.013411890715360641), (25, 0.014773016097024083), (24, 0.01589584769681096), (22, 0.01594504527747631), (27, 0.016057065688073635), (23, 0.017187519930303097), (38, 0.01836523856036365), (39, 0.018731158692389727), (42, 0.018845457350835204), (41, 0.020227219443768263), (43, 0.02047862485051155), (5, 0.021117351250723004), (14, 0.021327618043869734), (44, 0.021796139888465405), (45, 0.0228491744492203), (47, 0.023645549081265926), (40, 0.02389344247058034), (49, 0.024012631038203835), (37, 0.024080609204247594), (50, 0.025119471130892634), (21, 0.025540468515828252), (3, 0.02662608353421092), (20, 0.02713091066107154), (46, 0.027472961228340864), (51, 0.02944464865140617), (17, 0.030052859103307128), (48, 0.03019627882167697), (19, 0.034590966533869505), (16, 0.044494171626865864), (15, 0.046184626407921314), (0, 0.04746154695749283), (4, 0.05093384813517332), (7, 0.05248213466256857), (6, 0.05318683199584484), (10, 0.06307358853518963), (13, 0.06417542602866888), (52, 0.06433123257011175), (8, 0.07143167871981859), (12, 0.07294507790356874), (11, 0.07423978950828314), (9, 0.0819232165813446), (36, 0.335262943059206), (18, 0.48187143355607986), (53, 0.958902508020401)]
computing accuracy for after removing block 33 . block score: 0.010985722299665213
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011304. All blocks and scores: [(32, 0.011304144863970578), (28, 0.012222225544974208), (29, 0.013395004789344966), (26, 0.013411890831775963), (25, 0.014773016097024083), (24, 0.015895847463980317), (22, 0.015945045044645667), (27, 0.01605706545524299), (23, 0.01718752016313374), (38, 0.017859897343441844), (39, 0.01848121453076601), (42, 0.018494685646146536), (41, 0.019707750994712114), (43, 0.019804098643362522), (5, 0.021117351250723004), (14, 0.02132761781103909), (44, 0.021341139916330576), (45, 0.02275731205008924), (47, 0.022884674137458205), (40, 0.022964164149016142), (49, 0.02350937225855887), (37, 0.023596108425408602), (50, 0.024730789940804243), (21, 0.02554046781733632), (3, 0.026626083767041564), (46, 0.026851587928831577), (20, 0.027130911126732826), (51, 0.02867021202109754), (48, 0.029500648844987154), (17, 0.030052859103307128), (19, 0.034590966533869505), (16, 0.04449417255818844), (15, 0.04618462547659874), (0, 0.04746154835447669), (4, 0.05093384766951203), (7, 0.05248213419690728), (6, 0.05318683013319969), (52, 0.06240901444107294), (10, 0.06307358667254448), (13, 0.06417542602866888), (8, 0.07143167778849602), (12, 0.07294507883489132), (11, 0.07423979137092829), (9, 0.08192321378737688), (36, 0.3304997384548187), (18, 0.48187142983078957), (53, 0.9826682284474373)]
computing accuracy for after removing block 32 . block score: 0.011304144863970578
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 3 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012355. All blocks and scores: [(28, 0.012355308281257749), (26, 0.013044924940913916), (29, 0.013217372237704694), (25, 0.015043900581076741), (27, 0.01590808853507042), (24, 0.015953138237819076), (22, 0.015996810281649232), (23, 0.017881255131214857), (39, 0.019437420181930065), (42, 0.019985359627753496), (43, 0.020619657589122653), (41, 0.02088490966707468), (38, 0.02109490684233606), (14, 0.021540809189900756), (44, 0.021962957689538598), (5, 0.022102883085608482), (40, 0.023085549008101225), (45, 0.023130531422793865), (47, 0.024519971571862698), (37, 0.024669146165251732), (49, 0.025182637153193355), (50, 0.025254219537600875), (3, 0.025569433346390724), (21, 0.02622583811171353), (20, 0.02734869043342769), (46, 0.027977945981547236), (17, 0.030209701508283615), (48, 0.030986614292487502), (51, 0.031047965167090297), (19, 0.03474803455173969), (16, 0.04499942250549793), (15, 0.04631040431559086), (0, 0.048053859267383814), (6, 0.04991057422012091), (4, 0.05053355684503913), (7, 0.05094194691628218), (10, 0.06270997412502766), (13, 0.0643216660246253), (8, 0.06701334938406944), (52, 0.06728146784007549), (12, 0.07238478120416403), (11, 0.07413098774850368), (9, 0.0790961580350995), (36, 0.3257690817117691), (18, 0.4785770885646343), (53, 0.8976526185870171)]
computing accuracy for after removing block 28 . block score: 0.012355308281257749
removed block 28 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.012960. All blocks and scores: [(29, 0.012960201711393893), (26, 0.01304492517374456), (25, 0.015043900697492063), (27, 0.015908088302239776), (24, 0.015953138237819076), (22, 0.015996810514479876), (23, 0.017881255829706788), (42, 0.01919475756585598), (39, 0.01938541210256517), (43, 0.02007182058878243), (41, 0.020562050864100456), (38, 0.020721119130030274), (14, 0.0215408094227314), (44, 0.02156905480660498), (5, 0.022102883784100413), (40, 0.022360719507560134), (45, 0.022769945207983255), (47, 0.02386322943493724), (37, 0.024274282855913043), (49, 0.024605834623798728), (50, 0.02494416246190667), (3, 0.02556943311356008), (21, 0.026225839275866747), (20, 0.027348690666258335), (46, 0.02755121188238263), (17, 0.030209700809791684), (51, 0.030356498900800943), (48, 0.030420348048210144), (19, 0.03474803315475583), (16, 0.04499942110851407), (15, 0.04631040710955858), (0, 0.0480538597330451), (6, 0.04991057422012091), (4, 0.05053355684503913), (7, 0.050941948778927326), (10, 0.06270997738465667), (13, 0.06432166695594788), (52, 0.06608576234430075), (8, 0.06701335217803717), (12, 0.07238478027284145), (11, 0.07413098774850368), (9, 0.07909615710377693), (36, 0.3203507103025913), (18, 0.4785770960152149), (53, 0.9134213477373123)]
computing accuracy for after removing block 29 . block score: 0.012960201711393893
removed block 29 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013045. All blocks and scores: [(26, 0.013044925057329237), (25, 0.015043900697492063), (27, 0.01590808783657849), (24, 0.015953138237819076), (22, 0.015996810281649232), (23, 0.0178812553640455), (39, 0.019107013009488583), (42, 0.019276597537100315), (38, 0.019901704974472523), (43, 0.019932779017835855), (41, 0.020357314962893724), (44, 0.02109017432667315), (14, 0.021540809189900756), (5, 0.022102883318439126), (40, 0.022545906016603112), (45, 0.022677875822409987), (47, 0.023630919633433223), (37, 0.024119770154356956), (49, 0.02414885559119284), (50, 0.02479869988746941), (3, 0.02556943381205201), (21, 0.026225837878882885), (20, 0.02734868973493576), (46, 0.027677958132699132), (51, 0.030103486496955156), (17, 0.03020970057696104), (48, 0.030508858850225806), (19, 0.03474803362041712), (16, 0.04499942297115922), (15, 0.04631040617823601), (0, 0.048053859267383814), (6, 0.04991057375445962), (4, 0.05053355544805527), (7, 0.050941947381943464), (10, 0.0627099759876728), (13, 0.06432166695594788), (52, 0.06569994706660509), (8, 0.06701335217803717), (12, 0.07238477934151888), (11, 0.07413098867982626), (9, 0.07909615710377693), (36, 0.3228929303586483), (18, 0.4785770922899246), (53, 0.917605571448803)]
computing accuracy for after removing block 26 . block score: 0.013044925057329237
removed block 26 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.015044. All blocks and scores: [(25, 0.015043900697492063), (24, 0.01595313847064972), (22, 0.015996810281649232), (27, 0.016247425694018602), (23, 0.017881255596876144), (42, 0.01851888047531247), (39, 0.018665107432752848), (43, 0.019496531691402197), (38, 0.019679608521983027), (41, 0.020041203359141946), (44, 0.020829148590564728), (14, 0.02154080872423947), (5, 0.02210288355126977), (40, 0.022117336513474584), (45, 0.022466135676950216), (47, 0.023400277132168412), (37, 0.023877529427409172), (49, 0.023910818621516228), (50, 0.02486640540882945), (3, 0.025569434044882655), (21, 0.026225838344544172), (46, 0.027130342554301023), (20, 0.027348689502105117), (51, 0.02928188513033092), (17, 0.030209701042622328), (48, 0.03046246455051005), (19, 0.03474803501740098), (16, 0.044999422039836645), (15, 0.046310403384268284), (0, 0.0480538597330451), (6, 0.04991057328879833), (4, 0.05053355544805527), (7, 0.0509419459849596), (10, 0.06270997412502766), (13, 0.06432166695594788), (52, 0.06438924465328455), (8, 0.06701335031539202), (12, 0.07238478027284145), (11, 0.07413098961114883), (9, 0.0790961580350995), (36, 0.319826353341341), (18, 0.478577084839344), (53, 0.9373276755213737)]
computing accuracy for after removing block 25 . block score: 0.015043900697492063
removed block 25 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.015953. All blocks and scores: [(24, 0.015953138237819076), (22, 0.015996810048818588), (27, 0.016065650386735797), (23, 0.01788125606253743), (42, 0.018204223597422242), (39, 0.018210744485259056), (38, 0.019399301847442985), (43, 0.019438328919932246), (41, 0.019927511923015118), (44, 0.02069377899169922), (14, 0.0215408094227314), (40, 0.021934569347649813), (5, 0.02210288285277784), (45, 0.022168411873281002), (47, 0.02302026702091098), (37, 0.023393116192892194), (49, 0.02342187287285924), (50, 0.024845891632139683), (3, 0.02556943381205201), (21, 0.026225838344544172), (46, 0.02695256215520203), (20, 0.027348690666258335), (51, 0.02845259546302259), (48, 0.029978265520185232), (17, 0.030209700344130397), (19, 0.03474803501740098), (16, 0.04499942250549793), (15, 0.04631040431559086), (0, 0.0480538597330451), (6, 0.049910572823137045), (4, 0.050533555913716555), (7, 0.050941948778927326), (52, 0.06258362531661987), (10, 0.06270997412502766), (13, 0.06432166695594788), (8, 0.06701335124671459), (12, 0.07238478120416403), (11, 0.07413098961114883), (9, 0.07909615896642208), (36, 0.3226884827017784), (18, 0.4785770922899246), (53, 0.9500005170702934)]
computing accuracy for after removing block 24 . block score: 0.015953138237819076
removed block 24 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.015465. All blocks and scores: [(27, 0.015464685740880668), (22, 0.015996810048818588), (23, 0.017881255596876144), (42, 0.0179729163646698), (39, 0.018139713676646352), (38, 0.019257524982094765), (43, 0.0193104378413409), (41, 0.01978682610206306), (44, 0.02046975214034319), (14, 0.021540809189900756), (40, 0.021700530545786023), (45, 0.022065392462536693), (5, 0.02210288285277784), (47, 0.022625267738476396), (49, 0.023015335435047746), (37, 0.0237300805747509), (50, 0.024667297257110476), (3, 0.02556943381205201), (21, 0.026225838577374816), (46, 0.026490798918530345), (20, 0.02734869043342769), (51, 0.027756021823734045), (48, 0.029504976933822036), (17, 0.03020970057696104), (19, 0.03474803362041712), (16, 0.044999422039836645), (15, 0.046310403384268284), (0, 0.04805385833606124), (6, 0.049910574685782194), (4, 0.05053355498239398), (7, 0.050941947381943464), (52, 0.06131279096007347), (10, 0.0627099759876728), (13, 0.06432166695594788), (8, 0.06701334845274687), (12, 0.07238478027284145), (11, 0.07413098867982626), (9, 0.07909615710377693), (36, 0.32346486672759056), (18, 0.4785770885646343), (53, 0.956744447350502)]
computing accuracy for after removing block 27 . block score: 0.015464685740880668
removed block 27 current accuracy 0.9912 loss from initial  0.00880000000000003
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.015997. All blocks and scores: [(22, 0.015996810281649232), (39, 0.01757651288062334), (42, 0.017614651704207063), (23, 0.017881255596876144), (38, 0.018456363817676902), (43, 0.018650232581421733), (41, 0.01940425904467702), (44, 0.020416070241481066), (40, 0.021213163621723652), (14, 0.0215408094227314), (45, 0.021858211839571595), (47, 0.021997671341523528), (5, 0.02210288355126977), (49, 0.02251124707981944), (37, 0.02311790524981916), (50, 0.02490296447649598), (3, 0.025569434044882655), (46, 0.02594382595270872), (21, 0.026225838344544172), (51, 0.027133577736094594), (20, 0.02734868973493576), (48, 0.029167948523536325), (17, 0.03020970057696104), (19, 0.03474803548306227), (16, 0.04499942343682051), (15, 0.04631040524691343), (0, 0.04805385693907738), (6, 0.04991057515144348), (4, 0.05053355684503913), (7, 0.05094194691628218), (52, 0.06007980601862073), (10, 0.06270997552201152), (13, 0.0643216660246253), (8, 0.06701334938406944), (12, 0.07238478027284145), (11, 0.07413099054247141), (9, 0.07909615524113178), (36, 0.3194149397313595), (18, 0.4785770960152149), (53, 0.9694049283862114)]
computing accuracy for after removing block 22 . block score: 0.015996810281649232
removed block 22 current accuracy 0.9874 loss from initial  0.012599999999999945
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.016866. All blocks and scores: [(42, 0.016865576850250363), (23, 0.0173951112665236), (39, 0.01758942659944296), (38, 0.018439556704834104), (43, 0.018838715506717563), (41, 0.019477240042760968), (44, 0.020530740497633815), (40, 0.020625520031899214), (14, 0.021540809655562043), (47, 0.021602539578452706), (45, 0.02191723883152008), (5, 0.022102882619947195), (49, 0.022103636292740703), (37, 0.023107431130483747), (50, 0.02496446156874299), (3, 0.025569432880729437), (46, 0.02584796119481325), (21, 0.026225838577374816), (51, 0.026470839977264404), (20, 0.027348690200597048), (48, 0.02863173419609666), (17, 0.030209701042622328), (19, 0.03474803455173969), (16, 0.04499942297115922), (15, 0.04631040431559086), (0, 0.04805385880172253), (6, 0.04991057515144348), (4, 0.05053355498239398), (7, 0.05094194645062089), (52, 0.05907438648864627), (10, 0.06270997179672122), (13, 0.06432166695594788), (8, 0.06701335031539202), (12, 0.07238478027284145), (11, 0.07413098774850368), (9, 0.07909615524113178), (36, 0.31886719167232513), (18, 0.4785770885646343), (53, 0.9826266318559647)]
computing accuracy for after removing block 42 . block score: 0.016865576850250363
removed block 42 current accuracy 0.9844 loss from initial  0.015599999999999947
training start
training epoch 0 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 2 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 4 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 5 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 6 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 9 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 19 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 16
[activation diff]: block to remove picked: 39, with score 0.019348. All blocks and scores: [(39, 0.01934835873544216), (38, 0.020994462072849274), (41, 0.021209418075159192), (5, 0.021773548796772957), (14, 0.02199185057543218), (43, 0.022000347496941686), (44, 0.022642237367108464), (40, 0.022949740756303072), (45, 0.023236151784658432), (47, 0.023967556888237596), (37, 0.024473832454532385), (23, 0.024619690608233213), (50, 0.024984905030578375), (49, 0.02499281638301909), (3, 0.026056363712996244), (46, 0.027486759005114436), (21, 0.030586127657443285), (48, 0.030861472245305777), (17, 0.031083449255675077), (51, 0.03163470095023513), (20, 0.03330363426357508), (19, 0.03887282405048609), (0, 0.046736182644963264), (15, 0.04715339280664921), (16, 0.0472547416575253), (6, 0.04904128424823284), (7, 0.04991512792184949), (4, 0.05017128912732005), (10, 0.06057564355432987), (13, 0.06461664848029613), (8, 0.06570099294185638), (52, 0.06847847811877728), (12, 0.07150830328464508), (11, 0.07410501036792994), (9, 0.07719453796744347), (36, 0.3236081153154373), (18, 0.46902094408869743), (53, 0.8892464190721512)]
computing accuracy for after removing block 39 . block score: 0.01934835873544216
removed block 39 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 38, with score 0.020994. All blocks and scores: [(38, 0.020994462072849274), (41, 0.021635742159560323), (5, 0.021773548796772957), (14, 0.021991850109770894), (43, 0.022145505528897047), (40, 0.02321065030992031), (44, 0.023370476439595222), (45, 0.02376563986763358), (47, 0.024126901989802718), (37, 0.02447383222170174), (23, 0.02461968921124935), (50, 0.0248003292363137), (49, 0.025101583218201995), (3, 0.026056363945826888), (46, 0.027744557475671172), (21, 0.03058612928725779), (51, 0.030764028895646334), (17, 0.031083449721336365), (48, 0.03130470076575875), (20, 0.0333036333322525), (19, 0.03887282311916351), (0, 0.046736182644963264), (15, 0.0471533895470202), (16, 0.047254739329218864), (6, 0.04904128471389413), (7, 0.049915128853172064), (4, 0.05017128819599748), (10, 0.0605756426230073), (13, 0.06461664848029613), (8, 0.06570099201053381), (52, 0.06839271169155836), (12, 0.07150830421596766), (11, 0.07410501036792994), (9, 0.07719453889876604), (36, 0.323608111590147), (18, 0.46902094781398773), (53, 0.9329177513718605)]
computing accuracy for after removing block 38 . block score: 0.020994462072849274
removed block 38 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 5, with score 0.021774. All blocks and scores: [(5, 0.02177354833111167), (41, 0.02183084678836167), (14, 0.021991850109770894), (43, 0.022257654229179025), (45, 0.023448873311281204), (47, 0.023669370217248797), (50, 0.023811176186427474), (44, 0.02384234545752406), (49, 0.024216356920078397), (37, 0.02447383268736303), (40, 0.024566214298829436), (23, 0.024619690142571926), (3, 0.02605636464431882), (46, 0.027673673816025257), (51, 0.02911961916834116), (48, 0.030351027147844434), (21, 0.03058612789027393), (17, 0.031083449255675077), (20, 0.033303634729236364), (19, 0.03887282405048609), (0, 0.04673618217930198), (15, 0.04715338908135891), (16, 0.04725473979488015), (6, 0.049041283782571554), (7, 0.049915128387510777), (4, 0.0501712872646749), (10, 0.060575641226023436), (13, 0.06461664941161871), (8, 0.06570099107921124), (52, 0.0657885642722249), (12, 0.07150830421596766), (11, 0.07410501036792994), (9, 0.07719453889876604), (36, 0.3236081153154373), (18, 0.46902094408869743), (53, 0.9573635905981064)]
computing accuracy for after removing block 5 . block score: 0.02177354833111167
removed block 5 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 14, with score 0.021214. All blocks and scores: [(14, 0.021214364329352975), (41, 0.021982263773679733), (43, 0.022362233605235815), (45, 0.023694578558206558), (47, 0.023809140548110008), (50, 0.023923000320792198), (23, 0.024059739196673036), (44, 0.02408643765375018), (49, 0.024225694593042135), (37, 0.025527583435177803), (3, 0.026056364178657532), (40, 0.026405430166050792), (46, 0.02794916438870132), (51, 0.02892492967657745), (17, 0.029927168041467667), (21, 0.029951106756925583), (48, 0.030396463349461555), (20, 0.03279503807425499), (19, 0.03844593511894345), (16, 0.0461049098521471), (15, 0.04662025859579444), (0, 0.04673618357628584), (6, 0.04893504781648517), (4, 0.0501712872646749), (7, 0.05383152747526765), (10, 0.06046036584302783), (13, 0.06368340738117695), (52, 0.0654798299074173), (8, 0.06717758160084486), (11, 0.06956977304071188), (12, 0.07045083213597536), (9, 0.07698616199195385), (36, 0.3305935524404049), (18, 0.47559019178152084), (53, 0.9583391845226288)]
computing accuracy for after removing block 14 . block score: 0.021214364329352975
removed block 14 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.023905. All blocks and scores: [(23, 0.023905243491753936), (50, 0.023948053130879998), (47, 0.02405271027237177), (41, 0.02411465346813202), (45, 0.024444116046652198), (49, 0.025054009165614843), (43, 0.02545443852432072), (44, 0.02558493404649198), (3, 0.026056364178657532), (37, 0.026246170978993177), (40, 0.02811451442539692), (46, 0.02840340114198625), (51, 0.02882018219679594), (21, 0.02972049033269286), (48, 0.03044531517662108), (17, 0.031438949052244425), (20, 0.03332327865064144), (19, 0.04183014063164592), (0, 0.04673618357628584), (16, 0.0470603471621871), (15, 0.048312628641724586), (6, 0.0489350501447916), (4, 0.0501712872646749), (7, 0.05383152421563864), (10, 0.06046036630868912), (13, 0.06368340831249952), (52, 0.06585226021707058), (8, 0.06717757973819971), (11, 0.06956977304071188), (12, 0.07045083027333021), (9, 0.07698616199195385), (36, 0.3419255018234253), (18, 0.4779866300523281), (53, 0.9188626185059547)]
computing accuracy for after removing block 23 . block score: 0.023905243491753936
removed block 23 current accuracy 0.9862 loss from initial  0.013800000000000034
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 47, with score 0.022937. All blocks and scores: [(47, 0.02293678349815309), (45, 0.023088814923539758), (50, 0.023143751779571176), (41, 0.023371877847239375), (49, 0.023593415273353457), (44, 0.025002309354022145), (43, 0.02509566629305482), (37, 0.025105310138314962), (3, 0.026056363712996244), (51, 0.027057991130277514), (46, 0.027147625107318163), (40, 0.027191024972125888), (48, 0.02943362551741302), (21, 0.029720490565523505), (17, 0.03143894858658314), (20, 0.03332327911630273), (19, 0.04183014063164592), (0, 0.04673618311062455), (16, 0.0470603471621871), (15, 0.0483126281760633), (6, 0.04893504874780774), (4, 0.05017128819599748), (7, 0.05383152514696121), (10, 0.06046036630868912), (52, 0.062139853835105896), (13, 0.06368340831249952), (8, 0.06717758066952229), (11, 0.06956977397203445), (12, 0.07045083027333021), (9, 0.07698616199195385), (36, 0.3387461379170418), (18, 0.4779866226017475), (53, 0.9353400245308876)]
computing accuracy for after removing block 47 . block score: 0.02293678349815309
removed block 47 current accuracy 0.9754 loss from initial  0.024599999999999955
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.023089. All blocks and scores: [(45, 0.023088814923539758), (41, 0.023371878545731306), (50, 0.024634440895169973), (44, 0.025002309354022145), (43, 0.02509566629305482), (37, 0.025105310371145606), (49, 0.025858007138594985), (3, 0.026056364178657532), (46, 0.02714762487448752), (40, 0.027191025437787175), (51, 0.02781206020154059), (21, 0.029720490565523505), (17, 0.03143894812092185), (48, 0.03217188687995076), (20, 0.03332327911630273), (19, 0.04183014156296849), (0, 0.04673618217930198), (16, 0.04706034762784839), (15, 0.04831263003870845), (6, 0.04893504781648517), (4, 0.050171288661658764), (7, 0.0538315256126225), (10, 0.06046036584302783), (52, 0.06256433809176087), (13, 0.06368340738117695), (8, 0.06717757973819971), (11, 0.06956977117806673), (12, 0.07045082841068506), (9, 0.0769861601293087), (36, 0.3387461453676224), (18, 0.4779866300523281), (53, 1.0376051664352417)]
computing accuracy for after removing block 45 . block score: 0.023088814923539758
removed block 45 current accuracy 0.9592 loss from initial  0.04079999999999995
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 41, with score 0.023372. All blocks and scores: [(41, 0.023371877847239375), (50, 0.023879635613411665), (44, 0.025002307957038283), (43, 0.025095666060224175), (37, 0.02510531060397625), (3, 0.026056363945826888), (49, 0.026190853910520673), (51, 0.02711409400217235), (40, 0.027191024739295244), (46, 0.029206779319792986), (21, 0.029720491031184793), (17, 0.03143894858658314), (48, 0.03169926372356713), (20, 0.03332327865064144), (19, 0.04183014016598463), (0, 0.0467361812479794), (16, 0.0470603471621871), (15, 0.04831262771040201), (6, 0.0489350501447916), (4, 0.050171290058642626), (7, 0.05383152607828379), (52, 0.05939936125651002), (10, 0.060460366774350405), (13, 0.0636834092438221), (8, 0.06717757973819971), (11, 0.06956977397203445), (12, 0.07045083120465279), (9, 0.0769861601293087), (36, 0.338746152818203), (18, 0.4779866151511669), (53, 1.1307840198278427)]
computing accuracy for after removing block 41 . block score: 0.023371877847239375
removed block 41 current accuracy 0.9428 loss from initial  0.05720000000000003
training start
training epoch 0 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 1 val accuracy 0.9884 topk_dict {'top1': 0.9884} is_best True lr [0.001]
training epoch 2 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 3 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 4 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 5 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 6 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 7 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 8 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 9 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 10 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 11 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 12 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 13 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 14 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 15 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 16 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 17 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 18 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 20 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 21 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 22 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 23 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 24 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 25 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 26 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 27 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 28 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 30 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 31 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 33 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 34 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 35 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 36 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 37 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 38 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 39 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 40 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 41 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 42 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 43 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 45 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 46 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 47 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 48 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 49 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.997000)
finished training. finished 50 epochs. accuracy 0.997 topk_dict {'top1': 0.997}
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.025898. All blocks and scores: [(50, 0.02589774806983769), (43, 0.02612201077863574), (44, 0.026157458778470755), (3, 0.026928558945655823), (49, 0.02770752878859639), (40, 0.028823615051805973), (37, 0.029246482998132706), (17, 0.0310649243183434), (46, 0.03177629038691521), (51, 0.03182803746312857), (48, 0.03444364853203297), (20, 0.039755343459546566), (21, 0.040593968238681555), (0, 0.04326161229982972), (19, 0.04516452131792903), (6, 0.04579635616391897), (16, 0.04625509539619088), (15, 0.04784976039081812), (4, 0.04798970511183143), (7, 0.048619319684803486), (10, 0.05772219691425562), (8, 0.06224945141002536), (13, 0.06319330213591456), (52, 0.06731790117919445), (12, 0.07022904139012098), (11, 0.07232838775962591), (9, 0.0739334300160408), (36, 0.29679710045456886), (18, 0.4275604374706745), (53, 0.9308716282248497)]
computing accuracy for after removing block 50 . block score: 0.02589774806983769
removed block 50 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 43, with score 0.026122. All blocks and scores: [(43, 0.026122011011466384), (44, 0.02615745784714818), (3, 0.026928559178486466), (49, 0.02770752878859639), (40, 0.02882361481897533), (37, 0.029246484395116568), (17, 0.031064923154190183), (46, 0.03177629131823778), (48, 0.03444364806637168), (51, 0.03454995667561889), (20, 0.039755343459546566), (21, 0.04059396870434284), (0, 0.04326161136850715), (19, 0.04516452085226774), (6, 0.045796355698257685), (16, 0.04625509586185217), (15, 0.047849761322140694), (4, 0.04798970511183143), (7, 0.04861932015046477), (10, 0.05772219831123948), (8, 0.062249451875686646), (13, 0.063193304464221), (52, 0.06580868735909462), (12, 0.07022904139012098), (11, 0.07232838775962591), (9, 0.07393343094736338), (36, 0.29679709672927856), (18, 0.4275604374706745), (53, 1.1457935720682144)]
computing accuracy for after removing block 43 . block score: 0.026122011011466384
removed block 43 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 3, with score 0.026929. All blocks and scores: [(3, 0.026928558479994535), (49, 0.027901312336325645), (44, 0.028724170522764325), (40, 0.028823615051805973), (37, 0.029246483696624637), (17, 0.031064923852682114), (51, 0.03343855170533061), (46, 0.03442911058664322), (48, 0.03577411640435457), (20, 0.03975534299388528), (21, 0.04059396870434284), (0, 0.043261611834168434), (19, 0.04516452085226774), (6, 0.045796355698257685), (16, 0.04625509586185217), (15, 0.04784975992515683), (4, 0.047989706974476576), (7, 0.048619319684803486), (10, 0.057722197845578194), (8, 0.06224945141002536), (13, 0.06319330306723714), (52, 0.06377370236441493), (12, 0.07022904139012098), (11, 0.07232838775962591), (9, 0.07393343094736338), (36, 0.29679710417985916), (18, 0.4275604300200939), (53, 1.301928550004959)]
computing accuracy for after removing block 3 . block score: 0.026928558479994535
removed block 3 current accuracy 0.967 loss from initial  0.03300000000000003
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 49, with score 0.027690. All blocks and scores: [(49, 0.027690049959346652), (44, 0.028486546128988266), (37, 0.029388511087745428), (40, 0.029607711592689157), (17, 0.030631280038505793), (51, 0.03290224447846413), (46, 0.033727279864251614), (48, 0.03569779731333256), (20, 0.03917481889948249), (21, 0.03972553834319115), (0, 0.04326161136850715), (19, 0.04423774732276797), (16, 0.04437999054789543), (15, 0.046939946711063385), (4, 0.04735639784485102), (7, 0.04740056023001671), (6, 0.048490666318684816), (10, 0.0614097872748971), (8, 0.06144235609099269), (13, 0.061976793222129345), (52, 0.06336618959903717), (12, 0.06783485691994429), (11, 0.07227572053670883), (9, 0.07277040090411901), (36, 0.29413141310214996), (18, 0.428793016821146), (53, 1.3168828785419464)]
computing accuracy for after removing block 49 . block score: 0.027690049959346652
removed block 49 current accuracy 0.9372 loss from initial  0.06279999999999997
since last training loss: 0.059799999999999964 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 44, with score 0.028487. All blocks and scores: [(44, 0.028486545896157622), (37, 0.029388509690761566), (40, 0.029607711592689157), (17, 0.030631280038505793), (46, 0.033727279864251614), (48, 0.035697797778993845), (51, 0.03663937374949455), (20, 0.039174819365143776), (21, 0.03972553834319115), (0, 0.04326161136850715), (19, 0.04423774732276797), (16, 0.04437999241054058), (15, 0.046939946711063385), (4, 0.047356401570141315), (7, 0.04740056116133928), (6, 0.048490666784346104), (10, 0.061409787740558386), (8, 0.06144235469400883), (13, 0.061976791359484196), (12, 0.06783485785126686), (52, 0.06807056535035372), (11, 0.07227571960538626), (9, 0.07277039997279644), (36, 0.29413140937685966), (18, 0.428793016821146), (53, 1.4965001046657562)]
computing accuracy for after removing block 44 . block score: 0.028486545896157622
removed block 44 current accuracy 0.8884 loss from initial  0.11160000000000003
since last training loss: 0.10860000000000003 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 37, with score 0.029389. All blocks and scores: [(37, 0.029388509690761566), (40, 0.029607712058350444), (17, 0.030631279572844505), (51, 0.03553957538679242), (46, 0.03632611455395818), (48, 0.03647442860528827), (20, 0.039174819365143776), (21, 0.039725538808852434), (0, 0.04326161276549101), (19, 0.044237746857106686), (16, 0.04437999194487929), (15, 0.04693994764238596), (4, 0.04735639924183488), (7, 0.04740055976435542), (6, 0.04849066585302353), (10, 0.0614097872748971), (8, 0.06144235422834754), (13, 0.06197679042816162), (52, 0.06555698346346617), (12, 0.06783485691994429), (11, 0.07227571774274111), (9, 0.07277040090411901), (36, 0.29413141310214996), (18, 0.4287930019199848), (53, 1.6978396624326706)]
computing accuracy for after removing block 37 . block score: 0.029388509690761566
removed block 37 current accuracy 0.8638 loss from initial  0.1362
since last training loss: 0.13319999999999999 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 17, with score 0.030631. All blocks and scores: [(17, 0.03063128050416708), (40, 0.03284753626212478), (51, 0.03306097583845258), (48, 0.035508339293301105), (46, 0.03692954871803522), (20, 0.039174817968159914), (21, 0.039725538808852434), (0, 0.04326161090284586), (19, 0.04423774732276797), (16, 0.04437999101355672), (15, 0.04693994717672467), (4, 0.04735640063881874), (7, 0.047400559298694134), (6, 0.048490666318684816), (10, 0.061409786343574524), (8, 0.06144235376268625), (13, 0.061976793222129345), (52, 0.06267448980361223), (12, 0.06783485691994429), (11, 0.07227572053670883), (9, 0.07277039997279644), (36, 0.29413140937685966), (18, 0.4287930130958557), (53, 1.6867160648107529)]
computing accuracy for after removing block 17 . block score: 0.03063128050416708
removed block 17 current accuracy 0.8628 loss from initial  0.1372
since last training loss: 0.13419999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.031149. All blocks and scores: [(51, 0.03114905650727451), (40, 0.03176727634854615), (48, 0.03496705973520875), (20, 0.036238439846783876), (46, 0.03660838631913066), (21, 0.03856919473037124), (0, 0.043261611834168434), (19, 0.04434556933119893), (16, 0.044379991479218006), (15, 0.046939946711063385), (4, 0.047356399707496166), (7, 0.047400560695677996), (6, 0.04849066725000739), (52, 0.061272161547094584), (10, 0.061409787740558386), (8, 0.06144235469400883), (13, 0.06197679229080677), (12, 0.06783485785126686), (11, 0.07227571774274111), (9, 0.07277039997279644), (36, 0.28640299662947655), (18, 0.41435015201568604), (53, 1.6760667711496353)]
computing accuracy for after removing block 51 . block score: 0.03114905650727451
removed block 51 current accuracy 0.7936 loss from initial  0.20640000000000003
since last training loss: 0.20340000000000003 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 40, with score 0.031767. All blocks and scores: [(40, 0.03176727588288486), (48, 0.034967060666531324), (20, 0.036238439846783876), (46, 0.03660838585346937), (21, 0.03856919426470995), (0, 0.043261611834168434), (19, 0.04434556979686022), (16, 0.04437999101355672), (15, 0.04693994764238596), (4, 0.047356399707496166), (7, 0.04740055976435542), (6, 0.04849066585302353), (10, 0.06140978867188096), (8, 0.06144235609099269), (13, 0.06197679229080677), (12, 0.06783485878258944), (52, 0.07030695769935846), (11, 0.07227571774274111), (9, 0.07277039811015129), (36, 0.28640299662947655), (18, 0.41435016319155693), (53, 1.9491035640239716)]
computing accuracy for after removing block 40 . block score: 0.03176727588288486
removed block 40 current accuracy 0.7086 loss from initial  0.2914
training start
training epoch 0 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 1 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 2 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 3 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.001]
training epoch 4 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 5 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best True lr [0.001]
training epoch 6 val accuracy 0.9552 topk_dict {'top1': 0.9552} is_best False lr [0.001]
training epoch 7 val accuracy 0.956 topk_dict {'top1': 0.956} is_best True lr [0.001]
training epoch 8 val accuracy 0.962 topk_dict {'top1': 0.962} is_best True lr [0.001]
training epoch 9 val accuracy 0.9604 topk_dict {'top1': 0.9604} is_best False lr [0.001]
training epoch 10 val accuracy 0.9602 topk_dict {'top1': 0.9602} is_best False lr [0.001]
training epoch 11 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best True lr [0.001]
training epoch 12 val accuracy 0.9634 topk_dict {'top1': 0.9634} is_best False lr [0.001]
training epoch 13 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best True lr [0.001]
training epoch 14 val accuracy 0.965 topk_dict {'top1': 0.965} is_best True lr [0.001]
training epoch 15 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.001]
training epoch 16 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 17 val accuracy 0.9652 topk_dict {'top1': 0.9652} is_best False lr [0.001]
training epoch 18 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.001]
training epoch 19 val accuracy 0.9674 topk_dict {'top1': 0.9674} is_best True lr [0.001]
training epoch 20 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.001]
training epoch 21 val accuracy 0.9678 topk_dict {'top1': 0.9678} is_best False lr [0.001]
training epoch 22 val accuracy 0.969 topk_dict {'top1': 0.969} is_best True lr [0.001]
training epoch 23 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 24 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 25 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.001]
training epoch 26 val accuracy 0.97 topk_dict {'top1': 0.97} is_best True lr [0.001]
training epoch 27 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 28 val accuracy 0.969 topk_dict {'top1': 0.969} is_best False lr [0.001]
training epoch 29 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.001]
training epoch 30 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
training epoch 31 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.001]
training epoch 32 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
training epoch 33 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best True lr [0.001]
training epoch 34 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.001]
training epoch 35 val accuracy 0.9706 topk_dict {'top1': 0.9706} is_best False lr [0.001]
training epoch 36 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.001]
training epoch 37 val accuracy 0.97 topk_dict {'top1': 0.97} is_best False lr [0.001]
training epoch 38 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.001]
training epoch 39 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.001]
training epoch 40 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.001]
training epoch 41 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.001]
training epoch 42 val accuracy 0.9692 topk_dict {'top1': 0.9692} is_best False lr [0.001]
training epoch 43 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.001]
training epoch 44 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 45 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best True lr [0.001]
training epoch 46 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 47 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 48 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best True lr [0.001]
training epoch 49 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.973200)
finished training. finished 50 epochs. accuracy 0.9732 topk_dict {'top1': 0.9732}
