start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9938 loss from initial  0.006199999999999983
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 3 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.03420672845095396), (2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (19, 0.03390769101679325), (23, 0.03820023126900196), (25, 0.03555062972009182), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (30, 0.0372479809448123), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 19 . block score: 0.03390769101679325
removed block 19 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.03420672845095396), (2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (23, 0.03820023126900196), (25, 0.03555062972009182), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (30, 0.0372479809448123), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 0 . block score: 0.03420672845095396
removed block 0 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (23, 0.03820023126900196), (25, 0.03555062972009182), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (30, 0.0372479809448123), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 25 . block score: 0.03555062972009182
removed block 25 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (23, 0.03820023126900196), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (30, 0.0372479809448123), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 30 . block score: 0.0372479809448123
removed block 30 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (23, 0.03820023126900196), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 23 . block score: 0.03820023126900196
removed block 23 current accuracy 0.9904 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (26, 0.04479057714343071), (27, 0.0383926946669817), (28, 0.041850319132208824), (29, 0.04038430564105511), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 27 . block score: 0.0383926946669817
removed block 27 current accuracy 0.986 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (26, 0.04479057714343071), (28, 0.041850319132208824), (29, 0.04038430564105511), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (35, 0.03962417133152485), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 35 . block score: 0.03962417133152485
removed block 35 current accuracy 0.982 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.04199771024286747), (4, 0.05317643657326698), (7, 0.04151379317045212), (8, 0.04097097925841808), (9, 0.06643529608845711), (10, 0.0623190775513649), (11, 0.0549243800342083), (12, 0.06206095218658447), (13, 0.05073258653283119), (14, 0.06611248105764389), (15, 0.07058077864348888), (16, 0.05996810272336006), (17, 0.09402826428413391), (18, 0.1909966543316841), (26, 0.04479057714343071), (28, 0.041850319132208824), (29, 0.04038430564105511), (31, 0.04223890230059624), (32, 0.042462291195988655), (33, 0.04573829285800457), (34, 0.04650522209703922), (36, 0.1606338918209076), (37, 0.04166964814066887), (38, 0.044980429112911224), (39, 0.047255320474505424), (40, 0.05062755569815636), (41, 0.05120375193655491), (42, 0.052621955052018166), (43, 0.05390481650829315), (44, 0.051558392122387886), (45, 0.05122331157326698), (46, 0.0511681642383337), (47, 0.0488607045263052), (48, 0.04656902700662613), (49, 0.04508805088698864), (50, 0.044792305678129196), (51, 0.04399978742003441), (52, 0.04332679323852062), (53, 0.050774671137332916)]
computing accuracy for after removing block 29 . block score: 0.04038430564105511
removed block 29 current accuracy 0.9758 loss from initial  0.0242
training start
training epoch 0 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 1 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 3 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 5 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 6 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 8 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 9 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 10 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 11 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 14 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 16 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 22 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 24 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 26 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 40 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 17 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.04191209562122822), (4, 0.05299127660691738), (7, 0.041343238204717636), (8, 0.04077230021357536), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (28, 0.041639113798737526), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (37, 0.041437357664108276), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 8 . block score: 0.04077230021357536
removed block 8 current accuracy 0.9946 loss from initial  0.00539999999999996
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.04191209562122822), (4, 0.05299127660691738), (7, 0.041343238204717636), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (28, 0.041639113798737526), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (37, 0.041437357664108276), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 7 . block score: 0.041343238204717636
removed block 7 current accuracy 0.9632 loss from initial  0.036800000000000055
since last training loss: 0.0364000000000001 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.04191209562122822), (4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (28, 0.041639113798737526), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (37, 0.041437357664108276), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 37 . block score: 0.041437357664108276
removed block 37 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.04580000000000006 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.04191209562122822), (4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (28, 0.041639113798737526), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 28 . block score: 0.041639113798737526
removed block 28 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.06040000000000001 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.04191209562122822), (4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 2 . block score: 0.04191209562122822
removed block 2 current accuracy 0.8192 loss from initial  0.18079999999999996
since last training loss: 0.1804 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (31, 0.042007576674222946), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 31 . block score: 0.042007576674222946
removed block 31 current accuracy 0.8096 loss from initial  0.1904
since last training loss: 0.19000000000000006 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (32, 0.042220599949359894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 32 . block score: 0.042220599949359894
removed block 32 current accuracy 0.7974 loss from initial  0.2026
since last training loss: 0.20220000000000005 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.05299127660691738), (9, 0.06619810685515404), (10, 0.06205979734659195), (11, 0.05466031841933727), (12, 0.06173843517899513), (13, 0.05046028085052967), (14, 0.06582802161574364), (15, 0.07023826986551285), (16, 0.05965803004801273), (17, 0.09351453185081482), (18, 0.1898810788989067), (26, 0.044569242745637894), (33, 0.045505862683057785), (34, 0.04627149552106857), (36, 0.15983548760414124), (38, 0.04473106563091278), (39, 0.04699242301285267), (40, 0.050345929339528084), (41, 0.05092316307127476), (42, 0.05232652276754379), (43, 0.05360882170498371), (44, 0.0512736514210701), (45, 0.05094093084335327), (46, 0.050882354378700256), (47, 0.048594195395708084), (48, 0.04631298780441284), (49, 0.04483887739479542), (50, 0.04454803466796875), (51, 0.04375644028186798), (52, 0.04308907687664032), (53, 0.05048828572034836)]
computing accuracy for after removing block 52 . block score: 0.04308907687664032
removed block 52 current accuracy 0.8028 loss from initial  0.19720000000000004
training start
training epoch 0 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 1 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 2 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 3 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 4 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 5 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 6 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 7 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 8 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 9 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 10 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 11 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 12 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 13 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 14 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 15 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 16 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 17 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 18 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 19 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 22 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 23 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 24 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 25 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 26 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 27 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 28 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 29 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 30 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 31 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 32 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 33 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 34 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 35 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 36 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 37 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 38 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 39 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 40 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 41 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 42 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 43 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 44 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 45 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 46 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 47 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 48 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 49 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.998400)
finished training. finished 50 epochs. accuracy 0.9984 topk_dict {'top1': 0.9984}
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (26, 0.044027913361787796), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (38, 0.04408166743814945), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (49, 0.04419355466961861), (50, 0.043892866000533104), (51, 0.043135980144143105), (53, 0.04970693960785866)]
computing accuracy for after removing block 51 . block score: 0.043135980144143105
removed block 51 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (26, 0.044027913361787796), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (38, 0.04408166743814945), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (49, 0.04419355466961861), (50, 0.043892866000533104), (53, 0.04970693960785866)]
computing accuracy for after removing block 50 . block score: 0.043892866000533104
removed block 50 current accuracy 0.9844 loss from initial  0.015599999999999947
since last training loss: 0.013999999999999901 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (26, 0.044027913361787796), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (38, 0.04408166743814945), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (49, 0.04419355466961861), (53, 0.04970693960785866)]
computing accuracy for after removing block 26 . block score: 0.044027913361787796
removed block 26 current accuracy 0.9708 loss from initial  0.029200000000000004
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (38, 0.04408166743814945), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (49, 0.04419355466961861), (53, 0.04970693960785866)]
computing accuracy for after removing block 38 . block score: 0.04408166743814945
removed block 38 current accuracy 0.9644 loss from initial  0.035599999999999965
since last training loss: 0.03399999999999992 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (49, 0.04419355466961861), (53, 0.04970693960785866)]
computing accuracy for after removing block 49 . block score: 0.04419355466961861
removed block 49 current accuracy 0.9388 loss from initial  0.06120000000000003
since last training loss: 0.059599999999999986 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (33, 0.0449781883507967), (34, 0.045712923631072044), (36, 0.15752990543842316), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (53, 0.04970693960785866)]
computing accuracy for after removing block 33 . block score: 0.0449781883507967
removed block 33 current accuracy 0.9032 loss from initial  0.0968
since last training loss: 0.09519999999999995 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (34, 0.045712923631072044), (36, 0.15752990543842316), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (48, 0.0456414557993412), (53, 0.04970693960785866)]
computing accuracy for after removing block 48 . block score: 0.0456414557993412
removed block 48 current accuracy 0.8658 loss from initial  0.13419999999999999
since last training loss: 0.13259999999999994 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (34, 0.045712923631072044), (36, 0.15752990543842316), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (53, 0.04970693960785866)]
computing accuracy for after removing block 34 . block score: 0.045712923631072044
removed block 34 current accuracy 0.7808 loss from initial  0.21919999999999995
since last training loss: 0.2175999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.052608732134103775), (9, 0.0654657669365406), (10, 0.06125731207430363), (11, 0.053809452801942825), (12, 0.06081985495984554), (13, 0.04975503496825695), (14, 0.06493710912764072), (15, 0.06913491897284985), (16, 0.05873724818229675), (17, 0.09215636551380157), (18, 0.18705153465270996), (36, 0.15752990543842316), (39, 0.04629911296069622), (40, 0.049609897658228874), (41, 0.05017670802772045), (42, 0.051564961671829224), (43, 0.05283145792782307), (44, 0.05052615702152252), (45, 0.050201261416077614), (46, 0.05013516917824745), (47, 0.047894321382045746), (53, 0.04970693960785866)]
computing accuracy for after removing block 39 . block score: 0.04629911296069622
removed block 39 current accuracy 0.7424 loss from initial  0.25760000000000005
training start
training epoch 0 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 1 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.001]
training epoch 2 val accuracy 0.9612 topk_dict {'top1': 0.9612} is_best True lr [0.001]
training epoch 3 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best True lr [0.001]
training epoch 4 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.001]
training epoch 5 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best True lr [0.001]
training epoch 6 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best False lr [0.001]
training epoch 7 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 8 val accuracy 0.973 topk_dict {'top1': 0.973} is_best True lr [0.001]
training epoch 9 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 10 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 11 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 12 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 13 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 14 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 15 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 16 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 17 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 18 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 19 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 20 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 21 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 22 val accuracy 0.978 topk_dict {'top1': 0.978} is_best True lr [0.001]
training epoch 23 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 24 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 25 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 26 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 27 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 28 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 29 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 30 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 31 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 32 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 33 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 34 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 35 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 36 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 37 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 38 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 39 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 40 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 41 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 42 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 43 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 44 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 45 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 46 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 47 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 48 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 49 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.980000)
finished training. finished 50 epochs. accuracy 0.98 topk_dict {'top1': 0.98}
