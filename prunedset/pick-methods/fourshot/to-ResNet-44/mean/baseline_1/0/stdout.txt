start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 3 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (20, 0.0417126789689064), (21, 0.04085727967321873), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (30, 0.043620482087135315), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (42, 0.043288590386509895), (43, 0.042714934796094894), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 21 . block score: 0.04085727967321873
removed block 21 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (20, 0.0417126789689064), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (30, 0.043620482087135315), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (42, 0.043288590386509895), (43, 0.042714934796094894), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 20 . block score: 0.0417126789689064
removed block 20 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (30, 0.043620482087135315), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (42, 0.043288590386509895), (43, 0.042714934796094894), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 43 . block score: 0.042714934796094894
removed block 43 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (30, 0.043620482087135315), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (42, 0.043288590386509895), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 42 . block score: 0.043288590386509895
removed block 42 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (30, 0.043620482087135315), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 30 . block score: 0.043620482087135315
removed block 30 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (47, 0.044411081820726395), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 47 . block score: 0.044411081820726395
removed block 47 current accuracy 0.9884 loss from initial  0.011600000000000055
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (44, 0.04463077895343304), (45, 0.04673144780099392), (46, 0.044841475784778595), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 44 . block score: 0.04463077895343304
removed block 44 current accuracy 0.9828 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.0630496647208929), (1, 0.1051391027867794), (2, 0.08416958898305893), (3, 0.09124281629920006), (4, 0.08398186042904854), (5, 0.08875454217195511), (6, 0.0932186022400856), (7, 0.08281204849481583), (8, 0.08311048150062561), (9, 0.06330601871013641), (10, 0.05479077622294426), (11, 0.06313290819525719), (12, 0.06036711856722832), (13, 0.052063873037695885), (14, 0.06512422114610672), (15, 0.07317628897726536), (16, 0.07103093713521957), (17, 0.06618178449571133), (18, 0.2164628803730011), (22, 0.049554914236068726), (23, 0.050822021439671516), (24, 0.04490804672241211), (25, 0.04715549759566784), (26, 0.04469999670982361), (28, 0.04631955362856388), (36, 0.1636849083006382), (37, 0.047546446323394775), (38, 0.046439915895462036), (39, 0.044859571382403374), (40, 0.04530750587582588), (41, 0.04529348202049732), (45, 0.04673144780099392), (46, 0.044841475784778595), (48, 0.04514535516500473), (49, 0.046464405953884125), (50, 0.04763040132820606), (51, 0.04882798716425896), (52, 0.04964817129075527), (53, 0.051897214725613594)]
computing accuracy for after removing block 26 . block score: 0.04469999670982361
removed block 26 current accuracy 0.9764 loss from initial  0.023599999999999954
training start
training epoch 0 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 1 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 2 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 3 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 4 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 5 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 6 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 7 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 8 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 9 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 10 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 11 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 12 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 14 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 16 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 18 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 19 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 21 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 22 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 23 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 24 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 26 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 27 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 28 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 30 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 31 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 32 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 33 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 35 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 37 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 38 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 39 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 41 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 42 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 43 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 44 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 46 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 48 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 49 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.998600)
finished training. finished 50 epochs. accuracy 0.9986 topk_dict {'top1': 0.9986}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (24, 0.044281285256147385), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (39, 0.04418070614337921), (40, 0.04462501406669617), (41, 0.044614845886826515), (45, 0.04602730832993984), (46, 0.04415990598499775), (48, 0.04447268322110176), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 46 . block score: 0.04415990598499775
removed block 46 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (24, 0.044281285256147385), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (39, 0.04418070614337921), (40, 0.04462501406669617), (41, 0.044614845886826515), (45, 0.04602730832993984), (48, 0.04447268322110176), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 39 . block score: 0.04418070614337921
removed block 39 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (24, 0.044281285256147385), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (40, 0.04462501406669617), (41, 0.044614845886826515), (45, 0.04602730832993984), (48, 0.04447268322110176), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 24 . block score: 0.044281285256147385
removed block 24 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (40, 0.04462501406669617), (41, 0.044614845886826515), (45, 0.04602730832993984), (48, 0.04447268322110176), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 48 . block score: 0.04447268322110176
removed block 48 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (40, 0.04462501406669617), (41, 0.044614845886826515), (45, 0.04602730832993984), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 41 . block score: 0.044614845886826515
removed block 41 current accuracy 0.9558 loss from initial  0.04420000000000002
since last training loss: 0.04280000000000006 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (40, 0.04462501406669617), (45, 0.04602730832993984), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 40 . block score: 0.04462501406669617
removed block 40 current accuracy 0.9274 loss from initial  0.0726
since last training loss: 0.07120000000000004 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (25, 0.046463847160339355), (28, 0.045680975541472435), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (45, 0.04602730832993984), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 28 . block score: 0.045680975541472435
removed block 28 current accuracy 0.9024 loss from initial  0.09760000000000002
since last training loss: 0.09620000000000006 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06209623068571091), (1, 0.10353433713316917), (2, 0.08292710408568382), (3, 0.08990581706166267), (4, 0.0827249214053154), (5, 0.08740319311618805), (6, 0.09183517098426819), (7, 0.08158789947628975), (8, 0.08186346665024757), (9, 0.06234738603234291), (10, 0.05399964936077595), (11, 0.06220976263284683), (12, 0.05946527048945427), (13, 0.05130022019147873), (14, 0.06414021737873554), (15, 0.07217569649219513), (16, 0.07002229057252407), (17, 0.06530453264713287), (18, 0.21345965564250946), (22, 0.04882545955479145), (23, 0.05008939281105995), (25, 0.046463847160339355), (36, 0.1612817943096161), (37, 0.04683393985033035), (38, 0.04573750123381615), (45, 0.04602730832993984), (49, 0.04576454125344753), (50, 0.04691907949745655), (51, 0.04809188097715378), (52, 0.048908570781350136), (53, 0.05111149698495865)]
computing accuracy for after removing block 38 . block score: 0.04573750123381615
removed block 38 current accuracy 0.8686 loss from initial  0.13139999999999996
training start
training epoch 0 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best True lr [0.001]
training epoch 1 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best True lr [0.001]
training epoch 2 val accuracy 0.975 topk_dict {'top1': 0.975} is_best True lr [0.001]
training epoch 3 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best True lr [0.001]
training epoch 4 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best True lr [0.001]
training epoch 5 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 6 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 7 val accuracy 0.98 topk_dict {'top1': 0.98} is_best True lr [0.001]
training epoch 8 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 9 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 10 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 11 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 12 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 13 val accuracy 0.983 topk_dict {'top1': 0.983} is_best True lr [0.001]
training epoch 14 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 15 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 16 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 17 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 18 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 19 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 20 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 21 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 22 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 23 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 24 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 25 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 26 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 27 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 28 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best True lr [0.001]
training epoch 29 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 30 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 31 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 32 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 33 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 34 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best False lr [0.001]
training epoch 35 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 36 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 37 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 38 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 39 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 40 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 41 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 42 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 43 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 44 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 45 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 46 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 47 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 48 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 49 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.985800)
finished training. finished 50 epochs. accuracy 0.9858 topk_dict {'top1': 0.9858}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (25, 0.046082958579063416), (36, 0.1594759002327919), (37, 0.046326661482453346), (45, 0.04558304511010647), (49, 0.04533178359270096), (50, 0.04643835872411728), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 49 . block score: 0.04533178359270096
removed block 49 current accuracy 0.957 loss from initial  0.04300000000000004
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (25, 0.046082958579063416), (36, 0.1594759002327919), (37, 0.046326661482453346), (45, 0.04558304511010647), (50, 0.04643835872411728), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 45 . block score: 0.04558304511010647
removed block 45 current accuracy 0.9084 loss from initial  0.09160000000000001
since last training loss: 0.07740000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (25, 0.046082958579063416), (36, 0.1594759002327919), (37, 0.046326661482453346), (50, 0.04643835872411728), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 25 . block score: 0.046082958579063416
removed block 25 current accuracy 0.8886 loss from initial  0.11140000000000005
since last training loss: 0.09720000000000006 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (36, 0.1594759002327919), (37, 0.046326661482453346), (50, 0.04643835872411728), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 37 . block score: 0.046326661482453346
removed block 37 current accuracy 0.8236 loss from initial  0.1764
since last training loss: 0.1622 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (36, 0.1594759002327919), (50, 0.04643835872411728), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 50 . block score: 0.04643835872411728
removed block 50 current accuracy 0.7312 loss from initial  0.26880000000000004
since last training loss: 0.25460000000000005 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (36, 0.1594759002327919), (51, 0.047614457085728645), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 51 . block score: 0.047614457085728645
removed block 51 current accuracy 0.5086 loss from initial  0.49139999999999995
since last training loss: 0.47719999999999996 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (22, 0.04838477075099945), (23, 0.049699047580361366), (36, 0.1594759002327919), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 22 . block score: 0.04838477075099945
removed block 22 current accuracy 0.446 loss from initial  0.554
since last training loss: 0.5398000000000001 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (23, 0.049699047580361366), (36, 0.1594759002327919), (52, 0.04839428327977657), (53, 0.05050480365753174)]
computing accuracy for after removing block 52 . block score: 0.04839428327977657
removed block 52 current accuracy 0.3652 loss from initial  0.6348
since last training loss: 0.6206 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06145784817636013), (1, 0.10237634927034378), (2, 0.08190367370843887), (3, 0.08893607184290886), (4, 0.08177785947918892), (5, 0.08639703318476677), (6, 0.09075796231627464), (7, 0.08072755113244057), (8, 0.08094717562198639), (9, 0.061728352680802345), (10, 0.05349111557006836), (11, 0.06153917498886585), (12, 0.058823663741350174), (13, 0.05077867768704891), (14, 0.06334833055734634), (15, 0.07152546755969524), (16, 0.06929218210279942), (17, 0.06467422097921371), (18, 0.21096284687519073), (23, 0.049699047580361366), (36, 0.1594759002327919), (53, 0.05050480365753174)]
computing accuracy for after removing block 23 . block score: 0.049699047580361366
removed block 23 current accuracy 0.3256 loss from initial  0.6744
training start
training epoch 0 val accuracy 0.7936 topk_dict {'top1': 0.7936} is_best True lr [0.001]
training epoch 1 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best True lr [0.001]
training epoch 2 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best True lr [0.001]
training epoch 3 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.001]
training epoch 4 val accuracy 0.854 topk_dict {'top1': 0.854} is_best True lr [0.001]
training epoch 5 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.001]
training epoch 6 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.001]
training epoch 7 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.001]
training epoch 8 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.001]
training epoch 9 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.001]
training epoch 10 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.001]
training epoch 11 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.001]
training epoch 12 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.001]
training epoch 13 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.001]
training epoch 14 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.001]
training epoch 15 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.001]
training epoch 16 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 17 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.001]
training epoch 18 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.001]
training epoch 19 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.001]
training epoch 20 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.001]
training epoch 21 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.001]
training epoch 22 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 23 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.001]
training epoch 24 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 25 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 26 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 27 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 28 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 29 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.001]
training epoch 30 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 31 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 32 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.001]
training epoch 33 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 34 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 35 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 36 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.001]
training epoch 37 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.001]
training epoch 38 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 39 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 40 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 41 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 42 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 43 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 44 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.001]
training epoch 45 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.001]
training epoch 46 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 47 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 48 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.001]
training epoch 49 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.907600)
finished training. finished 50 epochs. accuracy 0.9076 topk_dict {'top1': 0.9076}
