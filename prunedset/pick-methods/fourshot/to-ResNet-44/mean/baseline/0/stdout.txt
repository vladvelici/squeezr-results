start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 4 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (26, 0.04366173781454563), (27, 0.05188341252505779), (28, 0.04459686949849129), (29, 0.044098690152168274), (36, 0.1713150069117546), (37, 0.04736836813390255), (38, 0.044221557676792145), (39, 0.04298556409776211), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 39 . block score: 0.04298556409776211
removed block 39 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (26, 0.04366173781454563), (27, 0.05188341252505779), (28, 0.04459686949849129), (29, 0.044098690152168274), (36, 0.1713150069117546), (37, 0.04736836813390255), (38, 0.044221557676792145), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 26 . block score: 0.04366173781454563
removed block 26 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (28, 0.04459686949849129), (29, 0.044098690152168274), (36, 0.1713150069117546), (37, 0.04736836813390255), (38, 0.044221557676792145), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 29 . block score: 0.044098690152168274
removed block 29 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (28, 0.04459686949849129), (36, 0.1713150069117546), (37, 0.04736836813390255), (38, 0.044221557676792145), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 38 . block score: 0.044221557676792145
removed block 38 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (28, 0.04459686949849129), (36, 0.1713150069117546), (37, 0.04736836813390255), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 28 . block score: 0.04459686949849129
removed block 28 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (36, 0.1713150069117546), (37, 0.04736836813390255), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (51, 0.04571069777011871), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 51 . block score: 0.04571069777011871
removed block 51 current accuracy 0.9906 loss from initial  0.009399999999999964
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (36, 0.1713150069117546), (37, 0.04736836813390255), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (50, 0.04619999788701534), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 50 . block score: 0.04619999788701534
removed block 50 current accuracy 0.9848 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.054747408255934715), (3, 0.04783387668430805), (4, 0.06694387644529343), (5, 0.055374013260006905), (6, 0.07435901835560799), (7, 0.08879107236862183), (8, 0.09372834488749504), (9, 0.09707755595445633), (10, 0.09139369055628777), (11, 0.09369096159934998), (12, 0.10786965489387512), (13, 0.08983888477087021), (14, 0.07705530151724815), (15, 0.08738274499773979), (16, 0.08575152605772018), (17, 0.07685495913028717), (18, 0.2592179551720619), (19, 0.06906324252486229), (20, 0.06374479457736015), (21, 0.06420920230448246), (22, 0.05773227661848068), (23, 0.05386381223797798), (24, 0.05411130003631115), (25, 0.051984237506985664), (27, 0.05188341252505779), (36, 0.1713150069117546), (37, 0.04736836813390255), (40, 0.04648125544190407), (41, 0.04792970232665539), (42, 0.046979060396552086), (43, 0.04736914858222008), (44, 0.04899251088500023), (45, 0.050290558487176895), (46, 0.052227167412638664), (47, 0.05019604228436947), (48, 0.05091984570026398), (49, 0.04827412776648998), (52, 0.047892119735479355), (53, 0.05570212006568909)]
computing accuracy for after removing block 40 . block score: 0.04648125544190407
removed block 40 current accuracy 0.9776 loss from initial  0.022399999999999975
training start
training epoch 0 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 1 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 2 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 3 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 4 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 5 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 8 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 9 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 10 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 11 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 34 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 38 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (3, 0.04740012437105179), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (37, 0.046929407864809036), (41, 0.047479452565312386), (42, 0.04654609598219395), (43, 0.046935977414250374), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (52, 0.04746038280427456), (53, 0.055187564343214035)]
computing accuracy for after removing block 42 . block score: 0.04654609598219395
removed block 42 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (3, 0.04740012437105179), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (37, 0.046929407864809036), (41, 0.047479452565312386), (43, 0.046935977414250374), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (52, 0.04746038280427456), (53, 0.055187564343214035)]
computing accuracy for after removing block 37 . block score: 0.046929407864809036
removed block 37 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (3, 0.04740012437105179), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (41, 0.047479452565312386), (43, 0.046935977414250374), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (52, 0.04746038280427456), (53, 0.055187564343214035)]
computing accuracy for after removing block 43 . block score: 0.046935977414250374
removed block 43 current accuracy 0.9836 loss from initial  0.01639999999999997
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (3, 0.04740012437105179), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (41, 0.047479452565312386), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (52, 0.04746038280427456), (53, 0.055187564343214035)]
computing accuracy for after removing block 3 . block score: 0.04740012437105179
removed block 3 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.01860000000000006 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (41, 0.047479452565312386), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (52, 0.04746038280427456), (53, 0.055187564343214035)]
computing accuracy for after removing block 52 . block score: 0.04746038280427456
removed block 52 current accuracy 0.9044 loss from initial  0.09560000000000002
since last training loss: 0.09540000000000004 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (41, 0.047479452565312386), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (53, 0.055187564343214035)]
computing accuracy for after removing block 41 . block score: 0.047479452565312386
removed block 41 current accuracy 0.8844 loss from initial  0.11560000000000004
since last training loss: 0.11540000000000006 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (49, 0.047830041497945786), (53, 0.055187564343214035)]
computing accuracy for after removing block 49 . block score: 0.047830041497945786
removed block 49 current accuracy 0.8342 loss from initial  0.16579999999999995
since last training loss: 0.16559999999999997 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.054316891357302666), (4, 0.06644257158041), (5, 0.0548501331359148), (6, 0.07374738529324532), (7, 0.08800600096583366), (8, 0.09286768734455109), (9, 0.09615549817681313), (10, 0.09057141467928886), (11, 0.092836182564497), (12, 0.1069212555885315), (13, 0.08901561796665192), (14, 0.07633960992097855), (15, 0.08658279106020927), (16, 0.08500954881310463), (17, 0.07619544491171837), (18, 0.25663552433252335), (19, 0.06841854378581047), (20, 0.06316032074391842), (21, 0.06361976638436317), (22, 0.05718652717769146), (23, 0.05335780046880245), (24, 0.053612494841217995), (25, 0.051489075645804405), (27, 0.05142778344452381), (36, 0.1697288602590561), (44, 0.04855017177760601), (45, 0.04983172379434109), (46, 0.05174701847136021), (47, 0.0497402548789978), (48, 0.05045055225491524), (53, 0.055187564343214035)]
computing accuracy for after removing block 44 . block score: 0.04855017177760601
removed block 44 current accuracy 0.7834 loss from initial  0.21660000000000001
training start
training epoch 0 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 1 val accuracy 0.9578 topk_dict {'top1': 0.9578} is_best True lr [0.001]
training epoch 2 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.001]
training epoch 3 val accuracy 0.9658 topk_dict {'top1': 0.9658} is_best True lr [0.001]
training epoch 4 val accuracy 0.9702 topk_dict {'top1': 0.9702} is_best True lr [0.001]
training epoch 5 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best True lr [0.001]
training epoch 6 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best True lr [0.001]
training epoch 7 val accuracy 0.975 topk_dict {'top1': 0.975} is_best True lr [0.001]
training epoch 8 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 9 val accuracy 0.9758 topk_dict {'top1': 0.9758} is_best False lr [0.001]
training epoch 10 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 11 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best True lr [0.001]
training epoch 12 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 13 val accuracy 0.978 topk_dict {'top1': 0.978} is_best True lr [0.001]
training epoch 14 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 15 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 16 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 17 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 18 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 19 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best False lr [0.001]
training epoch 20 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 21 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 22 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 23 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 24 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 25 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 26 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 27 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 28 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 29 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 30 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 31 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 32 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 33 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 34 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 35 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 36 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 37 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 38 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best True lr [0.001]
training epoch 39 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best False lr [0.001]
training epoch 40 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 41 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 42 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 43 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 44 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 45 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 46 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 47 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 48 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 49 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.983800)
finished training. finished 50 epochs. accuracy 0.9838 topk_dict {'top1': 0.9838}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (25, 0.05089646950364113), (27, 0.050882311537861824), (36, 0.16779174283146858), (45, 0.049212539568543434), (46, 0.05111260339617729), (47, 0.04919324070215225), (48, 0.04986285977065563), (53, 0.05445236153900623)]
computing accuracy for after removing block 47 . block score: 0.04919324070215225
removed block 47 current accuracy 0.9454 loss from initial  0.05459999999999998
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (25, 0.05089646950364113), (27, 0.050882311537861824), (36, 0.16779174283146858), (45, 0.049212539568543434), (46, 0.05111260339617729), (48, 0.04986285977065563), (53, 0.05445236153900623)]
computing accuracy for after removing block 45 . block score: 0.049212539568543434
removed block 45 current accuracy 0.87 loss from initial  0.13
since last training loss: 0.11380000000000001 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (25, 0.05089646950364113), (27, 0.050882311537861824), (36, 0.16779174283146858), (46, 0.05111260339617729), (48, 0.04986285977065563), (53, 0.05445236153900623)]
computing accuracy for after removing block 48 . block score: 0.04986285977065563
removed block 48 current accuracy 0.7526 loss from initial  0.24739999999999995
since last training loss: 0.23119999999999996 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (25, 0.05089646950364113), (27, 0.050882311537861824), (36, 0.16779174283146858), (46, 0.05111260339617729), (53, 0.05445236153900623)]
computing accuracy for after removing block 27 . block score: 0.050882311537861824
removed block 27 current accuracy 0.7524 loss from initial  0.24760000000000004
since last training loss: 0.23140000000000005 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (25, 0.05089646950364113), (36, 0.16779174283146858), (46, 0.05111260339617729), (53, 0.05445236153900623)]
computing accuracy for after removing block 25 . block score: 0.05089646950364113
removed block 25 current accuracy 0.7348 loss from initial  0.2652
since last training loss: 0.249 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (36, 0.16779174283146858), (46, 0.05111260339617729), (53, 0.05445236153900623)]
computing accuracy for after removing block 46 . block score: 0.05111260339617729
removed block 46 current accuracy 0.6146 loss from initial  0.38539999999999996
since last training loss: 0.3692 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (23, 0.05274723097681999), (24, 0.05302395112812519), (36, 0.16779174283146858), (53, 0.05445236153900623)]
computing accuracy for after removing block 23 . block score: 0.05274723097681999
removed block 23 current accuracy 0.5678 loss from initial  0.43220000000000003
since last training loss: 0.41600000000000004 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (24, 0.05302395112812519), (36, 0.16779174283146858), (53, 0.05445236153900623)]
computing accuracy for after removing block 24 . block score: 0.05302395112812519
removed block 24 current accuracy 0.539 loss from initial  0.46099999999999997
since last training loss: 0.4448 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.05370837077498436), (4, 0.06592268496751785), (5, 0.05425677075982094), (6, 0.07294179499149323), (7, 0.08696062862873077), (8, 0.09178664907813072), (9, 0.09484679996967316), (10, 0.08945423737168312), (11, 0.09157594293355942), (12, 0.10566476359963417), (13, 0.08794214576482773), (14, 0.0754041038453579), (15, 0.08546959236264229), (16, 0.08396218344569206), (17, 0.0752379447221756), (18, 0.25349607691168785), (19, 0.06760944426059723), (20, 0.062430089339613914), (21, 0.06286899745464325), (22, 0.056468416005373), (36, 0.16779174283146858), (53, 0.05445236153900623)]
computing accuracy for after removing block 0 . block score: 0.05370837077498436
removed block 0 current accuracy 0.5402 loss from initial  0.4598
training start
training epoch 0 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best True lr [0.001]
training epoch 1 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.001]
training epoch 2 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.001]
training epoch 3 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.001]
training epoch 4 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.001]
training epoch 5 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best True lr [0.001]
training epoch 6 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 7 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.001]
training epoch 8 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 10 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 11 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 12 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 13 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 14 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 15 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 16 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 17 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 18 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 19 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 20 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 21 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 22 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 23 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 24 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 25 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 26 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 27 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 28 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 29 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 30 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 31 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 32 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 33 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 34 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 35 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 36 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 37 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 38 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 39 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 40 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 41 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 42 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 43 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 44 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 45 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 46 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 47 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 48 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 49 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.929200)
finished training. finished 50 epochs. accuracy 0.9292 topk_dict {'top1': 0.9292}
