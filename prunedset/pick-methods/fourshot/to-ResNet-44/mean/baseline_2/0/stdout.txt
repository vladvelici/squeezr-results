start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.994 loss from initial  0.006000000000000005
training start
training epoch 0 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 2 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 13 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 14 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 25 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (14, 0.040821755304932594), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (24, 0.041457194834947586), (27, 0.04258838668465614), (28, 0.0443084966391325), (29, 0.04187144711613655), (30, 0.04091135784983635), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (39, 0.04164300300180912), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 14 . block score: 0.040821755304932594
removed block 14 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (24, 0.041457194834947586), (27, 0.04258838668465614), (28, 0.0443084966391325), (29, 0.04187144711613655), (30, 0.04091135784983635), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (39, 0.04164300300180912), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 30 . block score: 0.04091135784983635
removed block 30 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (24, 0.041457194834947586), (27, 0.04258838668465614), (28, 0.0443084966391325), (29, 0.04187144711613655), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (39, 0.04164300300180912), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 24 . block score: 0.041457194834947586
removed block 24 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (27, 0.04258838668465614), (28, 0.0443084966391325), (29, 0.04187144711613655), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (39, 0.04164300300180912), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 39 . block score: 0.04164300300180912
removed block 39 current accuracy 0.9928 loss from initial  0.007199999999999984
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (27, 0.04258838668465614), (28, 0.0443084966391325), (29, 0.04187144711613655), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 29 . block score: 0.04187144711613655
removed block 29 current accuracy 0.9838 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (21, 0.04199227876961231), (22, 0.04290848784148693), (27, 0.04258838668465614), (28, 0.0443084966391325), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 21 . block score: 0.04199227876961231
removed block 21 current accuracy 0.9742 loss from initial  0.025800000000000045
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (22, 0.04290848784148693), (27, 0.04258838668465614), (28, 0.0443084966391325), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (38, 0.04203925095498562), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 38 . block score: 0.04203925095498562
removed block 38 current accuracy 0.9686 loss from initial  0.031399999999999983
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.0989391840994358), (1, 0.07637528330087662), (2, 0.09065641462802887), (3, 0.08104576915502548), (4, 0.07480191066861153), (5, 0.06974058598279953), (6, 0.0767437294125557), (7, 0.060700155794620514), (8, 0.05719616822898388), (9, 0.06177947670221329), (10, 0.06238200515508652), (11, 0.05162915773689747), (12, 0.06379159353673458), (13, 0.06690653041005135), (15, 0.06032034195959568), (16, 0.05004502274096012), (17, 0.05229581706225872), (18, 0.20835166797041893), (19, 0.04254749044775963), (22, 0.04290848784148693), (27, 0.04258838668465614), (28, 0.0443084966391325), (33, 0.042547035962343216), (36, 0.1586337462067604), (37, 0.04286953806877136), (40, 0.04228675737977028), (41, 0.042792703956365585), (42, 0.04401138052344322), (43, 0.0445456113666296), (44, 0.043877240270376205), (45, 0.0459282249212265), (46, 0.048666706308722496), (47, 0.05042262375354767), (48, 0.04768802411854267), (49, 0.04943892918527126), (50, 0.04706388898193836), (51, 0.04480226896703243), (52, 0.043535683304071426), (53, 0.05158673971891403)]
computing accuracy for after removing block 40 . block score: 0.04228675737977028
removed block 40 current accuracy 0.962 loss from initial  0.038000000000000034
training start
training epoch 0 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 1 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 2 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 3 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 4 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 5 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 6 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 7 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 8 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 9 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 10 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 11 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 12 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 14 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 15 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 16 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 17 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 18 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 19 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 20 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 21 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 24 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 26 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 30 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 33 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 34 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 35 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 39 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 41 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 43 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (19, 0.04211108945310116), (22, 0.04251552000641823), (27, 0.04217199236154556), (28, 0.04390282183885574), (33, 0.0421441774815321), (36, 0.15693838149309158), (37, 0.04241352155804634), (41, 0.042340224608778954), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 19 . block score: 0.04211108945310116
removed block 19 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (22, 0.04251552000641823), (27, 0.04217199236154556), (28, 0.04390282183885574), (33, 0.0421441774815321), (36, 0.15693838149309158), (37, 0.04241352155804634), (41, 0.042340224608778954), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 33 . block score: 0.0421441774815321
removed block 33 current accuracy 0.9922 loss from initial  0.007800000000000029
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (22, 0.04251552000641823), (27, 0.04217199236154556), (28, 0.04390282183885574), (36, 0.15693838149309158), (37, 0.04241352155804634), (41, 0.042340224608778954), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 27 . block score: 0.04217199236154556
removed block 27 current accuracy 0.9824 loss from initial  0.01759999999999995
since last training loss: 0.016999999999999904 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (22, 0.04251552000641823), (28, 0.04390282183885574), (36, 0.15693838149309158), (37, 0.04241352155804634), (41, 0.042340224608778954), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 41 . block score: 0.042340224608778954
removed block 41 current accuracy 0.975 loss from initial  0.025000000000000022
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (22, 0.04251552000641823), (28, 0.04390282183885574), (36, 0.15693838149309158), (37, 0.04241352155804634), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 37 . block score: 0.04241352155804634
removed block 37 current accuracy 0.9664 loss from initial  0.03359999999999996
since last training loss: 0.03299999999999992 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (22, 0.04251552000641823), (28, 0.04390282183885574), (36, 0.15693838149309158), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 22 . block score: 0.04251552000641823
removed block 22 current accuracy 0.9396 loss from initial  0.06040000000000001
since last training loss: 0.059799999999999964 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (28, 0.04390282183885574), (36, 0.15693838149309158), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (52, 0.04308489337563515), (53, 0.05103939399123192)]
computing accuracy for after removing block 52 . block score: 0.04308489337563515
removed block 52 current accuracy 0.901 loss from initial  0.09899999999999998
since last training loss: 0.09839999999999993 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09795477613806725), (1, 0.07559822127223015), (2, 0.08974875509738922), (3, 0.08019276708364487), (4, 0.07403916493058205), (5, 0.06902851909399033), (6, 0.0759333148598671), (7, 0.060103459283709526), (8, 0.056619031354784966), (9, 0.061168380081653595), (10, 0.06173758953809738), (11, 0.051107585430145264), (12, 0.06317194551229477), (13, 0.06625663489103317), (15, 0.059718361124396324), (16, 0.049594782292842865), (17, 0.051853643730282784), (18, 0.20617596432566643), (28, 0.04390282183885574), (36, 0.15693838149309158), (42, 0.043557221069931984), (43, 0.04408377967774868), (44, 0.04342574067413807), (45, 0.04545403830707073), (46, 0.04816041141748428), (47, 0.0499055702239275), (48, 0.047203632071614265), (49, 0.04894035868346691), (50, 0.04657823219895363), (51, 0.0443402174860239), (53, 0.05103939399123192)]
computing accuracy for after removing block 44 . block score: 0.04342574067413807
removed block 44 current accuracy 0.8796 loss from initial  0.12039999999999995
training start
training epoch 0 val accuracy 0.9748 topk_dict {'top1': 0.9748} is_best True lr [0.001]
training epoch 1 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 2 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best True lr [0.001]
training epoch 3 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 4 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 5 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 6 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best True lr [0.001]
training epoch 7 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 8 val accuracy 0.9878 topk_dict {'top1': 0.9878} is_best False lr [0.001]
training epoch 9 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 10 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 11 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 12 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 13 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 14 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 15 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 16 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 17 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 18 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 19 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 20 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 21 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 22 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 23 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 24 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 25 val accuracy 0.9888 topk_dict {'top1': 0.9888} is_best False lr [0.001]
training epoch 26 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 27 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 28 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 29 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 30 val accuracy 0.989 topk_dict {'top1': 0.989} is_best False lr [0.001]
training epoch 31 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 32 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 33 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 34 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 35 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 36 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 37 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 38 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 39 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 40 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 41 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 42 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 43 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 44 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 45 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 46 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 47 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 48 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 49 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.990800)
finished training. finished 50 epochs. accuracy 0.9908 topk_dict {'top1': 0.9908}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (28, 0.04371689818799496), (36, 0.15505407005548477), (42, 0.04310857132077217), (43, 0.0436052568256855), (45, 0.044965846464037895), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (51, 0.0439058281481266), (53, 0.050449538975954056)]
computing accuracy for after removing block 42 . block score: 0.04310857132077217
removed block 42 current accuracy 0.9808 loss from initial  0.019199999999999995
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (28, 0.04371689818799496), (36, 0.15505407005548477), (43, 0.0436052568256855), (45, 0.044965846464037895), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (51, 0.0439058281481266), (53, 0.050449538975954056)]
computing accuracy for after removing block 43 . block score: 0.0436052568256855
removed block 43 current accuracy 0.9532 loss from initial  0.04679999999999995
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (28, 0.04371689818799496), (36, 0.15505407005548477), (45, 0.044965846464037895), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (51, 0.0439058281481266), (53, 0.050449538975954056)]
computing accuracy for after removing block 28 . block score: 0.04371689818799496
removed block 28 current accuracy 0.881 loss from initial  0.119
since last training loss: 0.10980000000000001 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (45, 0.044965846464037895), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (51, 0.0439058281481266), (53, 0.050449538975954056)]
computing accuracy for after removing block 51 . block score: 0.0439058281481266
removed block 51 current accuracy 0.8364 loss from initial  0.16359999999999997
since last training loss: 0.15439999999999998 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (45, 0.044965846464037895), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (53, 0.050449538975954056)]
computing accuracy for after removing block 45 . block score: 0.044965846464037895
removed block 45 current accuracy 0.796 loss from initial  0.20399999999999996
since last training loss: 0.19479999999999997 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (50, 0.04608806036412716), (53, 0.050449538975954056)]
computing accuracy for after removing block 50 . block score: 0.04608806036412716
removed block 50 current accuracy 0.741 loss from initial  0.259
since last training loss: 0.24980000000000002 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (46, 0.04764496721327305), (47, 0.04937846213579178), (48, 0.046700188890099525), (49, 0.0484194029122591), (53, 0.050449538975954056)]
computing accuracy for after removing block 48 . block score: 0.046700188890099525
removed block 48 current accuracy 0.6808 loss from initial  0.31920000000000004
since last training loss: 0.31000000000000005 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (46, 0.04764496721327305), (47, 0.04937846213579178), (49, 0.0484194029122591), (53, 0.050449538975954056)]
computing accuracy for after removing block 46 . block score: 0.04764496721327305
removed block 46 current accuracy 0.6028 loss from initial  0.3972
since last training loss: 0.388 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09691247344017029), (1, 0.07485323771834373), (2, 0.08877009525895119), (3, 0.07931079342961311), (4, 0.07331348583102226), (5, 0.06820256635546684), (6, 0.07508235052227974), (7, 0.0595083013176918), (8, 0.05606956221163273), (9, 0.0605615321546793), (10, 0.06112409941852093), (11, 0.0505639873445034), (12, 0.06253146380186081), (13, 0.06563222222030163), (15, 0.05914977379143238), (16, 0.04924355633556843), (17, 0.05145856738090515), (18, 0.20397255197167397), (36, 0.15505407005548477), (47, 0.04937846213579178), (49, 0.0484194029122591), (53, 0.050449538975954056)]
computing accuracy for after removing block 49 . block score: 0.0484194029122591
removed block 49 current accuracy 0.4478 loss from initial  0.5522
training start
training epoch 0 val accuracy 0.8382 topk_dict {'top1': 0.8382} is_best True lr [0.001]
training epoch 1 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best True lr [0.001]
training epoch 2 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best True lr [0.001]
training epoch 3 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.001]
training epoch 4 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.001]
training epoch 5 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 6 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 9 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 10 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 11 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 12 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 13 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 14 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 15 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 16 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 17 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 18 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 19 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 20 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 21 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 22 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 23 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 24 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 25 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 26 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 27 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 28 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 29 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 32 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 34 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 35 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 36 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 37 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 38 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 40 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 41 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 43 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 44 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 45 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 46 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 47 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 48 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 49 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.931600)
finished training. finished 50 epochs. accuracy 0.9316 topk_dict {'top1': 0.9316}
