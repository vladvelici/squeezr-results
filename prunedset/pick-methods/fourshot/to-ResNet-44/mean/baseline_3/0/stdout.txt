start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9908 loss from initial  0.009199999999999986
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9862 loss from initial  0.013800000000000034
training start
training epoch 0 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 1 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 2 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 3 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 12 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 14 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 22 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 34 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 25 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (29, 0.0464069489389658), (35, 0.04331057146191597), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (47, 0.044978730380535126), (48, 0.044616857543587685), (49, 0.043900441378355026), (53, 0.05050894245505333)]
computing accuracy for after removing block 35 . block score: 0.04331057146191597
removed block 35 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (29, 0.0464069489389658), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (47, 0.044978730380535126), (48, 0.044616857543587685), (49, 0.043900441378355026), (53, 0.05050894245505333)]
computing accuracy for after removing block 49 . block score: 0.043900441378355026
removed block 49 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (29, 0.0464069489389658), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (47, 0.044978730380535126), (48, 0.044616857543587685), (53, 0.05050894245505333)]
computing accuracy for after removing block 48 . block score: 0.044616857543587685
removed block 48 current accuracy 0.9896 loss from initial  0.010399999999999965
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (29, 0.0464069489389658), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (47, 0.044978730380535126), (53, 0.05050894245505333)]
computing accuracy for after removing block 47 . block score: 0.044978730380535126
removed block 47 current accuracy 0.9732 loss from initial  0.026800000000000046
since last training loss: 0.026600000000000068 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (29, 0.0464069489389658), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (53, 0.05050894245505333)]
computing accuracy for after removing block 29 . block score: 0.0464069489389658
removed block 29 current accuracy 0.9706 loss from initial  0.02939999999999998
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (46, 0.04667923226952553), (53, 0.05050894245505333)]
computing accuracy for after removing block 46 . block score: 0.04667923226952553
removed block 46 current accuracy 0.9374 loss from initial  0.06259999999999999
since last training loss: 0.06240000000000001 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (28, 0.04680203087627888), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (53, 0.05050894245505333)]
computing accuracy for after removing block 28 . block score: 0.04680203087627888
removed block 28 current accuracy 0.9382 loss from initial  0.061799999999999966
since last training loss: 0.06159999999999999 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.0659969188272953), (1, 0.0559658519923687), (2, 0.07476262375712395), (3, 0.07802267000079155), (4, 0.06159610114991665), (5, 0.09412458166480064), (6, 0.05946170166134834), (7, 0.060274653136730194), (8, 0.06660749390721321), (9, 0.08036698773503304), (10, 0.07979783788323402), (11, 0.0685294046998024), (12, 0.08212095871567726), (13, 0.07496849447488785), (14, 0.08535952493548393), (15, 0.08833072707056999), (16, 0.10462574288249016), (17, 0.12343158572912216), (18, 0.2717050090432167), (19, 0.07028225809335709), (20, 0.0684327557682991), (21, 0.06324482336640358), (22, 0.061488330364227295), (23, 0.05825689807534218), (24, 0.057632846757769585), (25, 0.057503191754221916), (26, 0.0512077733874321), (27, 0.05574014410376549), (36, 0.18132134899497032), (37, 0.05506246164441109), (38, 0.05383903905749321), (39, 0.05478101782500744), (40, 0.05359040945768356), (41, 0.05074862949550152), (42, 0.05333477258682251), (43, 0.05163298733532429), (44, 0.049969715997576714), (45, 0.05103239603340626), (53, 0.05050894245505333)]
computing accuracy for after removing block 44 . block score: 0.049969715997576714
removed block 44 current accuracy 0.8948 loss from initial  0.10519999999999996
training start
training epoch 0 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 1 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best True lr [0.001]
training epoch 2 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best True lr [0.001]
training epoch 3 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 4 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 5 val accuracy 0.99 topk_dict {'top1': 0.99} is_best True lr [0.001]
training epoch 6 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 7 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 8 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 9 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 10 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 11 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 12 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 13 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 14 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 15 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 16 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 18 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 21 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 22 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 23 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 24 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 25 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 26 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 27 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 28 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 29 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 30 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 31 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 32 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 33 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 34 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 35 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 36 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 37 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 38 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 39 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 40 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 41 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 42 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 43 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 44 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 45 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 46 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 47 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 48 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 49 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.995800)
finished training. finished 50 epochs. accuracy 0.9958 topk_dict {'top1': 0.9958}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (26, 0.05045762285590172), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (41, 0.049986058846116066), (42, 0.052508868277072906), (43, 0.050863929092884064), (45, 0.050276560708880424), (53, 0.04969826899468899)]
computing accuracy for after removing block 53 . block score: 0.04969826899468899
removed block 53 current accuracy 0.7546 loss from initial  0.24539999999999995
since last training loss: 0.24119999999999997 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (26, 0.05045762285590172), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (41, 0.049986058846116066), (42, 0.052508868277072906), (43, 0.050863929092884064), (45, 0.050276560708880424)]
computing accuracy for after removing block 41 . block score: 0.049986058846116066
removed block 41 current accuracy 0.7626 loss from initial  0.23740000000000006
since last training loss: 0.23320000000000007 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (26, 0.05045762285590172), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (42, 0.052508868277072906), (43, 0.050863929092884064), (45, 0.050276560708880424)]
computing accuracy for after removing block 45 . block score: 0.050276560708880424
removed block 45 current accuracy 0.6014 loss from initial  0.39859999999999995
since last training loss: 0.3944 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (26, 0.05045762285590172), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (42, 0.052508868277072906), (43, 0.050863929092884064)]
computing accuracy for after removing block 26 . block score: 0.05045762285590172
removed block 26 current accuracy 0.5718 loss from initial  0.4282
since last training loss: 0.42400000000000004 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (42, 0.052508868277072906), (43, 0.050863929092884064)]
computing accuracy for after removing block 43 . block score: 0.050863929092884064
removed block 43 current accuracy 0.5074 loss from initial  0.49260000000000004
since last training loss: 0.48840000000000006 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366), (42, 0.052508868277072906)]
computing accuracy for after removing block 42 . block score: 0.052508868277072906
removed block 42 current accuracy 0.5072 loss from initial  0.4928
since last training loss: 0.48860000000000003 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156), (40, 0.052789922803640366)]
computing accuracy for after removing block 40 . block score: 0.052789922803640366
removed block 40 current accuracy 0.4718 loss from initial  0.5282
since last training loss: 0.524 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06495686247944832), (1, 0.055184224620461464), (2, 0.07365930080413818), (3, 0.07687629386782646), (4, 0.0607376042753458), (5, 0.09271891787648201), (6, 0.05860327370464802), (7, 0.059401482343673706), (8, 0.0656137578189373), (9, 0.07909448817372322), (10, 0.07859176024794579), (11, 0.06754986196756363), (12, 0.08084443584084511), (13, 0.07387445122003555), (14, 0.08409177884459496), (15, 0.08704415336251259), (16, 0.10302579775452614), (17, 0.12152810767292976), (18, 0.2674670182168484), (19, 0.06925678625702858), (20, 0.0673888698220253), (21, 0.06230262666940689), (22, 0.060569508001208305), (23, 0.05739389732480049), (24, 0.0567740797996521), (25, 0.056651053950190544), (27, 0.054952966049313545), (36, 0.17858637869358063), (37, 0.05425429157912731), (38, 0.05304430611431599), (39, 0.053958212956786156)]
computing accuracy for after removing block 38 . block score: 0.05304430611431599
removed block 38 current accuracy 0.489 loss from initial  0.511
training start
training epoch 0 val accuracy 0.7464 topk_dict {'top1': 0.7464} is_best True lr [0.001]
training epoch 1 val accuracy 0.7828 topk_dict {'top1': 0.7828} is_best True lr [0.001]
training epoch 2 val accuracy 0.812 topk_dict {'top1': 0.812} is_best True lr [0.001]
training epoch 3 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best True lr [0.001]
training epoch 4 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best True lr [0.001]
training epoch 5 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best True lr [0.001]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.001]
training epoch 7 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.001]
training epoch 8 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.001]
training epoch 9 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 10 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.001]
training epoch 11 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.001]
training epoch 12 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 13 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 14 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 15 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 16 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.001]
training epoch 17 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 18 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 19 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 21 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 22 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 23 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 24 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 25 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 26 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 28 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 29 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 30 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 31 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 32 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 33 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 34 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 35 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 36 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 38 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 39 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 40 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 41 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 42 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 47 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (1, 0.05490746907889843), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (25, 0.056398624554276466), (27, 0.05488143116235733), (36, 0.17645074427127838), (37, 0.05367061495780945), (39, 0.05332144908607006)]
computing accuracy for after removing block 39 . block score: 0.05332144908607006
removed block 39 current accuracy 0.8848 loss from initial  0.11519999999999997
since last training loss: 0.05379999999999996 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (1, 0.05490746907889843), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (25, 0.056398624554276466), (27, 0.05488143116235733), (36, 0.17645074427127838), (37, 0.05367061495780945)]
computing accuracy for after removing block 37 . block score: 0.05367061495780945
removed block 37 current accuracy 0.7992 loss from initial  0.20079999999999998
since last training loss: 0.13939999999999997 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (1, 0.05490746907889843), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (25, 0.056398624554276466), (27, 0.05488143116235733), (36, 0.17645074427127838)]
computing accuracy for after removing block 27 . block score: 0.05488143116235733
removed block 27 current accuracy 0.7108 loss from initial  0.2892
since last training loss: 0.2278 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (1, 0.05490746907889843), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (25, 0.056398624554276466), (36, 0.17645074427127838)]
computing accuracy for after removing block 1 . block score: 0.05490746907889843
removed block 1 current accuracy 0.687 loss from initial  0.31299999999999994
since last training loss: 0.25159999999999993 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (25, 0.056398624554276466), (36, 0.17645074427127838)]
computing accuracy for after removing block 25 . block score: 0.056398624554276466
removed block 25 current accuracy 0.6394 loss from initial  0.36060000000000003
since last training loss: 0.2992 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (24, 0.0567227378487587), (36, 0.17645074427127838)]
computing accuracy for after removing block 24 . block score: 0.0567227378487587
removed block 24 current accuracy 0.5688 loss from initial  0.4312
since last training loss: 0.3698 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (23, 0.05704294890165329), (36, 0.17645074427127838)]
computing accuracy for after removing block 23 . block score: 0.05704294890165329
removed block 23 current accuracy 0.5134 loss from initial  0.48660000000000003
since last training loss: 0.4252 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (6, 0.057950459420681), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (36, 0.17645074427127838)]
computing accuracy for after removing block 6 . block score: 0.057950459420681
removed block 6 current accuracy 0.513 loss from initial  0.487
since last training loss: 0.4256 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06427791342139244), (2, 0.07281548157334328), (3, 0.0759601779282093), (4, 0.06002935208380222), (5, 0.09167269617319107), (7, 0.05885522440075874), (8, 0.06497499719262123), (9, 0.07805144786834717), (10, 0.07762425392866135), (11, 0.06697575747966766), (12, 0.07976838946342468), (13, 0.07321981340646744), (14, 0.08305773138999939), (15, 0.08608562499284744), (16, 0.10190175473690033), (17, 0.12013046443462372), (18, 0.26377344503998756), (19, 0.06842263415455818), (20, 0.06671184673905373), (21, 0.06171487644314766), (22, 0.059963032603263855), (36, 0.17645074427127838)]
computing accuracy for after removing block 7 . block score: 0.05885522440075874
removed block 7 current accuracy 0.4996 loss from initial  0.5004
training start
training epoch 0 val accuracy 0.761 topk_dict {'top1': 0.761} is_best True lr [0.001]
training epoch 1 val accuracy 0.783 topk_dict {'top1': 0.783} is_best True lr [0.001]
training epoch 2 val accuracy 0.801 topk_dict {'top1': 0.801} is_best True lr [0.001]
training epoch 3 val accuracy 0.815 topk_dict {'top1': 0.815} is_best True lr [0.001]
training epoch 4 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best True lr [0.001]
training epoch 5 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.001]
training epoch 6 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.001]
training epoch 7 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best True lr [0.001]
training epoch 8 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best True lr [0.001]
training epoch 9 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.001]
training epoch 10 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.001]
training epoch 11 val accuracy 0.862 topk_dict {'top1': 0.862} is_best True lr [0.001]
training epoch 12 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.001]
training epoch 13 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.001]
training epoch 14 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best True lr [0.001]
training epoch 15 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.001]
training epoch 16 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.001]
training epoch 17 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.001]
training epoch 18 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.001]
training epoch 19 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.001]
training epoch 20 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.001]
training epoch 21 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.001]
training epoch 22 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.001]
training epoch 23 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.001]
training epoch 24 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.001]
training epoch 25 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.001]
training epoch 26 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.001]
training epoch 27 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.001]
training epoch 28 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.001]
training epoch 29 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.001]
training epoch 30 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.001]
training epoch 31 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.001]
training epoch 32 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.001]
training epoch 33 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.001]
training epoch 34 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.001]
training epoch 35 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.001]
training epoch 36 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.001]
training epoch 37 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.001]
training epoch 38 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 39 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.001]
training epoch 40 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.001]
training epoch 41 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 42 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.001]
training epoch 43 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.001]
training epoch 44 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 45 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.001]
training epoch 46 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 47 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.001]
training epoch 48 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.001]
training epoch 49 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.888800)
finished training. finished 50 epochs. accuracy 0.8888 topk_dict {'top1': 0.8888}
