start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.996 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9886 loss from initial  0.011399999999999966
training start
training epoch 0 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 2 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 3 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 4 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 6 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 7 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 10 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 13 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 16 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 19 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 20 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 24 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 26 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 33 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (29, 0.04666556790471077), (35, 0.04716211184859276), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (46, 0.0480441115796566), (47, 0.04988858662545681), (49, 0.04630274884402752), (51, 0.0466445405036211), (53, 0.05309726484119892)]
computing accuracy for after removing block 49 . block score: 0.04630274884402752
removed block 49 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (29, 0.04666556790471077), (35, 0.04716211184859276), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (46, 0.0480441115796566), (47, 0.04988858662545681), (51, 0.0466445405036211), (53, 0.05309726484119892)]
computing accuracy for after removing block 51 . block score: 0.0466445405036211
removed block 51 current accuracy 0.9764 loss from initial  0.023599999999999954
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (29, 0.04666556790471077), (35, 0.04716211184859276), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (46, 0.0480441115796566), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 29 . block score: 0.04666556790471077
removed block 29 current accuracy 0.9724 loss from initial  0.027599999999999958
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (35, 0.04716211184859276), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (46, 0.0480441115796566), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 35 . block score: 0.04716211184859276
removed block 35 current accuracy 0.9652 loss from initial  0.03480000000000005
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (46, 0.0480441115796566), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 46 . block score: 0.0480441115796566
removed block 46 current accuracy 0.952 loss from initial  0.04800000000000004
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (43, 0.04831494577229023), (44, 0.050222938880324364), (45, 0.04846566542983055), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 43 . block score: 0.04831494577229023
removed block 43 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.05920000000000003 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (44, 0.050222938880324364), (45, 0.04846566542983055), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 45 . block score: 0.04846566542983055
removed block 45 current accuracy 0.9162 loss from initial  0.08379999999999999
since last training loss: 0.08379999999999999 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.056747956201434135), (1, 0.07319100946187973), (2, 0.07819365337491035), (3, 0.0929001085460186), (4, 0.07436506077647209), (5, 0.09807772189378738), (6, 0.08970238640904427), (7, 0.07967578247189522), (8, 0.08111077919602394), (9, 0.09428180009126663), (10, 0.09443274512887001), (11, 0.0760423131287098), (12, 0.10113321244716644), (13, 0.08648455888032913), (14, 0.07599854841828346), (15, 0.0677459817379713), (16, 0.08193142339587212), (17, 0.0737828891724348), (18, 0.2597258538007736), (19, 0.06530223414301872), (20, 0.06558467075228691), (21, 0.06607984937727451), (22, 0.06489197164773941), (23, 0.06042788736522198), (24, 0.06403900682926178), (25, 0.058907050639390945), (26, 0.05331587791442871), (27, 0.053055182099342346), (28, 0.05290332809090614), (36, 0.18162168189883232), (37, 0.05608910135924816), (38, 0.055521100759506226), (39, 0.05579097755253315), (40, 0.05034133233129978), (41, 0.049315767362713814), (42, 0.049599356949329376), (44, 0.050222938880324364), (47, 0.04988858662545681), (53, 0.05309726484119892)]
computing accuracy for after removing block 41 . block score: 0.049315767362713814
removed block 41 current accuracy 0.9032 loss from initial  0.0968
training start
training epoch 0 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 1 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 2 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best True lr [0.001]
training epoch 3 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best True lr [0.001]
training epoch 4 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 5 val accuracy 0.987 topk_dict {'top1': 0.987} is_best True lr [0.001]
training epoch 6 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 7 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 8 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 9 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best False lr [0.001]
training epoch 10 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 11 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 12 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 13 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 14 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 15 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 16 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 17 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 18 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 19 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 20 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 21 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 22 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 23 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 24 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 25 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 26 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 27 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 28 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 29 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 30 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 31 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 32 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 33 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 34 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 35 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 36 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 37 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 38 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 39 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 40 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 42 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 43 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 44 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 45 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 46 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 47 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 48 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 49 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.994000)
finished training. finished 50 epochs. accuracy 0.994 topk_dict {'top1': 0.994}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (28, 0.05213404819369316), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (40, 0.04960540123283863), (42, 0.04884852655231953), (44, 0.04949468374252319), (47, 0.04916309379041195), (53, 0.052314987406134605)]
computing accuracy for after removing block 42 . block score: 0.04884852655231953
removed block 42 current accuracy 0.9818 loss from initial  0.018199999999999994
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (28, 0.05213404819369316), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (40, 0.04960540123283863), (44, 0.04949468374252319), (47, 0.04916309379041195), (53, 0.052314987406134605)]
computing accuracy for after removing block 47 . block score: 0.04916309379041195
removed block 47 current accuracy 0.9278 loss from initial  0.07220000000000004
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (28, 0.05213404819369316), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (40, 0.04960540123283863), (44, 0.04949468374252319), (53, 0.052314987406134605)]
computing accuracy for after removing block 44 . block score: 0.04949468374252319
removed block 44 current accuracy 0.8796 loss from initial  0.12039999999999995
since last training loss: 0.11439999999999995 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (28, 0.05213404819369316), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (40, 0.04960540123283863), (53, 0.052314987406134605)]
computing accuracy for after removing block 40 . block score: 0.04960540123283863
removed block 40 current accuracy 0.8436 loss from initial  0.15639999999999998
since last training loss: 0.15039999999999998 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (28, 0.05213404819369316), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (53, 0.052314987406134605)]
computing accuracy for after removing block 28 . block score: 0.05213404819369316
removed block 28 current accuracy 0.838 loss from initial  0.16200000000000003
since last training loss: 0.15600000000000003 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (27, 0.05229780450463295), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (53, 0.052314987406134605)]
computing accuracy for after removing block 27 . block score: 0.05229780450463295
removed block 27 current accuracy 0.8266 loss from initial  0.1734
since last training loss: 0.1674 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478), (53, 0.052314987406134605)]
computing accuracy for after removing block 53 . block score: 0.052314987406134605
removed block 53 current accuracy 0.5658 loss from initial  0.43420000000000003
since last training loss: 0.4282 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05592789873480797), (1, 0.0721263624727726), (2, 0.07701121643185616), (3, 0.09153145179152489), (4, 0.07324686646461487), (5, 0.09675363823771477), (6, 0.08842678368091583), (7, 0.07855719327926636), (8, 0.07991025969386101), (9, 0.09292219579219818), (10, 0.0930807963013649), (11, 0.07496729865670204), (12, 0.09959167614579201), (13, 0.08525238186120987), (14, 0.07498227432370186), (15, 0.06681341677904129), (16, 0.0806945227086544), (17, 0.07276182807981968), (18, 0.25578875094652176), (19, 0.0643327496945858), (20, 0.06464268267154694), (21, 0.06511145830154419), (22, 0.06391694582998753), (23, 0.059532616287469864), (24, 0.06311413273215294), (25, 0.05804891511797905), (26, 0.05251987837255001), (36, 0.17894795164465904), (37, 0.05524940602481365), (38, 0.054715849459171295), (39, 0.05498012900352478)]
computing accuracy for after removing block 26 . block score: 0.05251987837255001
removed block 26 current accuracy 0.5432 loss from initial  0.4568
training start
training epoch 0 val accuracy 0.754 topk_dict {'top1': 0.754} is_best True lr [0.001]
training epoch 1 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best True lr [0.001]
training epoch 2 val accuracy 0.8254 topk_dict {'top1': 0.8254} is_best True lr [0.001]
training epoch 3 val accuracy 0.846 topk_dict {'top1': 0.846} is_best True lr [0.001]
training epoch 4 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best True lr [0.001]
training epoch 5 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.001]
training epoch 6 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.001]
training epoch 7 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.001]
training epoch 8 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 9 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 10 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 11 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 12 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 13 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 14 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 15 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 16 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 17 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 18 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 19 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 20 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 23 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 24 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 26 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 29 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 31 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 34 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 48 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05539095029234886), (1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (25, 0.057574812322854996), (36, 0.17647042497992516), (37, 0.054512159898877144), (38, 0.054021306335926056), (39, 0.054248323664069176)]
computing accuracy for after removing block 38 . block score: 0.054021306335926056
removed block 38 current accuracy 0.8862 loss from initial  0.11380000000000001
since last training loss: 0.05920000000000003 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05539095029234886), (1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (25, 0.057574812322854996), (36, 0.17647042497992516), (37, 0.054512159898877144), (39, 0.054248323664069176)]
computing accuracy for after removing block 39 . block score: 0.054248323664069176
removed block 39 current accuracy 0.789 loss from initial  0.21099999999999997
since last training loss: 0.15639999999999998 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05539095029234886), (1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (25, 0.057574812322854996), (36, 0.17647042497992516), (37, 0.054512159898877144)]
computing accuracy for after removing block 37 . block score: 0.054512159898877144
removed block 37 current accuracy 0.6754 loss from initial  0.3246
since last training loss: 0.27 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05539095029234886), (1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (25, 0.057574812322854996), (36, 0.17647042497992516)]
computing accuracy for after removing block 0 . block score: 0.05539095029234886
removed block 0 current accuracy 0.65 loss from initial  0.35
since last training loss: 0.2954 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (25, 0.057574812322854996), (36, 0.17647042497992516)]
computing accuracy for after removing block 25 . block score: 0.057574812322854996
removed block 25 current accuracy 0.5786 loss from initial  0.4214
since last training loss: 0.3668 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (23, 0.05889334715902805), (24, 0.06242910027503967), (36, 0.17647042497992516)]
computing accuracy for after removing block 23 . block score: 0.05889334715902805
removed block 23 current accuracy 0.543 loss from initial  0.45699999999999996
since last training loss: 0.4024 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (24, 0.06242910027503967), (36, 0.17647042497992516)]
computing accuracy for after removing block 24 . block score: 0.06242910027503967
removed block 24 current accuracy 0.4652 loss from initial  0.5347999999999999
since last training loss: 0.4802 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (22, 0.06305796094238758), (36, 0.17647042497992516)]
computing accuracy for after removing block 22 . block score: 0.06305796094238758
removed block 22 current accuracy 0.4078 loss from initial  0.5922000000000001
since last training loss: 0.5376000000000001 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.0712585337460041), (2, 0.07594603300094604), (3, 0.09027379751205444), (4, 0.07217775285243988), (5, 0.09560919553041458), (6, 0.08732622116804123), (7, 0.07754626497626305), (8, 0.07884638756513596), (9, 0.09153323620557785), (10, 0.09178079664707184), (11, 0.0739145316183567), (12, 0.0982532799243927), (13, 0.08389774709939957), (14, 0.0742761418223381), (15, 0.06625920161604881), (16, 0.07959020882844925), (17, 0.07201818749308586), (18, 0.25235331803560257), (19, 0.06344709917902946), (20, 0.06385744363069534), (21, 0.06432070583105087), (36, 0.17647042497992516)]
computing accuracy for after removing block 19 . block score: 0.06344709917902946
removed block 19 current accuracy 0.372 loss from initial  0.628
training start
training epoch 0 val accuracy 0.6884 topk_dict {'top1': 0.6884} is_best True lr [0.001]
training epoch 1 val accuracy 0.7264 topk_dict {'top1': 0.7264} is_best True lr [0.001]
training epoch 2 val accuracy 0.7486 topk_dict {'top1': 0.7486} is_best True lr [0.001]
training epoch 3 val accuracy 0.762 topk_dict {'top1': 0.762} is_best True lr [0.001]
training epoch 4 val accuracy 0.7792 topk_dict {'top1': 0.7792} is_best True lr [0.001]
training epoch 5 val accuracy 0.791 topk_dict {'top1': 0.791} is_best True lr [0.001]
training epoch 6 val accuracy 0.7966 topk_dict {'top1': 0.7966} is_best True lr [0.001]
training epoch 7 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best True lr [0.001]
training epoch 8 val accuracy 0.8126 topk_dict {'top1': 0.8126} is_best True lr [0.001]
training epoch 9 val accuracy 0.8164 topk_dict {'top1': 0.8164} is_best True lr [0.001]
training epoch 10 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best True lr [0.001]
training epoch 11 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best True lr [0.001]
training epoch 12 val accuracy 0.834 topk_dict {'top1': 0.834} is_best True lr [0.001]
training epoch 13 val accuracy 0.836 topk_dict {'top1': 0.836} is_best True lr [0.001]
training epoch 14 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best True lr [0.001]
training epoch 15 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.001]
training epoch 16 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.001]
training epoch 17 val accuracy 0.852 topk_dict {'top1': 0.852} is_best True lr [0.001]
training epoch 18 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.001]
training epoch 19 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best True lr [0.001]
training epoch 20 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.001]
training epoch 21 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.001]
training epoch 22 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.001]
training epoch 23 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.001]
training epoch 24 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.001]
training epoch 25 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best True lr [0.001]
training epoch 26 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.001]
training epoch 27 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.001]
training epoch 28 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.001]
training epoch 29 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.001]
training epoch 30 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.001]
training epoch 31 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.001]
training epoch 32 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.001]
training epoch 33 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.001]
training epoch 34 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.001]
training epoch 35 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.001]
training epoch 36 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.001]
training epoch 37 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.001]
training epoch 38 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.001]
training epoch 39 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.001]
training epoch 40 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.001]
training epoch 41 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.001]
training epoch 42 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.001]
training epoch 43 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.001]
training epoch 44 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.001]
training epoch 45 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.001]
training epoch 46 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.001]
training epoch 47 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.001]
training epoch 48 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.001]
training epoch 49 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.882600)
finished training. finished 50 epochs. accuracy 0.8826 topk_dict {'top1': 0.8826}
