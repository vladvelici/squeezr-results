start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054019. All blocks and scores: [(1, 0.05401874938979745), (34, 0.061866582836955786), (2, 0.06475786492228508), (31, 0.06720060762017965), (30, 0.06731617357581854), (35, 0.06825095508247614), (33, 0.07037476543337107), (32, 0.07732165139168501), (26, 0.07798098493367434), (28, 0.08341042045503855), (29, 0.09326864033937454), (25, 0.09926075674593449), (22, 0.09950833860784769), (27, 0.10294455103576183), (24, 0.10354442428797483), (23, 0.10383972246199846), (5, 0.11125390511006117), (14, 0.11721509229391813), (21, 0.1265479288995266), (3, 0.12764153257012367), (17, 0.1317060887813568), (20, 0.13274890556931496), (38, 0.146248584613204), (39, 0.1483139432966709), (16, 0.1503186635673046), (42, 0.1513474602252245), (37, 0.15663454495370388), (19, 0.15664509125053883), (41, 0.15758543461561203), (15, 0.15763606317341328), (40, 0.15781855769455433), (43, 0.15963220037519932), (4, 0.16029647924005985), (0, 0.17056752927601337), (44, 0.1717367023229599), (6, 0.17450461722910404), (13, 0.17458787001669407), (7, 0.17770990170538425), (45, 0.179588433355093), (47, 0.19627228192985058), (46, 0.19685631431639194), (8, 0.1990743726491928), (10, 0.20246456190943718), (12, 0.2052889671176672), (11, 0.20776454359292984), (9, 0.21767907962203026), (49, 0.22418830171227455), (48, 0.22521410137414932), (50, 0.23762784898281097), (51, 0.25685056671500206), (52, 0.2942989207804203), (36, 0.5084430128335953), (18, 0.5554970726370811), (53, 0.6521949768066406)]
computing accuracy for after removing block 1 . block score: 0.05401874938979745
removed block 1 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061784. All blocks and scores: [(34, 0.06178395077586174), (2, 0.06498363334685564), (31, 0.0671510873362422), (30, 0.06738731637597084), (35, 0.06822698190808296), (33, 0.07039163634181023), (32, 0.07726792711764574), (26, 0.07807760033756495), (28, 0.08352132048457861), (29, 0.09340976644307375), (25, 0.09919525776058435), (22, 0.09952599834650755), (27, 0.10326564870774746), (24, 0.10346821788698435), (23, 0.10366112925112247), (5, 0.11025469191372395), (14, 0.11720024887472391), (21, 0.1264019664376974), (3, 0.12822039984166622), (17, 0.13202346116304398), (20, 0.13253550231456757), (38, 0.14596638642251492), (39, 0.14783446677029133), (16, 0.1502179093658924), (42, 0.15124032646417618), (37, 0.1563769429922104), (19, 0.1566394306719303), (15, 0.1573416255414486), (41, 0.15746974758803844), (40, 0.15765290148556232), (43, 0.15933381579816341), (4, 0.1596198696643114), (0, 0.17056752927601337), (44, 0.17190805822610855), (13, 0.1750413067638874), (6, 0.1762730125337839), (45, 0.17932291887700558), (7, 0.1796624306589365), (47, 0.19619962759315968), (46, 0.1970810890197754), (10, 0.2021530196070671), (8, 0.20421498641371727), (12, 0.20567899011075497), (11, 0.20789441838860512), (9, 0.21970454044640064), (49, 0.22410406358540058), (48, 0.22510374709963799), (50, 0.23775307647883892), (51, 0.25690556690096855), (52, 0.29428064450621605), (36, 0.5084273591637611), (18, 0.5557390600442886), (53, 0.6521297469735146)]
computing accuracy for after removing block 34 . block score: 0.06178395077586174
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.064984. All blocks and scores: [(2, 0.06498363334685564), (31, 0.0671510873362422), (30, 0.06738731637597084), (35, 0.06815146654844284), (33, 0.07039163634181023), (32, 0.07726792711764574), (26, 0.07807760033756495), (28, 0.08352132048457861), (29, 0.09340976644307375), (25, 0.09919525776058435), (22, 0.09952599834650755), (27, 0.10326564870774746), (24, 0.10346821788698435), (23, 0.10366112925112247), (5, 0.11025469191372395), (14, 0.11720024887472391), (21, 0.1264019664376974), (3, 0.12822039984166622), (17, 0.13202346116304398), (20, 0.13253550231456757), (38, 0.14242407493293285), (39, 0.14578756876289845), (42, 0.1473459228873253), (16, 0.1502179093658924), (37, 0.15457867458462715), (41, 0.15483219921588898), (43, 0.15608007833361626), (40, 0.15629969350993633), (19, 0.1566394306719303), (15, 0.1573416255414486), (4, 0.1596198696643114), (44, 0.16899384930729866), (0, 0.17056752927601337), (13, 0.1750413067638874), (6, 0.1762730125337839), (45, 0.17868873290717602), (7, 0.1796624306589365), (47, 0.1949667390435934), (46, 0.19536413624882698), (10, 0.2021530196070671), (8, 0.20421498641371727), (12, 0.20567899011075497), (11, 0.20789441838860512), (9, 0.21970454044640064), (49, 0.22241780534386635), (48, 0.22368756122887135), (50, 0.23690163902938366), (51, 0.25510936975479126), (52, 0.29285823553800583), (36, 0.506484217941761), (18, 0.5557390600442886), (53, 0.6576055884361267)]
computing accuracy for after removing block 2 . block score: 0.06498363334685564
removed block 2 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067171. All blocks and scores: [(31, 0.06717052403837442), (30, 0.06770070735365152), (35, 0.06853656843304634), (33, 0.07045937329530716), (32, 0.07728759571909904), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.1427512913942337), (39, 0.1455790363252163), (42, 0.14751579612493515), (16, 0.1500795278698206), (37, 0.15462797693908215), (41, 0.15463546849787235), (43, 0.155882453545928), (40, 0.15648241341114044), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.16945297829806805), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17847860790789127), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.1949198991060257), (46, 0.19539336301386356), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (9, 0.22204345278441906), (49, 0.22231651470065117), (48, 0.22340366803109646), (50, 0.23685323260724545), (51, 0.2551177330315113), (52, 0.2926546782255173), (36, 0.5076062008738518), (18, 0.5585161447525024), (53, 0.6573801562190056)]
computing accuracy for after removing block 31 . block score: 0.06717052403837442
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067701. All blocks and scores: [(30, 0.06770070735365152), (35, 0.06832328625023365), (33, 0.06998600997030735), (32, 0.07691892981529236), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.14124376513063908), (39, 0.1451344545930624), (42, 0.14719805493950844), (16, 0.1500795278698206), (41, 0.1538275834172964), (37, 0.15450537204742432), (43, 0.15520221926271915), (40, 0.15676734037697315), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.16849523596465588), (0, 0.17056752927601337), (13, 0.17503763176500797), (6, 0.17874738574028015), (45, 0.1790821421891451), (7, 0.18173840269446373), (47, 0.19454056397080421), (46, 0.1959428545087576), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.22173571959137917), (9, 0.22204345278441906), (48, 0.22318027541041374), (50, 0.23713134415447712), (51, 0.2552882209420204), (52, 0.29228881001472473), (36, 0.509839341044426), (18, 0.5585161447525024), (53, 0.6598142385482788)]
computing accuracy for after removing block 30 . block score: 0.06770070735365152
removed block 30 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066485. All blocks and scores: [(35, 0.06648518890142441), (33, 0.0697032455354929), (32, 0.0773529801517725), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.13987880758941174), (39, 0.14415700547397137), (42, 0.1466123703867197), (16, 0.1500795278698206), (41, 0.15383746661245823), (37, 0.15544690564274788), (43, 0.1558341272175312), (19, 0.15676895901560783), (15, 0.15711238607764244), (40, 0.15844319015741348), (4, 0.15924772806465626), (44, 0.16802092269062996), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17812410183250904), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.19442151859402657), (46, 0.19502928480505943), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.22065376862883568), (9, 0.22204345278441906), (48, 0.2229733020067215), (50, 0.23717963695526123), (51, 0.2544683553278446), (52, 0.2924013286828995), (36, 0.5146597698330879), (18, 0.5585161447525024), (53, 0.6609868407249451)]
computing accuracy for after removing block 35 . block score: 0.06648518890142441
removed block 35 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.069703. All blocks and scores: [(33, 0.0697032455354929), (32, 0.0773529801517725), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.1360938735306263), (39, 0.141838101670146), (42, 0.14294663444161415), (16, 0.1500795278698206), (41, 0.15020381286740303), (37, 0.15248576924204826), (43, 0.15270084142684937), (40, 0.15538488514721394), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.1660057883709669), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17641019262373447), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.19183656759560108), (46, 0.19283500127494335), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.21770969592034817), (48, 0.21981644444167614), (9, 0.22204345278441906), (50, 0.2354977000504732), (51, 0.2516464442014694), (52, 0.28985515609383583), (36, 0.509383887052536), (18, 0.5585161447525024), (53, 0.6661642044782639)]
computing accuracy for after removing block 33 . block score: 0.0697032455354929
removed block 33 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 32, with score 0.077353. All blocks and scores: [(32, 0.0773529801517725), (26, 0.07822920847684145), (28, 0.08377066347748041), (29, 0.0943168792873621), (25, 0.09922410175204277), (22, 0.09982893988490105), (23, 0.10349493566900492), (24, 0.10364920925348997), (27, 0.10389785654842854), (5, 0.10947001352906227), (14, 0.11691283900290728), (21, 0.1263347864151001), (3, 0.1284698210656643), (17, 0.13226734288036823), (20, 0.13245221599936485), (38, 0.13412854634225368), (39, 0.14083792082965374), (42, 0.14123639650642872), (41, 0.14779866859316826), (43, 0.14963804744184017), (16, 0.1500795278698206), (37, 0.15125159919261932), (40, 0.15289564058184624), (19, 0.15676895901560783), (15, 0.15711238607764244), (4, 0.15924772806465626), (44, 0.16384162940084934), (0, 0.17056752927601337), (13, 0.17503763176500797), (45, 0.17633170448243618), (6, 0.17874738574028015), (7, 0.18173840269446373), (47, 0.18925410509109497), (46, 0.19053447246551514), (10, 0.20236636511981487), (12, 0.20552101731300354), (11, 0.20730233192443848), (8, 0.2113600131124258), (49, 0.21523582935333252), (48, 0.21705200150609016), (9, 0.22204345278441906), (50, 0.23344802483916283), (51, 0.24904770217835903), (52, 0.2864312268793583), (36, 0.5058818757534027), (18, 0.5585161447525024), (53, 0.6718884035944939)]
computing accuracy for after removing block 32 . block score: 0.0773529801517725
removed block 32 current accuracy 0.9994 loss from initial  0.0006000000000000449
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 4 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.078846. All blocks and scores: [(26, 0.07884566579014063), (28, 0.08448173850774765), (29, 0.09373684320598841), (25, 0.10055932775139809), (22, 0.10060882102698088), (27, 0.10335474088788033), (24, 0.10464360751211643), (23, 0.10557838715612888), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.1448940970003605), (39, 0.1460770107805729), (42, 0.149587607011199), (16, 0.15126072615385056), (40, 0.15473092533648014), (41, 0.1550555769354105), (37, 0.15546771883964539), (43, 0.1561615038663149), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.16929522715508938), (0, 0.17186155170202255), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (45, 0.1783241257071495), (46, 0.19256952218711376), (47, 0.19625503942370415), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (9, 0.21805324219167233), (49, 0.22464337013661861), (48, 0.22552574425935745), (50, 0.237065888941288), (51, 0.25753646343946457), (52, 0.29539571329951286), (36, 0.4969770759344101), (18, 0.5549339950084686), (53, 0.6442844048142433)]
computing accuracy for after removing block 26 . block score: 0.07884566579014063
removed block 26 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.083212. All blocks and scores: [(28, 0.08321160450577736), (29, 0.0934495022520423), (25, 0.10055932775139809), (22, 0.10060882102698088), (27, 0.10369543079286814), (24, 0.10464360751211643), (23, 0.10557838715612888), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.14319614320993423), (39, 0.14361394383013248), (42, 0.1460629403591156), (16, 0.15126072615385056), (40, 0.15307637676596642), (43, 0.15342777594923973), (41, 0.15402741730213165), (37, 0.15455231629312038), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.16751530393958092), (0, 0.17186155170202255), (6, 0.1744529791176319), (13, 0.17602317966520786), (45, 0.17704134061932564), (7, 0.1779695749282837), (46, 0.18976985290646553), (47, 0.19477710500359535), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (9, 0.21805324219167233), (49, 0.22298105992376804), (48, 0.22478257305920124), (50, 0.23700445890426636), (51, 0.25593457370996475), (52, 0.29374097287654877), (36, 0.49649324268102646), (18, 0.5549339950084686), (53, 0.649113804101944)]
computing accuracy for after removing block 28 . block score: 0.08321160450577736
removed block 28 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.092735. All blocks and scores: [(29, 0.09273520484566689), (25, 0.10055932775139809), (22, 0.10060882102698088), (27, 0.10369543079286814), (24, 0.10464360751211643), (23, 0.10557838715612888), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.1410577278584242), (42, 0.14298932813107967), (39, 0.14345193654298782), (40, 0.15074148401618004), (43, 0.15110884606838226), (16, 0.15126072615385056), (41, 0.15250591933727264), (37, 0.15318475663661957), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.16564505361020565), (0, 0.17186155170202255), (6, 0.1744529791176319), (45, 0.17534339800477028), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.18776947259902954), (47, 0.1918109469115734), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (9, 0.21805324219167233), (49, 0.22009786404669285), (48, 0.2224467284977436), (50, 0.2357422597706318), (51, 0.25323180109262466), (52, 0.29196692258119583), (36, 0.4922751188278198), (18, 0.5549339950084686), (53, 0.6528387814760208)]
computing accuracy for after removing block 29 . block score: 0.09273520484566689
removed block 29 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.100559. All blocks and scores: [(25, 0.10055932775139809), (22, 0.10060882102698088), (27, 0.10369543079286814), (24, 0.10464360751211643), (23, 0.10557838715612888), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.13803259655833244), (39, 0.1418144330382347), (42, 0.1431376039981842), (43, 0.15066941641271114), (40, 0.15115449391305447), (16, 0.15126072615385056), (41, 0.15143651887774467), (37, 0.1524563431739807), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.162658067420125), (0, 0.17186155170202255), (45, 0.1744041908532381), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.1873840857297182), (47, 0.19020666927099228), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (49, 0.217204000800848), (9, 0.21805324219167233), (48, 0.22212760150432587), (50, 0.23462477885186672), (51, 0.25182875245809555), (52, 0.2915179617702961), (36, 0.49369414523243904), (18, 0.5549339950084686), (53, 0.6552625447511673)]
computing accuracy for after removing block 25 . block score: 0.10055932775139809
removed block 25 current accuracy 0.9974 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 22, with score 0.100609. All blocks and scores: [(22, 0.10060882102698088), (27, 0.10213642287999392), (24, 0.10464360751211643), (23, 0.10557838715612888), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.1363402921706438), (39, 0.13929999060928822), (42, 0.14112703688442707), (43, 0.1498802024871111), (40, 0.14990857802331448), (37, 0.15076830051839352), (41, 0.1509679425507784), (16, 0.15126072615385056), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.16121960617601871), (0, 0.17186155170202255), (45, 0.17212708294391632), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.18569408729672432), (47, 0.187776617705822), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (49, 0.21393965743482113), (9, 0.21805324219167233), (48, 0.21966934390366077), (50, 0.23418729566037655), (51, 0.2492236252874136), (52, 0.28933319821953773), (36, 0.4957817941904068), (18, 0.5549339950084686), (53, 0.658671423792839)]
computing accuracy for after removing block 22 . block score: 0.10060882102698088
removed block 22 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 27, with score 0.101470. All blocks and scores: [(27, 0.1014696154743433), (23, 0.10369164030998945), (24, 0.10426524747163057), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (20, 0.1335709374397993), (17, 0.1336986944079399), (38, 0.1357214767485857), (42, 0.13787182234227657), (39, 0.139074444770813), (40, 0.14789939299225807), (37, 0.14976705983281136), (43, 0.15056383982300758), (41, 0.15097474306821823), (16, 0.15126072615385056), (19, 0.15728853084146976), (15, 0.15739915519952774), (4, 0.1600513458251953), (44, 0.1609102562069893), (45, 0.1715448796749115), (0, 0.17186155170202255), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.18492390774190426), (47, 0.1858492512255907), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (11, 0.20783519744873047), (49, 0.21118303947150707), (48, 0.21735742315649986), (9, 0.21805324219167233), (50, 0.23365579172968864), (51, 0.24639692716300488), (52, 0.2875557541847229), (36, 0.49747300893068314), (18, 0.5549339950084686), (53, 0.6626216173171997)]
computing accuracy for after removing block 27 . block score: 0.1014696154743433
removed block 27 current accuracy 0.9916 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 23, with score 0.103692. All blocks and scores: [(23, 0.10369164030998945), (24, 0.10426524747163057), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (38, 0.1323323640972376), (20, 0.1335709374397993), (17, 0.1336986944079399), (42, 0.13562460616230965), (39, 0.13600299693644047), (40, 0.1455201767385006), (43, 0.14679239876568317), (37, 0.1473957672715187), (41, 0.1483908724039793), (16, 0.15126072615385056), (19, 0.15728853084146976), (15, 0.15739915519952774), (44, 0.15932504646480083), (4, 0.1600513458251953), (45, 0.16939163580536842), (0, 0.17186155170202255), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.18209842406213284), (47, 0.18240594677627087), (8, 0.1999634001404047), (10, 0.20214256271719933), (12, 0.2052981462329626), (49, 0.20776830986142159), (11, 0.20783519744873047), (48, 0.21467710472643375), (9, 0.21805324219167233), (50, 0.23387059941887856), (51, 0.24391998164355755), (52, 0.28608525544404984), (36, 0.49454523250460625), (18, 0.5549339950084686), (53, 0.6645863652229309)]
computing accuracy for after removing block 23 . block score: 0.10369164030998945
removed block 23 current accuracy 0.9848 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.105082. All blocks and scores: [(24, 0.10508157126605511), (5, 0.11167656723409891), (14, 0.11721877194941044), (3, 0.12660588510334492), (21, 0.12765875458717346), (38, 0.1302042044699192), (20, 0.1335709374397993), (17, 0.1336986944079399), (42, 0.13372141122817993), (39, 0.13431020639836788), (40, 0.14471922628581524), (37, 0.14560768380761147), (43, 0.14670069888234138), (41, 0.14699174091219902), (16, 0.15126072615385056), (19, 0.15728853084146976), (15, 0.15739915519952774), (44, 0.15799452923238277), (4, 0.1600513458251953), (45, 0.16676918044686317), (0, 0.17186155170202255), (6, 0.1744529791176319), (13, 0.17602317966520786), (7, 0.1779695749282837), (46, 0.17965969070792198), (47, 0.17972828075289726), (8, 0.1999634001404047), (10, 0.20214256271719933), (49, 0.20394368283450603), (12, 0.2052981462329626), (11, 0.20783519744873047), (48, 0.2122326958924532), (9, 0.21805324219167233), (50, 0.23188763484358788), (51, 0.24039947986602783), (52, 0.28355797752738), (36, 0.4974631741642952), (18, 0.5549339950084686), (53, 0.6668575927615166)]
computing accuracy for after removing block 24 . block score: 0.10508157126605511
removed block 24 current accuracy 0.978 loss from initial  0.02200000000000002
training start
training epoch 0 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 1 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 2 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 3 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 4 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 5 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 6 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 8 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 9 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 10 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 11 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 12 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 13 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 14 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 15 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 16 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 17 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 18 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 19 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 20 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 21 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 24 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 25 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 26 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 40 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 45 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 48 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 16
[activation mean]: block to remove picked: 5, with score 0.110559. All blocks and scores: [(5, 0.11055923532694578), (14, 0.11879782099276781), (3, 0.12586585246026516), (17, 0.1363935712724924), (38, 0.14255953952670097), (39, 0.14277654513716698), (42, 0.14729444310069084), (21, 0.15133837796747684), (37, 0.15221711620688438), (41, 0.15285390242934227), (40, 0.15301471203565598), (16, 0.15328387543559074), (43, 0.15463700890541077), (20, 0.1570127923041582), (15, 0.1571871042251587), (4, 0.1584135890007019), (44, 0.16631348244845867), (6, 0.1711372695863247), (0, 0.17268433794379234), (7, 0.1730225533246994), (13, 0.17375355027616024), (45, 0.17430962808430195), (19, 0.1759096346795559), (46, 0.18829395435750484), (47, 0.1925039328634739), (10, 0.194633012637496), (8, 0.19619561545550823), (12, 0.20107878372073174), (11, 0.2066198941320181), (9, 0.21264208108186722), (49, 0.21993738040328026), (48, 0.22190643660724163), (50, 0.23300167173147202), (51, 0.25463083386421204), (52, 0.29061250388622284), (36, 0.4924866370856762), (18, 0.5459543541073799), (53, 0.6493832096457481)]
computing accuracy for after removing block 5 . block score: 0.11055923532694578
removed block 5 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.116632. All blocks and scores: [(14, 0.11663179658353329), (3, 0.12586585246026516), (17, 0.13413711823523045), (38, 0.1439263578504324), (39, 0.14446955360472202), (42, 0.14834867976605892), (21, 0.14980816282331944), (16, 0.15137835033237934), (41, 0.15298653207719326), (37, 0.1548931561410427), (43, 0.15548952110111713), (15, 0.15583665296435356), (20, 0.15584592707455158), (40, 0.15785618871450424), (4, 0.1584135890007019), (44, 0.16723129339516163), (6, 0.1723818052560091), (13, 0.17241131886839867), (0, 0.17268433794379234), (45, 0.17510206811130047), (19, 0.17601904086768627), (7, 0.1808250155299902), (46, 0.1896840501576662), (10, 0.19325228594243526), (47, 0.19385694153606892), (12, 0.1984244603663683), (8, 0.19852607138454914), (11, 0.19915363751351833), (9, 0.21142607927322388), (49, 0.21983844600617886), (48, 0.22260537184774876), (50, 0.23357364535331726), (51, 0.2538229189813137), (52, 0.2899823226034641), (36, 0.49988099187612534), (18, 0.5516595020890236), (53, 0.6506524085998535)]
computing accuracy for after removing block 14 . block score: 0.11663179658353329
removed block 14 current accuracy 0.9976 loss from initial  0.0023999999999999577
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.125866. All blocks and scores: [(3, 0.12586585246026516), (17, 0.13607250526547432), (21, 0.14853165112435818), (42, 0.14890839345753193), (38, 0.14898758754134178), (39, 0.15118079259991646), (16, 0.1522030122578144), (20, 0.15653282031416893), (37, 0.15673046559095383), (4, 0.1584135890007019), (15, 0.1584204901009798), (41, 0.16062752343714237), (40, 0.16184565238654613), (43, 0.1678447686135769), (6, 0.1723818052560091), (13, 0.17241131886839867), (0, 0.17268433794379234), (44, 0.1729301866143942), (45, 0.1764952316880226), (19, 0.1798273976892233), (7, 0.1808250155299902), (46, 0.18947074189782143), (10, 0.19325228594243526), (47, 0.19544830545783043), (12, 0.1984244603663683), (8, 0.19852607138454914), (11, 0.19915363751351833), (9, 0.21142607927322388), (49, 0.22311596386134624), (48, 0.22336862049996853), (50, 0.23468776233494282), (51, 0.2534392215311527), (52, 0.290581401437521), (36, 0.5086520463228226), (18, 0.5509722605347633), (53, 0.642731286585331)]
computing accuracy for after removing block 3 . block score: 0.12586585246026516
removed block 3 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.135660. All blocks and scores: [(17, 0.13566026464104652), (42, 0.14685196615755558), (21, 0.14687897078692913), (16, 0.14952120557427406), (38, 0.14970680885016918), (39, 0.1513682585209608), (20, 0.1547627318650484), (4, 0.15629814378917217), (37, 0.1568018663674593), (15, 0.15703397803008556), (41, 0.16000867076218128), (40, 0.1639941707253456), (43, 0.16620740294456482), (13, 0.17206834256649017), (0, 0.17268433794379234), (44, 0.172953637316823), (45, 0.17630081064999104), (19, 0.17788751237094402), (7, 0.18259064108133316), (6, 0.18276154063642025), (46, 0.18777594342827797), (47, 0.1954826693981886), (12, 0.1955574695020914), (8, 0.1968216970562935), (11, 0.1972749549895525), (10, 0.20015637949109077), (9, 0.21042273193597794), (49, 0.2224235013127327), (48, 0.2232733741402626), (50, 0.23487850278615952), (51, 0.25180768594145775), (52, 0.2887851558625698), (36, 0.5102232098579407), (18, 0.5539535582065582), (53, 0.6447933986783028)]
computing accuracy for after removing block 17 . block score: 0.13566026464104652
removed block 17 current accuracy 0.9908 loss from initial  0.009199999999999986
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.143196. All blocks and scores: [(42, 0.14319633692502975), (21, 0.1453014574944973), (20, 0.14898693561553955), (16, 0.14952120557427406), (38, 0.15328481048345566), (39, 0.15331828780472279), (37, 0.1561924498528242), (4, 0.15629814378917217), (15, 0.15703397803008556), (40, 0.16324466280639172), (41, 0.163661515340209), (13, 0.17206834256649017), (0, 0.17268433794379234), (43, 0.17295429296791553), (44, 0.17327754758298397), (45, 0.1735637914389372), (19, 0.17618843540549278), (7, 0.18259064108133316), (6, 0.18276154063642025), (46, 0.18452127650380135), (47, 0.19408047385513783), (12, 0.1955574695020914), (8, 0.1968216970562935), (11, 0.1972749549895525), (10, 0.20015637949109077), (9, 0.21042273193597794), (49, 0.22092493809759617), (48, 0.2218232061713934), (50, 0.23213917203247547), (51, 0.2467787880450487), (52, 0.2856427989900112), (36, 0.5092682167887688), (18, 0.5472257137298584), (53, 0.6444869861006737)]
computing accuracy for after removing block 42 . block score: 0.14319633692502975
removed block 42 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 21, with score 0.145301. All blocks and scores: [(21, 0.1453014574944973), (20, 0.14898693561553955), (16, 0.14952120557427406), (38, 0.15328481048345566), (39, 0.15331828780472279), (37, 0.1561924498528242), (4, 0.15629814378917217), (15, 0.15703397803008556), (40, 0.16324466280639172), (41, 0.163661515340209), (13, 0.17206834256649017), (0, 0.17268433794379234), (44, 0.1731927264481783), (45, 0.1755577027797699), (19, 0.17618843540549278), (43, 0.1777191087603569), (7, 0.18259064108133316), (6, 0.18276154063642025), (46, 0.18538100272417068), (47, 0.19356169365346432), (12, 0.1955574695020914), (8, 0.1968216970562935), (11, 0.1972749549895525), (10, 0.20015637949109077), (9, 0.21042273193597794), (48, 0.2191222570836544), (49, 0.2217603176832199), (50, 0.23057525604963303), (51, 0.24597287736833096), (52, 0.2841007895767689), (36, 0.5092682167887688), (18, 0.5472257137298584), (53, 0.6519121900200844)]
computing accuracy for after removing block 21 . block score: 0.1453014574944973
removed block 21 current accuracy 0.9702 loss from initial  0.02980000000000005
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 39, with score 0.148391. All blocks and scores: [(39, 0.14839110523462296), (20, 0.14898693561553955), (38, 0.14908113330602646), (16, 0.14952120557427406), (37, 0.15127060748636723), (4, 0.15629814378917217), (15, 0.15703397803008556), (40, 0.1600744891911745), (41, 0.1628202311694622), (44, 0.17009854689240456), (45, 0.17054149322211742), (13, 0.17206834256649017), (0, 0.17268433794379234), (19, 0.17618843540549278), (43, 0.1762138269841671), (46, 0.17969674058258533), (7, 0.18259064108133316), (6, 0.18276154063642025), (47, 0.18811878189444542), (12, 0.1955574695020914), (8, 0.1968216970562935), (11, 0.1972749549895525), (10, 0.20015637949109077), (9, 0.21042273193597794), (48, 0.2138544972985983), (49, 0.21480900421738625), (50, 0.225936371833086), (51, 0.23805885016918182), (52, 0.27981092780828476), (36, 0.5070526003837585), (18, 0.5472257137298584), (53, 0.6536710187792778)]
computing accuracy for after removing block 39 . block score: 0.14839110523462296
removed block 39 current accuracy 0.967 loss from initial  0.03300000000000003
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 20, with score 0.148987. All blocks and scores: [(20, 0.14898693561553955), (38, 0.14908113330602646), (16, 0.14952120557427406), (37, 0.15127060748636723), (4, 0.15629814378917217), (40, 0.15688921324908733), (15, 0.15703397803008556), (41, 0.16133646667003632), (45, 0.17115013115108013), (43, 0.17161685787141323), (44, 0.171722998842597), (13, 0.17206834256649017), (0, 0.17268433794379234), (19, 0.17618843540549278), (46, 0.17882908321917057), (7, 0.18259064108133316), (6, 0.18276154063642025), (47, 0.18746749311685562), (12, 0.1955574695020914), (8, 0.1968216970562935), (11, 0.1972749549895525), (10, 0.20015637949109077), (9, 0.21042273193597794), (48, 0.2148598860949278), (49, 0.21536383777856827), (50, 0.22755378857254982), (51, 0.23775342106819153), (52, 0.2791537120938301), (36, 0.5070526003837585), (18, 0.5472257137298584), (53, 0.6609137654304504)]
computing accuracy for after removing block 20 . block score: 0.14898693561553955
removed block 20 current accuracy 0.9442 loss from initial  0.05579999999999996
training start
training epoch 0 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best True lr [0.001]
training epoch 1 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 2 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 3 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 4 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 5 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 6 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 7 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 8 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 9 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 10 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 11 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 12 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 13 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 14 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 15 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 16 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 17 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 18 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 19 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 20 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 21 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 22 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 23 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 24 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 25 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 26 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 27 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 29 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 30 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 31 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 32 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 33 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 34 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 35 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 36 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 37 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 38 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 39 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 40 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 41 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 43 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 45 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 46 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 48 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 49 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 24
[activation mean]: block to remove picked: 38, with score 0.148506. All blocks and scores: [(38, 0.1485060378909111), (16, 0.15377435460686684), (41, 0.15660779178142548), (43, 0.15800407901406288), (37, 0.15858753956854343), (40, 0.15930798649787903), (4, 0.1644469741731882), (15, 0.1648399978876114), (44, 0.16849356330931187), (0, 0.1718881018459797), (6, 0.1731930859386921), (45, 0.17472831718623638), (7, 0.17632512748241425), (13, 0.17802639678120613), (46, 0.18898249231278896), (47, 0.19161682203412056), (10, 0.19452847354114056), (8, 0.1946649868041277), (12, 0.20094533637166023), (11, 0.2054688986390829), (19, 0.20653559267520905), (9, 0.2119030226022005), (48, 0.21889081224799156), (49, 0.21911966055631638), (50, 0.23131758347153664), (51, 0.25317130237817764), (52, 0.289016455411911), (36, 0.4857632555067539), (18, 0.5343866273760796), (53, 0.6566885635256767)]
computing accuracy for after removing block 38 . block score: 0.1485060378909111
removed block 38 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 16, with score 0.153774. All blocks and scores: [(16, 0.15377435460686684), (43, 0.1564140785485506), (41, 0.15680970437824726), (37, 0.15858753956854343), (40, 0.16152934543788433), (4, 0.1644469741731882), (15, 0.1648399978876114), (44, 0.1700172908604145), (0, 0.1718881018459797), (45, 0.17316011153161526), (6, 0.1731930859386921), (7, 0.17632512748241425), (13, 0.17802639678120613), (46, 0.18873213231563568), (47, 0.19091389328241348), (10, 0.19452847354114056), (8, 0.1946649868041277), (12, 0.20094533637166023), (11, 0.2054688986390829), (19, 0.20653559267520905), (9, 0.2119030226022005), (49, 0.2159724272787571), (48, 0.2167958915233612), (50, 0.2278935443609953), (51, 0.2490821797400713), (52, 0.28617480397224426), (36, 0.4857632555067539), (18, 0.5343866273760796), (53, 0.6620488688349724)]
computing accuracy for after removing block 16 . block score: 0.15377435460686684
removed block 16 current accuracy 0.9848 loss from initial  0.015199999999999991
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 37, with score 0.154571. All blocks and scores: [(37, 0.15457112900912762), (41, 0.16332559287548065), (4, 0.1644469741731882), (15, 0.1648399978876114), (40, 0.16599020920693874), (43, 0.17038214951753616), (0, 0.1718881018459797), (6, 0.1731930859386921), (45, 0.17379961349070072), (44, 0.17630739323794842), (7, 0.17632512748241425), (13, 0.17802639678120613), (46, 0.18401816673576832), (47, 0.19200298562645912), (10, 0.19452847354114056), (8, 0.1946649868041277), (12, 0.20094533637166023), (19, 0.2029583752155304), (11, 0.2054688986390829), (9, 0.2119030226022005), (49, 0.2159289512783289), (48, 0.21746261976659298), (50, 0.22689968161284924), (51, 0.2448521237820387), (52, 0.28230950981378555), (36, 0.4872789531946182), (18, 0.522141844034195), (53, 0.6525158286094666)]
computing accuracy for after removing block 37 . block score: 0.15457112900912762
removed block 37 current accuracy 0.9754 loss from initial  0.024599999999999955
since last training loss: 0.02079999999999993 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 4, with score 0.164447. All blocks and scores: [(4, 0.1644469741731882), (15, 0.1648399978876114), (41, 0.16635929979383945), (45, 0.1702757254242897), (43, 0.17095327004790306), (0, 0.1718881018459797), (6, 0.1731930859386921), (40, 0.17347251810133457), (44, 0.17620636336505413), (7, 0.17632512748241425), (13, 0.17802639678120613), (46, 0.18230610340833664), (47, 0.19184581749141216), (10, 0.19452847354114056), (8, 0.1946649868041277), (12, 0.20094533637166023), (19, 0.2029583752155304), (11, 0.2054688986390829), (49, 0.20931467227637768), (9, 0.2119030226022005), (48, 0.2132261712104082), (50, 0.21918213739991188), (51, 0.23542384803295135), (52, 0.2736717574298382), (36, 0.4872789531946182), (18, 0.522141844034195), (53, 0.6575300171971321)]
computing accuracy for after removing block 4 . block score: 0.1644469741731882
removed block 4 current accuracy 0.9604 loss from initial  0.03959999999999997
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 41, with score 0.160855. All blocks and scores: [(41, 0.16085529886186123), (15, 0.16114158928394318), (43, 0.1624244600534439), (45, 0.16607272811233997), (6, 0.1667508501559496), (13, 0.16973534785211086), (44, 0.1698891781270504), (0, 0.1718881018459797), (7, 0.17545423470437527), (40, 0.17579450830817223), (46, 0.17770487442612648), (8, 0.186006685718894), (11, 0.1870478969067335), (12, 0.19060937501490116), (10, 0.19063321314752102), (47, 0.19148060865700245), (19, 0.1948194932192564), (9, 0.19640094228088856), (49, 0.20171832479536533), (48, 0.21100720763206482), (50, 0.2159759234637022), (51, 0.2292080707848072), (52, 0.2699854001402855), (36, 0.48860425502061844), (18, 0.5165062993764877), (53, 0.6655976101756096)]
computing accuracy for after removing block 41 . block score: 0.16085529886186123
removed block 41 current accuracy 0.9422 loss from initial  0.05779999999999996
since last training loss: 0.05399999999999994 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 15, with score 0.161142. All blocks and scores: [(15, 0.16114158928394318), (45, 0.1654707621783018), (6, 0.1667508501559496), (13, 0.16973534785211086), (43, 0.17037120833992958), (0, 0.1718881018459797), (44, 0.17410868033766747), (7, 0.17545423470437527), (40, 0.17579450830817223), (46, 0.1773438397794962), (8, 0.186006685718894), (11, 0.1870478969067335), (47, 0.1890664380043745), (12, 0.19060937501490116), (10, 0.19063321314752102), (19, 0.1948194932192564), (9, 0.19640094228088856), (49, 0.1993518639355898), (48, 0.20910296775400639), (50, 0.21234854124486446), (51, 0.22582542523741722), (52, 0.2667265608906746), (36, 0.48860425502061844), (18, 0.5165062993764877), (53, 0.68404371291399)]
computing accuracy for after removing block 15 . block score: 0.16114158928394318
removed block 15 current accuracy 0.8878 loss from initial  0.11219999999999997
since last training loss: 0.10839999999999994 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 45, with score 0.157703. All blocks and scores: [(45, 0.15770259127020836), (6, 0.1667508501559496), (46, 0.16771012730896473), (13, 0.16973534785211086), (0, 0.1718881018459797), (7, 0.17545423470437527), (44, 0.17994103766977787), (40, 0.1844196692109108), (8, 0.186006685718894), (11, 0.1870478969067335), (47, 0.18822486512362957), (12, 0.19060937501490116), (10, 0.19063321314752102), (19, 0.1920778974890709), (9, 0.19640094228088856), (43, 0.19709288328886032), (49, 0.20171593688428402), (48, 0.20563565753400326), (50, 0.210488336160779), (51, 0.21970205381512642), (52, 0.263251181691885), (36, 0.5057980567216873), (18, 0.5099206864833832), (53, 0.6663941219449043)]
computing accuracy for after removing block 45 . block score: 0.15770259127020836
removed block 45 current accuracy 0.8806 loss from initial  0.11939999999999995
since last training loss: 0.11559999999999993 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 6, with score 0.166751. All blocks and scores: [(6, 0.1667508501559496), (46, 0.16765322536230087), (13, 0.16973534785211086), (0, 0.1718881018459797), (7, 0.17545423470437527), (44, 0.17994103766977787), (47, 0.1834370158612728), (40, 0.1844196692109108), (8, 0.186006685718894), (11, 0.1870478969067335), (12, 0.19060937501490116), (10, 0.19063321314752102), (19, 0.1920778974890709), (9, 0.19640094228088856), (43, 0.19709288328886032), (49, 0.2003315780311823), (48, 0.20219354890286922), (50, 0.20462258532643318), (51, 0.21482142060995102), (52, 0.25761543586850166), (36, 0.5057980567216873), (18, 0.5099206864833832), (53, 0.6901631653308868)]
computing accuracy for after removing block 6 . block score: 0.1667508501559496
removed block 6 current accuracy 0.8148 loss from initial  0.18520000000000003
since last training loss: 0.1814 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 46, with score 0.150519. All blocks and scores: [(46, 0.15051921270787716), (44, 0.1574620008468628), (13, 0.15792215056717396), (0, 0.1718881018459797), (40, 0.1768521312624216), (8, 0.17740138806402683), (47, 0.1774154268205166), (19, 0.17799080535769463), (7, 0.1800760831683874), (43, 0.18456402234733105), (11, 0.18457054160535336), (12, 0.1847791001200676), (49, 0.18559387139976025), (10, 0.19219697080552578), (9, 0.19402123428881168), (50, 0.19461016729474068), (48, 0.19470486603677273), (51, 0.2020019143819809), (52, 0.25451749563217163), (18, 0.49594974145293236), (36, 0.49682117626070976), (53, 0.6800015792250633)]
computing accuracy for after removing block 46 . block score: 0.15051921270787716
removed block 46 current accuracy 0.7746 loss from initial  0.22540000000000004
training start
training epoch 0 val accuracy 0.966 topk_dict {'top1': 0.966} is_best True lr [0.001]
training epoch 1 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 2 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best True lr [0.001]
training epoch 3 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best True lr [0.001]
training epoch 4 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 5 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 6 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 7 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 8 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 9 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 10 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 11 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 12 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 13 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best True lr [0.001]
training epoch 14 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 15 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 16 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 17 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 18 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 19 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 20 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best True lr [0.001]
training epoch 21 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 22 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 23 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 24 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 25 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 26 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 27 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 28 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 29 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 30 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 32 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 33 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 34 val accuracy 0.986 topk_dict {'top1': 0.986} is_best False lr [0.001]
training epoch 35 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best True lr [0.001]
training epoch 36 val accuracy 0.985 topk_dict {'top1': 0.985} is_best False lr [0.001]
training epoch 37 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 38 val accuracy 0.9852 topk_dict {'top1': 0.9852} is_best False lr [0.001]
training epoch 39 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 40 val accuracy 0.9854 topk_dict {'top1': 0.9854} is_best False lr [0.001]
training epoch 41 val accuracy 0.9876 topk_dict {'top1': 0.9876} is_best True lr [0.001]
training epoch 42 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 43 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 44 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 45 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 46 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best False lr [0.001]
training epoch 47 val accuracy 0.987 topk_dict {'top1': 0.987} is_best False lr [0.001]
training epoch 48 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best False lr [0.001]
training epoch 49 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.987600)
finished training. finished 50 epochs. accuracy 0.9876 topk_dict {'top1': 0.9876}
