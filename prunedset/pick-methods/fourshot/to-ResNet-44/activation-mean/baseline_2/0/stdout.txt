start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068702. All blocks and scores: [(26, 0.06870234198868275), (27, 0.0741223581135273), (31, 0.07421684544533491), (35, 0.07685474585741758), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08143280725926161), (24, 0.08224374894052744), (34, 0.08227442763745785), (33, 0.08310604561120272), (23, 0.08412310108542442), (32, 0.08623841684311628), (28, 0.0872054873034358), (22, 0.08930969890207052), (30, 0.09091433975845575), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13720723055303097), (39, 0.13744624331593513), (37, 0.14209549687802792), (38, 0.14290856197476387), (6, 0.14786463603377342), (41, 0.1508424561470747), (42, 0.15258264541625977), (4, 0.15538891777396202), (43, 0.15601677261292934), (44, 0.15883748047053814), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16798720695078373), (2, 0.18457405641674995), (46, 0.18493103049695492), (1, 0.20192440785467625), (47, 0.2080467976629734), (48, 0.21010252088308334), (49, 0.224680308252573), (50, 0.23862904869019985), (51, 0.25924162939190865), (52, 0.28526581451296806), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4550497271120548), (53, 0.6487655118107796)]
computing accuracy for after removing block 26 . block score: 0.06870234198868275
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074250. All blocks and scores: [(31, 0.07425017189234495), (27, 0.07438226789236069), (35, 0.0760756740346551), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08178351167589426), (34, 0.08181511238217354), (24, 0.08224374894052744), (33, 0.08314474113285542), (23, 0.08412310108542442), (32, 0.08550294954329729), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (40, 0.13959151320159435), (39, 0.1399664543569088), (37, 0.14363272115588188), (38, 0.1437524501234293), (6, 0.14786463603377342), (41, 0.15150794386863708), (42, 0.15349512174725533), (4, 0.15538891777396202), (43, 0.15715143270790577), (13, 0.1590876206755638), (44, 0.15911891870200634), (3, 0.16731475666165352), (45, 0.16931429505348206), (2, 0.18457405641674995), (46, 0.186824394389987), (1, 0.20192440785467625), (47, 0.20976067893207073), (48, 0.2109022866934538), (49, 0.2249483335763216), (50, 0.23839633911848068), (51, 0.2592626102268696), (52, 0.2852507643401623), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4592660255730152), (53, 0.6468537002801895)]
computing accuracy for after removing block 31 . block score: 0.07425017189234495
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074382. All blocks and scores: [(27, 0.07438226789236069), (35, 0.07612952496856451), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (21, 0.08055791165679693), (25, 0.08091523498296738), (34, 0.08106645382940769), (29, 0.08178351167589426), (24, 0.08224374894052744), (33, 0.08338531665503979), (23, 0.08412310108542442), (32, 0.08539257477968931), (28, 0.08704610168933868), (22, 0.08930969890207052), (30, 0.09067306388169527), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14128642156720161), (40, 0.14169061370193958), (39, 0.14174902439117432), (37, 0.14439108967781067), (6, 0.14786463603377342), (41, 0.15143204852938652), (42, 0.15228785201907158), (4, 0.15538891777396202), (43, 0.15636706165969372), (44, 0.15833302028477192), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.16788306273519993), (2, 0.18457405641674995), (46, 0.1864120475947857), (1, 0.20192440785467625), (47, 0.20843712612986565), (48, 0.21100311167538166), (49, 0.22473796643316746), (50, 0.23855118453502655), (51, 0.2591783180832863), (52, 0.28372708708047867), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.46568959951400757), (53, 0.6510000601410866)]
computing accuracy for after removing block 27 . block score: 0.07438226789236069
removed block 27 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075854. All blocks and scores: [(35, 0.07585428189486265), (20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.14026966504752636), (39, 0.14322753064334393), (40, 0.14488770440220833), (37, 0.14594712853431702), (6, 0.14786463603377342), (41, 0.15189490653574467), (42, 0.15252277441322803), (4, 0.15538891777396202), (43, 0.15715407766401768), (44, 0.15864605642855167), (13, 0.1590876206755638), (3, 0.16731475666165352), (45, 0.1683814972639084), (2, 0.18457405641674995), (46, 0.18689549528062344), (1, 0.20192440785467625), (47, 0.20870989188551903), (48, 0.21123779565095901), (49, 0.22443696111440659), (50, 0.23874318413436413), (51, 0.2584992125630379), (52, 0.2828393988311291), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4712146706879139), (53, 0.6518600136041641)]
computing accuracy for after removing block 35 . block score: 0.07585428189486265
removed block 35 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076914. All blocks and scores: [(20, 0.07691387087106705), (17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08039183169603348), (21, 0.08055791165679693), (25, 0.08091523498296738), (29, 0.08158359304070473), (24, 0.08224374894052744), (33, 0.08347001578658819), (23, 0.08412310108542442), (32, 0.08537359349429607), (28, 0.08727469574660063), (22, 0.08930969890207052), (30, 0.08968300838023424), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.1385685559362173), (40, 0.13947991654276848), (39, 0.14093938656151295), (37, 0.14259942434728146), (6, 0.14786463603377342), (41, 0.15029864758253098), (42, 0.15072360262274742), (43, 0.15525723062455654), (44, 0.1552812773734331), (4, 0.15538891777396202), (13, 0.1590876206755638), (45, 0.16552621126174927), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.1869147438555956), (1, 0.20192440785467625), (48, 0.20716596953570843), (47, 0.20739650540053844), (49, 0.22507839649915695), (50, 0.23703056946396828), (51, 0.25911351665854454), (52, 0.28219735622406006), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.47133130580186844), (53, 0.6564537882804871)]
computing accuracy for after removing block 20 . block score: 0.07691387087106705
removed block 20 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079448. All blocks and scores: [(17, 0.07944803778082132), (16, 0.08003389276564121), (34, 0.08003473933786154), (29, 0.08079283125698566), (21, 0.08103854302316904), (25, 0.08157523907721043), (24, 0.0828929403796792), (33, 0.08348109386861324), (23, 0.08391222264617682), (32, 0.0845849085599184), (28, 0.08620174136012793), (30, 0.088497344404459), (22, 0.09044258669018745), (14, 0.09289351291954517), (9, 0.09729468170553446), (11, 0.10143640916794538), (19, 0.10311755910515785), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13876904174685478), (40, 0.14043930359184742), (39, 0.14079759642481804), (37, 0.1433244775980711), (6, 0.14786463603377342), (41, 0.15065929107367992), (42, 0.15136869624257088), (4, 0.15538891777396202), (44, 0.1556632611900568), (43, 0.15633762441575527), (13, 0.1590876206755638), (45, 0.1662806160748005), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18815029971301556), (1, 0.20192440785467625), (48, 0.20721778832376003), (47, 0.208082502707839), (49, 0.22565172612667084), (50, 0.23704500310122967), (51, 0.2587750032544136), (52, 0.28254886716604233), (0, 0.3154492452740669), (18, 0.4302141107618809), (36, 0.4735274948179722), (53, 0.6537546589970589)]
computing accuracy for after removing block 17 . block score: 0.07944803778082132
removed block 17 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.077955. All blocks and scores: [(21, 0.07795533165335655), (34, 0.07894970290362835), (29, 0.0790198752656579), (25, 0.07908098585903645), (16, 0.08003389276564121), (33, 0.08208741899579763), (24, 0.08280743844807148), (23, 0.08313068188726902), (32, 0.08349784929305315), (28, 0.08599762804806232), (30, 0.08654309343546629), (22, 0.09004937391728163), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13761902786791325), (37, 0.14218291267752647), (39, 0.14250223897397518), (40, 0.1427330169826746), (6, 0.14786463603377342), (42, 0.149957912042737), (41, 0.15121997334063053), (4, 0.15538891777396202), (44, 0.15583417192101479), (43, 0.1559469159692526), (13, 0.1590876206755638), (45, 0.16489200666546822), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.18951294012367725), (1, 0.20192440785467625), (48, 0.20613021031022072), (47, 0.20653356611728668), (49, 0.2261425293982029), (50, 0.23595429211854935), (51, 0.2574720084667206), (52, 0.2808535546064377), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.47553205117583275), (53, 0.6502362936735153)]
computing accuracy for after removing block 21 . block score: 0.07795533165335655
removed block 21 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.077982. All blocks and scores: [(29, 0.07798169739544392), (25, 0.07838128041476011), (34, 0.07839732337743044), (16, 0.08003389276564121), (33, 0.08119457680732012), (23, 0.08126077149063349), (24, 0.0816669063642621), (32, 0.0824327003210783), (28, 0.08386608771979809), (30, 0.0852785985916853), (22, 0.09076022170484066), (14, 0.09289351291954517), (9, 0.09729468170553446), (19, 0.10036142077296972), (11, 0.10143640916794538), (8, 0.10692541860044003), (15, 0.11520706862211227), (7, 0.11757279746234417), (10, 0.12371599115431309), (12, 0.13088013418018818), (5, 0.1332902405411005), (38, 0.13711080700159073), (37, 0.14175310172140598), (39, 0.14240100793540478), (40, 0.14322563633322716), (6, 0.14786463603377342), (42, 0.15017673559486866), (41, 0.1524363812059164), (44, 0.1552524920552969), (4, 0.15538891777396202), (43, 0.15651666559278965), (13, 0.1590876206755638), (45, 0.1644004713743925), (3, 0.16731475666165352), (2, 0.18457405641674995), (46, 0.19123134016990662), (1, 0.20192440785467625), (48, 0.20559575967490673), (47, 0.2066254075616598), (49, 0.2266144324094057), (50, 0.23550251685082912), (51, 0.2582874819636345), (52, 0.2810910604894161), (0, 0.3154492452740669), (18, 0.4352080151438713), (36, 0.4777962565422058), (53, 0.651190422475338)]
computing accuracy for after removing block 29 . block score: 0.07798169739544392
removed block 29 current accuracy 0.9958 loss from initial  0.0041999999999999815
training start
training epoch 0 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 1 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 2 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 3 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 4 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 10 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 11 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 23 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 24 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 25 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 28 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 29 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 48 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 5 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation mean]: block to remove picked: 16, with score 0.081366. All blocks and scores: [(16, 0.08136580139398575), (25, 0.08169664535671473), (33, 0.0835370710119605), (34, 0.08490993361920118), (23, 0.0874622780829668), (24, 0.08765679504722357), (32, 0.08794920053333044), (28, 0.09046050999313593), (30, 0.09248705953359604), (14, 0.09267917554825544), (22, 0.09423358179628849), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10308590345084667), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (12, 0.13114257901906967), (5, 0.13275575079023838), (39, 0.13634612411260605), (40, 0.13755201175808907), (38, 0.14070489816367626), (37, 0.14127743802964687), (41, 0.14677417650818825), (6, 0.14824785850942135), (42, 0.15046744793653488), (43, 0.15402064844965935), (4, 0.15593685768544674), (44, 0.15688134729862213), (13, 0.15930364280939102), (45, 0.16468208096921444), (3, 0.16737028025090694), (46, 0.18393179774284363), (2, 0.1852165162563324), (1, 0.20217271894216537), (47, 0.2055540420114994), (48, 0.20852074399590492), (49, 0.22327221930027008), (50, 0.23735760524868965), (51, 0.2586524039506912), (52, 0.2817380391061306), (0, 0.3153342045843601), (18, 0.43062299117445946), (36, 0.45017994940280914), (53, 0.6451313272118568)]
computing accuracy for after removing block 16 . block score: 0.08136580139398575
removed block 16 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.081607. All blocks and scores: [(25, 0.08160740043967962), (33, 0.08249249216169119), (34, 0.08463089913129807), (23, 0.0870303949341178), (32, 0.08858963567763567), (24, 0.0896440977230668), (28, 0.09006298426538706), (30, 0.09161419328302145), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (12, 0.13114257901906967), (5, 0.13275575079023838), (39, 0.134843235835433), (40, 0.1361652258783579), (37, 0.14102548733353615), (38, 0.1411917433142662), (6, 0.14824785850942135), (41, 0.1484876126050949), (42, 0.14966854453086853), (43, 0.15371748805046082), (4, 0.15593685768544674), (44, 0.15696079842746258), (13, 0.15930364280939102), (45, 0.16446836106479168), (3, 0.16737028025090694), (46, 0.18295416235923767), (2, 0.1852165162563324), (1, 0.20217271894216537), (47, 0.20497626438736916), (48, 0.2068600319325924), (49, 0.2224909495562315), (50, 0.23472853563725948), (51, 0.2566182501614094), (52, 0.27991147339344025), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.4486554488539696), (53, 0.6459183692932129)]
computing accuracy for after removing block 25 . block score: 0.08160740043967962
removed block 25 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 33, with score 0.082402. All blocks and scores: [(33, 0.08240187726914883), (34, 0.0839188490062952), (23, 0.0870303949341178), (32, 0.08754368592053652), (28, 0.08932762406766415), (24, 0.0896440977230668), (30, 0.09019674267619848), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (12, 0.13114257901906967), (5, 0.13275575079023838), (40, 0.13635286130011082), (39, 0.1370042823255062), (38, 0.14025510661303997), (37, 0.14114263653755188), (42, 0.1474666465073824), (6, 0.14824785850942135), (41, 0.14894752204418182), (43, 0.15321135893464088), (4, 0.15593685768544674), (44, 0.1573107335716486), (13, 0.15930364280939102), (45, 0.16460319235920906), (3, 0.16737028025090694), (46, 0.18301780335605145), (2, 0.1852165162563324), (1, 0.20217271894216537), (47, 0.20468842796981335), (48, 0.20569072663784027), (49, 0.22202247940003872), (50, 0.23322953842580318), (51, 0.2560259960591793), (52, 0.27813754230737686), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.45279936864972115), (53, 0.6438773348927498)]
computing accuracy for after removing block 33 . block score: 0.08240187726914883
removed block 33 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 34, with score 0.083605. All blocks and scores: [(34, 0.08360460959374905), (23, 0.0870303949341178), (32, 0.08754368592053652), (28, 0.08932762406766415), (24, 0.0896440977230668), (30, 0.09019674267619848), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (12, 0.13114257901906967), (40, 0.1321136374026537), (38, 0.13228105194866657), (39, 0.13234517723321915), (5, 0.13275575079023838), (37, 0.13573279790580273), (42, 0.14353954792022705), (41, 0.14424476958811283), (6, 0.14824785850942135), (43, 0.14830573461949825), (44, 0.15209932439029217), (4, 0.15593685768544674), (45, 0.15876222774386406), (13, 0.15930364280939102), (3, 0.16737028025090694), (46, 0.17895806394517422), (2, 0.1852165162563324), (47, 0.19873304851353168), (48, 0.19925069622695446), (1, 0.20217271894216537), (49, 0.22048714384436607), (50, 0.22935869172215462), (51, 0.25387275218963623), (52, 0.27310289815068245), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.448278084397316), (53, 0.6536013558506966)]
computing accuracy for after removing block 34 . block score: 0.08360460959374905
removed block 34 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.087030. All blocks and scores: [(23, 0.0870303949341178), (32, 0.08754368592053652), (28, 0.08932762406766415), (24, 0.0896440977230668), (30, 0.09019674267619848), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (38, 0.12905248627066612), (12, 0.13114257901906967), (40, 0.1312630958855152), (5, 0.13275575079023838), (39, 0.13344780169427395), (37, 0.13498979806900024), (42, 0.14519238285720348), (41, 0.1463438682258129), (43, 0.1465726364403963), (6, 0.14824785850942135), (44, 0.1503445729613304), (4, 0.15593685768544674), (45, 0.1566198691725731), (13, 0.15930364280939102), (3, 0.16737028025090694), (46, 0.17754656076431274), (2, 0.1852165162563324), (48, 0.1970694176852703), (47, 0.19778208620846272), (1, 0.20217271894216537), (49, 0.22166811302304268), (50, 0.22783334739506245), (51, 0.25385870784521103), (52, 0.27193256095051765), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.45681920275092125), (53, 0.658540241420269)]
computing accuracy for after removing block 23 . block score: 0.0870303949341178
removed block 23 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.086150. All blocks and scores: [(32, 0.08615011628717184), (24, 0.08802061155438423), (28, 0.08806934300810099), (30, 0.08869867958128452), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (10, 0.12519253883510828), (38, 0.12796906754374504), (12, 0.13114257901906967), (40, 0.1322193555533886), (5, 0.13275575079023838), (37, 0.13483159989118576), (39, 0.1360323540866375), (42, 0.14412125572562218), (43, 0.14512982033193111), (41, 0.1466435268521309), (6, 0.14824785850942135), (44, 0.1488097570836544), (45, 0.15487084537744522), (4, 0.15593685768544674), (13, 0.15930364280939102), (3, 0.16737028025090694), (46, 0.17751352861523628), (2, 0.1852165162563324), (48, 0.19574805162847042), (47, 0.19714772887527943), (1, 0.20217271894216537), (49, 0.2213040105998516), (50, 0.2262321412563324), (51, 0.25422417744994164), (52, 0.2710384614765644), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.4589156322181225), (53, 0.6593538522720337)]
computing accuracy for after removing block 32 . block score: 0.08615011628717184
removed block 32 current accuracy 0.9866 loss from initial  0.013399999999999967
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.088021. All blocks and scores: [(24, 0.08802061155438423), (28, 0.08806934300810099), (30, 0.08869867958128452), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (38, 0.12284307647496462), (10, 0.12519253883510828), (12, 0.13114257901906967), (40, 0.1317853480577469), (5, 0.13275575079023838), (37, 0.13302095048129559), (39, 0.13561012223362923), (43, 0.14145826175808907), (42, 0.14177506044507027), (41, 0.14379572309553623), (44, 0.14518971741199493), (6, 0.14824785850942135), (45, 0.15188510157167912), (4, 0.15593685768544674), (13, 0.15930364280939102), (3, 0.16737028025090694), (46, 0.17613127827644348), (2, 0.1852165162563324), (48, 0.19180706329643726), (47, 0.1954517513513565), (1, 0.20217271894216537), (49, 0.2205513957887888), (50, 0.22321446985006332), (51, 0.25295209512114525), (52, 0.2661513276398182), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.4651454836130142), (53, 0.6674913018941879)]
computing accuracy for after removing block 24 . block score: 0.08802061155438423
removed block 24 current accuracy 0.975 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 30, with score 0.086239. All blocks and scores: [(30, 0.08623907435685396), (28, 0.08679940272122622), (14, 0.09267917554825544), (22, 0.0941077433526516), (9, 0.0975249083712697), (11, 0.10097307991236448), (19, 0.10222529713064432), (8, 0.10675953980535269), (15, 0.11598389036953449), (7, 0.11706889513880014), (38, 0.12013284303247929), (10, 0.12519253883510828), (12, 0.13114257901906967), (40, 0.13254520669579506), (37, 0.13272394612431526), (5, 0.13275575079023838), (39, 0.1384722013026476), (42, 0.1417259145528078), (43, 0.14180075377225876), (41, 0.14318776316940784), (44, 0.14507567510008812), (6, 0.14824785850942135), (45, 0.15169658698141575), (4, 0.15593685768544674), (13, 0.15930364280939102), (3, 0.16737028025090694), (46, 0.17626694776117802), (2, 0.1852165162563324), (48, 0.19033959694206715), (47, 0.19463139027357101), (1, 0.20217271894216537), (49, 0.22052680514752865), (50, 0.22159940376877785), (51, 0.2526102773845196), (52, 0.2642183154821396), (0, 0.3153342045843601), (18, 0.4327620044350624), (36, 0.47077134251594543), (53, 0.6680980995297432)]
computing accuracy for after removing block 30 . block score: 0.08623907435685396
removed block 30 current accuracy 0.9498 loss from initial  0.05020000000000002
training start
training epoch 0 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 1 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best True lr [0.001]
training epoch 2 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best True lr [0.001]
training epoch 3 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 4 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 5 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 6 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 8 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 9 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 10 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 11 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 12 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 13 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 15 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 16 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 17 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 18 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 19 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 20 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 21 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 24 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 25 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 26 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 27 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 28 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 29 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 32 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 33 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 34 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 35 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 36 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 37 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 39 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 40 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 45 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 46 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 47 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 48 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 49 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.999200)
finished training. finished 50 epochs. accuracy 0.9992 topk_dict {'top1': 0.9992}
start iteration 16
[activation mean]: block to remove picked: 14, with score 0.095493. All blocks and scores: [(14, 0.09549306333065033), (9, 0.09719005692750216), (11, 0.10320014879107475), (8, 0.10459507908672094), (7, 0.11540769040584564), (19, 0.11667256336659193), (22, 0.11750063579529524), (28, 0.12218614295125008), (15, 0.12301205564290285), (10, 0.12499984912574291), (12, 0.12915935553610325), (5, 0.1294630616903305), (40, 0.1347295083105564), (39, 0.1355291735380888), (37, 0.13998882099986076), (38, 0.1400070209056139), (41, 0.14473587088286877), (6, 0.1474217902868986), (42, 0.1487265732139349), (43, 0.15197175554931164), (44, 0.15474927611649036), (4, 0.15504859574139118), (13, 0.16311146691441536), (3, 0.16448661498725414), (45, 0.16467914916574955), (2, 0.18014540150761604), (46, 0.18123386055231094), (1, 0.1956859454512596), (47, 0.20274930074810982), (48, 0.20726302824914455), (49, 0.22150450944900513), (50, 0.23714447394013405), (51, 0.2580860070884228), (52, 0.2831229902803898), (0, 0.30554524809122086), (18, 0.4170997887849808), (36, 0.4468575455248356), (53, 0.6454974710941315)]
computing accuracy for after removing block 14 . block score: 0.09549306333065033
removed block 14 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 9, with score 0.097190. All blocks and scores: [(9, 0.09719005692750216), (11, 0.10320014879107475), (8, 0.10459507908672094), (19, 0.11319770943373442), (7, 0.11540769040584564), (22, 0.11697807814925909), (28, 0.1222158307209611), (10, 0.12499984912574291), (15, 0.12778293155133724), (12, 0.12915935553610325), (5, 0.1294630616903305), (38, 0.1377585083246231), (40, 0.13811388611793518), (39, 0.13842124864459038), (37, 0.14015879482030869), (41, 0.146083015948534), (6, 0.1474217902868986), (42, 0.1485135443508625), (43, 0.15055007487535477), (4, 0.15504859574139118), (44, 0.1557407919317484), (13, 0.16311146691441536), (45, 0.16379341296851635), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.1825913619250059), (1, 0.1956859454512596), (47, 0.2006513550877571), (48, 0.20428624749183655), (49, 0.22227722592651844), (50, 0.23454352654516697), (51, 0.2563835382461548), (52, 0.280586302280426), (0, 0.30554524809122086), (18, 0.4242277443408966), (36, 0.45199767500162125), (53, 0.6394537165760994)]
computing accuracy for after removing block 9 . block score: 0.09719005692750216
removed block 9 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.103447. All blocks and scores: [(11, 0.1034468337893486), (8, 0.10459507908672094), (19, 0.1128905713558197), (22, 0.1153718912974), (7, 0.11540769040584564), (28, 0.11868164222687483), (10, 0.12151200417429209), (15, 0.12480962928384542), (12, 0.12610594183206558), (5, 0.1294630616903305), (39, 0.13375379890203476), (40, 0.13530724681913853), (38, 0.13562989607453346), (37, 0.13717386685311794), (42, 0.14657171070575714), (41, 0.14707638695836067), (6, 0.1474217902868986), (43, 0.14807530865073204), (44, 0.1545373536646366), (13, 0.1550433188676834), (4, 0.15504859574139118), (45, 0.16230595856904984), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18141697347164154), (1, 0.1956859454512596), (47, 0.19660196267068386), (48, 0.20141984336078167), (49, 0.2207178007811308), (50, 0.23322074674069881), (51, 0.25452885031700134), (52, 0.27823659777641296), (0, 0.30554524809122086), (18, 0.41820257529616356), (36, 0.44813909754157066), (53, 0.6385991051793098)]
computing accuracy for after removing block 11 . block score: 0.1034468337893486
removed block 11 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 8, with score 0.104595. All blocks and scores: [(8, 0.10459507908672094), (19, 0.11185306776314974), (22, 0.11425833962857723), (7, 0.11540769040584564), (28, 0.11748437117785215), (10, 0.12151200417429209), (15, 0.12464336026459932), (12, 0.1256330981850624), (5, 0.1294630616903305), (39, 0.1308446954935789), (38, 0.13345964439213276), (40, 0.1340159121900797), (37, 0.1355483066290617), (42, 0.14531531743705273), (43, 0.14636792615056038), (41, 0.14691081829369068), (6, 0.1474217902868986), (13, 0.15394959412515163), (44, 0.15461871027946472), (4, 0.15504859574139118), (45, 0.1625095121562481), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18138642609119415), (47, 0.19417472183704376), (1, 0.1956859454512596), (48, 0.1979814860969782), (49, 0.22006851062178612), (50, 0.2312190979719162), (51, 0.25297366827726364), (52, 0.27567655220627785), (0, 0.30554524809122086), (18, 0.4150000214576721), (36, 0.44724972546100616), (53, 0.6337252035737038)]
computing accuracy for after removing block 8 . block score: 0.10459507908672094
removed block 8 current accuracy 0.9898 loss from initial  0.010199999999999987
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 19, with score 0.112005. All blocks and scores: [(19, 0.11200469452887774), (22, 0.11462161876261234), (28, 0.1152117969468236), (7, 0.11540769040584564), (10, 0.12391270883381367), (15, 0.12485689856112003), (12, 0.12759331986308098), (39, 0.12888437509536743), (5, 0.1294630616903305), (40, 0.13200331293046474), (37, 0.13429123349487782), (38, 0.13606026954948902), (42, 0.14218974858522415), (41, 0.14613974653184414), (43, 0.14679350890219212), (6, 0.1474217902868986), (44, 0.15224606730043888), (4, 0.15504859574139118), (13, 0.15700306557118893), (45, 0.16018029674887657), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18094881251454353), (47, 0.1940664630383253), (1, 0.1956859454512596), (48, 0.19579450972378254), (49, 0.2190449796617031), (50, 0.22868428379297256), (51, 0.25077835097908974), (52, 0.27307357266545296), (0, 0.30554524809122086), (18, 0.41491369158029556), (36, 0.44537269324064255), (53, 0.6314262077212334)]
computing accuracy for after removing block 19 . block score: 0.11200469452887774
removed block 19 current accuracy 0.9824 loss from initial  0.01759999999999995
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 28, with score 0.114313. All blocks and scores: [(28, 0.11431298404932022), (22, 0.11439454648643732), (7, 0.11540769040584564), (10, 0.12391270883381367), (15, 0.12485689856112003), (12, 0.12759331986308098), (39, 0.12848855927586555), (5, 0.1294630616903305), (37, 0.13511432148516178), (40, 0.13617690280079842), (38, 0.1361982338130474), (42, 0.14404070377349854), (41, 0.1464733872562647), (6, 0.1474217902868986), (43, 0.1484953984618187), (44, 0.15266426093876362), (4, 0.15504859574139118), (13, 0.15700306557118893), (45, 0.16272814571857452), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18299799412488937), (47, 0.19381937570869923), (48, 0.19538952596485615), (1, 0.1956859454512596), (49, 0.21897097490727901), (50, 0.22700475342571735), (51, 0.24951373599469662), (52, 0.27111009880900383), (0, 0.30554524809122086), (18, 0.41491369158029556), (36, 0.4551660977303982), (53, 0.6272870004177094)]
computing accuracy for after removing block 28 . block score: 0.11431298404932022
removed block 28 current accuracy 0.9518 loss from initial  0.04820000000000002
since last training loss: 0.0474 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 22, with score 0.114395. All blocks and scores: [(22, 0.11439454648643732), (7, 0.11540769040584564), (10, 0.12391270883381367), (15, 0.12485689856112003), (38, 0.1274445280432701), (12, 0.12759331986308098), (5, 0.1294630616903305), (37, 0.13322685845196247), (39, 0.1341751478612423), (40, 0.14078889042139053), (42, 0.14105714857578278), (41, 0.14479154720902443), (43, 0.1458410583436489), (6, 0.1474217902868986), (44, 0.14838640205562115), (4, 0.15504859574139118), (13, 0.15700306557118893), (45, 0.16153421066701412), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18347107991576195), (48, 0.19049749337136745), (47, 0.19148599170148373), (1, 0.1956859454512596), (49, 0.21728072501718998), (50, 0.22326683066785336), (51, 0.24944786168634892), (52, 0.2650683596730232), (0, 0.30554524809122086), (18, 0.41491369158029556), (36, 0.47032156586647034), (53, 0.6365272253751755)]
computing accuracy for after removing block 22 . block score: 0.11439454648643732
removed block 22 current accuracy 0.9096 loss from initial  0.09040000000000004
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 7, with score 0.115408. All blocks and scores: [(7, 0.11540769040584564), (10, 0.12391270883381367), (15, 0.12485689856112003), (38, 0.12640731781721115), (12, 0.12759331986308098), (5, 0.1294630616903305), (37, 0.1328762210905552), (42, 0.13902282528579235), (39, 0.1407481450587511), (43, 0.14257348328828812), (44, 0.14460701309144497), (41, 0.14684468135237694), (6, 0.1474217902868986), (40, 0.14808321185410023), (4, 0.15504859574139118), (13, 0.15700306557118893), (45, 0.15868031419813633), (3, 0.16448661498725414), (2, 0.18014540150761604), (46, 0.18408011831343174), (48, 0.19030494056642056), (47, 0.19068366661667824), (1, 0.1956859454512596), (49, 0.21749783121049404), (50, 0.21882006525993347), (51, 0.24858400039374828), (52, 0.25916703417897224), (0, 0.30554524809122086), (18, 0.41491369158029556), (36, 0.48536594584584236), (53, 0.64525156468153)]
computing accuracy for after removing block 7 . block score: 0.11540769040584564
removed block 7 current accuracy 0.8844 loss from initial  0.11560000000000004
training start
training epoch 0 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 1 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 2 val accuracy 0.991 topk_dict {'top1': 0.991} is_best True lr [0.001]
training epoch 3 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 4 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best True lr [0.001]
training epoch 5 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 6 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 7 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 8 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 9 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 10 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 11 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 12 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 13 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 14 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 15 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 16 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 17 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 18 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 19 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 20 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 21 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 22 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 23 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 24 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 25 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 26 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 27 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 28 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 30 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 32 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 33 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 34 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 35 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 36 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 37 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 38 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 39 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 40 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 41 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 42 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 43 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 44 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 45 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 47 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 48 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 49 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.995200)
finished training. finished 50 epochs. accuracy 0.9952 topk_dict {'top1': 0.9952}
start iteration 24
[activation mean]: block to remove picked: 15, with score 0.134975. All blocks and scores: [(15, 0.13497485034167767), (40, 0.1359157171100378), (39, 0.1361615527421236), (10, 0.13657032698392868), (5, 0.13837366923689842), (12, 0.14146809466183186), (37, 0.14165951125323772), (38, 0.1424890160560608), (41, 0.14608094654977322), (42, 0.14888883009552956), (43, 0.15184933133423328), (44, 0.15374116599559784), (6, 0.15764653496444225), (4, 0.1624430101364851), (3, 0.16385582834482193), (45, 0.16452495194971561), (2, 0.1749200727790594), (13, 0.17806287854909897), (46, 0.1784828919917345), (1, 0.18925721943378448), (47, 0.20258749835193157), (48, 0.20595064759254456), (49, 0.22034048289060593), (50, 0.23508797772228718), (51, 0.25682445988059044), (52, 0.2800593376159668), (0, 0.29069704189896584), (18, 0.41908857598900795), (36, 0.44689567759633064), (53, 0.6541912406682968)]
computing accuracy for after removing block 15 . block score: 0.13497485034167767
removed block 15 current accuracy 0.9876 loss from initial  0.012399999999999967
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.135451. All blocks and scores: [(37, 0.13545081205666065), (10, 0.13657032698392868), (39, 0.1371285282075405), (5, 0.13837366923689842), (40, 0.13897182792425156), (38, 0.13934258371591568), (12, 0.14146809466183186), (42, 0.14479007199406624), (41, 0.1459731850773096), (43, 0.14928359910845757), (44, 0.15203413739800453), (6, 0.15764653496444225), (45, 0.15903353318572044), (4, 0.1624430101364851), (3, 0.16385582834482193), (2, 0.1749200727790594), (13, 0.17806287854909897), (46, 0.1787789762020111), (1, 0.18925721943378448), (47, 0.19664574973285198), (48, 0.2015045192092657), (49, 0.22025504149496555), (50, 0.22972614876925945), (51, 0.252439234405756), (52, 0.27403975278139114), (0, 0.29069704189896584), (18, 0.4244713746011257), (36, 0.44792839512228966), (53, 0.6485960930585861)]
computing accuracy for after removing block 37 . block score: 0.13545081205666065
removed block 37 current accuracy 0.981 loss from initial  0.019000000000000017
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.136488. All blocks and scores: [(40, 0.13648778572678566), (10, 0.13657032698392868), (5, 0.13837366923689842), (39, 0.13872461393475533), (12, 0.14146809466183186), (41, 0.14277675934135914), (42, 0.1433920245617628), (38, 0.14387988299131393), (43, 0.1464989371597767), (44, 0.14751853980123997), (45, 0.15483788587152958), (6, 0.15764653496444225), (4, 0.1624430101364851), (3, 0.16385582834482193), (2, 0.1749200727790594), (46, 0.17613357119262218), (13, 0.17806287854909897), (1, 0.18925721943378448), (47, 0.19199181161820889), (48, 0.1960093080997467), (49, 0.21580354496836662), (50, 0.2250418495386839), (51, 0.24740266799926758), (52, 0.2674047723412514), (0, 0.29069704189896584), (18, 0.4244713746011257), (36, 0.44792839512228966), (53, 0.6597678661346436)]
computing accuracy for after removing block 40 . block score: 0.13648778572678566
removed block 40 current accuracy 0.9718 loss from initial  0.028200000000000003
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 10, with score 0.136570. All blocks and scores: [(10, 0.13657032698392868), (5, 0.13837366923689842), (39, 0.13872461393475533), (12, 0.14146809466183186), (38, 0.14387988299131393), (42, 0.1453704684972763), (41, 0.14554505050182343), (43, 0.14659463614225388), (44, 0.14854433946311474), (45, 0.15522016771137714), (6, 0.15764653496444225), (4, 0.1624430101364851), (3, 0.16385582834482193), (2, 0.1749200727790594), (46, 0.17647549882531166), (13, 0.17806287854909897), (1, 0.18925721943378448), (47, 0.190407020971179), (48, 0.19451613537967205), (49, 0.21523150242865086), (50, 0.22517928294837475), (51, 0.24776924587786198), (52, 0.26591669023036957), (0, 0.29069704189896584), (18, 0.4244713746011257), (36, 0.44792839512228966), (53, 0.6693830341100693)]
computing accuracy for after removing block 10 . block score: 0.13657032698392868
removed block 10 current accuracy 0.9392 loss from initial  0.060799999999999965
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.132455. All blocks and scores: [(39, 0.13245528936386108), (5, 0.13837366923689842), (41, 0.13968113623559475), (42, 0.1406420525163412), (38, 0.14682239666581154), (44, 0.1479816995561123), (43, 0.14918901398777962), (12, 0.1494512651115656), (45, 0.15487444028258324), (6, 0.15764653496444225), (4, 0.1624430101364851), (3, 0.16385582834482193), (2, 0.1749200727790594), (46, 0.1806462686508894), (47, 0.18773960135877132), (1, 0.18925721943378448), (13, 0.1900259256362915), (48, 0.1922441814094782), (49, 0.21591927856206894), (50, 0.2239014320075512), (51, 0.24341470189392567), (52, 0.26114344969391823), (0, 0.29069704189896584), (18, 0.4237554706633091), (36, 0.44583333283662796), (53, 0.6619928404688835)]
computing accuracy for after removing block 39 . block score: 0.13245528936386108
removed block 39 current accuracy 0.922 loss from initial  0.07799999999999996
since last training loss: 0.07319999999999993 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 5, with score 0.138374. All blocks and scores: [(5, 0.13837366923689842), (41, 0.14066158048808575), (42, 0.14430874399840832), (38, 0.14682239666581154), (44, 0.1479463018476963), (43, 0.14929474890232086), (12, 0.1494512651115656), (45, 0.15471829660236835), (6, 0.15764653496444225), (4, 0.1624430101364851), (3, 0.16385582834482193), (2, 0.1749200727790594), (46, 0.18200016766786575), (47, 0.18612118624150753), (1, 0.18925721943378448), (13, 0.1900259256362915), (48, 0.19028399139642715), (49, 0.21628556959331036), (50, 0.22311696037650108), (51, 0.24177567102015018), (52, 0.2598063051700592), (0, 0.29069704189896584), (18, 0.4237554706633091), (36, 0.44583333283662796), (53, 0.6659249514341354)]
computing accuracy for after removing block 5 . block score: 0.13837366923689842
removed block 5 current accuracy 0.8512 loss from initial  0.14880000000000004
since last training loss: 0.14400000000000002 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 41, with score 0.128091. All blocks and scores: [(41, 0.12809132225811481), (42, 0.13634005934000015), (43, 0.1450214758515358), (44, 0.14541631191968918), (38, 0.15090245567262173), (45, 0.15282614342868328), (12, 0.15433663874864578), (4, 0.1624430101364851), (3, 0.16385582834482193), (6, 0.16410664841532707), (2, 0.1749200727790594), (47, 0.18472718074917793), (46, 0.18542825803160667), (48, 0.18855922855436802), (1, 0.18925721943378448), (13, 0.18948727659881115), (49, 0.21628817729651928), (50, 0.22394796274602413), (51, 0.2384360432624817), (52, 0.2507543209940195), (0, 0.29069704189896584), (18, 0.4221637658774853), (36, 0.4533468186855316), (53, 0.6622139438986778)]
computing accuracy for after removing block 41 . block score: 0.12809132225811481
removed block 41 current accuracy 0.8246 loss from initial  0.1754
since last training loss: 0.17059999999999997 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 42, with score 0.142488. All blocks and scores: [(42, 0.14248809590935707), (43, 0.14565237425267696), (44, 0.14830486103892326), (38, 0.15090245567262173), (45, 0.15420405194163322), (12, 0.15433663874864578), (4, 0.1624430101364851), (3, 0.16385582834482193), (6, 0.16410664841532707), (2, 0.1749200727790594), (47, 0.18301552906632423), (46, 0.18354580365121365), (48, 0.185862697660923), (1, 0.18925721943378448), (13, 0.18948727659881115), (49, 0.21580025181174278), (50, 0.2229615729302168), (51, 0.23641585372388363), (52, 0.2466742042452097), (0, 0.29069704189896584), (18, 0.4221637658774853), (36, 0.4533468186855316), (53, 0.6737317964434624)]
computing accuracy for after removing block 42 . block score: 0.14248809590935707
removed block 42 current accuracy 0.8016 loss from initial  0.19840000000000002
since last training loss: 0.1936 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 43, with score 0.150226. All blocks and scores: [(43, 0.15022613108158112), (38, 0.15090245567262173), (44, 0.15123368427157402), (12, 0.15433663874864578), (45, 0.15523775294423103), (4, 0.1624430101364851), (3, 0.16385582834482193), (6, 0.16410664841532707), (2, 0.1749200727790594), (47, 0.1825832463800907), (46, 0.1836701612919569), (48, 0.18639411218464375), (1, 0.18925721943378448), (13, 0.18948727659881115), (49, 0.2159031219780445), (50, 0.2222917452454567), (51, 0.23307473212480545), (52, 0.24132496118545532), (0, 0.29069704189896584), (18, 0.4221637658774853), (36, 0.4533468186855316), (53, 0.6955601200461388)]
computing accuracy for after removing block 43 . block score: 0.15022613108158112
removed block 43 current accuracy 0.7402 loss from initial  0.25980000000000003
training start
training epoch 0 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.001]
training epoch 1 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best True lr [0.001]
training epoch 2 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best True lr [0.001]
training epoch 3 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.001]
training epoch 4 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best True lr [0.001]
training epoch 5 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best True lr [0.001]
training epoch 6 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 7 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 8 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 9 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 10 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 11 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 12 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 13 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 14 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best True lr [0.001]
training epoch 15 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 16 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 17 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 18 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best True lr [0.001]
training epoch 19 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 20 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 21 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 22 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 23 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best True lr [0.001]
training epoch 24 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 25 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 26 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 27 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 28 val accuracy 0.984 topk_dict {'top1': 0.984} is_best True lr [0.001]
training epoch 29 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 30 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 31 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 32 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 33 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best True lr [0.001]
training epoch 34 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 35 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 36 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 37 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 38 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 39 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 40 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 41 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best False lr [0.001]
training epoch 42 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best False lr [0.001]
training epoch 43 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 44 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 45 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 46 val accuracy 0.984 topk_dict {'top1': 0.984} is_best False lr [0.001]
training epoch 47 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 48 val accuracy 0.9842 topk_dict {'top1': 0.9842} is_best False lr [0.001]
training epoch 49 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.985600)
finished training. finished 50 epochs. accuracy 0.9856 topk_dict {'top1': 0.9856}
