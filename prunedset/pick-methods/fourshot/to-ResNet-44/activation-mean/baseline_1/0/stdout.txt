start iteration 0
[activation mean]: block to remove picked: 35, with score 0.068065. All blocks and scores: [(35, 0.06806544493883848), (34, 0.07155500166118145), (29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (40, 0.1485865917056799), (42, 0.14862949401140213), (39, 0.1502137091010809), (43, 0.15118332393467426), (16, 0.1542689297348261), (44, 0.1568443477153778), (41, 0.15819761157035828), (8, 0.1629196796566248), (38, 0.16311836056411266), (45, 0.16416819021105766), (7, 0.1642463244497776), (37, 0.1721880678087473), (46, 0.17476965300738811), (47, 0.17773926071822643), (0, 0.18282040394842625), (48, 0.18591997772455215), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.20708752237260342), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2280910387635231), (51, 0.26267513632774353), (52, 0.30729563161730766), (1, 0.3230183348059654), (36, 0.4830818697810173), (18, 0.48591700568795204), (53, 0.6321986317634583)]
computing accuracy for after removing block 35 . block score: 0.06806544493883848
removed block 35 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071555. All blocks and scores: [(34, 0.07155500166118145), (29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1475937645882368), (40, 0.14824344776570797), (39, 0.14968669041991234), (43, 0.15022495575249195), (16, 0.1542689297348261), (44, 0.15705609321594238), (41, 0.1583851631730795), (38, 0.16271816939115524), (8, 0.1629196796566248), (45, 0.16294064186513424), (7, 0.1642463244497776), (37, 0.17224120907485485), (46, 0.17422440648078918), (47, 0.17651107348501682), (0, 0.18282040394842625), (48, 0.18564523942768574), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.20694553293287754), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22779344767332077), (51, 0.2625165581703186), (52, 0.3068947494029999), (1, 0.3230183348059654), (36, 0.484864454716444), (18, 0.48591700568795204), (53, 0.6351279094815254)]
computing accuracy for after removing block 34 . block score: 0.07155500166118145
removed block 34 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074390. All blocks and scores: [(29, 0.07439009193331003), (27, 0.07475671451538801), (32, 0.07725425530225039), (31, 0.08129832707345486), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.09434029646217823), (33, 0.09519470483064651), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.14523832313716412), (40, 0.14652326703071594), (43, 0.14793959073722363), (39, 0.14857716858386993), (16, 0.1542689297348261), (44, 0.15653456933796406), (41, 0.15711732022464275), (38, 0.1611128505319357), (45, 0.1615363098680973), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.1709775011986494), (46, 0.17292680777609348), (47, 0.17471239902079105), (0, 0.18282040394842625), (48, 0.1851693782955408), (4, 0.1881055347621441), (5, 0.1926018800586462), (3, 0.2022159229964018), (49, 0.2042350433766842), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2266900520771742), (51, 0.2621644251048565), (52, 0.3062927797436714), (1, 0.3230183348059654), (36, 0.48343389481306076), (18, 0.48591700568795204), (53, 0.6365829855203629)]
computing accuracy for after removing block 29 . block score: 0.07439009193331003
removed block 29 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074757. All blocks and scores: [(27, 0.07475671451538801), (32, 0.07766200136393309), (31, 0.08081165514886379), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08459396101534367), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (33, 0.09446824062615633), (30, 0.09540940541774035), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1416273321956396), (40, 0.14506280422210693), (43, 0.14668023772537708), (39, 0.14681650139391422), (16, 0.1542689297348261), (44, 0.15490625984966755), (41, 0.15599514544010162), (45, 0.15919861383736134), (38, 0.16000054217875004), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.16922264359891415), (46, 0.16999387182295322), (47, 0.1726976167410612), (0, 0.18282040394842625), (48, 0.18339907936751842), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.20185521431267262), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2245034370571375), (51, 0.2610628716647625), (52, 0.3041844554245472), (1, 0.3230183348059654), (36, 0.48202379792928696), (18, 0.48591700568795204), (53, 0.6394148096442223)]
computing accuracy for after removing block 27 . block score: 0.07475671451538801
removed block 27 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.077250. All blocks and scores: [(32, 0.07724968623369932), (31, 0.08117342926561832), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08469565119594336), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (33, 0.09415383636951447), (30, 0.0952159846201539), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.14108119904994965), (40, 0.143192321062088), (43, 0.14595255255699158), (39, 0.14667929895222187), (44, 0.1532077770680189), (16, 0.1542689297348261), (41, 0.15477589331567287), (45, 0.1573938149958849), (38, 0.1598621904850006), (8, 0.1629196796566248), (7, 0.1642463244497776), (46, 0.16795594990253448), (37, 0.16871255822479725), (47, 0.16997651755809784), (48, 0.18075465224683285), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.19900811649858952), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22411376610398293), (51, 0.25980237126350403), (52, 0.3028869405388832), (1, 0.3230183348059654), (36, 0.48296551406383514), (18, 0.48591700568795204), (53, 0.6423995345830917)]
computing accuracy for after removing block 32 . block score: 0.07724968623369932
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081173. All blocks and scores: [(31, 0.08117342926561832), (10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08469565119594336), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (30, 0.0952159846201539), (33, 0.09552602842450142), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.1386425532400608), (40, 0.14054096303880215), (43, 0.1436892468482256), (39, 0.14488192275166512), (44, 0.15123293921351433), (41, 0.15253233164548874), (16, 0.1542689297348261), (45, 0.15517016500234604), (38, 0.15800295397639275), (8, 0.1629196796566248), (7, 0.1642463244497776), (37, 0.16566774062812328), (46, 0.16586396656930447), (47, 0.16746729612350464), (48, 0.1787626538425684), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.196839589625597), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.22219744883477688), (51, 0.257920503616333), (52, 0.3000909201800823), (1, 0.3230183348059654), (36, 0.48227667063474655), (18, 0.48591700568795204), (53, 0.6499040573835373)]
computing accuracy for after removing block 31 . block score: 0.08117342926561832
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 10, with score 0.081738. All blocks and scores: [(10, 0.08173766639083624), (21, 0.08243566565215588), (28, 0.08469565119594336), (13, 0.0886031249538064), (20, 0.09087823238223791), (17, 0.09236926585435867), (33, 0.09484413638710976), (30, 0.0952159846201539), (11, 0.0962625090032816), (9, 0.09772502537816763), (19, 0.09932698123157024), (24, 0.09942088276147842), (26, 0.10109961871057749), (25, 0.10171097982674837), (22, 0.1066881213337183), (14, 0.10815877374261618), (23, 0.10932782664895058), (12, 0.12481921259313822), (15, 0.13144206441938877), (42, 0.13630245625972748), (40, 0.13867876678705215), (43, 0.14093333669006824), (39, 0.14392022229731083), (44, 0.14989694394171238), (41, 0.15127837844192982), (45, 0.15312709659337997), (16, 0.1542689297348261), (38, 0.1565265078097582), (8, 0.1629196796566248), (7, 0.1642463244497776), (46, 0.16445603966712952), (37, 0.16476422920823097), (47, 0.16484363563358784), (48, 0.17756331898272038), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.19400625117123127), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.2207824159413576), (51, 0.2570772208273411), (52, 0.2992568165063858), (1, 0.3230183348059654), (36, 0.48256659135222435), (18, 0.48591700568795204), (53, 0.6530735120177269)]
computing accuracy for after removing block 10 . block score: 0.08173766639083624
removed block 10 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.081933. All blocks and scores: [(21, 0.08193257916718721), (28, 0.08475734200328588), (13, 0.08709158841520548), (20, 0.0909402770921588), (17, 0.09336956217885017), (33, 0.09543961193412542), (30, 0.09559811931103468), (9, 0.09772502537816763), (11, 0.09777635708451271), (24, 0.09943387471139431), (26, 0.10036311950534582), (25, 0.10171940363943577), (19, 0.10231029242277145), (22, 0.10646007303148508), (14, 0.10742118954658508), (23, 0.10943255852907896), (12, 0.11981025990098715), (15, 0.13125771284103394), (42, 0.1360226608812809), (40, 0.13804779388010502), (43, 0.140584172680974), (39, 0.14269376173615456), (44, 0.14864312671124935), (41, 0.15108839236199856), (45, 0.1519846897572279), (16, 0.1545173116028309), (38, 0.15683350339531898), (37, 0.16218410432338715), (8, 0.1629196796566248), (46, 0.16346561908721924), (7, 0.1642463244497776), (47, 0.1643897220492363), (48, 0.17506196536123753), (0, 0.18282040394842625), (4, 0.1881055347621441), (5, 0.1926018800586462), (49, 0.19465015642344952), (3, 0.2022159229964018), (2, 0.2100837603211403), (6, 0.2142431139945984), (50, 0.21908039413392544), (51, 0.2557343803346157), (52, 0.2978627681732178), (1, 0.3230183348059654), (36, 0.47845737263560295), (18, 0.4844735600054264), (53, 0.6531623303890228)]
computing accuracy for after removing block 21 . block score: 0.08193257916718721
removed block 21 current accuracy 0.9984 loss from initial  0.0016000000000000458
training start
training epoch 0 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 1 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 2 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 3 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 4 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 5 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 6 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 0 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.083888. All blocks and scores: [(28, 0.08388750720769167), (13, 0.08891334105283022), (20, 0.08980447147041559), (17, 0.092405098490417), (30, 0.09403115790337324), (11, 0.09484932199120522), (33, 0.09711522795259953), (9, 0.09801567811518908), (24, 0.09859417844563723), (19, 0.09884873125702143), (26, 0.10026130080223083), (25, 0.10101108904927969), (14, 0.10616237577050924), (22, 0.10688750259578228), (23, 0.10804720129817724), (12, 0.12168859131634235), (15, 0.12957154028117657), (16, 0.14479452930390835), (40, 0.14638852514326572), (42, 0.1469548251479864), (39, 0.14704365469515324), (43, 0.1488233581185341), (44, 0.15590191259980202), (41, 0.1571645587682724), (38, 0.15923197008669376), (8, 0.16233665123581886), (7, 0.1635928750038147), (45, 0.16425413638353348), (37, 0.17083784379065037), (46, 0.1741675455123186), (47, 0.1771704237908125), (0, 0.18133865110576153), (48, 0.1863591130822897), (4, 0.18756148591637611), (5, 0.19261321425437927), (3, 0.20051711611449718), (49, 0.20759556256234646), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.22773218341171741), (51, 0.26316969841718674), (52, 0.3118971809744835), (1, 0.3198661059141159), (36, 0.4743250012397766), (18, 0.48100196570158005), (53, 0.6238704696297646)]
computing accuracy for after removing block 28 . block score: 0.08388750720769167
removed block 28 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.088913. All blocks and scores: [(13, 0.08891334105283022), (20, 0.08980447147041559), (17, 0.092405098490417), (30, 0.09407636150717735), (11, 0.09484932199120522), (33, 0.09649218525737524), (9, 0.09801567811518908), (24, 0.09859417844563723), (19, 0.09884873125702143), (26, 0.10026130080223083), (25, 0.10101108904927969), (14, 0.10616237577050924), (22, 0.10688750259578228), (23, 0.10804720129817724), (12, 0.12168859131634235), (15, 0.12957154028117657), (42, 0.14277020655572414), (40, 0.1433559264987707), (39, 0.14366213977336884), (16, 0.14479452930390835), (43, 0.1464045625180006), (44, 0.1536447685211897), (41, 0.15541224740445614), (38, 0.1564712282270193), (45, 0.16073394753038883), (8, 0.16233665123581886), (7, 0.1635928750038147), (37, 0.16778373904526234), (46, 0.16967775486409664), (47, 0.17313043028116226), (0, 0.18133865110576153), (48, 0.18341145664453506), (4, 0.18756148591637611), (5, 0.19261321425437927), (3, 0.20051711611449718), (49, 0.20368529483675957), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.22473533265292645), (51, 0.26109954714775085), (52, 0.3090662732720375), (1, 0.3198661059141159), (36, 0.47240179404616356), (18, 0.48100196570158005), (53, 0.6286840587854385)]
computing accuracy for after removing block 13 . block score: 0.08891334105283022
removed block 13 current accuracy 0.997 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.088784. All blocks and scores: [(20, 0.0887838201597333), (17, 0.09282626118510962), (30, 0.09349735733121634), (11, 0.09484932199120522), (33, 0.09640166629105806), (24, 0.09780372586101294), (9, 0.09801567811518908), (19, 0.09913260955363512), (26, 0.09937882982194424), (25, 0.09963816124945879), (22, 0.1066178660839796), (23, 0.10665879398584366), (14, 0.10837027337402105), (12, 0.12168859131634235), (15, 0.13208191841840744), (40, 0.14213387481868267), (42, 0.14285728707909584), (39, 0.14495069347321987), (43, 0.14597484469413757), (16, 0.15027030929923058), (44, 0.1527743935585022), (41, 0.15516068413853645), (38, 0.15690025128424168), (45, 0.1594880111515522), (8, 0.16233665123581886), (7, 0.1635928750038147), (37, 0.165538152679801), (46, 0.16788853146135807), (47, 0.17118433490395546), (0, 0.18133865110576153), (48, 0.18263030610978603), (4, 0.18756148591637611), (5, 0.19261321425437927), (3, 0.20051711611449718), (49, 0.20292559638619423), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.222947983071208), (51, 0.2604319714009762), (52, 0.30964402109384537), (1, 0.3198661059141159), (36, 0.46900372207164764), (18, 0.4839538186788559), (53, 0.6263680905103683)]
computing accuracy for after removing block 20 . block score: 0.0887838201597333
removed block 20 current accuracy 0.9958 loss from initial  0.0041999999999999815
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 30, with score 0.091527. All blocks and scores: [(30, 0.09152734465897083), (17, 0.09282626118510962), (11, 0.09484932199120522), (33, 0.09593701176345348), (24, 0.09691068157553673), (25, 0.09744352288544178), (26, 0.09781915787607431), (9, 0.09801567811518908), (19, 0.09913260955363512), (23, 0.10605229251086712), (22, 0.10660981386899948), (14, 0.10837027337402105), (12, 0.12168859131634235), (15, 0.13208191841840744), (40, 0.13933810591697693), (42, 0.14011118188500404), (43, 0.14308816380798817), (39, 0.14347696118056774), (16, 0.15027030929923058), (44, 0.15180169604718685), (41, 0.15355786867439747), (38, 0.15668031387031078), (45, 0.15674035996198654), (8, 0.16233665123581886), (7, 0.1635928750038147), (37, 0.1657311599701643), (46, 0.16704913787543774), (47, 0.1683513093739748), (48, 0.18116000853478909), (0, 0.18133865110576153), (4, 0.18756148591637611), (5, 0.19261321425437927), (49, 0.2004131469875574), (3, 0.20051711611449718), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.22122068144381046), (51, 0.25908029451966286), (52, 0.3081912435591221), (1, 0.3198661059141159), (36, 0.4698483608663082), (18, 0.4839538186788559), (53, 0.626828707754612)]
computing accuracy for after removing block 30 . block score: 0.09152734465897083
removed block 30 current accuracy 0.9936 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 17, with score 0.092826. All blocks and scores: [(17, 0.09282626118510962), (33, 0.09433030057698488), (11, 0.09484932199120522), (24, 0.09691068157553673), (25, 0.09744352288544178), (26, 0.09781915787607431), (9, 0.09801567811518908), (19, 0.09913260955363512), (23, 0.10605229251086712), (22, 0.10660981386899948), (14, 0.10837027337402105), (12, 0.12168859131634235), (15, 0.13208191841840744), (42, 0.13632126711308956), (40, 0.1367366798222065), (43, 0.14182634837925434), (39, 0.14365367405116558), (44, 0.14948026649653912), (16, 0.15027030929923058), (41, 0.15183942019939423), (45, 0.15426542609930038), (38, 0.15566356666386127), (8, 0.16233665123581886), (7, 0.1635928750038147), (37, 0.1638379506766796), (46, 0.16406230255961418), (47, 0.16499118506908417), (48, 0.17921443469822407), (0, 0.18133865110576153), (4, 0.18756148591637611), (5, 0.19261321425437927), (49, 0.19787300936877728), (3, 0.20051711611449718), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.2198420763015747), (51, 0.25767358765006065), (52, 0.30606329068541527), (1, 0.3198661059141159), (36, 0.4718361459672451), (18, 0.4839538186788559), (53, 0.6333446651697159)]
computing accuracy for after removing block 17 . block score: 0.09282626118510962
removed block 17 current accuracy 0.9902 loss from initial  0.009800000000000031
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 33, with score 0.094383. All blocks and scores: [(33, 0.094382643699646), (11, 0.09484932199120522), (24, 0.09564292058348656), (26, 0.09724833350628614), (25, 0.09729211963713169), (9, 0.09801567811518908), (19, 0.09862752538174391), (23, 0.10386634059250355), (22, 0.10571276396512985), (14, 0.10837027337402105), (12, 0.12168859131634235), (15, 0.13208191841840744), (42, 0.13691034726798534), (40, 0.13733992166817188), (43, 0.1422334536910057), (39, 0.14596198685467243), (44, 0.149449048563838), (16, 0.15027030929923058), (41, 0.15099708922207355), (45, 0.1536520328372717), (38, 0.15653911232948303), (37, 0.1620492897927761), (46, 0.16212123818695545), (8, 0.16233665123581886), (47, 0.16323341242969036), (7, 0.1635928750038147), (48, 0.178784416988492), (0, 0.18133865110576153), (4, 0.18756148591637611), (5, 0.19261321425437927), (49, 0.1964870747178793), (3, 0.20051711611449718), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.21770074777305126), (51, 0.25633351132273674), (52, 0.3056371696293354), (1, 0.3198661059141159), (36, 0.46763089671730995), (18, 0.48558927699923515), (53, 0.629994660615921)]
computing accuracy for after removing block 33 . block score: 0.094382643699646
removed block 33 current accuracy 0.9874 loss from initial  0.012599999999999945
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 11, with score 0.094849. All blocks and scores: [(11, 0.09484932199120522), (24, 0.09564292058348656), (26, 0.09724833350628614), (25, 0.09729211963713169), (9, 0.09801567811518908), (19, 0.09862752538174391), (23, 0.10386634059250355), (22, 0.10571276396512985), (14, 0.10837027337402105), (12, 0.12168859131634235), (15, 0.13208191841840744), (40, 0.136663556098938), (42, 0.13707910850644112), (43, 0.1400924101471901), (39, 0.1449015624821186), (41, 0.14946366846561432), (44, 0.1499204058200121), (16, 0.15027030929923058), (45, 0.15260093100368977), (38, 0.15498360618948936), (37, 0.16109201312065125), (47, 0.161690142005682), (46, 0.16172381676733494), (8, 0.16233665123581886), (7, 0.1635928750038147), (48, 0.17907380126416683), (0, 0.18133865110576153), (4, 0.18756148591637611), (5, 0.19261321425437927), (49, 0.19391952082514763), (3, 0.20051711611449718), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.21655810065567493), (51, 0.25665509700775146), (52, 0.30490922555327415), (1, 0.3198661059141159), (36, 0.4727725237607956), (18, 0.48558927699923515), (53, 0.6372786089777946)]
computing accuracy for after removing block 11 . block score: 0.09484932199120522
removed block 11 current accuracy 0.9786 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.094838. All blocks and scores: [(24, 0.09483793843537569), (25, 0.09642853308469057), (26, 0.09719614591449499), (9, 0.09801567811518908), (19, 0.10070331115275621), (23, 0.1017571035772562), (22, 0.10505871195346117), (14, 0.1141955591738224), (12, 0.12406313698738813), (15, 0.1352322120219469), (42, 0.1374374981969595), (40, 0.1382179893553257), (43, 0.14108467660844326), (44, 0.14863761514425278), (39, 0.1486742403358221), (41, 0.15083853341639042), (45, 0.15186641924083233), (16, 0.15222396329045296), (38, 0.15710747241973877), (37, 0.15994814969599247), (47, 0.16075924783945084), (46, 0.16141485050320625), (8, 0.16233665123581886), (7, 0.1635928750038147), (48, 0.17925991490483284), (0, 0.18133865110576153), (4, 0.18756148591637611), (5, 0.19261321425437927), (49, 0.19521735608577728), (3, 0.20051711611449718), (2, 0.20926897786557674), (6, 0.21372606046497822), (50, 0.2152756918221712), (51, 0.25494011119008064), (52, 0.3029521442949772), (1, 0.3198661059141159), (36, 0.47350431606173515), (18, 0.4883102513849735), (53, 0.636160708963871)]
computing accuracy for after removing block 24 . block score: 0.09483793843537569
removed block 24 current accuracy 0.963 loss from initial  0.03700000000000003
training start
training epoch 0 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 1 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 2 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 4 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 5 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 6 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 7 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 8 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 9 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 10 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 11 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 12 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 13 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 14 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 17 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 18 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 19 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 20 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 22 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 23 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 24 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 25 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 26 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 27 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 30 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 31 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 32 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 33 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 34 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 35 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 36 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 37 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 40 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 41 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 42 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 43 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 44 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 45 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 46 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 47 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 48 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 49 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.999200)
finished training. finished 50 epochs. accuracy 0.9992 topk_dict {'top1': 0.9992}
start iteration 16
[activation mean]: block to remove picked: 19, with score 0.105564. All blocks and scores: [(19, 0.10556439030915499), (9, 0.10716006997972727), (26, 0.11194256413727999), (14, 0.11533140204846859), (25, 0.11661262158304453), (22, 0.12066804710775614), (23, 0.12282976508140564), (12, 0.12435126304626465), (15, 0.13350864313542843), (40, 0.14188680797815323), (42, 0.14545984007418156), (43, 0.1468155886977911), (39, 0.14709571562707424), (16, 0.15368062257766724), (44, 0.15518983453512192), (41, 0.1564868800342083), (38, 0.15773473121225834), (45, 0.16269182227551937), (7, 0.16318703442811966), (8, 0.16554790921509266), (37, 0.16895942576229572), (46, 0.17283038794994354), (47, 0.17573045380413532), (0, 0.17844645120203495), (48, 0.1838776022195816), (4, 0.18523840606212616), (5, 0.19081183895468712), (3, 0.2009023018181324), (49, 0.20431364700198174), (2, 0.20509937033057213), (6, 0.21263890527188778), (50, 0.22624431923031807), (51, 0.2622179798781872), (52, 0.3098435290157795), (1, 0.3169510178267956), (18, 0.47024034336209297), (36, 0.475991353392601), (53, 0.6344478204846382)]
computing accuracy for after removing block 19 . block score: 0.10556439030915499
removed block 19 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 9, with score 0.107160. All blocks and scores: [(9, 0.10716006997972727), (26, 0.11232552863657475), (14, 0.11533140204846859), (25, 0.11699517164379358), (22, 0.12111964821815491), (23, 0.12271818052977324), (12, 0.12435126304626465), (15, 0.13350864313542843), (40, 0.14083132706582546), (42, 0.1422844808548689), (43, 0.14457295835018158), (39, 0.1459130309522152), (44, 0.1535552628338337), (16, 0.15368062257766724), (41, 0.15748226642608643), (38, 0.15810745395720005), (45, 0.16094079799950123), (7, 0.16318703442811966), (8, 0.16554790921509266), (37, 0.16929674707353115), (46, 0.17094814032316208), (47, 0.17333149537444115), (0, 0.17844645120203495), (48, 0.1810210943222046), (4, 0.18523840606212616), (5, 0.19081183895468712), (3, 0.2009023018181324), (49, 0.20392128266394138), (2, 0.20509937033057213), (6, 0.21263890527188778), (50, 0.22453632578253746), (51, 0.2583148032426834), (52, 0.3057713732123375), (1, 0.3169510178267956), (18, 0.47024034336209297), (36, 0.4790879637002945), (53, 0.6359859928488731)]
computing accuracy for after removing block 9 . block score: 0.10716006997972727
removed block 9 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 26, with score 0.111454. All blocks and scores: [(26, 0.11145432200282812), (25, 0.11529486440122128), (14, 0.11715212650597095), (23, 0.12019792944192886), (22, 0.12131236493587494), (12, 0.12216554209589958), (15, 0.1353499721735716), (40, 0.1390229258686304), (42, 0.13996242359280586), (43, 0.1429501175880432), (39, 0.14731073752045631), (44, 0.15128555707633495), (41, 0.15399890579283237), (45, 0.15744848549365997), (38, 0.15889573097229004), (16, 0.16026893071830273), (37, 0.16270205937325954), (7, 0.16318703442811966), (8, 0.16554790921509266), (46, 0.16767475381493568), (47, 0.16962506249547005), (48, 0.17735754512250423), (0, 0.17844645120203495), (4, 0.18523840606212616), (5, 0.19081183895468712), (3, 0.2009023018181324), (49, 0.20198107324540615), (2, 0.20509937033057213), (6, 0.21263890527188778), (50, 0.22059434466063976), (51, 0.25467247143387794), (52, 0.30362553149461746), (1, 0.3169510178267956), (18, 0.4651530012488365), (36, 0.46693405136466026), (53, 0.6306190341711044)]
computing accuracy for after removing block 26 . block score: 0.11145432200282812
removed block 26 current accuracy 0.9954 loss from initial  0.0046000000000000485
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 25, with score 0.115295. All blocks and scores: [(25, 0.11529486440122128), (14, 0.11715212650597095), (23, 0.12019792944192886), (22, 0.12131236493587494), (12, 0.12216554209589958), (15, 0.1353499721735716), (40, 0.13781660236418247), (42, 0.1415493544191122), (43, 0.142770454287529), (39, 0.147588063031435), (44, 0.14948124438524246), (41, 0.15468554012477398), (45, 0.15499521233141422), (38, 0.15921744890511036), (16, 0.16026893071830273), (7, 0.16318703442811966), (46, 0.16367337480187416), (37, 0.16389214992523193), (8, 0.16554790921509266), (47, 0.16645517759025097), (48, 0.17560352943837643), (0, 0.17844645120203495), (4, 0.18523840606212616), (5, 0.19081183895468712), (49, 0.19807778485119343), (3, 0.2009023018181324), (2, 0.20509937033057213), (6, 0.21263890527188778), (50, 0.21834584511816502), (51, 0.2539847791194916), (52, 0.30230972170829773), (1, 0.3169510178267956), (18, 0.4651530012488365), (36, 0.4741608798503876), (53, 0.6322797685861588)]
computing accuracy for after removing block 25 . block score: 0.11529486440122128
removed block 25 current accuracy 0.9864 loss from initial  0.013599999999999945
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 14, with score 0.117152. All blocks and scores: [(14, 0.11715212650597095), (23, 0.12019792944192886), (22, 0.12131236493587494), (12, 0.12216554209589958), (40, 0.1334462258964777), (15, 0.1353499721735716), (43, 0.1389352474361658), (42, 0.14032169058918953), (44, 0.14641070552170277), (39, 0.14735862612724304), (45, 0.1498767826706171), (41, 0.15175681374967098), (38, 0.15744265541434288), (47, 0.1589590236544609), (46, 0.15917611867189407), (16, 0.16026893071830273), (37, 0.16179508157074451), (7, 0.16318703442811966), (8, 0.16554790921509266), (48, 0.1707073673605919), (0, 0.17844645120203495), (4, 0.18523840606212616), (5, 0.19081183895468712), (49, 0.19185450300574303), (3, 0.2009023018181324), (2, 0.20509937033057213), (6, 0.21263890527188778), (50, 0.21450033970177174), (51, 0.25160338543355465), (52, 0.29774755239486694), (1, 0.3169510178267956), (18, 0.4651530012488365), (36, 0.4794072210788727), (53, 0.636411264538765)]
computing accuracy for after removing block 14 . block score: 0.11715212650597095
removed block 14 current accuracy 0.9732 loss from initial  0.026800000000000046
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 23, with score 0.117056. All blocks and scores: [(23, 0.11705554183572531), (22, 0.1200459711253643), (12, 0.12216554209589958), (40, 0.13606762513518333), (43, 0.1386413499712944), (42, 0.140694422647357), (15, 0.14329962246119976), (44, 0.14621315337717533), (45, 0.14867055043578148), (39, 0.1497953198850155), (41, 0.15112548135221004), (47, 0.15706462785601616), (46, 0.1578009482473135), (38, 0.15962242893874645), (37, 0.1615576557815075), (7, 0.16318703442811966), (8, 0.16554790921509266), (16, 0.16585992462933064), (48, 0.1697323750704527), (0, 0.17844645120203495), (4, 0.18523840606212616), (49, 0.19007828831672668), (5, 0.19081183895468712), (3, 0.2009023018181324), (2, 0.20509937033057213), (50, 0.21166187711060047), (6, 0.21263890527188778), (51, 0.24944813922047615), (52, 0.2952117957174778), (1, 0.3169510178267956), (18, 0.46452758461236954), (36, 0.4789365530014038), (53, 0.6338839903473854)]
computing accuracy for after removing block 23 . block score: 0.11705554183572531
removed block 23 current accuracy 0.9408 loss from initial  0.05920000000000003
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 22, with score 0.120046. All blocks and scores: [(22, 0.1200459711253643), (12, 0.12216554209589958), (40, 0.1367666143923998), (43, 0.1370277050882578), (42, 0.1424113865941763), (44, 0.14307480119168758), (15, 0.14329962246119976), (45, 0.14391789957880974), (47, 0.15089562721550465), (41, 0.1523668747395277), (46, 0.15344712510704994), (39, 0.15534850023686886), (7, 0.16318703442811966), (37, 0.16329446248710155), (38, 0.16336806304752827), (48, 0.1654310468584299), (8, 0.16554790921509266), (16, 0.16585992462933064), (0, 0.17844645120203495), (49, 0.1852135006338358), (4, 0.18523840606212616), (5, 0.19081183895468712), (3, 0.2009023018181324), (2, 0.20509937033057213), (50, 0.2079419605433941), (6, 0.21263890527188778), (51, 0.24702979438006878), (52, 0.2905973084270954), (1, 0.3169510178267956), (18, 0.46452758461236954), (36, 0.48586806654930115), (53, 0.6376551315188408)]
computing accuracy for after removing block 22 . block score: 0.1200459711253643
removed block 22 current accuracy 0.8854 loss from initial  0.11460000000000004
since last training loss: 0.11380000000000001 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 12, with score 0.122166. All blocks and scores: [(12, 0.12216554209589958), (43, 0.134751308709383), (45, 0.14123760350048542), (40, 0.14238379709422588), (44, 0.14279368333518505), (15, 0.14329962246119976), (47, 0.14666381292045116), (42, 0.15199895575642586), (46, 0.15424681454896927), (41, 0.158834645524621), (7, 0.16318703442811966), (48, 0.1633094698190689), (8, 0.16554790921509266), (16, 0.16585992462933064), (39, 0.1671464890241623), (38, 0.17140048183500767), (37, 0.17380573600530624), (0, 0.17844645120203495), (49, 0.18261075392365456), (4, 0.18523840606212616), (5, 0.19081183895468712), (3, 0.2009023018181324), (50, 0.20467571541666985), (2, 0.20509937033057213), (6, 0.21263890527188778), (51, 0.2476050052791834), (52, 0.28720149397850037), (1, 0.3169510178267956), (18, 0.46452758461236954), (36, 0.5072345584630966), (53, 0.633545771241188)]
computing accuracy for after removing block 12 . block score: 0.12216554209589958
removed block 12 current accuracy 0.886 loss from initial  0.11399999999999999
training start
training epoch 0 val accuracy 0.9858 topk_dict {'top1': 0.9858} is_best True lr [0.001]
training epoch 1 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 2 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 3 val accuracy 0.9886 topk_dict {'top1': 0.9886} is_best False lr [0.001]
training epoch 4 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 5 val accuracy 0.99 topk_dict {'top1': 0.99} is_best False lr [0.001]
training epoch 6 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 7 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 8 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 9 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 10 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 11 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 12 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 13 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 14 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 15 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 16 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 17 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 18 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best True lr [0.001]
training epoch 19 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 20 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 21 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 22 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 23 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best True lr [0.001]
training epoch 24 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 25 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 26 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 27 val accuracy 0.9942 topk_dict {'top1': 0.9942} is_best False lr [0.001]
training epoch 28 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 29 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 30 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9938 topk_dict {'top1': 0.9938} is_best False lr [0.001]
training epoch 32 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best True lr [0.001]
training epoch 33 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 34 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 35 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 36 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 37 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 38 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 39 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 40 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 41 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 42 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 43 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 44 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 45 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 46 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 47 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 48 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 49 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.996000)
finished training. finished 50 epochs. accuracy 0.996 topk_dict {'top1': 0.996}
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.141499. All blocks and scores: [(40, 0.14149935729801655), (39, 0.14527546986937523), (42, 0.14543074369430542), (43, 0.14635091088712215), (44, 0.152687082067132), (41, 0.15519753471016884), (38, 0.1575994584709406), (15, 0.15906665287911892), (45, 0.16183129884302616), (7, 0.16507225297391415), (37, 0.16782613657414913), (0, 0.17143331095576286), (46, 0.1719372570514679), (47, 0.1741908024996519), (4, 0.1783771850168705), (8, 0.18320832587778568), (48, 0.18345400132238865), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (2, 0.19966379925608635), (49, 0.2029754128307104), (6, 0.2128267753869295), (50, 0.22478054277598858), (51, 0.26040011271834373), (1, 0.29958825558423996), (52, 0.3061702474951744), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.6407422199845314)]
computing accuracy for after removing block 40 . block score: 0.14149935729801655
removed block 40 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 43, with score 0.143495. All blocks and scores: [(43, 0.14349528960883617), (42, 0.1444147601723671), (39, 0.14527546986937523), (44, 0.14981436729431152), (38, 0.1575994584709406), (41, 0.15832021459937096), (45, 0.15902218781411648), (15, 0.15906665287911892), (7, 0.16507225297391415), (37, 0.16782613657414913), (46, 0.16994686797261238), (0, 0.17143331095576286), (47, 0.17169402912259102), (4, 0.1783771850168705), (48, 0.17908284440636635), (8, 0.18320832587778568), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (49, 0.1985785160213709), (2, 0.19966379925608635), (6, 0.2128267753869295), (50, 0.2210723739117384), (51, 0.25450609996914864), (1, 0.29958825558423996), (52, 0.30041081458330154), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.6493076011538506)]
computing accuracy for after removing block 43 . block score: 0.14349528960883617
removed block 43 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 42, with score 0.144415. All blocks and scores: [(42, 0.1444147601723671), (39, 0.14527546986937523), (44, 0.15053188987076283), (38, 0.1575994584709406), (41, 0.15832021459937096), (15, 0.15906665287911892), (45, 0.16125533357262611), (7, 0.16507225297391415), (37, 0.16782613657414913), (0, 0.17143331095576286), (46, 0.1719917207956314), (47, 0.17287481017410755), (4, 0.1783771850168705), (48, 0.18038873374462128), (8, 0.18320832587778568), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (49, 0.19719448871910572), (2, 0.19966379925608635), (6, 0.2128267753869295), (50, 0.2221260517835617), (51, 0.2532738856971264), (52, 0.2969234846532345), (1, 0.29958825558423996), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.6731791645288467)]
computing accuracy for after removing block 42 . block score: 0.1444147601723671
removed block 42 current accuracy 0.9788 loss from initial  0.021199999999999997
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 39, with score 0.145275. All blocks and scores: [(39, 0.14527546986937523), (44, 0.15282042883336544), (38, 0.1575994584709406), (41, 0.15832021459937096), (15, 0.15906665287911892), (45, 0.16387737356126308), (7, 0.16507225297391415), (37, 0.16782613657414913), (0, 0.17143331095576286), (46, 0.172443313524127), (47, 0.1767694652080536), (4, 0.1783771850168705), (8, 0.18320832587778568), (48, 0.18446380086243153), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (2, 0.19966379925608635), (49, 0.19978735037148), (6, 0.2128267753869295), (50, 0.22460529580712318), (51, 0.2542228102684021), (52, 0.29482100903987885), (1, 0.29958825558423996), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.6908647418022156)]
computing accuracy for after removing block 39 . block score: 0.14527546986937523
removed block 39 current accuracy 0.9698 loss from initial  0.030200000000000005
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 44, with score 0.152428. All blocks and scores: [(44, 0.15242797881364822), (38, 0.1575994584709406), (15, 0.15906665287911892), (41, 0.1595021653920412), (45, 0.16429118067026138), (7, 0.16507225297391415), (37, 0.16782613657414913), (46, 0.16785229928791523), (0, 0.17143331095576286), (47, 0.17379147559404373), (4, 0.1783771850168705), (48, 0.1823687143623829), (8, 0.18320832587778568), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (49, 0.1959673222154379), (2, 0.19966379925608635), (6, 0.2128267753869295), (50, 0.22322354651987553), (51, 0.2517445757985115), (52, 0.2897244915366173), (1, 0.29958825558423996), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.7078200578689575)]
computing accuracy for after removing block 44 . block score: 0.15242797881364822
removed block 44 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 38, with score 0.157599. All blocks and scores: [(38, 0.1575994584709406), (15, 0.15906665287911892), (41, 0.1595021653920412), (45, 0.16287272982299328), (46, 0.16341625154018402), (7, 0.16507225297391415), (37, 0.16782613657414913), (0, 0.17143331095576286), (47, 0.1716359294950962), (4, 0.1783771850168705), (8, 0.18320832587778568), (48, 0.18473410978913307), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (49, 0.19645295105874538), (2, 0.19966379925608635), (6, 0.2128267753869295), (50, 0.22108349204063416), (51, 0.24771942757070065), (52, 0.28475121781229973), (1, 0.29958825558423996), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.7423312738537788)]
computing accuracy for after removing block 38 . block score: 0.1575994584709406
removed block 38 current accuracy 0.939 loss from initial  0.061000000000000054
since last training loss: 0.05700000000000005 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 15, with score 0.159067. All blocks and scores: [(15, 0.15906665287911892), (46, 0.1610941868275404), (41, 0.16197796165943146), (7, 0.16507225297391415), (45, 0.16516017355024815), (37, 0.16782613657414913), (47, 0.16987603716552258), (0, 0.17143331095576286), (4, 0.1783771850168705), (48, 0.18246813863515854), (8, 0.18320832587778568), (5, 0.18743199482560158), (16, 0.18820490315556526), (3, 0.19517641887068748), (49, 0.19871033914387226), (2, 0.19966379925608635), (6, 0.2128267753869295), (50, 0.21993828378617764), (51, 0.24602638185024261), (52, 0.281217060983181), (1, 0.29958825558423996), (36, 0.47373002767562866), (18, 0.48346465826034546), (53, 0.7602104842662811)]
computing accuracy for after removing block 15 . block score: 0.15906665287911892
removed block 15 current accuracy 0.9172 loss from initial  0.08279999999999998
since last training loss: 0.07879999999999998 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 46, with score 0.158943. All blocks and scores: [(46, 0.15894311852753162), (45, 0.16055508889257908), (41, 0.1639243047684431), (37, 0.16478770226240158), (7, 0.16507225297391415), (47, 0.1664547398686409), (0, 0.17143331095576286), (4, 0.1783771850168705), (48, 0.1805181037634611), (8, 0.18320832587778568), (5, 0.18743199482560158), (49, 0.19466298073530197), (3, 0.19517641887068748), (2, 0.19966379925608635), (16, 0.20536505244672298), (6, 0.2128267753869295), (50, 0.2160404995083809), (51, 0.24108601734042168), (52, 0.27820349112153053), (1, 0.29958825558423996), (18, 0.4692177399992943), (36, 0.47029802575707436), (53, 0.7543123289942741)]
computing accuracy for after removing block 46 . block score: 0.15894311852753162
removed block 46 current accuracy 0.8936 loss from initial  0.10640000000000005
since last training loss: 0.10240000000000005 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 45, with score 0.160555. All blocks and scores: [(45, 0.16055508889257908), (41, 0.1639243047684431), (37, 0.16478770226240158), (7, 0.16507225297391415), (47, 0.16692430712282658), (0, 0.17143331095576286), (4, 0.1783771850168705), (48, 0.18242986872792244), (8, 0.18320832587778568), (5, 0.18743199482560158), (3, 0.19517641887068748), (49, 0.19631927460432053), (2, 0.19966379925608635), (16, 0.20536505244672298), (6, 0.2128267753869295), (50, 0.21831367164850235), (51, 0.23976638354361057), (52, 0.2731656953692436), (1, 0.29958825558423996), (18, 0.4692177399992943), (36, 0.47029802575707436), (53, 0.7893945202231407)]
computing accuracy for after removing block 45 . block score: 0.16055508889257908
removed block 45 current accuracy 0.8498 loss from initial  0.1502
training start
training epoch 0 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.001]
training epoch 1 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.001]
training epoch 2 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best True lr [0.001]
training epoch 3 val accuracy 0.9682 topk_dict {'top1': 0.9682} is_best False lr [0.001]
training epoch 4 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.001]
training epoch 5 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 6 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
training epoch 7 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best True lr [0.001]
training epoch 8 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 9 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.001]
training epoch 10 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 11 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best False lr [0.001]
training epoch 12 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best True lr [0.001]
training epoch 13 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 14 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 15 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 16 val accuracy 0.9754 topk_dict {'top1': 0.9754} is_best False lr [0.001]
training epoch 17 val accuracy 0.9744 topk_dict {'top1': 0.9744} is_best False lr [0.001]
training epoch 18 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 19 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 20 val accuracy 0.977 topk_dict {'top1': 0.977} is_best False lr [0.001]
training epoch 21 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 22 val accuracy 0.976 topk_dict {'top1': 0.976} is_best False lr [0.001]
training epoch 23 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best True lr [0.001]
training epoch 24 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 25 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 26 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best True lr [0.001]
training epoch 27 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 28 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 29 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 30 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 31 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 32 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 33 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 34 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 35 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 36 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 37 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 38 val accuracy 0.978 topk_dict {'top1': 0.978} is_best False lr [0.001]
training epoch 39 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 40 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 41 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 42 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 43 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best True lr [0.001]
training epoch 44 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 45 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 46 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 47 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best True lr [0.001]
training epoch 48 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 49 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.980400)
finished training. finished 50 epochs. accuracy 0.9804 topk_dict {'top1': 0.9804}
