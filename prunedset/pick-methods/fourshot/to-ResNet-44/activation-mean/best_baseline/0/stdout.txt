start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062186. All blocks and scores: [(33, 0.062185654416680336), (31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08460694830864668), (29, 0.08930057473480701), (35, 0.09068185184150934), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.15793540328741074), (41, 0.1598859392106533), (40, 0.16328190825879574), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (13, 0.17231429554522038), (16, 0.17250859178602695), (42, 0.173072362318635), (3, 0.17561711743474007), (44, 0.17696543596684933), (39, 0.18027342669665813), (46, 0.18065034598112106), (45, 0.18211421370506287), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.1851444821804762), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20122026838362217), (48, 0.20766260288655758), (47, 0.21044609509408474), (10, 0.21198169328272343), (49, 0.21626885049045086), (12, 0.2171211950480938), (50, 0.2270798273384571), (5, 0.24775297567248344), (51, 0.25931933149695396), (52, 0.27953876554965973), (18, 0.562093511223793), (36, 0.5809764266014099), (53, 0.6345704793930054)]
computing accuracy for after removing block 33 . block score: 0.062185654416680336
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075665. All blocks and scores: [(31, 0.07566479779779911), (32, 0.07689524348825216), (30, 0.08002207893878222), (34, 0.08419696148484945), (29, 0.08930057473480701), (35, 0.09093761537224054), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (43, 0.1572423968464136), (41, 0.157970754429698), (40, 0.16252249106764793), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.1718137189745903), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17635269090533257), (46, 0.17947880178689957), (39, 0.1794979516416788), (45, 0.18079246766865253), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18429154343903065), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20149224624037743), (48, 0.20621014572679996), (47, 0.2088273111730814), (10, 0.21198169328272343), (49, 0.21557523868978024), (12, 0.2171211950480938), (50, 0.2254290860146284), (5, 0.24775297567248344), (51, 0.2583659961819649), (52, 0.2788151502609253), (18, 0.562093511223793), (36, 0.5792211890220642), (53, 0.6342398598790169)]
computing accuracy for after removing block 31 . block score: 0.07566479779779911
removed block 31 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077217. All blocks and scores: [(32, 0.0772171588614583), (30, 0.08002207893878222), (34, 0.08413633890450001), (29, 0.08930057473480701), (35, 0.0912106977775693), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.15681212209165096), (9, 0.15687535144388676), (41, 0.1570850908756256), (40, 0.161650612950325), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17076795920729637), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17494448646903038), (3, 0.17561711743474007), (46, 0.17894328385591507), (39, 0.1794340517371893), (45, 0.18090466037392616), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.184414841234684), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20150442980229855), (48, 0.2049737572669983), (47, 0.2079013716429472), (10, 0.21198169328272343), (49, 0.2145967148244381), (12, 0.2171211950480938), (50, 0.22419615276157856), (5, 0.24775297567248344), (51, 0.2574971169233322), (52, 0.27774784341454506), (18, 0.562093511223793), (36, 0.578696958720684), (53, 0.6368038207292557)]
computing accuracy for after removing block 32 . block score: 0.0772171588614583
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080022. All blocks and scores: [(30, 0.08002207893878222), (34, 0.08331287186592817), (29, 0.08930057473480701), (35, 0.09091351181268692), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (43, 0.1567240171134472), (9, 0.15687535144388676), (41, 0.15688308142125607), (40, 0.16149466298520565), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17011075653135777), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.1743054185062647), (3, 0.17561711743474007), (39, 0.17930877394974232), (46, 0.1793159805238247), (45, 0.1810449492186308), (11, 0.18289094977080822), (38, 0.18401959165930748), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (37, 0.20230499655008316), (48, 0.20458471588790417), (47, 0.20751793310046196), (10, 0.21198169328272343), (49, 0.21405635960400105), (12, 0.2171211950480938), (50, 0.22361480072140694), (5, 0.24775297567248344), (51, 0.2571289539337158), (52, 0.2768261544406414), (18, 0.562093511223793), (36, 0.5805345475673676), (53, 0.6388764828443527)]
computing accuracy for after removing block 30 . block score: 0.08002207893878222
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082327. All blocks and scores: [(34, 0.0823270846158266), (29, 0.08930057473480701), (35, 0.09074232261627913), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (41, 0.15666824020445347), (43, 0.1568149123340845), (9, 0.15687535144388676), (40, 0.16184155084192753), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.16879690065979958), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.17466101422905922), (3, 0.17561711743474007), (46, 0.17866099812090397), (39, 0.17968248948454857), (45, 0.1809448804706335), (11, 0.18289094977080822), (38, 0.18364996276795864), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.20370880514383316), (37, 0.20395098999142647), (47, 0.20615417696535587), (10, 0.21198169328272343), (49, 0.21362591721117496), (12, 0.2171211950480938), (50, 0.22279280424118042), (5, 0.24775297567248344), (51, 0.2562031261622906), (52, 0.2757616192102432), (18, 0.562093511223793), (36, 0.5833301842212677), (53, 0.6426545828580856)]
computing accuracy for after removing block 34 . block score: 0.0823270846158266
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.089301. All blocks and scores: [(29, 0.08930057473480701), (35, 0.09233403950929642), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (9, 0.15687535144388676), (41, 0.15786897018551826), (43, 0.15851951949298382), (40, 0.16382364183664322), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (42, 0.17144694924354553), (13, 0.17231429554522038), (16, 0.17250859178602695), (3, 0.17561711743474007), (44, 0.17642127722501755), (46, 0.1792240459471941), (39, 0.18195353262126446), (45, 0.1821158267557621), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.18651140667498112), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.2036153506487608), (47, 0.20668456703424454), (37, 0.20811929553747177), (10, 0.21198169328272343), (49, 0.21409878507256508), (12, 0.2171211950480938), (50, 0.2226774599403143), (5, 0.24775297567248344), (51, 0.25564805790781975), (52, 0.2756016328930855), (18, 0.562093511223793), (36, 0.5907158851623535), (53, 0.6423948332667351)]
computing accuracy for after removing block 29 . block score: 0.08930057473480701
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.091657. All blocks and scores: [(35, 0.09165653120726347), (26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (19, 0.15310418419539928), (41, 0.15495886653661728), (43, 0.1564184371381998), (9, 0.15687535144388676), (40, 0.16190743818879128), (4, 0.1638463642448187), (14, 0.1646636202931404), (42, 0.1678131129592657), (6, 0.16876995004713535), (13, 0.17231429554522038), (16, 0.17250859178602695), (44, 0.1750869434326887), (3, 0.17561711743474007), (46, 0.17751540057361126), (45, 0.180727431550622), (39, 0.1812782883644104), (11, 0.18289094977080822), (8, 0.18417140655219555), (38, 0.1843508444726467), (2, 0.18877310492098331), (0, 0.19188890047371387), (1, 0.20094968006014824), (48, 0.20150871388614178), (47, 0.20382969826459885), (37, 0.20588894188404083), (10, 0.21198169328272343), (49, 0.21254768408834934), (12, 0.2171211950480938), (50, 0.22045584954321384), (5, 0.24775297567248344), (51, 0.25385941937565804), (52, 0.27405693009495735), (18, 0.562093511223793), (36, 0.5876752510666847), (53, 0.6453233808279037)]
computing accuracy for after removing block 35 . block score: 0.09165653120726347
removed block 35 current accuracy 0.9984 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.102849. All blocks and scores: [(26, 0.10284937918186188), (28, 0.10649203043431044), (27, 0.1175687788054347), (23, 0.12182437721639872), (25, 0.12312396708875895), (24, 0.12810388393700123), (21, 0.13027099333703518), (22, 0.13283132389187813), (15, 0.1362538281828165), (20, 0.13737017288804054), (7, 0.138400012627244), (17, 0.1462525948882103), (41, 0.14814221300184727), (43, 0.15043681487441063), (19, 0.15310418419539928), (9, 0.15687535144388676), (40, 0.15760448575019836), (42, 0.16072314977645874), (4, 0.1638463642448187), (14, 0.1646636202931404), (6, 0.16876995004713535), (44, 0.1713014841079712), (13, 0.17231429554522038), (46, 0.17232048697769642), (16, 0.17250859178602695), (3, 0.17561711743474007), (39, 0.17583631351590157), (45, 0.17609016224741936), (38, 0.17979468032717705), (11, 0.18289094977080822), (8, 0.18417140655219555), (2, 0.18877310492098331), (0, 0.19188890047371387), (48, 0.1943671703338623), (37, 0.1972644105553627), (47, 0.20038395375013351), (1, 0.20094968006014824), (49, 0.2090973649173975), (10, 0.21198169328272343), (50, 0.21475619822740555), (12, 0.2171211950480938), (5, 0.24775297567248344), (51, 0.2506211008876562), (52, 0.2706872373819351), (18, 0.562093511223793), (36, 0.5786933302879333), (53, 0.6560840830206871)]
computing accuracy for after removing block 26 . block score: 0.10284937918186188
removed block 26 current accuracy 0.9964 loss from initial  0.0036000000000000476
training start
training epoch 0 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 1 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 2 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 3 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 4 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 5 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 6 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 7 val accuracy 1.0 topk_dict {'top1': 1.0} is_best True lr [0.001]
training epoch 8 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 9 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 10 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 11 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 12 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 13 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 14 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 15 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 16 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 17 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 18 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 19 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 20 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 21 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 22 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 23 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 24 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 25 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 26 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 27 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 28 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 29 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 30 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 31 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 32 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 33 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 34 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 35 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 36 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 37 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 38 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 39 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 40 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 41 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 42 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 43 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 44 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 45 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 46 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 47 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 48 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
training epoch 49 val accuracy 1.0 topk_dict {'top1': 1.0} is_best False lr [0.001]
loading model_best from epoch 7 (acc 1.000000)
finished training. finished 50 epochs. accuracy 1.0 topk_dict {'top1': 1.0}
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.109355. All blocks and scores: [(28, 0.10935532674193382), (27, 0.12030978128314018), (23, 0.12513252906501293), (25, 0.1251828558743), (24, 0.13121477514505386), (21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (17, 0.14787757024168968), (19, 0.1539583671838045), (43, 0.156220069155097), (41, 0.15779824927449226), (9, 0.15803069435060024), (4, 0.16243899054825306), (40, 0.16250750049948692), (14, 0.16450546123087406), (6, 0.16796452552080154), (42, 0.17094062827527523), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (39, 0.17773417755961418), (44, 0.17857271991670132), (46, 0.17956852726638317), (45, 0.18030806817114353), (11, 0.18189396150410175), (38, 0.18194465897977352), (8, 0.18415881134569645), (2, 0.18855171464383602), (0, 0.1912123691290617), (37, 0.1981069315224886), (1, 0.2008061483502388), (48, 0.20685970038175583), (47, 0.2095082849264145), (10, 0.21189066022634506), (12, 0.21651808358728886), (49, 0.2169886063784361), (50, 0.22665569372475147), (5, 0.24546801671385765), (51, 0.26095206290483475), (52, 0.2805468700826168), (18, 0.5609442889690399), (36, 0.5726628825068474), (53, 0.6256396397948265)]
computing accuracy for after removing block 28 . block score: 0.10935532674193382
removed block 28 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.120310. All blocks and scores: [(27, 0.12030978128314018), (23, 0.12513252906501293), (25, 0.1251828558743), (24, 0.13121477514505386), (21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (17, 0.14787757024168968), (43, 0.1528737936168909), (19, 0.1539583671838045), (41, 0.15412765555083752), (9, 0.15803069435060024), (40, 0.16010651178658009), (4, 0.16243899054825306), (14, 0.16450546123087406), (42, 0.1658731810748577), (6, 0.16796452552080154), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (39, 0.17536462284624577), (46, 0.17570259049534798), (44, 0.1763836108148098), (45, 0.1770089864730835), (38, 0.17854486964643002), (11, 0.18189396150410175), (8, 0.18415881134569645), (2, 0.18855171464383602), (0, 0.1912123691290617), (37, 0.19525890611112118), (1, 0.2008061483502388), (48, 0.20299005880951881), (47, 0.20575859025120735), (10, 0.21189066022634506), (49, 0.21407952345907688), (12, 0.21651808358728886), (50, 0.22384387627243996), (5, 0.24546801671385765), (51, 0.25916892662644386), (52, 0.27900272235274315), (18, 0.5609442889690399), (36, 0.5678942650556564), (53, 0.6301640272140503)]
computing accuracy for after removing block 27 . block score: 0.12030978128314018
removed block 27 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.125133. All blocks and scores: [(23, 0.12513252906501293), (25, 0.1251828558743), (24, 0.13121477514505386), (21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (17, 0.14787757024168968), (43, 0.14957508817315102), (41, 0.15006333775818348), (19, 0.1539583671838045), (40, 0.15670299157500267), (9, 0.15803069435060024), (42, 0.16104757227003574), (4, 0.16243899054825306), (14, 0.16450546123087406), (6, 0.16796452552080154), (13, 0.1719190515577793), (39, 0.17224853299558163), (46, 0.17250780574977398), (16, 0.17280729860067368), (44, 0.17289138585329056), (45, 0.17435279116034508), (38, 0.17464310489594936), (3, 0.17506179586052895), (11, 0.18189396150410175), (8, 0.18415881134569645), (2, 0.18855171464383602), (0, 0.1912123691290617), (37, 0.1921168640255928), (48, 0.19922347366809845), (1, 0.2008061483502388), (47, 0.20199579745531082), (49, 0.21169797703623772), (10, 0.21189066022634506), (12, 0.21651808358728886), (50, 0.22066616639494896), (5, 0.24546801671385765), (51, 0.25687457621097565), (52, 0.2772148549556732), (18, 0.5609442889690399), (36, 0.5618458166718483), (53, 0.6340897679328918)]
computing accuracy for after removing block 23 . block score: 0.12513252906501293
removed block 23 current accuracy 0.9972 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.124909. All blocks and scores: [(25, 0.1249088179320097), (24, 0.1273084282875061), (21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (17, 0.14787757024168968), (41, 0.14819669723510742), (43, 0.14903944730758667), (19, 0.1539583671838045), (40, 0.15548956207931042), (9, 0.15803069435060024), (42, 0.15808436647057533), (4, 0.16243899054825306), (14, 0.16450546123087406), (6, 0.16796452552080154), (46, 0.17050186730921268), (44, 0.17144169844686985), (13, 0.1719190515577793), (39, 0.172505684196949), (16, 0.17280729860067368), (45, 0.17377698980271816), (38, 0.17381947860121727), (3, 0.17506179586052895), (11, 0.18189396150410175), (8, 0.18415881134569645), (2, 0.18855171464383602), (0, 0.1912123691290617), (37, 0.19476288929581642), (48, 0.19716198556125164), (47, 0.1995021030306816), (1, 0.2008061483502388), (49, 0.21048019267618656), (10, 0.21189066022634506), (12, 0.21651808358728886), (50, 0.21848438121378422), (5, 0.24546801671385765), (51, 0.2552355118095875), (52, 0.27535030245780945), (18, 0.5609442889690399), (36, 0.5624610558152199), (53, 0.6336979046463966)]
computing accuracy for after removing block 25 . block score: 0.1249088179320097
removed block 25 current accuracy 0.9938 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 24, with score 0.127308. All blocks and scores: [(24, 0.1273084282875061), (21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (41, 0.1449730396270752), (43, 0.14549403451383114), (17, 0.14787757024168968), (40, 0.1527004837989807), (42, 0.1535437311977148), (19, 0.1539583671838045), (9, 0.15803069435060024), (4, 0.16243899054825306), (14, 0.16450546123087406), (46, 0.166227912530303), (6, 0.16796452552080154), (44, 0.16830183006823063), (38, 0.17088880203664303), (45, 0.17094875872135162), (39, 0.17133743315935135), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (11, 0.18189396150410175), (8, 0.18415881134569645), (2, 0.18855171464383602), (0, 0.1912123691290617), (37, 0.19147595576941967), (48, 0.19354863092303276), (47, 0.195704722777009), (1, 0.2008061483502388), (49, 0.2069074995815754), (10, 0.21189066022634506), (50, 0.2147400826215744), (12, 0.21651808358728886), (5, 0.24546801671385765), (51, 0.2522599622607231), (52, 0.2727004401385784), (36, 0.5566344112157822), (18, 0.5609442889690399), (53, 0.6379363387823105)]
computing accuracy for after removing block 24 . block score: 0.1273084282875061
removed block 24 current accuracy 0.9844 loss from initial  0.015599999999999947
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 21, with score 0.131752. All blocks and scores: [(21, 0.13175175338983536), (22, 0.13454752415418625), (15, 0.13716560043394566), (7, 0.13784805871546268), (41, 0.13838448002934456), (20, 0.13848324120044708), (43, 0.1415382232517004), (17, 0.14787757024168968), (42, 0.14799213781952858), (40, 0.14844372123479843), (19, 0.1539583671838045), (9, 0.15803069435060024), (46, 0.16174433752894402), (4, 0.16243899054825306), (44, 0.16325641982257366), (14, 0.16450546123087406), (6, 0.16796452552080154), (45, 0.16805005818605423), (38, 0.1685223951935768), (39, 0.16939536295831203), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (11, 0.18189396150410175), (8, 0.18415881134569645), (2, 0.18855171464383602), (48, 0.18872323259711266), (37, 0.18932919204235077), (0, 0.1912123691290617), (47, 0.19241223856806755), (1, 0.2008061483502388), (49, 0.20372556895017624), (50, 0.21052891574800014), (10, 0.21189066022634506), (12, 0.21651808358728886), (5, 0.24546801671385765), (51, 0.24855940975248814), (52, 0.2686767876148224), (36, 0.5495087280869484), (18, 0.5609442889690399), (53, 0.6421175301074982)]
computing accuracy for after removing block 21 . block score: 0.13175175338983536
removed block 21 current accuracy 0.9788 loss from initial  0.021199999999999997
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 22, with score 0.129183. All blocks and scores: [(22, 0.1291827391833067), (41, 0.134135153144598), (15, 0.13716560043394566), (7, 0.13784805871546268), (43, 0.13836943171918392), (20, 0.13848324120044708), (42, 0.14280415512621403), (40, 0.14572838880121708), (17, 0.14787757024168968), (19, 0.1539583671838045), (9, 0.15803069435060024), (46, 0.158564580604434), (44, 0.15918336436152458), (4, 0.16243899054825306), (14, 0.16450546123087406), (38, 0.165268674492836), (45, 0.1653735712170601), (39, 0.16741999797523022), (6, 0.16796452552080154), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (11, 0.18189396150410175), (8, 0.18415881134569645), (48, 0.1851039044559002), (37, 0.18632209673523903), (2, 0.18855171464383602), (47, 0.18971094489097595), (0, 0.1912123691290617), (1, 0.2008061483502388), (49, 0.20160919800400734), (50, 0.2073682602494955), (10, 0.21189066022634506), (12, 0.21651808358728886), (5, 0.24546801671385765), (51, 0.24692217633128166), (52, 0.26577678322792053), (36, 0.5430671870708466), (18, 0.5609442889690399), (53, 0.6413955464959145)]
computing accuracy for after removing block 22 . block score: 0.1291827391833067
removed block 22 current accuracy 0.9642 loss from initial  0.035800000000000054
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 41, with score 0.129772. All blocks and scores: [(41, 0.12977175414562225), (43, 0.13625209592282772), (15, 0.13716560043394566), (7, 0.13784805871546268), (20, 0.13848324120044708), (42, 0.13889141753315926), (40, 0.14353123679757118), (17, 0.14787757024168968), (46, 0.1537504903972149), (19, 0.1539583671838045), (44, 0.15496710874140263), (9, 0.15803069435060024), (45, 0.16194970160722733), (4, 0.16243899054825306), (38, 0.16417529247701168), (14, 0.16450546123087406), (39, 0.16533306054770947), (6, 0.16796452552080154), (13, 0.1719190515577793), (16, 0.17280729860067368), (3, 0.17506179586052895), (48, 0.17985247448086739), (11, 0.18189396150410175), (8, 0.18415881134569645), (47, 0.1856620479375124), (37, 0.18681282550096512), (2, 0.18855171464383602), (0, 0.1912123691290617), (49, 0.19840496592223644), (1, 0.2008061483502388), (50, 0.20361868850886822), (10, 0.21189066022634506), (12, 0.21651808358728886), (51, 0.24438340589404106), (5, 0.24546801671385765), (52, 0.263026338070631), (36, 0.5405656918883324), (18, 0.5609442889690399), (53, 0.6400998905301094)]
computing accuracy for after removing block 41 . block score: 0.12977175414562225
removed block 41 current accuracy 0.9604 loss from initial  0.03959999999999997
training start
training epoch 0 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best True lr [0.001]
training epoch 1 val accuracy 0.992 topk_dict {'top1': 0.992} is_best True lr [0.001]
training epoch 2 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 3 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 4 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 5 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 6 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 7 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 8 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 9 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best True lr [0.001]
training epoch 10 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 11 val accuracy 0.9936 topk_dict {'top1': 0.9936} is_best False lr [0.001]
training epoch 12 val accuracy 0.994 topk_dict {'top1': 0.994} is_best True lr [0.001]
training epoch 13 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 14 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 15 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 16 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 17 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 18 val accuracy 0.994 topk_dict {'top1': 0.994} is_best False lr [0.001]
training epoch 19 val accuracy 0.995 topk_dict {'top1': 0.995} is_best True lr [0.001]
training epoch 20 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 21 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best True lr [0.001]
training epoch 22 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 23 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best False lr [0.001]
training epoch 24 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 25 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
training epoch 26 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 27 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 28 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 29 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 30 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 31 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 32 val accuracy 0.995 topk_dict {'top1': 0.995} is_best False lr [0.001]
training epoch 33 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 34 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 35 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 36 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best False lr [0.001]
training epoch 37 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 38 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 39 val accuracy 0.996 topk_dict {'top1': 0.996} is_best True lr [0.001]
training epoch 40 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 41 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 42 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 43 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 44 val accuracy 0.996 topk_dict {'top1': 0.996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 46 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 47 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 48 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 49 val accuracy 0.9946 topk_dict {'top1': 0.9946} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.996200)
finished training. finished 50 epochs. accuracy 0.9962 topk_dict {'top1': 0.9962}
start iteration 16
[activation mean]: block to remove picked: 7, with score 0.133249. All blocks and scores: [(7, 0.13324902951717377), (15, 0.14568926207721233), (9, 0.15212392434477806), (17, 0.15393211133778095), (43, 0.15658339485526085), (4, 0.16188311204314232), (40, 0.16281280107796192), (14, 0.16666647419333458), (6, 0.16774657927453518), (42, 0.1696622520685196), (13, 0.17055783234536648), (3, 0.17316998727619648), (44, 0.17555385828018188), (16, 0.17750567011535168), (46, 0.17762853018939495), (45, 0.17885934934020042), (39, 0.17919345572590828), (11, 0.17933840863406658), (8, 0.18074893951416016), (19, 0.18102111667394638), (20, 0.18142874352633953), (38, 0.1825043521821499), (2, 0.18331882916390896), (0, 0.18695111759006977), (1, 0.19521480984985828), (37, 0.19633057713508606), (48, 0.2053781859576702), (47, 0.20634687691926956), (10, 0.21190455555915833), (49, 0.21291271410882473), (12, 0.21543029323220253), (50, 0.2234823778271675), (5, 0.24183390475809574), (51, 0.25748201832175255), (52, 0.2773503437638283), (18, 0.5492442548274994), (36, 0.5681286975741386), (53, 0.6369678825139999)]
computing accuracy for after removing block 7 . block score: 0.13324902951717377
removed block 7 current accuracy 0.9942 loss from initial  0.005800000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 15, with score 0.145399. All blocks and scores: [(15, 0.14539893344044685), (17, 0.14639853686094284), (43, 0.15181771479547024), (9, 0.15414287522435188), (40, 0.16029287315905094), (13, 0.16103346832096577), (14, 0.16158015094697475), (4, 0.16188311204314232), (42, 0.1641708593815565), (6, 0.16774657927453518), (46, 0.17153188027441502), (16, 0.17204934172332287), (3, 0.17316998727619648), (44, 0.17427659779787064), (11, 0.17439045384526253), (45, 0.17535018362104893), (39, 0.17775746807456017), (20, 0.177912387996912), (19, 0.17840366810560226), (8, 0.17948312684893608), (38, 0.18202173709869385), (2, 0.18331882916390896), (0, 0.18695111759006977), (37, 0.1910822056233883), (1, 0.19521480984985828), (48, 0.1984269730746746), (47, 0.20400030724704266), (12, 0.20884222351014614), (49, 0.21059767715632915), (10, 0.21213093772530556), (50, 0.21916789188981056), (5, 0.24183390475809574), (51, 0.25529246032238007), (52, 0.27529409155249596), (18, 0.5441379174590111), (36, 0.5584654957056046), (53, 0.6455796658992767)]
computing accuracy for after removing block 15 . block score: 0.14539893344044685
removed block 15 current accuracy 0.9888 loss from initial  0.011199999999999988
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 17, with score 0.147060. All blocks and scores: [(17, 0.14705964550375938), (43, 0.1536811050027609), (9, 0.15414287522435188), (40, 0.15837603248655796), (13, 0.16103346832096577), (42, 0.16144570335745811), (14, 0.16158015094697475), (4, 0.16188311204314232), (6, 0.16774657927453518), (44, 0.17162702605128288), (20, 0.17196970246732235), (3, 0.17316998727619648), (11, 0.17439045384526253), (46, 0.17456135153770447), (45, 0.17547236569225788), (16, 0.17698764614760876), (39, 0.17706241831183434), (19, 0.1789658349007368), (8, 0.17948312684893608), (38, 0.18238329701125622), (2, 0.18331882916390896), (0, 0.18695111759006977), (37, 0.19316868670284748), (1, 0.19521480984985828), (48, 0.19959385320544243), (47, 0.20488395728170872), (12, 0.20884222351014614), (49, 0.21044053882360458), (10, 0.21213093772530556), (50, 0.2199048399925232), (5, 0.24183390475809574), (51, 0.2555208243429661), (52, 0.2760521173477173), (18, 0.5410242974758148), (36, 0.5568123310804367), (53, 0.6446392014622688)]
computing accuracy for after removing block 17 . block score: 0.14705964550375938
removed block 17 current accuracy 0.9812 loss from initial  0.01880000000000004
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 43, with score 0.147205. All blocks and scores: [(43, 0.14720525033771992), (40, 0.15180797688663006), (42, 0.15289864875376225), (9, 0.15414287522435188), (13, 0.16103346832096577), (14, 0.16158015094697475), (4, 0.16188311204314232), (44, 0.16301332227885723), (20, 0.16610117629170418), (6, 0.16774657927453518), (45, 0.1704278253018856), (39, 0.17222710140049458), (3, 0.17316998727619648), (46, 0.17348583601415157), (11, 0.17439045384526253), (16, 0.17698764614760876), (19, 0.17717614583671093), (38, 0.17782645486295223), (8, 0.17948312684893608), (2, 0.18331882916390896), (37, 0.18626510724425316), (0, 0.18695111759006977), (48, 0.19378476776182652), (1, 0.19521480984985828), (47, 0.2026233933866024), (49, 0.2058387640863657), (12, 0.20884222351014614), (10, 0.21213093772530556), (50, 0.2146569062024355), (5, 0.24183390475809574), (51, 0.25321706011891365), (52, 0.2734411060810089), (18, 0.5261374190449715), (36, 0.5380515903234482), (53, 0.6477484554052353)]
computing accuracy for after removing block 43 . block score: 0.14720525033771992
removed block 43 current accuracy 0.9784 loss from initial  0.021599999999999953
since last training loss: 0.017799999999999927 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 40, with score 0.151808. All blocks and scores: [(40, 0.15180797688663006), (42, 0.15289864875376225), (9, 0.15414287522435188), (13, 0.16103346832096577), (14, 0.16158015094697475), (4, 0.16188311204314232), (44, 0.16287987306714058), (20, 0.16610117629170418), (6, 0.16774657927453518), (45, 0.16981348022818565), (46, 0.17123455740511417), (39, 0.17222710140049458), (3, 0.17316998727619648), (11, 0.17439045384526253), (16, 0.17698764614760876), (19, 0.17717614583671093), (38, 0.17782645486295223), (8, 0.17948312684893608), (2, 0.18331882916390896), (37, 0.18626510724425316), (0, 0.18695111759006977), (48, 0.19349089451134205), (1, 0.19521480984985828), (47, 0.2015148252248764), (49, 0.20273096673190594), (12, 0.20884222351014614), (50, 0.2118038758635521), (10, 0.21213093772530556), (5, 0.24183390475809574), (51, 0.2502042427659035), (52, 0.26951904967427254), (18, 0.5261374190449715), (36, 0.5380515903234482), (53, 0.6675057709217072)]
computing accuracy for after removing block 40 . block score: 0.15180797688663006
removed block 40 current accuracy 0.97 loss from initial  0.030000000000000027
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 42, with score 0.147583. All blocks and scores: [(42, 0.14758341014385223), (9, 0.15414287522435188), (13, 0.16103346832096577), (14, 0.16158015094697475), (4, 0.16188311204314232), (44, 0.16313070245087147), (46, 0.16543562337756157), (20, 0.16610117629170418), (45, 0.16679520532488823), (6, 0.16774657927453518), (39, 0.17222710140049458), (3, 0.17316998727619648), (11, 0.17439045384526253), (16, 0.17698764614760876), (19, 0.17717614583671093), (38, 0.17782645486295223), (8, 0.17948312684893608), (2, 0.18331882916390896), (37, 0.18626510724425316), (48, 0.1867956519126892), (0, 0.18695111759006977), (1, 0.19521480984985828), (49, 0.19968532398343086), (47, 0.20088133960962296), (50, 0.20559939555823803), (12, 0.20884222351014614), (10, 0.21213093772530556), (5, 0.24183390475809574), (51, 0.24786456860601902), (52, 0.26604462414979935), (18, 0.5261374190449715), (36, 0.5380515903234482), (53, 0.6965283006429672)]
computing accuracy for after removing block 42 . block score: 0.14758341014385223
removed block 42 current accuracy 0.9576 loss from initial  0.04239999999999999
since last training loss: 0.03859999999999997 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 9, with score 0.154143. All blocks and scores: [(9, 0.15414287522435188), (13, 0.16103346832096577), (14, 0.16158015094697475), (4, 0.16188311204314232), (44, 0.16242926381528378), (46, 0.16478828713297844), (20, 0.16610117629170418), (45, 0.1667775921523571), (6, 0.16774657927453518), (39, 0.17222710140049458), (3, 0.17316998727619648), (11, 0.17439045384526253), (16, 0.17698764614760876), (19, 0.17717614583671093), (38, 0.17782645486295223), (8, 0.17948312684893608), (2, 0.18331882916390896), (48, 0.18347831070423126), (37, 0.18626510724425316), (0, 0.18695111759006977), (1, 0.19521480984985828), (49, 0.1977643072605133), (47, 0.19883074052631855), (50, 0.20326653309166431), (12, 0.20884222351014614), (10, 0.21213093772530556), (5, 0.24183390475809574), (51, 0.24398048594594002), (52, 0.2617388740181923), (18, 0.5261374190449715), (36, 0.5380515903234482), (53, 0.7156480997800827)]
computing accuracy for after removing block 9 . block score: 0.15414287522435188
removed block 9 current accuracy 0.9402 loss from initial  0.059799999999999964
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 44, with score 0.156552. All blocks and scores: [(44, 0.15655178017914295), (46, 0.1578457411378622), (13, 0.15866336971521378), (14, 0.1588332336395979), (4, 0.16188311204314232), (45, 0.1644398719072342), (20, 0.1648983173072338), (16, 0.16541977412998676), (6, 0.16774657927453518), (39, 0.16871828772127628), (11, 0.16974452883005142), (48, 0.17278234846889973), (3, 0.17316998727619648), (38, 0.17432381212711334), (37, 0.17663375101983547), (8, 0.17948312684893608), (19, 0.18143640644848347), (2, 0.18331882916390896), (0, 0.18695111759006977), (49, 0.19362332858145237), (1, 0.19521480984985828), (50, 0.19558081403374672), (47, 0.19866761937737465), (12, 0.19895851984620094), (10, 0.21248443610966206), (51, 0.24080638028681278), (5, 0.24183390475809574), (52, 0.25787481665611267), (36, 0.525757759809494), (18, 0.5261325538158417), (53, 0.7194738388061523)]
computing accuracy for after removing block 44 . block score: 0.15655178017914295
removed block 44 current accuracy 0.919 loss from initial  0.08099999999999996
training start
training epoch 0 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 1 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best True lr [0.001]
training epoch 2 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 3 val accuracy 0.9874 topk_dict {'top1': 0.9874} is_best True lr [0.001]
training epoch 4 val accuracy 0.9868 topk_dict {'top1': 0.9868} is_best False lr [0.001]
training epoch 5 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 6 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best True lr [0.001]
training epoch 7 val accuracy 0.9882 topk_dict {'top1': 0.9882} is_best False lr [0.001]
training epoch 8 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 9 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best True lr [0.001]
training epoch 10 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 11 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 12 val accuracy 0.9896 topk_dict {'top1': 0.9896} is_best False lr [0.001]
training epoch 13 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 14 val accuracy 0.9902 topk_dict {'top1': 0.9902} is_best True lr [0.001]
training epoch 15 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best True lr [0.001]
training epoch 16 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 17 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 18 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 19 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 20 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 21 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 22 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 23 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 24 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 25 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 26 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 27 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 28 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 29 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 30 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 31 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 32 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 33 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 34 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best True lr [0.001]
training epoch 35 val accuracy 0.9926 topk_dict {'top1': 0.9926} is_best False lr [0.001]
training epoch 36 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
training epoch 37 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 38 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best False lr [0.001]
training epoch 39 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best False lr [0.001]
training epoch 40 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best True lr [0.001]
training epoch 41 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 42 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 43 val accuracy 0.993 topk_dict {'top1': 0.993} is_best True lr [0.001]
training epoch 44 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 45 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 46 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best False lr [0.001]
training epoch 47 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best False lr [0.001]
training epoch 48 val accuracy 0.9928 topk_dict {'top1': 0.9928} is_best False lr [0.001]
training epoch 49 val accuracy 0.9922 topk_dict {'top1': 0.9922} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.993400)
finished training. finished 50 epochs. accuracy 0.9934 topk_dict {'top1': 0.9934}
start iteration 24
[activation mean]: block to remove picked: 4, with score 0.159940. All blocks and scores: [(4, 0.15994036011397839), (13, 0.16531548649072647), (6, 0.1663837991654873), (14, 0.1685338094830513), (3, 0.17103946395218372), (2, 0.17524467408657074), (16, 0.17639575712382793), (11, 0.17812337167561054), (0, 0.180998083204031), (8, 0.18302853032946587), (46, 0.18741007149219513), (45, 0.19011376984417439), (1, 0.19039855897426605), (38, 0.19484498724341393), (19, 0.19511418603360653), (39, 0.19538939371705055), (20, 0.1997165773063898), (10, 0.20379437878727913), (37, 0.2089130450040102), (12, 0.20903249457478523), (48, 0.2115793526172638), (47, 0.21202228590846062), (49, 0.21845980547368526), (50, 0.22859816625714302), (5, 0.24462745897471905), (51, 0.26053794100880623), (52, 0.28098098561167717), (18, 0.5215965583920479), (36, 0.5478467866778374), (53, 0.6488988250494003)]
computing accuracy for after removing block 4 . block score: 0.15994036011397839
removed block 4 current accuracy 0.9884 loss from initial  0.011600000000000055
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 13, with score 0.165164. All blocks and scores: [(13, 0.16516409255564213), (14, 0.16713123209774494), (16, 0.16930202953517437), (3, 0.17103946395218372), (6, 0.17306933738291264), (11, 0.17482859455049038), (2, 0.17524467408657074), (0, 0.180998083204031), (8, 0.18586244247853756), (46, 0.18992442823946476), (1, 0.19039855897426605), (45, 0.19091192446649075), (38, 0.19486020505428314), (39, 0.1958419606089592), (20, 0.20065669156610966), (19, 0.20110098831355572), (10, 0.2053176388144493), (12, 0.2073506861925125), (47, 0.209852434694767), (48, 0.2123053688555956), (37, 0.2128765843808651), (49, 0.2170667853206396), (50, 0.22713433019816875), (5, 0.25180282816290855), (51, 0.25907596200704575), (52, 0.27971064671874046), (18, 0.5257426798343658), (36, 0.5518335700035095), (53, 0.6474383547902107)]
computing accuracy for after removing block 13 . block score: 0.16516409255564213
removed block 13 current accuracy 0.9782 loss from initial  0.02180000000000004
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 3, with score 0.171039. All blocks and scores: [(3, 0.17103946395218372), (6, 0.17306933738291264), (11, 0.17482859455049038), (2, 0.17524467408657074), (16, 0.1786918956786394), (0, 0.180998083204031), (8, 0.18586244247853756), (14, 0.18803906068205833), (45, 0.1884930320084095), (46, 0.19023016467690468), (1, 0.19039855897426605), (39, 0.1959171500056982), (20, 0.19597606733441353), (38, 0.1969095841050148), (19, 0.20299919322133064), (10, 0.2053176388144493), (12, 0.2073506861925125), (47, 0.20888501219451427), (48, 0.21022840775549412), (49, 0.21368721313774586), (37, 0.2150187585502863), (50, 0.2251044660806656), (5, 0.25180282816290855), (51, 0.256937675178051), (52, 0.27702460810542107), (18, 0.5185371562838554), (36, 0.5468996688723564), (53, 0.6450828537344933)]
computing accuracy for after removing block 3 . block score: 0.17103946395218372
removed block 3 current accuracy 0.921 loss from initial  0.07899999999999996
since last training loss: 0.07239999999999991 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 16, with score 0.165306. All blocks and scores: [(16, 0.16530634835362434), (11, 0.1719103679060936), (2, 0.17524467408657074), (6, 0.17609344236552715), (14, 0.1794818937778473), (0, 0.180998083204031), (45, 0.18111965246498585), (8, 0.1832740344107151), (20, 0.18815097212791443), (46, 0.18875079043209553), (39, 0.1887748558074236), (1, 0.19039855897426605), (38, 0.19194915890693665), (47, 0.19976036623120308), (19, 0.2001245729625225), (12, 0.20586504228413105), (48, 0.205989433452487), (49, 0.2094024084508419), (10, 0.2100514993071556), (50, 0.21911199018359184), (37, 0.21943801268935204), (51, 0.24913678877055645), (5, 0.25742851570248604), (52, 0.2728572189807892), (18, 0.5091397613286972), (36, 0.544099472463131), (53, 0.6581313982605934)]
computing accuracy for after removing block 16 . block score: 0.16530634835362434
removed block 16 current accuracy 0.8484 loss from initial  0.15159999999999996
since last training loss: 0.1449999999999999 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 11, with score 0.171910. All blocks and scores: [(11, 0.1719103679060936), (2, 0.17524467408657074), (6, 0.17609344236552715), (14, 0.1794818937778473), (45, 0.17996895499527454), (0, 0.180998083204031), (20, 0.18297367170453072), (8, 0.1832740344107151), (38, 0.1886263620108366), (39, 0.18876778706908226), (1, 0.19039855897426605), (46, 0.19478429295122623), (47, 0.1987949013710022), (19, 0.20187848806381226), (49, 0.2019323892891407), (48, 0.20555548928678036), (12, 0.20586504228413105), (10, 0.2100514993071556), (37, 0.21794847026467323), (50, 0.2184072807431221), (51, 0.24441598542034626), (5, 0.25742851570248604), (52, 0.2679981365799904), (18, 0.5005722157657146), (36, 0.5257999524474144), (53, 0.6554995849728584)]
computing accuracy for after removing block 11 . block score: 0.1719103679060936
removed block 11 current accuracy 0.8312 loss from initial  0.16879999999999995
since last training loss: 0.1621999999999999 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 2, with score 0.175245. All blocks and scores: [(2, 0.17524467408657074), (6, 0.17609344236552715), (20, 0.17986752837896347), (0, 0.180998083204031), (45, 0.18104870803654194), (14, 0.1832489427179098), (8, 0.1832740344107151), (39, 0.18606196157634258), (38, 0.18897993303835392), (46, 0.18987521156668663), (1, 0.19039855897426605), (12, 0.1965507585555315), (49, 0.19932121969759464), (48, 0.19983002915978432), (47, 0.20242339745163918), (37, 0.20976968482136726), (10, 0.2100514993071556), (19, 0.21188992075622082), (50, 0.21589715592563152), (51, 0.24645126052200794), (5, 0.25742851570248604), (52, 0.2664330489933491), (18, 0.5075447410345078), (36, 0.5267616584897041), (53, 0.6688971593976021)]
computing accuracy for after removing block 2 . block score: 0.17524467408657074
removed block 2 current accuracy 0.7682 loss from initial  0.2318
since last training loss: 0.22519999999999996 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 20, with score 0.169761. All blocks and scores: [(20, 0.16976094245910645), (6, 0.17388801090419292), (45, 0.17537746392190456), (14, 0.17598487623035908), (8, 0.17952443473041058), (39, 0.18070773221552372), (0, 0.180998083204031), (38, 0.1830675397068262), (46, 0.1832353100180626), (12, 0.18775304406881332), (1, 0.19039855897426605), (48, 0.19184739142656326), (49, 0.19289087131619453), (37, 0.19908163882791996), (47, 0.20278318598866463), (50, 0.20918362773954868), (10, 0.21141167543828487), (19, 0.2130682971328497), (51, 0.24382930994033813), (5, 0.2550066225230694), (52, 0.26114436239004135), (18, 0.49419065564870834), (36, 0.5119098871946335), (53, 0.6826884299516678)]
computing accuracy for after removing block 20 . block score: 0.16976094245910645
removed block 20 current accuracy 0.705 loss from initial  0.29500000000000004
since last training loss: 0.2884 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 45, with score 0.170237. All blocks and scores: [(45, 0.17023670114576817), (46, 0.17221841774880886), (39, 0.17287044785916805), (6, 0.17388801090419292), (38, 0.17450877279043198), (14, 0.17598487623035908), (8, 0.17952443473041058), (0, 0.180998083204031), (48, 0.1826280951499939), (12, 0.18775304406881332), (49, 0.18823313526809216), (1, 0.19039855897426605), (47, 0.19456828944385052), (37, 0.20040886476635933), (50, 0.2005954533815384), (10, 0.21141167543828487), (19, 0.2130682971328497), (51, 0.23905467242002487), (52, 0.2539123669266701), (5, 0.2550066225230694), (18, 0.49419065564870834), (36, 0.5088167935609818), (53, 0.6893633902072906)]
computing accuracy for after removing block 45 . block score: 0.17023670114576817
removed block 45 current accuracy 0.6754 loss from initial  0.3246
since last training loss: 0.31799999999999995 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 46, with score 0.162453. All blocks and scores: [(46, 0.16245293989777565), (39, 0.17287044785916805), (6, 0.17388801090419292), (48, 0.17428446933627129), (38, 0.17450877279043198), (14, 0.17598487623035908), (8, 0.17952443473041058), (0, 0.180998083204031), (49, 0.1839176770299673), (12, 0.18775304406881332), (1, 0.19039855897426605), (50, 0.1941160000860691), (47, 0.19532626681029797), (37, 0.20040886476635933), (10, 0.21141167543828487), (19, 0.2130682971328497), (51, 0.23264975100755692), (52, 0.24978875741362572), (5, 0.2550066225230694), (18, 0.49419065564870834), (36, 0.5088167935609818), (53, 0.7561669498682022)]
computing accuracy for after removing block 46 . block score: 0.16245293989777565
removed block 46 current accuracy 0.6376 loss from initial  0.36240000000000006
training start
training epoch 0 val accuracy 0.9642 topk_dict {'top1': 0.9642} is_best True lr [0.001]
training epoch 1 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best True lr [0.001]
training epoch 2 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best True lr [0.001]
training epoch 3 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 4 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 5 val accuracy 0.9764 topk_dict {'top1': 0.9764} is_best False lr [0.001]
training epoch 6 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 7 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 8 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 9 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best False lr [0.001]
training epoch 10 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best True lr [0.001]
training epoch 11 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 12 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 13 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 14 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 15 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 16 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 17 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 18 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 19 val accuracy 0.98 topk_dict {'top1': 0.98} is_best False lr [0.001]
training epoch 20 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best True lr [0.001]
training epoch 21 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best True lr [0.001]
training epoch 22 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 23 val accuracy 0.982 topk_dict {'top1': 0.982} is_best True lr [0.001]
training epoch 24 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best True lr [0.001]
training epoch 25 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 26 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 27 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 28 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 29 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 30 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 31 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 32 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best True lr [0.001]
training epoch 33 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 34 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 35 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best True lr [0.001]
training epoch 36 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 37 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 38 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 39 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best False lr [0.001]
training epoch 40 val accuracy 0.9838 topk_dict {'top1': 0.9838} is_best False lr [0.001]
training epoch 41 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 42 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best True lr [0.001]
training epoch 43 val accuracy 0.9848 topk_dict {'top1': 0.9848} is_best False lr [0.001]
training epoch 44 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
training epoch 45 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 46 val accuracy 0.9836 topk_dict {'top1': 0.9836} is_best False lr [0.001]
training epoch 47 val accuracy 0.983 topk_dict {'top1': 0.983} is_best False lr [0.001]
training epoch 48 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 49 val accuracy 0.9844 topk_dict {'top1': 0.9844} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.985000)
finished training. finished 50 epochs. accuracy 0.985 topk_dict {'top1': 0.985}
