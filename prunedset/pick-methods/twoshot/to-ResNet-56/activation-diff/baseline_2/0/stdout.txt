start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007452. All blocks and scores: [(26, 0.007451974903233349), (20, 0.008696247939951718), (27, 0.009198295301757753), (31, 0.009675504290498793), (29, 0.01003042096272111), (22, 0.010588386561721563), (23, 0.010651617776602507), (21, 0.010725351166911423), (28, 0.011828799964860082), (24, 0.01205872860737145), (17, 0.012199451099149883), (19, 0.013177948421798646), (33, 0.013279786915518343), (35, 0.013483816175721586), (25, 0.013839342282153666), (11, 0.013912909082137048), (32, 0.013956584967672825), (16, 0.014766238047741354), (30, 0.015491604339331388), (9, 0.01554769033100456), (40, 0.015986334765329957), (34, 0.016656322870403528), (39, 0.017517176223918796), (44, 0.018641565926373005), (37, 0.01879900461062789), (43, 0.018935034051537514), (42, 0.019514338113367558), (41, 0.01959002111107111), (45, 0.019901464693248272), (38, 0.020000957418233156), (14, 0.020047536119818687), (8, 0.02166792075149715), (7, 0.021806211210787296), (15, 0.024833297124132514), (46, 0.025212790817022324), (10, 0.025900362292304635), (49, 0.027116776444017887), (48, 0.027511440450325608), (47, 0.027820878429338336), (50, 0.028723245952278376), (51, 0.031788796186447144), (12, 0.03298326954245567), (5, 0.03333624405786395), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.043747184332460165), (52, 0.05253404378890991), (13, 0.05450336029753089), (2, 0.06120603624731302), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.2727429270744324), (18, 0.30386047810316086), (53, 0.8891632854938507)]
computing accuracy for after removing block 26 . block score: 0.007451974903233349
removed block 26 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008696. All blocks and scores: [(20, 0.00869624805636704), (27, 0.009569326997734606), (31, 0.009736894513480365), (29, 0.01037009828723967), (22, 0.010588386445306242), (23, 0.010651617776602507), (21, 0.010725351050496101), (24, 0.01205872860737145), (28, 0.01206758536864072), (17, 0.01219945086631924), (19, 0.013177948421798646), (33, 0.013200338813476264), (35, 0.013297739089466631), (32, 0.013540126266889274), (25, 0.013839342049323022), (11, 0.013912909314967692), (16, 0.014766237698495388), (30, 0.015476007363758981), (9, 0.015547690563835204), (34, 0.01633565337397158), (40, 0.016489707631990314), (39, 0.018151729367673397), (44, 0.01880926568992436), (43, 0.01927204616367817), (37, 0.019370622700080276), (41, 0.019797631073743105), (42, 0.019846386276185513), (14, 0.0200475356541574), (38, 0.020208331756293774), (45, 0.020282168872654438), (8, 0.02166792005300522), (7, 0.02180621074512601), (15, 0.024833296658471227), (46, 0.025710680289193988), (10, 0.025900360895320773), (49, 0.027175756404176354), (48, 0.02780761383473873), (47, 0.02826968370936811), (50, 0.02872340497560799), (51, 0.031959859654307365), (12, 0.032983270939439535), (5, 0.033336243126541376), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.04374718386679888), (52, 0.052661973517388105), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250694096088), (0, 0.14636892266571522), (36, 0.2777215540409088), (18, 0.30386048182845116), (53, 0.8825649693608284)]
computing accuracy for after removing block 20 . block score: 0.00869624805636704
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009247. All blocks and scores: [(27, 0.009247071226127446), (31, 0.009490355383604765), (29, 0.010141469771042466), (23, 0.010720769292674959), (21, 0.010873694904148579), (22, 0.010951440082862973), (28, 0.011602517799474299), (17, 0.012199450749903917), (24, 0.012428545043803751), (33, 0.013006685767322779), (32, 0.013030687347054482), (35, 0.013141493196599185), (19, 0.013177949003875256), (11, 0.013912908500060439), (25, 0.014337054453790188), (30, 0.01473109913058579), (16, 0.014766238164156675), (9, 0.01554769033100456), (34, 0.015950741712003946), (40, 0.01667696749791503), (39, 0.01812331867404282), (44, 0.019042733358219266), (43, 0.019525704672560096), (37, 0.01953594689257443), (41, 0.020023913588374853), (42, 0.020024611614644527), (14, 0.02004753495566547), (38, 0.02022995171137154), (45, 0.020495346980169415), (8, 0.02166792075149715), (7, 0.02180621074512601), (15, 0.02483329619280994), (10, 0.02590036136098206), (46, 0.02600882202386856), (49, 0.027358209248632193), (48, 0.027944064000621438), (47, 0.02855871361680329), (50, 0.02887403266504407), (51, 0.03197578340768814), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968294009566), (4, 0.03804349293932319), (3, 0.04374718200415373), (52, 0.053193129133433104), (13, 0.05450336076319218), (2, 0.061206033919006586), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.27894822880625725), (18, 0.30386047810316086), (53, 0.874676525592804)]
computing accuracy for after removing block 27 . block score: 0.009247071226127446
removed block 27 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009703. All blocks and scores: [(31, 0.009703440242446959), (29, 0.01040199410635978), (23, 0.010720769292674959), (21, 0.010873695136979222), (22, 0.01095143985003233), (28, 0.01190426992252469), (17, 0.01219945086631924), (24, 0.012428545043803751), (33, 0.012989282724447548), (35, 0.01303201261907816), (32, 0.013032321236096323), (19, 0.013177948538213968), (11, 0.013912908732891083), (25, 0.014337054803036153), (30, 0.014530949643813074), (16, 0.01476623781491071), (34, 0.015523915993981063), (9, 0.01554769033100456), (40, 0.017428284278139472), (39, 0.018635700223967433), (44, 0.01932337530888617), (43, 0.019895021803677082), (14, 0.020047535886988044), (37, 0.020162818022072315), (38, 0.02019783016294241), (42, 0.020295765716582537), (41, 0.020331317791715264), (45, 0.020738494815304875), (8, 0.021667920285835862), (7, 0.021806210512295365), (15, 0.024833296425640583), (10, 0.025900361593812704), (46, 0.026298312470316887), (49, 0.02737220819108188), (48, 0.028113745152950287), (47, 0.02882404252886772), (50, 0.029082486405968666), (51, 0.032043971586972475), (12, 0.03298327047377825), (5, 0.033336244989186525), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.05334703577682376), (13, 0.05450336076319218), (2, 0.06120603624731302), (1, 0.07061250787228346), (0, 0.14636892080307007), (36, 0.2865508534014225), (18, 0.30386048182845116), (53, 0.873922660946846)]
computing accuracy for after removing block 31 . block score: 0.009703440242446959
removed block 31 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010402. All blocks and scores: [(29, 0.010401993873529136), (23, 0.01072076940909028), (21, 0.010873694904148579), (22, 0.010951440199278295), (28, 0.011904269456863403), (17, 0.012199451099149883), (24, 0.012428545160219073), (33, 0.01307527325116098), (19, 0.013177949003875256), (32, 0.013221941189840436), (35, 0.013311224523931742), (11, 0.013912909082137048), (25, 0.014337055035866797), (30, 0.01453094941098243), (16, 0.014766237698495388), (34, 0.01510901446454227), (9, 0.015547690447419882), (40, 0.017963848309591413), (44, 0.019172759959474206), (39, 0.019229266559705138), (38, 0.019627248402684927), (43, 0.019773422041907907), (42, 0.02001499035395682), (14, 0.0200475356541574), (41, 0.020369442645460367), (45, 0.020458239829167724), (37, 0.020535161951556802), (8, 0.021667920518666506), (7, 0.021806210512295365), (15, 0.02483329689130187), (10, 0.02590036136098206), (46, 0.026439889101311564), (49, 0.02731970837339759), (48, 0.02830672264099121), (47, 0.028651983244344592), (50, 0.029288705671206117), (51, 0.03214396582916379), (12, 0.03298327000811696), (5, 0.03333624452352524), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.052529138047248125), (13, 0.054503362625837326), (2, 0.061206033919006586), (1, 0.07061250880360603), (0, 0.14636892266571522), (36, 0.29571831226348877), (18, 0.30386047810316086), (53, 0.8852703794836998)]
computing accuracy for after removing block 29 . block score: 0.010401993873529136
removed block 29 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010721. All blocks and scores: [(23, 0.010720769059844315), (21, 0.0108736950205639), (22, 0.01095143926795572), (28, 0.011904270155355334), (17, 0.012199450517073274), (24, 0.012428545160219073), (33, 0.013095533475279808), (19, 0.013177949003875256), (32, 0.013331790687516332), (35, 0.013342682155780494), (11, 0.013912908965721726), (25, 0.014337054919451475), (16, 0.014766237465664744), (34, 0.014780625351704657), (30, 0.0148480812786147), (9, 0.015547690098173916), (40, 0.017947439569979906), (44, 0.018570148618891835), (38, 0.018818871583789587), (39, 0.01928418385796249), (42, 0.019550167489796877), (43, 0.019667528104037046), (41, 0.02001996780745685), (14, 0.020047535886988044), (45, 0.020145078422501683), (37, 0.020778114907443523), (8, 0.02166792075149715), (7, 0.021806211210787296), (15, 0.0248332975897938), (10, 0.025900360895320773), (46, 0.026351965265348554), (49, 0.026999606285244226), (48, 0.02782399649731815), (47, 0.028508094139397144), (50, 0.02933459240011871), (51, 0.03217176906764507), (12, 0.03298326954245567), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.051905466709285975), (13, 0.05450336076319218), (2, 0.061206037644296885), (1, 0.07061250694096088), (0, 0.14636891894042492), (36, 0.299510408192873), (18, 0.30386047437787056), (53, 0.8962140157818794)]
computing accuracy for after removing block 23 . block score: 0.010720769059844315
removed block 23 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010874. All blocks and scores: [(21, 0.010873695136979222), (22, 0.010951440082862973), (28, 0.011454623891040683), (24, 0.011984122917056084), (17, 0.01219945086631924), (35, 0.013001650921069086), (32, 0.013018106343224645), (33, 0.013115601381286979), (19, 0.013177948771044612), (25, 0.013824697234667838), (11, 0.013912908732891083), (30, 0.014240248361602426), (34, 0.014703377615660429), (16, 0.014766238164156675), (9, 0.01554768974892795), (40, 0.018065203446894884), (44, 0.018300466472283006), (38, 0.018600984010845423), (42, 0.019345170818269253), (43, 0.019551129546016455), (39, 0.019822366070002317), (45, 0.019911038223654032), (41, 0.020028739469125867), (14, 0.0200475356541574), (37, 0.02084772032685578), (8, 0.02166792075149715), (7, 0.02180621027946472), (15, 0.024833297124132514), (10, 0.02590036136098206), (46, 0.026478099636733532), (49, 0.02697809273377061), (48, 0.0275181676261127), (47, 0.028530240058898926), (50, 0.029085059417411685), (51, 0.03238660376518965), (12, 0.03298326954245567), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.04374718340113759), (52, 0.05187077587470412), (13, 0.05450335890054703), (2, 0.06120603438466787), (1, 0.07061250694096088), (0, 0.14636892080307007), (36, 0.3020646646618843), (18, 0.30386047065258026), (53, 0.8938302919268608)]
computing accuracy for after removing block 21 . block score: 0.010873695136979222
removed block 21 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010718. All blocks and scores: [(28, 0.010718231671489775), (22, 0.011124415090307593), (24, 0.011734541621990502), (17, 0.012199450982734561), (32, 0.012339043896645308), (35, 0.012350355391390622), (33, 0.012773355701938272), (19, 0.01317794865462929), (30, 0.013385720434598625), (25, 0.013581673381850123), (11, 0.013912908500060439), (34, 0.014493828755803406), (16, 0.014766237582080066), (9, 0.015547690563835204), (40, 0.018178855068981647), (44, 0.018340062350034714), (38, 0.01862968597561121), (42, 0.019575109239667654), (43, 0.019729839637875557), (39, 0.01983336010016501), (14, 0.0200475356541574), (45, 0.0200941888615489), (41, 0.020734292455017567), (37, 0.020795797696337104), (8, 0.021667920518666506), (7, 0.021806210977956653), (15, 0.02483329689130187), (10, 0.025900361128151417), (46, 0.02719624014571309), (49, 0.027292133076116443), (48, 0.027600203873589635), (47, 0.02890662639401853), (50, 0.029168642591685057), (51, 0.03279080893844366), (12, 0.03298327047377825), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349293932319), (3, 0.04374718340113759), (52, 0.05234553571790457), (13, 0.05450336076319218), (2, 0.061206037644296885), (1, 0.07061250787228346), (0, 0.14636891894042492), (18, 0.30386047810316086), (36, 0.3042290061712265), (53, 0.8967952653765678)]
computing accuracy for after removing block 28 . block score: 0.010718231671489775
removed block 28 current accuracy 0.99 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011124. All blocks and scores: [(22, 0.011124415090307593), (24, 0.011734541621990502), (32, 0.012095691752620041), (35, 0.012157876044511795), (17, 0.012199451215565205), (33, 0.013105916907079518), (19, 0.013177948771044612), (30, 0.013323650229722261), (25, 0.01358167314901948), (11, 0.013912909547798336), (34, 0.014369336306117475), (16, 0.01476623781491071), (9, 0.015547690447419882), (38, 0.01792138093151152), (44, 0.01819704077206552), (40, 0.01891227439045906), (42, 0.01936492556706071), (43, 0.019978849217295647), (14, 0.0200475356541574), (45, 0.020337820518761873), (39, 0.020597088616341352), (41, 0.020729141542688012), (37, 0.021321294363588095), (8, 0.02166792075149715), (7, 0.02180621144361794), (15, 0.02483329619280994), (10, 0.02590036205947399), (49, 0.027097658719867468), (48, 0.027195147704333067), (46, 0.02748569822870195), (47, 0.02907437179237604), (50, 0.029169490560889244), (12, 0.032983269076794386), (51, 0.0331334276124835), (5, 0.03333624405786395), (6, 0.03351968340575695), (4, 0.03804349387064576), (3, 0.04374718386679888), (52, 0.05157360201701522), (13, 0.05450336029753089), (2, 0.06120603438466787), (1, 0.07061250787228346), (0, 0.14636892266571522), (18, 0.30386047065258026), (36, 0.31568818911910057), (53, 0.9053315222263336)]
computing accuracy for after removing block 22 . block score: 0.011124415090307593
removed block 22 current accuracy 0.9804 loss from initial  0.01959999999999995
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.010824. All blocks and scores: [(24, 0.010824102559126914), (32, 0.011274677119217813), (35, 0.012037030071951449), (17, 0.012199450749903917), (30, 0.012747167842462659), (33, 0.013064955594018102), (25, 0.013176510110497475), (19, 0.013177949003875256), (11, 0.013912908965721726), (34, 0.014271511929109693), (16, 0.01476623781491071), (9, 0.015547689865343273), (38, 0.01757415011525154), (44, 0.017618532525375485), (42, 0.01886556763201952), (40, 0.01895146956667304), (43, 0.01948712021112442), (45, 0.019938055658712983), (14, 0.020047535188496113), (39, 0.02067698258906603), (41, 0.020799742778763175), (37, 0.020918888971209526), (8, 0.02166792075149715), (7, 0.02180621074512601), (15, 0.024833297356963158), (10, 0.025900360895320773), (49, 0.02698867116123438), (48, 0.027127153240144253), (46, 0.027369854971766472), (50, 0.02874125773087144), (47, 0.029024814255535603), (12, 0.03298327047377825), (51, 0.03313175914809108), (5, 0.03333624359220266), (6, 0.03351968294009566), (4, 0.038043493404984474), (3, 0.0437471829354763), (52, 0.05089538358151913), (13, 0.054503359366208315), (2, 0.06120603438466787), (1, 0.07061250507831573), (0, 0.14636892266571522), (18, 0.30386047437787056), (36, 0.3163903132081032), (53, 0.9149599894881248)]
computing accuracy for after removing block 24 . block score: 0.010824102559126914
removed block 24 current accuracy 0.9664 loss from initial  0.03359999999999996
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.010877. All blocks and scores: [(32, 0.010876586544327438), (35, 0.011955110356211662), (30, 0.012104445369914174), (17, 0.012199451099149883), (25, 0.013075435999780893), (19, 0.013177949120290577), (33, 0.01325787988025695), (11, 0.013912909314967692), (34, 0.014449171139858663), (16, 0.014766237698495388), (9, 0.015547690563835204), (38, 0.01698773866519332), (44, 0.017669430235400796), (42, 0.018743420485407114), (40, 0.01916838134638965), (43, 0.01985725574195385), (45, 0.019892358453944325), (14, 0.020047535421326756), (41, 0.0207320146728307), (37, 0.021041916916146874), (39, 0.021407435182482004), (8, 0.021667920285835862), (7, 0.021806211676448584), (15, 0.02483329689130187), (10, 0.025900361128151417), (49, 0.026679034112021327), (48, 0.0268447061534971), (46, 0.027388096787035465), (50, 0.028316201409325004), (47, 0.02873399737291038), (51, 0.03292590379714966), (12, 0.03298327000811696), (5, 0.03333624359220266), (6, 0.03351968387141824), (4, 0.03804349293932319), (3, 0.0437471829354763), (52, 0.049682377837598324), (13, 0.05450336169451475), (2, 0.061206037644296885), (1, 0.07061250787228346), (0, 0.14636892080307007), (18, 0.30386047810316086), (36, 0.3254365213215351), (53, 0.9151448979973793)]
computing accuracy for after removing block 32 . block score: 0.010876586544327438
removed block 32 current accuracy 0.9502 loss from initial  0.049799999999999955
since last training loss: 0.049799999999999955 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.012104. All blocks and scores: [(30, 0.012104446068406105), (17, 0.012199451099149883), (35, 0.012797020724974573), (25, 0.013075435417704284), (19, 0.013177948188968003), (33, 0.013797620427794755), (11, 0.01391290919855237), (34, 0.014519993332214653), (16, 0.014766237465664744), (9, 0.015547690447419882), (38, 0.01624030666425824), (44, 0.017033956944942474), (42, 0.018259100848808885), (40, 0.01946928258985281), (45, 0.019506812328472733), (43, 0.019664270104840398), (14, 0.020047535886988044), (41, 0.020211152033880353), (37, 0.020982666173949838), (39, 0.021373851224780083), (8, 0.021667920285835862), (7, 0.021806211210787296), (15, 0.024833297356963158), (10, 0.025900361826643348), (49, 0.02632763865403831), (48, 0.026497263927012682), (46, 0.027324117021635175), (50, 0.02800402487628162), (47, 0.028627989813685417), (51, 0.03261660737916827), (12, 0.032983269076794386), (5, 0.03333624359220266), (6, 0.03351968340575695), (4, 0.038043493404984474), (3, 0.043747182469815016), (52, 0.04806074220687151), (13, 0.05450336029753089), (2, 0.06120603671297431), (1, 0.07061250880360603), (0, 0.14636891894042492), (18, 0.30386047810316086), (36, 0.33333006128668785), (53, 0.9361404478549957)]
computing accuracy for after removing block 30 . block score: 0.012104446068406105
removed block 30 current accuracy 0.9186 loss from initial  0.08140000000000003
since last training loss: 0.08140000000000003 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 17, with score 0.012199. All blocks and scores: [(17, 0.012199451448395848), (25, 0.013075435883365571), (19, 0.013177948771044612), (35, 0.013523002970032394), (11, 0.013912908965721726), (34, 0.014766030013561249), (16, 0.014766238164156675), (33, 0.015034388285130262), (9, 0.015547690447419882), (38, 0.015858327271416783), (44, 0.016648652032017708), (42, 0.01781687792390585), (45, 0.019354375544935465), (43, 0.019491265062242746), (41, 0.020042051561176777), (14, 0.02004753495566547), (40, 0.020565516082569957), (8, 0.021667921217158437), (7, 0.02180621074512601), (37, 0.022225635824725032), (39, 0.022749602096155286), (15, 0.024833296658471227), (10, 0.025900361593812704), (49, 0.02600616170093417), (48, 0.026390113634988666), (46, 0.02736017433926463), (50, 0.027876119362190366), (47, 0.028576354030519724), (51, 0.03262453339993954), (12, 0.03298326954245567), (5, 0.033336243126541376), (6, 0.03351968387141824), (4, 0.038043493404984474), (3, 0.04374718479812145), (52, 0.04603598453104496), (13, 0.054503361228853464), (2, 0.06120603624731302), (1, 0.07061250787228346), (0, 0.14636892266571522), (18, 0.30386047065258026), (36, 0.3517293371260166), (53, 0.9536165222525597)]
computing accuracy for after removing block 17 . block score: 0.012199451448395848
removed block 17 current accuracy 0.9074 loss from initial  0.09260000000000002
since last training loss: 0.09260000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.012180. All blocks and scores: [(19, 0.012179647921584547), (25, 0.012272003688849509), (35, 0.013189252000302076), (11, 0.013912908849306405), (33, 0.014486355474218726), (34, 0.014641908113844693), (16, 0.014766237349249423), (9, 0.015547690796665847), (38, 0.015624886029399931), (44, 0.016568857477977872), (42, 0.0173870250582695), (45, 0.018840335309505463), (43, 0.01932032499462366), (14, 0.020047535421326756), (41, 0.02039071382023394), (40, 0.021592806559056044), (8, 0.021667920518666506), (7, 0.021806211210787296), (37, 0.022732951445505023), (39, 0.024223787477239966), (15, 0.02483329689130187), (49, 0.025589684955775738), (10, 0.025900361826643348), (48, 0.02611984731629491), (50, 0.027166033629328012), (46, 0.027381492545828223), (47, 0.02795734000392258), (51, 0.03151704557240009), (12, 0.03298327000811696), (5, 0.03333624266088009), (6, 0.03351968387141824), (4, 0.038043493404984474), (52, 0.04372498253360391), (3, 0.04374718386679888), (13, 0.05450336029753089), (2, 0.06120603624731302), (1, 0.07061250787228346), (0, 0.14636892080307007), (18, 0.31064050644636154), (36, 0.35844869911670685), (53, 0.94353898614645)]
computing accuracy for after removing block 19 . block score: 0.012179647921584547
removed block 19 current accuracy 0.886 loss from initial  0.11399999999999999
training start
training epoch 0 val accuracy 0.9934 topk_dict {'top1': 0.9934} is_best True lr [0.001]
training epoch 1 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 2 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 3 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 4 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 5 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 7 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 9 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 10 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 13 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 15 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 16 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 17 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 18 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 19 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 20 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 21 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 22 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 29 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 32 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 33 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 38 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 40 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 41 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 42 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 43 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 46 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 47 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 48 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 14
[activation diff]: block to remove picked: 11, with score 0.014085. All blocks and scores: [(11, 0.014085494331084192), (16, 0.015601023100316525), (9, 0.015622130129486322), (40, 0.01637810468673706), (33, 0.016886951867491007), (39, 0.017901086015626788), (44, 0.018220684491097927), (35, 0.018240090692415833), (43, 0.01843253942206502), (37, 0.018774118972942233), (42, 0.01902692182920873), (41, 0.01930750929750502), (45, 0.01948172366246581), (14, 0.019592833472415805), (38, 0.020313149550929666), (25, 0.020774864125996828), (7, 0.020973735488951206), (34, 0.021104865008965135), (8, 0.02143467590212822), (46, 0.024900622200220823), (15, 0.026175239589065313), (49, 0.02635929547250271), (10, 0.026391185354441404), (47, 0.02700674021616578), (48, 0.02712983824312687), (50, 0.02816520188935101), (51, 0.03090828168205917), (5, 0.0322543834336102), (12, 0.03238487662747502), (6, 0.03257728414610028), (4, 0.03821847587823868), (3, 0.04297929396852851), (52, 0.051206646021455526), (13, 0.053489561192691326), (2, 0.06062386138364673), (1, 0.066542181186378), (0, 0.14112673327326775), (36, 0.2669579088687897), (18, 0.2895093597471714), (53, 0.8837863504886627)]
computing accuracy for after removing block 11 . block score: 0.014085494331084192
removed block 11 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 9, with score 0.015622. All blocks and scores: [(9, 0.015622129780240357), (16, 0.015984934521839023), (40, 0.01618397911079228), (33, 0.016659256536513567), (39, 0.017300417413935065), (35, 0.017819579923525453), (44, 0.018072246806696057), (43, 0.01815175311639905), (37, 0.01830834010615945), (42, 0.018549500964581966), (14, 0.018712045392021537), (41, 0.01936363661661744), (45, 0.019623417872935534), (38, 0.01996449357829988), (25, 0.02018957259133458), (34, 0.02041592518799007), (7, 0.020973735954612494), (8, 0.02143467590212822), (46, 0.024876304203644395), (15, 0.026144002797082067), (10, 0.02639118582010269), (49, 0.02649939595721662), (48, 0.026578884106129408), (47, 0.026772718178108335), (50, 0.02795181074179709), (51, 0.030683258781209588), (12, 0.030771489487960935), (5, 0.03225438483059406), (6, 0.03257728461176157), (4, 0.038218476343899965), (3, 0.04297929536551237), (52, 0.05093435337767005), (13, 0.05147800641134381), (2, 0.060623859986662865), (1, 0.06654218211770058), (0, 0.14112673327326775), (36, 0.26476265862584114), (18, 0.281874381005764), (53, 0.8698216751217842)]
computing accuracy for after removing block 9 . block score: 0.015622129780240357
removed block 9 current accuracy 0.998 loss from initial  0.0020000000000000018
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 16, with score 0.014888. All blocks and scores: [(16, 0.014887818018905818), (40, 0.01550687209237367), (33, 0.016114626778289676), (39, 0.0163283278234303), (35, 0.016583143267780542), (14, 0.017094685696065426), (37, 0.017412391025573015), (43, 0.01752083725295961), (44, 0.017586152534931898), (42, 0.017948621418327093), (45, 0.01918861479498446), (38, 0.01941108307801187), (41, 0.019606044050306082), (34, 0.019669706467539072), (25, 0.019722696160897613), (7, 0.020973735954612494), (8, 0.021434675436466932), (46, 0.02440788340754807), (10, 0.02490875986404717), (15, 0.025711597641929984), (48, 0.025825455551967025), (47, 0.025948217837139964), (49, 0.026054689195007086), (50, 0.027609290555119514), (51, 0.02999288053251803), (12, 0.030168125638738275), (5, 0.0322543834336102), (6, 0.03257728414610028), (4, 0.03821847680956125), (3, 0.04297929396852851), (13, 0.0471345828846097), (52, 0.0493179839104414), (2, 0.06062385952100158), (1, 0.066542181186378), (0, 0.1411267388612032), (36, 0.2578701302409172), (18, 0.2704905830323696), (53, 0.8761235997080803)]
computing accuracy for after removing block 16 . block score: 0.014887818018905818
removed block 16 current accuracy 0.9948 loss from initial  0.005199999999999982
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.015250. All blocks and scores: [(40, 0.01525008783210069), (33, 0.015592128154821694), (39, 0.015958460047841072), (35, 0.016134475823491812), (14, 0.017094686161726713), (37, 0.017242017667740583), (44, 0.017543156864121556), (43, 0.017569479765370488), (42, 0.01788150006905198), (45, 0.019096112344413996), (34, 0.019410280045121908), (38, 0.019457191228866577), (25, 0.01986975409090519), (41, 0.02062588674016297), (7, 0.02097373572178185), (8, 0.02143467590212822), (46, 0.023740712320432067), (10, 0.02490875986404717), (48, 0.025285573676228523), (49, 0.025631063617765903), (47, 0.02568682376295328), (15, 0.025711596477776766), (50, 0.026955283479765058), (51, 0.029057491570711136), (12, 0.03016812540590763), (5, 0.03225438483059406), (6, 0.032577283680438995), (4, 0.03821847680956125), (3, 0.042979294434189796), (13, 0.04713458148762584), (52, 0.04808374773710966), (2, 0.06062386045232415), (1, 0.06654218304902315), (0, 0.14112673699855804), (36, 0.2571571171283722), (18, 0.27514663338661194), (53, 0.8810722753405571)]
computing accuracy for after removing block 40 . block score: 0.01525008783210069
removed block 40 current accuracy 0.9924 loss from initial  0.007600000000000051
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 33, with score 0.015592. All blocks and scores: [(33, 0.015592128038406372), (39, 0.01595845981501043), (35, 0.016134475590661168), (14, 0.01709468592889607), (37, 0.017242017900571227), (44, 0.018054660642519593), (43, 0.01810221723280847), (42, 0.01881723222322762), (45, 0.019136452581733465), (34, 0.01941027957946062), (38, 0.019457190996035933), (25, 0.01986975409090519), (7, 0.020973736187443137), (8, 0.02143467520363629), (41, 0.022480419604107738), (46, 0.024268676061183214), (10, 0.02490875916555524), (48, 0.02503371494822204), (15, 0.02571159740909934), (47, 0.02576794964261353), (49, 0.026050503132864833), (50, 0.027568371267989278), (51, 0.029527093516662717), (12, 0.030168126104399562), (5, 0.0322543834336102), (6, 0.03257728461176157), (4, 0.03821847680956125), (3, 0.042979294899851084), (13, 0.04713458102196455), (52, 0.047624054830521345), (2, 0.060623859986662865), (1, 0.066542181186378), (0, 0.1411267388612032), (36, 0.2571571134030819), (18, 0.27514662593603134), (53, 0.8983889147639275)]
computing accuracy for after removing block 33 . block score: 0.015592128038406372
removed block 33 current accuracy 0.9876 loss from initial  0.012399999999999967
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.016199. All blocks and scores: [(39, 0.016198583180084825), (37, 0.016768118366599083), (14, 0.017094686161726713), (44, 0.017260011984035373), (43, 0.017267398303374648), (35, 0.017419443698599935), (38, 0.01754780882038176), (42, 0.018230331828817725), (45, 0.018567075254395604), (34, 0.019417983014136553), (25, 0.01986975409090519), (7, 0.020973736187443137), (8, 0.021434675436466932), (41, 0.022333849454298615), (46, 0.0241024496499449), (48, 0.024280498502776027), (47, 0.024864526698365808), (10, 0.02490875916555524), (15, 0.025711596943438053), (49, 0.02640029089525342), (50, 0.027090254239737988), (51, 0.02950720372609794), (12, 0.030168126337230206), (5, 0.03225438389927149), (6, 0.03257728461176157), (4, 0.038218476343899965), (3, 0.04297929396852851), (52, 0.045798758044838905), (13, 0.047134580090641975), (2, 0.06062385952100158), (1, 0.066542181186378), (0, 0.1411267388612032), (36, 0.2676921598613262), (18, 0.27514663711190224), (53, 0.9224218055605888)]
computing accuracy for after removing block 39 . block score: 0.016198583180084825
removed block 39 current accuracy 0.9794 loss from initial  0.02059999999999995
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 37, with score 0.016768. All blocks and scores: [(37, 0.01676811883226037), (14, 0.017094685696065426), (44, 0.017309211427345872), (43, 0.01735783158801496), (35, 0.017419443698599935), (38, 0.017547809286043048), (45, 0.018607197562232614), (34, 0.019417983712628484), (42, 0.01953968429006636), (25, 0.019869754556566477), (7, 0.020973735954612494), (8, 0.02143467590212822), (41, 0.023316145641729236), (48, 0.023747896309942007), (46, 0.024334415327757597), (47, 0.024627989856526256), (10, 0.024908759631216526), (15, 0.025711596943438053), (49, 0.02666586358100176), (50, 0.026926758233457804), (51, 0.028920393669977784), (12, 0.030168125871568918), (5, 0.0322543834336102), (6, 0.032577285543084145), (4, 0.038218476343899965), (3, 0.042979294434189796), (52, 0.04565371386706829), (13, 0.0471345828846097), (2, 0.06062386045232415), (1, 0.06654218211770058), (0, 0.1411267388612032), (36, 0.2676921635866165), (18, 0.27514663338661194), (53, 0.9266521334648132)]
computing accuracy for after removing block 37 . block score: 0.01676811883226037
removed block 37 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.016442. All blocks and scores: [(44, 0.016442360589280725), (43, 0.016837693518027663), (14, 0.017094686161726713), (35, 0.017419443698599935), (45, 0.01767987059429288), (38, 0.01861782604828477), (34, 0.019417983246967196), (42, 0.019791246857494116), (25, 0.01986975409090519), (7, 0.020973735488951206), (8, 0.021434675436466932), (48, 0.02230464154854417), (47, 0.023425407242029905), (41, 0.02348611643537879), (46, 0.023608908290043473), (10, 0.024908759398385882), (50, 0.025362659245729446), (49, 0.02538112993352115), (15, 0.025711596477776766), (51, 0.026949117658659816), (12, 0.030168126337230206), (5, 0.03225438389927149), (6, 0.032577283680438995), (4, 0.03821847680956125), (52, 0.040778090711683035), (3, 0.04297929396852851), (13, 0.04713458102196455), (2, 0.060623858589679), (1, 0.06654218211770058), (0, 0.14112674072384834), (36, 0.2676921561360359), (18, 0.27514663338661194), (53, 0.9575668722391129)]
computing accuracy for after removing block 44 . block score: 0.016442360589280725
removed block 44 current accuracy 0.9634 loss from initial  0.036599999999999966
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 43, with score 0.016838. All blocks and scores: [(43, 0.01683769398368895), (14, 0.01709468592889607), (35, 0.01741944346576929), (38, 0.01861782604828477), (45, 0.019304645946249366), (34, 0.01941798347979784), (42, 0.01979124709032476), (25, 0.019869754556566477), (7, 0.020973735954612494), (8, 0.021434675669297576), (48, 0.022470828145742416), (41, 0.02348611643537879), (47, 0.02393225464038551), (10, 0.024908760329708457), (46, 0.025107177440077066), (50, 0.02530232653953135), (49, 0.025452786358073354), (15, 0.02571159601211548), (51, 0.02684962493367493), (12, 0.030168126104399562), (5, 0.0322543834336102), (6, 0.03257728461176157), (4, 0.03821847680956125), (52, 0.039511454757303), (3, 0.04297929396852851), (13, 0.04713458102196455), (2, 0.06062386138364673), (1, 0.06654218211770058), (0, 0.14112673327326775), (36, 0.2676921598613262), (18, 0.27514663711190224), (53, 1.0138287171721458)]
computing accuracy for after removing block 43 . block score: 0.01683769398368895
removed block 43 current accuracy 0.945 loss from initial  0.05500000000000005
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 14, with score 0.017095. All blocks and scores: [(14, 0.01709468592889607), (35, 0.017419443698599935), (38, 0.018617825815454125), (34, 0.01941798347979784), (42, 0.019791246624663472), (45, 0.0198525816667825), (25, 0.019869754556566477), (7, 0.020973736187443137), (8, 0.021434676134958863), (48, 0.022000048542395234), (41, 0.02348611573688686), (47, 0.024378590052947402), (10, 0.024908760096877813), (50, 0.025012930622324347), (49, 0.025669334456324577), (15, 0.02571159740909934), (46, 0.02605331945233047), (51, 0.026339717442169785), (12, 0.03016812540590763), (5, 0.03225438389927149), (6, 0.03257728461176157), (4, 0.038218476343899965), (52, 0.03836594521999359), (3, 0.04297929583117366), (13, 0.04713458148762584), (2, 0.060623859986662865), (1, 0.06654218025505543), (0, 0.14112673699855804), (36, 0.2676921561360359), (18, 0.27514663338661194), (53, 1.0739323049783707)]
computing accuracy for after removing block 14 . block score: 0.01709468592889607
removed block 14 current accuracy 0.9184 loss from initial  0.0816
since last training loss: 0.08140000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 35, with score 0.017093. All blocks and scores: [(35, 0.017093144822865725), (38, 0.017745117656886578), (34, 0.018470679176971316), (25, 0.019386355066671968), (42, 0.0197814900893718), (45, 0.020195672754198313), (7, 0.020973736187443137), (48, 0.021375086158514023), (8, 0.02143467590212822), (47, 0.024119385750964284), (41, 0.024277851451188326), (50, 0.024876721436157823), (10, 0.02490875986404717), (51, 0.025681147817522287), (49, 0.025966869201511145), (46, 0.026850942289456725), (15, 0.027650349773466587), (12, 0.030168124940246344), (5, 0.03225438389927149), (6, 0.032577283680438995), (52, 0.03683090303093195), (4, 0.03821847680956125), (3, 0.04297929396852851), (13, 0.04713458055630326), (2, 0.06062386138364673), (1, 0.066542181186378), (0, 0.14112674072384834), (36, 0.2798508293926716), (18, 0.2897353321313858), (53, 1.0559773296117783)]
computing accuracy for after removing block 35 . block score: 0.017093144822865725
removed block 35 current accuracy 0.8976 loss from initial  0.10240000000000005
since last training loss: 0.10220000000000007 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.016749. All blocks and scores: [(38, 0.016748947324231267), (34, 0.01847067940980196), (42, 0.01902325008995831), (25, 0.01938635529950261), (45, 0.0200956913176924), (48, 0.02031104266643524), (7, 0.020973735954612494), (8, 0.02143467660062015), (47, 0.023573802784085274), (41, 0.023877353640273213), (50, 0.024668818339705467), (10, 0.02490875916555524), (51, 0.025449726032093167), (49, 0.026537261437624693), (46, 0.027073149336501956), (15, 0.027650350937619805), (12, 0.030168125638738275), (5, 0.0322543834336102), (6, 0.03257728414610028), (52, 0.034247342962771654), (4, 0.03821847727522254), (3, 0.042979294899851084), (13, 0.0471345791593194), (2, 0.060623859986662865), (1, 0.06654218211770058), (0, 0.1411267388612032), (36, 0.2879062555730343), (18, 0.2897353246808052), (53, 1.0932639390230179)]
computing accuracy for after removing block 38 . block score: 0.016748947324231267
removed block 38 current accuracy 0.8652 loss from initial  0.13480000000000003
since last training loss: 0.13460000000000005 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 34, with score 0.018471. All blocks and scores: [(34, 0.01847067940980196), (45, 0.018865350168198347), (48, 0.019129694206640124), (25, 0.01938635529950261), (42, 0.019493643892928958), (7, 0.020973735488951206), (8, 0.02143467590212822), (47, 0.02250431547872722), (50, 0.02386203990317881), (51, 0.02438775636255741), (10, 0.02490875916555524), (41, 0.02501065330579877), (49, 0.025807648664340377), (46, 0.02658014092594385), (15, 0.027650350239127874), (12, 0.030168125173076987), (52, 0.03153502871282399), (5, 0.0322543834336102), (6, 0.03257728414610028), (4, 0.03821847541257739), (3, 0.04297929583117366), (13, 0.04713458055630326), (2, 0.060623861849308014), (1, 0.066542181186378), (0, 0.1411267388612032), (36, 0.2879062667489052), (18, 0.2897353284060955), (53, 1.103886216878891)]
computing accuracy for after removing block 34 . block score: 0.01847067940980196
removed block 34 current accuracy 0.814 loss from initial  0.18600000000000005
training start
training epoch 0 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best True lr [0.001]
training epoch 1 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best True lr [0.001]
training epoch 2 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 3 val accuracy 0.9834 topk_dict {'top1': 0.9834} is_best True lr [0.001]
training epoch 4 val accuracy 0.9846 topk_dict {'top1': 0.9846} is_best True lr [0.001]
training epoch 5 val accuracy 0.986 topk_dict {'top1': 0.986} is_best True lr [0.001]
training epoch 6 val accuracy 0.9856 topk_dict {'top1': 0.9856} is_best False lr [0.001]
training epoch 7 val accuracy 0.9866 topk_dict {'top1': 0.9866} is_best True lr [0.001]
training epoch 8 val accuracy 0.9862 topk_dict {'top1': 0.9862} is_best False lr [0.001]
training epoch 9 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 10 val accuracy 0.9872 topk_dict {'top1': 0.9872} is_best True lr [0.001]
training epoch 11 val accuracy 0.9864 topk_dict {'top1': 0.9864} is_best False lr [0.001]
training epoch 12 val accuracy 0.988 topk_dict {'top1': 0.988} is_best True lr [0.001]
training epoch 13 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best True lr [0.001]
training epoch 14 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 15 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best True lr [0.001]
training epoch 16 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 17 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 18 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best True lr [0.001]
training epoch 19 val accuracy 0.9898 topk_dict {'top1': 0.9898} is_best False lr [0.001]
training epoch 20 val accuracy 0.9892 topk_dict {'top1': 0.9892} is_best False lr [0.001]
training epoch 21 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 22 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 23 val accuracy 0.9894 topk_dict {'top1': 0.9894} is_best False lr [0.001]
training epoch 24 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best True lr [0.001]
training epoch 25 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best True lr [0.001]
training epoch 26 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 27 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 28 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 29 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 30 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 31 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 32 val accuracy 0.9918 topk_dict {'top1': 0.9918} is_best True lr [0.001]
training epoch 33 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 34 val accuracy 0.9904 topk_dict {'top1': 0.9904} is_best False lr [0.001]
training epoch 35 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 36 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 37 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 38 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 39 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 40 val accuracy 0.9908 topk_dict {'top1': 0.9908} is_best False lr [0.001]
training epoch 41 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 42 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 43 val accuracy 0.991 topk_dict {'top1': 0.991} is_best False lr [0.001]
training epoch 44 val accuracy 0.9914 topk_dict {'top1': 0.9914} is_best False lr [0.001]
training epoch 45 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 46 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
training epoch 47 val accuracy 0.9906 topk_dict {'top1': 0.9906} is_best False lr [0.001]
training epoch 48 val accuracy 0.9912 topk_dict {'top1': 0.9912} is_best False lr [0.001]
training epoch 49 val accuracy 0.9916 topk_dict {'top1': 0.9916} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.991800)
finished training. finished 50 epochs. accuracy 0.9918 topk_dict {'top1': 0.9918}
