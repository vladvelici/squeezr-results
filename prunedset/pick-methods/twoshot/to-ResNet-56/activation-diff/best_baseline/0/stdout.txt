start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996206175536), (32, 0.009233050514012575), (30, 0.010039400891400874), (31, 0.01036160031799227), (34, 0.013312276219949126), (29, 0.013541154330596328), (35, 0.016018461901694536), (26, 0.016037591034546494), (28, 0.017728674691170454), (27, 0.019127048319205642), (43, 0.020232456270605326), (46, 0.02104453998617828), (25, 0.02197260339744389), (23, 0.02237953571602702), (41, 0.022826648084446788), (44, 0.023395078722387552), (40, 0.024025025311857462), (45, 0.024295411072671413), (21, 0.024924598401412368), (22, 0.02516876789741218), (48, 0.02534125978127122), (24, 0.025899536907672882), (50, 0.026409972459077835), (42, 0.02667410089634359), (20, 0.026859006378799677), (49, 0.027037164429202676), (47, 0.02930646948516369), (39, 0.031570713268592954), (38, 0.031637870240956545), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03796026110649109), (51, 0.041734172496944666), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.04783663246780634), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.06095684692263603), (0, 0.06300980783998966), (1, 0.06676734331995249), (52, 0.0686293737962842), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.43758000060915947), (18, 0.5108213052153587), (53, 0.8211489170789719)]
computing accuracy for after removing block 33 . block score: 0.007061996206175536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.013133947737514973), (29, 0.013541154679842293), (26, 0.016037590336054564), (35, 0.016169289592653513), (28, 0.01772867515683174), (27, 0.019127049017697573), (43, 0.020072476472705603), (46, 0.020731386030092835), (25, 0.02197260269895196), (41, 0.02234709239564836), (23, 0.02237953501753509), (44, 0.0232356870546937), (40, 0.023841066984459758), (45, 0.023965541971847415), (48, 0.024917916394770145), (21, 0.024924598401412368), (22, 0.025168768363073468), (50, 0.025840813061222434), (24, 0.02589953667484224), (42, 0.02631532377563417), (49, 0.026655675610527396), (20, 0.02685900731012225), (47, 0.028728798031806946), (39, 0.03131764172576368), (38, 0.03138036374002695), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03802584297955036), (51, 0.041223939042538404), (9, 0.043401881121098995), (6, 0.046609030570834875), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.054548464715480804), (3, 0.05722427926957607), (13, 0.05892290361225605), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300981156527996), (1, 0.06676734238862991), (52, 0.06745155062526464), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.43538710474967957), (18, 0.5108213052153587), (53, 0.8222573921084404)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.01003940065857023), (31, 0.010361599968746305), (34, 0.012765232706442475), (29, 0.013541154563426971), (35, 0.01599275111220777), (26, 0.01603759010322392), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020075131440535188), (46, 0.02084140619263053), (25, 0.021972603164613247), (41, 0.022319766925647855), (23, 0.022379535250365734), (44, 0.023154049646109343), (40, 0.02388568432070315), (45, 0.0240716899279505), (48, 0.024877465097233653), (21, 0.024924597470089793), (22, 0.025168768595904112), (50, 0.02569117909297347), (24, 0.025899536907672882), (42, 0.026123748160898685), (49, 0.026479421881958842), (20, 0.026859006844460964), (47, 0.028693131636828184), (38, 0.03123679501004517), (39, 0.031295291148126125), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.03837669035419822), (51, 0.041114033199846745), (9, 0.04340188158676028), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846518114209), (3, 0.057224278803914785), (13, 0.05892290314659476), (11, 0.059249128215014935), (17, 0.06095685018226504), (0, 0.06300980830565095), (1, 0.06676734331995249), (52, 0.06700456235557795), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387302964926), (36, 0.43640001490712166), (18, 0.5108213126659393), (53, 0.8289348781108856)]
computing accuracy for after removing block 30 . block score: 0.01003940065857023
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.012387836934067309), (29, 0.013541154563426971), (35, 0.016008096281439066), (26, 0.016037590336054564), (28, 0.01772867562249303), (27, 0.019127048319205642), (43, 0.020083633484318852), (46, 0.020704444032162428), (25, 0.02197260269895196), (41, 0.02225319715216756), (23, 0.02237953571602702), (44, 0.023267761105671525), (40, 0.024013880407437682), (45, 0.02409299253486097), (48, 0.024665280245244503), (21, 0.024924598401412368), (22, 0.025168768363073468), (50, 0.025459734722971916), (42, 0.02565571293234825), (24, 0.025899536907672882), (49, 0.02628775709308684), (20, 0.026859007077291608), (47, 0.02836342342197895), (38, 0.031047646887600422), (39, 0.03138077212497592), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03897124482318759), (51, 0.040756203699857), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.0572242783382535), (13, 0.05892289988696575), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980970263481), (52, 0.0658631594851613), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282697200775), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4389924630522728), (18, 0.5108212903141975), (53, 0.8391561433672905)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619548432529), (29, 0.01354115444701165), (26, 0.016037590568885207), (35, 0.01605736301280558), (28, 0.017728675389662385), (27, 0.01912704878486693), (43, 0.02004934987053275), (46, 0.020552987465634942), (25, 0.02197260269895196), (41, 0.02206748491153121), (23, 0.02237953571602702), (44, 0.022979131899774075), (40, 0.02385834720917046), (45, 0.024124702205881476), (48, 0.024386122822761536), (21, 0.024924598401412368), (50, 0.025042241904884577), (22, 0.025168768595904112), (42, 0.025414508068934083), (49, 0.025842698523774743), (24, 0.02589953737333417), (20, 0.026859007077291608), (47, 0.028050735127180815), (38, 0.03104005940258503), (39, 0.03150080284103751), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.039112848695367575), (51, 0.040246272925287485), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.047836633399128914), (2, 0.05454846750944853), (3, 0.05722427926957607), (13, 0.05892290314659476), (11, 0.05924912728369236), (17, 0.06095685018226504), (0, 0.06300981156527996), (52, 0.06486208783462644), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4381278455257416), (18, 0.5108213201165199), (53, 0.8458427712321281)]
computing accuracy for after removing block 34 . block score: 0.012489619548432529
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.01603759010322392), (35, 0.016653420170769095), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020503456238657236), (46, 0.020725322188809514), (25, 0.021972603164613247), (23, 0.022379535483196378), (41, 0.02245262893848121), (44, 0.023364474764093757), (48, 0.0242903558537364), (45, 0.024438712978735566), (40, 0.02447055885568261), (21, 0.02492459793575108), (50, 0.025042172521352768), (22, 0.025168767664581537), (49, 0.0258759711869061), (24, 0.02589953737333417), (42, 0.026205406989902258), (20, 0.02685900777578354), (47, 0.028178582899272442), (15, 0.03192339185625315), (38, 0.03208350157365203), (7, 0.03228544630110264), (39, 0.03233744064345956), (19, 0.03262859582901001), (51, 0.03994725737720728), (37, 0.04073968203738332), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.04749368317425251), (14, 0.04783663293346763), (2, 0.054548466112464666), (3, 0.057224280666559935), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.060956848319619894), (0, 0.06300980877131224), (52, 0.06433630455285311), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.45053430646657944), (18, 0.5108212903141975), (53, 0.84432003647089)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037591034546494), (35, 0.016470607835799456), (28, 0.01772867515683174), (27, 0.01912704878486693), (43, 0.02004686719737947), (46, 0.020376993576064706), (41, 0.02172324270941317), (25, 0.02197260269895196), (23, 0.022379535250365734), (44, 0.023028337163850665), (48, 0.02377187693491578), (40, 0.023930812953040004), (45, 0.024178662337362766), (50, 0.02439029887318611), (21, 0.024924598168581724), (22, 0.025168768130242825), (42, 0.02518825139850378), (49, 0.025361529318615794), (24, 0.02589953667484224), (20, 0.026859007542952895), (47, 0.027363279135897756), (38, 0.031365619506686926), (15, 0.03192339185625315), (39, 0.03212768491357565), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.038935923017561436), (37, 0.04020634340122342), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.05892290361225605), (11, 0.059249128215014935), (17, 0.060956849716603756), (52, 0.06232855003327131), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4444201961159706), (18, 0.5108213052153587), (53, 0.8537911996245384)]
computing accuracy for after removing block 26 . block score: 0.016037591034546494
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.015597365912981331), (28, 0.017088500782847404), (27, 0.01888244692236185), (43, 0.01959516596980393), (46, 0.020073580322787166), (41, 0.020961584523320198), (25, 0.021972602931782603), (23, 0.022379535483196378), (44, 0.022814956260845065), (48, 0.023128160974010825), (40, 0.02334519545547664), (50, 0.023756147362291813), (42, 0.02384730218909681), (45, 0.023873880272731185), (21, 0.024924598168581724), (49, 0.02496031578630209), (22, 0.025168768595904112), (24, 0.025899537606164813), (47, 0.026855542324483395), (20, 0.02685900661163032), (38, 0.03042401373386383), (39, 0.03151404415257275), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (51, 0.03782488079741597), (37, 0.03936835192143917), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493682242929935), (14, 0.047836633399128914), (2, 0.05454846424981952), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912914633751), (52, 0.060332820285111666), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4360685609281063), (18, 0.5108212903141975), (53, 0.8749377131462097)]
computing accuracy for after removing block 35 . block score: 0.015597365912981331
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.018555945716798306), (27, 0.018882446689531207), (46, 0.019160084892064333), (41, 0.01942429505288601), (48, 0.021467271726578474), (25, 0.021972602233290672), (44, 0.022026916034519672), (40, 0.02217966062016785), (42, 0.022206430323421955), (50, 0.02225612848997116), (23, 0.022379535250365734), (45, 0.022931481944397092), (49, 0.023708512540906668), (21, 0.024924598401412368), (22, 0.025168768130242825), (47, 0.025829139165580273), (24, 0.025899537140503526), (20, 0.02685900731012225), (38, 0.028956546215340495), (39, 0.0296678279992193), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.036009025294333696), (37, 0.03651238605380058), (9, 0.04340187832713127), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.05454846564680338), (52, 0.056107287760823965), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912728369236), (17, 0.06095684878528118), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387396097183), (36, 0.4175764471292496), (18, 0.5108212903141975), (53, 0.9117144793272018)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102241948247), (41, 0.018849018262699246), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.021432004403322935), (40, 0.0218324214220047), (44, 0.02184053068049252), (50, 0.021869864081963897), (25, 0.021972602233290672), (23, 0.022379535250365734), (45, 0.022492847638204694), (49, 0.023123498540371656), (21, 0.02492459723725915), (47, 0.025067138951271772), (22, 0.025168768595904112), (24, 0.025899536907672882), (20, 0.026859007077291608), (38, 0.02811406971886754), (39, 0.02920690830796957), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.03545433608815074), (37, 0.03597763879224658), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368503689766), (14, 0.0478366338647902), (2, 0.054548466578125954), (52, 0.05469645792618394), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.05924913194030523), (17, 0.06095684738829732), (0, 0.06300981156527996), (1, 0.06676733959466219), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387209832668), (36, 0.4135979190468788), (18, 0.5108212903141975), (53, 0.9246632680296898)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.018849018728360534), (27, 0.018882447155192494), (46, 0.019302030326798558), (42, 0.021432004403322935), (48, 0.02154484367929399), (40, 0.0218324214220047), (50, 0.021946269553154707), (25, 0.02197260269895196), (23, 0.022379535483196378), (49, 0.02300687017850578), (44, 0.02310851076617837), (45, 0.023535607615485787), (21, 0.024924597702920437), (22, 0.025168768363073468), (47, 0.025820446433499455), (24, 0.025899537140503526), (20, 0.02685900661163032), (38, 0.028114069486036897), (39, 0.029206908773630857), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.0326285962946713), (51, 0.035091488156467676), (37, 0.03597763832658529), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368503689766), (14, 0.04783663526177406), (52, 0.053329029120504856), (2, 0.054548467975109816), (3, 0.05722427926957607), (13, 0.05892290361225605), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979115962982), (18, 0.5108213052153587), (53, 0.9678284376859665)]
computing accuracy for after removing block 41 . block score: 0.018849018728360534
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008863054216), (48, 0.020678167697042227), (50, 0.021344397217035294), (40, 0.021832421654835343), (25, 0.021972603630274534), (42, 0.021986940875649452), (23, 0.022379535483196378), (49, 0.02253474830649793), (45, 0.023929917253553867), (44, 0.02405400318093598), (21, 0.024924597470089793), (22, 0.025168768828734756), (24, 0.02589953737333417), (47, 0.026043936843052506), (20, 0.02685900731012225), (38, 0.028114069253206253), (39, 0.029206908075138927), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (51, 0.033794480841606855), (37, 0.03597763925790787), (9, 0.04340188018977642), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.0478366338647902), (52, 0.050476094242185354), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.058922901283949614), (11, 0.059249126352369785), (17, 0.06095684925094247), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667386930435896), (36, 0.4135979115962982), (18, 0.5108213126659393), (53, 1.0278179794549942)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462491869926), (48, 0.019989707740023732), (50, 0.02077506179921329), (40, 0.021085952874273062), (42, 0.021369647467508912), (49, 0.02191002992913127), (25, 0.021972602466121316), (23, 0.022379535250365734), (44, 0.023239311762154102), (45, 0.02358530811034143), (21, 0.024924597702920437), (47, 0.025076947873458266), (22, 0.025168768130242825), (24, 0.025899537606164813), (20, 0.02685900731012225), (38, 0.027183360187336802), (39, 0.02858075825497508), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.03281426033936441), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836633399128914), (52, 0.04852363280951977), (2, 0.054548464715480804), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.406523410230875), (18, 0.5108212903141975), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462491869926
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.02083116164430976), (40, 0.02108595333993435), (42, 0.02136964723467827), (25, 0.02197260269895196), (23, 0.022379535948857665), (49, 0.022536989068612456), (44, 0.023239311762154102), (45, 0.023585307644680142), (21, 0.024924598168581724), (22, 0.025168768130242825), (24, 0.02589953737333417), (47, 0.02658304898068309), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.02858075825497508), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03285081312060356), (37, 0.03542024362832308), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.047493685968220234), (14, 0.04783663433045149), (52, 0.04812479903921485), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.060956846456974745), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828325599432), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.4065234065055847), (18, 0.5108213052153587), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
training start
training epoch 0 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best True lr [0.001]
training epoch 1 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 2 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 3 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 4 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 5 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 6 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 7 val accuracy 0.9976 topk_dict {'top1': 0.9976} is_best False lr [0.001]
training epoch 8 val accuracy 0.998 topk_dict {'top1': 0.998} is_best False lr [0.001]
training epoch 9 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 10 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 11 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 12 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 13 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 14 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 15 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 16 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 17 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 18 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 19 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 20 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 21 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best False lr [0.001]
training epoch 22 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 23 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 24 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 25 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 26 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 27 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 28 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 29 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 30 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 31 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 32 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 33 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 34 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 35 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 38 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 39 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 40 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 41 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 42 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 43 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 44 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 45 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 46 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 49 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.999400)
finished training. finished 50 epochs. accuracy 0.9994 topk_dict {'top1': 0.9994}
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.024062. All blocks and scores: [(40, 0.024061928736045957), (45, 0.025294604944065213), (44, 0.02534662140533328), (25, 0.025758082047104836), (23, 0.02685742173343897), (42, 0.027552286395803094), (21, 0.028707951540127397), (22, 0.028745766961947083), (50, 0.029040939640253782), (20, 0.029443945735692978), (49, 0.029909531818702817), (38, 0.030650305096060038), (39, 0.03111338848248124), (7, 0.031407337402924895), (24, 0.03175746602937579), (47, 0.03265633434057236), (15, 0.03304692404344678), (19, 0.034083062782883644), (37, 0.03605502704158425), (51, 0.04267472634091973), (9, 0.04415637021884322), (6, 0.04583944985643029), (4, 0.045863973908126354), (14, 0.04805612191557884), (2, 0.05327622080221772), (3, 0.057181703858077526), (11, 0.057791301514953375), (13, 0.05834820168092847), (0, 0.06168303871527314), (17, 0.06209965655580163), (1, 0.0656074695289135), (52, 0.07242526300251484), (8, 0.07330516632646322), (10, 0.07729101832956076), (16, 0.08276382833719254), (12, 0.08940102625638247), (5, 0.10401794221252203), (36, 0.40184398740530014), (18, 0.4864235445857048), (53, 0.8412824720144272)]
computing accuracy for after removing block 40 . block score: 0.024061928736045957
removed block 40 current accuracy 0.9968 loss from initial  0.0031999999999999806
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.025034. All blocks and scores: [(45, 0.025033716578036547), (25, 0.025758081814274192), (42, 0.02636669180355966), (44, 0.026796256192028522), (23, 0.02685742173343897), (50, 0.027890281286090612), (21, 0.028707951307296753), (22, 0.028745766263455153), (20, 0.029443944804370403), (49, 0.02955065667629242), (38, 0.030650304863229394), (39, 0.031113388016819954), (7, 0.03140733693726361), (24, 0.031757465563714504), (15, 0.03304692357778549), (47, 0.03317871084436774), (19, 0.03408306231722236), (37, 0.03605502704158425), (51, 0.041728387121111155), (9, 0.044156371150165796), (6, 0.04583944985643029), (4, 0.0458639757707715), (14, 0.04805612238124013), (2, 0.0532762217335403), (3, 0.05718170711770654), (11, 0.0577913043089211), (13, 0.05834820307791233), (0, 0.061683039646595716), (17, 0.06209965702146292), (1, 0.06560746766626835), (52, 0.06992871966212988), (8, 0.07330516632646322), (10, 0.07729101926088333), (16, 0.08276382926851511), (12, 0.08940102811902761), (5, 0.10401793848723173), (36, 0.40184399113059044), (18, 0.4864235557615757), (53, 0.9312313571572304)]
computing accuracy for after removing block 45 . block score: 0.025033716578036547
removed block 45 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.025758. All blocks and scores: [(25, 0.02575808111578226), (42, 0.026366692269220948), (44, 0.026796256192028522), (23, 0.02685742173343897), (50, 0.028418078320100904), (21, 0.028707950841635466), (22, 0.02874576603062451), (20, 0.029443945037201047), (49, 0.030083403224125504), (38, 0.030650303699076176), (39, 0.031113388249650598), (7, 0.03140733693726361), (24, 0.03175746602937579), (15, 0.03304692404344678), (19, 0.03408306231722236), (47, 0.0350028071552515), (37, 0.03605502750724554), (51, 0.04014805145561695), (9, 0.04415637068450451), (6, 0.04583945032209158), (4, 0.045863975305110216), (14, 0.04805612238124013), (2, 0.053276222199201584), (3, 0.05718170711770654), (11, 0.057791301514953375), (13, 0.05834820121526718), (0, 0.061683038249611855), (17, 0.06209965888410807), (52, 0.06454355269670486), (1, 0.06560746859759092), (8, 0.0733051672577858), (10, 0.07729101926088333), (16, 0.08276382833719254), (12, 0.08940102718770504), (5, 0.10401793755590916), (36, 0.40184398368000984), (18, 0.486423559486866), (53, 1.0868584364652634)]
computing accuracy for after removing block 25 . block score: 0.02575808111578226
removed block 25 current accuracy 0.9888 loss from initial  0.011199999999999988
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 42, with score 0.024787. All blocks and scores: [(42, 0.024787494679912925), (44, 0.026013862574473023), (23, 0.0268574224319309), (50, 0.026911078952252865), (49, 0.028618842363357544), (21, 0.028707950841635466), (22, 0.028745766263455153), (20, 0.029443945037201047), (38, 0.029468275839462876), (39, 0.030756991589441895), (7, 0.03140733623877168), (24, 0.03175746416673064), (15, 0.03304692357778549), (47, 0.03375664632767439), (19, 0.03408306324854493), (37, 0.03507545357570052), (51, 0.03836712194606662), (9, 0.04415637068450451), (6, 0.04583945032209158), (4, 0.04586397437378764), (14, 0.048056121449917555), (2, 0.05327621893957257), (3, 0.05718170525506139), (11, 0.05779130244627595), (13, 0.058348202146589756), (52, 0.061488968785852194), (0, 0.061683041509240866), (17, 0.062099657487124205), (1, 0.06560747046023607), (8, 0.07330516539514065), (10, 0.07729101926088333), (16, 0.08276382833719254), (12, 0.08940102811902761), (5, 0.10401793569326401), (36, 0.3904542848467827), (18, 0.4864235483109951), (53, 1.109020248055458)]
computing accuracy for after removing block 42 . block score: 0.024787494679912925
removed block 42 current accuracy 0.9794 loss from initial  0.02059999999999995
since last training loss: 0.019999999999999907 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.026857. All blocks and scores: [(23, 0.02685742313042283), (44, 0.02776413061656058), (50, 0.027864908799529076), (21, 0.028707950841635466), (22, 0.02874576603062451), (20, 0.02944394457153976), (49, 0.02946653449907899), (38, 0.029468276537954807), (39, 0.030756991123780608), (7, 0.03140733763575554), (24, 0.031757465563714504), (15, 0.033046924974769354), (19, 0.03408306231722236), (47, 0.03501656744629145), (37, 0.035075453110039234), (51, 0.038163583260029554), (9, 0.044156371150165796), (6, 0.04583944985643029), (4, 0.0458639757707715), (14, 0.04805612005293369), (2, 0.05327621940523386), (3, 0.0571817047894001), (11, 0.05779130198061466), (13, 0.058348202146589756), (0, 0.06168303918093443), (52, 0.06183763546869159), (17, 0.06209965841844678), (1, 0.0656074695289135), (8, 0.0733051672577858), (10, 0.07729101739823818), (16, 0.08276382740586996), (12, 0.08940102811902761), (5, 0.10401793755590916), (36, 0.3904542848467827), (18, 0.486423559486866), (53, 1.1740467846393585)]
computing accuracy for after removing block 23 . block score: 0.02685742313042283
removed block 23 current accuracy 0.9748 loss from initial  0.0252
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.026934. All blocks and scores: [(50, 0.02693415549583733), (44, 0.02706196764484048), (21, 0.02870795107446611), (22, 0.028745766496285796), (49, 0.028986606746912003), (38, 0.029106182511895895), (24, 0.02941656089387834), (20, 0.029443944338709116), (39, 0.030617994954809546), (7, 0.03140733647160232), (15, 0.033046924974769354), (47, 0.0336151784285903), (19, 0.03408306185156107), (37, 0.03592445934191346), (51, 0.037276726216077805), (9, 0.04415637021884322), (6, 0.04583945032209158), (4, 0.04586397297680378), (14, 0.04805612377822399), (2, 0.05327621893957257), (3, 0.05718170432373881), (11, 0.05779130244627595), (13, 0.05834820121526718), (52, 0.05847086803987622), (0, 0.061683039646595716), (17, 0.062099655624479055), (1, 0.06560747046023607), (8, 0.0733051672577858), (10, 0.07729101926088333), (16, 0.08276382833719254), (12, 0.08940102718770504), (5, 0.1040179394185543), (36, 0.3885893300175667), (18, 0.4864235632121563), (53, 1.168386459350586)]
computing accuracy for after removing block 50 . block score: 0.02693415549583733
removed block 50 current accuracy 0.9588 loss from initial  0.041200000000000014
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.027062. All blocks and scores: [(44, 0.027061968110501766), (21, 0.02870795107446611), (22, 0.028745766496285796), (49, 0.02898660651408136), (38, 0.02910618344321847), (24, 0.02941656019538641), (20, 0.029443944338709116), (39, 0.03061799448914826), (7, 0.03140733623877168), (15, 0.03304692357778549), (47, 0.0336151784285903), (19, 0.034083062782883644), (37, 0.0359244579449296), (51, 0.04050894593819976), (9, 0.04415637021884322), (6, 0.04583945032209158), (4, 0.045863975305110216), (14, 0.048056123312562704), (2, 0.05327621893957257), (3, 0.057181705720722675), (11, 0.057791303377598524), (13, 0.05834820028394461), (0, 0.06168303918093443), (17, 0.06209965981543064), (1, 0.06560746859759092), (52, 0.07025997806340456), (8, 0.07330516632646322), (10, 0.07729101926088333), (16, 0.08276382833719254), (12, 0.08940102811902761), (5, 0.10401793476194143), (36, 0.3885893486440182), (18, 0.486423559486866), (53, 1.383947730064392)]
computing accuracy for after removing block 44 . block score: 0.027061968110501766
removed block 44 current accuracy 0.933 loss from initial  0.06699999999999995
since last training loss: 0.0663999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.028329. All blocks and scores: [(49, 0.02832914888858795), (21, 0.028707951307296753), (22, 0.028745766496285796), (38, 0.029106183210387826), (24, 0.02941656089387834), (20, 0.029443944804370403), (39, 0.030617993790656328), (7, 0.03140733623877168), (15, 0.03304692357778549), (19, 0.03408306185156107), (47, 0.03590674186125398), (37, 0.03592445841059089), (51, 0.0390847441740334), (9, 0.04415637254714966), (6, 0.04583945078775287), (4, 0.04586397623643279), (14, 0.04805612238124013), (2, 0.053276220336556435), (3, 0.05718170432373881), (11, 0.0577913043089211), (13, 0.058348200749605894), (0, 0.06168304104357958), (17, 0.06209965888410807), (1, 0.06560746859759092), (52, 0.06759421899914742), (8, 0.07330516632646322), (10, 0.07729101926088333), (16, 0.08276382740586996), (12, 0.08940102625638247), (5, 0.10401793848723173), (36, 0.388589333742857), (18, 0.4864235557615757), (53, 1.5486780256032944)]
computing accuracy for after removing block 49 . block score: 0.02832914888858795
removed block 49 current accuracy 0.8928 loss from initial  0.10719999999999996
since last training loss: 0.10659999999999992 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.028708. All blocks and scores: [(21, 0.02870795107446611), (22, 0.028745766263455153), (38, 0.02910618274472654), (24, 0.029416560428217053), (20, 0.029443945735692978), (39, 0.030617994954809546), (7, 0.03140733717009425), (15, 0.03304692450910807), (19, 0.03408306231722236), (47, 0.03590674186125398), (37, 0.03592445980757475), (51, 0.03987613786011934), (9, 0.044156371615827084), (6, 0.04583944985643029), (4, 0.04586397483944893), (14, 0.04805612051859498), (2, 0.053276222199201584), (3, 0.05718170618638396), (11, 0.05779130384325981), (13, 0.05834820261225104), (0, 0.061683038249611855), (17, 0.06209965795278549), (1, 0.0656074695289135), (52, 0.07164205610752106), (8, 0.07330516632646322), (10, 0.07729101926088333), (16, 0.08276382926851511), (12, 0.08940102811902761), (5, 0.10401793755590916), (36, 0.3885893374681473), (18, 0.4864235520362854), (53, 1.7385709881782532)]
computing accuracy for after removing block 21 . block score: 0.02870795107446611
removed block 21 current accuracy 0.8802 loss from initial  0.11980000000000002
since last training loss: 0.11919999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.026538. All blocks and scores: [(24, 0.02653819276019931), (22, 0.026578399818390608), (38, 0.027586805867031217), (20, 0.029443945502862334), (39, 0.02953633456490934), (7, 0.03140733717009425), (15, 0.03304692404344678), (47, 0.03387546073645353), (19, 0.034083062782883644), (37, 0.03431920055299997), (51, 0.038030529860407114), (9, 0.04415637021884322), (6, 0.045839449390769005), (4, 0.04586397483944893), (14, 0.04805612284690142), (2, 0.053276220336556435), (3, 0.057181705720722675), (11, 0.05779130524024367), (13, 0.05834820168092847), (0, 0.06168303918093443), (17, 0.06209965981543064), (52, 0.06453336216509342), (1, 0.06560747046023607), (8, 0.07330516912043095), (10, 0.07729101926088333), (16, 0.08276382647454739), (12, 0.08940102532505989), (5, 0.10401793848723173), (36, 0.3660622574388981), (18, 0.4864235445857048), (53, 1.7908764779567719)]
computing accuracy for after removing block 24 . block score: 0.02653819276019931
removed block 24 current accuracy 0.8382 loss from initial  0.16180000000000005
since last training loss: 0.1612 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.026578. All blocks and scores: [(22, 0.026578399818390608), (38, 0.026788063114508986), (39, 0.028727037832140923), (20, 0.029443945037201047), (7, 0.03140733763575554), (47, 0.03188417316414416), (15, 0.033046924974769354), (37, 0.033467347268015146), (19, 0.03408306324854493), (51, 0.036084940657019615), (9, 0.044156371615827084), (6, 0.04583945032209158), (4, 0.045863973908126354), (14, 0.048056121449917555), (2, 0.053276220336556435), (3, 0.0571817047894001), (11, 0.0577913043089211), (13, 0.05834820307791233), (52, 0.0603226013481617), (0, 0.061683039646595716), (17, 0.06209965795278549), (1, 0.06560746859759092), (8, 0.0733051635324955), (10, 0.07729101832956076), (16, 0.08276382926851511), (12, 0.08940102718770504), (5, 0.10401793662458658), (36, 0.35334644839167595), (18, 0.4864235669374466), (53, 1.8069755882024765)]
computing accuracy for after removing block 22 . block score: 0.026578399818390608
removed block 22 current accuracy 0.8008 loss from initial  0.19920000000000004
since last training loss: 0.1986 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.026668. All blocks and scores: [(38, 0.026667968835681677), (39, 0.028027208289131522), (20, 0.02944394527003169), (47, 0.03008422371931374), (7, 0.031407336704432964), (15, 0.033046924974769354), (37, 0.0339502259157598), (19, 0.034083062782883644), (51, 0.03503188397735357), (9, 0.04415637021884322), (6, 0.045839449390769005), (4, 0.045863973908126354), (14, 0.04805612191557884), (2, 0.05327622126787901), (52, 0.056780084036290646), (3, 0.05718170525506139), (11, 0.05779130244627595), (13, 0.05834820261225104), (0, 0.061683038249611855), (17, 0.06209965702146292), (1, 0.06560746859759092), (8, 0.07330516539514065), (10, 0.07729101832956076), (16, 0.08276382926851511), (12, 0.08940102625638247), (5, 0.10401794034987688), (36, 0.3482525981962681), (18, 0.486423559486866), (53, 1.7933993190526962)]
computing accuracy for after removing block 38 . block score: 0.026667968835681677
removed block 38 current accuracy 0.7684 loss from initial  0.23160000000000003
since last training loss: 0.23099999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.028556. All blocks and scores: [(47, 0.028556437231600285), (20, 0.029443944804370403), (39, 0.029491744237020612), (7, 0.03140733763575554), (15, 0.03304692404344678), (37, 0.033950225450098515), (19, 0.03408306231722236), (51, 0.03462789114564657), (9, 0.04415637021884322), (6, 0.04583945171907544), (4, 0.04586397670209408), (14, 0.04805612284690142), (52, 0.0529162110760808), (2, 0.05327621987089515), (3, 0.05718170525506139), (11, 0.057791303377598524), (13, 0.058348200749605894), (0, 0.061683039646595716), (17, 0.06209965609014034), (1, 0.0656074695289135), (8, 0.0733051672577858), (10, 0.07729101832956076), (16, 0.08276382740586996), (12, 0.08940102532505989), (5, 0.1040179394185543), (36, 0.3482526056468487), (18, 0.4864235557615757), (53, 1.8583041429519653)]
computing accuracy for after removing block 47 . block score: 0.028556437231600285
removed block 47 current accuracy 0.6706 loss from initial  0.3294
training start
training epoch 0 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 1 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 2 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 3 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 4 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 5 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 6 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 7 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 8 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 9 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best True lr [0.001]
training epoch 10 val accuracy 0.958 topk_dict {'top1': 0.958} is_best True lr [0.001]
training epoch 11 val accuracy 0.9624 topk_dict {'top1': 0.9624} is_best True lr [0.001]
training epoch 12 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.001]
training epoch 13 val accuracy 0.9626 topk_dict {'top1': 0.9626} is_best False lr [0.001]
training epoch 14 val accuracy 0.9646 topk_dict {'top1': 0.9646} is_best True lr [0.001]
training epoch 15 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.001]
training epoch 16 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.001]
training epoch 17 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best False lr [0.001]
training epoch 18 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.001]
training epoch 19 val accuracy 0.9694 topk_dict {'top1': 0.9694} is_best True lr [0.001]
training epoch 20 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best True lr [0.001]
training epoch 21 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.001]
training epoch 22 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best True lr [0.001]
training epoch 23 val accuracy 0.9676 topk_dict {'top1': 0.9676} is_best False lr [0.001]
training epoch 24 val accuracy 0.968 topk_dict {'top1': 0.968} is_best False lr [0.001]
training epoch 25 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.001]
training epoch 26 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best True lr [0.001]
training epoch 27 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best True lr [0.001]
training epoch 28 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best True lr [0.001]
training epoch 29 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 30 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 31 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 32 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 33 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 34 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.001]
training epoch 35 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best True lr [0.001]
training epoch 36 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 37 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.001]
training epoch 38 val accuracy 0.9696 topk_dict {'top1': 0.9696} is_best False lr [0.001]
training epoch 39 val accuracy 0.9704 topk_dict {'top1': 0.9704} is_best False lr [0.001]
training epoch 40 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.001]
training epoch 41 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 42 val accuracy 0.973 topk_dict {'top1': 0.973} is_best True lr [0.001]
training epoch 43 val accuracy 0.9712 topk_dict {'top1': 0.9712} is_best False lr [0.001]
training epoch 44 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.001]
training epoch 45 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.001]
training epoch 46 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 47 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 48 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 49 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.973400)
finished training. finished 50 epochs. accuracy 0.9734 topk_dict {'top1': 0.9734}
