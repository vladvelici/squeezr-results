start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008455. All blocks and scores: [(32, 0.008455108967609704), (30, 0.009703245712444186), (33, 0.011115942848846316), (34, 0.011622710153460503), (31, 0.0122752032475546), (28, 0.012290219077840447), (29, 0.014791248715482652), (27, 0.016729247989133), (26, 0.017444903030991554), (1, 0.018259593285620213), (7, 0.018379185814410448), (8, 0.01953245233744383), (25, 0.019648710265755653), (35, 0.019787947181612253), (24, 0.020829483401030302), (22, 0.021021660650148988), (23, 0.02157451375387609), (47, 0.022546384716406465), (44, 0.023842158494517207), (41, 0.024168545845896006), (46, 0.02465107524767518), (6, 0.024668579688295722), (21, 0.025249343598261476), (43, 0.025803553871810436), (10, 0.02636369620449841), (42, 0.026426069671288133), (4, 0.026659546652808785), (45, 0.026823592372238636), (39, 0.026881904806941748), (40, 0.026893551694229245), (49, 0.027856426313519478), (48, 0.028491604141891003), (50, 0.028780476190149784), (11, 0.02900235913693905), (38, 0.02966292155906558), (3, 0.032272040378302336), (13, 0.03333653463050723), (37, 0.035762057173997164), (20, 0.03646321874111891), (12, 0.03799272049218416), (9, 0.03963937098160386), (51, 0.039642108138650656), (19, 0.04421887546777725), (52, 0.04580832691863179), (15, 0.04691674979403615), (14, 0.049041638150811195), (2, 0.05722745647653937), (0, 0.0588825736194849), (16, 0.06225228914991021), (5, 0.09379573632031679), (17, 0.25432228296995163), (36, 0.41727546975016594), (18, 0.4852069243788719), (53, 0.7453346699476242)]
computing accuracy for after removing block 32 . block score: 0.008455108967609704
removed block 32 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009703. All blocks and scores: [(30, 0.009703245712444186), (33, 0.01119989063590765), (34, 0.011937809409573674), (31, 0.012275203131139278), (28, 0.012290218961425126), (29, 0.014791248482652009), (27, 0.016729247989133), (26, 0.017444903263822198), (1, 0.018259592819958925), (7, 0.018379186280071735), (8, 0.01953245303593576), (25, 0.01964871073141694), (35, 0.020431341603398323), (24, 0.020829483401030302), (22, 0.021021660650148988), (23, 0.02157451375387609), (47, 0.022262108977884054), (44, 0.023293233243748546), (41, 0.023795815650373697), (46, 0.024043595185503364), (6, 0.024668579688295722), (21, 0.025249343132600188), (43, 0.025525056989863515), (42, 0.026236766716465354), (40, 0.02631577313877642), (10, 0.026363696670159698), (4, 0.026659545954316854), (45, 0.026667138328775764), (39, 0.02688687085174024), (49, 0.02732702507637441), (48, 0.027911514043807983), (50, 0.02820870536379516), (38, 0.028610609006136656), (11, 0.02900235983543098), (3, 0.03227204130962491), (13, 0.03333653463050723), (37, 0.034699315670877695), (20, 0.03646321874111891), (12, 0.03799272049218416), (51, 0.039370250422507524), (9, 0.039639370050281286), (19, 0.04421887546777725), (52, 0.045125022530555725), (15, 0.046916747931391), (14, 0.04904163861647248), (2, 0.057227454613894224), (0, 0.05888257687911391), (16, 0.06225228821858764), (5, 0.09379573818296194), (17, 0.2543222811073065), (36, 0.4077852964401245), (18, 0.4852069243788719), (53, 0.7581149265170097)]
computing accuracy for after removing block 30 . block score: 0.009703245712444186
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011317. All blocks and scores: [(33, 0.011317006428726017), (34, 0.01188752893358469), (28, 0.012290219543501735), (31, 0.012499805074185133), (29, 0.014791248715482652), (27, 0.016729247756302357), (26, 0.017444903263822198), (1, 0.018259593285620213), (7, 0.01837918534874916), (8, 0.01953245303593576), (25, 0.01964871073141694), (35, 0.02071700361557305), (24, 0.020829483633860946), (22, 0.02102166088297963), (23, 0.02157451305538416), (47, 0.022107098950073123), (44, 0.02311369334347546), (46, 0.02374216029420495), (41, 0.02392919920384884), (6, 0.024668579688295722), (21, 0.025249343132600188), (43, 0.025264928117394447), (40, 0.02624745201319456), (10, 0.02636369550600648), (42, 0.02652742271311581), (4, 0.026659545954316854), (45, 0.026712610386312008), (39, 0.027034528786316514), (49, 0.027338512241840363), (48, 0.027909939642995596), (50, 0.027956509962677956), (38, 0.028708983212709427), (11, 0.029002359602600336), (3, 0.03227203991264105), (13, 0.03333653509616852), (37, 0.03434832580387592), (20, 0.036463219206780195), (12, 0.03799272049218416), (51, 0.039133232086896896), (9, 0.03963937098160386), (19, 0.04421887546777725), (52, 0.04478001920506358), (15, 0.046916748862713575), (14, 0.04904163768514991), (2, 0.057227457873523235), (0, 0.05888257408514619), (16, 0.06225228821858764), (5, 0.09379573911428452), (17, 0.2543222904205322), (36, 0.40603339299559593), (18, 0.4852069281041622), (53, 0.7581836432218552)]
computing accuracy for after removing block 33 . block score: 0.011317006428726017
removed block 33 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012240. All blocks and scores: [(34, 0.012240082025527954), (28, 0.012290219543501735), (31, 0.01249980553984642), (29, 0.014791248366236687), (27, 0.016729247989133), (26, 0.01744490349665284), (1, 0.01825959305278957), (7, 0.01837918604724109), (8, 0.019532452570274472), (25, 0.019648709800094366), (24, 0.02082948386669159), (22, 0.021021660417318344), (35, 0.021477244328707457), (23, 0.021574513288214803), (47, 0.02193372999317944), (44, 0.022819967940449715), (46, 0.023398497607558966), (41, 0.02404660196043551), (6, 0.024668580386787653), (21, 0.025249343598261476), (43, 0.025404764339327812), (40, 0.02601964701898396), (10, 0.026363695273175836), (4, 0.026659546187147498), (42, 0.026750181335955858), (45, 0.026783813256770372), (49, 0.02706983406096697), (39, 0.027496121125295758), (48, 0.027574570383876562), (50, 0.027946369722485542), (38, 0.028736302629113197), (11, 0.029002359369769692), (3, 0.03227204130962491), (13, 0.03333653509616852), (37, 0.0340590481646359), (20, 0.03646321967244148), (12, 0.037992721889168024), (51, 0.038808980491012335), (9, 0.039639370515942574), (19, 0.044218875002115965), (52, 0.04450394958257675), (15, 0.04691674932837486), (14, 0.04904163861647248), (2, 0.057227456010878086), (0, 0.058882578276097775), (16, 0.062252290081232786), (5, 0.09379573818296194), (17, 0.25432228669524193), (36, 0.40450604259967804), (18, 0.4852069355547428), (53, 0.7641193121671677)]
computing accuracy for after removing block 34 . block score: 0.012240082025527954
removed block 34 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012290. All blocks and scores: [(28, 0.012290219077840447), (31, 0.012499805190600455), (29, 0.014791248133406043), (27, 0.016729247756302357), (26, 0.017444903030991554), (1, 0.018259592819958925), (7, 0.018379185814410448), (8, 0.019532452570274472), (25, 0.019648710265755653), (24, 0.020829483633860946), (22, 0.02102166088297963), (23, 0.021574512822553515), (35, 0.021708656568080187), (47, 0.021801755065098405), (44, 0.022438113344833255), (46, 0.02333690971136093), (41, 0.023686284432187676), (6, 0.024668580386787653), (21, 0.025249343365430832), (43, 0.025404840242117643), (40, 0.025569377467036247), (10, 0.026363695971667767), (42, 0.02655180124565959), (39, 0.026582872727885842), (49, 0.026649242034181952), (4, 0.026659546652808785), (45, 0.026776783633977175), (48, 0.026865947293117642), (50, 0.027566451113671064), (38, 0.027829118305817246), (11, 0.029002359602600336), (3, 0.032272040378302336), (37, 0.03319812100380659), (13, 0.03333653509616852), (20, 0.03646321967244148), (12, 0.037992720026522875), (51, 0.038059926591813564), (9, 0.03963937144726515), (52, 0.04353108163923025), (19, 0.044218875002115965), (15, 0.046916747000068426), (14, 0.049041638150811195), (2, 0.05722745740786195), (0, 0.05888257548213005), (16, 0.06225228821858764), (5, 0.09379573725163937), (17, 0.25432228296995163), (36, 0.3958275243639946), (18, 0.4852069318294525), (53, 0.7794358655810356)]
computing accuracy for after removing block 28 . block score: 0.012290219077840447
removed block 28 current accuracy 0.9994 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011875. All blocks and scores: [(31, 0.011874645482748747), (29, 0.014790620421990752), (27, 0.016729247989133), (26, 0.01744490349665284), (1, 0.018259593285620213), (7, 0.01837918534874916), (8, 0.019532452803105116), (25, 0.019648711197078228), (24, 0.020829483633860946), (22, 0.02102166088297963), (47, 0.02134651760570705), (23, 0.02157451375387609), (35, 0.021596733713522553), (44, 0.021918716141954064), (46, 0.022734675323590636), (41, 0.023228027625009418), (6, 0.02466857945546508), (40, 0.02483913558535278), (43, 0.024858604883775115), (21, 0.025249343365430832), (39, 0.025966263609007), (48, 0.02597146388143301), (42, 0.02599131455644965), (49, 0.026064810575917363), (10, 0.02636369620449841), (45, 0.026453920640051365), (4, 0.026659545954316854), (50, 0.026680128183215857), (38, 0.02702008350752294), (11, 0.029002360068261623), (37, 0.032236403319984674), (3, 0.03227203991264105), (13, 0.033336535561829805), (20, 0.036463219206780195), (51, 0.037587924394756556), (12, 0.037992720026522875), (9, 0.03963936958462), (52, 0.04288490256294608), (19, 0.04421887639909983), (15, 0.046916747931391), (14, 0.049041638150811195), (2, 0.057227456010878086), (0, 0.058882574550807476), (16, 0.062252288684248924), (5, 0.09379573725163937), (17, 0.25432228669524193), (36, 0.3858989179134369), (18, 0.4852069206535816), (53, 0.7881819307804108)]
computing accuracy for after removing block 31 . block score: 0.011874645482748747
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.014791. All blocks and scores: [(29, 0.014790620538406074), (27, 0.016729248221963644), (26, 0.017444903263822198), (1, 0.018259592819958925), (7, 0.018379186280071735), (8, 0.019532452803105116), (25, 0.019648710498586297), (24, 0.02082948386669159), (47, 0.020932046696543694), (22, 0.02102166088297963), (44, 0.021379180951043963), (23, 0.02157451375387609), (46, 0.02206318941898644), (35, 0.022440448869019747), (41, 0.02264889213256538), (40, 0.024130781646817923), (43, 0.024664208060130477), (6, 0.02466858015395701), (21, 0.025249343132600188), (48, 0.025250396691262722), (49, 0.025515809655189514), (42, 0.025626871269196272), (39, 0.02564757945947349), (38, 0.025854782667011023), (50, 0.025972344912588596), (45, 0.026165933813899755), (10, 0.02636369690299034), (4, 0.026659545954316854), (11, 0.02900235913693905), (37, 0.03128928714431822), (3, 0.03227203991264105), (13, 0.03333653509616852), (20, 0.03646321967244148), (51, 0.03728976147249341), (12, 0.03799272142350674), (9, 0.03963937098160386), (52, 0.041992184706032276), (19, 0.04421887546777725), (15, 0.046916748862713575), (14, 0.049041636288166046), (2, 0.057227457873523235), (0, 0.0588825773447752), (16, 0.0622522896155715), (5, 0.09379573911428452), (17, 0.25432227551937103), (36, 0.3760597035288811), (18, 0.4852069243788719), (53, 0.801954098045826)]
computing accuracy for after removing block 29 . block score: 0.014790620538406074
removed block 29 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016729. All blocks and scores: [(27, 0.016729248221963644), (26, 0.017444903263822198), (1, 0.01825959258712828), (7, 0.018379185581579804), (8, 0.019532453268766403), (25, 0.019648710265755653), (47, 0.020515700103715062), (24, 0.020829484332352877), (44, 0.02097513247281313), (22, 0.02102166088297963), (23, 0.02157451305538416), (46, 0.021652451949194074), (41, 0.0226618186570704), (35, 0.022723624482750893), (40, 0.02388307498767972), (43, 0.02418972342275083), (6, 0.024668579688295722), (48, 0.024881582939997315), (49, 0.025212351698428392), (42, 0.0252292996738106), (21, 0.025249343598261476), (38, 0.025457143085077405), (50, 0.025512879248708487), (39, 0.025584626477211714), (45, 0.02621095417998731), (10, 0.02636369550600648), (4, 0.02665954572148621), (11, 0.029002359602600336), (37, 0.031102394685149193), (3, 0.03227204084396362), (13, 0.03333653602749109), (20, 0.036463219206780195), (51, 0.03752173809334636), (12, 0.03799272049218416), (9, 0.039639370515942574), (52, 0.041576670948415995), (19, 0.04421887639909983), (15, 0.046916748862713575), (14, 0.049041638150811195), (2, 0.057227456010878086), (0, 0.0588825773447752), (16, 0.062252286821603775), (5, 0.09379573538899422), (17, 0.2543222773820162), (36, 0.3744279034435749), (18, 0.4852069094777107), (53, 0.8058174103498459)]
computing accuracy for after removing block 27 . block score: 0.016729248221963644
removed block 27 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.017445. All blocks and scores: [(26, 0.017444903263822198), (1, 0.018259592819958925), (7, 0.018379186280071735), (8, 0.019532452803105116), (25, 0.019648710498586297), (47, 0.020196364726871252), (44, 0.020198779879137874), (24, 0.02082948386669159), (22, 0.0210216601844877), (46, 0.021314961835741997), (23, 0.02157451305538416), (35, 0.021661201491951942), (41, 0.022262451238930225), (40, 0.02343457192182541), (43, 0.02366974949836731), (48, 0.02387001784518361), (49, 0.024273037910461426), (39, 0.02463195798918605), (6, 0.02466857898980379), (50, 0.024705926422029734), (38, 0.024713971419259906), (42, 0.024764888919889927), (21, 0.025249343598261476), (45, 0.025909220799803734), (10, 0.02636369620449841), (4, 0.02665954572148621), (11, 0.02900235983543098), (37, 0.03029576176777482), (3, 0.03227204130962491), (13, 0.03333653509616852), (20, 0.03646321827545762), (51, 0.03686857596039772), (12, 0.03799272049218416), (9, 0.03963937144726515), (52, 0.040492805652320385), (19, 0.04421887546777725), (15, 0.04691674932837486), (14, 0.04904163861647248), (2, 0.0572274555452168), (0, 0.05888257781043649), (16, 0.06225228821858764), (5, 0.09379573725163937), (17, 0.2543222848325968), (36, 0.3650362640619278), (18, 0.4852069318294525), (53, 0.8347273245453835)]
computing accuracy for after removing block 26 . block score: 0.017444903263822198
removed block 26 current accuracy 0.9944 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018260. All blocks and scores: [(1, 0.01825959258712828), (7, 0.01837918534874916), (8, 0.019532452803105116), (25, 0.01964871073141694), (44, 0.019705433631315827), (47, 0.019746013451367617), (46, 0.02080916124396026), (24, 0.020829483633860946), (22, 0.02102166088297963), (35, 0.021195971174165606), (23, 0.021574513288214803), (41, 0.02216319367289543), (48, 0.022673572413623333), (40, 0.0228444782551378), (43, 0.023211446357890964), (49, 0.023580190492793918), (38, 0.02393691590987146), (39, 0.02414303505793214), (50, 0.024241250939667225), (42, 0.024461105233058333), (6, 0.024668579921126366), (21, 0.025249343132600188), (45, 0.02550865663215518), (10, 0.026363695738837123), (4, 0.02665954572148621), (11, 0.02900236053392291), (37, 0.029677377315238118), (3, 0.03227203991264105), (13, 0.033336535561829805), (51, 0.03632144723087549), (20, 0.03646321874111891), (12, 0.03799272095784545), (9, 0.039639371912926435), (52, 0.03989553218707442), (19, 0.044218875002115965), (15, 0.046916748862713575), (14, 0.04904163768514991), (2, 0.057227457873523235), (0, 0.05888257501646876), (16, 0.062252288684248924), (5, 0.09379573632031679), (17, 0.25432228669524193), (36, 0.36152271553874016), (18, 0.4852069281041622), (53, 0.8471468538045883)]
computing accuracy for after removing block 1 . block score: 0.01825959258712828
removed block 1 current accuracy 0.9932 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017854. All blocks and scores: [(7, 0.01785351149737835), (8, 0.01868281955830753), (25, 0.019129086518660188), (44, 0.019602667773142457), (24, 0.019680222729220986), (47, 0.019842988112941384), (22, 0.020383452996611595), (35, 0.020452448166906834), (46, 0.020825861720368266), (23, 0.021086918422952294), (41, 0.021640335908159614), (48, 0.02230572933331132), (40, 0.022332167252898216), (43, 0.022896901471540332), (38, 0.023239596281200647), (39, 0.023386763874441385), (49, 0.023744063451886177), (50, 0.024021204095333815), (6, 0.02404174581170082), (42, 0.024278491036966443), (21, 0.024377909488976002), (45, 0.02549561858177185), (10, 0.025961281498894095), (11, 0.028003805549815297), (4, 0.028626713901758194), (37, 0.02906385832466185), (3, 0.032400965224951506), (13, 0.03324462799355388), (20, 0.0351724773645401), (51, 0.03656556410714984), (12, 0.037181293591856956), (9, 0.03868303261697292), (52, 0.03969471110031009), (19, 0.04354848060756922), (15, 0.047371077351272106), (14, 0.0481217703782022), (2, 0.057159021496772766), (0, 0.05888257548213005), (16, 0.060861748177558184), (5, 0.09224656689912081), (17, 0.2509492486715317), (36, 0.34972937405109406), (18, 0.46861381456255913), (53, 0.8498541414737701)]
computing accuracy for after removing block 7 . block score: 0.01785351149737835
removed block 7 current accuracy 0.9926 loss from initial  0.007399999999999962
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.018390. All blocks and scores: [(25, 0.018389766570180655), (24, 0.018951865378767252), (35, 0.019241960253566504), (47, 0.019434643210843205), (44, 0.019624897744506598), (23, 0.019739443669095635), (22, 0.01995630143210292), (8, 0.01996665564365685), (46, 0.020434766076505184), (41, 0.021304226713255048), (40, 0.02142042270861566), (48, 0.021825639996677637), (43, 0.02223287569358945), (38, 0.0225537302903831), (39, 0.022905306424945593), (21, 0.023317469283938408), (50, 0.02360892458818853), (49, 0.023631911259144545), (42, 0.02400621841661632), (6, 0.024041746044531465), (45, 0.025045355781912804), (10, 0.026167657924816012), (11, 0.028026719810441136), (37, 0.02840108727104962), (4, 0.02862671297043562), (3, 0.032400965224951506), (13, 0.03292407561093569), (20, 0.034043310675770044), (51, 0.03644962003454566), (12, 0.03690121416002512), (52, 0.039229558780789375), (9, 0.03934459388256073), (19, 0.041988575365394354), (15, 0.046306459698826075), (14, 0.047303914558142424), (2, 0.05715902056545019), (0, 0.05888257687911391), (16, 0.05941257858648896), (5, 0.09224656596779823), (17, 0.238845843821764), (36, 0.3409247435629368), (18, 0.45438621938228607), (53, 0.8508737608790398)]
computing accuracy for after removing block 25 . block score: 0.018389766570180655
removed block 25 current accuracy 0.988 loss from initial  0.01200000000000001
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.018641. All blocks and scores: [(35, 0.01864069001749158), (24, 0.01895186584442854), (47, 0.019162753596901894), (44, 0.01937291957437992), (23, 0.019739443436264992), (22, 0.01995630143210292), (8, 0.019966655876487494), (46, 0.020180067280307412), (41, 0.020792829105630517), (40, 0.020806472981348634), (48, 0.021095545263960958), (38, 0.021664809668436646), (43, 0.022042255150154233), (39, 0.022102958289906383), (50, 0.022921857424080372), (49, 0.02298674453049898), (21, 0.02331746951676905), (42, 0.023690476780757308), (6, 0.024041746743023396), (45, 0.025103284744545817), (10, 0.026167658856138587), (37, 0.02770885149948299), (11, 0.028026720276102424), (4, 0.02862671297043562), (3, 0.03240096615627408), (13, 0.03292407561093569), (20, 0.03404331114143133), (51, 0.035923190880566835), (12, 0.03690121416002512), (52, 0.03849219577386975), (9, 0.039344592951238155), (19, 0.041988575365394354), (15, 0.04630645830184221), (14, 0.047303912695497274), (2, 0.05715902289375663), (0, 0.05888257594779134), (16, 0.05941258231177926), (5, 0.09224656410515308), (17, 0.23884584195911884), (36, 0.33257048204541206), (18, 0.4543862156569958), (53, 0.857995018362999)]
computing accuracy for after removing block 35 . block score: 0.01864069001749158
removed block 35 current accuracy 0.9826 loss from initial  0.01739999999999997
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.018301. All blocks and scores: [(47, 0.018301398027688265), (44, 0.01887912000529468), (24, 0.01895186584442854), (48, 0.019549657125025988), (46, 0.01955736498348415), (40, 0.01958549744449556), (23, 0.01973944390192628), (22, 0.019956301664933562), (8, 0.019966655876487494), (41, 0.01999355899170041), (38, 0.020276635652408004), (39, 0.020718253683298826), (43, 0.021324649220332503), (50, 0.021922264248132706), (49, 0.02205569949001074), (42, 0.02288483246229589), (21, 0.023317469749599695), (6, 0.024041746277362108), (45, 0.02426778362132609), (10, 0.0261676583904773), (37, 0.026483883149921894), (11, 0.028026719810441136), (4, 0.028626713436096907), (3, 0.03240096569061279), (13, 0.032924074213951826), (20, 0.03404331160709262), (51, 0.034338879864662886), (12, 0.03690121416002512), (52, 0.03733885195106268), (9, 0.03934459341689944), (19, 0.04198857443407178), (15, 0.04630645690485835), (14, 0.047303915489465), (2, 0.05715902056545019), (0, 0.05888257594779134), (16, 0.05941258044913411), (5, 0.09224656410515308), (17, 0.23884584568440914), (36, 0.31887492910027504), (18, 0.4543862119317055), (53, 0.8835926800966263)]
computing accuracy for after removing block 47 . block score: 0.018301398027688265
removed block 47 current accuracy 0.9784 loss from initial  0.021599999999999953
training start
training epoch 0 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 2 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best False lr [0.001]
training epoch 3 val accuracy 0.9982 topk_dict {'top1': 0.9982} is_best True lr [0.001]
training epoch 4 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best True lr [0.001]
training epoch 5 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 6 val accuracy 0.9984 topk_dict {'top1': 0.9984} is_best False lr [0.001]
training epoch 7 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 8 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 10 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 11 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 12 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best False lr [0.001]
training epoch 13 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 14 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 15 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best True lr [0.001]
training epoch 17 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 18 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 19 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 20 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 21 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 31 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 32 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 33 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 34 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 35 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 36 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 48 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best False lr [0.001]
training epoch 49 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
loading model_best from epoch 16 (acc 0.999600)
finished training. finished 50 epochs. accuracy 0.9996 topk_dict {'top1': 0.9996}
start iteration 14
[activation diff]: block to remove picked: 8, with score 0.019641. All blocks and scores: [(8, 0.019641214981675148), (22, 0.023031670600175858), (44, 0.02330499910749495), (41, 0.02385801589116454), (46, 0.024265082320198417), (24, 0.024828118039295077), (23, 0.025093604577705264), (43, 0.025178176118060946), (6, 0.025568627286702394), (39, 0.02577944565564394), (42, 0.02584164123982191), (40, 0.026256592478603125), (45, 0.026319759199395776), (10, 0.02721799840219319), (11, 0.028032839996740222), (38, 0.02803998999297619), (49, 0.02858438971452415), (4, 0.029083656845614314), (21, 0.029184052953496575), (48, 0.03016679733991623), (50, 0.030370943946763873), (13, 0.03278154833242297), (3, 0.033937732223421335), (37, 0.034889791160821915), (12, 0.03753777872771025), (9, 0.03808888513594866), (20, 0.039117805659770966), (51, 0.03976023010909557), (19, 0.0464639556594193), (52, 0.04724542377516627), (15, 0.04735505906865001), (14, 0.049005718901753426), (0, 0.058172392658889294), (2, 0.06016415450721979), (16, 0.06168701313436031), (5, 0.09092460293322802), (17, 0.2433237750083208), (36, 0.3992308899760246), (18, 0.46876729279756546), (53, 0.7172733917832375)]
computing accuracy for after removing block 8 . block score: 0.019641214981675148
removed block 8 current accuracy 0.9992 loss from initial  0.0008000000000000229
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.022490. All blocks and scores: [(22, 0.022490449948236346), (44, 0.023167278384789824), (41, 0.023520922055467963), (24, 0.023683737963438034), (46, 0.023839258588850498), (23, 0.02398018608801067), (43, 0.024811236187815666), (39, 0.025315021630376577), (40, 0.02549526677466929), (6, 0.025568627519533038), (42, 0.02573740598745644), (45, 0.025815864093601704), (38, 0.026957359164953232), (10, 0.027648080373182893), (21, 0.02784411096945405), (49, 0.028520317981019616), (4, 0.029083656147122383), (11, 0.0293009162414819), (48, 0.029482715530321002), (50, 0.030001502251252532), (13, 0.033228615298867226), (3, 0.03393773175776005), (37, 0.034221882931888103), (12, 0.037508437875658274), (20, 0.03835090436041355), (9, 0.039103358052670956), (51, 0.039396651554852724), (19, 0.04482700815424323), (15, 0.04644192522391677), (52, 0.04655672423541546), (14, 0.04772465908899903), (0, 0.058172394055873156), (2, 0.060164152178913355), (16, 0.06083649769425392), (5, 0.09092460479587317), (17, 0.23442408442497253), (36, 0.3885527104139328), (18, 0.45230599492788315), (53, 0.7163358330726624)]
computing accuracy for after removing block 22 . block score: 0.022490449948236346
removed block 22 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.022098. All blocks and scores: [(44, 0.022097640670835972), (23, 0.02215087879449129), (41, 0.0224177164491266), (46, 0.02282023662701249), (24, 0.023054696852341294), (40, 0.024132269667461514), (43, 0.02420256263576448), (39, 0.024247573455795646), (42, 0.024322817334905267), (45, 0.024992928141728044), (6, 0.025568627752363682), (38, 0.02591330884024501), (49, 0.026820265920832753), (48, 0.026983245508745313), (10, 0.02764808153733611), (21, 0.027844111900776625), (50, 0.028433409286662936), (4, 0.02908365661278367), (11, 0.029300916707143188), (37, 0.03289515292271972), (13, 0.033228615298867226), (3, 0.03393773129209876), (12, 0.037508437409996986), (20, 0.038350902032107115), (51, 0.038456718903034925), (9, 0.039103358052670956), (52, 0.04429412912577391), (19, 0.04482700861990452), (15, 0.046441926155239344), (14, 0.04772465629503131), (0, 0.05817239498719573), (2, 0.06016415357589722), (16, 0.06083649676293135), (5, 0.09092460386455059), (17, 0.23442408815026283), (36, 0.3695427402853966), (18, 0.45230600610375404), (53, 0.7235097661614418)]
computing accuracy for after removing block 44 . block score: 0.022097640670835972
removed block 44 current accuracy 0.9956 loss from initial  0.0043999999999999595
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.022151. All blocks and scores: [(23, 0.022150879027321935), (41, 0.022417716681957245), (24, 0.02305469778366387), (46, 0.023682690458372235), (40, 0.02413226873613894), (43, 0.02420256263576448), (39, 0.02424757368862629), (42, 0.02432281756773591), (45, 0.025362804997712374), (6, 0.025568627286702394), (38, 0.025913308607414365), (49, 0.026524651562795043), (48, 0.026990284910425544), (10, 0.027648081071674824), (21, 0.027844111202284694), (50, 0.028767020208761096), (4, 0.02908365661278367), (11, 0.029300915310159326), (37, 0.03289515431970358), (13, 0.033228615298867226), (3, 0.03393773129209876), (12, 0.037508437875658274), (20, 0.0383509024977684), (51, 0.03845771588385105), (9, 0.03910335572436452), (52, 0.043734647799283266), (19, 0.04482700861990452), (15, 0.04644192662090063), (14, 0.04772465908899903), (0, 0.058172392658889294), (2, 0.06016415264457464), (16, 0.06083650095388293), (5, 0.09092460665851831), (17, 0.23442408069968224), (36, 0.3695427365601063), (18, 0.45230600237846375), (53, 0.7821888998150826)]
computing accuracy for after removing block 23 . block score: 0.022150879027321935
removed block 23 current accuracy 0.992 loss from initial  0.008000000000000007
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 41, with score 0.021917. All blocks and scores: [(41, 0.0219167263712734), (46, 0.022766230395063758), (43, 0.0234289956279099), (24, 0.023555609164759517), (40, 0.023607198614627123), (42, 0.023929564282298088), (39, 0.02398852095939219), (45, 0.024863114580512047), (38, 0.025492973858490586), (49, 0.02554293442517519), (6, 0.025568627286702394), (48, 0.0260638608597219), (10, 0.027648081071674824), (21, 0.027844112366437912), (50, 0.027891746256500483), (4, 0.0290836573112756), (11, 0.029300915310159326), (37, 0.03247773600742221), (13, 0.033228615298867226), (3, 0.03393773082643747), (12, 0.0375084369443357), (51, 0.038103343453258276), (20, 0.03835090342909098), (9, 0.039103358052670956), (52, 0.042536718770861626), (19, 0.04482700815424323), (15, 0.04644192522391677), (14, 0.047724657226353884), (0, 0.058172394055873156), (2, 0.06016415264457464), (16, 0.06083649909123778), (5, 0.09092460107058287), (17, 0.23442408442497253), (36, 0.36021529883146286), (18, 0.45230601355433464), (53, 0.7829432860016823)]
computing accuracy for after removing block 41 . block score: 0.0219167263712734
removed block 41 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.010200000000000098 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 46, with score 0.022480. All blocks and scores: [(46, 0.022479633800685406), (42, 0.02295430703088641), (43, 0.022968352306634188), (24, 0.023555608466267586), (40, 0.023607197450473905), (39, 0.023988521192222834), (49, 0.024045037804171443), (45, 0.024113863008096814), (48, 0.02512633567675948), (38, 0.0254929733928293), (6, 0.025568626821041107), (50, 0.02678820351138711), (10, 0.027648081304505467), (21, 0.027844111202284694), (4, 0.029083656845614314), (11, 0.02930091554298997), (37, 0.032477736473083496), (13, 0.033228615298867226), (3, 0.03393773129209876), (51, 0.036651887465268373), (12, 0.03750843834131956), (20, 0.038350903894752264), (9, 0.03910335712134838), (52, 0.04111776361241937), (19, 0.04482700955122709), (15, 0.04644192662090063), (14, 0.04772465815767646), (0, 0.058172394055873156), (2, 0.060164154041558504), (16, 0.06083649676293135), (5, 0.09092460479587317), (17, 0.23442408069968224), (36, 0.36021530255675316), (18, 0.45230600610375404), (53, 0.8685766533017159)]
computing accuracy for after removing block 46 . block score: 0.022479633800685406
removed block 46 current accuracy 0.9836 loss from initial  0.01639999999999997
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.022954. All blocks and scores: [(42, 0.022954307263717055), (43, 0.022968352073803544), (24, 0.02355560869909823), (40, 0.023607197683304548), (39, 0.02398852026090026), (45, 0.02411386463791132), (49, 0.0245105791836977), (38, 0.0254929733928293), (48, 0.025527474703267217), (6, 0.025568627286702394), (50, 0.02699243347160518), (10, 0.0276480820029974), (21, 0.027844110503792763), (4, 0.029083657544106245), (11, 0.02930091484449804), (37, 0.03247773600742221), (13, 0.03322861483320594), (3, 0.03393773129209876), (51, 0.03746092226356268), (12, 0.03750843647867441), (20, 0.038350903894752264), (9, 0.039103358052670956), (52, 0.04153934679925442), (19, 0.04482700815424323), (15, 0.04644192522391677), (14, 0.047724657226353884), (0, 0.05817239312455058), (2, 0.06016415357589722), (16, 0.060836498625576496), (5, 0.09092460293322802), (17, 0.23442407324910164), (36, 0.36021529510617256), (18, 0.45230600982904434), (53, 0.950081542134285)]
computing accuracy for after removing block 42 . block score: 0.022954307263717055
removed block 42 current accuracy 0.9684 loss from initial  0.03159999999999996
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.023556. All blocks and scores: [(24, 0.02355560939759016), (40, 0.023607198614627123), (49, 0.02370002563111484), (45, 0.023969218600541353), (39, 0.023988521192222834), (43, 0.024081272538751364), (48, 0.0253971666097641), (38, 0.025492972694337368), (6, 0.025568627985194325), (50, 0.026886719977483153), (10, 0.027648081071674824), (21, 0.027844111435115337), (4, 0.02908365847542882), (11, 0.029300916008651257), (37, 0.03247773693874478), (13, 0.03322861576452851), (3, 0.03393773082643747), (51, 0.036583730019629), (12, 0.0375084369443357), (20, 0.03835090342909098), (9, 0.039103358052670956), (52, 0.04080019798129797), (19, 0.04482700955122709), (15, 0.04644192475825548), (14, 0.04772465769201517), (0, 0.05817239312455058), (2, 0.06016415311023593), (16, 0.060836498625576496), (5, 0.09092460293322802), (17, 0.23442407697439194), (36, 0.36021529510617256), (18, 0.45230599865317345), (53, 1.0550836026668549)]
computing accuracy for after removing block 24 . block score: 0.02355560939759016
removed block 24 current accuracy 0.9512 loss from initial  0.048799999999999955
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.022514. All blocks and scores: [(39, 0.02251394046470523), (49, 0.022542661987245083), (40, 0.022585681173950434), (45, 0.02286789962090552), (43, 0.022959963884204626), (48, 0.02390886261127889), (38, 0.024258576799184084), (50, 0.02553435368463397), (6, 0.025568627519533038), (10, 0.027648079674690962), (21, 0.027844111202284694), (4, 0.029083658009767532), (11, 0.029300916474312544), (37, 0.031003761803731322), (13, 0.0332286162301898), (3, 0.03393773175776005), (51, 0.035072626546025276), (12, 0.037508437409996986), (20, 0.0383509024977684), (9, 0.03910335758700967), (52, 0.03951903712004423), (19, 0.04482700815424323), (15, 0.046441925689578056), (14, 0.047724656760692596), (0, 0.058172390796244144), (2, 0.060164154041558504), (16, 0.06083649629727006), (5, 0.09092460572719574), (17, 0.23442408069968224), (36, 0.3466899134218693), (18, 0.45230600610375404), (53, 1.0914894193410873)]
computing accuracy for after removing block 39 . block score: 0.02251394046470523
removed block 39 current accuracy 0.928 loss from initial  0.07199999999999995
since last training loss: 0.0716 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 49, with score 0.021453. All blocks and scores: [(49, 0.021452566143125296), (43, 0.022495253942906857), (45, 0.022660144604742527), (48, 0.022861470002681017), (40, 0.02310358895920217), (50, 0.02407363406382501), (38, 0.024258577497676015), (6, 0.025568627286702394), (10, 0.02764808153733611), (21, 0.027844111435115337), (4, 0.02908365777693689), (11, 0.029300915775820613), (37, 0.03100376226939261), (51, 0.03280436433851719), (13, 0.03322861483320594), (3, 0.03393773082643747), (12, 0.0375084369443357), (20, 0.03835090296342969), (52, 0.038390891160815954), (9, 0.03910335712134838), (19, 0.044827007222920656), (15, 0.046441926155239344), (14, 0.047724658623337746), (0, 0.05817239452153444), (2, 0.06016415311023593), (16, 0.060836497228592634), (5, 0.09092460200190544), (17, 0.23442408256232738), (36, 0.34668993949890137), (18, 0.45230600610375404), (53, 1.1803598254919052)]
computing accuracy for after removing block 49 . block score: 0.021452566143125296
removed block 49 current accuracy 0.9062 loss from initial  0.0938
since last training loss: 0.09340000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 43, with score 0.022495. All blocks and scores: [(43, 0.022495254408568144), (45, 0.022660144604742527), (48, 0.022861470002681017), (40, 0.023103588726371527), (38, 0.024258577032014728), (50, 0.025179221760481596), (6, 0.025568627519533038), (10, 0.027648081071674824), (21, 0.027844111435115337), (4, 0.0290836573112756), (11, 0.029300915077328682), (37, 0.031003762036561966), (13, 0.03322861669585109), (3, 0.03393773082643747), (51, 0.03586473874747753), (12, 0.03750843647867441), (20, 0.03835090296342969), (9, 0.039103356190025806), (52, 0.04048933833837509), (19, 0.044827009085565805), (15, 0.046441927552223206), (14, 0.04772465815767646), (0, 0.058172392658889294), (2, 0.06016415450721979), (16, 0.06083649815991521), (5, 0.09092460107058287), (17, 0.23442408815026283), (36, 0.3466899208724499), (18, 0.45230600610375404), (53, 1.3051340728998184)]
computing accuracy for after removing block 43 . block score: 0.022495254408568144
removed block 43 current accuracy 0.8648 loss from initial  0.1352
since last training loss: 0.13480000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.022708. All blocks and scores: [(45, 0.02270848723128438), (40, 0.02310359012335539), (48, 0.023371590301394463), (38, 0.024258577497676015), (50, 0.024957050569355488), (6, 0.025568627985194325), (10, 0.027648081071674824), (21, 0.027844111202284694), (4, 0.029083658009767532), (11, 0.029300916008651257), (37, 0.03100376296788454), (13, 0.033228615298867226), (3, 0.03393773175776005), (51, 0.03526182845234871), (12, 0.037508437875658274), (20, 0.03835090342909098), (9, 0.039103356655687094), (52, 0.041520817670971155), (19, 0.04482700815424323), (15, 0.046441926155239344), (14, 0.04772465769201517), (0, 0.058172394055873156), (2, 0.06016415171325207), (16, 0.06083649676293135), (5, 0.09092460479587317), (17, 0.2344240788370371), (36, 0.3466899245977402), (18, 0.45230600982904434), (53, 1.444030538201332)]
computing accuracy for after removing block 45 . block score: 0.02270848723128438
removed block 45 current accuracy 0.8194 loss from initial  0.18059999999999998
since last training loss: 0.18020000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 40, with score 0.023104. All blocks and scores: [(40, 0.023103588493540883), (38, 0.02425857773050666), (48, 0.0244009243324399), (50, 0.02520908717997372), (6, 0.02556862705387175), (10, 0.027648081304505467), (21, 0.027844111900776625), (4, 0.02908365777693689), (11, 0.02930091484449804), (37, 0.031003762735053897), (13, 0.033228615298867226), (3, 0.03393773082643747), (51, 0.03580403607338667), (12, 0.03750843647867441), (20, 0.03835090296342969), (9, 0.03910335712134838), (52, 0.04331043967977166), (19, 0.04482700815424323), (15, 0.04644192522391677), (14, 0.047724658623337746), (0, 0.058172394055873156), (2, 0.06016415357589722), (16, 0.06083649909123778), (5, 0.09092460665851831), (17, 0.23442408256232738), (36, 0.34668993204832077), (18, 0.45230600982904434), (53, 1.5600006878376007)]
computing accuracy for after removing block 40 . block score: 0.023103588493540883
removed block 40 current accuracy 0.7698 loss from initial  0.23019999999999996
training start
training epoch 0 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 1 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.001]
training epoch 2 val accuracy 0.9576 topk_dict {'top1': 0.9576} is_best True lr [0.001]
training epoch 3 val accuracy 0.961 topk_dict {'top1': 0.961} is_best True lr [0.001]
training epoch 4 val accuracy 0.9632 topk_dict {'top1': 0.9632} is_best True lr [0.001]
training epoch 5 val accuracy 0.9654 topk_dict {'top1': 0.9654} is_best True lr [0.001]
training epoch 6 val accuracy 0.9668 topk_dict {'top1': 0.9668} is_best True lr [0.001]
training epoch 7 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best True lr [0.001]
training epoch 8 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.001]
training epoch 9 val accuracy 0.971 topk_dict {'top1': 0.971} is_best True lr [0.001]
training epoch 10 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best True lr [0.001]
training epoch 11 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best True lr [0.001]
training epoch 12 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 13 val accuracy 0.9738 topk_dict {'top1': 0.9738} is_best True lr [0.001]
training epoch 14 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.001]
training epoch 15 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.001]
training epoch 16 val accuracy 0.974 topk_dict {'top1': 0.974} is_best True lr [0.001]
training epoch 17 val accuracy 0.9752 topk_dict {'top1': 0.9752} is_best True lr [0.001]
training epoch 18 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best True lr [0.001]
training epoch 19 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 20 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 21 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 22 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 23 val accuracy 0.9766 topk_dict {'top1': 0.9766} is_best False lr [0.001]
training epoch 24 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 25 val accuracy 0.979 topk_dict {'top1': 0.979} is_best False lr [0.001]
training epoch 26 val accuracy 0.9784 topk_dict {'top1': 0.9784} is_best False lr [0.001]
training epoch 27 val accuracy 0.9782 topk_dict {'top1': 0.9782} is_best False lr [0.001]
training epoch 28 val accuracy 0.9788 topk_dict {'top1': 0.9788} is_best False lr [0.001]
training epoch 29 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best True lr [0.001]
training epoch 30 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 31 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 32 val accuracy 0.9796 topk_dict {'top1': 0.9796} is_best True lr [0.001]
training epoch 33 val accuracy 0.9774 topk_dict {'top1': 0.9774} is_best False lr [0.001]
training epoch 34 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best True lr [0.001]
training epoch 35 val accuracy 0.9798 topk_dict {'top1': 0.9798} is_best False lr [0.001]
training epoch 36 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best True lr [0.001]
training epoch 37 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best True lr [0.001]
training epoch 38 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 39 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 40 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 41 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 42 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 43 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 44 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best True lr [0.001]
training epoch 45 val accuracy 0.9826 topk_dict {'top1': 0.9826} is_best True lr [0.001]
training epoch 46 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 47 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 48 val accuracy 0.9816 topk_dict {'top1': 0.9816} is_best False lr [0.001]
training epoch 49 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.982600)
finished training. finished 50 epochs. accuracy 0.9826 topk_dict {'top1': 0.9826}
