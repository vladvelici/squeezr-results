start iteration 0
(cache recomputed) Accuracy log [(0, 1.0, {'top1': 1.0}), (1, 1.0, {'top1': 1.0}), (2, 0.9992, {'top1': 0.9992}), (3, 1.0, {'top1': 1.0}), (4, 0.9994, {'top1': 0.9994}), (5, 1.0, {'top1': 1.0}), (6, 1.0, {'top1': 1.0}), (7, 1.0, {'top1': 1.0}), (8, 0.9992, {'top1': 0.9992}), (9, 0.9982, {'top1': 0.9982}), (10, 0.9942, {'top1': 0.9942}), (11, 1.0, {'top1': 1.0}), (12, 0.9998, {'top1': 0.9998}), (13, 1.0, {'top1': 1.0}), (14, 1.0, {'top1': 1.0}), (15, 0.9996, {'top1': 0.9996}), (16, 0.9998, {'top1': 0.9998}), (17, 0.9978, {'top1': 0.9978}), (18, 0.7344, {'top1': 0.7344}), (19, 1.0, {'top1': 1.0}), (20, 1.0, {'top1': 1.0}), (21, 1.0, {'top1': 1.0}), (22, 1.0, {'top1': 1.0}), (23, 1.0, {'top1': 1.0}), (24, 1.0, {'top1': 1.0}), (25, 1.0, {'top1': 1.0}), (26, 1.0, {'top1': 1.0}), (27, 1.0, {'top1': 1.0}), (28, 1.0, {'top1': 1.0}), (29, 1.0, {'top1': 1.0}), (30, 1.0, {'top1': 1.0}), (31, 1.0, {'top1': 1.0}), (32, 1.0, {'top1': 1.0}), (33, 1.0, {'top1': 1.0}), (34, 1.0, {'top1': 1.0}), (35, 1.0, {'top1': 1.0}), (36, 0.7354, {'top1': 0.7354}), (37, 0.9998, {'top1': 0.9998}), (38, 1.0, {'top1': 1.0}), (39, 1.0, {'top1': 1.0}), (40, 0.9998, {'top1': 0.9998}), (41, 1.0, {'top1': 1.0}), (42, 0.9998, {'top1': 0.9998}), (43, 1.0, {'top1': 1.0}), (44, 0.9986, {'top1': 0.9986}), (45, 0.9996, {'top1': 0.9996}), (46, 1.0, {'top1': 1.0}), (47, 0.9992, {'top1': 0.9992}), (48, 1.0, {'top1': 1.0}), (49, 1.0, {'top1': 1.0}), (50, 0.9984, {'top1': 0.9984}), (51, 1.0, {'top1': 1.0}), (52, 0.9992, {'top1': 0.9992}), (53, 0.9716, {'top1': 0.9716})]
just computed impact of block 0 . accuracy after removing:  1.0
removed block 0 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(1, 0.995, {'top1': 0.995}), (2, 0.9864, {'top1': 0.9864}), (3, 0.9986, {'top1': 0.9986}), (4, 0.9806, {'top1': 0.9806}), (5, 0.9996, {'top1': 0.9996}), (6, 0.9998, {'top1': 0.9998}), (7, 0.9974, {'top1': 0.9974}), (8, 0.9948, {'top1': 0.9948}), (9, 0.9936, {'top1': 0.9936}), (10, 0.9926, {'top1': 0.9926}), (11, 0.999, {'top1': 0.999}), (12, 0.9982, {'top1': 0.9982}), (13, 0.9992, {'top1': 0.9992}), (14, 0.998, {'top1': 0.998}), (15, 0.9982, {'top1': 0.9982}), (16, 0.9972, {'top1': 0.9972}), (17, 0.9932, {'top1': 0.9932}), (18, 0.6866, {'top1': 0.6866}), (19, 0.9998, {'top1': 0.9998}), (20, 1.0, {'top1': 1.0}), (21, 0.9994, {'top1': 0.9994}), (22, 0.9998, {'top1': 0.9998}), (23, 1.0, {'top1': 1.0}), (24, 0.9998, {'top1': 0.9998}), (25, 1.0, {'top1': 1.0}), (26, 0.9998, {'top1': 0.9998}), (27, 0.9998, {'top1': 0.9998}), (28, 0.9998, {'top1': 0.9998}), (29, 0.9998, {'top1': 0.9998}), (30, 0.9996, {'top1': 0.9996}), (31, 0.9998, {'top1': 0.9998}), (32, 0.9998, {'top1': 0.9998}), (33, 0.9998, {'top1': 0.9998}), (34, 0.9996, {'top1': 0.9996}), (35, 0.9996, {'top1': 0.9996}), (36, 0.696, {'top1': 0.696}), (37, 0.9998, {'top1': 0.9998}), (38, 0.9996, {'top1': 0.9996}), (39, 0.9992, {'top1': 0.9992}), (40, 0.9994, {'top1': 0.9994}), (41, 0.9994, {'top1': 0.9994}), (42, 0.9992, {'top1': 0.9992}), (43, 0.9986, {'top1': 0.9986}), (44, 0.9974, {'top1': 0.9974}), (45, 0.9992, {'top1': 0.9992}), (46, 0.9984, {'top1': 0.9984}), (47, 0.9986, {'top1': 0.9986}), (48, 0.9988, {'top1': 0.9988}), (49, 0.9996, {'top1': 0.9996}), (50, 0.9968, {'top1': 0.9968}), (51, 0.999, {'top1': 0.999}), (52, 0.9968, {'top1': 0.9968}), (53, 0.9542, {'top1': 0.9542})]
just computed impact of block 20 . accuracy after removing:  1.0
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(1, 0.994, {'top1': 0.994}), (2, 0.983, {'top1': 0.983}), (3, 0.9964, {'top1': 0.9964}), (4, 0.9778, {'top1': 0.9778}), (5, 0.9994, {'top1': 0.9994}), (6, 0.9984, {'top1': 0.9984}), (7, 0.9974, {'top1': 0.9974}), (8, 0.9968, {'top1': 0.9968}), (9, 0.992, {'top1': 0.992}), (10, 0.9906, {'top1': 0.9906}), (11, 0.999, {'top1': 0.999}), (12, 0.998, {'top1': 0.998}), (13, 0.9992, {'top1': 0.9992}), (14, 0.9988, {'top1': 0.9988}), (15, 0.9982, {'top1': 0.9982}), (16, 0.9968, {'top1': 0.9968}), (17, 0.9938, {'top1': 0.9938}), (18, 0.66, {'top1': 0.66}), (19, 1.0, {'top1': 1.0}), (21, 0.9996, {'top1': 0.9996}), (22, 1.0, {'top1': 1.0}), (23, 0.9998, {'top1': 0.9998}), (24, 1.0, {'top1': 1.0}), (25, 1.0, {'top1': 1.0}), (26, 0.9994, {'top1': 0.9994}), (27, 0.9994, {'top1': 0.9994}), (28, 0.9994, {'top1': 0.9994}), (29, 0.9996, {'top1': 0.9996}), (30, 0.9998, {'top1': 0.9998}), (31, 0.9998, {'top1': 0.9998}), (32, 0.9994, {'top1': 0.9994}), (33, 0.9996, {'top1': 0.9996}), (34, 0.9992, {'top1': 0.9992}), (35, 0.9998, {'top1': 0.9998}), (36, 0.6642, {'top1': 0.6642}), (37, 0.999, {'top1': 0.999}), (38, 0.9996, {'top1': 0.9996}), (39, 0.9988, {'top1': 0.9988}), (40, 0.9992, {'top1': 0.9992}), (41, 0.9992, {'top1': 0.9992}), (42, 0.9978, {'top1': 0.9978}), (43, 0.9986, {'top1': 0.9986}), (44, 0.9972, {'top1': 0.9972}), (45, 0.999, {'top1': 0.999}), (46, 0.9976, {'top1': 0.9976}), (47, 0.998, {'top1': 0.998}), (48, 0.9986, {'top1': 0.9986}), (49, 0.9988, {'top1': 0.9988}), (50, 0.9962, {'top1': 0.9962}), (51, 0.9992, {'top1': 0.9992}), (52, 0.9966, {'top1': 0.9966}), (53, 0.9482, {'top1': 0.9482})]
just computed impact of block 19 . accuracy after removing:  1.0
removed block 19 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(1, 0.992, {'top1': 0.992}), (2, 0.979, {'top1': 0.979}), (3, 0.9946, {'top1': 0.9946}), (4, 0.972, {'top1': 0.972}), (5, 0.999, {'top1': 0.999}), (6, 0.9982, {'top1': 0.9982}), (7, 0.9954, {'top1': 0.9954}), (8, 0.9958, {'top1': 0.9958}), (9, 0.9892, {'top1': 0.9892}), (10, 0.9888, {'top1': 0.9888}), (11, 0.9978, {'top1': 0.9978}), (12, 0.997, {'top1': 0.997}), (13, 0.9988, {'top1': 0.9988}), (14, 0.9982, {'top1': 0.9982}), (15, 0.9974, {'top1': 0.9974}), (16, 0.9954, {'top1': 0.9954}), (17, 0.9928, {'top1': 0.9928}), (18, 0.6676, {'top1': 0.6676}), (21, 0.999, {'top1': 0.999}), (22, 0.9998, {'top1': 0.9998}), (23, 0.9998, {'top1': 0.9998}), (24, 0.9994, {'top1': 0.9994}), (25, 0.9998, {'top1': 0.9998}), (26, 0.9982, {'top1': 0.9982}), (27, 0.9988, {'top1': 0.9988}), (28, 0.9992, {'top1': 0.9992}), (29, 0.999, {'top1': 0.999}), (30, 0.9994, {'top1': 0.9994}), (31, 0.9994, {'top1': 0.9994}), (32, 0.9988, {'top1': 0.9988}), (33, 0.9994, {'top1': 0.9994}), (34, 0.9988, {'top1': 0.9988}), (35, 0.999, {'top1': 0.999}), (36, 0.6486, {'top1': 0.6486}), (37, 0.998, {'top1': 0.998}), (38, 0.9986, {'top1': 0.9986}), (39, 0.9986, {'top1': 0.9986}), (40, 0.9986, {'top1': 0.9986}), (41, 0.9986, {'top1': 0.9986}), (42, 0.9966, {'top1': 0.9966}), (43, 0.9976, {'top1': 0.9976}), (44, 0.996, {'top1': 0.996}), (45, 0.999, {'top1': 0.999}), (46, 0.9972, {'top1': 0.9972}), (47, 0.9978, {'top1': 0.9978}), (48, 0.9978, {'top1': 0.9978}), (49, 0.9978, {'top1': 0.9978}), (50, 0.9954, {'top1': 0.9954}), (51, 0.9982, {'top1': 0.9982}), (52, 0.9964, {'top1': 0.9964}), (53, 0.939, {'top1': 0.939})]
just computed impact of block 22 . accuracy after removing:  0.9998
removed block 22 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(1, 0.9904, {'top1': 0.9904}), (2, 0.975, {'top1': 0.975}), (3, 0.9928, {'top1': 0.9928}), (4, 0.9676, {'top1': 0.9676}), (5, 0.9984, {'top1': 0.9984}), (6, 0.9982, {'top1': 0.9982}), (7, 0.9944, {'top1': 0.9944}), (8, 0.9932, {'top1': 0.9932}), (9, 0.9872, {'top1': 0.9872}), (10, 0.9872, {'top1': 0.9872}), (11, 0.9974, {'top1': 0.9974}), (12, 0.9968, {'top1': 0.9968}), (13, 0.9984, {'top1': 0.9984}), (14, 0.9976, {'top1': 0.9976}), (15, 0.996, {'top1': 0.996}), (16, 0.9944, {'top1': 0.9944}), (17, 0.992, {'top1': 0.992}), (18, 0.6648, {'top1': 0.6648}), (21, 0.998, {'top1': 0.998}), (23, 0.9992, {'top1': 0.9992}), (24, 0.999, {'top1': 0.999}), (25, 0.9998, {'top1': 0.9998}), (26, 0.9978, {'top1': 0.9978}), (27, 0.9974, {'top1': 0.9974}), (28, 0.9986, {'top1': 0.9986}), (29, 0.9986, {'top1': 0.9986}), (30, 0.9986, {'top1': 0.9986}), (31, 0.9988, {'top1': 0.9988}), (32, 0.9984, {'top1': 0.9984}), (33, 0.999, {'top1': 0.999}), (34, 0.9978, {'top1': 0.9978}), (35, 0.999, {'top1': 0.999}), (36, 0.6354, {'top1': 0.6354}), (37, 0.9974, {'top1': 0.9974}), (38, 0.9974, {'top1': 0.9974}), (39, 0.9978, {'top1': 0.9978}), (40, 0.9984, {'top1': 0.9984}), (41, 0.998, {'top1': 0.998}), (42, 0.9948, {'top1': 0.9948}), (43, 0.9962, {'top1': 0.9962}), (44, 0.9946, {'top1': 0.9946}), (45, 0.9974, {'top1': 0.9974}), (46, 0.996, {'top1': 0.996}), (47, 0.9974, {'top1': 0.9974}), (48, 0.9976, {'top1': 0.9976}), (49, 0.9968, {'top1': 0.9968}), (50, 0.9944, {'top1': 0.9944}), (51, 0.9978, {'top1': 0.9978}), (52, 0.9952, {'top1': 0.9952}), (53, 0.9342, {'top1': 0.9342})]
just computed impact of block 25 . accuracy after removing:  0.9998
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(1, 0.99, {'top1': 0.99}), (2, 0.9754, {'top1': 0.9754}), (3, 0.9936, {'top1': 0.9936}), (4, 0.9668, {'top1': 0.9668}), (5, 0.9986, {'top1': 0.9986}), (6, 0.998, {'top1': 0.998}), (7, 0.9932, {'top1': 0.9932}), (8, 0.992, {'top1': 0.992}), (9, 0.9856, {'top1': 0.9856}), (10, 0.9856, {'top1': 0.9856}), (11, 0.9974, {'top1': 0.9974}), (12, 0.9958, {'top1': 0.9958}), (13, 0.9974, {'top1': 0.9974}), (14, 0.9972, {'top1': 0.9972}), (15, 0.9954, {'top1': 0.9954}), (16, 0.9944, {'top1': 0.9944}), (17, 0.9912, {'top1': 0.9912}), (18, 0.624, {'top1': 0.624}), (21, 0.9978, {'top1': 0.9978}), (23, 0.9986, {'top1': 0.9986}), (24, 0.9988, {'top1': 0.9988}), (26, 0.9976, {'top1': 0.9976}), (27, 0.9974, {'top1': 0.9974}), (28, 0.9986, {'top1': 0.9986}), (29, 0.9986, {'top1': 0.9986}), (30, 0.9988, {'top1': 0.9988}), (31, 0.9986, {'top1': 0.9986}), (32, 0.9982, {'top1': 0.9982}), (33, 0.9982, {'top1': 0.9982}), (34, 0.9976, {'top1': 0.9976}), (35, 0.9986, {'top1': 0.9986}), (36, 0.6082, {'top1': 0.6082}), (37, 0.997, {'top1': 0.997}), (38, 0.998, {'top1': 0.998}), (39, 0.9976, {'top1': 0.9976}), (40, 0.9986, {'top1': 0.9986}), (41, 0.9966, {'top1': 0.9966}), (42, 0.9952, {'top1': 0.9952}), (43, 0.995, {'top1': 0.995}), (44, 0.9938, {'top1': 0.9938}), (45, 0.9974, {'top1': 0.9974}), (46, 0.997, {'top1': 0.997}), (47, 0.9968, {'top1': 0.9968}), (48, 0.9978, {'top1': 0.9978}), (49, 0.9966, {'top1': 0.9966}), (50, 0.9942, {'top1': 0.9942}), (51, 0.9978, {'top1': 0.9978}), (52, 0.9946, {'top1': 0.9946}), (53, 0.9334, {'top1': 0.9334})]
just computed impact of block 24 . accuracy after removing:  0.9988
removed block 24 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(1, 0.9888, {'top1': 0.9888}), (2, 0.9704, {'top1': 0.9704}), (3, 0.9912, {'top1': 0.9912}), (4, 0.9634, {'top1': 0.9634}), (5, 0.9972, {'top1': 0.9972}), (6, 0.9966, {'top1': 0.9966}), (7, 0.991, {'top1': 0.991}), (8, 0.9906, {'top1': 0.9906}), (9, 0.9822, {'top1': 0.9822}), (10, 0.9812, {'top1': 0.9812}), (11, 0.9954, {'top1': 0.9954}), (12, 0.994, {'top1': 0.994}), (13, 0.9958, {'top1': 0.9958}), (14, 0.995, {'top1': 0.995}), (15, 0.9938, {'top1': 0.9938}), (16, 0.9926, {'top1': 0.9926}), (17, 0.9892, {'top1': 0.9892}), (18, 0.6022, {'top1': 0.6022}), (21, 0.9966, {'top1': 0.9966}), (23, 0.9962, {'top1': 0.9962}), (26, 0.9956, {'top1': 0.9956}), (27, 0.996, {'top1': 0.996}), (28, 0.9966, {'top1': 0.9966}), (29, 0.9968, {'top1': 0.9968}), (30, 0.9964, {'top1': 0.9964}), (31, 0.9964, {'top1': 0.9964}), (32, 0.9974, {'top1': 0.9974}), (33, 0.9974, {'top1': 0.9974}), (34, 0.9964, {'top1': 0.9964}), (35, 0.9976, {'top1': 0.9976}), (36, 0.5882, {'top1': 0.5882}), (37, 0.996, {'top1': 0.996}), (38, 0.9966, {'top1': 0.9966}), (39, 0.9964, {'top1': 0.9964}), (40, 0.9978, {'top1': 0.9978}), (41, 0.995, {'top1': 0.995}), (42, 0.993, {'top1': 0.993}), (43, 0.9938, {'top1': 0.9938}), (44, 0.9926, {'top1': 0.9926}), (45, 0.9962, {'top1': 0.9962}), (46, 0.9954, {'top1': 0.9954}), (47, 0.9954, {'top1': 0.9954}), (48, 0.9966, {'top1': 0.9966}), (49, 0.9948, {'top1': 0.9948}), (50, 0.9922, {'top1': 0.9922}), (51, 0.9968, {'top1': 0.9968}), (52, 0.9926, {'top1': 0.9926}), (53, 0.9258, {'top1': 0.9258})]
just computed impact of block 40 . accuracy after removing:  0.9978
removed block 40 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(1, 0.987, {'top1': 0.987}), (2, 0.9656, {'top1': 0.9656}), (3, 0.99, {'top1': 0.99}), (4, 0.9546, {'top1': 0.9546}), (5, 0.9958, {'top1': 0.9958}), (6, 0.9946, {'top1': 0.9946}), (7, 0.9886, {'top1': 0.9886}), (8, 0.9868, {'top1': 0.9868}), (9, 0.9806, {'top1': 0.9806}), (10, 0.977, {'top1': 0.977}), (11, 0.993, {'top1': 0.993}), (12, 0.9924, {'top1': 0.9924}), (13, 0.9944, {'top1': 0.9944}), (14, 0.9918, {'top1': 0.9918}), (15, 0.9898, {'top1': 0.9898}), (16, 0.9856, {'top1': 0.9856}), (17, 0.9836, {'top1': 0.9836}), (18, 0.578, {'top1': 0.578}), (21, 0.9946, {'top1': 0.9946}), (23, 0.9946, {'top1': 0.9946}), (26, 0.9942, {'top1': 0.9942}), (27, 0.9928, {'top1': 0.9928}), (28, 0.9944, {'top1': 0.9944}), (29, 0.9952, {'top1': 0.9952}), (30, 0.9956, {'top1': 0.9956}), (31, 0.9948, {'top1': 0.9948}), (32, 0.9954, {'top1': 0.9954}), (33, 0.9954, {'top1': 0.9954}), (34, 0.9936, {'top1': 0.9936}), (35, 0.9966, {'top1': 0.9966}), (36, 0.5434, {'top1': 0.5434}), (37, 0.9934, {'top1': 0.9934}), (38, 0.9942, {'top1': 0.9942}), (39, 0.9928, {'top1': 0.9928}), (41, 0.9916, {'top1': 0.9916}), (42, 0.9864, {'top1': 0.9864}), (43, 0.9888, {'top1': 0.9888}), (44, 0.9896, {'top1': 0.9896}), (45, 0.9932, {'top1': 0.9932}), (46, 0.9902, {'top1': 0.9902}), (47, 0.9902, {'top1': 0.9902}), (48, 0.9936, {'top1': 0.9936}), (49, 0.9904, {'top1': 0.9904}), (50, 0.9884, {'top1': 0.9884}), (51, 0.9928, {'top1': 0.9928}), (52, 0.9872, {'top1': 0.9872}), (53, 0.9024, {'top1': 0.9024})]
just computed impact of block 35 . accuracy after removing:  0.9966
removed block 35 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(1, 0.985, {'top1': 0.985}), (2, 0.9638, {'top1': 0.9638}), (3, 0.9888, {'top1': 0.9888}), (4, 0.9552, {'top1': 0.9552}), (5, 0.994, {'top1': 0.994}), (6, 0.993, {'top1': 0.993}), (7, 0.9886, {'top1': 0.9886}), (8, 0.984, {'top1': 0.984}), (9, 0.9764, {'top1': 0.9764}), (10, 0.9766, {'top1': 0.9766}), (11, 0.9916, {'top1': 0.9916}), (12, 0.9904, {'top1': 0.9904}), (13, 0.9922, {'top1': 0.9922}), (14, 0.9914, {'top1': 0.9914}), (15, 0.9884, {'top1': 0.9884}), (16, 0.9858, {'top1': 0.9858}), (17, 0.9816, {'top1': 0.9816}), (18, 0.5682, {'top1': 0.5682}), (21, 0.9926, {'top1': 0.9926}), (23, 0.9934, {'top1': 0.9934}), (26, 0.993, {'top1': 0.993}), (27, 0.9902, {'top1': 0.9902}), (28, 0.992, {'top1': 0.992}), (29, 0.9928, {'top1': 0.9928}), (30, 0.9936, {'top1': 0.9936}), (31, 0.9926, {'top1': 0.9926}), (32, 0.9916, {'top1': 0.9916}), (33, 0.9918, {'top1': 0.9918}), (34, 0.9902, {'top1': 0.9902}), (36, 0.5184, {'top1': 0.5184}), (37, 0.9898, {'top1': 0.9898}), (38, 0.993, {'top1': 0.993}), (39, 0.99, {'top1': 0.99}), (41, 0.989, {'top1': 0.989}), (42, 0.9844, {'top1': 0.9844}), (43, 0.9872, {'top1': 0.9872}), (44, 0.9866, {'top1': 0.9866}), (45, 0.991, {'top1': 0.991}), (46, 0.9866, {'top1': 0.9866}), (47, 0.9892, {'top1': 0.9892}), (48, 0.992, {'top1': 0.992}), (49, 0.9888, {'top1': 0.9888}), (50, 0.9854, {'top1': 0.9854}), (51, 0.9898, {'top1': 0.9898}), (52, 0.9826, {'top1': 0.9826}), (53, 0.9026, {'top1': 0.9026})]
just computed impact of block 5 . accuracy after removing:  0.994
removed block 5 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(1, 0.9788, {'top1': 0.9788}), (2, 0.9534, {'top1': 0.9534}), (3, 0.9836, {'top1': 0.9836}), (4, 0.942, {'top1': 0.942}), (6, 0.99, {'top1': 0.99}), (7, 0.9806, {'top1': 0.9806}), (8, 0.979, {'top1': 0.979}), (9, 0.9708, {'top1': 0.9708}), (10, 0.973, {'top1': 0.973}), (11, 0.9892, {'top1': 0.9892}), (12, 0.9874, {'top1': 0.9874}), (13, 0.9898, {'top1': 0.9898}), (14, 0.9866, {'top1': 0.9866}), (15, 0.987, {'top1': 0.987}), (16, 0.9816, {'top1': 0.9816}), (17, 0.9766, {'top1': 0.9766}), (18, 0.5754, {'top1': 0.5754}), (21, 0.9894, {'top1': 0.9894}), (23, 0.9894, {'top1': 0.9894}), (26, 0.99, {'top1': 0.99}), (27, 0.9868, {'top1': 0.9868}), (28, 0.9912, {'top1': 0.9912}), (29, 0.9898, {'top1': 0.9898}), (30, 0.991, {'top1': 0.991}), (31, 0.9908, {'top1': 0.9908}), (32, 0.9906, {'top1': 0.9906}), (33, 0.9916, {'top1': 0.9916}), (34, 0.987, {'top1': 0.987}), (36, 0.5082, {'top1': 0.5082}), (37, 0.9894, {'top1': 0.9894}), (38, 0.9916, {'top1': 0.9916}), (39, 0.9866, {'top1': 0.9866}), (41, 0.9854, {'top1': 0.9854}), (42, 0.982, {'top1': 0.982}), (43, 0.9844, {'top1': 0.9844}), (44, 0.9836, {'top1': 0.9836}), (45, 0.988, {'top1': 0.988}), (46, 0.9852, {'top1': 0.9852}), (47, 0.9858, {'top1': 0.9858}), (48, 0.9894, {'top1': 0.9894}), (49, 0.9854, {'top1': 0.9854}), (50, 0.9838, {'top1': 0.9838}), (51, 0.9866, {'top1': 0.9866}), (52, 0.9808, {'top1': 0.9808}), (53, 0.8904, {'top1': 0.8904})]
just computed impact of block 33 . accuracy after removing:  0.9916
removed block 33 current accuracy 0.9916 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(1, 0.9746, {'top1': 0.9746}), (2, 0.9526, {'top1': 0.9526}), (3, 0.9796, {'top1': 0.9796}), (4, 0.939, {'top1': 0.939}), (6, 0.9858, {'top1': 0.9858}), (7, 0.9762, {'top1': 0.9762}), (8, 0.9764, {'top1': 0.9764}), (9, 0.9628, {'top1': 0.9628}), (10, 0.9668, {'top1': 0.9668}), (11, 0.9856, {'top1': 0.9856}), (12, 0.981, {'top1': 0.981}), (13, 0.9852, {'top1': 0.9852}), (14, 0.9846, {'top1': 0.9846}), (15, 0.9814, {'top1': 0.9814}), (16, 0.9798, {'top1': 0.9798}), (17, 0.9722, {'top1': 0.9722}), (18, 0.5544, {'top1': 0.5544}), (21, 0.9862, {'top1': 0.9862}), (23, 0.9836, {'top1': 0.9836}), (26, 0.9848, {'top1': 0.9848}), (27, 0.9846, {'top1': 0.9846}), (28, 0.9846, {'top1': 0.9846}), (29, 0.9868, {'top1': 0.9868}), (30, 0.986, {'top1': 0.986}), (31, 0.9848, {'top1': 0.9848}), (32, 0.9848, {'top1': 0.9848}), (34, 0.982, {'top1': 0.982}), (36, 0.4646, {'top1': 0.4646}), (37, 0.9832, {'top1': 0.9832}), (38, 0.9878, {'top1': 0.9878}), (39, 0.9828, {'top1': 0.9828}), (41, 0.9802, {'top1': 0.9802}), (42, 0.9772, {'top1': 0.9772}), (43, 0.98, {'top1': 0.98}), (44, 0.9798, {'top1': 0.9798}), (45, 0.983, {'top1': 0.983}), (46, 0.9796, {'top1': 0.9796}), (47, 0.9818, {'top1': 0.9818}), (48, 0.9848, {'top1': 0.9848}), (49, 0.98, {'top1': 0.98}), (50, 0.978, {'top1': 0.978}), (51, 0.9826, {'top1': 0.9826}), (52, 0.975, {'top1': 0.975}), (53, 0.8906, {'top1': 0.8906})]
just computed impact of block 38 . accuracy after removing:  0.9878
removed block 38 current accuracy 0.9878 loss from initial  0.012199999999999989
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(1, 0.9708, {'top1': 0.9708}), (2, 0.9436, {'top1': 0.9436}), (3, 0.9744, {'top1': 0.9744}), (4, 0.9304, {'top1': 0.9304}), (6, 0.9808, {'top1': 0.9808}), (7, 0.9728, {'top1': 0.9728}), (8, 0.9726, {'top1': 0.9726}), (9, 0.9556, {'top1': 0.9556}), (10, 0.9586, {'top1': 0.9586}), (11, 0.982, {'top1': 0.982}), (12, 0.9744, {'top1': 0.9744}), (13, 0.9812, {'top1': 0.9812}), (14, 0.978, {'top1': 0.978}), (15, 0.9768, {'top1': 0.9768}), (16, 0.9766, {'top1': 0.9766}), (17, 0.969, {'top1': 0.969}), (18, 0.55, {'top1': 0.55}), (21, 0.9822, {'top1': 0.9822}), (23, 0.9794, {'top1': 0.9794}), (26, 0.9788, {'top1': 0.9788}), (27, 0.9804, {'top1': 0.9804}), (28, 0.9806, {'top1': 0.9806}), (29, 0.9834, {'top1': 0.9834}), (30, 0.9804, {'top1': 0.9804}), (31, 0.9806, {'top1': 0.9806}), (32, 0.9806, {'top1': 0.9806}), (34, 0.9748, {'top1': 0.9748}), (36, 0.317, {'top1': 0.317}), (37, 0.9776, {'top1': 0.9776}), (39, 0.9768, {'top1': 0.9768}), (41, 0.975, {'top1': 0.975}), (42, 0.9698, {'top1': 0.9698}), (43, 0.9748, {'top1': 0.9748}), (44, 0.975, {'top1': 0.975}), (45, 0.9788, {'top1': 0.9788}), (46, 0.9746, {'top1': 0.9746}), (47, 0.9744, {'top1': 0.9744}), (48, 0.98, {'top1': 0.98}), (49, 0.9768, {'top1': 0.9768}), (50, 0.9732, {'top1': 0.9732}), (51, 0.9778, {'top1': 0.9778}), (52, 0.9698, {'top1': 0.9698}), (53, 0.8736, {'top1': 0.8736})]
just computed impact of block 29 . accuracy after removing:  0.9834
removed block 29 current accuracy 0.9834 loss from initial  0.016599999999999948
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(1, 0.9644, {'top1': 0.9644}), (2, 0.938, {'top1': 0.938}), (3, 0.971, {'top1': 0.971}), (4, 0.9224, {'top1': 0.9224}), (6, 0.9744, {'top1': 0.9744}), (7, 0.9668, {'top1': 0.9668}), (8, 0.968, {'top1': 0.968}), (9, 0.948, {'top1': 0.948}), (10, 0.957, {'top1': 0.957}), (11, 0.9764, {'top1': 0.9764}), (12, 0.9682, {'top1': 0.9682}), (13, 0.9758, {'top1': 0.9758}), (14, 0.9746, {'top1': 0.9746}), (15, 0.9714, {'top1': 0.9714}), (16, 0.9728, {'top1': 0.9728}), (17, 0.9618, {'top1': 0.9618}), (18, 0.5518, {'top1': 0.5518}), (21, 0.976, {'top1': 0.976}), (23, 0.9748, {'top1': 0.9748}), (26, 0.9714, {'top1': 0.9714}), (27, 0.9754, {'top1': 0.9754}), (28, 0.9746, {'top1': 0.9746}), (30, 0.9732, {'top1': 0.9732}), (31, 0.9724, {'top1': 0.9724}), (32, 0.9752, {'top1': 0.9752}), (34, 0.9694, {'top1': 0.9694}), (36, 0.297, {'top1': 0.297}), (37, 0.9722, {'top1': 0.9722}), (39, 0.9718, {'top1': 0.9718}), (41, 0.9696, {'top1': 0.9696}), (42, 0.9644, {'top1': 0.9644}), (43, 0.9684, {'top1': 0.9684}), (44, 0.9664, {'top1': 0.9664}), (45, 0.9736, {'top1': 0.9736}), (46, 0.9698, {'top1': 0.9698}), (47, 0.9704, {'top1': 0.9704}), (48, 0.9734, {'top1': 0.9734}), (49, 0.9712, {'top1': 0.9712}), (50, 0.968, {'top1': 0.968}), (51, 0.9728, {'top1': 0.9728}), (52, 0.9658, {'top1': 0.9658}), (53, 0.863, {'top1': 0.863})]
just computed impact of block 11 . accuracy after removing:  0.9764
removed block 11 current accuracy 0.9764 loss from initial  0.023599999999999954
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(1, 0.9556, {'top1': 0.9556}), (2, 0.9164, {'top1': 0.9164}), (3, 0.963, {'top1': 0.963}), (4, 0.8962, {'top1': 0.8962}), (6, 0.968, {'top1': 0.968}), (7, 0.9534, {'top1': 0.9534}), (8, 0.952, {'top1': 0.952}), (9, 0.9248, {'top1': 0.9248}), (10, 0.9158, {'top1': 0.9158}), (12, 0.9494, {'top1': 0.9494}), (13, 0.9608, {'top1': 0.9608}), (14, 0.955, {'top1': 0.955}), (15, 0.9584, {'top1': 0.9584}), (16, 0.954, {'top1': 0.954}), (17, 0.9136, {'top1': 0.9136}), (18, 0.484, {'top1': 0.484}), (21, 0.9682, {'top1': 0.9682}), (23, 0.9658, {'top1': 0.9658}), (26, 0.9654, {'top1': 0.9654}), (27, 0.969, {'top1': 0.969}), (28, 0.9656, {'top1': 0.9656}), (30, 0.9678, {'top1': 0.9678}), (31, 0.9678, {'top1': 0.9678}), (32, 0.9694, {'top1': 0.9694}), (34, 0.961, {'top1': 0.961}), (36, 0.2598, {'top1': 0.2598}), (37, 0.9648, {'top1': 0.9648}), (39, 0.9638, {'top1': 0.9638}), (41, 0.9598, {'top1': 0.9598}), (42, 0.9556, {'top1': 0.9556}), (43, 0.9622, {'top1': 0.9622}), (44, 0.955, {'top1': 0.955}), (45, 0.9664, {'top1': 0.9664}), (46, 0.961, {'top1': 0.961}), (47, 0.9602, {'top1': 0.9602}), (48, 0.969, {'top1': 0.969}), (49, 0.9658, {'top1': 0.9658}), (50, 0.961, {'top1': 0.961}), (51, 0.9678, {'top1': 0.9678}), (52, 0.9568, {'top1': 0.9568}), (53, 0.8366, {'top1': 0.8366})]
just computed impact of block 32 . accuracy after removing:  0.9694
removed block 32 current accuracy 0.9694 loss from initial  0.03059999999999996
since last training loss: 0.03059999999999996 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(1, 0.946, {'top1': 0.946}), (2, 0.9108, {'top1': 0.9108}), (3, 0.9554, {'top1': 0.9554}), (4, 0.8904, {'top1': 0.8904}), (6, 0.9614, {'top1': 0.9614}), (7, 0.9478, {'top1': 0.9478}), (8, 0.9402, {'top1': 0.9402}), (9, 0.9072, {'top1': 0.9072}), (10, 0.904, {'top1': 0.904}), (12, 0.9366, {'top1': 0.9366}), (13, 0.9536, {'top1': 0.9536}), (14, 0.9464, {'top1': 0.9464}), (15, 0.9502, {'top1': 0.9502}), (16, 0.9496, {'top1': 0.9496}), (17, 0.9068, {'top1': 0.9068}), (18, 0.4616, {'top1': 0.4616}), (21, 0.9624, {'top1': 0.9624}), (23, 0.9558, {'top1': 0.9558}), (26, 0.9554, {'top1': 0.9554}), (27, 0.9592, {'top1': 0.9592}), (28, 0.9586, {'top1': 0.9586}), (30, 0.9586, {'top1': 0.9586}), (31, 0.9564, {'top1': 0.9564}), (34, 0.9444, {'top1': 0.9444}), (36, 0.2436, {'top1': 0.2436}), (37, 0.9566, {'top1': 0.9566}), (39, 0.9552, {'top1': 0.9552}), (41, 0.949, {'top1': 0.949}), (42, 0.948, {'top1': 0.948}), (43, 0.9516, {'top1': 0.9516}), (44, 0.9476, {'top1': 0.9476}), (45, 0.9574, {'top1': 0.9574}), (46, 0.9538, {'top1': 0.9538}), (47, 0.9558, {'top1': 0.9558}), (48, 0.9602, {'top1': 0.9602}), (49, 0.9574, {'top1': 0.9574}), (50, 0.9554, {'top1': 0.9554}), (51, 0.959, {'top1': 0.959}), (52, 0.9474, {'top1': 0.9474}), (53, 0.8272, {'top1': 0.8272})]
just computed impact of block 21 . accuracy after removing:  0.9624
removed block 21 current accuracy 0.9624 loss from initial  0.03759999999999997
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(1, 0.9338, {'top1': 0.9338}), (2, 0.893, {'top1': 0.893}), (3, 0.9436, {'top1': 0.9436}), (4, 0.8698, {'top1': 0.8698}), (6, 0.9524, {'top1': 0.9524}), (7, 0.9332, {'top1': 0.9332}), (8, 0.928, {'top1': 0.928}), (9, 0.8852, {'top1': 0.8852}), (10, 0.8818, {'top1': 0.8818}), (12, 0.9208, {'top1': 0.9208}), (13, 0.9376, {'top1': 0.9376}), (14, 0.9342, {'top1': 0.9342}), (15, 0.9344, {'top1': 0.9344}), (16, 0.9394, {'top1': 0.9394}), (17, 0.8968, {'top1': 0.8968}), (18, 0.4368, {'top1': 0.4368}), (23, 0.9412, {'top1': 0.9412}), (26, 0.9442, {'top1': 0.9442}), (27, 0.95, {'top1': 0.95}), (28, 0.9486, {'top1': 0.9486}), (30, 0.9456, {'top1': 0.9456}), (31, 0.944, {'top1': 0.944}), (34, 0.9352, {'top1': 0.9352}), (36, 0.2398, {'top1': 0.2398}), (37, 0.9432, {'top1': 0.9432}), (39, 0.9446, {'top1': 0.9446}), (41, 0.9368, {'top1': 0.9368}), (42, 0.9366, {'top1': 0.9366}), (43, 0.9404, {'top1': 0.9404}), (44, 0.9338, {'top1': 0.9338}), (45, 0.9488, {'top1': 0.9488}), (46, 0.9434, {'top1': 0.9434}), (47, 0.9448, {'top1': 0.9448}), (48, 0.9476, {'top1': 0.9476}), (49, 0.9464, {'top1': 0.9464}), (50, 0.9444, {'top1': 0.9444}), (51, 0.9484, {'top1': 0.9484}), (52, 0.9372, {'top1': 0.9372}), (53, 0.8136, {'top1': 0.8136})]
just computed impact of block 6 . accuracy after removing:  0.9524
removed block 6 current accuracy 0.9524 loss from initial  0.047599999999999976
training start
training epoch 0 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 1 val accuracy 0.9978 topk_dict {'top1': 0.9978} is_best True lr [0.001]
training epoch 2 val accuracy 0.998 topk_dict {'top1': 0.998} is_best True lr [0.001]
training epoch 3 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best True lr [0.001]
training epoch 4 val accuracy 0.9988 topk_dict {'top1': 0.9988} is_best True lr [0.001]
training epoch 5 val accuracy 0.999 topk_dict {'top1': 0.999} is_best True lr [0.001]
training epoch 6 val accuracy 0.9986 topk_dict {'top1': 0.9986} is_best False lr [0.001]
training epoch 7 val accuracy 0.999 topk_dict {'top1': 0.999} is_best False lr [0.001]
training epoch 8 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best True lr [0.001]
training epoch 9 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 10 val accuracy 0.9994 topk_dict {'top1': 0.9994} is_best True lr [0.001]
training epoch 11 val accuracy 0.9992 topk_dict {'top1': 0.9992} is_best False lr [0.001]
training epoch 12 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best True lr [0.001]
training epoch 13 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 14 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 15 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 16 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 17 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 18 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 19 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 20 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 21 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 22 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 23 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 24 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 25 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 26 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 27 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 29 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 30 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 31 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 32 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 33 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 34 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 35 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 36 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 37 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 38 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 39 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 40 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 41 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 42 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
training epoch 43 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 44 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 45 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 46 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 47 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 48 val accuracy 0.9996 topk_dict {'top1': 0.9996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9998 topk_dict {'top1': 0.9998} is_best False lr [0.001]
loading model_best from epoch 12 (acc 0.999800)
finished training. finished 50 epochs. accuracy 0.9998 topk_dict {'top1': 0.9998}
start iteration 16
(cache recomputed) Accuracy log [(1, 0.9974, {'top1': 0.9974}), (2, 0.9922, {'top1': 0.9922}), (3, 0.9976, {'top1': 0.9976}), (4, 0.9896, {'top1': 0.9896}), (7, 0.9984, {'top1': 0.9984}), (8, 0.9916, {'top1': 0.9916}), (9, 0.9892, {'top1': 0.9892}), (10, 0.983, {'top1': 0.983}), (12, 0.9954, {'top1': 0.9954}), (13, 0.999, {'top1': 0.999}), (14, 0.9982, {'top1': 0.9982}), (15, 0.9956, {'top1': 0.9956}), (16, 0.9954, {'top1': 0.9954}), (17, 0.9898, {'top1': 0.9898}), (18, 0.61, {'top1': 0.61}), (23, 0.998, {'top1': 0.998}), (26, 0.9978, {'top1': 0.9978}), (27, 0.997, {'top1': 0.997}), (28, 0.9974, {'top1': 0.9974}), (30, 0.998, {'top1': 0.998}), (31, 0.998, {'top1': 0.998}), (34, 0.9966, {'top1': 0.9966}), (36, 0.543, {'top1': 0.543}), (37, 0.997, {'top1': 0.997}), (39, 0.9948, {'top1': 0.9948}), (41, 0.9966, {'top1': 0.9966}), (42, 0.9932, {'top1': 0.9932}), (43, 0.995, {'top1': 0.995}), (44, 0.9948, {'top1': 0.9948}), (45, 0.9986, {'top1': 0.9986}), (46, 0.997, {'top1': 0.997}), (47, 0.9954, {'top1': 0.9954}), (48, 0.9968, {'top1': 0.9968}), (49, 0.9982, {'top1': 0.9982}), (50, 0.9942, {'top1': 0.9942}), (51, 0.9962, {'top1': 0.9962}), (52, 0.9916, {'top1': 0.9916}), (53, 0.9562, {'top1': 0.9562})]
just computed impact of block 13 . accuracy after removing:  0.999
removed block 13 current accuracy 0.999 loss from initial  0.0010000000000000009
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(1, 0.9962, {'top1': 0.9962}), (2, 0.9836, {'top1': 0.9836}), (3, 0.997, {'top1': 0.997}), (4, 0.9766, {'top1': 0.9766}), (7, 0.9968, {'top1': 0.9968}), (8, 0.986, {'top1': 0.986}), (9, 0.972, {'top1': 0.972}), (10, 0.9636, {'top1': 0.9636}), (12, 0.988, {'top1': 0.988}), (14, 0.9926, {'top1': 0.9926}), (15, 0.992, {'top1': 0.992}), (16, 0.9884, {'top1': 0.9884}), (17, 0.9732, {'top1': 0.9732}), (18, 0.5882, {'top1': 0.5882}), (23, 0.9972, {'top1': 0.9972}), (26, 0.9978, {'top1': 0.9978}), (27, 0.9966, {'top1': 0.9966}), (28, 0.9962, {'top1': 0.9962}), (30, 0.9974, {'top1': 0.9974}), (31, 0.9982, {'top1': 0.9982}), (34, 0.9968, {'top1': 0.9968}), (36, 0.5438, {'top1': 0.5438}), (37, 0.9964, {'top1': 0.9964}), (39, 0.9956, {'top1': 0.9956}), (41, 0.9958, {'top1': 0.9958}), (42, 0.9924, {'top1': 0.9924}), (43, 0.9926, {'top1': 0.9926}), (44, 0.9936, {'top1': 0.9936}), (45, 0.9974, {'top1': 0.9974}), (46, 0.996, {'top1': 0.996}), (47, 0.995, {'top1': 0.995}), (48, 0.9948, {'top1': 0.9948}), (49, 0.9978, {'top1': 0.9978}), (50, 0.9916, {'top1': 0.9916}), (51, 0.996, {'top1': 0.996}), (52, 0.9914, {'top1': 0.9914}), (53, 0.9444, {'top1': 0.9444})]
just computed impact of block 31 . accuracy after removing:  0.9982
removed block 31 current accuracy 0.9982 loss from initial  0.0018000000000000238
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(1, 0.991, {'top1': 0.991}), (2, 0.977, {'top1': 0.977}), (3, 0.9938, {'top1': 0.9938}), (4, 0.9718, {'top1': 0.9718}), (7, 0.993, {'top1': 0.993}), (8, 0.9762, {'top1': 0.9762}), (9, 0.9638, {'top1': 0.9638}), (10, 0.9502, {'top1': 0.9502}), (12, 0.9806, {'top1': 0.9806}), (14, 0.9884, {'top1': 0.9884}), (15, 0.988, {'top1': 0.988}), (16, 0.983, {'top1': 0.983}), (17, 0.967, {'top1': 0.967}), (18, 0.563, {'top1': 0.563}), (23, 0.9926, {'top1': 0.9926}), (26, 0.993, {'top1': 0.993}), (27, 0.9936, {'top1': 0.9936}), (28, 0.9938, {'top1': 0.9938}), (30, 0.9924, {'top1': 0.9924}), (34, 0.9914, {'top1': 0.9914}), (36, 0.5078, {'top1': 0.5078}), (37, 0.9944, {'top1': 0.9944}), (39, 0.9924, {'top1': 0.9924}), (41, 0.9912, {'top1': 0.9912}), (42, 0.9874, {'top1': 0.9874}), (43, 0.99, {'top1': 0.99}), (44, 0.9892, {'top1': 0.9892}), (45, 0.995, {'top1': 0.995}), (46, 0.9934, {'top1': 0.9934}), (47, 0.9912, {'top1': 0.9912}), (48, 0.9934, {'top1': 0.9934}), (49, 0.9948, {'top1': 0.9948}), (50, 0.9904, {'top1': 0.9904}), (51, 0.9932, {'top1': 0.9932}), (52, 0.985, {'top1': 0.985}), (53, 0.941, {'top1': 0.941})]
just computed impact of block 45 . accuracy after removing:  0.995
removed block 45 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(1, 0.9846, {'top1': 0.9846}), (2, 0.9698, {'top1': 0.9698}), (3, 0.9884, {'top1': 0.9884}), (4, 0.9592, {'top1': 0.9592}), (7, 0.9842, {'top1': 0.9842}), (8, 0.9668, {'top1': 0.9668}), (9, 0.9516, {'top1': 0.9516}), (10, 0.932, {'top1': 0.932}), (12, 0.9682, {'top1': 0.9682}), (14, 0.9806, {'top1': 0.9806}), (15, 0.9794, {'top1': 0.9794}), (16, 0.9758, {'top1': 0.9758}), (17, 0.954, {'top1': 0.954}), (18, 0.5442, {'top1': 0.5442}), (23, 0.986, {'top1': 0.986}), (26, 0.989, {'top1': 0.989}), (27, 0.9892, {'top1': 0.9892}), (28, 0.9894, {'top1': 0.9894}), (30, 0.9868, {'top1': 0.9868}), (34, 0.9858, {'top1': 0.9858}), (36, 0.5082, {'top1': 0.5082}), (37, 0.989, {'top1': 0.989}), (39, 0.986, {'top1': 0.986}), (41, 0.9834, {'top1': 0.9834}), (42, 0.9742, {'top1': 0.9742}), (43, 0.9818, {'top1': 0.9818}), (44, 0.9786, {'top1': 0.9786}), (46, 0.9832, {'top1': 0.9832}), (47, 0.9852, {'top1': 0.9852}), (48, 0.986, {'top1': 0.986}), (49, 0.9872, {'top1': 0.9872}), (50, 0.9832, {'top1': 0.9832}), (51, 0.987, {'top1': 0.987}), (52, 0.9772, {'top1': 0.9772}), (53, 0.911, {'top1': 0.911})]
just computed impact of block 28 . accuracy after removing:  0.9894
removed block 28 current accuracy 0.9894 loss from initial  0.010600000000000054
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(1, 0.9794, {'top1': 0.9794}), (2, 0.9648, {'top1': 0.9648}), (3, 0.9838, {'top1': 0.9838}), (4, 0.956, {'top1': 0.956}), (7, 0.9794, {'top1': 0.9794}), (8, 0.9604, {'top1': 0.9604}), (9, 0.9366, {'top1': 0.9366}), (10, 0.9214, {'top1': 0.9214}), (12, 0.9624, {'top1': 0.9624}), (14, 0.9748, {'top1': 0.9748}), (15, 0.9736, {'top1': 0.9736}), (16, 0.9716, {'top1': 0.9716}), (17, 0.9466, {'top1': 0.9466}), (18, 0.4786, {'top1': 0.4786}), (23, 0.9804, {'top1': 0.9804}), (26, 0.9788, {'top1': 0.9788}), (27, 0.9804, {'top1': 0.9804}), (30, 0.9786, {'top1': 0.9786}), (34, 0.978, {'top1': 0.978}), (36, 0.4206, {'top1': 0.4206}), (37, 0.9816, {'top1': 0.9816}), (39, 0.981, {'top1': 0.981}), (41, 0.9776, {'top1': 0.9776}), (42, 0.9694, {'top1': 0.9694}), (43, 0.9786, {'top1': 0.9786}), (44, 0.9726, {'top1': 0.9726}), (46, 0.9804, {'top1': 0.9804}), (47, 0.9786, {'top1': 0.9786}), (48, 0.983, {'top1': 0.983}), (49, 0.9784, {'top1': 0.9784}), (50, 0.979, {'top1': 0.979}), (51, 0.9812, {'top1': 0.9812}), (52, 0.9724, {'top1': 0.9724}), (53, 0.898, {'top1': 0.898})]
just computed impact of block 3 . accuracy after removing:  0.9838
removed block 3 current accuracy 0.9838 loss from initial  0.016199999999999992
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(1, 0.9622, {'top1': 0.9622}), (2, 0.934, {'top1': 0.934}), (4, 0.9088, {'top1': 0.9088}), (7, 0.9606, {'top1': 0.9606}), (8, 0.9462, {'top1': 0.9462}), (9, 0.9246, {'top1': 0.9246}), (10, 0.919, {'top1': 0.919}), (12, 0.9542, {'top1': 0.9542}), (14, 0.9654, {'top1': 0.9654}), (15, 0.9668, {'top1': 0.9668}), (16, 0.9604, {'top1': 0.9604}), (17, 0.9382, {'top1': 0.9382}), (18, 0.4802, {'top1': 0.4802}), (23, 0.9746, {'top1': 0.9746}), (26, 0.9746, {'top1': 0.9746}), (27, 0.9778, {'top1': 0.9778}), (30, 0.975, {'top1': 0.975}), (34, 0.9754, {'top1': 0.9754}), (36, 0.4116, {'top1': 0.4116}), (37, 0.976, {'top1': 0.976}), (39, 0.9756, {'top1': 0.9756}), (41, 0.9736, {'top1': 0.9736}), (42, 0.9618, {'top1': 0.9618}), (43, 0.9738, {'top1': 0.9738}), (44, 0.9618, {'top1': 0.9618}), (46, 0.9748, {'top1': 0.9748}), (47, 0.9712, {'top1': 0.9712}), (48, 0.976, {'top1': 0.976}), (49, 0.9746, {'top1': 0.9746}), (50, 0.9726, {'top1': 0.9726}), (51, 0.9756, {'top1': 0.9756}), (52, 0.9684, {'top1': 0.9684}), (53, 0.8852, {'top1': 0.8852})]
just computed impact of block 27 . accuracy after removing:  0.9778
removed block 27 current accuracy 0.9778 loss from initial  0.022199999999999998
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(1, 0.9532, {'top1': 0.9532}), (2, 0.925, {'top1': 0.925}), (4, 0.9002, {'top1': 0.9002}), (7, 0.9508, {'top1': 0.9508}), (8, 0.936, {'top1': 0.936}), (9, 0.9166, {'top1': 0.9166}), (10, 0.9094, {'top1': 0.9094}), (12, 0.9422, {'top1': 0.9422}), (14, 0.9606, {'top1': 0.9606}), (15, 0.9594, {'top1': 0.9594}), (16, 0.954, {'top1': 0.954}), (17, 0.9328, {'top1': 0.9328}), (18, 0.4484, {'top1': 0.4484}), (23, 0.9672, {'top1': 0.9672}), (26, 0.9648, {'top1': 0.9648}), (30, 0.9662, {'top1': 0.9662}), (34, 0.9618, {'top1': 0.9618}), (36, 0.3526, {'top1': 0.3526}), (37, 0.9652, {'top1': 0.9652}), (39, 0.9626, {'top1': 0.9626}), (41, 0.9602, {'top1': 0.9602}), (42, 0.9506, {'top1': 0.9506}), (43, 0.9644, {'top1': 0.9644}), (44, 0.952, {'top1': 0.952}), (46, 0.9684, {'top1': 0.9684}), (47, 0.9626, {'top1': 0.9626}), (48, 0.966, {'top1': 0.966}), (49, 0.968, {'top1': 0.968}), (50, 0.9614, {'top1': 0.9614}), (51, 0.964, {'top1': 0.964}), (52, 0.9598, {'top1': 0.9598}), (53, 0.873, {'top1': 0.873})]
just computed impact of block 46 . accuracy after removing:  0.9684
removed block 46 current accuracy 0.9684 loss from initial  0.03159999999999996
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(1, 0.937, {'top1': 0.937}), (2, 0.9018, {'top1': 0.9018}), (4, 0.8744, {'top1': 0.8744}), (7, 0.9334, {'top1': 0.9334}), (8, 0.9206, {'top1': 0.9206}), (9, 0.885, {'top1': 0.885}), (10, 0.8826, {'top1': 0.8826}), (12, 0.9216, {'top1': 0.9216}), (14, 0.946, {'top1': 0.946}), (15, 0.9458, {'top1': 0.9458}), (16, 0.9362, {'top1': 0.9362}), (17, 0.905, {'top1': 0.905}), (18, 0.4354, {'top1': 0.4354}), (23, 0.9498, {'top1': 0.9498}), (26, 0.9484, {'top1': 0.9484}), (30, 0.9532, {'top1': 0.9532}), (34, 0.947, {'top1': 0.947}), (36, 0.3128, {'top1': 0.3128}), (37, 0.9538, {'top1': 0.9538}), (39, 0.9466, {'top1': 0.9466}), (41, 0.9428, {'top1': 0.9428}), (42, 0.9342, {'top1': 0.9342}), (43, 0.9444, {'top1': 0.9444}), (44, 0.9294, {'top1': 0.9294}), (47, 0.941, {'top1': 0.941}), (48, 0.948, {'top1': 0.948}), (49, 0.9464, {'top1': 0.9464}), (50, 0.9472, {'top1': 0.9472}), (51, 0.947, {'top1': 0.947}), (52, 0.9344, {'top1': 0.9344}), (53, 0.819, {'top1': 0.819})]
just computed impact of block 37 . accuracy after removing:  0.9538
removed block 37 current accuracy 0.9538 loss from initial  0.04620000000000002
since last training loss: 0.04600000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(1, 0.9208, {'top1': 0.9208}), (2, 0.8914, {'top1': 0.8914}), (4, 0.857, {'top1': 0.857}), (7, 0.9174, {'top1': 0.9174}), (8, 0.9002, {'top1': 0.9002}), (9, 0.8704, {'top1': 0.8704}), (10, 0.865, {'top1': 0.865}), (12, 0.9052, {'top1': 0.9052}), (14, 0.9284, {'top1': 0.9284}), (15, 0.9338, {'top1': 0.9338}), (16, 0.9158, {'top1': 0.9158}), (17, 0.8932, {'top1': 0.8932}), (18, 0.4326, {'top1': 0.4326}), (23, 0.9336, {'top1': 0.9336}), (26, 0.9322, {'top1': 0.9322}), (30, 0.9374, {'top1': 0.9374}), (34, 0.927, {'top1': 0.927}), (36, 0.221, {'top1': 0.221}), (39, 0.9268, {'top1': 0.9268}), (41, 0.9224, {'top1': 0.9224}), (42, 0.9132, {'top1': 0.9132}), (43, 0.9238, {'top1': 0.9238}), (44, 0.9164, {'top1': 0.9164}), (47, 0.9254, {'top1': 0.9254}), (48, 0.928, {'top1': 0.928}), (49, 0.9314, {'top1': 0.9314}), (50, 0.934, {'top1': 0.934}), (51, 0.9296, {'top1': 0.9296}), (52, 0.9242, {'top1': 0.9242}), (53, 0.7918, {'top1': 0.7918})]
just computed impact of block 30 . accuracy after removing:  0.9374
removed block 30 current accuracy 0.9374 loss from initial  0.06259999999999999
since last training loss: 0.06240000000000001 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(1, 0.8986, {'top1': 0.8986}), (2, 0.864, {'top1': 0.864}), (4, 0.8272, {'top1': 0.8272}), (7, 0.8966, {'top1': 0.8966}), (8, 0.8792, {'top1': 0.8792}), (9, 0.8386, {'top1': 0.8386}), (10, 0.83, {'top1': 0.83}), (12, 0.875, {'top1': 0.875}), (14, 0.9002, {'top1': 0.9002}), (15, 0.9122, {'top1': 0.9122}), (16, 0.8998, {'top1': 0.8998}), (17, 0.859, {'top1': 0.859}), (18, 0.3788, {'top1': 0.3788}), (23, 0.9118, {'top1': 0.9118}), (26, 0.9078, {'top1': 0.9078}), (34, 0.9066, {'top1': 0.9066}), (36, 0.2122, {'top1': 0.2122}), (39, 0.9108, {'top1': 0.9108}), (41, 0.9006, {'top1': 0.9006}), (42, 0.894, {'top1': 0.894}), (43, 0.902, {'top1': 0.902}), (44, 0.8946, {'top1': 0.8946}), (47, 0.9018, {'top1': 0.9018}), (48, 0.9098, {'top1': 0.9098}), (49, 0.913, {'top1': 0.913}), (50, 0.911, {'top1': 0.911}), (51, 0.9172, {'top1': 0.9172}), (52, 0.8986, {'top1': 0.8986}), (53, 0.7654, {'top1': 0.7654})]
just computed impact of block 51 . accuracy after removing:  0.9172
removed block 51 current accuracy 0.9172 loss from initial  0.08279999999999998
since last training loss: 0.0826 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(1, 0.8732, {'top1': 0.8732}), (2, 0.8362, {'top1': 0.8362}), (4, 0.8052, {'top1': 0.8052}), (7, 0.8708, {'top1': 0.8708}), (8, 0.857, {'top1': 0.857}), (9, 0.8028, {'top1': 0.8028}), (10, 0.7904, {'top1': 0.7904}), (12, 0.8462, {'top1': 0.8462}), (14, 0.872, {'top1': 0.872}), (15, 0.8864, {'top1': 0.8864}), (16, 0.8792, {'top1': 0.8792}), (17, 0.8372, {'top1': 0.8372}), (18, 0.316, {'top1': 0.316}), (23, 0.8882, {'top1': 0.8882}), (26, 0.8822, {'top1': 0.8822}), (34, 0.8768, {'top1': 0.8768}), (36, 0.235, {'top1': 0.235}), (39, 0.8842, {'top1': 0.8842}), (41, 0.8742, {'top1': 0.8742}), (42, 0.864, {'top1': 0.864}), (43, 0.8794, {'top1': 0.8794}), (44, 0.8668, {'top1': 0.8668}), (47, 0.8694, {'top1': 0.8694}), (48, 0.878, {'top1': 0.878}), (49, 0.875, {'top1': 0.875}), (50, 0.8798, {'top1': 0.8798}), (52, 0.8628, {'top1': 0.8628}), (53, 0.705, {'top1': 0.705})]
just computed impact of block 23 . accuracy after removing:  0.8882
removed block 23 current accuracy 0.8882 loss from initial  0.11180000000000001
since last training loss: 0.11160000000000003 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(1, 0.8432, {'top1': 0.8432}), (2, 0.8028, {'top1': 0.8028}), (4, 0.7672, {'top1': 0.7672}), (7, 0.84, {'top1': 0.84}), (8, 0.8246, {'top1': 0.8246}), (9, 0.7498, {'top1': 0.7498}), (10, 0.7368, {'top1': 0.7368}), (12, 0.806, {'top1': 0.806}), (14, 0.8374, {'top1': 0.8374}), (15, 0.8536, {'top1': 0.8536}), (16, 0.8488, {'top1': 0.8488}), (17, 0.7962, {'top1': 0.7962}), (18, 0.2842, {'top1': 0.2842}), (26, 0.8468, {'top1': 0.8468}), (34, 0.8418, {'top1': 0.8418}), (36, 0.2114, {'top1': 0.2114}), (39, 0.8528, {'top1': 0.8528}), (41, 0.84, {'top1': 0.84}), (42, 0.8324, {'top1': 0.8324}), (43, 0.8502, {'top1': 0.8502}), (44, 0.8308, {'top1': 0.8308}), (47, 0.8324, {'top1': 0.8324}), (48, 0.8468, {'top1': 0.8468}), (49, 0.8484, {'top1': 0.8484}), (50, 0.851, {'top1': 0.851}), (52, 0.8232, {'top1': 0.8232}), (53, 0.667, {'top1': 0.667})]
just computed impact of block 15 . accuracy after removing:  0.8536
removed block 15 current accuracy 0.8536 loss from initial  0.14639999999999997
since last training loss: 0.1462 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(1, 0.8108, {'top1': 0.8108}), (2, 0.7612, {'top1': 0.7612}), (4, 0.721, {'top1': 0.721}), (7, 0.8054, {'top1': 0.8054}), (8, 0.8138, {'top1': 0.8138}), (9, 0.7016, {'top1': 0.7016}), (10, 0.6936, {'top1': 0.6936}), (12, 0.746, {'top1': 0.746}), (14, 0.7852, {'top1': 0.7852}), (16, 0.7814, {'top1': 0.7814}), (17, 0.6322, {'top1': 0.6322}), (18, 0.265, {'top1': 0.265}), (26, 0.8106, {'top1': 0.8106}), (34, 0.8078, {'top1': 0.8078}), (36, 0.2184, {'top1': 0.2184}), (39, 0.8172, {'top1': 0.8172}), (41, 0.7946, {'top1': 0.7946}), (42, 0.7894, {'top1': 0.7894}), (43, 0.8108, {'top1': 0.8108}), (44, 0.7944, {'top1': 0.7944}), (47, 0.7954, {'top1': 0.7954}), (48, 0.8032, {'top1': 0.8032}), (49, 0.809, {'top1': 0.809}), (50, 0.8152, {'top1': 0.8152}), (52, 0.7736, {'top1': 0.7736}), (53, 0.6476, {'top1': 0.6476})]
just computed impact of block 39 . accuracy after removing:  0.8172
removed block 39 current accuracy 0.8172 loss from initial  0.18279999999999996
since last training loss: 0.18259999999999998 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(1, 0.7828, {'top1': 0.7828}), (2, 0.7332, {'top1': 0.7332}), (4, 0.6876, {'top1': 0.6876}), (7, 0.7742, {'top1': 0.7742}), (8, 0.7864, {'top1': 0.7864}), (9, 0.6584, {'top1': 0.6584}), (10, 0.6564, {'top1': 0.6564}), (12, 0.7128, {'top1': 0.7128}), (14, 0.7586, {'top1': 0.7586}), (16, 0.746, {'top1': 0.746}), (17, 0.612, {'top1': 0.612}), (18, 0.2628, {'top1': 0.2628}), (26, 0.7706, {'top1': 0.7706}), (34, 0.7688, {'top1': 0.7688}), (36, 0.2392, {'top1': 0.2392}), (41, 0.7552, {'top1': 0.7552}), (42, 0.7524, {'top1': 0.7524}), (43, 0.7808, {'top1': 0.7808}), (44, 0.7566, {'top1': 0.7566}), (47, 0.762, {'top1': 0.762}), (48, 0.7744, {'top1': 0.7744}), (49, 0.7764, {'top1': 0.7764}), (50, 0.7808, {'top1': 0.7808}), (52, 0.7218, {'top1': 0.7218}), (53, 0.5994, {'top1': 0.5994})]
just computed impact of block 8 . accuracy after removing:  0.7864
removed block 8 current accuracy 0.7864 loss from initial  0.2136
since last training loss: 0.21340000000000003 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(1, 0.727, {'top1': 0.727}), (2, 0.672, {'top1': 0.672}), (4, 0.625, {'top1': 0.625}), (7, 0.6838, {'top1': 0.6838}), (9, 0.5578, {'top1': 0.5578}), (10, 0.5598, {'top1': 0.5598}), (12, 0.6618, {'top1': 0.6618}), (14, 0.7026, {'top1': 0.7026}), (16, 0.6392, {'top1': 0.6392}), (17, 0.5182, {'top1': 0.5182}), (18, 0.2678, {'top1': 0.2678}), (26, 0.7388, {'top1': 0.7388}), (34, 0.7368, {'top1': 0.7368}), (36, 0.2204, {'top1': 0.2204}), (41, 0.7138, {'top1': 0.7138}), (42, 0.7034, {'top1': 0.7034}), (43, 0.7278, {'top1': 0.7278}), (44, 0.7118, {'top1': 0.7118}), (47, 0.7184, {'top1': 0.7184}), (48, 0.7312, {'top1': 0.7312}), (49, 0.7198, {'top1': 0.7198}), (50, 0.741, {'top1': 0.741}), (52, 0.7222, {'top1': 0.7222}), (53, 0.4834, {'top1': 0.4834})]
just computed impact of block 50 . accuracy after removing:  0.741
removed block 50 current accuracy 0.741 loss from initial  0.259
since last training loss: 0.25880000000000003 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(1, 0.6816, {'top1': 0.6816}), (2, 0.6284, {'top1': 0.6284}), (4, 0.5804, {'top1': 0.5804}), (7, 0.638, {'top1': 0.638}), (9, 0.506, {'top1': 0.506}), (10, 0.5154, {'top1': 0.5154}), (12, 0.6038, {'top1': 0.6038}), (14, 0.6508, {'top1': 0.6508}), (16, 0.599, {'top1': 0.599}), (17, 0.4722, {'top1': 0.4722}), (18, 0.257, {'top1': 0.257}), (26, 0.6954, {'top1': 0.6954}), (34, 0.6824, {'top1': 0.6824}), (36, 0.2384, {'top1': 0.2384}), (41, 0.6574, {'top1': 0.6574}), (42, 0.6536, {'top1': 0.6536}), (43, 0.6772, {'top1': 0.6772}), (44, 0.6646, {'top1': 0.6646}), (47, 0.6486, {'top1': 0.6486}), (48, 0.6786, {'top1': 0.6786}), (49, 0.6614, {'top1': 0.6614}), (52, 0.6902, {'top1': 0.6902}), (53, 0.4506, {'top1': 0.4506})]
just computed impact of block 26 . accuracy after removing:  0.6954
removed block 26 current accuracy 0.6954 loss from initial  0.3046
since last training loss: 0.3044 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(1, 0.631, {'top1': 0.631}), (2, 0.587, {'top1': 0.587}), (4, 0.5402, {'top1': 0.5402}), (7, 0.604, {'top1': 0.604}), (9, 0.4646, {'top1': 0.4646}), (10, 0.4754, {'top1': 0.4754}), (12, 0.5544, {'top1': 0.5544}), (14, 0.6114, {'top1': 0.6114}), (16, 0.569, {'top1': 0.569}), (17, 0.4576, {'top1': 0.4576}), (18, 0.245, {'top1': 0.245}), (34, 0.6286, {'top1': 0.6286}), (36, 0.2298, {'top1': 0.2298}), (41, 0.614, {'top1': 0.614}), (42, 0.6062, {'top1': 0.6062}), (43, 0.6376, {'top1': 0.6376}), (44, 0.6212, {'top1': 0.6212}), (47, 0.6022, {'top1': 0.6022}), (48, 0.6234, {'top1': 0.6234}), (49, 0.6168, {'top1': 0.6168}), (52, 0.6422, {'top1': 0.6422}), (53, 0.4192, {'top1': 0.4192})]
just computed impact of block 52 . accuracy after removing:  0.6422
removed block 52 current accuracy 0.6422 loss from initial  0.3578
training start
training epoch 0 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 1 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.001]
training epoch 2 val accuracy 0.9588 topk_dict {'top1': 0.9588} is_best True lr [0.001]
training epoch 3 val accuracy 0.9628 topk_dict {'top1': 0.9628} is_best True lr [0.001]
training epoch 4 val accuracy 0.9662 topk_dict {'top1': 0.9662} is_best True lr [0.001]
training epoch 5 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best True lr [0.001]
training epoch 6 val accuracy 0.971 topk_dict {'top1': 0.971} is_best True lr [0.001]
training epoch 7 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best True lr [0.001]
training epoch 8 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.001]
training epoch 9 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best True lr [0.001]
training epoch 10 val accuracy 0.976 topk_dict {'top1': 0.976} is_best True lr [0.001]
training epoch 11 val accuracy 0.9768 topk_dict {'top1': 0.9768} is_best True lr [0.001]
training epoch 12 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 13 val accuracy 0.9762 topk_dict {'top1': 0.9762} is_best False lr [0.001]
training epoch 14 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best True lr [0.001]
training epoch 15 val accuracy 0.979 topk_dict {'top1': 0.979} is_best True lr [0.001]
training epoch 16 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best True lr [0.001]
training epoch 17 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 18 val accuracy 0.9792 topk_dict {'top1': 0.9792} is_best False lr [0.001]
training epoch 19 val accuracy 0.9772 topk_dict {'top1': 0.9772} is_best False lr [0.001]
training epoch 20 val accuracy 0.9794 topk_dict {'top1': 0.9794} is_best False lr [0.001]
training epoch 21 val accuracy 0.9786 topk_dict {'top1': 0.9786} is_best False lr [0.001]
training epoch 22 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 23 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best True lr [0.001]
training epoch 24 val accuracy 0.9776 topk_dict {'top1': 0.9776} is_best False lr [0.001]
training epoch 25 val accuracy 0.9778 topk_dict {'top1': 0.9778} is_best False lr [0.001]
training epoch 26 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best True lr [0.001]
training epoch 27 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 28 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 29 val accuracy 0.981 topk_dict {'top1': 0.981} is_best True lr [0.001]
training epoch 30 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best True lr [0.001]
training epoch 31 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 32 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 33 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best True lr [0.001]
training epoch 34 val accuracy 0.9812 topk_dict {'top1': 0.9812} is_best False lr [0.001]
training epoch 35 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
training epoch 36 val accuracy 0.9824 topk_dict {'top1': 0.9824} is_best True lr [0.001]
training epoch 37 val accuracy 0.9804 topk_dict {'top1': 0.9804} is_best False lr [0.001]
training epoch 38 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 39 val accuracy 0.9808 topk_dict {'top1': 0.9808} is_best False lr [0.001]
training epoch 40 val accuracy 0.981 topk_dict {'top1': 0.981} is_best False lr [0.001]
training epoch 41 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 42 val accuracy 0.9818 topk_dict {'top1': 0.9818} is_best False lr [0.001]
training epoch 43 val accuracy 0.9806 topk_dict {'top1': 0.9806} is_best False lr [0.001]
training epoch 44 val accuracy 0.9832 topk_dict {'top1': 0.9832} is_best True lr [0.001]
training epoch 45 val accuracy 0.9822 topk_dict {'top1': 0.9822} is_best False lr [0.001]
training epoch 46 val accuracy 0.9802 topk_dict {'top1': 0.9802} is_best False lr [0.001]
training epoch 47 val accuracy 0.9828 topk_dict {'top1': 0.9828} is_best False lr [0.001]
training epoch 48 val accuracy 0.9814 topk_dict {'top1': 0.9814} is_best False lr [0.001]
training epoch 49 val accuracy 0.982 topk_dict {'top1': 0.982} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.983200)
finished training. finished 50 epochs. accuracy 0.9832 topk_dict {'top1': 0.9832}
