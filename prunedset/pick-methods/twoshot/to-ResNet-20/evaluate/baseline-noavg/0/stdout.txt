start iteration 0
(cache recomputed) Accuracy log [(0, 1.0, {'top1': 1.0}), (1, 1.0, {'top1': 1.0}), (2, 0.9992, {'top1': 0.9992}), (3, 1.0, {'top1': 1.0}), (4, 0.9994, {'top1': 0.9994}), (5, 1.0, {'top1': 1.0}), (6, 1.0, {'top1': 1.0}), (7, 1.0, {'top1': 1.0}), (8, 0.9992, {'top1': 0.9992}), (9, 0.9982, {'top1': 0.9982}), (10, 0.9942, {'top1': 0.9942}), (11, 1.0, {'top1': 1.0}), (12, 0.9998, {'top1': 0.9998}), (13, 1.0, {'top1': 1.0}), (14, 1.0, {'top1': 1.0}), (15, 0.9996, {'top1': 0.9996}), (16, 0.9998, {'top1': 0.9998}), (17, 0.9978, {'top1': 0.9978}), (18, 0.7344, {'top1': 0.7344}), (19, 1.0, {'top1': 1.0}), (20, 1.0, {'top1': 1.0}), (21, 1.0, {'top1': 1.0}), (22, 1.0, {'top1': 1.0}), (23, 1.0, {'top1': 1.0}), (24, 1.0, {'top1': 1.0}), (25, 1.0, {'top1': 1.0}), (26, 1.0, {'top1': 1.0}), (27, 1.0, {'top1': 1.0}), (28, 1.0, {'top1': 1.0}), (29, 1.0, {'top1': 1.0}), (30, 1.0, {'top1': 1.0}), (31, 1.0, {'top1': 1.0}), (32, 1.0, {'top1': 1.0}), (33, 1.0, {'top1': 1.0}), (34, 1.0, {'top1': 1.0}), (35, 1.0, {'top1': 1.0}), (36, 0.7354, {'top1': 0.7354}), (37, 0.9998, {'top1': 0.9998}), (38, 1.0, {'top1': 1.0}), (39, 1.0, {'top1': 1.0}), (40, 0.9998, {'top1': 0.9998}), (41, 1.0, {'top1': 1.0}), (42, 0.9998, {'top1': 0.9998}), (43, 1.0, {'top1': 1.0}), (44, 0.9986, {'top1': 0.9986}), (45, 0.9996, {'top1': 0.9996}), (46, 1.0, {'top1': 1.0}), (47, 0.9992, {'top1': 0.9992}), (48, 1.0, {'top1': 1.0}), (49, 1.0, {'top1': 1.0}), (50, 0.9984, {'top1': 0.9984}), (51, 1.0, {'top1': 1.0}), (52, 0.9992, {'top1': 0.9992}), (53, 0.9716, {'top1': 0.9716})]
just computed impact of block 0 . accuracy after removing:  1.0
removed block 0 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(1, 0.995, {'top1': 0.995}), (2, 0.9864, {'top1': 0.9864}), (3, 0.9986, {'top1': 0.9986}), (4, 0.9806, {'top1': 0.9806}), (5, 0.9996, {'top1': 0.9996}), (6, 0.9998, {'top1': 0.9998}), (7, 0.9974, {'top1': 0.9974}), (8, 0.9948, {'top1': 0.9948}), (9, 0.9936, {'top1': 0.9936}), (10, 0.9926, {'top1': 0.9926}), (11, 0.999, {'top1': 0.999}), (12, 0.9982, {'top1': 0.9982}), (13, 0.9992, {'top1': 0.9992}), (14, 0.998, {'top1': 0.998}), (15, 0.9982, {'top1': 0.9982}), (16, 0.9972, {'top1': 0.9972}), (17, 0.9932, {'top1': 0.9932}), (18, 0.6866, {'top1': 0.6866}), (19, 0.9998, {'top1': 0.9998}), (20, 1.0, {'top1': 1.0}), (21, 0.9994, {'top1': 0.9994}), (22, 0.9998, {'top1': 0.9998}), (23, 1.0, {'top1': 1.0}), (24, 0.9998, {'top1': 0.9998}), (25, 1.0, {'top1': 1.0}), (26, 0.9998, {'top1': 0.9998}), (27, 0.9998, {'top1': 0.9998}), (28, 0.9998, {'top1': 0.9998}), (29, 0.9998, {'top1': 0.9998}), (30, 0.9996, {'top1': 0.9996}), (31, 0.9998, {'top1': 0.9998}), (32, 0.9998, {'top1': 0.9998}), (33, 0.9998, {'top1': 0.9998}), (34, 0.9996, {'top1': 0.9996}), (35, 0.9996, {'top1': 0.9996}), (36, 0.696, {'top1': 0.696}), (37, 0.9998, {'top1': 0.9998}), (38, 0.9996, {'top1': 0.9996}), (39, 0.9992, {'top1': 0.9992}), (40, 0.9994, {'top1': 0.9994}), (41, 0.9994, {'top1': 0.9994}), (42, 0.9992, {'top1': 0.9992}), (43, 0.9986, {'top1': 0.9986}), (44, 0.9974, {'top1': 0.9974}), (45, 0.9992, {'top1': 0.9992}), (46, 0.9984, {'top1': 0.9984}), (47, 0.9986, {'top1': 0.9986}), (48, 0.9988, {'top1': 0.9988}), (49, 0.9996, {'top1': 0.9996}), (50, 0.9968, {'top1': 0.9968}), (51, 0.999, {'top1': 0.999}), (52, 0.9968, {'top1': 0.9968}), (53, 0.9542, {'top1': 0.9542})]
just computed impact of block 20 . accuracy after removing:  1.0
removed block 20 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(1, 0.994, {'top1': 0.994}), (2, 0.983, {'top1': 0.983}), (3, 0.9964, {'top1': 0.9964}), (4, 0.9778, {'top1': 0.9778}), (5, 0.9994, {'top1': 0.9994}), (6, 0.9984, {'top1': 0.9984}), (7, 0.9974, {'top1': 0.9974}), (8, 0.9968, {'top1': 0.9968}), (9, 0.992, {'top1': 0.992}), (10, 0.9906, {'top1': 0.9906}), (11, 0.999, {'top1': 0.999}), (12, 0.998, {'top1': 0.998}), (13, 0.9992, {'top1': 0.9992}), (14, 0.9988, {'top1': 0.9988}), (15, 0.9982, {'top1': 0.9982}), (16, 0.9968, {'top1': 0.9968}), (17, 0.9938, {'top1': 0.9938}), (18, 0.66, {'top1': 0.66}), (19, 1.0, {'top1': 1.0}), (21, 0.9996, {'top1': 0.9996}), (22, 1.0, {'top1': 1.0}), (23, 0.9998, {'top1': 0.9998}), (24, 1.0, {'top1': 1.0}), (25, 1.0, {'top1': 1.0}), (26, 0.9994, {'top1': 0.9994}), (27, 0.9994, {'top1': 0.9994}), (28, 0.9994, {'top1': 0.9994}), (29, 0.9996, {'top1': 0.9996}), (30, 0.9998, {'top1': 0.9998}), (31, 0.9998, {'top1': 0.9998}), (32, 0.9994, {'top1': 0.9994}), (33, 0.9996, {'top1': 0.9996}), (34, 0.9992, {'top1': 0.9992}), (35, 0.9998, {'top1': 0.9998}), (36, 0.6642, {'top1': 0.6642}), (37, 0.999, {'top1': 0.999}), (38, 0.9996, {'top1': 0.9996}), (39, 0.9988, {'top1': 0.9988}), (40, 0.9992, {'top1': 0.9992}), (41, 0.9992, {'top1': 0.9992}), (42, 0.9978, {'top1': 0.9978}), (43, 0.9986, {'top1': 0.9986}), (44, 0.9972, {'top1': 0.9972}), (45, 0.999, {'top1': 0.999}), (46, 0.9976, {'top1': 0.9976}), (47, 0.998, {'top1': 0.998}), (48, 0.9986, {'top1': 0.9986}), (49, 0.9988, {'top1': 0.9988}), (50, 0.9962, {'top1': 0.9962}), (51, 0.9992, {'top1': 0.9992}), (52, 0.9966, {'top1': 0.9966}), (53, 0.9482, {'top1': 0.9482})]
just computed impact of block 19 . accuracy after removing:  1.0
removed block 19 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(1, 0.992, {'top1': 0.992}), (2, 0.979, {'top1': 0.979}), (3, 0.9946, {'top1': 0.9946}), (4, 0.972, {'top1': 0.972}), (5, 0.999, {'top1': 0.999}), (6, 0.9982, {'top1': 0.9982}), (7, 0.9954, {'top1': 0.9954}), (8, 0.9958, {'top1': 0.9958}), (9, 0.9892, {'top1': 0.9892}), (10, 0.9888, {'top1': 0.9888}), (11, 0.9978, {'top1': 0.9978}), (12, 0.997, {'top1': 0.997}), (13, 0.9988, {'top1': 0.9988}), (14, 0.9982, {'top1': 0.9982}), (15, 0.9974, {'top1': 0.9974}), (16, 0.9954, {'top1': 0.9954}), (17, 0.9928, {'top1': 0.9928}), (18, 0.6676, {'top1': 0.6676}), (21, 0.999, {'top1': 0.999}), (22, 0.9998, {'top1': 0.9998}), (23, 0.9998, {'top1': 0.9998}), (24, 0.9994, {'top1': 0.9994}), (25, 0.9998, {'top1': 0.9998}), (26, 0.9982, {'top1': 0.9982}), (27, 0.9988, {'top1': 0.9988}), (28, 0.9992, {'top1': 0.9992}), (29, 0.999, {'top1': 0.999}), (30, 0.9994, {'top1': 0.9994}), (31, 0.9994, {'top1': 0.9994}), (32, 0.9988, {'top1': 0.9988}), (33, 0.9994, {'top1': 0.9994}), (34, 0.9988, {'top1': 0.9988}), (35, 0.999, {'top1': 0.999}), (36, 0.6486, {'top1': 0.6486}), (37, 0.998, {'top1': 0.998}), (38, 0.9986, {'top1': 0.9986}), (39, 0.9986, {'top1': 0.9986}), (40, 0.9986, {'top1': 0.9986}), (41, 0.9986, {'top1': 0.9986}), (42, 0.9966, {'top1': 0.9966}), (43, 0.9976, {'top1': 0.9976}), (44, 0.996, {'top1': 0.996}), (45, 0.999, {'top1': 0.999}), (46, 0.9972, {'top1': 0.9972}), (47, 0.9978, {'top1': 0.9978}), (48, 0.9978, {'top1': 0.9978}), (49, 0.9978, {'top1': 0.9978}), (50, 0.9954, {'top1': 0.9954}), (51, 0.9982, {'top1': 0.9982}), (52, 0.9964, {'top1': 0.9964}), (53, 0.939, {'top1': 0.939})]
just computed impact of block 22 . accuracy after removing:  0.9998
removed block 22 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(1, 0.9904, {'top1': 0.9904}), (2, 0.975, {'top1': 0.975}), (3, 0.9928, {'top1': 0.9928}), (4, 0.9676, {'top1': 0.9676}), (5, 0.9984, {'top1': 0.9984}), (6, 0.9982, {'top1': 0.9982}), (7, 0.9944, {'top1': 0.9944}), (8, 0.9932, {'top1': 0.9932}), (9, 0.9872, {'top1': 0.9872}), (10, 0.9872, {'top1': 0.9872}), (11, 0.9974, {'top1': 0.9974}), (12, 0.9968, {'top1': 0.9968}), (13, 0.9984, {'top1': 0.9984}), (14, 0.9976, {'top1': 0.9976}), (15, 0.996, {'top1': 0.996}), (16, 0.9944, {'top1': 0.9944}), (17, 0.992, {'top1': 0.992}), (18, 0.6648, {'top1': 0.6648}), (21, 0.998, {'top1': 0.998}), (23, 0.9992, {'top1': 0.9992}), (24, 0.999, {'top1': 0.999}), (25, 0.9998, {'top1': 0.9998}), (26, 0.9978, {'top1': 0.9978}), (27, 0.9974, {'top1': 0.9974}), (28, 0.9986, {'top1': 0.9986}), (29, 0.9986, {'top1': 0.9986}), (30, 0.9986, {'top1': 0.9986}), (31, 0.9988, {'top1': 0.9988}), (32, 0.9984, {'top1': 0.9984}), (33, 0.999, {'top1': 0.999}), (34, 0.9978, {'top1': 0.9978}), (35, 0.999, {'top1': 0.999}), (36, 0.6354, {'top1': 0.6354}), (37, 0.9974, {'top1': 0.9974}), (38, 0.9974, {'top1': 0.9974}), (39, 0.9978, {'top1': 0.9978}), (40, 0.9984, {'top1': 0.9984}), (41, 0.998, {'top1': 0.998}), (42, 0.9948, {'top1': 0.9948}), (43, 0.9962, {'top1': 0.9962}), (44, 0.9946, {'top1': 0.9946}), (45, 0.9974, {'top1': 0.9974}), (46, 0.996, {'top1': 0.996}), (47, 0.9974, {'top1': 0.9974}), (48, 0.9976, {'top1': 0.9976}), (49, 0.9968, {'top1': 0.9968}), (50, 0.9944, {'top1': 0.9944}), (51, 0.9978, {'top1': 0.9978}), (52, 0.9952, {'top1': 0.9952}), (53, 0.9342, {'top1': 0.9342})]
just computed impact of block 25 . accuracy after removing:  0.9998
removed block 25 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(1, 0.99, {'top1': 0.99}), (2, 0.9754, {'top1': 0.9754}), (3, 0.9936, {'top1': 0.9936}), (4, 0.9668, {'top1': 0.9668}), (5, 0.9986, {'top1': 0.9986}), (6, 0.998, {'top1': 0.998}), (7, 0.9932, {'top1': 0.9932}), (8, 0.992, {'top1': 0.992}), (9, 0.9856, {'top1': 0.9856}), (10, 0.9856, {'top1': 0.9856}), (11, 0.9974, {'top1': 0.9974}), (12, 0.9958, {'top1': 0.9958}), (13, 0.9974, {'top1': 0.9974}), (14, 0.9972, {'top1': 0.9972}), (15, 0.9954, {'top1': 0.9954}), (16, 0.9944, {'top1': 0.9944}), (17, 0.9912, {'top1': 0.9912}), (18, 0.624, {'top1': 0.624}), (21, 0.9978, {'top1': 0.9978}), (23, 0.9986, {'top1': 0.9986}), (24, 0.9988, {'top1': 0.9988}), (26, 0.9976, {'top1': 0.9976}), (27, 0.9974, {'top1': 0.9974}), (28, 0.9986, {'top1': 0.9986}), (29, 0.9986, {'top1': 0.9986}), (30, 0.9988, {'top1': 0.9988}), (31, 0.9986, {'top1': 0.9986}), (32, 0.9982, {'top1': 0.9982}), (33, 0.9982, {'top1': 0.9982}), (34, 0.9976, {'top1': 0.9976}), (35, 0.9986, {'top1': 0.9986}), (36, 0.6082, {'top1': 0.6082}), (37, 0.997, {'top1': 0.997}), (38, 0.998, {'top1': 0.998}), (39, 0.9976, {'top1': 0.9976}), (40, 0.9986, {'top1': 0.9986}), (41, 0.9966, {'top1': 0.9966}), (42, 0.9952, {'top1': 0.9952}), (43, 0.995, {'top1': 0.995}), (44, 0.9938, {'top1': 0.9938}), (45, 0.9974, {'top1': 0.9974}), (46, 0.997, {'top1': 0.997}), (47, 0.9968, {'top1': 0.9968}), (48, 0.9978, {'top1': 0.9978}), (49, 0.9966, {'top1': 0.9966}), (50, 0.9942, {'top1': 0.9942}), (51, 0.9978, {'top1': 0.9978}), (52, 0.9946, {'top1': 0.9946}), (53, 0.9334, {'top1': 0.9334})]
just computed impact of block 24 . accuracy after removing:  0.9988
removed block 24 current accuracy 0.9988 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(1, 0.9888, {'top1': 0.9888}), (2, 0.9704, {'top1': 0.9704}), (3, 0.9912, {'top1': 0.9912}), (4, 0.9634, {'top1': 0.9634}), (5, 0.9972, {'top1': 0.9972}), (6, 0.9966, {'top1': 0.9966}), (7, 0.991, {'top1': 0.991}), (8, 0.9906, {'top1': 0.9906}), (9, 0.9822, {'top1': 0.9822}), (10, 0.9812, {'top1': 0.9812}), (11, 0.9954, {'top1': 0.9954}), (12, 0.994, {'top1': 0.994}), (13, 0.9958, {'top1': 0.9958}), (14, 0.995, {'top1': 0.995}), (15, 0.9938, {'top1': 0.9938}), (16, 0.9926, {'top1': 0.9926}), (17, 0.9892, {'top1': 0.9892}), (18, 0.6022, {'top1': 0.6022}), (21, 0.9966, {'top1': 0.9966}), (23, 0.9962, {'top1': 0.9962}), (26, 0.9956, {'top1': 0.9956}), (27, 0.996, {'top1': 0.996}), (28, 0.9966, {'top1': 0.9966}), (29, 0.9968, {'top1': 0.9968}), (30, 0.9964, {'top1': 0.9964}), (31, 0.9964, {'top1': 0.9964}), (32, 0.9974, {'top1': 0.9974}), (33, 0.9974, {'top1': 0.9974}), (34, 0.9964, {'top1': 0.9964}), (35, 0.9976, {'top1': 0.9976}), (36, 0.5882, {'top1': 0.5882}), (37, 0.996, {'top1': 0.996}), (38, 0.9966, {'top1': 0.9966}), (39, 0.9964, {'top1': 0.9964}), (40, 0.9978, {'top1': 0.9978}), (41, 0.995, {'top1': 0.995}), (42, 0.993, {'top1': 0.993}), (43, 0.9938, {'top1': 0.9938}), (44, 0.9926, {'top1': 0.9926}), (45, 0.9962, {'top1': 0.9962}), (46, 0.9954, {'top1': 0.9954}), (47, 0.9954, {'top1': 0.9954}), (48, 0.9966, {'top1': 0.9966}), (49, 0.9948, {'top1': 0.9948}), (50, 0.9922, {'top1': 0.9922}), (51, 0.9968, {'top1': 0.9968}), (52, 0.9926, {'top1': 0.9926}), (53, 0.9258, {'top1': 0.9258})]
just computed impact of block 40 . accuracy after removing:  0.9978
removed block 40 current accuracy 0.9978 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(1, 0.987, {'top1': 0.987}), (2, 0.9656, {'top1': 0.9656}), (3, 0.99, {'top1': 0.99}), (4, 0.9546, {'top1': 0.9546}), (5, 0.9958, {'top1': 0.9958}), (6, 0.9946, {'top1': 0.9946}), (7, 0.9886, {'top1': 0.9886}), (8, 0.9868, {'top1': 0.9868}), (9, 0.9806, {'top1': 0.9806}), (10, 0.977, {'top1': 0.977}), (11, 0.993, {'top1': 0.993}), (12, 0.9924, {'top1': 0.9924}), (13, 0.9944, {'top1': 0.9944}), (14, 0.9918, {'top1': 0.9918}), (15, 0.9898, {'top1': 0.9898}), (16, 0.9856, {'top1': 0.9856}), (17, 0.9836, {'top1': 0.9836}), (18, 0.578, {'top1': 0.578}), (21, 0.9946, {'top1': 0.9946}), (23, 0.9946, {'top1': 0.9946}), (26, 0.9942, {'top1': 0.9942}), (27, 0.9928, {'top1': 0.9928}), (28, 0.9944, {'top1': 0.9944}), (29, 0.9952, {'top1': 0.9952}), (30, 0.9956, {'top1': 0.9956}), (31, 0.9948, {'top1': 0.9948}), (32, 0.9954, {'top1': 0.9954}), (33, 0.9954, {'top1': 0.9954}), (34, 0.9936, {'top1': 0.9936}), (35, 0.9966, {'top1': 0.9966}), (36, 0.5434, {'top1': 0.5434}), (37, 0.9934, {'top1': 0.9934}), (38, 0.9942, {'top1': 0.9942}), (39, 0.9928, {'top1': 0.9928}), (41, 0.9916, {'top1': 0.9916}), (42, 0.9864, {'top1': 0.9864}), (43, 0.9888, {'top1': 0.9888}), (44, 0.9896, {'top1': 0.9896}), (45, 0.9932, {'top1': 0.9932}), (46, 0.9902, {'top1': 0.9902}), (47, 0.9902, {'top1': 0.9902}), (48, 0.9936, {'top1': 0.9936}), (49, 0.9904, {'top1': 0.9904}), (50, 0.9884, {'top1': 0.9884}), (51, 0.9928, {'top1': 0.9928}), (52, 0.9872, {'top1': 0.9872}), (53, 0.9024, {'top1': 0.9024})]
just computed impact of block 35 . accuracy after removing:  0.9966
removed block 35 current accuracy 0.9966 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(1, 0.985, {'top1': 0.985}), (2, 0.9638, {'top1': 0.9638}), (3, 0.9888, {'top1': 0.9888}), (4, 0.9552, {'top1': 0.9552}), (5, 0.994, {'top1': 0.994}), (6, 0.993, {'top1': 0.993}), (7, 0.9886, {'top1': 0.9886}), (8, 0.984, {'top1': 0.984}), (9, 0.9764, {'top1': 0.9764}), (10, 0.9766, {'top1': 0.9766}), (11, 0.9916, {'top1': 0.9916}), (12, 0.9904, {'top1': 0.9904}), (13, 0.9922, {'top1': 0.9922}), (14, 0.9914, {'top1': 0.9914}), (15, 0.9884, {'top1': 0.9884}), (16, 0.9858, {'top1': 0.9858}), (17, 0.9816, {'top1': 0.9816}), (18, 0.5682, {'top1': 0.5682}), (21, 0.9926, {'top1': 0.9926}), (23, 0.9934, {'top1': 0.9934}), (26, 0.993, {'top1': 0.993}), (27, 0.9902, {'top1': 0.9902}), (28, 0.992, {'top1': 0.992}), (29, 0.9928, {'top1': 0.9928}), (30, 0.9936, {'top1': 0.9936}), (31, 0.9926, {'top1': 0.9926}), (32, 0.9916, {'top1': 0.9916}), (33, 0.9918, {'top1': 0.9918}), (34, 0.9902, {'top1': 0.9902}), (36, 0.5184, {'top1': 0.5184}), (37, 0.9898, {'top1': 0.9898}), (38, 0.993, {'top1': 0.993}), (39, 0.99, {'top1': 0.99}), (41, 0.989, {'top1': 0.989}), (42, 0.9844, {'top1': 0.9844}), (43, 0.9872, {'top1': 0.9872}), (44, 0.9866, {'top1': 0.9866}), (45, 0.991, {'top1': 0.991}), (46, 0.9866, {'top1': 0.9866}), (47, 0.9892, {'top1': 0.9892}), (48, 0.992, {'top1': 0.992}), (49, 0.9888, {'top1': 0.9888}), (50, 0.9854, {'top1': 0.9854}), (51, 0.9898, {'top1': 0.9898}), (52, 0.9826, {'top1': 0.9826}), (53, 0.9026, {'top1': 0.9026})]
just computed impact of block 5 . accuracy after removing:  0.994
removed block 5 current accuracy 0.994 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(1, 0.9788, {'top1': 0.9788}), (2, 0.9534, {'top1': 0.9534}), (3, 0.9836, {'top1': 0.9836}), (4, 0.942, {'top1': 0.942}), (6, 0.99, {'top1': 0.99}), (7, 0.9806, {'top1': 0.9806}), (8, 0.979, {'top1': 0.979}), (9, 0.9708, {'top1': 0.9708}), (10, 0.973, {'top1': 0.973}), (11, 0.9892, {'top1': 0.9892}), (12, 0.9874, {'top1': 0.9874}), (13, 0.9898, {'top1': 0.9898}), (14, 0.9866, {'top1': 0.9866}), (15, 0.987, {'top1': 0.987}), (16, 0.9816, {'top1': 0.9816}), (17, 0.9766, {'top1': 0.9766}), (18, 0.5754, {'top1': 0.5754}), (21, 0.9894, {'top1': 0.9894}), (23, 0.9894, {'top1': 0.9894}), (26, 0.99, {'top1': 0.99}), (27, 0.9868, {'top1': 0.9868}), (28, 0.9912, {'top1': 0.9912}), (29, 0.9898, {'top1': 0.9898}), (30, 0.991, {'top1': 0.991}), (31, 0.9908, {'top1': 0.9908}), (32, 0.9906, {'top1': 0.9906}), (33, 0.9916, {'top1': 0.9916}), (34, 0.987, {'top1': 0.987}), (36, 0.5082, {'top1': 0.5082}), (37, 0.9894, {'top1': 0.9894}), (38, 0.9916, {'top1': 0.9916}), (39, 0.9866, {'top1': 0.9866}), (41, 0.9854, {'top1': 0.9854}), (42, 0.982, {'top1': 0.982}), (43, 0.9844, {'top1': 0.9844}), (44, 0.9836, {'top1': 0.9836}), (45, 0.988, {'top1': 0.988}), (46, 0.9852, {'top1': 0.9852}), (47, 0.9858, {'top1': 0.9858}), (48, 0.9894, {'top1': 0.9894}), (49, 0.9854, {'top1': 0.9854}), (50, 0.9838, {'top1': 0.9838}), (51, 0.9866, {'top1': 0.9866}), (52, 0.9808, {'top1': 0.9808}), (53, 0.8904, {'top1': 0.8904})]
just computed impact of block 33 . accuracy after removing:  0.9916
removed block 33 current accuracy 0.9916 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(1, 0.9746, {'top1': 0.9746}), (2, 0.9526, {'top1': 0.9526}), (3, 0.9796, {'top1': 0.9796}), (4, 0.939, {'top1': 0.939}), (6, 0.9858, {'top1': 0.9858}), (7, 0.9762, {'top1': 0.9762}), (8, 0.9764, {'top1': 0.9764}), (9, 0.9628, {'top1': 0.9628}), (10, 0.9668, {'top1': 0.9668}), (11, 0.9856, {'top1': 0.9856}), (12, 0.981, {'top1': 0.981}), (13, 0.9852, {'top1': 0.9852}), (14, 0.9846, {'top1': 0.9846}), (15, 0.9814, {'top1': 0.9814}), (16, 0.9798, {'top1': 0.9798}), (17, 0.9722, {'top1': 0.9722}), (18, 0.5544, {'top1': 0.5544}), (21, 0.9862, {'top1': 0.9862}), (23, 0.9836, {'top1': 0.9836}), (26, 0.9848, {'top1': 0.9848}), (27, 0.9846, {'top1': 0.9846}), (28, 0.9846, {'top1': 0.9846}), (29, 0.9868, {'top1': 0.9868}), (30, 0.986, {'top1': 0.986}), (31, 0.9848, {'top1': 0.9848}), (32, 0.9848, {'top1': 0.9848}), (34, 0.982, {'top1': 0.982}), (36, 0.4646, {'top1': 0.4646}), (37, 0.9832, {'top1': 0.9832}), (38, 0.9878, {'top1': 0.9878}), (39, 0.9828, {'top1': 0.9828}), (41, 0.9802, {'top1': 0.9802}), (42, 0.9772, {'top1': 0.9772}), (43, 0.98, {'top1': 0.98}), (44, 0.9798, {'top1': 0.9798}), (45, 0.983, {'top1': 0.983}), (46, 0.9796, {'top1': 0.9796}), (47, 0.9818, {'top1': 0.9818}), (48, 0.9848, {'top1': 0.9848}), (49, 0.98, {'top1': 0.98}), (50, 0.978, {'top1': 0.978}), (51, 0.9826, {'top1': 0.9826}), (52, 0.975, {'top1': 0.975}), (53, 0.8906, {'top1': 0.8906})]
just computed impact of block 38 . accuracy after removing:  0.9878
removed block 38 current accuracy 0.9878 loss from initial  0.012199999999999989
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(1, 0.9708, {'top1': 0.9708}), (2, 0.9436, {'top1': 0.9436}), (3, 0.9744, {'top1': 0.9744}), (4, 0.9304, {'top1': 0.9304}), (6, 0.9808, {'top1': 0.9808}), (7, 0.9728, {'top1': 0.9728}), (8, 0.9726, {'top1': 0.9726}), (9, 0.9556, {'top1': 0.9556}), (10, 0.9586, {'top1': 0.9586}), (11, 0.982, {'top1': 0.982}), (12, 0.9744, {'top1': 0.9744}), (13, 0.9812, {'top1': 0.9812}), (14, 0.978, {'top1': 0.978}), (15, 0.9768, {'top1': 0.9768}), (16, 0.9766, {'top1': 0.9766}), (17, 0.969, {'top1': 0.969}), (18, 0.55, {'top1': 0.55}), (21, 0.9822, {'top1': 0.9822}), (23, 0.9794, {'top1': 0.9794}), (26, 0.9788, {'top1': 0.9788}), (27, 0.9804, {'top1': 0.9804}), (28, 0.9806, {'top1': 0.9806}), (29, 0.9834, {'top1': 0.9834}), (30, 0.9804, {'top1': 0.9804}), (31, 0.9806, {'top1': 0.9806}), (32, 0.9806, {'top1': 0.9806}), (34, 0.9748, {'top1': 0.9748}), (36, 0.317, {'top1': 0.317}), (37, 0.9776, {'top1': 0.9776}), (39, 0.9768, {'top1': 0.9768}), (41, 0.975, {'top1': 0.975}), (42, 0.9698, {'top1': 0.9698}), (43, 0.9748, {'top1': 0.9748}), (44, 0.975, {'top1': 0.975}), (45, 0.9788, {'top1': 0.9788}), (46, 0.9746, {'top1': 0.9746}), (47, 0.9744, {'top1': 0.9744}), (48, 0.98, {'top1': 0.98}), (49, 0.9768, {'top1': 0.9768}), (50, 0.9732, {'top1': 0.9732}), (51, 0.9778, {'top1': 0.9778}), (52, 0.9698, {'top1': 0.9698}), (53, 0.8736, {'top1': 0.8736})]
just computed impact of block 29 . accuracy after removing:  0.9834
removed block 29 current accuracy 0.9834 loss from initial  0.016599999999999948
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(1, 0.9644, {'top1': 0.9644}), (2, 0.938, {'top1': 0.938}), (3, 0.971, {'top1': 0.971}), (4, 0.9224, {'top1': 0.9224}), (6, 0.9744, {'top1': 0.9744}), (7, 0.9668, {'top1': 0.9668}), (8, 0.968, {'top1': 0.968}), (9, 0.948, {'top1': 0.948}), (10, 0.957, {'top1': 0.957}), (11, 0.9764, {'top1': 0.9764}), (12, 0.9682, {'top1': 0.9682}), (13, 0.9758, {'top1': 0.9758}), (14, 0.9746, {'top1': 0.9746}), (15, 0.9714, {'top1': 0.9714}), (16, 0.9728, {'top1': 0.9728}), (17, 0.9618, {'top1': 0.9618}), (18, 0.5518, {'top1': 0.5518}), (21, 0.976, {'top1': 0.976}), (23, 0.9748, {'top1': 0.9748}), (26, 0.9714, {'top1': 0.9714}), (27, 0.9754, {'top1': 0.9754}), (28, 0.9746, {'top1': 0.9746}), (30, 0.9732, {'top1': 0.9732}), (31, 0.9724, {'top1': 0.9724}), (32, 0.9752, {'top1': 0.9752}), (34, 0.9694, {'top1': 0.9694}), (36, 0.297, {'top1': 0.297}), (37, 0.9722, {'top1': 0.9722}), (39, 0.9718, {'top1': 0.9718}), (41, 0.9696, {'top1': 0.9696}), (42, 0.9644, {'top1': 0.9644}), (43, 0.9684, {'top1': 0.9684}), (44, 0.9664, {'top1': 0.9664}), (45, 0.9736, {'top1': 0.9736}), (46, 0.9698, {'top1': 0.9698}), (47, 0.9704, {'top1': 0.9704}), (48, 0.9734, {'top1': 0.9734}), (49, 0.9712, {'top1': 0.9712}), (50, 0.968, {'top1': 0.968}), (51, 0.9728, {'top1': 0.9728}), (52, 0.9658, {'top1': 0.9658}), (53, 0.863, {'top1': 0.863})]
just computed impact of block 11 . accuracy after removing:  0.9764
removed block 11 current accuracy 0.9764 loss from initial  0.023599999999999954
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(1, 0.9556, {'top1': 0.9556}), (2, 0.9164, {'top1': 0.9164}), (3, 0.963, {'top1': 0.963}), (4, 0.8962, {'top1': 0.8962}), (6, 0.968, {'top1': 0.968}), (7, 0.9534, {'top1': 0.9534}), (8, 0.952, {'top1': 0.952}), (9, 0.9248, {'top1': 0.9248}), (10, 0.9158, {'top1': 0.9158}), (12, 0.9494, {'top1': 0.9494}), (13, 0.9608, {'top1': 0.9608}), (14, 0.955, {'top1': 0.955}), (15, 0.9584, {'top1': 0.9584}), (16, 0.954, {'top1': 0.954}), (17, 0.9136, {'top1': 0.9136}), (18, 0.484, {'top1': 0.484}), (21, 0.9682, {'top1': 0.9682}), (23, 0.9658, {'top1': 0.9658}), (26, 0.9654, {'top1': 0.9654}), (27, 0.969, {'top1': 0.969}), (28, 0.9656, {'top1': 0.9656}), (30, 0.9678, {'top1': 0.9678}), (31, 0.9678, {'top1': 0.9678}), (32, 0.9694, {'top1': 0.9694}), (34, 0.961, {'top1': 0.961}), (36, 0.2598, {'top1': 0.2598}), (37, 0.9648, {'top1': 0.9648}), (39, 0.9638, {'top1': 0.9638}), (41, 0.9598, {'top1': 0.9598}), (42, 0.9556, {'top1': 0.9556}), (43, 0.9622, {'top1': 0.9622}), (44, 0.955, {'top1': 0.955}), (45, 0.9664, {'top1': 0.9664}), (46, 0.961, {'top1': 0.961}), (47, 0.9602, {'top1': 0.9602}), (48, 0.969, {'top1': 0.969}), (49, 0.9658, {'top1': 0.9658}), (50, 0.961, {'top1': 0.961}), (51, 0.9678, {'top1': 0.9678}), (52, 0.9568, {'top1': 0.9568}), (53, 0.8366, {'top1': 0.8366})]
just computed impact of block 32 . accuracy after removing:  0.9694
removed block 32 current accuracy 0.9694 loss from initial  0.03059999999999996
since last training loss: 0.03059999999999996 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(1, 0.946, {'top1': 0.946}), (2, 0.9108, {'top1': 0.9108}), (3, 0.9554, {'top1': 0.9554}), (4, 0.8904, {'top1': 0.8904}), (6, 0.9614, {'top1': 0.9614}), (7, 0.9478, {'top1': 0.9478}), (8, 0.9402, {'top1': 0.9402}), (9, 0.9072, {'top1': 0.9072}), (10, 0.904, {'top1': 0.904}), (12, 0.9366, {'top1': 0.9366}), (13, 0.9536, {'top1': 0.9536}), (14, 0.9464, {'top1': 0.9464}), (15, 0.9502, {'top1': 0.9502}), (16, 0.9496, {'top1': 0.9496}), (17, 0.9068, {'top1': 0.9068}), (18, 0.4616, {'top1': 0.4616}), (21, 0.9624, {'top1': 0.9624}), (23, 0.9558, {'top1': 0.9558}), (26, 0.9554, {'top1': 0.9554}), (27, 0.9592, {'top1': 0.9592}), (28, 0.9586, {'top1': 0.9586}), (30, 0.9586, {'top1': 0.9586}), (31, 0.9564, {'top1': 0.9564}), (34, 0.9444, {'top1': 0.9444}), (36, 0.2436, {'top1': 0.2436}), (37, 0.9566, {'top1': 0.9566}), (39, 0.9552, {'top1': 0.9552}), (41, 0.949, {'top1': 0.949}), (42, 0.948, {'top1': 0.948}), (43, 0.9516, {'top1': 0.9516}), (44, 0.9476, {'top1': 0.9476}), (45, 0.9574, {'top1': 0.9574}), (46, 0.9538, {'top1': 0.9538}), (47, 0.9558, {'top1': 0.9558}), (48, 0.9602, {'top1': 0.9602}), (49, 0.9574, {'top1': 0.9574}), (50, 0.9554, {'top1': 0.9554}), (51, 0.959, {'top1': 0.959}), (52, 0.9474, {'top1': 0.9474}), (53, 0.8272, {'top1': 0.8272})]
just computed impact of block 21 . accuracy after removing:  0.9624
removed block 21 current accuracy 0.9624 loss from initial  0.03759999999999997
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(1, 0.9338, {'top1': 0.9338}), (2, 0.893, {'top1': 0.893}), (3, 0.9436, {'top1': 0.9436}), (4, 0.8698, {'top1': 0.8698}), (6, 0.9524, {'top1': 0.9524}), (7, 0.9332, {'top1': 0.9332}), (8, 0.928, {'top1': 0.928}), (9, 0.8852, {'top1': 0.8852}), (10, 0.8818, {'top1': 0.8818}), (12, 0.9208, {'top1': 0.9208}), (13, 0.9376, {'top1': 0.9376}), (14, 0.9342, {'top1': 0.9342}), (15, 0.9344, {'top1': 0.9344}), (16, 0.9394, {'top1': 0.9394}), (17, 0.8968, {'top1': 0.8968}), (18, 0.4368, {'top1': 0.4368}), (23, 0.9412, {'top1': 0.9412}), (26, 0.9442, {'top1': 0.9442}), (27, 0.95, {'top1': 0.95}), (28, 0.9486, {'top1': 0.9486}), (30, 0.9456, {'top1': 0.9456}), (31, 0.944, {'top1': 0.944}), (34, 0.9352, {'top1': 0.9352}), (36, 0.2398, {'top1': 0.2398}), (37, 0.9432, {'top1': 0.9432}), (39, 0.9446, {'top1': 0.9446}), (41, 0.9368, {'top1': 0.9368}), (42, 0.9366, {'top1': 0.9366}), (43, 0.9404, {'top1': 0.9404}), (44, 0.9338, {'top1': 0.9338}), (45, 0.9488, {'top1': 0.9488}), (46, 0.9434, {'top1': 0.9434}), (47, 0.9448, {'top1': 0.9448}), (48, 0.9476, {'top1': 0.9476}), (49, 0.9464, {'top1': 0.9464}), (50, 0.9444, {'top1': 0.9444}), (51, 0.9484, {'top1': 0.9484}), (52, 0.9372, {'top1': 0.9372}), (53, 0.8136, {'top1': 0.8136})]
just computed impact of block 6 . accuracy after removing:  0.9524
removed block 6 current accuracy 0.9524 loss from initial  0.047599999999999976
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(1, 0.9148, {'top1': 0.9148}), (2, 0.8744, {'top1': 0.8744}), (3, 0.9258, {'top1': 0.9258}), (4, 0.8452, {'top1': 0.8452}), (7, 0.9078, {'top1': 0.9078}), (8, 0.912, {'top1': 0.912}), (9, 0.8644, {'top1': 0.8644}), (10, 0.8626, {'top1': 0.8626}), (12, 0.9102, {'top1': 0.9102}), (13, 0.9242, {'top1': 0.9242}), (14, 0.9186, {'top1': 0.9186}), (15, 0.925, {'top1': 0.925}), (16, 0.9252, {'top1': 0.9252}), (17, 0.8736, {'top1': 0.8736}), (18, 0.4342, {'top1': 0.4342}), (23, 0.931, {'top1': 0.931}), (26, 0.9352, {'top1': 0.9352}), (27, 0.9388, {'top1': 0.9388}), (28, 0.9366, {'top1': 0.9366}), (30, 0.936, {'top1': 0.936}), (31, 0.9316, {'top1': 0.9316}), (34, 0.9258, {'top1': 0.9258}), (36, 0.2304, {'top1': 0.2304}), (37, 0.9322, {'top1': 0.9322}), (39, 0.9342, {'top1': 0.9342}), (41, 0.928, {'top1': 0.928}), (42, 0.9232, {'top1': 0.9232}), (43, 0.9288, {'top1': 0.9288}), (44, 0.9222, {'top1': 0.9222}), (45, 0.934, {'top1': 0.934}), (46, 0.93, {'top1': 0.93}), (47, 0.9338, {'top1': 0.9338}), (48, 0.9374, {'top1': 0.9374}), (49, 0.9342, {'top1': 0.9342}), (50, 0.931, {'top1': 0.931}), (51, 0.938, {'top1': 0.938}), (52, 0.927, {'top1': 0.927}), (53, 0.7892, {'top1': 0.7892})]
just computed impact of block 27 . accuracy after removing:  0.9388
removed block 27 current accuracy 0.9388 loss from initial  0.06120000000000003
since last training loss: 0.06120000000000003 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(1, 0.9026, {'top1': 0.9026}), (2, 0.8624, {'top1': 0.8624}), (3, 0.9138, {'top1': 0.9138}), (4, 0.8288, {'top1': 0.8288}), (7, 0.8938, {'top1': 0.8938}), (8, 0.8966, {'top1': 0.8966}), (9, 0.8532, {'top1': 0.8532}), (10, 0.851, {'top1': 0.851}), (12, 0.8958, {'top1': 0.8958}), (13, 0.9068, {'top1': 0.9068}), (14, 0.9096, {'top1': 0.9096}), (15, 0.9156, {'top1': 0.9156}), (16, 0.9144, {'top1': 0.9144}), (17, 0.857, {'top1': 0.857}), (18, 0.4272, {'top1': 0.4272}), (23, 0.919, {'top1': 0.919}), (26, 0.9166, {'top1': 0.9166}), (28, 0.9256, {'top1': 0.9256}), (30, 0.921, {'top1': 0.921}), (31, 0.9164, {'top1': 0.9164}), (34, 0.9074, {'top1': 0.9074}), (36, 0.2178, {'top1': 0.2178}), (37, 0.9206, {'top1': 0.9206}), (39, 0.9198, {'top1': 0.9198}), (41, 0.913, {'top1': 0.913}), (42, 0.9112, {'top1': 0.9112}), (43, 0.9172, {'top1': 0.9172}), (44, 0.9116, {'top1': 0.9116}), (45, 0.9198, {'top1': 0.9198}), (46, 0.9194, {'top1': 0.9194}), (47, 0.9226, {'top1': 0.9226}), (48, 0.923, {'top1': 0.923}), (49, 0.9222, {'top1': 0.9222}), (50, 0.9192, {'top1': 0.9192}), (51, 0.9226, {'top1': 0.9226}), (52, 0.9116, {'top1': 0.9116}), (53, 0.7714, {'top1': 0.7714})]
just computed impact of block 28 . accuracy after removing:  0.9256
removed block 28 current accuracy 0.9256 loss from initial  0.07440000000000002
since last training loss: 0.07440000000000002 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(1, 0.891, {'top1': 0.891}), (2, 0.8542, {'top1': 0.8542}), (3, 0.9022, {'top1': 0.9022}), (4, 0.8146, {'top1': 0.8146}), (7, 0.8782, {'top1': 0.8782}), (8, 0.878, {'top1': 0.878}), (9, 0.82, {'top1': 0.82}), (10, 0.8202, {'top1': 0.8202}), (12, 0.876, {'top1': 0.876}), (13, 0.8904, {'top1': 0.8904}), (14, 0.896, {'top1': 0.896}), (15, 0.8992, {'top1': 0.8992}), (16, 0.8976, {'top1': 0.8976}), (17, 0.8384, {'top1': 0.8384}), (18, 0.3598, {'top1': 0.3598}), (23, 0.9012, {'top1': 0.9012}), (26, 0.9002, {'top1': 0.9002}), (30, 0.9078, {'top1': 0.9078}), (31, 0.9036, {'top1': 0.9036}), (34, 0.8888, {'top1': 0.8888}), (36, 0.2038, {'top1': 0.2038}), (37, 0.9006, {'top1': 0.9006}), (39, 0.9036, {'top1': 0.9036}), (41, 0.8926, {'top1': 0.8926}), (42, 0.8938, {'top1': 0.8938}), (43, 0.9034, {'top1': 0.9034}), (44, 0.8936, {'top1': 0.8936}), (45, 0.9026, {'top1': 0.9026}), (46, 0.9074, {'top1': 0.9074}), (47, 0.905, {'top1': 0.905}), (48, 0.9094, {'top1': 0.9094}), (49, 0.9086, {'top1': 0.9086}), (50, 0.9056, {'top1': 0.9056}), (51, 0.9098, {'top1': 0.9098}), (52, 0.8938, {'top1': 0.8938}), (53, 0.7384, {'top1': 0.7384})]
just computed impact of block 51 . accuracy after removing:  0.9098
removed block 51 current accuracy 0.9098 loss from initial  0.09019999999999995
since last training loss: 0.09019999999999995 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(1, 0.8674, {'top1': 0.8674}), (2, 0.829, {'top1': 0.829}), (3, 0.88, {'top1': 0.88}), (4, 0.7896, {'top1': 0.7896}), (7, 0.8552, {'top1': 0.8552}), (8, 0.8578, {'top1': 0.8578}), (9, 0.7982, {'top1': 0.7982}), (10, 0.7942, {'top1': 0.7942}), (12, 0.858, {'top1': 0.858}), (13, 0.8734, {'top1': 0.8734}), (14, 0.8736, {'top1': 0.8736}), (15, 0.8812, {'top1': 0.8812}), (16, 0.8828, {'top1': 0.8828}), (17, 0.8256, {'top1': 0.8256}), (18, 0.315, {'top1': 0.315}), (23, 0.8838, {'top1': 0.8838}), (26, 0.883, {'top1': 0.883}), (30, 0.8856, {'top1': 0.8856}), (31, 0.8788, {'top1': 0.8788}), (34, 0.8698, {'top1': 0.8698}), (36, 0.2334, {'top1': 0.2334}), (37, 0.8858, {'top1': 0.8858}), (39, 0.8806, {'top1': 0.8806}), (41, 0.873, {'top1': 0.873}), (42, 0.8736, {'top1': 0.8736}), (43, 0.8812, {'top1': 0.8812}), (44, 0.8748, {'top1': 0.8748}), (45, 0.8836, {'top1': 0.8836}), (46, 0.8802, {'top1': 0.8802}), (47, 0.8814, {'top1': 0.8814}), (48, 0.8872, {'top1': 0.8872}), (49, 0.885, {'top1': 0.885}), (50, 0.8828, {'top1': 0.8828}), (52, 0.8724, {'top1': 0.8724}), (53, 0.6798, {'top1': 0.6798})]
just computed impact of block 48 . accuracy after removing:  0.8872
removed block 48 current accuracy 0.8872 loss from initial  0.11280000000000001
since last training loss: 0.11280000000000001 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(1, 0.8462, {'top1': 0.8462}), (2, 0.7966, {'top1': 0.7966}), (3, 0.8584, {'top1': 0.8584}), (4, 0.7588, {'top1': 0.7588}), (7, 0.8272, {'top1': 0.8272}), (8, 0.8302, {'top1': 0.8302}), (9, 0.7546, {'top1': 0.7546}), (10, 0.7564, {'top1': 0.7564}), (12, 0.8346, {'top1': 0.8346}), (13, 0.849, {'top1': 0.849}), (14, 0.8534, {'top1': 0.8534}), (15, 0.866, {'top1': 0.866}), (16, 0.859, {'top1': 0.859}), (17, 0.8138, {'top1': 0.8138}), (18, 0.3014, {'top1': 0.3014}), (23, 0.8612, {'top1': 0.8612}), (26, 0.8644, {'top1': 0.8644}), (30, 0.867, {'top1': 0.867}), (31, 0.8594, {'top1': 0.8594}), (34, 0.8472, {'top1': 0.8472}), (36, 0.2448, {'top1': 0.2448}), (37, 0.8638, {'top1': 0.8638}), (39, 0.858, {'top1': 0.858}), (41, 0.8506, {'top1': 0.8506}), (42, 0.842, {'top1': 0.842}), (43, 0.849, {'top1': 0.849}), (44, 0.8464, {'top1': 0.8464}), (45, 0.863, {'top1': 0.863}), (46, 0.8516, {'top1': 0.8516}), (47, 0.8546, {'top1': 0.8546}), (49, 0.851, {'top1': 0.851}), (50, 0.8586, {'top1': 0.8586}), (52, 0.8552, {'top1': 0.8552}), (53, 0.648, {'top1': 0.648})]
just computed impact of block 30 . accuracy after removing:  0.867
removed block 30 current accuracy 0.867 loss from initial  0.133
since last training loss: 0.133 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(1, 0.8222, {'top1': 0.8222}), (2, 0.7692, {'top1': 0.7692}), (3, 0.8352, {'top1': 0.8352}), (4, 0.727, {'top1': 0.727}), (7, 0.8082, {'top1': 0.8082}), (8, 0.808, {'top1': 0.808}), (9, 0.7098, {'top1': 0.7098}), (10, 0.7192, {'top1': 0.7192}), (12, 0.8016, {'top1': 0.8016}), (13, 0.824, {'top1': 0.824}), (14, 0.8258, {'top1': 0.8258}), (15, 0.8384, {'top1': 0.8384}), (16, 0.8368, {'top1': 0.8368}), (17, 0.782, {'top1': 0.782}), (18, 0.2724, {'top1': 0.2724}), (23, 0.8326, {'top1': 0.8326}), (26, 0.839, {'top1': 0.839}), (31, 0.8262, {'top1': 0.8262}), (34, 0.8186, {'top1': 0.8186}), (36, 0.2404, {'top1': 0.2404}), (37, 0.8434, {'top1': 0.8434}), (39, 0.8402, {'top1': 0.8402}), (41, 0.824, {'top1': 0.824}), (42, 0.819, {'top1': 0.819}), (43, 0.8258, {'top1': 0.8258}), (44, 0.8238, {'top1': 0.8238}), (45, 0.8402, {'top1': 0.8402}), (46, 0.8286, {'top1': 0.8286}), (47, 0.8292, {'top1': 0.8292}), (49, 0.8302, {'top1': 0.8302}), (50, 0.8338, {'top1': 0.8338}), (52, 0.8258, {'top1': 0.8258}), (53, 0.63, {'top1': 0.63})]
just computed impact of block 37 . accuracy after removing:  0.8434
removed block 37 current accuracy 0.8434 loss from initial  0.15659999999999996
training start
training epoch 0 val accuracy 0.985 topk_dict {'top1': 0.985} is_best True lr [0.001]
training epoch 1 val accuracy 0.989 topk_dict {'top1': 0.989} is_best True lr [0.001]
training epoch 2 val accuracy 0.9924 topk_dict {'top1': 0.9924} is_best True lr [0.001]
training epoch 3 val accuracy 0.992 topk_dict {'top1': 0.992} is_best False lr [0.001]
training epoch 4 val accuracy 0.9932 topk_dict {'top1': 0.9932} is_best True lr [0.001]
training epoch 5 val accuracy 0.993 topk_dict {'top1': 0.993} is_best False lr [0.001]
training epoch 6 val accuracy 0.9944 topk_dict {'top1': 0.9944} is_best True lr [0.001]
training epoch 7 val accuracy 0.9948 topk_dict {'top1': 0.9948} is_best True lr [0.001]
training epoch 8 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best True lr [0.001]
training epoch 9 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 10 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 11 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 12 val accuracy 0.9952 topk_dict {'top1': 0.9952} is_best False lr [0.001]
training epoch 13 val accuracy 0.9954 topk_dict {'top1': 0.9954} is_best False lr [0.001]
training epoch 14 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best True lr [0.001]
training epoch 15 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best True lr [0.001]
training epoch 16 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 17 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 18 val accuracy 0.9956 topk_dict {'top1': 0.9956} is_best False lr [0.001]
training epoch 19 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 20 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 21 val accuracy 0.9962 topk_dict {'top1': 0.9962} is_best False lr [0.001]
training epoch 22 val accuracy 0.9958 topk_dict {'top1': 0.9958} is_best False lr [0.001]
training epoch 23 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best True lr [0.001]
training epoch 24 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 25 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 26 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 27 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best True lr [0.001]
training epoch 28 val accuracy 0.997 topk_dict {'top1': 0.997} is_best True lr [0.001]
training epoch 29 val accuracy 0.9964 topk_dict {'top1': 0.9964} is_best False lr [0.001]
training epoch 30 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 31 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best True lr [0.001]
training epoch 32 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 33 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 34 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best True lr [0.001]
training epoch 35 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 36 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 37 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 38 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 39 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 40 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 41 val accuracy 0.9974 topk_dict {'top1': 0.9974} is_best False lr [0.001]
training epoch 42 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 43 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 44 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 45 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
training epoch 46 val accuracy 0.9968 topk_dict {'top1': 0.9968} is_best False lr [0.001]
training epoch 47 val accuracy 0.9966 topk_dict {'top1': 0.9966} is_best False lr [0.001]
training epoch 48 val accuracy 0.997 topk_dict {'top1': 0.997} is_best False lr [0.001]
training epoch 49 val accuracy 0.9972 topk_dict {'top1': 0.9972} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.997400)
finished training. finished 50 epochs. accuracy 0.9974 topk_dict {'top1': 0.9974}
start iteration 22
(cache recomputed) Accuracy log [(1, 0.9928, {'top1': 0.9928}), (2, 0.9846, {'top1': 0.9846}), (3, 0.9946, {'top1': 0.9946}), (4, 0.9802, {'top1': 0.9802}), (7, 0.9942, {'top1': 0.9942}), (8, 0.9898, {'top1': 0.9898}), (9, 0.9782, {'top1': 0.9782}), (10, 0.9746, {'top1': 0.9746}), (12, 0.9866, {'top1': 0.9866}), (13, 0.995, {'top1': 0.995}), (14, 0.9916, {'top1': 0.9916}), (15, 0.9912, {'top1': 0.9912}), (16, 0.992, {'top1': 0.992}), (17, 0.9822, {'top1': 0.9822}), (18, 0.5522, {'top1': 0.5522}), (23, 0.9914, {'top1': 0.9914}), (26, 0.9894, {'top1': 0.9894}), (31, 0.9912, {'top1': 0.9912}), (34, 0.9864, {'top1': 0.9864}), (36, 0.5228, {'top1': 0.5228}), (39, 0.9892, {'top1': 0.9892}), (41, 0.9892, {'top1': 0.9892}), (42, 0.9856, {'top1': 0.9856}), (43, 0.9906, {'top1': 0.9906}), (44, 0.9886, {'top1': 0.9886}), (45, 0.9924, {'top1': 0.9924}), (46, 0.989, {'top1': 0.989}), (47, 0.9874, {'top1': 0.9874}), (49, 0.9908, {'top1': 0.9908}), (50, 0.9854, {'top1': 0.9854}), (52, 0.9802, {'top1': 0.9802}), (53, 0.92, {'top1': 0.92})]
just computed impact of block 13 . accuracy after removing:  0.995
removed block 13 current accuracy 0.995 loss from initial  0.0050000000000000044
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(1, 0.9898, {'top1': 0.9898}), (2, 0.9758, {'top1': 0.9758}), (3, 0.9908, {'top1': 0.9908}), (4, 0.969, {'top1': 0.969}), (7, 0.9882, {'top1': 0.9882}), (8, 0.9812, {'top1': 0.9812}), (9, 0.9544, {'top1': 0.9544}), (10, 0.9492, {'top1': 0.9492}), (12, 0.974, {'top1': 0.974}), (14, 0.9826, {'top1': 0.9826}), (15, 0.9802, {'top1': 0.9802}), (16, 0.9852, {'top1': 0.9852}), (17, 0.9592, {'top1': 0.9592}), (18, 0.5182, {'top1': 0.5182}), (23, 0.9894, {'top1': 0.9894}), (26, 0.9874, {'top1': 0.9874}), (31, 0.9874, {'top1': 0.9874}), (34, 0.9852, {'top1': 0.9852}), (36, 0.5136, {'top1': 0.5136}), (39, 0.9868, {'top1': 0.9868}), (41, 0.9872, {'top1': 0.9872}), (42, 0.9806, {'top1': 0.9806}), (43, 0.986, {'top1': 0.986}), (44, 0.985, {'top1': 0.985}), (45, 0.9902, {'top1': 0.9902}), (46, 0.9852, {'top1': 0.9852}), (47, 0.9848, {'top1': 0.9848}), (49, 0.9896, {'top1': 0.9896}), (50, 0.983, {'top1': 0.983}), (52, 0.9756, {'top1': 0.9756}), (53, 0.903, {'top1': 0.903})]
just computed impact of block 3 . accuracy after removing:  0.9908
removed block 3 current accuracy 0.9908 loss from initial  0.009199999999999986
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(1, 0.9744, {'top1': 0.9744}), (2, 0.9496, {'top1': 0.9496}), (4, 0.9412, {'top1': 0.9412}), (7, 0.975, {'top1': 0.975}), (8, 0.9716, {'top1': 0.9716}), (9, 0.946, {'top1': 0.946}), (10, 0.9406, {'top1': 0.9406}), (12, 0.9696, {'top1': 0.9696}), (14, 0.979, {'top1': 0.979}), (15, 0.9746, {'top1': 0.9746}), (16, 0.9772, {'top1': 0.9772}), (17, 0.9528, {'top1': 0.9528}), (18, 0.5186, {'top1': 0.5186}), (23, 0.9854, {'top1': 0.9854}), (26, 0.9838, {'top1': 0.9838}), (31, 0.9802, {'top1': 0.9802}), (34, 0.984, {'top1': 0.984}), (36, 0.4932, {'top1': 0.4932}), (39, 0.9822, {'top1': 0.9822}), (41, 0.9822, {'top1': 0.9822}), (42, 0.9756, {'top1': 0.9756}), (43, 0.981, {'top1': 0.981}), (44, 0.979, {'top1': 0.979}), (45, 0.9848, {'top1': 0.9848}), (46, 0.9794, {'top1': 0.9794}), (47, 0.9798, {'top1': 0.9798}), (49, 0.9838, {'top1': 0.9838}), (50, 0.9752, {'top1': 0.9752}), (52, 0.974, {'top1': 0.974}), (53, 0.8886, {'top1': 0.8886})]
just computed impact of block 23 . accuracy after removing:  0.9854
removed block 23 current accuracy 0.9854 loss from initial  0.014599999999999946
since last training loss: 0.0119999999999999 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(1, 0.966, {'top1': 0.966}), (2, 0.94, {'top1': 0.94}), (4, 0.9218, {'top1': 0.9218}), (7, 0.969, {'top1': 0.969}), (8, 0.965, {'top1': 0.965}), (9, 0.9248, {'top1': 0.9248}), (10, 0.9212, {'top1': 0.9212}), (12, 0.9534, {'top1': 0.9534}), (14, 0.9704, {'top1': 0.9704}), (15, 0.9648, {'top1': 0.9648}), (16, 0.9702, {'top1': 0.9702}), (17, 0.939, {'top1': 0.939}), (18, 0.4334, {'top1': 0.4334}), (26, 0.9668, {'top1': 0.9668}), (31, 0.9702, {'top1': 0.9702}), (34, 0.9736, {'top1': 0.9736}), (36, 0.4084, {'top1': 0.4084}), (39, 0.9746, {'top1': 0.9746}), (41, 0.97, {'top1': 0.97}), (42, 0.9688, {'top1': 0.9688}), (43, 0.975, {'top1': 0.975}), (44, 0.9698, {'top1': 0.9698}), (45, 0.9728, {'top1': 0.9728}), (46, 0.97, {'top1': 0.97}), (47, 0.9696, {'top1': 0.9696}), (49, 0.9764, {'top1': 0.9764}), (50, 0.9704, {'top1': 0.9704}), (52, 0.9606, {'top1': 0.9606}), (53, 0.8688, {'top1': 0.8688})]
just computed impact of block 49 . accuracy after removing:  0.9764
removed block 49 current accuracy 0.9764 loss from initial  0.023599999999999954
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(1, 0.9484, {'top1': 0.9484}), (2, 0.9128, {'top1': 0.9128}), (4, 0.894, {'top1': 0.894}), (7, 0.9488, {'top1': 0.9488}), (8, 0.9478, {'top1': 0.9478}), (9, 0.8952, {'top1': 0.8952}), (10, 0.8998, {'top1': 0.8998}), (12, 0.9328, {'top1': 0.9328}), (14, 0.954, {'top1': 0.954}), (15, 0.9486, {'top1': 0.9486}), (16, 0.9538, {'top1': 0.9538}), (17, 0.9214, {'top1': 0.9214}), (18, 0.4456, {'top1': 0.4456}), (26, 0.9564, {'top1': 0.9564}), (31, 0.9588, {'top1': 0.9588}), (34, 0.9594, {'top1': 0.9594}), (36, 0.4208, {'top1': 0.4208}), (39, 0.9636, {'top1': 0.9636}), (41, 0.9586, {'top1': 0.9586}), (42, 0.9496, {'top1': 0.9496}), (43, 0.9572, {'top1': 0.9572}), (44, 0.9554, {'top1': 0.9554}), (45, 0.9598, {'top1': 0.9598}), (46, 0.9412, {'top1': 0.9412}), (47, 0.937, {'top1': 0.937}), (50, 0.9424, {'top1': 0.9424}), (52, 0.9428, {'top1': 0.9428}), (53, 0.8188, {'top1': 0.8188})]
just computed impact of block 39 . accuracy after removing:  0.9636
removed block 39 current accuracy 0.9636 loss from initial  0.03639999999999999
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(1, 0.929, {'top1': 0.929}), (2, 0.8944, {'top1': 0.8944}), (4, 0.864, {'top1': 0.864}), (7, 0.9336, {'top1': 0.9336}), (8, 0.9306, {'top1': 0.9306}), (9, 0.864, {'top1': 0.864}), (10, 0.8652, {'top1': 0.8652}), (12, 0.9126, {'top1': 0.9126}), (14, 0.9356, {'top1': 0.9356}), (15, 0.9308, {'top1': 0.9308}), (16, 0.9306, {'top1': 0.9306}), (17, 0.9028, {'top1': 0.9028}), (18, 0.4176, {'top1': 0.4176}), (26, 0.9378, {'top1': 0.9378}), (31, 0.944, {'top1': 0.944}), (34, 0.9406, {'top1': 0.9406}), (36, 0.409, {'top1': 0.409}), (41, 0.9344, {'top1': 0.9344}), (42, 0.9236, {'top1': 0.9236}), (43, 0.9364, {'top1': 0.9364}), (44, 0.929, {'top1': 0.929}), (45, 0.94, {'top1': 0.94}), (46, 0.9206, {'top1': 0.9206}), (47, 0.9206, {'top1': 0.9206}), (50, 0.9276, {'top1': 0.9276}), (52, 0.9186, {'top1': 0.9186}), (53, 0.7678, {'top1': 0.7678})]
just computed impact of block 31 . accuracy after removing:  0.944
removed block 31 current accuracy 0.944 loss from initial  0.05600000000000005
since last training loss: 0.0534 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(1, 0.9048, {'top1': 0.9048}), (2, 0.862, {'top1': 0.862}), (4, 0.8292, {'top1': 0.8292}), (7, 0.9, {'top1': 0.9}), (8, 0.8942, {'top1': 0.8942}), (9, 0.8172, {'top1': 0.8172}), (10, 0.8154, {'top1': 0.8154}), (12, 0.8752, {'top1': 0.8752}), (14, 0.8982, {'top1': 0.8982}), (15, 0.9056, {'top1': 0.9056}), (16, 0.9062, {'top1': 0.9062}), (17, 0.8692, {'top1': 0.8692}), (18, 0.348, {'top1': 0.348}), (26, 0.8998, {'top1': 0.8998}), (34, 0.8976, {'top1': 0.8976}), (36, 0.3516, {'top1': 0.3516}), (41, 0.899, {'top1': 0.899}), (42, 0.8932, {'top1': 0.8932}), (43, 0.913, {'top1': 0.913}), (44, 0.8944, {'top1': 0.8944}), (45, 0.9124, {'top1': 0.9124}), (46, 0.8912, {'top1': 0.8912}), (47, 0.8904, {'top1': 0.8904}), (50, 0.8968, {'top1': 0.8968}), (52, 0.8828, {'top1': 0.8828}), (53, 0.7384, {'top1': 0.7384})]
just computed impact of block 43 . accuracy after removing:  0.913
removed block 43 current accuracy 0.913 loss from initial  0.08699999999999997
since last training loss: 0.08439999999999992 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(1, 0.8708, {'top1': 0.8708}), (2, 0.8306, {'top1': 0.8306}), (4, 0.787, {'top1': 0.787}), (7, 0.8642, {'top1': 0.8642}), (8, 0.8446, {'top1': 0.8446}), (9, 0.7896, {'top1': 0.7896}), (10, 0.7748, {'top1': 0.7748}), (12, 0.8436, {'top1': 0.8436}), (14, 0.8724, {'top1': 0.8724}), (15, 0.8846, {'top1': 0.8846}), (16, 0.8746, {'top1': 0.8746}), (17, 0.839, {'top1': 0.839}), (18, 0.2746, {'top1': 0.2746}), (26, 0.8696, {'top1': 0.8696}), (34, 0.856, {'top1': 0.856}), (36, 0.3022, {'top1': 0.3022}), (41, 0.8652, {'top1': 0.8652}), (42, 0.8488, {'top1': 0.8488}), (44, 0.8538, {'top1': 0.8538}), (45, 0.8812, {'top1': 0.8812}), (46, 0.8556, {'top1': 0.8556}), (47, 0.8568, {'top1': 0.8568}), (50, 0.8598, {'top1': 0.8598}), (52, 0.8586, {'top1': 0.8586}), (53, 0.6806, {'top1': 0.6806})]
just computed impact of block 15 . accuracy after removing:  0.8846
removed block 15 current accuracy 0.8846 loss from initial  0.11539999999999995
since last training loss: 0.1127999999999999 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(1, 0.8404, {'top1': 0.8404}), (2, 0.7912, {'top1': 0.7912}), (4, 0.7414, {'top1': 0.7414}), (7, 0.8372, {'top1': 0.8372}), (8, 0.8366, {'top1': 0.8366}), (9, 0.7488, {'top1': 0.7488}), (10, 0.7446, {'top1': 0.7446}), (12, 0.7828, {'top1': 0.7828}), (14, 0.8192, {'top1': 0.8192}), (16, 0.8104, {'top1': 0.8104}), (17, 0.6762, {'top1': 0.6762}), (18, 0.272, {'top1': 0.272}), (26, 0.8404, {'top1': 0.8404}), (34, 0.835, {'top1': 0.835}), (36, 0.2932, {'top1': 0.2932}), (41, 0.8392, {'top1': 0.8392}), (42, 0.8208, {'top1': 0.8208}), (44, 0.8244, {'top1': 0.8244}), (45, 0.837, {'top1': 0.837}), (46, 0.826, {'top1': 0.826}), (47, 0.8244, {'top1': 0.8244}), (50, 0.8296, {'top1': 0.8296}), (52, 0.8198, {'top1': 0.8198}), (53, 0.6588, {'top1': 0.6588})]
just computed impact of block 1 . accuracy after removing:  0.8404
removed block 1 current accuracy 0.8404 loss from initial  0.15959999999999996
since last training loss: 0.15699999999999992 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(2, 0.6936, {'top1': 0.6936}), (4, 0.6458, {'top1': 0.6458}), (7, 0.7552, {'top1': 0.7552}), (8, 0.7832, {'top1': 0.7832}), (9, 0.6772, {'top1': 0.6772}), (10, 0.684, {'top1': 0.684}), (12, 0.7252, {'top1': 0.7252}), (14, 0.7654, {'top1': 0.7654}), (16, 0.7576, {'top1': 0.7576}), (17, 0.6322, {'top1': 0.6322}), (18, 0.2618, {'top1': 0.2618}), (26, 0.7852, {'top1': 0.7852}), (34, 0.7998, {'top1': 0.7998}), (36, 0.285, {'top1': 0.285}), (41, 0.7934, {'top1': 0.7934}), (42, 0.7618, {'top1': 0.7618}), (44, 0.7638, {'top1': 0.7638}), (45, 0.7842, {'top1': 0.7842}), (46, 0.7658, {'top1': 0.7658}), (47, 0.7628, {'top1': 0.7628}), (50, 0.7688, {'top1': 0.7688}), (52, 0.787, {'top1': 0.787}), (53, 0.597, {'top1': 0.597})]
just computed impact of block 34 . accuracy after removing:  0.7998
removed block 34 current accuracy 0.7998 loss from initial  0.20020000000000004
since last training loss: 0.1976 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(2, 0.674, {'top1': 0.674}), (4, 0.6168, {'top1': 0.6168}), (7, 0.7228, {'top1': 0.7228}), (8, 0.7308, {'top1': 0.7308}), (9, 0.618, {'top1': 0.618}), (10, 0.6396, {'top1': 0.6396}), (12, 0.682, {'top1': 0.682}), (14, 0.7252, {'top1': 0.7252}), (16, 0.7088, {'top1': 0.7088}), (17, 0.575, {'top1': 0.575}), (18, 0.2402, {'top1': 0.2402}), (26, 0.7268, {'top1': 0.7268}), (36, 0.2238, {'top1': 0.2238}), (41, 0.7312, {'top1': 0.7312}), (42, 0.708, {'top1': 0.708}), (44, 0.7186, {'top1': 0.7186}), (45, 0.7416, {'top1': 0.7416}), (46, 0.7198, {'top1': 0.7198}), (47, 0.7062, {'top1': 0.7062}), (50, 0.7302, {'top1': 0.7302}), (52, 0.7424, {'top1': 0.7424}), (53, 0.5652, {'top1': 0.5652})]
just computed impact of block 52 . accuracy after removing:  0.7424
removed block 52 current accuracy 0.7424 loss from initial  0.25760000000000005
since last training loss: 0.255 threshold 999.0 training needed False
start iteration 33
(cache recomputed) Accuracy log [(2, 0.6538, {'top1': 0.6538}), (4, 0.6022, {'top1': 0.6022}), (7, 0.6922, {'top1': 0.6922}), (8, 0.6952, {'top1': 0.6952}), (9, 0.557, {'top1': 0.557}), (10, 0.571, {'top1': 0.571}), (12, 0.6298, {'top1': 0.6298}), (14, 0.6872, {'top1': 0.6872}), (16, 0.6658, {'top1': 0.6658}), (17, 0.5558, {'top1': 0.5558}), (18, 0.1928, {'top1': 0.1928}), (26, 0.673, {'top1': 0.673}), (36, 0.2514, {'top1': 0.2514}), (41, 0.677, {'top1': 0.677}), (42, 0.677, {'top1': 0.677}), (44, 0.6842, {'top1': 0.6842}), (45, 0.6894, {'top1': 0.6894}), (46, 0.663, {'top1': 0.663}), (47, 0.6694, {'top1': 0.6694}), (50, 0.6828, {'top1': 0.6828}), (53, 0.4554, {'top1': 0.4554})]
just computed impact of block 8 . accuracy after removing:  0.6952
removed block 8 current accuracy 0.6952 loss from initial  0.30479999999999996
since last training loss: 0.3021999999999999 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(2, 0.572, {'top1': 0.572}), (4, 0.4844, {'top1': 0.4844}), (7, 0.521, {'top1': 0.521}), (9, 0.4814, {'top1': 0.4814}), (10, 0.509, {'top1': 0.509}), (12, 0.5742, {'top1': 0.5742}), (14, 0.6228, {'top1': 0.6228}), (16, 0.5514, {'top1': 0.5514}), (17, 0.4342, {'top1': 0.4342}), (18, 0.2002, {'top1': 0.2002}), (26, 0.6304, {'top1': 0.6304}), (36, 0.2226, {'top1': 0.2226}), (41, 0.617, {'top1': 0.617}), (42, 0.6206, {'top1': 0.6206}), (44, 0.6186, {'top1': 0.6186}), (45, 0.6554, {'top1': 0.6554}), (46, 0.5984, {'top1': 0.5984}), (47, 0.614, {'top1': 0.614}), (50, 0.6242, {'top1': 0.6242}), (53, 0.3474, {'top1': 0.3474})]
just computed impact of block 45 . accuracy after removing:  0.6554
removed block 45 current accuracy 0.6554 loss from initial  0.3446
since last training loss: 0.34199999999999997 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(2, 0.5236, {'top1': 0.5236}), (4, 0.4556, {'top1': 0.4556}), (7, 0.4994, {'top1': 0.4994}), (9, 0.4446, {'top1': 0.4446}), (10, 0.4648, {'top1': 0.4648}), (12, 0.5376, {'top1': 0.5376}), (14, 0.5868, {'top1': 0.5868}), (16, 0.5302, {'top1': 0.5302}), (17, 0.4214, {'top1': 0.4214}), (18, 0.179, {'top1': 0.179}), (26, 0.5966, {'top1': 0.5966}), (36, 0.2692, {'top1': 0.2692}), (41, 0.572, {'top1': 0.572}), (42, 0.5824, {'top1': 0.5824}), (44, 0.583, {'top1': 0.583}), (46, 0.5584, {'top1': 0.5584}), (47, 0.5658, {'top1': 0.5658}), (50, 0.5816, {'top1': 0.5816}), (53, 0.3132, {'top1': 0.3132})]
just computed impact of block 26 . accuracy after removing:  0.5966
removed block 26 current accuracy 0.5966 loss from initial  0.4034
since last training loss: 0.40079999999999993 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(2, 0.4668, {'top1': 0.4668}), (4, 0.4112, {'top1': 0.4112}), (7, 0.447, {'top1': 0.447}), (9, 0.4034, {'top1': 0.4034}), (10, 0.4262, {'top1': 0.4262}), (12, 0.4818, {'top1': 0.4818}), (14, 0.5372, {'top1': 0.5372}), (16, 0.4886, {'top1': 0.4886}), (17, 0.4058, {'top1': 0.4058}), (18, 0.1704, {'top1': 0.1704}), (36, 0.235, {'top1': 0.235}), (41, 0.5088, {'top1': 0.5088}), (42, 0.5232, {'top1': 0.5232}), (44, 0.5386, {'top1': 0.5386}), (46, 0.5136, {'top1': 0.5136}), (47, 0.5124, {'top1': 0.5124}), (50, 0.5198, {'top1': 0.5198}), (53, 0.2822, {'top1': 0.2822})]
just computed impact of block 44 . accuracy after removing:  0.5386
removed block 44 current accuracy 0.5386 loss from initial  0.46140000000000003
since last training loss: 0.4588 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(2, 0.4528, {'top1': 0.4528}), (4, 0.4004, {'top1': 0.4004}), (7, 0.4126, {'top1': 0.4126}), (9, 0.3772, {'top1': 0.3772}), (10, 0.4014, {'top1': 0.4014}), (12, 0.4376, {'top1': 0.4376}), (14, 0.4934, {'top1': 0.4934}), (16, 0.4336, {'top1': 0.4336}), (17, 0.3684, {'top1': 0.3684}), (18, 0.1658, {'top1': 0.1658}), (36, 0.237, {'top1': 0.237}), (41, 0.467, {'top1': 0.467}), (42, 0.4822, {'top1': 0.4822}), (46, 0.4538, {'top1': 0.4538}), (47, 0.4622, {'top1': 0.4622}), (50, 0.4768, {'top1': 0.4768}), (53, 0.2696, {'top1': 0.2696})]
just computed impact of block 14 . accuracy after removing:  0.4934
removed block 14 current accuracy 0.4934 loss from initial  0.5065999999999999
since last training loss: 0.504 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(2, 0.4108, {'top1': 0.4108}), (4, 0.3604, {'top1': 0.3604}), (7, 0.3728, {'top1': 0.3728}), (9, 0.3412, {'top1': 0.3412}), (10, 0.3596, {'top1': 0.3596}), (12, 0.3814, {'top1': 0.3814}), (16, 0.3598, {'top1': 0.3598}), (17, 0.2616, {'top1': 0.2616}), (18, 0.1574, {'top1': 0.1574}), (36, 0.2268, {'top1': 0.2268}), (41, 0.4256, {'top1': 0.4256}), (42, 0.4326, {'top1': 0.4326}), (46, 0.4052, {'top1': 0.4052}), (47, 0.43, {'top1': 0.43}), (50, 0.4506, {'top1': 0.4506}), (53, 0.2462, {'top1': 0.2462})]
just computed impact of block 50 . accuracy after removing:  0.4506
removed block 50 current accuracy 0.4506 loss from initial  0.5494
since last training loss: 0.5468 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(2, 0.392, {'top1': 0.392}), (4, 0.3478, {'top1': 0.3478}), (7, 0.346, {'top1': 0.346}), (9, 0.313, {'top1': 0.313}), (10, 0.3348, {'top1': 0.3348}), (12, 0.3452, {'top1': 0.3452}), (16, 0.3342, {'top1': 0.3342}), (17, 0.2628, {'top1': 0.2628}), (18, 0.1534, {'top1': 0.1534}), (36, 0.1922, {'top1': 0.1922}), (41, 0.3802, {'top1': 0.3802}), (42, 0.3992, {'top1': 0.3992}), (46, 0.367, {'top1': 0.367}), (47, 0.3746, {'top1': 0.3746}), (53, 0.2518, {'top1': 0.2518})]
just computed impact of block 42 . accuracy after removing:  0.3992
removed block 42 current accuracy 0.3992 loss from initial  0.6008
since last training loss: 0.5982 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(2, 0.3472, {'top1': 0.3472}), (4, 0.2996, {'top1': 0.2996}), (7, 0.3004, {'top1': 0.3004}), (9, 0.2746, {'top1': 0.2746}), (10, 0.2858, {'top1': 0.2858}), (12, 0.3036, {'top1': 0.3036}), (16, 0.304, {'top1': 0.304}), (17, 0.2286, {'top1': 0.2286}), (18, 0.1574, {'top1': 0.1574}), (36, 0.2642, {'top1': 0.2642}), (41, 0.3338, {'top1': 0.3338}), (46, 0.3354, {'top1': 0.3354}), (47, 0.3434, {'top1': 0.3434}), (53, 0.2234, {'top1': 0.2234})]
just computed impact of block 2 . accuracy after removing:  0.3472
removed block 2 current accuracy 0.3472 loss from initial  0.6528
since last training loss: 0.6501999999999999 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(4, 0.2524, {'top1': 0.2524}), (7, 0.2494, {'top1': 0.2494}), (9, 0.302, {'top1': 0.302}), (10, 0.2766, {'top1': 0.2766}), (12, 0.3096, {'top1': 0.3096}), (16, 0.2332, {'top1': 0.2332}), (17, 0.1616, {'top1': 0.1616}), (18, 0.1502, {'top1': 0.1502}), (36, 0.2356, {'top1': 0.2356}), (41, 0.2846, {'top1': 0.2846}), (46, 0.2928, {'top1': 0.2928}), (47, 0.3172, {'top1': 0.3172}), (53, 0.1902, {'top1': 0.1902})]
just computed impact of block 47 . accuracy after removing:  0.3172
removed block 47 current accuracy 0.3172 loss from initial  0.6828000000000001
since last training loss: 0.6801999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(4, 0.265, {'top1': 0.265}), (7, 0.2492, {'top1': 0.2492}), (9, 0.2848, {'top1': 0.2848}), (10, 0.286, {'top1': 0.286}), (12, 0.2872, {'top1': 0.2872}), (16, 0.2446, {'top1': 0.2446}), (17, 0.1706, {'top1': 0.1706}), (18, 0.1632, {'top1': 0.1632}), (36, 0.236, {'top1': 0.236}), (41, 0.2544, {'top1': 0.2544}), (46, 0.2682, {'top1': 0.2682}), (53, 0.2242, {'top1': 0.2242})]
just computed impact of block 12 . accuracy after removing:  0.2872
removed block 12 current accuracy 0.2872 loss from initial  0.7128
since last training loss: 0.7101999999999999 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(4, 0.2334, {'top1': 0.2334}), (7, 0.2266, {'top1': 0.2266}), (9, 0.1998, {'top1': 0.1998}), (10, 0.2266, {'top1': 0.2266}), (16, 0.242, {'top1': 0.242}), (17, 0.1514, {'top1': 0.1514}), (18, 0.1506, {'top1': 0.1506}), (36, 0.218, {'top1': 0.218}), (41, 0.2302, {'top1': 0.2302}), (46, 0.2436, {'top1': 0.2436}), (53, 0.224, {'top1': 0.224})]
just computed impact of block 46 . accuracy after removing:  0.2436
removed block 46 current accuracy 0.2436 loss from initial  0.7564
since last training loss: 0.7537999999999999 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(4, 0.1812, {'top1': 0.1812}), (7, 0.1872, {'top1': 0.1872}), (9, 0.1828, {'top1': 0.1828}), (10, 0.1958, {'top1': 0.1958}), (16, 0.2378, {'top1': 0.2378}), (17, 0.17, {'top1': 0.17}), (18, 0.1758, {'top1': 0.1758}), (36, 0.1926, {'top1': 0.1926}), (41, 0.1948, {'top1': 0.1948}), (53, 0.2108, {'top1': 0.2108})]
just computed impact of block 16 . accuracy after removing:  0.2378
removed block 16 current accuracy 0.2378 loss from initial  0.7622
training start
training epoch 0 val accuracy 0.7516 topk_dict {'top1': 0.7516} is_best True lr [0.001]
training epoch 1 val accuracy 0.7888 topk_dict {'top1': 0.7888} is_best True lr [0.001]
training epoch 2 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best True lr [0.001]
training epoch 3 val accuracy 0.814 topk_dict {'top1': 0.814} is_best True lr [0.001]
training epoch 4 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 5 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.001]
training epoch 6 val accuracy 0.85 topk_dict {'top1': 0.85} is_best True lr [0.001]
training epoch 7 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.001]
training epoch 8 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.001]
training epoch 9 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best True lr [0.001]
training epoch 10 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.001]
training epoch 11 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.001]
training epoch 12 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.001]
training epoch 13 val accuracy 0.873 topk_dict {'top1': 0.873} is_best True lr [0.001]
training epoch 14 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.001]
training epoch 15 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.001]
training epoch 16 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.001]
training epoch 17 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.001]
training epoch 18 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.001]
training epoch 19 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best True lr [0.001]
training epoch 20 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.001]
training epoch 21 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.001]
training epoch 22 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.001]
training epoch 23 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.001]
training epoch 24 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 25 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 26 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.001]
training epoch 27 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 28 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 29 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.001]
training epoch 30 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 31 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 32 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 33 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 34 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.001]
training epoch 35 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 36 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.001]
training epoch 37 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 38 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.001]
training epoch 39 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 40 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.001]
training epoch 41 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.001]
training epoch 42 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.001]
training epoch 43 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.001]
training epoch 44 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 45 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.001]
training epoch 46 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 47 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.001]
training epoch 48 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 49 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.904800)
finished training. finished 50 epochs. accuracy 0.9048 topk_dict {'top1': 0.9048}
