start iteration 0
[activation diff]: block to remove picked: 35, with score 0.014275. All blocks and scores: [(35, 0.014274864224717021), (34, 0.014493348891846836), (33, 0.015328856417909265), (32, 0.01540135475806892), (27, 0.016854834277182817), (24, 0.01739622838795185), (26, 0.017841696739196777), (31, 0.017852150136604905), (23, 0.018011785112321377), (37, 0.018020291812717915), (28, 0.018068779725581408), (20, 0.01833631587214768), (25, 0.018579797353595495), (30, 0.018911650637164712), (29, 0.019017092185094953), (22, 0.019087886437773705), (38, 0.019831778248772025), (21, 0.020666001830250025), (40, 0.020699823275208473), (41, 0.02083682338707149), (39, 0.021874285070225596), (42, 0.023939984384924173), (44, 0.027291724225506186), (43, 0.027380846440792084), (53, 0.028202868532389402), (19, 0.028207605006173253), (52, 0.02841529855504632), (51, 0.029680656967684627), (45, 0.030162296490743756), (46, 0.03169302945025265), (50, 0.03270378150045872), (49, 0.03325699083507061), (47, 0.03593745548278093), (3, 0.03641833085566759), (2, 0.03660873416811228), (48, 0.03829950327053666), (6, 0.04146078648045659), (13, 0.04233343247324228), (11, 0.04962976183742285), (14, 0.05005708243697882), (7, 0.05049914959818125), (8, 0.05102512892335653), (15, 0.052085168194025755), (10, 0.05232794210314751), (16, 0.05589384539052844), (12, 0.05712253460660577), (0, 0.05717562837526202), (9, 0.06140707805752754), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154567420483), (18, 0.15011721849441528), (36, 0.23893354646861553)]
computing accuracy for after removing block 35 . block score: 0.014274864224717021
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 34, with score 0.014493. All blocks and scores: [(34, 0.014493348426185548), (33, 0.015328856417909265), (32, 0.015401354990899563), (37, 0.01668984047137201), (27, 0.016854834044352174), (24, 0.01739622838795185), (26, 0.01784169697202742), (31, 0.01785215036943555), (23, 0.01801178534515202), (28, 0.018068780191242695), (20, 0.018336316337808967), (38, 0.01837015966884792), (25, 0.018579797353595495), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (40, 0.019572118297219276), (41, 0.01961697917431593), (39, 0.020275143440812826), (21, 0.020666001830250025), (42, 0.022649952908977866), (43, 0.025927709881216288), (44, 0.026192617136985064), (53, 0.02760886331088841), (52, 0.02764224517159164), (19, 0.028207605006173253), (51, 0.028980919858440757), (45, 0.02902725455351174), (46, 0.030406811740249395), (50, 0.03191784326918423), (49, 0.032416850328445435), (47, 0.034735485911369324), (3, 0.036418331786990166), (2, 0.03660873416811228), (48, 0.03714345162734389), (6, 0.04146078648045659), (13, 0.04233343154191971), (11, 0.04962976323440671), (14, 0.05005708243697882), (7, 0.0504991514608264), (8, 0.051025130320340395), (15, 0.05208516726270318), (10, 0.05232794163748622), (16, 0.05589384399354458), (12, 0.05712253646925092), (0, 0.05717562744393945), (9, 0.06140707852318883), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764383465052), (17, 0.0842915466055274), (18, 0.15011722035706043), (36, 0.22269113920629025)]
computing accuracy for after removing block 34 . block score: 0.014493348426185548
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.015329. All blocks and scores: [(33, 0.015328856185078621), (32, 0.015401354990899563), (37, 0.01564904337283224), (27, 0.01685483381152153), (38, 0.017188325058668852), (24, 0.017396227922290564), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.01806877995841205), (20, 0.01833631587214768), (25, 0.018579797353595495), (41, 0.01863350300118327), (40, 0.01864513591863215), (30, 0.018911650869995356), (39, 0.018983179237693548), (29, 0.019017092417925596), (22, 0.01908788620494306), (21, 0.02066600206308067), (42, 0.021567409625276923), (43, 0.02474153903312981), (44, 0.025241218507289886), (52, 0.02675225562416017), (53, 0.02690034988336265), (45, 0.02801583521068096), (51, 0.02813188941217959), (19, 0.028207605704665184), (46, 0.029172033304348588), (50, 0.03104190109297633), (49, 0.03151613497175276), (47, 0.033557758666574955), (48, 0.03598395921289921), (3, 0.036418331786990166), (2, 0.036608734633773565), (6, 0.04146078694611788), (13, 0.042333433870226145), (11, 0.049629763700068), (14, 0.050057082902640104), (7, 0.05049914959818125), (8, 0.051025128457695246), (15, 0.05208516959100962), (10, 0.05232794024050236), (16, 0.055893844459205866), (12, 0.05712253414094448), (0, 0.05717562744393945), (9, 0.06140707898885012), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722408235073), (36, 0.20549122244119644)]
computing accuracy for after removing block 33 . block score: 0.015328856185078621
removed block 33 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 37, with score 0.014727. All blocks and scores: [(37, 0.014727167319506407), (32, 0.015401355107314885), (38, 0.016087534138932824), (27, 0.016854834044352174), (24, 0.017396228620782495), (41, 0.017636816017329693), (39, 0.017656564246863127), (40, 0.01771946670487523), (26, 0.017841696739196777), (31, 0.01785214990377426), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.01833631587214768), (25, 0.01857979712076485), (30, 0.018911651102826), (29, 0.019017092417925596), (22, 0.01908788620494306), (42, 0.02041433728300035), (21, 0.020666001830250025), (43, 0.023449430475011468), (44, 0.02405423205345869), (52, 0.025544947711750865), (53, 0.02587294322438538), (45, 0.02667240845039487), (51, 0.0270409204531461), (46, 0.027673481265082955), (19, 0.028207605704665184), (50, 0.029852008214220405), (49, 0.03029270237311721), (47, 0.03202386596240103), (48, 0.03438834426924586), (3, 0.03641833085566759), (2, 0.03660873509943485), (6, 0.04146078694611788), (13, 0.04233343154191971), (11, 0.04962976463139057), (14, 0.05005708243697882), (7, 0.05049915052950382), (8, 0.05102512892335653), (15, 0.05208516912534833), (10, 0.05232794163748622), (16, 0.05589384399354458), (12, 0.05712253414094448), (0, 0.05717562697827816), (9, 0.06140707898885012), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764104068279), (17, 0.08429154567420483), (18, 0.15011722408235073), (36, 0.19365961477160454)]
computing accuracy for after removing block 37 . block score: 0.014727167319506407
removed block 37 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 38, with score 0.015322. All blocks and scores: [(38, 0.01532166008837521), (32, 0.015401354874484241), (41, 0.015430084662511945), (40, 0.015811879187822342), (39, 0.01603815332055092), (27, 0.016854834044352174), (24, 0.01739622838795185), (42, 0.017457409761846066), (26, 0.017841696506366134), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.018068780656903982), (20, 0.01833631587214768), (25, 0.018579797353595495), (30, 0.018911651335656643), (29, 0.019017092185094953), (22, 0.019087886437773705), (43, 0.019953368231654167), (44, 0.020435143262147903), (21, 0.020666001830250025), (52, 0.021591539727523923), (53, 0.022010742453858256), (45, 0.02262773923575878), (51, 0.022835362004116178), (46, 0.0230266316793859), (50, 0.025466162711381912), (49, 0.025596699211746454), (47, 0.026748374570161104), (19, 0.02820760547183454), (48, 0.028763408306986094), (3, 0.03641833085566759), (2, 0.036608734633773565), (6, 0.04146078694611788), (13, 0.04233343247324228), (11, 0.04962976323440671), (14, 0.05005708243697882), (7, 0.050499151926487684), (8, 0.05102512985467911), (15, 0.052085168194025755), (10, 0.052327940706163645), (16, 0.05589384399354458), (12, 0.05712253460660577), (0, 0.05717562837526202), (9, 0.06140707898885012), (5, 0.06478630285710096), (4, 0.06930218357592821), (1, 0.07571764104068279), (17, 0.0842915466055274), (18, 0.15011722221970558), (36, 0.19365961104631424)]
computing accuracy for after removing block 38 . block score: 0.01532166008837521
removed block 38 current accuracy 0.94 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 41, with score 0.013861. All blocks and scores: [(41, 0.013860961073078215), (40, 0.01467142766341567), (42, 0.01534125569742173), (32, 0.015401354990899563), (39, 0.015461977920494974), (27, 0.016854833578690886), (24, 0.017396228620782495), (43, 0.017514181789010763), (44, 0.017543905647471547), (26, 0.017841696506366134), (31, 0.017852150136604905), (23, 0.01801178464666009), (28, 0.01806877995841205), (20, 0.018336316337808967), (52, 0.01834895694628358), (25, 0.01857979758642614), (53, 0.018839581636711955), (30, 0.018911650637164712), (29, 0.019017092185094953), (22, 0.019087886437773705), (45, 0.019300540909171104), (46, 0.01930436654947698), (51, 0.019394941395148635), (21, 0.020666001830250025), (49, 0.02167896879836917), (50, 0.02184727438725531), (47, 0.022476088255643845), (48, 0.024215633748099208), (19, 0.028207605704665184), (3, 0.03641833085566759), (2, 0.036608734633773565), (6, 0.041460785549134016), (13, 0.042333432007580996), (11, 0.04962976463139057), (14, 0.05005708243697882), (7, 0.05049914913251996), (8, 0.05102512938901782), (15, 0.05208516959100962), (10, 0.052327940706163645), (16, 0.05589384352788329), (12, 0.057122533675283194), (0, 0.057175627909600735), (9, 0.06140707898885012), (5, 0.06478630285710096), (4, 0.06930218543857336), (1, 0.07571764290332794), (17, 0.08429154846817255), (18, 0.15011722221970558), (36, 0.19365961477160454)]
computing accuracy for after removing block 41 . block score: 0.013860961073078215
removed block 41 current accuracy 0.937 loss from initial  0.01739999999999997
training start
training epoch 0 val accuracy 0.7054 topk_dict {'top1': 0.7054} is_best False lr [0.1]
training epoch 1 val accuracy 0.768 topk_dict {'top1': 0.768} is_best False lr [0.1]
training epoch 2 val accuracy 0.7774 topk_dict {'top1': 0.7774} is_best False lr [0.1]
training epoch 3 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 4 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 5 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best False lr [0.1]
training epoch 6 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 7 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 8 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 9 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 10 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.940400)
finished training. finished 50 epochs. accuracy 0.9404 topk_dict {'top1': 0.9404}
start iteration 6
[activation diff]: block to remove picked: 53, with score 0.027532. All blocks and scores: [(53, 0.027532212901860476), (24, 0.03658037493005395), (32, 0.03664591442793608), (52, 0.037283539306372404), (22, 0.03945625992491841), (20, 0.040125906467437744), (30, 0.04017464071512222), (26, 0.04393223859369755), (50, 0.04411253286525607), (23, 0.04451363533735275), (25, 0.04605273716151714), (51, 0.04699441371485591), (31, 0.05522325495257974), (19, 0.05720414128154516), (21, 0.05791338440030813), (2, 0.058317404706031084), (49, 0.058806583285331726), (29, 0.06019938224926591), (6, 0.06322691962122917), (28, 0.06404870934784412), (27, 0.068088517524302), (43, 0.07146378606557846), (11, 0.07407343201339245), (40, 0.07696010451763868), (42, 0.07865091040730476), (14, 0.08508367836475372), (45, 0.08555776160210371), (0, 0.08693813253194094), (44, 0.08697094861418009), (46, 0.09010229539126158), (39, 0.09089286159723997), (13, 0.09277724754065275), (48, 0.0945369191467762), (7, 0.0963448341935873), (47, 0.09989017713814974), (3, 0.1046959962695837), (15, 0.11193664371967316), (16, 0.12486673705279827), (1, 0.12725490052253008), (10, 0.13127509504556656), (9, 0.13581936061382294), (12, 0.14029237441718578), (8, 0.14564503729343414), (4, 0.17011712864041328), (5, 0.1702718697488308), (17, 0.21819256618618965), (18, 0.5548801049590111), (36, 0.6387950330972672)]
computing accuracy for after removing block 53 . block score: 0.027532212901860476
removed block 53 current accuracy 0.9374 loss from initial  0.017000000000000015
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 24, with score 0.036580. All blocks and scores: [(24, 0.03658037353307009), (32, 0.03664591396227479), (52, 0.03728353977203369), (22, 0.0394562603905797), (20, 0.04012590693309903), (30, 0.040174638852477074), (26, 0.04393223952502012), (50, 0.044112532399594784), (23, 0.04451363626867533), (25, 0.04605273809283972), (51, 0.04699441185221076), (31, 0.0552232563495636), (19, 0.05720414221286774), (21, 0.05791338346898556), (2, 0.058317406103014946), (49, 0.05880658468231559), (29, 0.06019938085228205), (6, 0.06322691775858402), (28, 0.0640487102791667), (27, 0.06808851845562458), (43, 0.07146378420293331), (11, 0.0740734338760376), (40, 0.07696010358631611), (42, 0.07865091040730476), (14, 0.08508367836475372), (45, 0.08555776253342628), (0, 0.08693813253194094), (44, 0.08697095140814781), (46, 0.09010229632258415), (39, 0.0908928606659174), (13, 0.09277724474668503), (48, 0.09453692007809877), (7, 0.09634483605623245), (47, 0.09989017806947231), (3, 0.1046959962695837), (15, 0.11193664278835058), (16, 0.12486673519015312), (1, 0.12725489679723978), (10, 0.13127509132027626), (9, 0.13581936061382294), (12, 0.14029237069189548), (8, 0.145645035430789), (4, 0.17011713050305843), (5, 0.1702718697488308), (17, 0.21819256618618965), (18, 0.5548800900578499), (36, 0.6387950330972672)]
computing accuracy for after removing block 24 . block score: 0.03658037353307009
removed block 24 current accuracy 0.9334 loss from initial  0.02100000000000002
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.034663. All blocks and scores: [(32, 0.0346630634739995), (52, 0.036179432179778814), (30, 0.038404174614697695), (22, 0.0394562603905797), (20, 0.040125906467437744), (26, 0.04226691089570522), (50, 0.043233060743659735), (23, 0.04451363626867533), (25, 0.04552887100726366), (51, 0.04591702437028289), (31, 0.052432524506002665), (19, 0.05720414221286774), (21, 0.05791338440030813), (2, 0.05831740656867623), (29, 0.058951258193701506), (49, 0.05908069061115384), (28, 0.061943278182297945), (6, 0.06322691775858402), (27, 0.06623469106853008), (43, 0.06856109760701656), (11, 0.0740734338760376), (40, 0.07475234661251307), (42, 0.07674765307456255), (45, 0.08470255974680185), (14, 0.08508367836475372), (44, 0.08544586505740881), (0, 0.08693813532590866), (39, 0.08696188312023878), (46, 0.08793074823915958), (13, 0.09277724660933018), (48, 0.09322608914226294), (7, 0.09634483139961958), (47, 0.0994292413815856), (3, 0.10469599720090628), (15, 0.11193664371967316), (16, 0.12486673519015312), (1, 0.1272548958659172), (10, 0.13127509132027626), (9, 0.1358193624764681), (12, 0.14029237069189548), (8, 0.145645035430789), (4, 0.17011713050305843), (5, 0.17027187161147594), (17, 0.21819256618618965), (18, 0.5548800900578499), (36, 0.6053055226802826)]
computing accuracy for after removing block 32 . block score: 0.0346630634739995
removed block 32 current accuracy 0.9314 loss from initial  0.02300000000000002
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 52, with score 0.034287. All blocks and scores: [(52, 0.03428683755919337), (30, 0.03840417554602027), (22, 0.03945625992491841), (20, 0.040125907864421606), (50, 0.04107152111828327), (26, 0.04226691136136651), (51, 0.04384067002683878), (23, 0.04451363580301404), (25, 0.04552887100726366), (31, 0.05243252497166395), (19, 0.057204142678529024), (49, 0.057374339550733566), (21, 0.057913383934646845), (2, 0.05831740563735366), (29, 0.05895125865936279), (28, 0.06194327911362052), (6, 0.06322691775858402), (43, 0.06490824092179537), (27, 0.06623469199985266), (40, 0.0705186864361167), (42, 0.07210556790232658), (11, 0.07407343294471502), (45, 0.07990874629467726), (39, 0.08029433060437441), (44, 0.08223950490355492), (46, 0.08473286498337984), (14, 0.08508367836475372), (0, 0.08693813253194094), (48, 0.09076028876006603), (13, 0.0927772456780076), (47, 0.09589887037873268), (7, 0.0963448341935873), (3, 0.10469599347561598), (15, 0.1119366455823183), (16, 0.12486673705279827), (1, 0.12725490052253008), (10, 0.13127509132027626), (9, 0.1358193624764681), (12, 0.14029237255454063), (8, 0.14564504101872444), (4, 0.17011713236570358), (5, 0.1702718697488308), (17, 0.21819256246089935), (18, 0.5548800900578499), (36, 0.5686080157756805)]
computing accuracy for after removing block 52 . block score: 0.03428683755919337
removed block 52 current accuracy 0.93 loss from initial  0.024399999999999977
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 30, with score 0.038404. All blocks and scores: [(30, 0.03840417508035898), (22, 0.0394562603905797), (20, 0.040125906467437744), (50, 0.04107152111828327), (26, 0.042266910430043936), (51, 0.043840669095516205), (23, 0.04451363580301404), (25, 0.04552887054160237), (31, 0.05243252497166395), (19, 0.05720414174720645), (49, 0.05737434048205614), (21, 0.057913383934646845), (2, 0.05831740563735366), (29, 0.058951258193701506), (28, 0.06194327725097537), (6, 0.06322692055255175), (43, 0.06490824185311794), (27, 0.06623469199985266), (40, 0.0705186864361167), (42, 0.07210556790232658), (11, 0.07407343573868275), (45, 0.07990874722599983), (39, 0.08029433060437441), (44, 0.08223950490355492), (46, 0.08473286312073469), (14, 0.0850836792960763), (0, 0.08693813532590866), (48, 0.09076028876006603), (13, 0.0927772456780076), (47, 0.09589887596666813), (7, 0.09634483233094215), (3, 0.10469599533826113), (15, 0.1119366455823183), (16, 0.1248667361214757), (1, 0.12725489865988493), (10, 0.1312750894576311), (9, 0.1358193587511778), (12, 0.14029237255454063), (8, 0.14564503729343414), (4, 0.17011712864041328), (5, 0.1702718697488308), (17, 0.21819256618618965), (18, 0.5548800975084305), (36, 0.5686080083251)]
computing accuracy for after removing block 30 . block score: 0.03840417508035898
removed block 30 current accuracy 0.9278 loss from initial  0.026600000000000068
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 50, with score 0.039114. All blocks and scores: [(50, 0.03911365754902363), (22, 0.0394562603905797), (20, 0.04012590693309903), (51, 0.04114759573712945), (26, 0.04226691136136651), (23, 0.04451363626867533), (25, 0.04552887054160237), (31, 0.051059991121292114), (49, 0.05580372270196676), (19, 0.05720414128154516), (21, 0.05791338440030813), (2, 0.058317406103014946), (29, 0.05895125726237893), (43, 0.061229728162288666), (28, 0.06194327911362052), (6, 0.06322691775858402), (27, 0.06623469199985266), (40, 0.0672477213665843), (42, 0.06806385703384876), (39, 0.07368131540715694), (11, 0.0740734338760376), (45, 0.07500331662595272), (44, 0.07975468225777149), (46, 0.08163908217102289), (14, 0.08508368115872145), (0, 0.08693813439458609), (48, 0.08804258424788713), (13, 0.09277724660933018), (47, 0.09294749423861504), (7, 0.09634483139961958), (3, 0.1046959962695837), (15, 0.11193664371967316), (16, 0.12486673519015312), (1, 0.1272548958659172), (10, 0.1312750931829214), (9, 0.13581936061382294), (12, 0.14029237255454063), (8, 0.1456450391560793), (4, 0.17011713050305843), (5, 0.1702718697488308), (17, 0.21819256618618965), (36, 0.5369248539209366), (18, 0.5548801049590111)]
computing accuracy for after removing block 50 . block score: 0.03911365754902363
removed block 50 current accuracy 0.9224 loss from initial  0.03200000000000003
training start
training epoch 0 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best False lr [0.1]
training epoch 1 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 2 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 5 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 6 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 7 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 8 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 9 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
start iteration 12
[activation diff]: block to remove picked: 22, with score 0.036949. All blocks and scores: [(22, 0.036949435248970985), (26, 0.04534217528998852), (20, 0.04586929176002741), (25, 0.0490372097119689), (23, 0.05060329893603921), (31, 0.054400508757680655), (11, 0.06216722307726741), (19, 0.06264894641935825), (6, 0.06472424138337374), (28, 0.06647654622793198), (21, 0.06836352497339249), (2, 0.07099238503724337), (43, 0.07166836317628622), (0, 0.07439176365733147), (40, 0.07634658925235271), (29, 0.07683052495121956), (42, 0.07764325384050608), (44, 0.08190470468252897), (27, 0.08277015667408705), (45, 0.08293264918029308), (46, 0.08729582279920578), (7, 0.09215220529586077), (51, 0.09260948654264212), (39, 0.09516541101038456), (49, 0.09814932104200125), (14, 0.09824344329535961), (13, 0.10170583240687847), (15, 0.10429889801889658), (3, 0.11098100990056992), (9, 0.12299975659698248), (12, 0.12352677807211876), (8, 0.1257280819118023), (47, 0.1258966363966465), (10, 0.13013752549886703), (1, 0.13287559617310762), (48, 0.13294780626893044), (16, 0.14817259833216667), (5, 0.1663893312215805), (4, 0.17319472692906857), (17, 0.25980715453624725), (18, 0.6076002418994904), (36, 0.6591523662209511)]
computing accuracy for after removing block 22 . block score: 0.036949435248970985
removed block 22 current accuracy 0.9386 loss from initial  0.015800000000000036
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 26, with score 0.044378. All blocks and scores: [(26, 0.04437833372503519), (20, 0.04586929269134998), (25, 0.048659578897058964), (23, 0.05072304978966713), (31, 0.051686675287783146), (11, 0.062167222145944834), (19, 0.06264894641935825), (28, 0.0634226743131876), (6, 0.06472424231469631), (21, 0.06836352497339249), (43, 0.07047451287508011), (2, 0.07099238596856594), (29, 0.0742616904899478), (0, 0.07439176458865404), (40, 0.07557087857276201), (42, 0.0784178962931037), (27, 0.07878970168530941), (44, 0.08174226805567741), (45, 0.08251147903501987), (46, 0.08564652688801289), (7, 0.09215220436453819), (51, 0.09326947946101427), (39, 0.09457814414054155), (49, 0.09818457905203104), (14, 0.09824344050139189), (13, 0.10170583240687847), (15, 0.10429889895021915), (3, 0.11098100990056992), (9, 0.12299975659698248), (12, 0.12352678086608648), (8, 0.12572807911783457), (47, 0.1266275104135275), (10, 0.13013752549886703), (48, 0.13153008930385113), (1, 0.13287559617310762), (16, 0.14817259833216667), (5, 0.16638933308422565), (4, 0.17319472134113312), (17, 0.25980715453624725), (18, 0.6076002568006516), (36, 0.6391317322850227)]
computing accuracy for after removing block 26 . block score: 0.04437833372503519
removed block 26 current accuracy 0.9322 loss from initial  0.022199999999999998
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.045869. All blocks and scores: [(20, 0.04586929269134998), (25, 0.04865958169102669), (23, 0.05072304978966713), (31, 0.052308226469904184), (28, 0.06147080520167947), (11, 0.062167223542928696), (19, 0.06264894548803568), (6, 0.06472424045205116), (43, 0.06738978251814842), (21, 0.06836352404206991), (2, 0.07099238317459822), (29, 0.07134672813117504), (0, 0.07439176365733147), (40, 0.07502319570630789), (42, 0.07621612399816513), (27, 0.07865564431995153), (45, 0.08035331219434738), (44, 0.08170733507722616), (46, 0.08537844009697437), (51, 0.08966838382184505), (7, 0.09215220808982849), (39, 0.09252625238150358), (14, 0.09824343770742416), (49, 0.09913410525768995), (13, 0.10170583240687847), (15, 0.10429889615625143), (3, 0.11098100990056992), (9, 0.12299975473433733), (12, 0.12352677527815104), (47, 0.12488326616585255), (8, 0.1257280819118023), (48, 0.12961721792817116), (10, 0.13013752549886703), (1, 0.13287559617310762), (16, 0.14817260019481182), (5, 0.1663893312215805), (4, 0.17319472320377827), (17, 0.25980715081095695), (18, 0.607600249350071), (36, 0.622122623026371)]
computing accuracy for after removing block 20 . block score: 0.04586929269134998
removed block 20 current accuracy 0.9316 loss from initial  0.022800000000000042
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.047253. All blocks and scores: [(25, 0.04725320730358362), (31, 0.04869436286389828), (23, 0.049456785432994366), (28, 0.057635150384157896), (11, 0.06216722307726741), (19, 0.06264894595369697), (43, 0.06380167603492737), (6, 0.06472423952072859), (29, 0.06509550847113132), (21, 0.0657332893460989), (2, 0.07099238224327564), (40, 0.07205730676651001), (42, 0.07310451101511717), (27, 0.07337085716426373), (0, 0.07439176272600889), (45, 0.07772968430072069), (44, 0.07960536051541567), (46, 0.08342658169567585), (51, 0.08800069987773895), (39, 0.08878220617771149), (7, 0.09215220529586077), (49, 0.09549113176763058), (14, 0.09824344143271446), (13, 0.10170583426952362), (15, 0.10429889801889658), (3, 0.11098100990056992), (47, 0.11959064193069935), (9, 0.1229997593909502), (12, 0.12352677527815104), (8, 0.12572808098047972), (48, 0.12580264825373888), (10, 0.13013752363622189), (1, 0.13287559431046247), (16, 0.14817260019481182), (5, 0.1663893312215805), (4, 0.17319472692906857), (17, 0.25980715453624725), (36, 0.5904636457562447), (18, 0.607600249350071)]
computing accuracy for after removing block 25 . block score: 0.04725320730358362
removed block 25 current accuracy 0.9174 loss from initial  0.03700000000000003
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 31, with score 0.047730. All blocks and scores: [(31, 0.04772990336641669), (23, 0.049456784036010504), (28, 0.05841281823813915), (43, 0.06009982991963625), (29, 0.06213172059506178), (11, 0.06216722447425127), (19, 0.06264894641935825), (6, 0.06472424045205116), (21, 0.0657332893460989), (42, 0.06889974046498537), (40, 0.0693121887743473), (2, 0.07099238410592079), (27, 0.07302539516240358), (45, 0.07305918261408806), (0, 0.07439176365733147), (44, 0.07787606958299875), (46, 0.08131424710154533), (39, 0.08321095444262028), (51, 0.0834275521337986), (7, 0.09215220436453819), (49, 0.09360871743410826), (14, 0.09824344236403704), (13, 0.10170583054423332), (15, 0.104298897087574), (3, 0.11098101176321507), (47, 0.11621952801942825), (48, 0.12237984780222178), (9, 0.12299975752830505), (12, 0.12352677993476391), (8, 0.12572808098047972), (10, 0.13013752549886703), (1, 0.13287559244781733), (16, 0.14817260019481182), (5, 0.1663893349468708), (4, 0.17319472320377827), (17, 0.25980715826153755), (36, 0.5691500827670097), (18, 0.6076002568006516)]
computing accuracy for after removing block 31 . block score: 0.04772990336641669
removed block 31 current accuracy 0.9068 loss from initial  0.047599999999999976
since last training loss: 0.03299999999999992 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.049457. All blocks and scores: [(23, 0.049456785432994366), (43, 0.05643091071397066), (28, 0.05841281730681658), (29, 0.062131719663739204), (11, 0.06216722307726741), (19, 0.06264894735068083), (42, 0.064087625592947), (6, 0.06472423952072859), (40, 0.06519029848277569), (21, 0.06573328841477633), (45, 0.06691661477088928), (2, 0.07099238503724337), (27, 0.07302539423108101), (44, 0.0741696348413825), (0, 0.07439176458865404), (39, 0.07595168519765139), (46, 0.07623583171516657), (51, 0.07929473370313644), (49, 0.08900228049606085), (7, 0.09215220622718334), (14, 0.09824344050139189), (13, 0.1017058314755559), (15, 0.104298897087574), (47, 0.11052049696445465), (3, 0.11098100896924734), (48, 0.11894362233579159), (9, 0.12299975845962763), (12, 0.12352677527815104), (8, 0.12572808284312487), (10, 0.13013752549886703), (1, 0.13287559803575277), (16, 0.14817260019481182), (5, 0.1663893312215805), (4, 0.17319472692906857), (17, 0.25980715081095695), (36, 0.5413546115159988), (18, 0.607600249350071)]
computing accuracy for after removing block 23 . block score: 0.049456785432994366
removed block 23 current accuracy 0.8856 loss from initial  0.06879999999999997
training start
training epoch 0 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 1 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 2 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 3 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.1]
training epoch 4 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 5 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 6 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.1]
training epoch 7 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 8 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.1]
training epoch 9 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
start iteration 18
[activation diff]: block to remove picked: 11, with score 0.057665. All blocks and scores: [(11, 0.05766483675688505), (2, 0.06497037038207054), (43, 0.07207031548023224), (6, 0.07251275796443224), (42, 0.07825981825590134), (40, 0.0790636008605361), (0, 0.08089513704180717), (46, 0.08099261950701475), (44, 0.08177320845425129), (45, 0.08221221715211868), (19, 0.08283902332186699), (28, 0.08499226998537779), (3, 0.08766888920217752), (29, 0.09509834367781878), (27, 0.09648062195628881), (7, 0.09664159081876278), (14, 0.09833719115704298), (39, 0.09841286949813366), (21, 0.10723837837576866), (13, 0.11410854198038578), (15, 0.11742119304835796), (49, 0.1189372455701232), (51, 0.11925854627043009), (47, 0.12194690573960543), (9, 0.12382945884019136), (1, 0.13143404200673103), (8, 0.13315710797905922), (48, 0.14137628488242626), (10, 0.1419406533241272), (16, 0.14221504144370556), (12, 0.14302311837673187), (4, 0.15597434155642986), (5, 0.1686091646552086), (17, 0.2983737550675869), (18, 0.5720272734761238), (36, 0.7114119231700897)]
computing accuracy for after removing block 11 . block score: 0.05766483675688505
removed block 11 current accuracy 0.9402 loss from initial  0.01419999999999999
since last training loss: -0.00040000000000006697 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 2, with score 0.064970. All blocks and scores: [(2, 0.06497037038207054), (43, 0.07109540328383446), (6, 0.07251275703310966), (40, 0.07846900727599859), (42, 0.07867411617189646), (46, 0.07998760417103767), (44, 0.08086850959807634), (0, 0.08089513704180717), (45, 0.08180966041982174), (28, 0.08286737836897373), (19, 0.08315351791679859), (14, 0.0870447913184762), (3, 0.08766889292746782), (29, 0.09251620806753635), (27, 0.09316695388406515), (7, 0.09664159268140793), (39, 0.09705487731844187), (13, 0.10498947836458683), (21, 0.10607349127531052), (15, 0.10792023222893476), (49, 0.11695400346070528), (51, 0.1187860919162631), (47, 0.12076910585165024), (9, 0.12382945604622364), (1, 0.13143404200673103), (8, 0.13315710797905922), (12, 0.13499348610639572), (16, 0.1366555355489254), (48, 0.14148641377687454), (10, 0.1419406495988369), (4, 0.1559743396937847), (5, 0.16860916279256344), (17, 0.2704475671052933), (18, 0.551032043993473), (36, 0.6954448893666267)]
computing accuracy for after removing block 2 . block score: 0.06497037038207054
removed block 2 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.068874. All blocks and scores: [(43, 0.0688735144212842), (6, 0.0714423805475235), (40, 0.07694311812520027), (46, 0.07753168977797031), (44, 0.07842940837144852), (42, 0.07873951457440853), (28, 0.08075828105211258), (45, 0.08076825179159641), (0, 0.08089513704180717), (19, 0.08359299506992102), (14, 0.08549680933356285), (27, 0.08968354295939207), (7, 0.09056111332029104), (29, 0.09080977365374565), (39, 0.09547662921249866), (3, 0.10059751104563475), (13, 0.10313485562801361), (15, 0.10521325841546059), (21, 0.10752801410853863), (49, 0.11344015505164862), (9, 0.11659485008567572), (47, 0.11736948695033789), (51, 0.11804964207112789), (10, 0.12931275181472301), (1, 0.13143404386937618), (16, 0.13396364264190197), (12, 0.1349367182701826), (8, 0.13919556885957718), (48, 0.14038450829684734), (4, 0.1548420675098896), (5, 0.17571323923766613), (17, 0.2578829973936081), (18, 0.539574645459652), (36, 0.6818101704120636)]
computing accuracy for after removing block 43 . block score: 0.0688735144212842
removed block 43 current accuracy 0.9272 loss from initial  0.027200000000000002
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 6, with score 0.071442. All blocks and scores: [(6, 0.07144238147884607), (46, 0.0719508258625865), (40, 0.07694311812520027), (45, 0.07713810540735722), (44, 0.07777667511254549), (42, 0.07873951457440853), (28, 0.08075828105211258), (0, 0.0808951361104846), (19, 0.08359299506992102), (14, 0.085496811196208), (27, 0.0896835420280695), (7, 0.09056111238896847), (29, 0.09080977365374565), (39, 0.09547662548720837), (3, 0.10059750732034445), (13, 0.10313485469669104), (15, 0.10521325748413801), (21, 0.10752801597118378), (49, 0.10884427931159735), (47, 0.11108444537967443), (51, 0.11542763188481331), (9, 0.11659484915435314), (10, 0.12931275181472301), (1, 0.13143404200673103), (48, 0.13312001712620258), (16, 0.13396364636719227), (12, 0.13493672013282776), (8, 0.13919556885957718), (4, 0.15484206937253475), (5, 0.17571324110031128), (17, 0.2578830048441887), (18, 0.539574645459652), (36, 0.6818101480603218)]
computing accuracy for after removing block 6 . block score: 0.07144238147884607
removed block 6 current accuracy 0.9146 loss from initial  0.03980000000000006
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.069835. All blocks and scores: [(46, 0.06983499974012375), (14, 0.07267784792929888), (44, 0.07606811448931694), (45, 0.07647566590458155), (40, 0.07674255594611168), (28, 0.07675961963832378), (42, 0.07941933628171682), (0, 0.08089513797312975), (19, 0.08236585836857557), (27, 0.08552732318639755), (29, 0.08859297726303339), (39, 0.09318357892334461), (13, 0.09387258626520634), (7, 0.09745312761515379), (15, 0.09941940475255251), (3, 0.10059751197695732), (21, 0.10542349424213171), (47, 0.10723992437124252), (49, 0.10835154727101326), (9, 0.11377043556421995), (51, 0.11466329544782639), (10, 0.12067666184157133), (16, 0.1228618873283267), (12, 0.12776315864175558), (8, 0.1309221964329481), (1, 0.13143404200673103), (48, 0.1322524081915617), (4, 0.15484206564724445), (5, 0.17571323923766613), (17, 0.22231301106512547), (18, 0.5187147632241249), (36, 0.6617451757192612)]
computing accuracy for after removing block 46 . block score: 0.06983499974012375
removed block 46 current accuracy 0.9026 loss from initial  0.05180000000000007
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 14, with score 0.072678. All blocks and scores: [(14, 0.0726778469979763), (44, 0.07606811448931694), (45, 0.07647566683590412), (40, 0.0767425550147891), (28, 0.07675961870700121), (42, 0.07941933535039425), (0, 0.08089513890445232), (19, 0.08236586209386587), (27, 0.08552732411772013), (29, 0.08859297912567854), (39, 0.09318358171731234), (13, 0.09387258533388376), (49, 0.09460171684622765), (51, 0.09558030311018229), (47, 0.09613656904548407), (7, 0.09745312668383121), (15, 0.09941940568387508), (3, 0.10059750732034445), (21, 0.10542349331080914), (9, 0.11377043649554253), (48, 0.1172297177836299), (10, 0.12067666184157133), (16, 0.1228618873283267), (12, 0.12776315864175558), (8, 0.1309222001582384), (1, 0.13143404386937618), (4, 0.1548420675098896), (5, 0.17571324110031128), (17, 0.22231301106512547), (18, 0.5187147632241249), (36, 0.6617451682686806)]
computing accuracy for after removing block 14 . block score: 0.0726778469979763
removed block 14 current accuracy 0.888 loss from initial  0.06640000000000001
since last training loss: 0.05179999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 28, with score 0.073429. All blocks and scores: [(28, 0.07342915050685406), (45, 0.07468710094690323), (44, 0.07521369494497776), (40, 0.07632863335311413), (42, 0.07923356536775827), (0, 0.08089513797312975), (19, 0.0819488326087594), (27, 0.08293371740728617), (29, 0.08652818389236927), (39, 0.09193381108343601), (51, 0.09386422205716372), (13, 0.09387258626520634), (47, 0.09449819382280111), (49, 0.09522288106381893), (7, 0.09745312575250864), (3, 0.10059750825166702), (21, 0.10264852643013), (15, 0.10710913874208927), (9, 0.11377043649554253), (48, 0.11689053662121296), (10, 0.12067666091024876), (12, 0.12776315677911043), (8, 0.13092219829559326), (1, 0.13143404386937618), (16, 0.13755269348621368), (4, 0.15484206937253475), (5, 0.17571323923766613), (17, 0.22745723463594913), (18, 0.5138088911771774), (36, 0.6549175307154655)]
computing accuracy for after removing block 28 . block score: 0.07342915050685406
removed block 28 current accuracy 0.8614 loss from initial  0.09299999999999997
since last training loss: 0.07839999999999991 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.067040. All blocks and scores: [(45, 0.06704002618789673), (44, 0.07104588858783245), (40, 0.07145240623503923), (42, 0.07408687565475702), (29, 0.08089469838887453), (0, 0.08089513704180717), (39, 0.08159857615828514), (19, 0.08194883167743683), (27, 0.08293371740728617), (47, 0.0893114572390914), (51, 0.09319371823221445), (13, 0.09387258812785149), (49, 0.09427834395319223), (7, 0.09745312388986349), (3, 0.10059750732034445), (21, 0.10264852549880743), (15, 0.10710913501679897), (9, 0.11377043183892965), (48, 0.11623636167496443), (10, 0.12067665997892618), (12, 0.1277631614357233), (8, 0.13092219829559326), (1, 0.13143404200673103), (16, 0.13755269348621368), (4, 0.15484206937253475), (5, 0.17571324482560158), (17, 0.2274572290480137), (18, 0.5138089060783386), (36, 0.6120821088552475)]
computing accuracy for after removing block 45 . block score: 0.06704002618789673
removed block 45 current accuracy 0.8146 loss from initial  0.13980000000000004
since last training loss: 0.12519999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.071046. All blocks and scores: [(44, 0.07104588858783245), (40, 0.07145240623503923), (42, 0.07408687472343445), (47, 0.07937106676399708), (49, 0.08028043992817402), (29, 0.08089469838887453), (0, 0.08089513797312975), (39, 0.08159857429563999), (19, 0.0819488326087594), (27, 0.08293371554464102), (51, 0.08319250494241714), (13, 0.09387258999049664), (7, 0.09745312575250864), (3, 0.1005975091829896), (21, 0.10264852549880743), (15, 0.1071091340854764), (48, 0.1092044934630394), (9, 0.11377043556421995), (10, 0.12067666184157133), (12, 0.12776315864175558), (8, 0.13092219829559326), (1, 0.13143404386937618), (16, 0.13755269534885883), (4, 0.15484206937253475), (5, 0.17571323923766613), (17, 0.22745723649859428), (18, 0.5138088911771774), (36, 0.6120821088552475)]
computing accuracy for after removing block 44 . block score: 0.07104588858783245
removed block 44 current accuracy 0.7486 loss from initial  0.20579999999999998
training start
training epoch 0 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 1 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 2 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 6 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 8 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
