start iteration 0
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778), (53, 0.02245476096868515)]
computing accuracy for after removing block 53 . block score: 0.02245476096868515
removed block 53 current accuracy 0.9532 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778)]
computing accuracy for after removing block 52 . block score: 0.023782813921570778
removed block 52 current accuracy 0.9534 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347)]
computing accuracy for after removing block 51 . block score: 0.026051300577819347
removed block 51 current accuracy 0.953 loss from initial  0.0014000000000000679
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383)]
computing accuracy for after removing block 50 . block score: 0.028078997507691383
removed block 50 current accuracy 0.951 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694)]
computing accuracy for after removing block 49 . block score: 0.030814231373369694
removed block 49 current accuracy 0.9494 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084)]
computing accuracy for after removing block 48 . block score: 0.034880238585174084
removed block 48 current accuracy 0.9462 loss from initial  0.008199999999999985
training start
training epoch 0 val accuracy 0.8102 topk_dict {'top1': 0.8102} is_best False lr [0.1]
training epoch 1 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.1]
training epoch 2 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 3 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 4 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best False lr [0.1]
training epoch 5 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 6 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 7 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 8 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 9 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (34, 0.060477711260318756), (35, 0.058227844536304474), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631), (45, 0.057357992976903915), (46, 0.05354313738644123), (47, 0.049392009153962135)]
computing accuracy for after removing block 47 . block score: 0.049392009153962135
removed block 47 current accuracy 0.9434 loss from initial  0.01100000000000001
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (34, 0.060477711260318756), (35, 0.058227844536304474), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631), (45, 0.057357992976903915), (46, 0.05354313738644123)]
computing accuracy for after removing block 46 . block score: 0.05354313738644123
removed block 46 current accuracy 0.9346 loss from initial  0.01980000000000004
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (34, 0.060477711260318756), (35, 0.058227844536304474), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631), (45, 0.057357992976903915)]
computing accuracy for after removing block 45 . block score: 0.057357992976903915
removed block 45 current accuracy 0.9232 loss from initial  0.031200000000000006
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (34, 0.060477711260318756), (35, 0.058227844536304474), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631)]
computing accuracy for after removing block 35 . block score: 0.058227844536304474
removed block 35 current accuracy 0.921 loss from initial  0.033399999999999985
since last training loss: 0.025799999999999934 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (34, 0.060477711260318756), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631)]
computing accuracy for after removing block 34 . block score: 0.060477711260318756
removed block 34 current accuracy 0.9174 loss from initial  0.03700000000000003
since last training loss: 0.02939999999999998 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.08936808630824089), (1, 0.11216636374592781), (2, 0.09683602675795555), (3, 0.10611952468752861), (4, 0.12160614505410194), (5, 0.1215297318994999), (6, 0.10629389062523842), (7, 0.11728397756814957), (8, 0.13036460801959038), (9, 0.12872347608208656), (10, 0.1258217617869377), (11, 0.12404320761561394), (12, 0.1269335299730301), (13, 0.11572930589318275), (14, 0.11547503247857094), (15, 0.12144676595926285), (16, 0.12276262789964676), (17, 0.11846273019909859), (18, 0.3680494874715805), (19, 0.09657685458660126), (20, 0.09395947679877281), (21, 0.09639937430620193), (22, 0.09203838184475899), (23, 0.09137452021241188), (24, 0.0843493677675724), (25, 0.08448563888669014), (26, 0.08454906567931175), (27, 0.0807674415409565), (28, 0.07769419997930527), (29, 0.07394860312342644), (30, 0.07208985090255737), (31, 0.068815803155303), (32, 0.06350229308009148), (33, 0.061716439202427864), (36, 0.24568432569503784), (37, 0.06987502798438072), (38, 0.07114775851368904), (39, 0.069891557097435), (40, 0.06813884899020195), (41, 0.06644230708479881), (42, 0.0649312473833561), (43, 0.06393774598836899), (44, 0.06051306612789631)]
computing accuracy for after removing block 44 . block score: 0.06051306612789631
removed block 44 current accuracy 0.9014 loss from initial  0.05300000000000005
training start
training epoch 0 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 1 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 2 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 3 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 6 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.1]
training epoch 7 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 10 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.948800)
finished training. finished 50 epochs. accuracy 0.9488 topk_dict {'top1': 0.9488}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (31, 0.0728776715695858), (32, 0.0674305371940136), (33, 0.06600797176361084), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339), (42, 0.07646350562572479), (43, 0.07310319505631924)]
computing accuracy for after removing block 33 . block score: 0.06600797176361084
removed block 33 current accuracy 0.9472 loss from initial  0.007199999999999984
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (31, 0.0728776715695858), (32, 0.0674305371940136), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339), (42, 0.07646350562572479), (43, 0.07310319505631924)]
computing accuracy for after removing block 32 . block score: 0.0674305371940136
removed block 32 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (31, 0.0728776715695858), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339), (42, 0.07646350562572479), (43, 0.07310319505631924)]
computing accuracy for after removing block 31 . block score: 0.0728776715695858
removed block 31 current accuracy 0.9432 loss from initial  0.011199999999999988
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339), (42, 0.07646350562572479), (43, 0.07310319505631924)]
computing accuracy for after removing block 43 . block score: 0.07310319505631924
removed block 43 current accuracy 0.9258 loss from initial  0.02860000000000007
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339), (42, 0.07646350562572479)]
computing accuracy for after removing block 42 . block score: 0.07646350562572479
removed block 42 current accuracy 0.8904 loss from initial  0.06400000000000006
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09059059619903564), (1, 0.11418624594807625), (2, 0.09779499471187592), (3, 0.10567370802164078), (4, 0.12455515190958977), (5, 0.12507879361510277), (6, 0.10635601356625557), (7, 0.11855098232626915), (8, 0.13145951554179192), (9, 0.13189714401960373), (10, 0.12825429812073708), (11, 0.12728898599743843), (12, 0.12968038395047188), (13, 0.11911705136299133), (14, 0.11918298900127411), (15, 0.12542670965194702), (16, 0.12576695531606674), (17, 0.12141883745789528), (18, 0.37794043123722076), (19, 0.09949082136154175), (20, 0.09716002643108368), (21, 0.09924959391355515), (22, 0.09507404267787933), (23, 0.09497610852122307), (24, 0.08817068859934807), (25, 0.08851828798651695), (26, 0.08841806277632713), (27, 0.08567096665501595), (28, 0.08176164329051971), (29, 0.07906477525830269), (30, 0.07650712132453918), (36, 0.2556862011551857), (37, 0.07769647985696793), (38, 0.07955263927578926), (39, 0.07942873239517212), (40, 0.07835445925593376), (41, 0.07694477960467339)]
computing accuracy for after removing block 30 . block score: 0.07650712132453918
removed block 30 current accuracy 0.8826 loss from initial  0.07179999999999997
training start
training epoch 0 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 1 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 2 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 3 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 4 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 5 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 6 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 7 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 8 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 9 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (29, 0.08786189183592796), (36, 0.2616381011903286), (37, 0.08642350509762764), (38, 0.08897733688354492), (39, 0.08898970857262611), (40, 0.08891526609659195), (41, 0.08425019308924675)]
computing accuracy for after removing block 41 . block score: 0.08425019308924675
removed block 41 current accuracy 0.9062 loss from initial  0.04820000000000002
since last training loss: 0.04159999999999997 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (29, 0.08786189183592796), (36, 0.2616381011903286), (37, 0.08642350509762764), (38, 0.08897733688354492), (39, 0.08898970857262611), (40, 0.08891526609659195)]
computing accuracy for after removing block 37 . block score: 0.08642350509762764
removed block 37 current accuracy 0.8956 loss from initial  0.058800000000000074
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (29, 0.08786189183592796), (36, 0.2616381011903286), (38, 0.08897733688354492), (39, 0.08898970857262611), (40, 0.08891526609659195)]
computing accuracy for after removing block 29 . block score: 0.08786189183592796
removed block 29 current accuracy 0.892 loss from initial  0.06240000000000001
since last training loss: 0.05579999999999996 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (36, 0.2616381011903286), (38, 0.08897733688354492), (39, 0.08898970857262611), (40, 0.08891526609659195)]
computing accuracy for after removing block 40 . block score: 0.08891526609659195
removed block 40 current accuracy 0.8274 loss from initial  0.127
since last training loss: 0.12039999999999995 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (36, 0.2616381011903286), (38, 0.08897733688354492), (39, 0.08898970857262611)]
computing accuracy for after removing block 38 . block score: 0.08897733688354492
removed block 38 current accuracy 0.7684 loss from initial  0.18600000000000005
since last training loss: 0.1794 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (36, 0.2616381011903286), (39, 0.08898970857262611)]
computing accuracy for after removing block 39 . block score: 0.08898970857262611
removed block 39 current accuracy 0.6754 loss from initial  0.279
since last training loss: 0.2724 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.08990103751420975), (1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (36, 0.2616381011903286)]
computing accuracy for after removing block 0 . block score: 0.08990103751420975
removed block 0 current accuracy 0.6134 loss from initial  0.3410000000000001
since last training loss: 0.33440000000000003 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (28, 0.09006296470761299), (36, 0.2616381011903286)]
computing accuracy for after removing block 28 . block score: 0.09006296470761299
removed block 28 current accuracy 0.5858 loss from initial  0.36860000000000004
since last training loss: 0.362 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(1, 0.11589797213673592), (2, 0.09865690395236015), (3, 0.1052282340824604), (4, 0.12352141365408897), (5, 0.12446304038167), (6, 0.10543632507324219), (7, 0.11840696260333061), (8, 0.13309068232774734), (9, 0.13320909813046455), (10, 0.13061793893575668), (11, 0.12872674316167831), (12, 0.12963977083563805), (13, 0.12005193904042244), (14, 0.11973442137241364), (15, 0.12713677436113358), (16, 0.12726493924856186), (17, 0.12265093252062798), (18, 0.3791994974017143), (19, 0.10280409827828407), (20, 0.10151759907603264), (21, 0.10376106947660446), (22, 0.09947701171040535), (23, 0.09922292828559875), (24, 0.09311831369996071), (25, 0.09502986073493958), (26, 0.09587555378675461), (27, 0.09304678067564964), (36, 0.2616381011903286)]
computing accuracy for after removing block 27 . block score: 0.09304678067564964
removed block 27 current accuracy 0.5572 loss from initial  0.3972
training start
training epoch 0 val accuracy 0.79 topk_dict {'top1': 0.79} is_best True lr [0.1]
training epoch 1 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best True lr [0.1]
training epoch 2 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 3 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 4 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.1]
training epoch 5 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 6 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 7 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 8 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 9 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 10 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.929600)
finished training. finished 50 epochs. accuracy 0.9296 topk_dict {'top1': 0.9296}
