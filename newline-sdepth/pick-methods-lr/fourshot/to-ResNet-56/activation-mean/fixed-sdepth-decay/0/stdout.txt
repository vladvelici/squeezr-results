start iteration 0
[activation mean]: block to remove picked: 35, with score 0.094478. All blocks and scores: [(35, 0.09447801485657692), (34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.14710238575935364), (19, 0.14895895309746265), (53, 0.1498922035098076), (52, 0.15163039043545723), (51, 0.1535380631685257), (13, 0.15705686062574387), (14, 0.16249225474894047), (38, 0.16445158794522285), (50, 0.16464474610984325), (49, 0.1657810639590025), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (40, 0.173427015542984), (16, 0.17345409654080868), (41, 0.17369753867387772), (11, 0.17475955933332443), (46, 0.17609802819788456), (45, 0.17827162519097328), (39, 0.1792436372488737), (44, 0.18025114387273788), (48, 0.18066065199673176), (42, 0.18066276982426643), (47, 0.18073148280382156), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (43, 0.189305879175663), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.23272303864359856), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 35 . block score: 0.09447801485657692
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.096040. All blocks and scores: [(34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.1407872699201107), (53, 0.14861096628010273), (19, 0.14895895309746265), (52, 0.14969445951282978), (51, 0.1523898020386696), (13, 0.15705686062574387), (38, 0.15781539678573608), (14, 0.16249225474894047), (50, 0.16313881427049637), (49, 0.16411315463483334), (40, 0.1689014621078968), (41, 0.1690248530358076), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (39, 0.17247052490711212), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (46, 0.17373871989548206), (11, 0.17475955933332443), (45, 0.17579046078026295), (42, 0.1771144587546587), (44, 0.17722493782639503), (47, 0.17847622744739056), (48, 0.1788573693484068), (8, 0.18169353157281876), (12, 0.18286443874239922), (43, 0.18561581149697304), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.2266793828457594), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 34 . block score: 0.09604021441191435
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.097944. All blocks and scores: [(32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13551420159637928), (53, 0.14707430079579353), (52, 0.14760426990687847), (19, 0.14895895309746265), (51, 0.15091686882078648), (38, 0.1523499172180891), (13, 0.15705686062574387), (50, 0.16150624863803387), (14, 0.16249225474894047), (49, 0.1625587809830904), (40, 0.16517788171768188), (41, 0.16536311618983746), (39, 0.16688678227365017), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (46, 0.1715139839798212), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (45, 0.1736477129161358), (42, 0.1742321215569973), (11, 0.17475955933332443), (44, 0.1747924704104662), (47, 0.17631406895816326), (48, 0.17726918868720531), (8, 0.18169353157281876), (43, 0.1826457940042019), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (36, 0.221288425847888), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 32 . block score: 0.09794430993497372
removed block 32 current accuracy 0.945 loss from initial  0.009400000000000075
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 33, with score 0.096237. All blocks and scores: [(33, 0.0962365735322237), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13045251369476318), (53, 0.14460941962897778), (52, 0.14462984167039394), (38, 0.1469358094036579), (51, 0.1486178170889616), (19, 0.14895895309746265), (13, 0.15705686062574387), (50, 0.15898261778056622), (49, 0.1601924430578947), (39, 0.1610004734247923), (41, 0.16117839701473713), (40, 0.16137539595365524), (14, 0.16249225474894047), (46, 0.16855736821889877), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (45, 0.1705855056643486), (42, 0.17088175937533379), (44, 0.17191905342042446), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (47, 0.17325890436768532), (16, 0.17345409654080868), (48, 0.1746351718902588), (11, 0.17475955933332443), (43, 0.17927574925124645), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21651554107666016), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 33 . block score: 0.0962365735322237
removed block 33 current accuracy 0.9408 loss from initial  0.013600000000000056
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 31, with score 0.106299. All blocks and scores: [(31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (37, 0.1261464450508356), (21, 0.1281397920101881), (52, 0.141027070581913), (53, 0.14170901477336884), (38, 0.14201517030596733), (51, 0.14598987624049187), (19, 0.14895895309746265), (39, 0.15555569157004356), (50, 0.15602300502359867), (13, 0.15705686062574387), (49, 0.15735810063779354), (41, 0.15751718543469906), (40, 0.15766894072294235), (14, 0.16249225474894047), (46, 0.16544132120907307), (45, 0.16723843477666378), (42, 0.16781402193009853), (44, 0.16861379332840443), (6, 0.16913926228880882), (47, 0.17008974589407444), (15, 0.17030494660139084), (3, 0.17048806883394718), (48, 0.17144453153014183), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (43, 0.1758242715150118), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21325702220201492), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 31 . block score: 0.10629933141171932
removed block 31 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 27, with score 0.107886. All blocks and scores: [(27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (37, 0.12083858530968428), (20, 0.12209091056138277), (21, 0.1281397920101881), (38, 0.13578535057604313), (52, 0.13683941774070263), (53, 0.13806491903960705), (51, 0.1427531000226736), (39, 0.14883904717862606), (19, 0.14895895309746265), (50, 0.1524738073348999), (41, 0.15277637541294098), (40, 0.15300416387617588), (49, 0.15408698096871376), (13, 0.15705686062574387), (46, 0.16158179938793182), (14, 0.16249225474894047), (45, 0.16341477446258068), (42, 0.1641642488539219), (44, 0.16474203765392303), (47, 0.1662686076015234), (48, 0.16778318211436272), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (43, 0.17166327871382236), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.2090455386787653), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 27 . block score: 0.10788614861667156
removed block 27 current accuracy 0.924 loss from initial  0.030399999999999983
training start
training epoch 0 val accuracy 0.708 topk_dict {'top1': 0.708} is_best False lr [0.1]
training epoch 1 val accuracy 0.7662 topk_dict {'top1': 0.7662} is_best False lr [0.1]
training epoch 2 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best False lr [0.1]
training epoch 3 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best False lr [0.1]
training epoch 4 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 5 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 6 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 7 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 8 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.939400)
finished training. finished 50 epochs. accuracy 0.9394 topk_dict {'top1': 0.9394}
start iteration 6
[activation mean]: block to remove picked: 28, with score 0.156761. All blocks and scores: [(28, 0.15676114335656166), (30, 0.163890628144145), (20, 0.1658401247113943), (26, 0.1674444954842329), (29, 0.17580527253448963), (25, 0.18242404237389565), (23, 0.18896031752228737), (21, 0.1937120258808136), (53, 0.19444740004837513), (24, 0.19742139987647533), (22, 0.20011228881776333), (19, 0.20598390884697437), (13, 0.211869977414608), (6, 0.21413812786340714), (51, 0.21545902825891972), (14, 0.21837366744875908), (52, 0.2186604104936123), (7, 0.23355312086641788), (15, 0.23671959899365902), (50, 0.23931673727929592), (3, 0.245864350348711), (49, 0.24640196561813354), (37, 0.2505422364920378), (10, 0.2530979849398136), (16, 0.2589519992470741), (12, 0.26139719411730766), (2, 0.263686440885067), (47, 0.2684200368821621), (17, 0.26845237612724304), (11, 0.2741606794297695), (48, 0.2795931398868561), (8, 0.2892211675643921), (9, 0.29042425751686096), (39, 0.29493967071175575), (38, 0.2962316758930683), (46, 0.29974570870399475), (41, 0.3037949614226818), (40, 0.30457357317209244), (45, 0.30571650713682175), (42, 0.31027231365442276), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.32382552325725555), (44, 0.33500446379184723), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.555973544716835), (18, 0.5838701725006104)]
computing accuracy for after removing block 28 . block score: 0.15676114335656166
removed block 28 current accuracy 0.936 loss from initial  0.018399999999999972
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 30, with score 0.160475. All blocks and scores: [(30, 0.16047525964677334), (20, 0.1658401247113943), (26, 0.1674444954842329), (29, 0.17406124621629715), (53, 0.18196376040577888), (25, 0.18242404237389565), (23, 0.18896031752228737), (21, 0.1937120258808136), (24, 0.19742139987647533), (22, 0.20011228881776333), (19, 0.20598390884697437), (51, 0.21156656369566917), (13, 0.211869977414608), (6, 0.21413812786340714), (52, 0.2153166439384222), (14, 0.21837366744875908), (7, 0.23355312086641788), (50, 0.23639177903532982), (15, 0.23671959899365902), (37, 0.23867481388151646), (49, 0.2430566269904375), (3, 0.245864350348711), (10, 0.2530979849398136), (16, 0.2589519992470741), (12, 0.26139719411730766), (47, 0.2633556015789509), (2, 0.263686440885067), (17, 0.26845237612724304), (11, 0.2741606794297695), (48, 0.2764495350420475), (38, 0.2823682688176632), (39, 0.2853053882718086), (8, 0.2892211675643921), (9, 0.29042425751686096), (41, 0.29232336953282356), (40, 0.2962912395596504), (46, 0.2965891435742378), (45, 0.29881811141967773), (42, 0.3035222999751568), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.3202902488410473), (44, 0.3282623626291752), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.5394505336880684), (18, 0.5838701725006104)]
computing accuracy for after removing block 30 . block score: 0.16047525964677334
removed block 30 current accuracy 0.935 loss from initial  0.019399999999999973
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 20, with score 0.165840. All blocks and scores: [(20, 0.1658401247113943), (26, 0.1674444954842329), (29, 0.17406124621629715), (53, 0.17505512945353985), (25, 0.18242404237389565), (23, 0.18896031752228737), (21, 0.1937120258808136), (24, 0.19742139987647533), (22, 0.20011228881776333), (19, 0.20598390884697437), (51, 0.20981906726956367), (13, 0.211869977414608), (52, 0.21226727962493896), (6, 0.21413812786340714), (14, 0.21837366744875908), (37, 0.23008744418621063), (7, 0.23355312086641788), (50, 0.23513303324580193), (15, 0.23671959899365902), (49, 0.24037396907806396), (3, 0.245864350348711), (10, 0.2530979849398136), (16, 0.2589519992470741), (12, 0.26139719411730766), (47, 0.2615877687931061), (2, 0.263686440885067), (17, 0.26845237612724304), (38, 0.2716887928545475), (48, 0.27389195933938026), (11, 0.2741606794297695), (39, 0.2755299210548401), (41, 0.28415458649396896), (40, 0.28793850913643837), (8, 0.2892211675643921), (9, 0.29042425751686096), (45, 0.2945893704891205), (46, 0.2967700622975826), (42, 0.30075864493846893), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.31873295828700066), (44, 0.3256886973977089), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.5275573879480362), (18, 0.5838701725006104)]
computing accuracy for after removing block 20 . block score: 0.1658401247113943
removed block 20 current accuracy 0.9312 loss from initial  0.0232
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.165094. All blocks and scores: [(26, 0.16509445011615753), (53, 0.17100712470710278), (29, 0.1737031601369381), (25, 0.17645932734012604), (23, 0.1855966802686453), (21, 0.1900952197611332), (24, 0.19407944567501545), (22, 0.1951842214912176), (19, 0.20598390884697437), (51, 0.20846650935709476), (52, 0.21065557561814785), (13, 0.211869977414608), (6, 0.21413812786340714), (14, 0.21837366744875908), (37, 0.2246298100799322), (7, 0.23355312086641788), (50, 0.2337715830653906), (15, 0.23671959899365902), (49, 0.2383986860513687), (3, 0.245864350348711), (10, 0.2530979849398136), (16, 0.2589519992470741), (47, 0.25909772142767906), (12, 0.26139719411730766), (2, 0.263686440885067), (38, 0.2648323327302933), (39, 0.2683080844581127), (17, 0.26845237612724304), (48, 0.272992305457592), (11, 0.2741606794297695), (41, 0.28015507757663727), (40, 0.2838047407567501), (8, 0.2892211675643921), (9, 0.29042425751686096), (45, 0.29439081996679306), (42, 0.29662152752280235), (46, 0.2974068894982338), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.3173478916287422), (44, 0.3255673833191395), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.5244284272193909), (18, 0.5838701725006104)]
computing accuracy for after removing block 26 . block score: 0.16509445011615753
removed block 26 current accuracy 0.9194 loss from initial  0.03500000000000003
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 53, with score 0.162531. All blocks and scores: [(53, 0.16253093257546425), (29, 0.17489335127174854), (25, 0.17645932734012604), (23, 0.1855966802686453), (21, 0.1900952197611332), (24, 0.19407944567501545), (22, 0.1951842214912176), (51, 0.20578807592391968), (19, 0.20598390884697437), (52, 0.20762502402067184), (13, 0.211869977414608), (6, 0.21413812786340714), (14, 0.21837366744875908), (37, 0.21930133178830147), (50, 0.2303653359413147), (7, 0.23355312086641788), (49, 0.23565939255058765), (15, 0.23671959899365902), (3, 0.245864350348711), (10, 0.2530979849398136), (47, 0.2553512565791607), (38, 0.25658658146858215), (16, 0.2589519992470741), (12, 0.26139719411730766), (39, 0.2627185210585594), (2, 0.263686440885067), (17, 0.26845237612724304), (48, 0.2705646641552448), (41, 0.27398408204317093), (11, 0.2741606794297695), (40, 0.2779983803629875), (8, 0.2892211675643921), (45, 0.28928204253315926), (9, 0.29042425751686096), (42, 0.2907881774008274), (46, 0.2955019436776638), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.31684449687600136), (44, 0.3225299268960953), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.5220872089266777), (18, 0.5838701725006104)]
computing accuracy for after removing block 53 . block score: 0.16253093257546425
removed block 53 current accuracy 0.9182 loss from initial  0.03620000000000001
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 29, with score 0.174893. All blocks and scores: [(29, 0.17489335127174854), (25, 0.17645932734012604), (23, 0.1855966802686453), (21, 0.1900952197611332), (24, 0.19407944567501545), (22, 0.1951842214912176), (51, 0.20578807592391968), (19, 0.20598390884697437), (52, 0.20762502402067184), (13, 0.211869977414608), (6, 0.21413812786340714), (14, 0.21837366744875908), (37, 0.21930133178830147), (50, 0.2303653359413147), (7, 0.23355312086641788), (49, 0.23565939255058765), (15, 0.23671959899365902), (3, 0.245864350348711), (10, 0.2530979849398136), (47, 0.2553512565791607), (38, 0.25658658146858215), (16, 0.2589519992470741), (12, 0.26139719411730766), (39, 0.2627185210585594), (2, 0.263686440885067), (17, 0.26845237612724304), (48, 0.2705646641552448), (41, 0.27398408204317093), (11, 0.2741606794297695), (40, 0.2779983803629875), (8, 0.2892211675643921), (45, 0.28928204253315926), (9, 0.29042425751686096), (42, 0.2907881774008274), (46, 0.2955019436776638), (5, 0.3112947307527065), (0, 0.31496118381619453), (43, 0.31684449687600136), (44, 0.3225299268960953), (4, 0.35194265842437744), (1, 0.3784763813018799), (36, 0.5220872089266777), (18, 0.5838701725006104)]
computing accuracy for after removing block 29 . block score: 0.17489335127174854
removed block 29 current accuracy 0.9044 loss from initial  0.050000000000000044
training start
training epoch 0 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 1 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 2 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 3 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 4 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 5 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 6 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 7 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 8 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 9 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 10 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 12
[activation mean]: block to remove picked: 13, with score 0.203614. All blocks and scores: [(13, 0.2036137469112873), (23, 0.2117342371493578), (19, 0.21325633861124516), (21, 0.21850969828665257), (25, 0.2206039372831583), (6, 0.22428541630506516), (24, 0.2258756011724472), (14, 0.22642642259597778), (22, 0.22704477794468403), (51, 0.2281445860862732), (52, 0.22875727899372578), (3, 0.23885414004325867), (15, 0.2456200271844864), (2, 0.24862674996256828), (49, 0.24989686533808708), (10, 0.2509586103260517), (50, 0.25387146323919296), (7, 0.2577207498252392), (16, 0.25814415886998177), (37, 0.2608816772699356), (12, 0.2627381645143032), (11, 0.2635774165391922), (47, 0.27421874552965164), (9, 0.27560747414827347), (17, 0.27624085173010826), (48, 0.28386273980140686), (0, 0.2887451499700546), (38, 0.29977821558713913), (46, 0.30023928731679916), (39, 0.30049679800868034), (40, 0.3008720874786377), (41, 0.3017163835465908), (8, 0.3021107614040375), (45, 0.30623265355825424), (5, 0.3078044727444649), (42, 0.30812253803014755), (43, 0.3184373639523983), (44, 0.33906228840351105), (4, 0.35866326466202736), (1, 0.39840229228138924), (18, 0.6120230033993721), (36, 0.6364179477095604)]
computing accuracy for after removing block 13 . block score: 0.2036137469112873
removed block 13 current accuracy 0.939 loss from initial  0.01540000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.210805. All blocks and scores: [(19, 0.2108053844422102), (23, 0.21254952438175678), (21, 0.21701538562774658), (14, 0.21866551227867603), (25, 0.22032584808766842), (24, 0.22427263483405113), (6, 0.22428541630506516), (22, 0.2263723649084568), (51, 0.22637609764933586), (52, 0.22874045930802822), (3, 0.23885414004325867), (15, 0.24357419461011887), (49, 0.24791607819497585), (2, 0.24862674996256828), (16, 0.24878105148673058), (10, 0.2509586103260517), (50, 0.2542945258319378), (7, 0.2577207498252392), (37, 0.2600444182753563), (12, 0.2627381645143032), (11, 0.2635774165391922), (17, 0.2649110108613968), (47, 0.27114636451005936), (9, 0.27560747414827347), (48, 0.2812098413705826), (0, 0.2887451499700546), (46, 0.29479002207517624), (38, 0.30091768130660057), (40, 0.3019080348312855), (41, 0.30196811258792877), (8, 0.3021107614040375), (45, 0.3036384731531143), (39, 0.3054923191666603), (42, 0.307764682918787), (5, 0.3078044727444649), (43, 0.3178507797420025), (44, 0.33700744062662125), (4, 0.35866326466202736), (1, 0.39840229228138924), (18, 0.6101700067520142), (36, 0.6385301500558853)]
computing accuracy for after removing block 19 . block score: 0.2108053844422102
removed block 19 current accuracy 0.9322 loss from initial  0.022199999999999998
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.211922. All blocks and scores: [(25, 0.21192192286252975), (23, 0.21195852756500244), (21, 0.21350763738155365), (14, 0.21866551227867603), (24, 0.21975583769381046), (22, 0.2226158306002617), (51, 0.2229159064590931), (6, 0.22428541630506516), (52, 0.22439313866198063), (3, 0.23885414004325867), (15, 0.24357419461011887), (49, 0.24482430703938007), (2, 0.24862674996256828), (16, 0.24878105148673058), (10, 0.2509586103260517), (50, 0.2518406417220831), (37, 0.2539023607969284), (7, 0.2577207498252392), (12, 0.2627381645143032), (11, 0.2635774165391922), (17, 0.2649110108613968), (47, 0.26699190959334373), (9, 0.27560747414827347), (48, 0.2785409688949585), (0, 0.2887451499700546), (38, 0.2917665205895901), (41, 0.2927541509270668), (40, 0.2944078557193279), (39, 0.29469380900263786), (46, 0.2959430515766144), (42, 0.2971351593732834), (8, 0.3021107614040375), (45, 0.30283576995134354), (5, 0.3078044727444649), (43, 0.3128970265388489), (44, 0.3355056010186672), (4, 0.35866326466202736), (1, 0.39840229228138924), (18, 0.6101700067520142), (36, 0.626188151538372)]
computing accuracy for after removing block 25 . block score: 0.21192192286252975
removed block 25 current accuracy 0.923 loss from initial  0.031399999999999983
since last training loss: 0.02079999999999993 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.211959. All blocks and scores: [(23, 0.21195852756500244), (21, 0.21350763738155365), (51, 0.2177530974149704), (52, 0.2183951698243618), (14, 0.21866551227867603), (24, 0.21975583769381046), (22, 0.2226158306002617), (6, 0.22428541630506516), (3, 0.23885414004325867), (49, 0.24071723595261574), (37, 0.2409548182040453), (15, 0.24357419461011887), (2, 0.24862674996256828), (16, 0.24878105148673058), (50, 0.24989247135818005), (10, 0.2509586103260517), (7, 0.2577207498252392), (47, 0.2608879543840885), (12, 0.2627381645143032), (11, 0.2635774165391922), (17, 0.2649110108613968), (48, 0.2729153595864773), (38, 0.27536962926387787), (9, 0.27560747414827347), (41, 0.28230108693242073), (39, 0.28266914188861847), (40, 0.28407181426882744), (42, 0.288028959184885), (0, 0.2887451499700546), (46, 0.29328469187021255), (45, 0.29659096896648407), (8, 0.3021107614040375), (43, 0.30555494874715805), (5, 0.3078044727444649), (44, 0.32902319356799126), (4, 0.35866326466202736), (1, 0.39840229228138924), (36, 0.6096770614385605), (18, 0.6101700067520142)]
computing accuracy for after removing block 23 . block score: 0.21195852756500244
removed block 23 current accuracy 0.9074 loss from initial  0.04700000000000004
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 52, with score 0.212379. All blocks and scores: [(52, 0.2123786211013794), (21, 0.21350763738155365), (51, 0.21481428667902946), (24, 0.21742986887693405), (14, 0.21866551227867603), (22, 0.2226158306002617), (6, 0.22428541630506516), (37, 0.23055775836110115), (49, 0.23534144647419453), (3, 0.23885414004325867), (15, 0.24357419461011887), (50, 0.24607964046299458), (2, 0.24862674996256828), (16, 0.24878105148673058), (10, 0.2509586103260517), (47, 0.2525889575481415), (7, 0.2577207498252392), (12, 0.2627381645143032), (38, 0.2634393312036991), (11, 0.2635774165391922), (17, 0.2649110108613968), (48, 0.26847100257873535), (40, 0.27483827620744705), (39, 0.2750580869615078), (41, 0.2755432799458504), (9, 0.27560747414827347), (42, 0.2808254025876522), (0, 0.2887451499700546), (46, 0.29181722179055214), (45, 0.29445770010352135), (43, 0.30009080097079277), (8, 0.3021107614040375), (5, 0.3078044727444649), (44, 0.32259584963321686), (4, 0.35866326466202736), (1, 0.39840229228138924), (36, 0.602507084608078), (18, 0.6101700067520142)]
computing accuracy for after removing block 52 . block score: 0.2123786211013794
removed block 52 current accuracy 0.9074 loss from initial  0.04700000000000004
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.213508. All blocks and scores: [(21, 0.21350763738155365), (51, 0.21481428667902946), (24, 0.21742986887693405), (14, 0.21866551227867603), (22, 0.2226158306002617), (6, 0.22428541630506516), (37, 0.23055775836110115), (49, 0.23534144647419453), (3, 0.23885414004325867), (15, 0.24357419461011887), (50, 0.24607964046299458), (2, 0.24862674996256828), (16, 0.24878105148673058), (10, 0.2509586103260517), (47, 0.2525889575481415), (7, 0.2577207498252392), (12, 0.2627381645143032), (38, 0.2634393312036991), (11, 0.2635774165391922), (17, 0.2649110108613968), (48, 0.26847100257873535), (40, 0.27483827620744705), (39, 0.2750580869615078), (41, 0.2755432799458504), (9, 0.27560747414827347), (42, 0.2808254025876522), (0, 0.2887451499700546), (46, 0.29181722179055214), (45, 0.29445770010352135), (43, 0.30009080097079277), (8, 0.3021107614040375), (5, 0.3078044727444649), (44, 0.32259584963321686), (4, 0.35866326466202736), (1, 0.39840229228138924), (36, 0.602507084608078), (18, 0.6101700067520142)]
computing accuracy for after removing block 21 . block score: 0.21350763738155365
removed block 21 current accuracy 0.8792 loss from initial  0.07520000000000004
training start
training epoch 0 val accuracy 0.843 topk_dict {'top1': 0.843} is_best False lr [0.1]
training epoch 1 val accuracy 0.8024 topk_dict {'top1': 0.8024} is_best False lr [0.1]
training epoch 2 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 3 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 6 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 7 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 8 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best True lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.214692. All blocks and scores: [(3, 0.21469243243336678), (2, 0.2248799279332161), (6, 0.23500039242208004), (14, 0.2388348337262869), (7, 0.24779351614415646), (16, 0.2507812138646841), (10, 0.25453921034932137), (15, 0.2563738115131855), (51, 0.2694854065775871), (37, 0.2752281241118908), (11, 0.27666811272501945), (49, 0.27696507424116135), (22, 0.2779022753238678), (12, 0.28206487372517586), (50, 0.2842384800314903), (47, 0.28448136150836945), (24, 0.28699810802936554), (0, 0.2875196635723114), (17, 0.2949487753212452), (9, 0.29703470319509506), (48, 0.30638252198696136), (8, 0.3082261085510254), (42, 0.3108650930225849), (39, 0.3115503638982773), (38, 0.31233377754688263), (45, 0.31324608996510506), (41, 0.3145183436572552), (40, 0.3156825825572014), (46, 0.3168143145740032), (43, 0.31849172711372375), (5, 0.31969228759407997), (44, 0.3511232100427151), (4, 0.35575904324650764), (1, 0.39423783868551254), (18, 0.6294181272387505), (36, 0.691243477165699)]
computing accuracy for after removing block 3 . block score: 0.21469243243336678
removed block 3 current accuracy 0.9376 loss from initial  0.016800000000000037
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 2, with score 0.224880. All blocks and scores: [(2, 0.2248799279332161), (6, 0.23796327225863934), (14, 0.24259299412369728), (16, 0.24536453932523727), (7, 0.2504789885133505), (15, 0.2505463473498821), (10, 0.2591792233288288), (37, 0.2701580971479416), (51, 0.27033697068691254), (49, 0.27481647953391075), (11, 0.2760522812604904), (22, 0.2776436358690262), (12, 0.28077003359794617), (47, 0.282240804284811), (24, 0.2834518067538738), (50, 0.2840288579463959), (0, 0.2875196635723114), (17, 0.2916097342967987), (9, 0.29346147924661636), (8, 0.305563498288393), (39, 0.3057824596762657), (48, 0.30632032081484795), (38, 0.30790820345282555), (45, 0.3095349445939064), (40, 0.3097141236066818), (42, 0.3111314959824085), (41, 0.31141769513487816), (43, 0.3159417286515236), (46, 0.3160609342157841), (5, 0.3190179355442524), (44, 0.3467031754553318), (4, 0.35905196890234947), (1, 0.39423783868551254), (18, 0.6219869628548622), (36, 0.6799237355589867)]
computing accuracy for after removing block 2 . block score: 0.2248799279332161
removed block 2 current accuracy 0.9288 loss from initial  0.025600000000000067
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 6, with score 0.237894. All blocks and scores: [(6, 0.23789383843541145), (16, 0.24256843887269497), (14, 0.2442668378353119), (7, 0.2476728968322277), (15, 0.24907949194312096), (10, 0.25709888711571693), (37, 0.266178660094738), (51, 0.26800519973039627), (49, 0.27086080610752106), (22, 0.27476244047284126), (11, 0.2748051732778549), (47, 0.2781040742993355), (12, 0.2795552462339401), (24, 0.28007879480719566), (50, 0.281367938965559), (0, 0.2875196635723114), (17, 0.28852611780166626), (9, 0.29092004895210266), (39, 0.3019527234137058), (38, 0.30335400998592377), (40, 0.30383069813251495), (48, 0.30422187969088554), (45, 0.30452945455908775), (8, 0.3055609129369259), (41, 0.3073115274310112), (42, 0.30840807408094406), (43, 0.31318459287285805), (46, 0.31417614966630936), (5, 0.31817717105150223), (44, 0.3423824571073055), (4, 0.361470278352499), (1, 0.39423783868551254), (18, 0.6154334172606468), (36, 0.6710996702313423)]
computing accuracy for after removing block 6 . block score: 0.23789383843541145
removed block 6 current accuracy 0.9028 loss from initial  0.05159999999999998
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 16, with score 0.222388. All blocks and scores: [(16, 0.222388269379735), (15, 0.2380986548960209), (14, 0.24090281128883362), (7, 0.25346412137150764), (10, 0.2604561671614647), (12, 0.26536812260746956), (51, 0.2658287137746811), (37, 0.26644491776824), (49, 0.266725592315197), (11, 0.2680283486843109), (47, 0.26920029893517494), (22, 0.2707986645400524), (17, 0.2731551416218281), (24, 0.2738891988992691), (50, 0.28306590020656586), (9, 0.28495365753769875), (0, 0.2875196635723114), (45, 0.29528477042913437), (38, 0.2999345324933529), (40, 0.3015713356435299), (41, 0.30158839374780655), (39, 0.3030095025897026), (42, 0.3038664571940899), (8, 0.30666642636060715), (48, 0.3075655624270439), (46, 0.3133271411061287), (43, 0.31381190195679665), (5, 0.31817717105150223), (44, 0.3371393047273159), (4, 0.361470278352499), (1, 0.39423783868551254), (18, 0.6171050891280174), (36, 0.6713281646370888)]
computing accuracy for after removing block 16 . block score: 0.222388269379735
removed block 16 current accuracy 0.8882 loss from initial  0.06620000000000004
since last training loss: 0.05300000000000005 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 15, with score 0.238099. All blocks and scores: [(15, 0.2380986548960209), (14, 0.24090281128883362), (7, 0.25346412137150764), (10, 0.2604561671614647), (22, 0.2624385617673397), (51, 0.26351025328040123), (37, 0.26436420157551765), (49, 0.2645016349852085), (12, 0.26536812260746956), (47, 0.2671247534453869), (11, 0.2680283486843109), (24, 0.27419543266296387), (50, 0.28400371968746185), (9, 0.28495365753769875), (0, 0.2875196635723114), (45, 0.29502252489328384), (41, 0.29955698549747467), (40, 0.30045105889439583), (48, 0.3021567650139332), (38, 0.30245279520750046), (42, 0.30473631247878075), (8, 0.30666642636060715), (39, 0.3077649064362049), (46, 0.31100283563137054), (43, 0.31538620963692665), (5, 0.31817717105150223), (17, 0.3231545314192772), (44, 0.3356539122760296), (4, 0.361470278352499), (1, 0.39423783868551254), (18, 0.604699581861496), (36, 0.670610785484314)]
computing accuracy for after removing block 15 . block score: 0.2380986548960209
removed block 15 current accuracy 0.855 loss from initial  0.09940000000000004
since last training loss: 0.08620000000000005 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 14, with score 0.240903. All blocks and scores: [(14, 0.24090281128883362), (22, 0.25064970180392265), (7, 0.25346412137150764), (37, 0.2543439343571663), (51, 0.2583005353808403), (47, 0.2593073807656765), (49, 0.260454885661602), (10, 0.2604561671614647), (12, 0.26536812260746956), (11, 0.2680283486843109), (24, 0.27004489302635193), (9, 0.28495365753769875), (50, 0.2854955643415451), (0, 0.2875196635723114), (45, 0.29112450405955315), (41, 0.29224055632948875), (40, 0.29634832590818405), (48, 0.2971646152436733), (38, 0.3014737293124199), (42, 0.3015604615211487), (39, 0.30555083602666855), (8, 0.30666642636060715), (46, 0.30965667963027954), (43, 0.3160422742366791), (5, 0.31817717105150223), (44, 0.33006617799401283), (17, 0.360819224268198), (4, 0.361470278352499), (1, 0.39423783868551254), (18, 0.5885483473539352), (36, 0.6648745164275169)]
computing accuracy for after removing block 14 . block score: 0.24090281128883362
removed block 14 current accuracy 0.7658 loss from initial  0.1886
since last training loss: 0.1754 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 22, with score 0.243919. All blocks and scores: [(22, 0.24391929246485233), (47, 0.24997665733098984), (51, 0.2507056724280119), (37, 0.2530902996659279), (7, 0.25346412137150764), (49, 0.2562221996486187), (10, 0.2604561671614647), (12, 0.26536812260746956), (24, 0.2663219943642616), (11, 0.2680283486843109), (41, 0.28176747262477875), (45, 0.2828378528356552), (9, 0.28495365753769875), (50, 0.28602925315499306), (0, 0.2875196635723114), (48, 0.2898850180208683), (40, 0.29260582849383354), (42, 0.29802294820547104), (46, 0.3063071295619011), (8, 0.30666642636060715), (38, 0.3079330027103424), (39, 0.31678082421422005), (5, 0.31817717105150223), (43, 0.32307925447821617), (44, 0.32523316890001297), (4, 0.361470278352499), (17, 0.38377540931105614), (1, 0.39423783868551254), (18, 0.5886679142713547), (36, 0.6736208721995354)]
computing accuracy for after removing block 22 . block score: 0.24391929246485233
removed block 22 current accuracy 0.7112 loss from initial  0.24319999999999997
since last training loss: 0.22999999999999998 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.246672. All blocks and scores: [(37, 0.2466716505587101), (47, 0.2473551481962204), (51, 0.25114006735384464), (49, 0.2534213736653328), (7, 0.25346412137150764), (24, 0.2598951756954193), (10, 0.2604561671614647), (12, 0.26536812260746956), (11, 0.2680283486843109), (41, 0.2704988531768322), (50, 0.2766501009464264), (40, 0.2772705629467964), (45, 0.2786075621843338), (48, 0.2812782861292362), (9, 0.28495365753769875), (42, 0.28549516573548317), (0, 0.2875196635723114), (38, 0.2881058044731617), (8, 0.30666642636060715), (46, 0.3127502240240574), (39, 0.3137427680194378), (5, 0.31817717105150223), (43, 0.3248078301548958), (44, 0.329157043248415), (4, 0.361470278352499), (17, 0.38377540931105614), (1, 0.39423783868551254), (18, 0.5886679142713547), (36, 0.6759186461567879)]
computing accuracy for after removing block 37 . block score: 0.2466716505587101
removed block 37 current accuracy 0.6814 loss from initial  0.273
since last training loss: 0.25980000000000003 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 47, with score 0.239791. All blocks and scores: [(47, 0.2397905457764864), (51, 0.2504025921225548), (49, 0.25064861960709095), (7, 0.25346412137150764), (24, 0.2598951756954193), (10, 0.2604561671614647), (41, 0.26141519099473953), (12, 0.26536812260746956), (11, 0.2680283486843109), (40, 0.26831114664673805), (45, 0.2704543024301529), (42, 0.27491312846541405), (50, 0.2750696465373039), (48, 0.2794499285519123), (9, 0.28495365753769875), (0, 0.2875196635723114), (38, 0.29115723446011543), (8, 0.30666642636060715), (46, 0.30700936913490295), (39, 0.3127046301960945), (5, 0.31817717105150223), (43, 0.31960612162947655), (44, 0.3263544961810112), (4, 0.361470278352499), (17, 0.38377540931105614), (1, 0.39423783868551254), (18, 0.5886679142713547), (36, 0.6759186461567879)]
computing accuracy for after removing block 47 . block score: 0.2397905457764864
removed block 47 current accuracy 0.6588 loss from initial  0.2956
training start
training epoch 0 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best True lr [0.1]
training epoch 1 val accuracy 0.867 topk_dict {'top1': 0.867} is_best True lr [0.1]
training epoch 2 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 3 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 4 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 5 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 7 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 8 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 9 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
