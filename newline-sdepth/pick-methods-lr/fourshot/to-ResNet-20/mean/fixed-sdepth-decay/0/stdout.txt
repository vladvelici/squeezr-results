start iteration 0
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778), (53, 0.02245476096868515)]
computing accuracy for after removing block 53 . block score: 0.02245476096868515
removed block 53 current accuracy 0.9532 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778)]
computing accuracy for after removing block 52 . block score: 0.023782813921570778
removed block 52 current accuracy 0.9534 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347)]
computing accuracy for after removing block 51 . block score: 0.026051300577819347
removed block 51 current accuracy 0.953 loss from initial  0.0014000000000000679
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383)]
computing accuracy for after removing block 50 . block score: 0.028078997507691383
removed block 50 current accuracy 0.951 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694)]
computing accuracy for after removing block 49 . block score: 0.030814231373369694
removed block 49 current accuracy 0.9494 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084)]
computing accuracy for after removing block 48 . block score: 0.034880238585174084
removed block 48 current accuracy 0.9462 loss from initial  0.008199999999999985
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636)]
computing accuracy for after removing block 47 . block score: 0.03726085647940636
removed block 47 current accuracy 0.9426 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807)]
computing accuracy for after removing block 46 . block score: 0.04001962952315807
removed block 46 current accuracy 0.9372 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677)]
computing accuracy for after removing block 45 . block score: 0.04362349584698677
removed block 45 current accuracy 0.9292 loss from initial  0.0252
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946)]
computing accuracy for after removing block 44 . block score: 0.04579608142375946
removed block 44 current accuracy 0.919 loss from initial  0.03539999999999999
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284)]
computing accuracy for after removing block 43 . block score: 0.04886435717344284
removed block 43 current accuracy 0.905 loss from initial  0.0494
training start
training epoch 0 val accuracy 0.8252 topk_dict {'top1': 0.8252} is_best False lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 2 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 3 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 4 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 5 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 6 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 7 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (32, 0.06617472134530544), (33, 0.06506830640137196), (34, 0.06278614513576031), (35, 0.05967865698039532), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177), (42, 0.07039345242083073)]
computing accuracy for after removing block 35 . block score: 0.05967865698039532
removed block 35 current accuracy 0.946 loss from initial  0.008400000000000074
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (32, 0.06617472134530544), (33, 0.06506830640137196), (34, 0.06278614513576031), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177), (42, 0.07039345242083073)]
computing accuracy for after removing block 34 . block score: 0.06278614513576031
removed block 34 current accuracy 0.9452 loss from initial  0.009199999999999986
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (32, 0.06617472134530544), (33, 0.06506830640137196), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177), (42, 0.07039345242083073)]
computing accuracy for after removing block 33 . block score: 0.06506830640137196
removed block 33 current accuracy 0.9406 loss from initial  0.013800000000000034
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (32, 0.06617472134530544), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177), (42, 0.07039345242083073)]
computing accuracy for after removing block 32 . block score: 0.06617472134530544
removed block 32 current accuracy 0.9394 loss from initial  0.015000000000000013
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177), (42, 0.07039345242083073)]
computing accuracy for after removing block 42 . block score: 0.07039345242083073
removed block 42 current accuracy 0.9142 loss from initial  0.040200000000000014
since last training loss: 0.03400000000000003 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (31, 0.07108249515295029), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177)]
computing accuracy for after removing block 31 . block score: 0.07108249515295029
removed block 31 current accuracy 0.9112 loss from initial  0.043200000000000016
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (30, 0.07451014593243599), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177)]
computing accuracy for after removing block 30 . block score: 0.07451014593243599
removed block 30 current accuracy 0.9054 loss from initial  0.049000000000000044
since last training loss: 0.04280000000000006 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491), (41, 0.07495294138789177)]
computing accuracy for after removing block 41 . block score: 0.07495294138789177
removed block 41 current accuracy 0.8554 loss from initial  0.09899999999999998
since last training loss: 0.0928 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (29, 0.07651926204562187), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491)]
computing accuracy for after removing block 29 . block score: 0.07651926204562187
removed block 29 current accuracy 0.8398 loss from initial  0.11460000000000004
since last training loss: 0.10840000000000005 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (36, 0.24667856469750404), (37, 0.07725868374109268), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491)]
computing accuracy for after removing block 37 . block score: 0.07725868374109268
removed block 37 current accuracy 0.8072 loss from initial  0.1472
since last training loss: 0.14100000000000001 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09076303616166115), (1, 0.11131463944911957), (2, 0.09907889366149902), (3, 0.108160849660635), (4, 0.12145164981484413), (5, 0.12091583013534546), (6, 0.10783317312598228), (7, 0.1178203746676445), (8, 0.1297469213604927), (9, 0.13059042766690254), (10, 0.12720457464456558), (11, 0.12245574221014977), (12, 0.12766041606664658), (13, 0.11590616405010223), (14, 0.11687926575541496), (15, 0.12271753698587418), (16, 0.11993258446455002), (17, 0.11798644065856934), (18, 0.36813513934612274), (19, 0.0981539748609066), (20, 0.09466793015599251), (21, 0.09736930206418037), (22, 0.09300630539655685), (23, 0.09267273172736168), (24, 0.0861116461455822), (25, 0.08722204715013504), (26, 0.085885189473629), (27, 0.08156537637114525), (28, 0.07858449220657349), (36, 0.24667856469750404), (38, 0.07910669222474098), (39, 0.07762076705694199), (40, 0.07728404924273491)]
computing accuracy for after removing block 40 . block score: 0.07728404924273491
removed block 40 current accuracy 0.7442 loss from initial  0.21020000000000005
training start
training epoch 0 val accuracy 0.8124 topk_dict {'top1': 0.8124} is_best True lr [0.1]
training epoch 1 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.1]
training epoch 2 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best True lr [0.1]
training epoch 3 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.1]
training epoch 4 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best True lr [0.1]
training epoch 6 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 7 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 8 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 9 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09332268312573433), (1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (24, 0.10231514275074005), (25, 0.10516674444079399), (26, 0.1037912666797638), (27, 0.1023397296667099), (28, 0.10171134397387505), (36, 0.27352655678987503), (38, 0.10933669283986092), (39, 0.0985180027782917)]
computing accuracy for after removing block 0 . block score: 0.09332268312573433
removed block 0 current accuracy 0.9326 loss from initial  0.02180000000000004
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (24, 0.10231514275074005), (25, 0.10516674444079399), (26, 0.1037912666797638), (27, 0.1023397296667099), (28, 0.10171134397387505), (36, 0.27352655678987503), (38, 0.10933669283986092), (39, 0.0985180027782917)]
computing accuracy for after removing block 39 . block score: 0.0985180027782917
removed block 39 current accuracy 0.8262 loss from initial  0.12819999999999998
since last training loss: 0.11839999999999995 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (24, 0.10231514275074005), (25, 0.10516674444079399), (26, 0.1037912666797638), (27, 0.1023397296667099), (28, 0.10171134397387505), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 28 . block score: 0.10171134397387505
removed block 28 current accuracy 0.8026 loss from initial  0.15180000000000005
since last training loss: 0.14200000000000002 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (24, 0.10231514275074005), (25, 0.10516674444079399), (26, 0.1037912666797638), (27, 0.1023397296667099), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 24 . block score: 0.10231514275074005
removed block 24 current accuracy 0.7794 loss from initial  0.17500000000000004
since last training loss: 0.1652 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (25, 0.10516674444079399), (26, 0.1037912666797638), (27, 0.1023397296667099), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 27 . block score: 0.1023397296667099
removed block 27 current accuracy 0.7346 loss from initial  0.2198
since last training loss: 0.20999999999999996 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (2, 0.10316891595721245), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (25, 0.10516674444079399), (26, 0.1037912666797638), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 2 . block score: 0.10316891595721245
removed block 2 current accuracy 0.68 loss from initial  0.2744
since last training loss: 0.26459999999999995 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (25, 0.10516674444079399), (26, 0.1037912666797638), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 26 . block score: 0.1037912666797638
removed block 26 current accuracy 0.6254 loss from initial  0.32900000000000007
since last training loss: 0.31920000000000004 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (25, 0.10516674444079399), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 25 . block score: 0.10516674444079399
removed block 25 current accuracy 0.5304 loss from initial  0.42400000000000004
since last training loss: 0.4142 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (20, 0.10851013660430908), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 20 . block score: 0.10851013660430908
removed block 20 current accuracy 0.4882 loss from initial  0.4662
since last training loss: 0.4564 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (21, 0.11225339770317078), (22, 0.1085674799978733), (23, 0.11050131544470787), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 22 . block score: 0.1085674799978733
removed block 22 current accuracy 0.4232 loss from initial  0.5312
since last training loss: 0.5214 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.11899968609213829), (3, 0.11362475901842117), (4, 0.12781967967748642), (5, 0.1289045289158821), (6, 0.11346673220396042), (7, 0.12309536710381508), (8, 0.13708386570215225), (9, 0.13810625672340393), (10, 0.13583949208259583), (11, 0.132338248193264), (12, 0.13395962864160538), (13, 0.124880101531744), (14, 0.12387358024716377), (15, 0.1317862942814827), (16, 0.12751354277133942), (17, 0.12908484786748886), (18, 0.39228011667728424), (19, 0.1120164692401886), (21, 0.11225339770317078), (23, 0.11050131544470787), (36, 0.27352655678987503), (38, 0.10933669283986092)]
computing accuracy for after removing block 38 . block score: 0.10933669283986092
removed block 38 current accuracy 0.352 loss from initial  0.6024
training start
training epoch 0 val accuracy 0.816 topk_dict {'top1': 0.816} is_best True lr [0.1]
training epoch 1 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.1]
training epoch 2 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.1]
training epoch 3 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best False lr [0.1]
training epoch 4 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best True lr [0.1]
training epoch 5 val accuracy 0.766 topk_dict {'top1': 0.766} is_best False lr [0.1]
training epoch 6 val accuracy 0.849 topk_dict {'top1': 0.849} is_best True lr [0.1]
training epoch 7 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best True lr [0.1]
training epoch 8 val accuracy 0.805 topk_dict {'top1': 0.805} is_best False lr [0.1]
training epoch 9 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 10 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.922200)
finished training. finished 50 epochs. accuracy 0.9222 topk_dict {'top1': 0.9222}
start iteration 33
(cache recomputed : MEAN) score log [(1, 0.13651780039072037), (3, 0.1290971264243126), (4, 0.1424272209405899), (5, 0.14724743366241455), (6, 0.12658951431512833), (7, 0.13464491814374924), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (14, 0.13728654757142067), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 6 . block score: 0.12658951431512833
removed block 6 current accuracy 0.9098 loss from initial  0.04459999999999997
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(1, 0.13651780039072037), (3, 0.1290971264243126), (4, 0.1424272209405899), (5, 0.14724743366241455), (7, 0.13464491814374924), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (14, 0.13728654757142067), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 3 . block score: 0.1290971264243126
removed block 3 current accuracy 0.8798 loss from initial  0.0746
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(1, 0.13651780039072037), (4, 0.1424272209405899), (5, 0.14724743366241455), (7, 0.13464491814374924), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (14, 0.13728654757142067), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 7 . block score: 0.13464491814374924
removed block 7 current accuracy 0.8338 loss from initial  0.12060000000000004
since last training loss: 0.08840000000000003 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(1, 0.13651780039072037), (4, 0.1424272209405899), (5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (14, 0.13728654757142067), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 1 . block score: 0.13651780039072037
removed block 1 current accuracy 0.6002 loss from initial  0.35420000000000007
since last training loss: 0.32200000000000006 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.1424272209405899), (5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (14, 0.13728654757142067), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 14 . block score: 0.13728654757142067
removed block 14 current accuracy 0.5456 loss from initial  0.40880000000000005
since last training loss: 0.37660000000000005 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.1424272209405899), (5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (13, 0.140083909034729), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 13 . block score: 0.140083909034729
removed block 13 current accuracy 0.4812 loss from initial  0.4732
since last training loss: 0.441 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(4, 0.1424272209405899), (5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 4 . block score: 0.1424272209405899
removed block 4 current accuracy 0.176 loss from initial  0.7784
since last training loss: 0.7462 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (15, 0.1452755257487297), (16, 0.1437433734536171), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 16 . block score: 0.1437433734536171
removed block 16 current accuracy 0.178 loss from initial  0.7764
since last training loss: 0.7442 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (15, 0.1452755257487297), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 15 . block score: 0.1452755257487297
removed block 15 current accuracy 0.1558 loss from initial  0.7986
since last training loss: 0.7664 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (17, 0.14579765498638153), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 17 . block score: 0.14579765498638153
removed block 17 current accuracy 0.1292 loss from initial  0.8252
since last training loss: 0.793 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (12, 0.14652377367019653), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 12 . block score: 0.14652377367019653
removed block 12 current accuracy 0.1046 loss from initial  0.8498
since last training loss: 0.8176 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(5, 0.14724743366241455), (8, 0.15354563295841217), (9, 0.14910252392292023), (10, 0.14888816326856613), (11, 0.14715616405010223), (18, 0.42772118002176285), (19, 0.16030266135931015), (21, 0.1696586012840271), (23, 0.16915902495384216), (36, 0.2710787355899811)]
computing accuracy for after removing block 11 . block score: 0.14715616405010223
removed block 11 current accuracy 0.0972 loss from initial  0.8572000000000001
training start
training epoch 0 val accuracy 0.8066 topk_dict {'top1': 0.8066} is_best True lr [0.1]
training epoch 1 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best True lr [0.1]
training epoch 2 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best False lr [0.1]
training epoch 3 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best False lr [0.1]
training epoch 4 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best True lr [0.1]
training epoch 5 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 6 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 7 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.1]
training epoch 8 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 9 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.1]
training epoch 10 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.920800)
finished training. finished 50 epochs. accuracy 0.9208 topk_dict {'top1': 0.9208}
