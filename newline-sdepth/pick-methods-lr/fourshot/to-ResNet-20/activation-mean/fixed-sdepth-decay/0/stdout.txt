start iteration 0
[activation mean]: block to remove picked: 35, with score 0.094478. All blocks and scores: [(35, 0.09447801485657692), (34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.14710238575935364), (19, 0.14895895309746265), (53, 0.1498922035098076), (52, 0.15163039043545723), (51, 0.1535380631685257), (13, 0.15705686062574387), (14, 0.16249225474894047), (38, 0.16445158794522285), (50, 0.16464474610984325), (49, 0.1657810639590025), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (40, 0.173427015542984), (16, 0.17345409654080868), (41, 0.17369753867387772), (11, 0.17475955933332443), (46, 0.17609802819788456), (45, 0.17827162519097328), (39, 0.1792436372488737), (44, 0.18025114387273788), (48, 0.18066065199673176), (42, 0.18066276982426643), (47, 0.18073148280382156), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (43, 0.189305879175663), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.23272303864359856), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 35 . block score: 0.09447801485657692
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.096040. All blocks and scores: [(34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.1407872699201107), (53, 0.14861096628010273), (19, 0.14895895309746265), (52, 0.14969445951282978), (51, 0.1523898020386696), (13, 0.15705686062574387), (38, 0.15781539678573608), (14, 0.16249225474894047), (50, 0.16313881427049637), (49, 0.16411315463483334), (40, 0.1689014621078968), (41, 0.1690248530358076), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (39, 0.17247052490711212), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (46, 0.17373871989548206), (11, 0.17475955933332443), (45, 0.17579046078026295), (42, 0.1771144587546587), (44, 0.17722493782639503), (47, 0.17847622744739056), (48, 0.1788573693484068), (8, 0.18169353157281876), (12, 0.18286443874239922), (43, 0.18561581149697304), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.2266793828457594), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 34 . block score: 0.09604021441191435
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.097944. All blocks and scores: [(32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13551420159637928), (53, 0.14707430079579353), (52, 0.14760426990687847), (19, 0.14895895309746265), (51, 0.15091686882078648), (38, 0.1523499172180891), (13, 0.15705686062574387), (50, 0.16150624863803387), (14, 0.16249225474894047), (49, 0.1625587809830904), (40, 0.16517788171768188), (41, 0.16536311618983746), (39, 0.16688678227365017), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (46, 0.1715139839798212), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (45, 0.1736477129161358), (42, 0.1742321215569973), (11, 0.17475955933332443), (44, 0.1747924704104662), (47, 0.17631406895816326), (48, 0.17726918868720531), (8, 0.18169353157281876), (43, 0.1826457940042019), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (36, 0.221288425847888), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 32 . block score: 0.09794430993497372
removed block 32 current accuracy 0.945 loss from initial  0.009400000000000075
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 33, with score 0.096237. All blocks and scores: [(33, 0.0962365735322237), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13045251369476318), (53, 0.14460941962897778), (52, 0.14462984167039394), (38, 0.1469358094036579), (51, 0.1486178170889616), (19, 0.14895895309746265), (13, 0.15705686062574387), (50, 0.15898261778056622), (49, 0.1601924430578947), (39, 0.1610004734247923), (41, 0.16117839701473713), (40, 0.16137539595365524), (14, 0.16249225474894047), (46, 0.16855736821889877), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (45, 0.1705855056643486), (42, 0.17088175937533379), (44, 0.17191905342042446), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (47, 0.17325890436768532), (16, 0.17345409654080868), (48, 0.1746351718902588), (11, 0.17475955933332443), (43, 0.17927574925124645), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21651554107666016), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 33 . block score: 0.0962365735322237
removed block 33 current accuracy 0.9408 loss from initial  0.013600000000000056
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 31, with score 0.106299. All blocks and scores: [(31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (37, 0.1261464450508356), (21, 0.1281397920101881), (52, 0.141027070581913), (53, 0.14170901477336884), (38, 0.14201517030596733), (51, 0.14598987624049187), (19, 0.14895895309746265), (39, 0.15555569157004356), (50, 0.15602300502359867), (13, 0.15705686062574387), (49, 0.15735810063779354), (41, 0.15751718543469906), (40, 0.15766894072294235), (14, 0.16249225474894047), (46, 0.16544132120907307), (45, 0.16723843477666378), (42, 0.16781402193009853), (44, 0.16861379332840443), (6, 0.16913926228880882), (47, 0.17008974589407444), (15, 0.17030494660139084), (3, 0.17048806883394718), (48, 0.17144453153014183), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (43, 0.1758242715150118), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21325702220201492), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 31 . block score: 0.10629933141171932
removed block 31 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 27, with score 0.107886. All blocks and scores: [(27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (37, 0.12083858530968428), (20, 0.12209091056138277), (21, 0.1281397920101881), (38, 0.13578535057604313), (52, 0.13683941774070263), (53, 0.13806491903960705), (51, 0.1427531000226736), (39, 0.14883904717862606), (19, 0.14895895309746265), (50, 0.1524738073348999), (41, 0.15277637541294098), (40, 0.15300416387617588), (49, 0.15408698096871376), (13, 0.15705686062574387), (46, 0.16158179938793182), (14, 0.16249225474894047), (45, 0.16341477446258068), (42, 0.1641642488539219), (44, 0.16474203765392303), (47, 0.1662686076015234), (48, 0.16778318211436272), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (43, 0.17166327871382236), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.2090455386787653), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 27 . block score: 0.10788614861667156
removed block 27 current accuracy 0.924 loss from initial  0.030399999999999983
since last training loss: 0.030399999999999983 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 28, with score 0.106738. All blocks and scores: [(28, 0.10673764999955893), (26, 0.11042157281190157), (30, 0.11067065969109535), (29, 0.11133305355906487), (24, 0.11232952307909727), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (37, 0.11763431876897812), (20, 0.12209091056138277), (21, 0.1281397920101881), (38, 0.1322858203202486), (52, 0.13285555504262447), (53, 0.13448705151677132), (51, 0.13945471122860909), (39, 0.14460883848369122), (19, 0.14895895309746265), (50, 0.1491220686584711), (41, 0.14991099573671818), (40, 0.15057450346648693), (49, 0.15146508067846298), (13, 0.15705686062574387), (46, 0.1585084218531847), (45, 0.16032307222485542), (42, 0.16191182099282742), (44, 0.1621392723172903), (14, 0.16249225474894047), (47, 0.16306034848093987), (48, 0.16480598971247673), (6, 0.16913926228880882), (43, 0.1691585797816515), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.20675696805119514), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 28 . block score: 0.10673764999955893
removed block 28 current accuracy 0.9088 loss from initial  0.045599999999999974
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 30, with score 0.109426. All blocks and scores: [(30, 0.10942596197128296), (29, 0.11006557941436768), (26, 0.11042157281190157), (24, 0.11232952307909727), (25, 0.11343235615640879), (23, 0.11373872216790915), (37, 0.11397116631269455), (22, 0.11607348453253508), (20, 0.12209091056138277), (52, 0.1276452001184225), (21, 0.1281397920101881), (38, 0.12814830243587494), (53, 0.12998243235051632), (51, 0.13509063608944416), (39, 0.13992793671786785), (50, 0.1448505874723196), (41, 0.14685502834618092), (40, 0.1476672012358904), (49, 0.14781243167817593), (19, 0.14895895309746265), (46, 0.15456506796181202), (45, 0.1561567336320877), (13, 0.15705686062574387), (44, 0.15868035145103931), (47, 0.15883814729750156), (42, 0.15912745893001556), (48, 0.16070632450282574), (14, 0.16249225474894047), (43, 0.16632746905088425), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.20438146404922009), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 30 . block score: 0.10942596197128296
removed block 30 current accuracy 0.8858 loss from initial  0.0686
since last training loss: 0.0686 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 29, with score 0.110066. All blocks and scores: [(29, 0.11006557941436768), (37, 0.11036087200045586), (26, 0.11042157281190157), (24, 0.11232952307909727), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (52, 0.12214420270174742), (38, 0.12343395035713911), (53, 0.12508574686944485), (21, 0.1281397920101881), (51, 0.13062750548124313), (39, 0.13458676636219025), (50, 0.1402657013386488), (41, 0.14357097260653973), (49, 0.14429350569844246), (40, 0.1446359045803547), (19, 0.14895895309746265), (46, 0.150791235268116), (45, 0.1522215474396944), (47, 0.15496998094022274), (44, 0.15500954166054726), (42, 0.15667841956019402), (48, 0.1567078810185194), (13, 0.15705686062574387), (14, 0.16249225474894047), (43, 0.16319439373910427), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.20264936238527298), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 29 . block score: 0.11006557941436768
removed block 29 current accuracy 0.8484 loss from initial  0.10599999999999998
since last training loss: 0.10599999999999998 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 37, with score 0.107011. All blocks and scores: [(37, 0.10701143741607666), (26, 0.11042157281190157), (24, 0.11232952307909727), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (52, 0.11677477322518826), (38, 0.11913189385086298), (53, 0.12010902538895607), (20, 0.12209091056138277), (51, 0.1260470673441887), (21, 0.1281397920101881), (39, 0.13014333695173264), (50, 0.13568492978811264), (49, 0.14074983820319176), (41, 0.14124692790210247), (40, 0.14258781261742115), (46, 0.14776249416172504), (19, 0.14895895309746265), (45, 0.14913098141551018), (47, 0.1520196497440338), (44, 0.15248003043234348), (48, 0.15296611189842224), (42, 0.15593615919351578), (13, 0.15705686062574387), (43, 0.1610369011759758), (14, 0.16249225474894047), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.20333525352180004), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 37 . block score: 0.10701143741607666
removed block 37 current accuracy 0.839 loss from initial  0.11540000000000006
since last training loss: 0.11540000000000006 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 52, with score 0.107801. All blocks and scores: [(52, 0.10780143830925226), (26, 0.11042157281190157), (53, 0.11198651231825352), (24, 0.11232952307909727), (25, 0.11343235615640879), (23, 0.11373872216790915), (38, 0.11566449329257011), (22, 0.11607348453253508), (51, 0.11818043421953917), (20, 0.12209091056138277), (39, 0.1251817001029849), (50, 0.12805110216140747), (21, 0.1281397920101881), (49, 0.13227111287415028), (41, 0.13504927791655064), (40, 0.13535837084054947), (46, 0.13895178213715553), (45, 0.14117915742099285), (48, 0.14357793889939785), (44, 0.1436984594911337), (47, 0.14464883878827095), (42, 0.147613275796175), (19, 0.14895895309746265), (43, 0.1526580210775137), (13, 0.15705686062574387), (14, 0.16249225474894047), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.20333525352180004), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 52 . block score: 0.10780143830925226
removed block 52 current accuracy 0.8406 loss from initial  0.11380000000000001
training start
training epoch 0 val accuracy 0.7484 topk_dict {'top1': 0.7484} is_best False lr [0.1]
training epoch 1 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best False lr [0.1]
training epoch 2 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best True lr [0.1]
training epoch 3 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.1]
training epoch 4 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 5 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.1]
training epoch 6 val accuracy 0.8294 topk_dict {'top1': 0.8294} is_best False lr [0.1]
training epoch 7 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.1]
training epoch 8 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 9 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.191712. All blocks and scores: [(25, 0.19171246327459812), (24, 0.1928680408746004), (3, 0.19917282834649086), (53, 0.20397518388926983), (20, 0.20643990114331245), (22, 0.20836490765213966), (7, 0.20939427614212036), (23, 0.2127322107553482), (21, 0.21300428919494152), (2, 0.21766841411590576), (26, 0.21916505135595798), (13, 0.22272567637264729), (14, 0.22276728600263596), (19, 0.22701945155858994), (11, 0.23545004799962044), (6, 0.2362444456666708), (12, 0.24444938637316227), (10, 0.2455131709575653), (51, 0.2481758575886488), (9, 0.2505731750279665), (50, 0.2546321675181389), (15, 0.25719742104411125), (16, 0.26043298095464706), (8, 0.2705829404294491), (0, 0.27072058245539665), (49, 0.2722616381943226), (39, 0.2836996875703335), (17, 0.28915266692638397), (48, 0.29235864803195), (5, 0.29344431683421135), (38, 0.2975980266928673), (46, 0.2993859201669693), (47, 0.3014579005539417), (40, 0.3029504790902138), (45, 0.3078923672437668), (42, 0.31198083609342575), (41, 0.312614094465971), (43, 0.31593531742691994), (4, 0.31867601722478867), (44, 0.3368537276983261), (1, 0.3647548146545887), (18, 0.5392604097723961), (36, 0.5643307790160179)]
computing accuracy for after removing block 25 . block score: 0.19171246327459812
removed block 25 current accuracy 0.9384 loss from initial  0.016000000000000014
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 53, with score 0.191827. All blocks and scores: [(53, 0.19182711653411388), (24, 0.1928680408746004), (3, 0.19917282834649086), (20, 0.20643990114331245), (22, 0.20836490765213966), (7, 0.20939427614212036), (23, 0.2127322107553482), (21, 0.21300428919494152), (2, 0.21766841411590576), (26, 0.21842856518924236), (13, 0.22272567637264729), (14, 0.22276728600263596), (19, 0.22701945155858994), (11, 0.23545004799962044), (6, 0.2362444456666708), (12, 0.24444938637316227), (51, 0.24516768008470535), (10, 0.2455131709575653), (50, 0.2501051388680935), (9, 0.2505731750279665), (15, 0.25719742104411125), (16, 0.26043298095464706), (49, 0.26915617287158966), (8, 0.2705829404294491), (0, 0.27072058245539665), (39, 0.2751813121140003), (38, 0.28654785454273224), (48, 0.28717294335365295), (17, 0.28915266692638397), (40, 0.2921435050666332), (5, 0.29344431683421135), (46, 0.2942415811121464), (47, 0.29641118273139), (41, 0.30231982469558716), (45, 0.3049700893461704), (42, 0.30574361234903336), (43, 0.3082532696425915), (4, 0.31867601722478867), (44, 0.3342292606830597), (1, 0.3647548146545887), (18, 0.5392604097723961), (36, 0.5546585768461227)]
computing accuracy for after removing block 53 . block score: 0.19182711653411388
removed block 53 current accuracy 0.9398 loss from initial  0.014600000000000057
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.192868. All blocks and scores: [(24, 0.1928680408746004), (3, 0.19917282834649086), (20, 0.20643990114331245), (22, 0.20836490765213966), (7, 0.20939427614212036), (23, 0.2127322107553482), (21, 0.21300428919494152), (2, 0.21766841411590576), (26, 0.21842856518924236), (13, 0.22272567637264729), (14, 0.22276728600263596), (19, 0.22701945155858994), (11, 0.23545004799962044), (6, 0.2362444456666708), (12, 0.24444938637316227), (51, 0.24516768008470535), (10, 0.2455131709575653), (50, 0.2501051388680935), (9, 0.2505731750279665), (15, 0.25719742104411125), (16, 0.26043298095464706), (49, 0.26915617287158966), (8, 0.2705829404294491), (0, 0.27072058245539665), (39, 0.2751813121140003), (38, 0.28654785454273224), (48, 0.28717294335365295), (17, 0.28915266692638397), (40, 0.2921435050666332), (5, 0.29344431683421135), (46, 0.2942415811121464), (47, 0.29641118273139), (41, 0.30231982469558716), (45, 0.3049700893461704), (42, 0.30574361234903336), (43, 0.3082532696425915), (4, 0.31867601722478867), (44, 0.3342292606830597), (1, 0.3647548146545887), (18, 0.5392604097723961), (36, 0.5546585768461227)]
computing accuracy for after removing block 24 . block score: 0.1928680408746004
removed block 24 current accuracy 0.9324 loss from initial  0.02200000000000002
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 3, with score 0.199173. All blocks and scores: [(3, 0.19917282834649086), (20, 0.20643990114331245), (22, 0.20836490765213966), (7, 0.20939427614212036), (26, 0.2119324430823326), (23, 0.2127322107553482), (21, 0.21300428919494152), (2, 0.21766841411590576), (13, 0.22272567637264729), (14, 0.22276728600263596), (19, 0.22701945155858994), (11, 0.23545004799962044), (6, 0.2362444456666708), (51, 0.24032747745513916), (12, 0.24444938637316227), (50, 0.2449525874108076), (10, 0.2455131709575653), (9, 0.2505731750279665), (15, 0.25719742104411125), (16, 0.26043298095464706), (39, 0.2628871090710163), (49, 0.264711182564497), (8, 0.2705829404294491), (0, 0.27072058245539665), (38, 0.27181799337267876), (40, 0.27731384709477425), (48, 0.28009143099188805), (46, 0.28908831626176834), (17, 0.28915266692638397), (41, 0.2901940755546093), (47, 0.29075467213988304), (5, 0.29344431683421135), (42, 0.2977716885507107), (45, 0.29949967935681343), (43, 0.29955295845866203), (4, 0.31867601722478867), (44, 0.33146433532238007), (1, 0.3647548146545887), (36, 0.5374230369925499), (18, 0.5392604097723961)]
computing accuracy for after removing block 3 . block score: 0.19917282834649086
removed block 3 current accuracy 0.9324 loss from initial  0.02200000000000002
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 7, with score 0.205061. All blocks and scores: [(7, 0.2050605323165655), (20, 0.2070724293589592), (22, 0.2091844119131565), (26, 0.2099219709634781), (21, 0.2137247659265995), (23, 0.2143514733761549), (2, 0.21766841411590576), (13, 0.2195561919361353), (14, 0.22092375718057156), (19, 0.2278440911322832), (11, 0.23213542997837067), (6, 0.23515968769788742), (51, 0.2400241233408451), (12, 0.2418762519955635), (50, 0.24588539823889732), (10, 0.2461548149585724), (9, 0.24738798663020134), (15, 0.2561194598674774), (16, 0.25705573707818985), (39, 0.26330843940377235), (49, 0.26472289487719536), (38, 0.2682172395288944), (0, 0.27072058245539665), (8, 0.2714846394956112), (40, 0.2732979767024517), (48, 0.2808773033320904), (17, 0.2862744629383087), (41, 0.28871362283825874), (47, 0.28970274701714516), (46, 0.28999046608805656), (42, 0.29683807119727135), (5, 0.2969331368803978), (45, 0.2990276925265789), (43, 0.29968273267149925), (4, 0.32356519252061844), (44, 0.32959524914622307), (1, 0.3647548146545887), (36, 0.5316175147891045), (18, 0.535103939473629)]
computing accuracy for after removing block 7 . block score: 0.2050605323165655
removed block 7 current accuracy 0.9302 loss from initial  0.0242
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 26, with score 0.206829. All blocks and scores: [(26, 0.20682938396930695), (22, 0.20767394080758095), (20, 0.20897460170090199), (21, 0.21270531602203846), (23, 0.21404868364334106), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (19, 0.22760101221501827), (11, 0.2302460428327322), (6, 0.23515968769788742), (51, 0.23995480500161648), (12, 0.24010520428419113), (15, 0.24576075933873653), (50, 0.2464202307164669), (9, 0.24653958529233932), (16, 0.24948204681277275), (10, 0.25468965992331505), (49, 0.2621004246175289), (39, 0.2621728628873825), (38, 0.2635320611298084), (40, 0.26916342601180077), (17, 0.270513117313385), (0, 0.27072058245539665), (48, 0.2807730846107006), (41, 0.2874778099358082), (46, 0.2885604240000248), (47, 0.28967852517962456), (8, 0.2931172773241997), (42, 0.29438416659832), (45, 0.2968689054250717), (5, 0.2969331368803978), (43, 0.2996796742081642), (4, 0.32356519252061844), (44, 0.325704138725996), (1, 0.3647548146545887), (36, 0.5269433483481407), (18, 0.5304391756653786)]
computing accuracy for after removing block 26 . block score: 0.20682938396930695
removed block 26 current accuracy 0.9198 loss from initial  0.034600000000000075
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 22, with score 0.207674. All blocks and scores: [(22, 0.20767394080758095), (20, 0.20897460170090199), (21, 0.21270531602203846), (23, 0.21404868364334106), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (19, 0.22760101221501827), (11, 0.2302460428327322), (51, 0.2330684307962656), (6, 0.23515968769788742), (12, 0.24010520428419113), (50, 0.24050564877688885), (15, 0.24576075933873653), (9, 0.24653958529233932), (38, 0.24680660292506218), (39, 0.2492877710610628), (16, 0.24948204681277275), (49, 0.25412485748529434), (10, 0.25468965992331505), (40, 0.25506406277418137), (17, 0.270513117313385), (0, 0.27072058245539665), (48, 0.2743956372141838), (41, 0.2769567295908928), (46, 0.28318311274051666), (42, 0.28432581946253777), (47, 0.2847111374139786), (45, 0.2901078388094902), (43, 0.29225316271185875), (8, 0.2931172773241997), (5, 0.2969331368803978), (44, 0.32309891656041145), (4, 0.32356519252061844), (1, 0.3647548146545887), (36, 0.5113571211695671), (18, 0.5304391756653786)]
computing accuracy for after removing block 22 . block score: 0.20767394080758095
removed block 22 current accuracy 0.9046 loss from initial  0.049800000000000066
since last training loss: 0.038000000000000034 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 20, with score 0.208975. All blocks and scores: [(20, 0.20897460170090199), (23, 0.2105746790766716), (21, 0.21270531602203846), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (19, 0.22760101221501827), (51, 0.22939352318644524), (11, 0.2302460428327322), (6, 0.23515968769788742), (38, 0.23551280237734318), (50, 0.23594667203724384), (12, 0.24010520428419113), (39, 0.24075073562562466), (40, 0.24280834570527077), (15, 0.24576075933873653), (9, 0.24653958529233932), (16, 0.24948204681277275), (49, 0.25105057284235954), (10, 0.25468965992331505), (41, 0.2691052295267582), (48, 0.26937010139226913), (17, 0.270513117313385), (0, 0.27072058245539665), (42, 0.2778540663421154), (46, 0.2798120751976967), (47, 0.2811046727001667), (45, 0.28481075912714005), (43, 0.28780556097626686), (8, 0.2931172773241997), (5, 0.2969331368803978), (44, 0.3231254070997238), (4, 0.32356519252061844), (1, 0.3647548146545887), (36, 0.5009687580168247), (18, 0.5304391756653786)]
computing accuracy for after removing block 20 . block score: 0.20897460170090199
removed block 20 current accuracy 0.8788 loss from initial  0.0756
since last training loss: 0.06379999999999997 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 23, with score 0.202656. All blocks and scores: [(23, 0.20265586115419865), (21, 0.2069986630231142), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (51, 0.22266480699181557), (38, 0.22577454522252083), (19, 0.22760101221501827), (11, 0.2302460428327322), (50, 0.2322188187390566), (40, 0.23406590893864632), (6, 0.23515968769788742), (39, 0.23520593158900738), (12, 0.24010520428419113), (15, 0.24576075933873653), (9, 0.24653958529233932), (49, 0.24784494936466217), (16, 0.24948204681277275), (10, 0.25468965992331505), (41, 0.2645677886903286), (48, 0.26464126259088516), (17, 0.270513117313385), (0, 0.27072058245539665), (42, 0.27308376505970955), (47, 0.277196753770113), (46, 0.27885397523641586), (45, 0.27986322715878487), (43, 0.2847864329814911), (8, 0.2931172773241997), (5, 0.2969331368803978), (4, 0.32356519252061844), (44, 0.3236443065106869), (1, 0.3647548146545887), (36, 0.4916617088019848), (18, 0.5304391756653786)]
computing accuracy for after removing block 23 . block score: 0.20265586115419865
removed block 23 current accuracy 0.828 loss from initial  0.12640000000000007
since last training loss: 0.11460000000000004 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 21, with score 0.206999. All blocks and scores: [(21, 0.2069986630231142), (38, 0.21216734498739243), (51, 0.21374912187457085), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (40, 0.22148791141808033), (50, 0.22298285737633705), (39, 0.22530455701053143), (19, 0.22760101221501827), (11, 0.2302460428327322), (6, 0.23515968769788742), (12, 0.24010520428419113), (49, 0.24057776667177677), (15, 0.24576075933873653), (9, 0.24653958529233932), (16, 0.24948204681277275), (41, 0.25461020693182945), (48, 0.25466253980994225), (10, 0.25468965992331505), (42, 0.26276447623968124), (45, 0.2698238641023636), (17, 0.270513117313385), (0, 0.27072058245539665), (47, 0.27136245369911194), (46, 0.2732577472925186), (43, 0.27814125269651413), (8, 0.2931172773241997), (5, 0.2969331368803978), (44, 0.32331593707203865), (4, 0.32356519252061844), (1, 0.3647548146545887), (36, 0.48868249356746674), (18, 0.5304391756653786)]
computing accuracy for after removing block 21 . block score: 0.2069986630231142
removed block 21 current accuracy 0.7562 loss from initial  0.19820000000000004
since last training loss: 0.1864 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 51, with score 0.202291. All blocks and scores: [(51, 0.2022908478975296), (38, 0.20414721965789795), (40, 0.21359079517424107), (50, 0.21476429887115955), (13, 0.21517986059188843), (14, 0.2176352832466364), (2, 0.21766841411590576), (39, 0.22203591279685497), (19, 0.22760101221501827), (11, 0.2302460428327322), (49, 0.23203248716890812), (6, 0.23515968769788742), (12, 0.24010520428419113), (15, 0.24576075933873653), (9, 0.24653958529233932), (48, 0.24764851108193398), (16, 0.24948204681277275), (41, 0.2525849863886833), (10, 0.25468965992331505), (42, 0.2585157975554466), (45, 0.26026420667767525), (47, 0.2673982307314873), (17, 0.270513117313385), (0, 0.27072058245539665), (46, 0.2737157940864563), (43, 0.27602391690015793), (8, 0.2931172773241997), (5, 0.2969331368803978), (44, 0.32287847250699997), (4, 0.32356519252061844), (1, 0.3647548146545887), (36, 0.48397501558065414), (18, 0.5304391756653786)]
computing accuracy for after removing block 51 . block score: 0.2022908478975296
removed block 51 current accuracy 0.7534 loss from initial  0.20100000000000007
training start
training epoch 0 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 1 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 2 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 3 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best True lr [0.1]
training epoch 4 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 5 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 6 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 7 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 8 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 9 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
start iteration 22
[activation mean]: block to remove picked: 13, with score 0.239279. All blocks and scores: [(13, 0.23927921801805496), (14, 0.24293792434036732), (10, 0.2527743838727474), (6, 0.2601906806230545), (2, 0.2614429071545601), (11, 0.26336998865008354), (12, 0.2639349438250065), (0, 0.2650322802364826), (15, 0.27412718534469604), (9, 0.28218957409262657), (8, 0.29021136090159416), (16, 0.29080937057733536), (39, 0.30706771463155746), (38, 0.312531940639019), (17, 0.3127295784652233), (40, 0.3139675259590149), (42, 0.321169700473547), (41, 0.3248083330690861), (50, 0.32521070167422295), (49, 0.3252563327550888), (48, 0.3286812976002693), (45, 0.32910265401005745), (46, 0.3314230740070343), (47, 0.33490077778697014), (43, 0.3387402184307575), (5, 0.3450957089662552), (44, 0.3527866005897522), (19, 0.3772996738553047), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.6001709029078484), (36, 0.6806910187005997)]
computing accuracy for after removing block 13 . block score: 0.23927921801805496
removed block 13 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 14, with score 0.233970. All blocks and scores: [(14, 0.23396991565823555), (10, 0.2527743838727474), (6, 0.2601906806230545), (2, 0.2614429071545601), (11, 0.26336998865008354), (12, 0.2639349438250065), (0, 0.2650322802364826), (15, 0.2745996490120888), (9, 0.28218957409262657), (16, 0.28720133006572723), (8, 0.29021136090159416), (17, 0.294698279350996), (39, 0.3028528690338135), (40, 0.31754903122782707), (42, 0.31935134902596474), (38, 0.31970178708434105), (49, 0.3228755183517933), (41, 0.3237796872854233), (50, 0.32540159672498703), (48, 0.3272780366241932), (45, 0.3285011760890484), (46, 0.330790001899004), (47, 0.33140745759010315), (43, 0.33978137001395226), (5, 0.3450957089662552), (44, 0.3527790196239948), (19, 0.3749077171087265), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5954655483365059), (36, 0.6837990805506706)]
computing accuracy for after removing block 14 . block score: 0.23396991565823555
removed block 14 current accuracy 0.9226 loss from initial  0.03180000000000005
since last training loss: 0.018199999999999994 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 10, with score 0.252774. All blocks and scores: [(10, 0.2527743838727474), (6, 0.2601906806230545), (2, 0.2614429071545601), (11, 0.26336998865008354), (12, 0.2639349438250065), (0, 0.2650322802364826), (9, 0.28218957409262657), (8, 0.29021136090159416), (17, 0.2918543145060539), (16, 0.2922612465918064), (15, 0.29401658847928047), (39, 0.2977656312286854), (42, 0.31357335671782494), (40, 0.3150433748960495), (38, 0.3186691626906395), (41, 0.319902952760458), (49, 0.32204313948750496), (48, 0.3236558511853218), (45, 0.3249087631702423), (50, 0.3252166174352169), (47, 0.32745063677430153), (46, 0.3304284028708935), (43, 0.3379116840660572), (5, 0.3450957089662552), (44, 0.35149234905838966), (19, 0.36861950159072876), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5833221524953842), (36, 0.6770469024777412)]
computing accuracy for after removing block 10 . block score: 0.2527743838727474
removed block 10 current accuracy 0.893 loss from initial  0.06140000000000001
since last training loss: 0.047799999999999954 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 12, with score 0.255830. All blocks and scores: [(12, 0.25583038479089737), (6, 0.2601906806230545), (11, 0.26061977818608284), (2, 0.2614429071545601), (0, 0.2650322802364826), (17, 0.2785859666764736), (39, 0.2793799191713333), (9, 0.28218957409262657), (16, 0.2830371744930744), (8, 0.29021136090159416), (15, 0.2928151860833168), (42, 0.30091389268636703), (40, 0.3040160611271858), (38, 0.3086198642849922), (41, 0.30898458138108253), (49, 0.31304964795708656), (45, 0.3147261030972004), (48, 0.3158944174647331), (47, 0.3208777941763401), (50, 0.3220069743692875), (46, 0.32379642501473427), (43, 0.3296872563660145), (44, 0.34112316370010376), (5, 0.3450957089662552), (19, 0.35638340562582016), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5716154277324677), (36, 0.6558036878705025)]
computing accuracy for after removing block 12 . block score: 0.25583038479089737
removed block 12 current accuracy 0.814 loss from initial  0.14040000000000008
since last training loss: 0.12680000000000002 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 6, with score 0.260191. All blocks and scores: [(6, 0.2601906806230545), (11, 0.26061977818608284), (2, 0.2614429071545601), (0, 0.2650322802364826), (39, 0.26609502732753754), (17, 0.27643825486302376), (16, 0.2817438580095768), (9, 0.28218957409262657), (42, 0.2897190675139427), (8, 0.29021136090159416), (40, 0.2951628565788269), (41, 0.299971554428339), (45, 0.30314652249217033), (48, 0.3044363111257553), (15, 0.30500972643494606), (49, 0.30513839423656464), (38, 0.30799882113933563), (47, 0.3108106143772602), (50, 0.31731514260172844), (46, 0.32006003335118294), (43, 0.32512037828564644), (44, 0.3307528905570507), (5, 0.3450957089662552), (19, 0.3465113341808319), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.569028876721859), (36, 0.6442508846521378)]
computing accuracy for after removing block 6 . block score: 0.2601906806230545
removed block 6 current accuracy 0.6688 loss from initial  0.2856000000000001
since last training loss: 0.272 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 11, with score 0.252755. All blocks and scores: [(11, 0.2527545243501663), (39, 0.25698088482022285), (2, 0.2614429071545601), (0, 0.2650322802364826), (17, 0.2699074409902096), (16, 0.2708304449915886), (9, 0.282166451215744), (42, 0.28796837478876114), (40, 0.29379597306251526), (15, 0.29541880264878273), (41, 0.29715298116207123), (45, 0.29755687341094017), (49, 0.29838666692376137), (48, 0.2999604903161526), (47, 0.30255915224552155), (8, 0.3045964688062668), (38, 0.30769720301032066), (50, 0.31949421763420105), (46, 0.32262108474969864), (43, 0.3238985016942024), (44, 0.3288741335272789), (19, 0.33872220292687416), (5, 0.3450957089662552), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5776078552007675), (36, 0.653305359184742)]
computing accuracy for after removing block 11 . block score: 0.2527545243501663
removed block 11 current accuracy 0.4584 loss from initial  0.49600000000000005
since last training loss: 0.4824 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.237985. All blocks and scores: [(39, 0.23798471689224243), (16, 0.2607588917016983), (17, 0.26134565845131874), (2, 0.2614429071545601), (0, 0.2650322802364826), (40, 0.2779528945684433), (42, 0.28179512172937393), (9, 0.282166451215744), (41, 0.2858254052698612), (45, 0.2878964841365814), (48, 0.289267186075449), (49, 0.29222114384174347), (47, 0.2991332747042179), (8, 0.3045964688062668), (38, 0.3151407763361931), (15, 0.3173351436853409), (44, 0.3200976885855198), (50, 0.32421383261680603), (46, 0.325259555131197), (19, 0.326741024851799), (43, 0.3270563706755638), (5, 0.3450957089662552), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5841719955205917), (36, 0.6433325037360191)]
computing accuracy for after removing block 39 . block score: 0.23798471689224243
removed block 39 current accuracy 0.4194 loss from initial  0.535
since last training loss: 0.5214 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 16, with score 0.260759. All blocks and scores: [(16, 0.2607588917016983), (17, 0.26134565845131874), (2, 0.2614429071545601), (0, 0.2650322802364826), (40, 0.27519526332616806), (45, 0.27739839628338814), (48, 0.2790081799030304), (42, 0.27999110519886017), (9, 0.282166451215744), (41, 0.282615352421999), (49, 0.28784969449043274), (47, 0.2884051725268364), (8, 0.3045964688062668), (46, 0.31383273005485535), (44, 0.31403909623622894), (43, 0.31484176591038704), (38, 0.3151407763361931), (15, 0.3173351436853409), (50, 0.3238297216594219), (19, 0.326741024851799), (5, 0.3450957089662552), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5841719955205917), (36, 0.6433325037360191)]
computing accuracy for after removing block 16 . block score: 0.2607588917016983
removed block 16 current accuracy 0.3172 loss from initial  0.6372
since last training loss: 0.6235999999999999 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 2, with score 0.261443. All blocks and scores: [(2, 0.2614429071545601), (0, 0.2650322802364826), (48, 0.26938769221305847), (45, 0.27837328612804413), (41, 0.28017156943678856), (9, 0.282166451215744), (40, 0.28230856731534004), (49, 0.28568941727280617), (47, 0.2877218797802925), (42, 0.2904805317521095), (8, 0.3045964688062668), (46, 0.3162351921200752), (44, 0.31692225858569145), (15, 0.3173351436853409), (50, 0.32021476700901985), (17, 0.3244013972580433), (43, 0.3250911682844162), (19, 0.331758763641119), (38, 0.3340587615966797), (5, 0.3450957089662552), (1, 0.3778020404279232), (4, 0.38469434902071953), (18, 0.5849516540765762), (36, 0.6468304991722107)]
computing accuracy for after removing block 2 . block score: 0.2614429071545601
removed block 2 current accuracy 0.2888 loss from initial  0.6656
since last training loss: 0.6519999999999999 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 0, with score 0.265032. All blocks and scores: [(0, 0.2650322802364826), (48, 0.2735581509768963), (45, 0.27759789302945137), (40, 0.27996988222002983), (47, 0.2813368998467922), (41, 0.28217461705207825), (9, 0.2823857441544533), (49, 0.2874731943011284), (42, 0.29940715059638023), (8, 0.3090760409832001), (15, 0.3144524320960045), (44, 0.31751125678420067), (46, 0.3205687403678894), (38, 0.32567527890205383), (17, 0.325895581394434), (19, 0.3290254510939121), (43, 0.3291330859065056), (50, 0.3303315117955208), (5, 0.3456041142344475), (1, 0.3778020404279232), (4, 0.3892506919801235), (18, 0.5868005082011223), (36, 0.6625757664442062)]
computing accuracy for after removing block 0 . block score: 0.2650322802364826
removed block 0 current accuracy 0.2442 loss from initial  0.7102
since last training loss: 0.6966 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 40, with score 0.267479. All blocks and scores: [(40, 0.2674792595207691), (45, 0.27198534458875656), (48, 0.2726406790316105), (47, 0.27420640364289284), (9, 0.27876346185803413), (41, 0.28074005991220474), (49, 0.28293313831090927), (15, 0.2911641225218773), (42, 0.29687003046274185), (8, 0.3033571094274521), (38, 0.30986469984054565), (46, 0.3180634193122387), (19, 0.31966423615813255), (17, 0.3210446387529373), (44, 0.3231149911880493), (43, 0.3231634795665741), (50, 0.33518292754888535), (5, 0.3379818834364414), (4, 0.38840746507048607), (1, 0.39684823527932167), (18, 0.5827042758464813), (36, 0.6649433895945549)]
computing accuracy for after removing block 40 . block score: 0.2674792595207691
removed block 40 current accuracy 0.2286 loss from initial  0.7258
training start
training epoch 0 val accuracy 0.8382 topk_dict {'top1': 0.8382} is_best True lr [0.1]
training epoch 1 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best True lr [0.1]
training epoch 2 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 3 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.1]
training epoch 5 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.1]
training epoch 6 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 7 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 8 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 9 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.939000)
finished training. finished 50 epochs. accuracy 0.939 topk_dict {'top1': 0.939}
start iteration 33
[activation mean]: block to remove picked: 48, with score 0.334285. All blocks and scores: [(48, 0.3342854157090187), (46, 0.3396189659833908), (47, 0.3417234681546688), (45, 0.343852162361145), (42, 0.345780398696661), (49, 0.3464173972606659), (50, 0.35297607257962227), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 48 . block score: 0.3342854157090187
removed block 48 current accuracy 0.9332 loss from initial  0.021199999999999997
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 49, with score 0.313617. All blocks and scores: [(49, 0.3136165589094162), (50, 0.3216848559677601), (46, 0.3396189659833908), (47, 0.3417234681546688), (45, 0.343852162361145), (42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 49 . block score: 0.3136165589094162
removed block 49 current accuracy 0.9272 loss from initial  0.027200000000000002
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 50, with score 0.285659. All blocks and scores: [(50, 0.28565897420048714), (46, 0.3396189659833908), (47, 0.3417234681546688), (45, 0.343852162361145), (42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 50 . block score: 0.28565897420048714
removed block 50 current accuracy 0.9156 loss from initial  0.03880000000000006
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 46, with score 0.339619. All blocks and scores: [(46, 0.3396189659833908), (47, 0.3417234681546688), (45, 0.343852162361145), (42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 46 . block score: 0.3396189659833908
removed block 46 current accuracy 0.8956 loss from initial  0.058800000000000074
since last training loss: 0.043399999999999994 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 47, with score 0.316167. All blocks and scores: [(47, 0.3161667585372925), (45, 0.343852162361145), (42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 47 . block score: 0.3161667585372925
removed block 47 current accuracy 0.8672 loss from initial  0.08720000000000006
since last training loss: 0.07179999999999997 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 45, with score 0.343852. All blocks and scores: [(45, 0.343852162361145), (42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 45 . block score: 0.343852162361145
removed block 45 current accuracy 0.8216 loss from initial  0.13280000000000003
since last training loss: 0.11739999999999995 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 42, with score 0.345780. All blocks and scores: [(42, 0.345780398696661), (43, 0.3620319217443466), (41, 0.36385493725538254), (44, 0.37138841301202774), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 42 . block score: 0.345780398696661
removed block 42 current accuracy 0.7818 loss from initial  0.17259999999999998
since last training loss: 0.1571999999999999 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 43, with score 0.344940. All blocks and scores: [(43, 0.34493983164429665), (44, 0.3541366569697857), (41, 0.36385493725538254), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 43 . block score: 0.34493983164429665
removed block 43 current accuracy 0.7282 loss from initial  0.22620000000000007
since last training loss: 0.2108 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 44, with score 0.332292. All blocks and scores: [(44, 0.332292053848505), (41, 0.36385493725538254), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 44 . block score: 0.332292053848505
removed block 44 current accuracy 0.6544 loss from initial  0.30000000000000004
since last training loss: 0.28459999999999996 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 41, with score 0.363855. All blocks and scores: [(41, 0.36385493725538254), (38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 41 . block score: 0.36385493725538254
removed block 41 current accuracy 0.6088 loss from initial  0.3456
since last training loss: 0.33019999999999994 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 38, with score 0.384834. All blocks and scores: [(38, 0.3848339430987835), (15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 38 . block score: 0.3848339430987835
removed block 38 current accuracy 0.5704 loss from initial  0.384
since last training loss: 0.3685999999999999 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 15, with score 0.394511. All blocks and scores: [(15, 0.3945111893117428), (9, 0.3965770862996578), (17, 0.4135497286915779), (19, 0.41776592284440994), (8, 0.42835958674550056), (5, 0.4428819380700588), (4, 0.47407814115285873), (1, 0.4855191335082054), (18, 0.6353338658809662), (36, 0.7332315519452095)]
computing accuracy for after removing block 15 . block score: 0.3945111893117428
removed block 15 current accuracy 0.425 loss from initial  0.5294000000000001
training start
training epoch 0 val accuracy 0.7678 topk_dict {'top1': 0.7678} is_best True lr [0.1]
training epoch 1 val accuracy 0.789 topk_dict {'top1': 0.789} is_best True lr [0.1]
training epoch 2 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best True lr [0.1]
training epoch 3 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.1]
training epoch 4 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.1]
training epoch 5 val accuracy 0.8218 topk_dict {'top1': 0.8218} is_best False lr [0.1]
training epoch 6 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best False lr [0.1]
training epoch 7 val accuracy 0.833 topk_dict {'top1': 0.833} is_best True lr [0.1]
training epoch 8 val accuracy 0.829 topk_dict {'top1': 0.829} is_best False lr [0.1]
training epoch 9 val accuracy 0.8252 topk_dict {'top1': 0.8252} is_best False lr [0.1]
training epoch 10 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.903800)
finished training. finished 50 epochs. accuracy 0.9038 topk_dict {'top1': 0.9038}
