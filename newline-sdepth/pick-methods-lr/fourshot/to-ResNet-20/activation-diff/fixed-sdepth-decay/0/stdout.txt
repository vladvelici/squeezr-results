start iteration 0
[activation diff]: block to remove picked: 35, with score 0.014275. All blocks and scores: [(35, 0.014274864341132343), (34, 0.014493348309770226), (33, 0.015328855952247977), (32, 0.015401354641653597), (27, 0.01685483381152153), (24, 0.017396228620782495), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011785577982664), (37, 0.018020291347056627), (28, 0.018068779725581408), (20, 0.01833631657063961), (25, 0.018579797353595495), (30, 0.018911650869995356), (29, 0.019017092417925596), (22, 0.01908788620494306), (38, 0.01983177848160267), (21, 0.020666002295911312), (40, 0.020699822576716542), (41, 0.020836823154240847), (39, 0.021874285535886884), (42, 0.023939985083416104), (44, 0.027291724225506186), (43, 0.027380845742300153), (53, 0.028202867601066828), (19, 0.028207604307681322), (52, 0.02841529855504632), (51, 0.029680656036362052), (45, 0.030162296956405044), (46, 0.03169303014874458), (50, 0.03270378103479743), (49, 0.03325698943808675), (47, 0.03593745641410351), (3, 0.03641833085566759), (2, 0.03660873556509614), (48, 0.03829950327053666), (6, 0.0414607860147953), (13, 0.04233343154191971), (11, 0.04962976463139057), (14, 0.05005708197131753), (7, 0.05049915099516511), (8, 0.051025130320340395), (15, 0.05208516912534833), (10, 0.05232794303447008), (16, 0.05589384399354458), (12, 0.05712253460660577), (0, 0.0571756293065846), (9, 0.06140707992017269), (5, 0.06478630565106869), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.0842915466055274), (18, 0.15011722221970558), (36, 0.23893354088068008)]
computing accuracy for after removing block 35 . block score: 0.014274864341132343
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 34, with score 0.014493. All blocks and scores: [(34, 0.014493348891846836), (33, 0.015328856417909265), (32, 0.015401355223730206), (37, 0.016689840238541365), (27, 0.016854834044352174), (24, 0.01739622838795185), (26, 0.017841696040704846), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.018068780191242695), (20, 0.018336316104978323), (38, 0.018370160134509206), (25, 0.018579796655103564), (30, 0.018911650637164712), (29, 0.019017092185094953), (22, 0.019087886437773705), (40, 0.019572118762880564), (41, 0.019616978708654642), (39, 0.02027514367364347), (21, 0.02066600206308067), (42, 0.022649952676147223), (43, 0.025927708949893713), (44, 0.02619261760264635), (53, 0.027608863078057766), (52, 0.02764224400743842), (19, 0.02820760477334261), (51, 0.0289809200912714), (45, 0.029027254320681095), (46, 0.030406813835725188), (50, 0.031917844200506806), (49, 0.032416850328445435), (47, 0.034735485911369324), (3, 0.03641833085566759), (2, 0.03660873556509614), (48, 0.037143451161682606), (6, 0.04146078694611788), (13, 0.04233343107625842), (11, 0.049629763700068), (14, 0.05005708336830139), (7, 0.05049915099516511), (8, 0.05102512938901782), (15, 0.05208516912534833), (10, 0.05232794350013137), (16, 0.05589384352788329), (12, 0.057122535072267056), (0, 0.0571756293065846), (9, 0.061407079454511404), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764383465052), (17, 0.0842915466055274), (18, 0.15011722221970558), (36, 0.2226911447942257)]
computing accuracy for after removing block 34 . block score: 0.014493348891846836
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.015329. All blocks and scores: [(33, 0.015328855835832655), (32, 0.015401355572976172), (37, 0.01564904337283224), (27, 0.016854834044352174), (38, 0.017188324825838208), (24, 0.017396227456629276), (26, 0.01784169627353549), (31, 0.01785215036943555), (23, 0.01801178464666009), (28, 0.018068779492750764), (20, 0.01833631587214768), (25, 0.018579796887934208), (41, 0.018633502535521984), (40, 0.018645135452970862), (30, 0.018911650869995356), (39, 0.018983178539201617), (29, 0.019017091719433665), (22, 0.019087886437773705), (21, 0.020666002528741956), (42, 0.021567409625276923), (43, 0.024741539265960455), (44, 0.025241219671443105), (52, 0.02675225492566824), (53, 0.026900351280346513), (45, 0.0280158338136971), (51, 0.02813189011067152), (19, 0.028207604540511966), (46, 0.029172033770009875), (50, 0.031041900627315044), (49, 0.03151613427326083), (47, 0.03355775820091367), (48, 0.03598395828157663), (3, 0.036418331786990166), (2, 0.03660873509943485), (6, 0.041460787411779165), (13, 0.04233343107625842), (11, 0.049629766028374434), (14, 0.05005708243697882), (7, 0.0504991514608264), (8, 0.05102512985467911), (15, 0.05208516912534833), (10, 0.05232794303447008), (16, 0.05589384352788329), (12, 0.05712253646925092), (0, 0.05717562884092331), (9, 0.06140707805752754), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764383465052), (17, 0.08429154753684998), (18, 0.15011721663177013), (36, 0.20549121871590614)]
computing accuracy for after removing block 33 . block score: 0.015328855835832655
removed block 33 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 37, with score 0.014727. All blocks and scores: [(37, 0.014727167785167694), (32, 0.015401355107314885), (38, 0.016087534371763468), (27, 0.016854834742844105), (24, 0.017396227922290564), (41, 0.01763681578449905), (39, 0.017656564246863127), (40, 0.017719466472044587), (26, 0.017841696506366134), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.01806877995841205), (20, 0.018336316104978323), (25, 0.01857979758642614), (30, 0.018911651335656643), (29, 0.019017092417925596), (22, 0.01908788620494306), (42, 0.020414337050169706), (21, 0.02066600206308067), (43, 0.023449428845196962), (44, 0.02405423205345869), (52, 0.025544948177412152), (53, 0.025872942060232162), (45, 0.026672408217564225), (51, 0.02704092161729932), (46, 0.02767348103225231), (19, 0.028207605239003897), (50, 0.029852007515728474), (49, 0.030292702605947852), (47, 0.03202386572957039), (48, 0.03438834426924586), (3, 0.03641833132132888), (2, 0.036608734633773565), (6, 0.041460787411779165), (13, 0.042333432007580996), (11, 0.04962976509705186), (14, 0.05005708197131753), (7, 0.050499150063842535), (8, 0.05102512892335653), (15, 0.05208516959100962), (10, 0.05232794117182493), (16, 0.05589384585618973), (12, 0.057122533209621906), (0, 0.0571756293065846), (9, 0.06140707898885012), (5, 0.06478630192577839), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.08429154474288225), (18, 0.15011722408235073), (36, 0.1936596091836691)]
computing accuracy for after removing block 37 . block score: 0.014727167785167694
removed block 37 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 38, with score 0.015322. All blocks and scores: [(38, 0.015321659855544567), (32, 0.015401355223730206), (41, 0.015430084196850657), (40, 0.015811878954991698), (39, 0.01603815285488963), (27, 0.016854834277182817), (24, 0.017396228155121207), (42, 0.01745741069316864), (26, 0.017841696040704846), (31, 0.017852150136604905), (23, 0.01801178534515202), (28, 0.018068780656903982), (20, 0.018336316104978323), (25, 0.01857979712076485), (30, 0.01891165040433407), (29, 0.019017092417925596), (22, 0.019087886437773705), (43, 0.019953369395807385), (44, 0.02043514302931726), (21, 0.020666001364588737), (52, 0.021591540658846498), (53, 0.022010742453858256), (45, 0.02262773970142007), (51, 0.02283536270260811), (46, 0.023026632145047188), (50, 0.025466163642704487), (49, 0.02559670014306903), (47, 0.02674837363883853), (19, 0.028207606403157115), (48, 0.028763408306986094), (3, 0.036418331786990166), (2, 0.03660873416811228), (6, 0.04146078648045659), (13, 0.04233343293890357), (11, 0.049629764165729284), (14, 0.050057082902640104), (7, 0.050499151926487684), (8, 0.05102512892335653), (15, 0.05208516865968704), (10, 0.05232794117182493), (16, 0.05589384585618973), (12, 0.05712253600358963), (0, 0.05717562837526202), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218543857336), (1, 0.07571764197200537), (17, 0.08429154846817255), (18, 0.15011722221970558), (36, 0.19365961104631424)]
computing accuracy for after removing block 38 . block score: 0.015321659855544567
removed block 38 current accuracy 0.94 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 41, with score 0.013861. All blocks and scores: [(41, 0.013860961073078215), (40, 0.01467142766341567), (42, 0.01534125569742173), (32, 0.015401354874484241), (39, 0.01546197768766433), (27, 0.016854834277182817), (24, 0.017396228853613138), (43, 0.017514182021841407), (44, 0.01754390588030219), (26, 0.017841696506366134), (31, 0.017852150835096836), (23, 0.01801178534515202), (28, 0.01806877995841205), (20, 0.018336315639317036), (52, 0.018348957179114223), (25, 0.018579797819256783), (53, 0.01883958140388131), (30, 0.018911651102826), (29, 0.019017092417925596), (22, 0.019087886670604348), (45, 0.01930054067634046), (46, 0.01930436701513827), (51, 0.019394941395148635), (21, 0.020666002528741956), (49, 0.021678968565538526), (50, 0.021847275085747242), (47, 0.022476087557151914), (48, 0.02421563398092985), (19, 0.02820760617032647), (3, 0.03641833085566759), (2, 0.03660873509943485), (6, 0.04146078694611788), (13, 0.04233343340456486), (11, 0.04962976509705186), (14, 0.05005708243697882), (7, 0.050499150063842535), (8, 0.051025128457695246), (15, 0.05208517052233219), (10, 0.05232794117182493), (16, 0.05589384539052844), (12, 0.05712253553792834), (0, 0.05717562884092331), (9, 0.06140707992017269), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011721849441528), (36, 0.1936596129089594)]
computing accuracy for after removing block 41 . block score: 0.013860961073078215
removed block 41 current accuracy 0.937 loss from initial  0.01739999999999997
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 42, with score 0.013690. All blocks and scores: [(42, 0.013689911342225969), (40, 0.014671427197754383), (44, 0.01503468316514045), (52, 0.015179633279331028), (32, 0.01540135545656085), (39, 0.015461977222003043), (43, 0.015499333967454731), (53, 0.01567198208067566), (51, 0.01593275275081396), (46, 0.015958459582179785), (45, 0.016258909599855542), (27, 0.01685483451001346), (24, 0.017396228155121207), (26, 0.017841696040704846), (49, 0.017846781061962247), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.01806877995841205), (50, 0.01825446682050824), (20, 0.018336315639317036), (47, 0.01837508473545313), (25, 0.018579796887934208), (30, 0.018911650869995356), (29, 0.019017092417925596), (22, 0.019087885972112417), (48, 0.01978056994266808), (21, 0.02066600159741938), (19, 0.02820760547183454), (3, 0.03641833085566759), (2, 0.03660873416811228), (6, 0.04146078694611788), (13, 0.04233343247324228), (11, 0.04962976463139057), (14, 0.05005708150565624), (7, 0.050499150063842535), (8, 0.051025130320340395), (15, 0.052085170056670904), (10, 0.05232794117182493), (16, 0.05589384492486715), (12, 0.057122535072267056), (0, 0.057175629772245884), (9, 0.061407079454511404), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.08429154846817255), (18, 0.15011722221970558), (36, 0.1936596129089594)]
computing accuracy for after removing block 42 . block score: 0.013689911342225969
removed block 42 current accuracy 0.9328 loss from initial  0.021600000000000064
since last training loss: 0.021600000000000064 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 52, with score 0.012497. All blocks and scores: [(52, 0.01249660097528249), (44, 0.012997499899938703), (53, 0.013001907151192427), (51, 0.013041546917520463), (46, 0.01315907179377973), (45, 0.013672355678863823), (43, 0.013903803890570998), (49, 0.014462789986282587), (40, 0.014671427547000349), (47, 0.014907657052390277), (50, 0.015199760906398296), (32, 0.015401354874484241), (39, 0.015461977920494974), (48, 0.016047357581555843), (27, 0.016854834044352174), (24, 0.017396228155121207), (26, 0.017841696506366134), (31, 0.017852150835096836), (23, 0.018011784879490733), (28, 0.018068780191242695), (20, 0.018336316104978323), (25, 0.01857979758642614), (30, 0.018911651568487287), (29, 0.019017092417925596), (22, 0.019087886437773705), (21, 0.020666002295911312), (19, 0.028207605937495828), (3, 0.03641833225265145), (2, 0.03660873416811228), (6, 0.04146078694611788), (13, 0.04233343293890357), (11, 0.04962976276874542), (14, 0.050057081039994955), (7, 0.05049914913251996), (8, 0.05102513078600168), (15, 0.05208516959100962), (10, 0.05232794163748622), (16, 0.05589384492486715), (12, 0.05712253600358963), (0, 0.0571756293065846), (9, 0.06140707898885012), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011721849441528), (36, 0.1936596129089594)]
computing accuracy for after removing block 52 . block score: 0.01249660097528249
removed block 52 current accuracy 0.9326 loss from initial  0.02180000000000004
since last training loss: 0.02180000000000004 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 53, with score 0.010955. All blocks and scores: [(53, 0.010954919387586415), (44, 0.012997500016354024), (51, 0.013041547266766429), (46, 0.013159071444533765), (45, 0.013672355562448502), (43, 0.013903804356232285), (49, 0.014462790568359196), (40, 0.014671427430585027), (47, 0.0149076571688056), (50, 0.015199760906398296), (32, 0.015401355340145528), (39, 0.015461977105587721), (48, 0.01604735804721713), (27, 0.016854834277182817), (24, 0.01739622838795185), (26, 0.017841696506366134), (31, 0.017852150835096836), (23, 0.018011784879490733), (28, 0.01806878042407334), (20, 0.018336316337808967), (25, 0.018579796655103564), (30, 0.018911651102826), (29, 0.01901709265075624), (22, 0.01908788620494306), (21, 0.020666002295911312), (19, 0.02820760407485068), (3, 0.03641833085566759), (2, 0.03660873509943485), (6, 0.041460785549134016), (13, 0.04233343247324228), (11, 0.049629764165729284), (14, 0.05005708243697882), (7, 0.050499150063842535), (8, 0.05102512892335653), (15, 0.052085168194025755), (10, 0.05232794210314751), (16, 0.055893844459205866), (12, 0.05712253646925092), (0, 0.05717562837526202), (9, 0.06140708038583398), (5, 0.06478630285710096), (4, 0.06930218264460564), (1, 0.07571764104068279), (17, 0.0842915503308177), (18, 0.15011722035706043), (36, 0.1936596091836691)]
computing accuracy for after removing block 53 . block score: 0.010954919387586415
removed block 53 current accuracy 0.9322 loss from initial  0.022199999999999998
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 44, with score 0.012997. All blocks and scores: [(44, 0.01299749978352338), (51, 0.013041547499597073), (46, 0.013159071211703122), (45, 0.013672355678863823), (43, 0.013903804472647607), (49, 0.014462789986282587), (40, 0.01467142766341567), (47, 0.014907657285220921), (50, 0.015199761022813618), (32, 0.015401354641653597), (39, 0.015461977920494974), (48, 0.01604735804721713), (27, 0.016854834044352174), (24, 0.01739622838795185), (26, 0.017841696040704846), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.018068779725581408), (20, 0.018336316337808967), (25, 0.018579797353595495), (30, 0.018911651102826), (29, 0.01901709265075624), (22, 0.01908788620494306), (21, 0.020666002528741956), (19, 0.02820760547183454), (3, 0.03641833132132888), (2, 0.036608734633773565), (6, 0.04146078648045659), (13, 0.042333433870226145), (11, 0.049629763700068), (14, 0.050057082902640104), (7, 0.05049915099516511), (8, 0.051025128457695246), (15, 0.05208517098799348), (10, 0.05232794210314751), (16, 0.05589384539052844), (12, 0.057122535072267056), (0, 0.05717562884092331), (9, 0.06140707852318883), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764383465052), (17, 0.08429154753684998), (18, 0.15011722221970558), (36, 0.19365961104631424)]
computing accuracy for after removing block 44 . block score: 0.01299749978352338
removed block 44 current accuracy 0.9238 loss from initial  0.03060000000000007
since last training loss: 0.03060000000000007 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 51, with score 0.010134. All blocks and scores: [(51, 0.010133508942089975), (46, 0.010826117009855807), (49, 0.011331661487929523), (45, 0.011613044538535178), (47, 0.011881413636729121), (50, 0.012055806000716984), (48, 0.012604234390892088), (43, 0.013903804472647607), (40, 0.014671427430585027), (32, 0.015401355107314885), (39, 0.015461977804079652), (27, 0.016854834044352174), (24, 0.017396227922290564), (26, 0.017841696506366134), (31, 0.017852150602266192), (23, 0.01801178534515202), (28, 0.01806878042407334), (20, 0.018336316104978323), (25, 0.01857979758642614), (30, 0.018911651102826), (29, 0.01901709265075624), (22, 0.01908788620494306), (21, 0.020666001830250025), (19, 0.028207606403157115), (3, 0.036418331786990166), (2, 0.03660873509943485), (6, 0.04146078787744045), (13, 0.04233343247324228), (11, 0.04962976509705186), (14, 0.05005708150565624), (7, 0.05049915099516511), (8, 0.051025130320340395), (15, 0.05208516912534833), (10, 0.05232794117182493), (16, 0.05589384399354458), (12, 0.05712253414094448), (0, 0.05717562837526202), (9, 0.061407079454511404), (5, 0.06478630285710096), (4, 0.06930218450725079), (1, 0.07571764197200537), (17, 0.08429154753684998), (18, 0.15011722035706043), (36, 0.19365960732102394)]
computing accuracy for after removing block 51 . block score: 0.010133508942089975
removed block 51 current accuracy 0.9214 loss from initial  0.03300000000000003
training start
training epoch 0 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best False lr [0.1]
training epoch 1 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 2 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 5 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 6 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 7 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 8 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 9 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.949000)
finished training. finished 50 epochs. accuracy 0.949 topk_dict {'top1': 0.949}
start iteration 11
[activation diff]: block to remove picked: 32, with score 0.042567. All blocks and scores: [(32, 0.04256711807101965), (31, 0.04265910340473056), (20, 0.04361095232889056), (27, 0.04495093412697315), (25, 0.045961092226207256), (24, 0.046329325530678034), (28, 0.046892714221030474), (30, 0.04739158088341355), (26, 0.04788336809724569), (23, 0.04842796130105853), (22, 0.048738622572273016), (29, 0.04933424526825547), (21, 0.05233714869245887), (19, 0.06039312155917287), (45, 0.06503624003380537), (2, 0.06846366031095386), (40, 0.06885845586657524), (43, 0.06977200321853161), (3, 0.0710094552487135), (6, 0.07161521725356579), (14, 0.07711510639637709), (46, 0.07843139208853245), (47, 0.08050997741520405), (39, 0.0826764116063714), (13, 0.08498421683907509), (11, 0.08750791754573584), (15, 0.0879032788798213), (10, 0.0884287552908063), (7, 0.08926454093307257), (0, 0.08990854863077402), (8, 0.09971603751182556), (48, 0.10151245165616274), (9, 0.10236366745084524), (12, 0.10730010829865932), (16, 0.11121213994920254), (49, 0.12220217473804951), (50, 0.12739455234259367), (5, 0.13064092956483364), (4, 0.14758644998073578), (1, 0.15777838416397572), (17, 0.2213094774633646), (18, 0.5348725020885468), (36, 0.5531421005725861)]
computing accuracy for after removing block 32 . block score: 0.04256711807101965
removed block 32 current accuracy 0.9466 loss from initial  0.007800000000000029
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 31, with score 0.042659. All blocks and scores: [(31, 0.04265910154208541), (20, 0.04361095326021314), (27, 0.04495093459263444), (25, 0.04596109362319112), (24, 0.04632932413369417), (28, 0.046892714221030474), (30, 0.04739158181473613), (26, 0.04788336995989084), (23, 0.04842796130105853), (22, 0.04873862164095044), (29, 0.0493342443369329), (21, 0.05233714682981372), (19, 0.06039312109351158), (45, 0.061948929913342), (43, 0.06568559724837542), (40, 0.06606539525091648), (2, 0.0684636584483087), (3, 0.0710094552487135), (6, 0.07161521725356579), (46, 0.07458777539432049), (14, 0.07711510639637709), (39, 0.0776694780215621), (47, 0.07769832108169794), (13, 0.08498421777039766), (11, 0.08750791754573584), (15, 0.08790327794849873), (10, 0.08842875249683857), (7, 0.08926454372704029), (0, 0.08990854863077402), (48, 0.09817200526595116), (8, 0.09971603471785784), (9, 0.10236366931349039), (12, 0.10730011202394962), (16, 0.11121214088052511), (49, 0.11810301057994366), (50, 0.12420035246759653), (5, 0.1306409277021885), (4, 0.14758645184338093), (1, 0.15777838230133057), (17, 0.22130947560071945), (36, 0.5196015611290932), (18, 0.5348724722862244)]
computing accuracy for after removing block 31 . block score: 0.04265910154208541
removed block 31 current accuracy 0.944 loss from initial  0.010400000000000076
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.043611. All blocks and scores: [(20, 0.04361095232889056), (27, 0.04495093319565058), (25, 0.04596109455451369), (24, 0.04632932646200061), (28, 0.046892714221030474), (30, 0.04739158088341355), (26, 0.04788336995989084), (23, 0.048427964095026255), (22, 0.0487386230379343), (29, 0.049334244802594185), (21, 0.05233714822679758), (45, 0.057566107250750065), (19, 0.06039311923086643), (43, 0.06088990205898881), (40, 0.06170476321130991), (2, 0.0684636584483087), (46, 0.07015358470380306), (39, 0.07024431228637695), (3, 0.07100945618003607), (6, 0.07161521818488836), (47, 0.07379605248570442), (14, 0.07711510453373194), (13, 0.08498421870172024), (11, 0.08750791754573584), (15, 0.087903275154531), (10, 0.08842875622212887), (7, 0.08926454372704029), (0, 0.08990854769945145), (48, 0.09474662970751524), (8, 0.09971603564918041), (9, 0.10236366745084524), (12, 0.10730010736733675), (16, 0.11121213901787996), (49, 0.11338897980749607), (50, 0.12079552840441465), (5, 0.1306409277021885), (4, 0.14758645370602608), (1, 0.15777838230133057), (17, 0.221309470012784), (36, 0.4872587136924267), (18, 0.534872479736805)]
computing accuracy for after removing block 20 . block score: 0.04361095232889056
removed block 20 current accuracy 0.9402 loss from initial  0.01419999999999999
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.041719. All blocks and scores: [(27, 0.04171894583851099), (25, 0.042221876326948404), (24, 0.04295082530006766), (28, 0.04301837831735611), (30, 0.04380836337804794), (23, 0.04522548336535692), (26, 0.04543936671689153), (22, 0.04577391780912876), (29, 0.04660547384992242), (21, 0.051218144595623016), (45, 0.05539582250639796), (43, 0.05831163190305233), (40, 0.06021559564396739), (19, 0.06039312295615673), (39, 0.06713873613625765), (46, 0.06742487102746964), (2, 0.06846365937963128), (3, 0.0710094552487135), (6, 0.07161521725356579), (47, 0.07239934429526329), (14, 0.07711510639637709), (13, 0.08498421497642994), (11, 0.08750791847705841), (15, 0.08790327794849873), (10, 0.08842875435948372), (7, 0.08926454372704029), (0, 0.08990854863077402), (48, 0.09241745807230473), (8, 0.09971603658050299), (9, 0.10236366558820009), (12, 0.10730011016130447), (49, 0.11053196899592876), (16, 0.11121213901787996), (50, 0.11748100724071264), (5, 0.13064092583954334), (4, 0.14758645370602608), (1, 0.15777838416397572), (17, 0.2213094737380743), (36, 0.45272890850901604), (18, 0.534872479736805)]
computing accuracy for after removing block 27 . block score: 0.04171894583851099
removed block 27 current accuracy 0.9336 loss from initial  0.02080000000000004
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 28, with score 0.041646. All blocks and scores: [(28, 0.0416461699642241), (30, 0.04181300336495042), (25, 0.042221874464303255), (24, 0.0429508239030838), (29, 0.044194272719323635), (23, 0.04522548196837306), (26, 0.04543936951085925), (22, 0.04577391827479005), (21, 0.05121814366430044), (45, 0.05310830008238554), (43, 0.05558232916519046), (40, 0.05814016284421086), (19, 0.06039312249049544), (39, 0.06318169925361872), (46, 0.06453191302716732), (2, 0.06846365751698613), (47, 0.07014061324298382), (3, 0.07100945431739092), (6, 0.07161521725356579), (14, 0.07711510546505451), (13, 0.08498421963304281), (11, 0.08750791940838099), (15, 0.08790328167378902), (10, 0.08842875715345144), (7, 0.08926454000174999), (48, 0.08984074369072914), (0, 0.08990854769945145), (8, 0.09971603378653526), (9, 0.10236366838216782), (49, 0.10682177823036909), (12, 0.10730011016130447), (16, 0.11121213994920254), (50, 0.11416224297136068), (5, 0.1306409239768982), (4, 0.14758645184338093), (1, 0.15777838416397572), (17, 0.22130947932600975), (36, 0.42759743332862854), (18, 0.5348724871873856)]
computing accuracy for after removing block 28 . block score: 0.0416461699642241
removed block 28 current accuracy 0.9238 loss from initial  0.03060000000000007
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 30, with score 0.039822. All blocks and scores: [(30, 0.03982154978439212), (29, 0.0420944239012897), (25, 0.04222187492996454), (24, 0.04295082530006766), (23, 0.04522548196837306), (26, 0.04543936625123024), (22, 0.04577391594648361), (45, 0.04954977845773101), (21, 0.05121814366430044), (43, 0.052197680808603764), (40, 0.05530920950695872), (39, 0.05855444725602865), (19, 0.06039312109351158), (46, 0.0607848335057497), (47, 0.0661938488483429), (2, 0.06846365751698613), (3, 0.07100945431739092), (6, 0.07161521632224321), (14, 0.07711510453373194), (13, 0.08498421870172024), (48, 0.08543158136308193), (11, 0.08750792033970356), (15, 0.0879032826051116), (10, 0.08842875622212887), (7, 0.08926454186439514), (0, 0.0899085495620966), (8, 0.09971603751182556), (49, 0.10162453725934029), (9, 0.10236366651952267), (12, 0.1073001055046916), (50, 0.11029241234064102), (16, 0.11121214367449284), (5, 0.13064092583954334), (4, 0.14758645370602608), (1, 0.15777838230133057), (17, 0.22130947932600975), (36, 0.40259842574596405), (18, 0.5348724722862244)]
computing accuracy for after removing block 30 . block score: 0.03982154978439212
removed block 30 current accuracy 0.9148 loss from initial  0.03960000000000008
since last training loss: 0.03420000000000001 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 29, with score 0.042094. All blocks and scores: [(29, 0.04209442529827356), (25, 0.04222187492996454), (24, 0.042950824834406376), (23, 0.045225482899695635), (26, 0.0454393676482141), (22, 0.04577391827479005), (45, 0.04610501229763031), (43, 0.04891400784254074), (21, 0.051218141335994005), (40, 0.052749169524759054), (39, 0.053848027251660824), (46, 0.05725184688344598), (19, 0.06039312295615673), (47, 0.06207703007385135), (2, 0.06846365658566356), (3, 0.07100945431739092), (6, 0.07161521632224321), (14, 0.07711510360240936), (48, 0.07995751034468412), (13, 0.08498421870172024), (11, 0.08750792220234871), (15, 0.08790327701717615), (10, 0.08842875715345144), (7, 0.08926454372704029), (0, 0.08990854676812887), (49, 0.09437812957912683), (8, 0.09971603658050299), (50, 0.10206454340368509), (9, 0.10236366838216782), (12, 0.10730010829865932), (16, 0.11121213715523481), (5, 0.1306409277021885), (4, 0.14758645370602608), (1, 0.15777838416397572), (17, 0.22130947187542915), (36, 0.3788059242069721), (18, 0.5348724946379662)]
computing accuracy for after removing block 29 . block score: 0.04209442529827356
removed block 29 current accuracy 0.8956 loss from initial  0.058800000000000074
since last training loss: 0.0534 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 25, with score 0.042222. All blocks and scores: [(25, 0.04222187539562583), (24, 0.04295082530006766), (45, 0.04356018779799342), (23, 0.045225481037050486), (26, 0.045439367182552814), (22, 0.04577391780912876), (43, 0.047334976959973574), (39, 0.05060273874551058), (40, 0.05087032122537494), (21, 0.05121814366430044), (46, 0.05511191813275218), (47, 0.05897137988358736), (19, 0.060393122024834156), (2, 0.06846365937963128), (3, 0.0710094515234232), (6, 0.07161521911621094), (48, 0.07570411637425423), (14, 0.07711510453373194), (13, 0.08498421777039766), (11, 0.08750791754573584), (49, 0.08755552396178246), (15, 0.08790327981114388), (10, 0.0884287552908063), (7, 0.08926454372704029), (0, 0.08990855049341917), (50, 0.0942010274156928), (8, 0.09971603658050299), (9, 0.10236366838216782), (12, 0.10730010829865932), (16, 0.11121213715523481), (5, 0.13064092956483364), (4, 0.14758644625544548), (1, 0.15777838230133057), (17, 0.22130947932600975), (36, 0.363982941955328), (18, 0.5348725020885468)]
computing accuracy for after removing block 25 . block score: 0.04222187539562583
removed block 25 current accuracy 0.8722 loss from initial  0.08220000000000005
since last training loss: 0.07679999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.041077. All blocks and scores: [(45, 0.041077114176005125), (24, 0.0429508239030838), (23, 0.045225482899695635), (26, 0.04553659353405237), (43, 0.04570797923952341), (22, 0.04577391780912876), (39, 0.047880076337605715), (40, 0.049126874189823866), (21, 0.051218144595623016), (46, 0.05286280857399106), (47, 0.05623023910447955), (19, 0.06039312155917287), (2, 0.06846365937963128), (3, 0.07100945338606834), (6, 0.07161521632224321), (48, 0.07182645611464977), (14, 0.07711510546505451), (49, 0.08183912467211485), (13, 0.08498421683907509), (11, 0.08750792033970356), (15, 0.087903275154531), (10, 0.0884287552908063), (50, 0.08847831562161446), (7, 0.08926454000174999), (0, 0.0899085495620966), (8, 0.09971603564918041), (9, 0.10236366838216782), (12, 0.10730011016130447), (16, 0.11121213715523481), (5, 0.13064092583954334), (4, 0.14758645184338093), (1, 0.15777838230133057), (17, 0.22130946815013885), (36, 0.3489024415612221), (18, 0.5348724871873856)]
computing accuracy for after removing block 45 . block score: 0.041077114176005125
removed block 45 current accuracy 0.8664 loss from initial  0.08800000000000008
since last training loss: 0.0826 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.042951. All blocks and scores: [(24, 0.04295082436874509), (23, 0.045225481037050486), (46, 0.045490818563848734), (26, 0.045536593068391085), (43, 0.04570798110216856), (22, 0.0457739164121449), (47, 0.04597217822447419), (39, 0.04788007866591215), (40, 0.04912687325850129), (21, 0.051218143198639154), (48, 0.05835196329280734), (19, 0.060393122024834156), (49, 0.06528785824775696), (2, 0.06846365937963128), (3, 0.07100945245474577), (6, 0.07161521818488836), (50, 0.07189956121146679), (14, 0.07711510546505451), (13, 0.08498421777039766), (11, 0.08750791847705841), (15, 0.08790327981114388), (10, 0.08842875435948372), (7, 0.08926453813910484), (0, 0.08990854863077402), (8, 0.09971603564918041), (9, 0.10236366651952267), (12, 0.10730011202394962), (16, 0.11121213901787996), (5, 0.13064092583954334), (4, 0.14758645556867123), (1, 0.15777838230133057), (17, 0.22130947187542915), (36, 0.3489024266600609), (18, 0.5348724946379662)]
computing accuracy for after removing block 24 . block score: 0.04295082436874509
removed block 24 current accuracy 0.8292 loss from initial  0.12519999999999998
since last training loss: 0.1197999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 47, with score 0.043646. All blocks and scores: [(47, 0.04364609671756625), (46, 0.04377031372860074), (43, 0.04379952559247613), (26, 0.044217482674866915), (39, 0.04503219574689865), (23, 0.04522548243403435), (22, 0.04577391780912876), (40, 0.046773967798799276), (21, 0.05121814273297787), (48, 0.05468970350921154), (19, 0.060393122024834156), (49, 0.06098088575527072), (50, 0.06650965940207243), (2, 0.06846365937963128), (3, 0.0710094552487135), (6, 0.07161521818488836), (14, 0.07711510546505451), (13, 0.08498421777039766), (11, 0.08750792127102613), (15, 0.08790328074246645), (10, 0.08842875435948372), (7, 0.08926454279571772), (0, 0.0899085495620966), (8, 0.09971603751182556), (9, 0.10236366931349039), (12, 0.10730010736733675), (16, 0.11121214088052511), (5, 0.1306409277021885), (4, 0.14758645556867123), (1, 0.15777837857604027), (17, 0.22130947187542915), (36, 0.33306969329714775), (18, 0.5348724871873856)]
computing accuracy for after removing block 47 . block score: 0.04364609671756625
removed block 47 current accuracy 0.8156 loss from initial  0.13880000000000003
training start
training epoch 0 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best True lr [0.1]
training epoch 1 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.1]
training epoch 3 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 4 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.1]
training epoch 5 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 6 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 22
[activation diff]: block to remove picked: 2, with score 0.073196. All blocks and scores: [(2, 0.07319600833579898), (6, 0.07642226666212082), (3, 0.08116128295660019), (21, 0.08260445110499859), (23, 0.08566855825483799), (19, 0.08629850205034018), (22, 0.08651633188128471), (10, 0.08668928314000368), (14, 0.08766538091003895), (13, 0.08860266767442226), (40, 0.09011942241340876), (7, 0.09139630198478699), (11, 0.09367465134710073), (43, 0.09646978136152029), (39, 0.09852796234190464), (0, 0.10578675847500563), (46, 0.10825503896921873), (12, 0.10938591044396162), (8, 0.109671575948596), (15, 0.10979354754090309), (9, 0.11469126865267754), (48, 0.12021608091890812), (26, 0.12553430907428265), (5, 0.1304414626210928), (16, 0.13524779863655567), (4, 0.1807795986533165), (49, 0.18404456973075867), (1, 0.18887954205274582), (17, 0.23214794881641865), (50, 0.25075945630669594), (18, 0.5337114036083221), (36, 0.5807631462812424)]
computing accuracy for after removing block 2 . block score: 0.07319600833579898
removed block 2 current accuracy 0.9454 loss from initial  0.009000000000000008
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 6, with score 0.076120. All blocks and scores: [(6, 0.07611951604485512), (21, 0.0838076276704669), (19, 0.08495627623051405), (23, 0.0856059892103076), (10, 0.08563220780342817), (3, 0.08617415465414524), (22, 0.08832188509404659), (7, 0.08844532445073128), (40, 0.08865783363580704), (14, 0.08912103343755007), (13, 0.08974089846014977), (11, 0.0917867124080658), (43, 0.09488509502261877), (39, 0.09725817199796438), (46, 0.10466810129582882), (0, 0.10578676033765078), (15, 0.10771443974226713), (12, 0.10902439430356026), (8, 0.11138590890914202), (48, 0.11749374959617853), (9, 0.12094368599355221), (26, 0.12475628033280373), (16, 0.13545800000429153), (5, 0.136778200045228), (49, 0.17806417122483253), (4, 0.18138462863862514), (1, 0.18887954391539097), (17, 0.23019583150744438), (50, 0.2434435561299324), (18, 0.5306459367275238), (36, 0.5703074634075165)]
computing accuracy for after removing block 6 . block score: 0.07611951604485512
removed block 6 current accuracy 0.939 loss from initial  0.01540000000000008
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 14, with score 0.083455. All blocks and scores: [(14, 0.08345547504723072), (13, 0.08482637349516153), (23, 0.08581690676510334), (3, 0.08617415931075811), (21, 0.08629378490149975), (19, 0.08853898383677006), (40, 0.08874982688575983), (11, 0.08998917695134878), (22, 0.09127863589674234), (10, 0.0931785898283124), (7, 0.09496094472706318), (43, 0.09503949247300625), (39, 0.09981368482112885), (12, 0.10214697476476431), (15, 0.10299974121153355), (46, 0.10339217819273472), (0, 0.10578675847500563), (48, 0.11665077786892653), (26, 0.12304692529141903), (9, 0.12432768568396568), (16, 0.1259432900696993), (8, 0.12636156287044287), (5, 0.1367782037705183), (49, 0.1746899075806141), (4, 0.18138462491333485), (1, 0.18887954205274582), (17, 0.21780295856297016), (50, 0.23823277279734612), (18, 0.5373266711831093), (36, 0.5740021467208862)]
computing accuracy for after removing block 14 . block score: 0.08345547504723072
removed block 14 current accuracy 0.931 loss from initial  0.023399999999999976
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 21, with score 0.084406. All blocks and scores: [(21, 0.08440639637410641), (13, 0.08482637535780668), (23, 0.08531863708049059), (3, 0.08617415651679039), (19, 0.08854176849126816), (40, 0.08898940216749907), (11, 0.08998917508870363), (22, 0.09086358826607466), (10, 0.0931785898283124), (7, 0.09496094286441803), (43, 0.09584471955895424), (39, 0.10065423510968685), (12, 0.10214697383344173), (46, 0.1021781088784337), (0, 0.10578675847500563), (48, 0.11547687649726868), (15, 0.11640935484319925), (26, 0.1206091158092022), (9, 0.12432768195867538), (8, 0.12636156100779772), (16, 0.13514435291290283), (5, 0.13677820190787315), (49, 0.1737690009176731), (4, 0.1813846305012703), (1, 0.18887954577803612), (17, 0.2264139335602522), (50, 0.23733500018715858), (18, 0.5372063517570496), (36, 0.572989247739315)]
computing accuracy for after removing block 21 . block score: 0.08440639637410641
removed block 21 current accuracy 0.9178 loss from initial  0.03660000000000008
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 23, with score 0.077008. All blocks and scores: [(23, 0.07700837682932615), (40, 0.08206048514693975), (13, 0.08482637349516153), (3, 0.08617415651679039), (43, 0.08813504222780466), (19, 0.08854176942259073), (11, 0.08998917322605848), (39, 0.09027198795229197), (22, 0.09142232034355402), (10, 0.09317858796566725), (7, 0.09496094472706318), (46, 0.09667194075882435), (12, 0.10214697383344173), (0, 0.10578676220029593), (48, 0.11110397707670927), (26, 0.11161229386925697), (15, 0.11640935391187668), (9, 0.12432768195867538), (8, 0.12636156659573317), (16, 0.13514435477554798), (5, 0.13677819818258286), (49, 0.16822014935314655), (4, 0.18138462863862514), (1, 0.18887955322861671), (17, 0.2264139335602522), (50, 0.23334980569779873), (36, 0.522467590868473), (18, 0.5372063517570496)]
computing accuracy for after removing block 23 . block score: 0.07700837682932615
removed block 23 current accuracy 0.9024 loss from initial  0.052000000000000046
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 40, with score 0.078006. All blocks and scores: [(40, 0.07800558395683765), (43, 0.08099792897701263), (39, 0.0822306415066123), (13, 0.08482637442648411), (3, 0.08617415931075811), (19, 0.08854177128523588), (11, 0.08998917229473591), (22, 0.09142231848090887), (46, 0.09195647481828928), (10, 0.0931785861030221), (7, 0.09496094565838575), (26, 0.10179050732403994), (12, 0.10214697383344173), (0, 0.10578675847500563), (48, 0.10608550067991018), (15, 0.11640935111790895), (9, 0.12432768382132053), (8, 0.12636156845837831), (16, 0.13514435850083828), (5, 0.1367782037705183), (49, 0.1591218262910843), (4, 0.18138462677598), (1, 0.18887954764068127), (50, 0.22554577514529228), (17, 0.2264139298349619), (36, 0.48389124870300293), (18, 0.537206344306469)]
computing accuracy for after removing block 40 . block score: 0.07800558395683765
removed block 40 current accuracy 0.8782 loss from initial  0.07620000000000005
since last training loss: 0.0696 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 43, with score 0.074891. All blocks and scores: [(43, 0.07489114906638861), (46, 0.08160069491714239), (39, 0.08223064430058002), (13, 0.08482637256383896), (3, 0.08617415744811296), (19, 0.08854176849126816), (11, 0.08998917695134878), (48, 0.0912914639338851), (22, 0.09142231568694115), (10, 0.09317858796566725), (7, 0.09496094565838575), (26, 0.10179050266742706), (12, 0.10214697290211916), (0, 0.10578675754368305), (15, 0.11640935856848955), (9, 0.12432768102735281), (8, 0.12636156659573317), (49, 0.1334009189158678), (16, 0.13514435291290283), (5, 0.13677820190787315), (4, 0.1813846305012703), (1, 0.18887954950332642), (50, 0.207513015717268), (17, 0.22641393542289734), (36, 0.48389125242829323), (18, 0.5372063592076302)]
computing accuracy for after removing block 43 . block score: 0.07489114906638861
removed block 43 current accuracy 0.8264 loss from initial  0.128
since last training loss: 0.12139999999999995 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 46, with score 0.072744. All blocks and scores: [(46, 0.07274414226412773), (48, 0.07703530509024858), (39, 0.08223064243793488), (13, 0.08482637535780668), (3, 0.08617415558546782), (19, 0.08854176849126816), (11, 0.08998917322605848), (22, 0.09142232034355402), (10, 0.09317858424037695), (7, 0.09496094565838575), (26, 0.10179050546139479), (12, 0.10214697290211916), (0, 0.10578676033765078), (15, 0.11640935484319925), (49, 0.11707410495728254), (9, 0.12432768382132053), (8, 0.12636156287044287), (16, 0.13514435105025768), (5, 0.13677820563316345), (4, 0.18138462863862514), (1, 0.18887954391539097), (50, 0.19272592850029469), (17, 0.22641393542289734), (36, 0.48389124497771263), (18, 0.5372063666582108)]
computing accuracy for after removing block 46 . block score: 0.07274414226412773
removed block 46 current accuracy 0.7186 loss from initial  0.2358
since last training loss: 0.22919999999999996 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 48, with score 0.057229. All blocks and scores: [(48, 0.057229108177125454), (39, 0.08223064057528973), (13, 0.08482637349516153), (3, 0.08617415558546782), (49, 0.08847393002361059), (19, 0.08854177128523588), (11, 0.08998917508870363), (22, 0.0914223175495863), (10, 0.09317858517169952), (7, 0.09496094286441803), (26, 0.10179050639271736), (12, 0.10214697383344173), (0, 0.10578676033765078), (15, 0.1164093567058444), (9, 0.12432768382132053), (8, 0.12636156473308802), (16, 0.13514435105025768), (5, 0.13677819818258286), (50, 0.1408801730722189), (4, 0.1813846342265606), (1, 0.18887954764068127), (17, 0.2264139298349619), (36, 0.48389124870300293), (18, 0.5372063592076302)]
computing accuracy for after removing block 48 . block score: 0.057229108177125454
removed block 48 current accuracy 0.6832 loss from initial  0.2712
since last training loss: 0.26459999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 49, with score 0.059370. All blocks and scores: [(49, 0.059370397590100765), (50, 0.07940818555653095), (39, 0.08223064243793488), (13, 0.08482636976987123), (3, 0.08617415651679039), (19, 0.08854176942259073), (11, 0.08998917415738106), (22, 0.09142232220619917), (10, 0.09317858796566725), (7, 0.09496094472706318), (26, 0.10179050825536251), (12, 0.10214697569608688), (0, 0.1057867594063282), (15, 0.11640935577452183), (9, 0.12432768195867538), (8, 0.12636156287044287), (16, 0.13514435105025768), (5, 0.13677820190787315), (4, 0.18138462863862514), (1, 0.18887954391539097), (17, 0.22641393914818764), (36, 0.48389124497771263), (18, 0.5372063666582108)]
computing accuracy for after removing block 49 . block score: 0.059370397590100765
removed block 49 current accuracy 0.6538 loss from initial  0.3006
since last training loss: 0.29399999999999993 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 50, with score 0.040399. All blocks and scores: [(50, 0.04039907734841108), (39, 0.08223064243793488), (13, 0.08482637070119381), (3, 0.08617415837943554), (19, 0.08854176849126816), (11, 0.08998917136341333), (22, 0.09142231941223145), (10, 0.09317858796566725), (7, 0.0949609437957406), (26, 0.10179050453007221), (12, 0.10214697476476431), (0, 0.10578676033765078), (15, 0.11640935484319925), (9, 0.12432768382132053), (8, 0.12636156752705574), (16, 0.13514435477554798), (5, 0.1367782037705183), (4, 0.18138462677598), (1, 0.18887954764068127), (17, 0.22641392797231674), (36, 0.4838912598788738), (18, 0.5372063592076302)]
computing accuracy for after removing block 50 . block score: 0.04039907734841108
removed block 50 current accuracy 0.5954 loss from initial  0.359
training start
training epoch 0 val accuracy 0.8146 topk_dict {'top1': 0.8146} is_best True lr [0.1]
training epoch 1 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best True lr [0.1]
training epoch 2 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 3 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.1]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 5 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 6 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 7 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 8 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 9 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 10 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 33
[activation diff]: block to remove picked: 10, with score 0.104276. All blocks and scores: [(10, 0.10427576117217541), (11, 0.11678112111985683), (3, 0.11743796057999134), (0, 0.11820007767528296), (13, 0.12291272077709436), (7, 0.13466713391244411), (15, 0.13964263163506985), (9, 0.14056836999952793), (12, 0.14163517579436302), (8, 0.14733807183802128), (19, 0.14739624224603176), (5, 0.15902589075267315), (16, 0.17235125228762627), (22, 0.17255758307874203), (26, 0.21051562018692493), (4, 0.22497452422976494), (1, 0.22812552191317081), (17, 0.2864697352051735), (18, 0.5181329697370529), (36, 0.7379336878657341), (39, 1.2097621858119965)]
computing accuracy for after removing block 10 . block score: 0.10427576117217541
removed block 10 current accuracy 0.924 loss from initial  0.030399999999999983
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 11, with score 0.112008. All blocks and scores: [(11, 0.1120078843086958), (13, 0.11227602884173393), (3, 0.11743796057999134), (0, 0.11820008046925068), (12, 0.13004268519580364), (7, 0.13466713204979897), (15, 0.13799920678138733), (9, 0.14056837186217308), (19, 0.1426248624920845), (8, 0.14733807370066643), (5, 0.1590258926153183), (16, 0.16432594694197178), (22, 0.1681048832833767), (26, 0.19809777103364468), (4, 0.2249745223671198), (1, 0.22812552191317081), (17, 0.26000726222991943), (18, 0.48694493994116783), (36, 0.7104584127664566), (39, 1.1562538892030716)]
computing accuracy for after removing block 11 . block score: 0.1120078843086958
removed block 11 current accuracy 0.9062 loss from initial  0.04820000000000002
since last training loss: 0.03059999999999996 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 13, with score 0.105360. All blocks and scores: [(13, 0.1053598765283823), (3, 0.11743795685470104), (0, 0.11820007674396038), (12, 0.12444570567458868), (7, 0.13466713204979897), (19, 0.13912471570074558), (15, 0.13955334201455116), (9, 0.14056836999952793), (8, 0.14733807556331158), (16, 0.15765497460961342), (5, 0.15902589075267315), (22, 0.1619106326252222), (26, 0.182650750502944), (4, 0.22497452050447464), (1, 0.2281255293637514), (17, 0.23212205804884434), (18, 0.46818698570132256), (36, 0.6804553419351578), (39, 1.0565003752708435)]
computing accuracy for after removing block 13 . block score: 0.1053598765283823
removed block 13 current accuracy 0.8854 loss from initial  0.06900000000000006
since last training loss: 0.0514 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.117438. All blocks and scores: [(3, 0.11743795871734619), (0, 0.11820008046925068), (12, 0.12444570567458868), (15, 0.13052274659276009), (7, 0.13466713204979897), (19, 0.139035040512681), (9, 0.14056836813688278), (8, 0.14733807183802128), (16, 0.1513301618397236), (22, 0.15754117257893085), (5, 0.15902589075267315), (26, 0.17243891023099422), (17, 0.21123320423066616), (4, 0.2249745223671198), (1, 0.2281255330890417), (18, 0.46347857266664505), (36, 0.6707342267036438), (39, 0.9820979982614517)]
computing accuracy for after removing block 3 . block score: 0.11743795871734619
removed block 3 current accuracy 0.8458 loss from initial  0.10860000000000003
since last training loss: 0.09099999999999997 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 0, with score 0.118200. All blocks and scores: [(0, 0.11820008233189583), (12, 0.12286462634801865), (15, 0.12539640348404646), (7, 0.13505973294377327), (9, 0.13756833225488663), (19, 0.13997451029717922), (16, 0.14593992941081524), (8, 0.14803384989500046), (22, 0.16031939163804054), (26, 0.1639545075595379), (5, 0.16837850771844387), (17, 0.22146477177739143), (1, 0.2281255293637514), (4, 0.2308734655380249), (18, 0.46455661579966545), (36, 0.652508445084095), (39, 0.9295860975980759)]
computing accuracy for after removing block 0 . block score: 0.11820008233189583
removed block 0 current accuracy 0.7122 loss from initial  0.24219999999999997
since last training loss: 0.2245999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 12, with score 0.110153. All blocks and scores: [(12, 0.11015344597399235), (15, 0.11611878778785467), (9, 0.12450434640049934), (7, 0.12569479271769524), (19, 0.12691183388233185), (16, 0.13674770668148994), (26, 0.1431555300951004), (8, 0.14562097750604153), (22, 0.15245414897799492), (5, 0.17518447898328304), (17, 0.20549163408577442), (4, 0.21995787881314754), (1, 0.3147113025188446), (18, 0.46220018342137337), (36, 0.5905865952372551), (39, 0.7150076851248741)]
computing accuracy for after removing block 12 . block score: 0.11015344597399235
removed block 12 current accuracy 0.5558 loss from initial  0.39860000000000007
since last training loss: 0.381 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 19, with score 0.123154. All blocks and scores: [(19, 0.12315426208078861), (9, 0.12450434360653162), (7, 0.12569479644298553), (26, 0.12944402359426022), (15, 0.13166578486561775), (8, 0.14562097564339638), (16, 0.14714736677706242), (22, 0.1493355557322502), (5, 0.17518447898328304), (4, 0.21995788626372814), (17, 0.2529036980122328), (1, 0.314711295068264), (18, 0.48268912360072136), (36, 0.57833531498909), (39, 0.5986878946423531)]
computing accuracy for after removing block 19 . block score: 0.12315426208078861
removed block 19 current accuracy 0.4886 loss from initial  0.46580000000000005
since last training loss: 0.4482 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 26, with score 0.111325. All blocks and scores: [(26, 0.1113254688680172), (9, 0.12450434640049934), (7, 0.1256947899237275), (15, 0.1316657904535532), (8, 0.14562097750604153), (16, 0.14714736491441727), (22, 0.1490181852132082), (5, 0.17518448270857334), (4, 0.21995788626372814), (17, 0.25290368869900703), (1, 0.314711295068264), (18, 0.48268912732601166), (36, 0.5137883722782135), (39, 0.5603752285242081)]
computing accuracy for after removing block 26 . block score: 0.1113254688680172
removed block 26 current accuracy 0.3338 loss from initial  0.6206
since last training loss: 0.603 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 9, with score 0.124504. All blocks and scores: [(9, 0.1245043445378542), (7, 0.1256947936490178), (15, 0.1316657941788435), (8, 0.14562097750604153), (16, 0.14714736491441727), (22, 0.1490181852132082), (5, 0.1751844845712185), (4, 0.2199578881263733), (17, 0.25290369614958763), (1, 0.3147112987935543), (18, 0.48268911615014076), (36, 0.511044904589653), (39, 0.6635199040174484)]
computing accuracy for after removing block 9 . block score: 0.1245043445378542
removed block 9 current accuracy 0.2012 loss from initial  0.7532000000000001
since last training loss: 0.7356 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 7, with score 0.125695. All blocks and scores: [(7, 0.12569479458034039), (8, 0.14562097750604153), (22, 0.14614519104361534), (16, 0.1531126331537962), (15, 0.15408392809331417), (5, 0.1751844845712185), (4, 0.2199578806757927), (17, 0.3049727864563465), (1, 0.3147113025188446), (36, 0.5192224010825157), (18, 0.5544070154428482), (39, 0.6606439650058746)]
computing accuracy for after removing block 7 . block score: 0.12569479458034039
removed block 7 current accuracy 0.1542 loss from initial  0.8002
since last training loss: 0.7826 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 22, with score 0.160605. All blocks and scores: [(22, 0.16060548648238182), (5, 0.17518448270857334), (16, 0.178625063970685), (15, 0.1888546608388424), (8, 0.19828497804701328), (4, 0.2199578918516636), (1, 0.3147113062441349), (17, 0.3741965591907501), (36, 0.5635985881090164), (39, 0.6641284227371216), (18, 0.6733434721827507)]
computing accuracy for after removing block 22 . block score: 0.16060548648238182
removed block 22 current accuracy 0.142 loss from initial  0.8124
since last training loss: 0.7948 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 5, with score 0.175184. All blocks and scores: [(5, 0.17518449015915394), (16, 0.178625063970685), (15, 0.1888546571135521), (8, 0.19828497245907784), (4, 0.2199578806757927), (1, 0.3147112987935543), (17, 0.374196570366621), (36, 0.5768578350543976), (18, 0.6733434721827507), (39, 0.9998157694935799)]
computing accuracy for after removing block 5 . block score: 0.17518449015915394
removed block 5 current accuracy 0.1364 loss from initial  0.8180000000000001
training start
training epoch 0 val accuracy 0.7978 topk_dict {'top1': 0.7978} is_best True lr [0.1]
training epoch 1 val accuracy 0.8224 topk_dict {'top1': 0.8224} is_best True lr [0.1]
training epoch 2 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best True lr [0.1]
training epoch 3 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best False lr [0.1]
training epoch 4 val accuracy 0.85 topk_dict {'top1': 0.85} is_best True lr [0.1]
training epoch 5 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best True lr [0.1]
training epoch 6 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best False lr [0.1]
training epoch 7 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 8 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 9 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.921800)
finished training. finished 50 epochs. accuracy 0.9218 topk_dict {'top1': 0.9218}
