start iteration 0
[activation diff]: block to remove picked: 35, with score 0.014275. All blocks and scores: [(35, 0.014274864573962986), (34, 0.014493348775431514), (33, 0.015328855952247977), (32, 0.015401355107314885), (27, 0.016854834044352174), (24, 0.017396228620782495), (26, 0.017841696506366134), (31, 0.017852150602266192), (23, 0.01801178534515202), (37, 0.018020291812717915), (28, 0.018068780191242695), (20, 0.01833631657063961), (25, 0.018579796887934208), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (38, 0.019831779412925243), (21, 0.0206660027615726), (40, 0.020699823275208473), (41, 0.02083682408556342), (39, 0.02187428600154817), (42, 0.023939984617754817), (44, 0.027291724225506186), (43, 0.027380845742300153), (53, 0.028202867368236184), (19, 0.028207604540511966), (52, 0.028415298089385033), (51, 0.02968065650202334), (45, 0.030162296956405044), (46, 0.03169302875176072), (50, 0.03270378056913614), (49, 0.03325698943808675), (47, 0.035937456879764795), (3, 0.036418330390006304), (2, 0.036608734633773565), (48, 0.038299502804875374), (6, 0.04146078694611788), (13, 0.042333432007580996), (11, 0.049629763700068), (14, 0.05005708336830139), (7, 0.050499150063842535), (8, 0.05102512938901782), (15, 0.05208516912534833), (10, 0.052327943965792656), (16, 0.055893843062222004), (12, 0.05712253646925092), (0, 0.057175627909600735), (9, 0.06140707992017269), (5, 0.06478630565106869), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.0842915466055274), (18, 0.15011722408235073), (36, 0.23893354088068008)]
computing accuracy for after removing block 35 . block score: 0.014274864573962986
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 34, with score 0.014493. All blocks and scores: [(34, 0.014493348775431514), (33, 0.015328856068663299), (32, 0.015401354874484241), (37, 0.016689840238541365), (27, 0.016854834044352174), (24, 0.01739622838795185), (26, 0.017841696739196777), (31, 0.017852150136604905), (23, 0.01801178464666009), (28, 0.01806877995841205), (20, 0.018336316337808967), (38, 0.018370160134509206), (25, 0.018579797819256783), (30, 0.018911650637164712), (29, 0.01901709265075624), (22, 0.019087886670604348), (40, 0.01957211922854185), (41, 0.019616978941485286), (39, 0.02027514297515154), (21, 0.02066600159741938), (42, 0.022649952676147223), (43, 0.025927708949893713), (44, 0.026192617136985064), (53, 0.027608862379565835), (52, 0.027642244240269065), (19, 0.02820760547183454), (51, 0.028980921022593975), (45, 0.02902725525200367), (46, 0.03040681197308004), (50, 0.03191784326918423), (49, 0.03241685125976801), (47, 0.034735485911369324), (3, 0.03641833085566759), (2, 0.03660873603075743), (48, 0.037143451161682606), (6, 0.041460785549134016), (13, 0.042333432007580996), (11, 0.049629766028374434), (14, 0.05005708197131753), (7, 0.050499150063842535), (8, 0.05102512938901782), (15, 0.05208517052233219), (10, 0.05232794117182493), (16, 0.05589384352788329), (12, 0.057122535072267056), (0, 0.05717562744393945), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764197200537), (17, 0.08429154846817255), (18, 0.15011721849441528), (36, 0.2226911447942257)]
computing accuracy for after removing block 34 . block score: 0.014493348775431514
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.015329. All blocks and scores: [(33, 0.015328856301493943), (32, 0.015401355107314885), (37, 0.015649043722078204), (27, 0.016854834044352174), (38, 0.017188325058668852), (24, 0.017396228620782495), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336315639317036), (25, 0.01857979758642614), (41, 0.018633503234013915), (40, 0.01864513522014022), (30, 0.018911651335656643), (39, 0.018983178306370974), (29, 0.01901709265075624), (22, 0.019087885972112417), (21, 0.020666001830250025), (42, 0.021567409858107567), (43, 0.02474153903312981), (44, 0.02524121943861246), (52, 0.02675225562416017), (53, 0.02690034988336265), (45, 0.02801583451218903), (51, 0.028131889877840877), (19, 0.02820760663598776), (46, 0.029172033071517944), (50, 0.03104190109297633), (49, 0.03151613404043019), (47, 0.03355775820091367), (48, 0.03598395921289921), (3, 0.03641833225265145), (2, 0.03660873556509614), (6, 0.041460785549134016), (13, 0.04233343340456486), (11, 0.049629764165729284), (14, 0.05005708243697882), (7, 0.050499150063842535), (8, 0.05102512985467911), (15, 0.052085170056670904), (10, 0.05232794210314751), (16, 0.05589384399354458), (12, 0.057122535072267056), (0, 0.05717562884092331), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764104068279), (17, 0.08429154846817255), (18, 0.15011722035706043), (36, 0.2054912280291319)]
computing accuracy for after removing block 33 . block score: 0.015328856301493943
removed block 33 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 37, with score 0.014727. All blocks and scores: [(37, 0.014727167319506407), (32, 0.01540135475806892), (38, 0.01608753460459411), (27, 0.01685483381152153), (24, 0.017396228853613138), (41, 0.017636816250160336), (39, 0.01765656378120184), (40, 0.017719466472044587), (26, 0.017841695807874203), (31, 0.017852150136604905), (23, 0.01801178534515202), (28, 0.018068780191242695), (20, 0.01833631657063961), (25, 0.01857979712076485), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886903434992), (42, 0.02041433728300035), (21, 0.020666002295911312), (43, 0.023449429543688893), (44, 0.02405423135496676), (52, 0.025544948177412152), (53, 0.025872941128909588), (45, 0.026672408916056156), (51, 0.027040921384468675), (46, 0.027673480799421668), (19, 0.028207605006173253), (50, 0.029852008214220405), (49, 0.030292703304439783), (47, 0.0320238652639091), (48, 0.03438834333792329), (3, 0.03641833132132888), (2, 0.036608734633773565), (6, 0.0414607860147953), (13, 0.04233343340456486), (11, 0.049629764165729284), (14, 0.05005708243697882), (7, 0.050499150063842535), (8, 0.05102512938901782), (15, 0.05208517052233219), (10, 0.05232794117182493), (16, 0.055893843062222004), (12, 0.05712253553792834), (0, 0.05717562884092331), (9, 0.06140707898885012), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.0842915466055274), (18, 0.15011722035706043), (36, 0.19365960732102394)]
computing accuracy for after removing block 37 . block score: 0.014727167319506407
removed block 37 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 38, with score 0.015322. All blocks and scores: [(38, 0.015321659971959889), (32, 0.015401354641653597), (41, 0.015430084196850657), (40, 0.015811878954991698), (39, 0.016038152622058988), (27, 0.016854834044352174), (24, 0.017396228155121207), (42, 0.017457410460337996), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.018068780191242695), (20, 0.018336316337808967), (25, 0.01857979712076485), (30, 0.018911651335656643), (29, 0.019017092417925596), (22, 0.019087886670604348), (43, 0.019953368930146098), (44, 0.02043514302931726), (21, 0.020666002295911312), (52, 0.021591540426015854), (53, 0.0220107426866889), (45, 0.022627739002928138), (51, 0.02283536223694682), (46, 0.023026632145047188), (50, 0.025466163409873843), (49, 0.02559669967740774), (47, 0.026748374104499817), (19, 0.02820760477334261), (48, 0.028763408539816737), (3, 0.036418331786990166), (2, 0.03660873556509614), (6, 0.04146078648045659), (13, 0.04233343293890357), (11, 0.049629763700068), (14, 0.05005708150565624), (7, 0.05049915285781026), (8, 0.05102512938901782), (15, 0.05208516959100962), (10, 0.05232794350013137), (16, 0.055893843062222004), (12, 0.05712253553792834), (0, 0.057175627909600735), (9, 0.06140707992017269), (5, 0.06478630565106869), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.0842915466055274), (18, 0.15011721849441528), (36, 0.1936596129089594)]
computing accuracy for after removing block 38 . block score: 0.015321659971959889
removed block 38 current accuracy 0.94 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 41, with score 0.013861. All blocks and scores: [(41, 0.013860960956662893), (40, 0.014671427547000349), (42, 0.015341256279498339), (32, 0.015401355223730206), (39, 0.015461977454833686), (27, 0.016854834044352174), (24, 0.017396228620782495), (43, 0.017514181323349476), (44, 0.01754390518181026), (26, 0.01784169627353549), (31, 0.017852150602266192), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336316337808967), (52, 0.018348957411944866), (25, 0.018579797353595495), (53, 0.018839580938220024), (30, 0.01891165040433407), (29, 0.019017092417925596), (22, 0.019087886437773705), (45, 0.019300541374832392), (46, 0.01930436701513827), (51, 0.019394941395148635), (21, 0.020666002295911312), (49, 0.021678968565538526), (50, 0.021847274620085955), (47, 0.022476087557151914), (48, 0.02421563444659114), (19, 0.028207604540511966), (3, 0.036418329924345016), (2, 0.0366087332367897), (6, 0.04146078694611788), (13, 0.04233343247324228), (11, 0.049629763700068), (14, 0.05005708197131753), (7, 0.05049915099516511), (8, 0.05102512985467911), (15, 0.05208516912534833), (10, 0.05232794163748622), (16, 0.05589384539052844), (12, 0.05712253646925092), (0, 0.05717562884092331), (9, 0.06140707805752754), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764197200537), (17, 0.08429154846817255), (18, 0.15011722035706043), (36, 0.19365961104631424)]
computing accuracy for after removing block 41 . block score: 0.013860960956662893
removed block 41 current accuracy 0.937 loss from initial  0.01739999999999997
training start
training epoch 0 val accuracy 0.7884 topk_dict {'top1': 0.7884} is_best False lr [0.1]
training epoch 1 val accuracy 0.8016 topk_dict {'top1': 0.8016} is_best False lr [0.1]
training epoch 2 val accuracy 0.799 topk_dict {'top1': 0.799} is_best False lr [0.1]
training epoch 3 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 4 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.1]
training epoch 5 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 6 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 7 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 8 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 9 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 6
[activation diff]: block to remove picked: 53, with score 0.023196. All blocks and scores: [(53, 0.02319637732580304), (19, 0.02761656534858048), (24, 0.030473033199086785), (20, 0.030921361409127712), (49, 0.03130442509427667), (32, 0.033028644509613514), (3, 0.033851750660687685), (51, 0.0340913669206202), (29, 0.03412967408075929), (30, 0.03468576958402991), (23, 0.036435616202652454), (27, 0.0367565150372684), (31, 0.03714651148766279), (46, 0.03737609647214413), (45, 0.03769948100671172), (22, 0.03820771211758256), (25, 0.03915205039083958), (50, 0.040679403115063906), (28, 0.04094709688797593), (43, 0.040984420105814934), (21, 0.0419291160069406), (52, 0.042076030280441046), (26, 0.04355114232748747), (48, 0.044309130404144526), (2, 0.045180163346230984), (47, 0.0461735506542027), (44, 0.04661088390275836), (0, 0.047173094004392624), (42, 0.05584529275074601), (40, 0.055865047965198755), (4, 0.06319929845631123), (39, 0.06465673539787531), (6, 0.0677195405587554), (7, 0.06830139085650444), (1, 0.07028156239539385), (8, 0.07900391984730959), (13, 0.07969519030302763), (10, 0.08018657099455595), (5, 0.08401756174862385), (15, 0.08595706429332495), (14, 0.08736639656126499), (11, 0.08832618407905102), (9, 0.09286332316696644), (12, 0.10178579483181238), (16, 0.10776908602565527), (17, 0.12285140622407198), (18, 0.3258810490369797), (36, 0.4629735164344311)]
computing accuracy for after removing block 53 . block score: 0.02319637732580304
removed block 53 current accuracy 0.9436 loss from initial  0.010800000000000032
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.027617. All blocks and scores: [(19, 0.02761656465008855), (24, 0.03047303343191743), (20, 0.030921361641958356), (49, 0.03130442462861538), (32, 0.03302864404395223), (3, 0.03385175112634897), (51, 0.034091366454958916), (29, 0.03412967501208186), (30, 0.0346857700496912), (23, 0.03643561480566859), (27, 0.036756514105945826), (31, 0.03714651195332408), (46, 0.03737609647214413), (45, 0.03769948147237301), (22, 0.038207713048905134), (25, 0.03915205132216215), (50, 0.04067940218374133), (28, 0.04094709549099207), (43, 0.040984421502798796), (21, 0.041929117403924465), (52, 0.04207603121176362), (26, 0.04355114093050361), (48, 0.04430913086980581), (2, 0.04518016381189227), (47, 0.046173549722880125), (44, 0.04661088343709707), (0, 0.04717309633269906), (42, 0.055845294147729874), (40, 0.05586504843086004), (4, 0.0631993031129241), (39, 0.06465673353523016), (6, 0.06771954242140055), (7, 0.06830139271914959), (1, 0.07028156239539385), (8, 0.07900392264127731), (13, 0.07969519030302763), (10, 0.08018657006323338), (5, 0.0840175598859787), (15, 0.08595706708729267), (14, 0.08736639469861984), (11, 0.08832618594169617), (9, 0.09286332316696644), (12, 0.10178579483181238), (16, 0.10776908323168755), (17, 0.12285140249878168), (18, 0.32588106021285057), (36, 0.4629735164344311)]
computing accuracy for after removing block 19 . block score: 0.02761656465008855
removed block 19 current accuracy 0.94 loss from initial  0.01440000000000008
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 24, with score 0.029043. All blocks and scores: [(24, 0.029042508685961366), (20, 0.030135797802358866), (49, 0.030149376252666116), (32, 0.03110899613238871), (30, 0.03280490403994918), (29, 0.03281855583190918), (51, 0.03302082186564803), (3, 0.03385175159201026), (27, 0.034369138069450855), (31, 0.03479500347748399), (23, 0.03534567356109619), (46, 0.0364141957834363), (45, 0.03645179606974125), (22, 0.03699977928772569), (25, 0.037373201455920935), (50, 0.03868449851870537), (28, 0.03880517324432731), (43, 0.03974303463473916), (52, 0.04024830739945173), (21, 0.041281542275100946), (26, 0.041387165896594524), (48, 0.04265426052734256), (47, 0.044997989665716887), (44, 0.045040749944746494), (2, 0.045180164743214846), (0, 0.04717309679836035), (42, 0.053623894695192575), (40, 0.0538399638608098), (39, 0.061217674519866705), (4, 0.0631993031129241), (6, 0.06771953962743282), (7, 0.06830139085650444), (1, 0.07028156332671642), (8, 0.07900392077863216), (13, 0.07969519030302763), (10, 0.08018657192587852), (5, 0.08401756081730127), (15, 0.08595706708729267), (14, 0.08736639842391014), (11, 0.08832618407905102), (9, 0.09286332223564386), (12, 0.10178579390048981), (16, 0.10776908602565527), (17, 0.1228514052927494), (18, 0.3258810453116894), (36, 0.4184638671576977)]
computing accuracy for after removing block 24 . block score: 0.029042508685961366
removed block 24 current accuracy 0.9362 loss from initial  0.018199999999999994
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 49, with score 0.029275. All blocks and scores: [(49, 0.029274692991748452), (32, 0.02974785608239472), (20, 0.030135798268020153), (30, 0.031159892678260803), (29, 0.032106393948197365), (51, 0.03220569039694965), (27, 0.03272464917972684), (31, 0.032888757064938545), (3, 0.03385175112634897), (23, 0.03534567542374134), (46, 0.035613938234746456), (45, 0.035723666194826365), (25, 0.036471724044531584), (28, 0.03685103263705969), (22, 0.03699977928772569), (50, 0.03726247977465391), (52, 0.038726203609257936), (43, 0.03879823675379157), (26, 0.03987472178414464), (48, 0.04126297403126955), (21, 0.041281542275100946), (44, 0.04365543415769935), (47, 0.04396056989207864), (2, 0.04518016427755356), (0, 0.047173097264021635), (42, 0.051541577093303204), (40, 0.051632100250571966), (39, 0.05854543251916766), (4, 0.06319930218160152), (6, 0.06771953962743282), (7, 0.06830138992518187), (1, 0.0702815605327487), (8, 0.07900392170995474), (13, 0.07969519030302763), (10, 0.08018657006323338), (5, 0.084017563611269), (15, 0.08595706708729267), (14, 0.08736639656126499), (11, 0.08832618501037359), (9, 0.09286332596093416), (12, 0.10178579576313496), (16, 0.10776908602565527), (17, 0.1228514015674591), (18, 0.32588105276227), (36, 0.38200969621539116)]
computing accuracy for after removing block 49 . block score: 0.029274692991748452
removed block 49 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 51, with score 0.027549. All blocks and scores: [(51, 0.0275487476028502), (32, 0.029747856548056006), (20, 0.03013579989783466), (30, 0.03115989314392209), (29, 0.03210639301687479), (52, 0.03261916642077267), (27, 0.03272464731708169), (31, 0.03288875613361597), (50, 0.0330889499746263), (3, 0.033851750660687685), (23, 0.035345674492418766), (46, 0.03561393916606903), (45, 0.035723666194826365), (25, 0.036471723578870296), (28, 0.036851031705737114), (22, 0.03699978021904826), (43, 0.03879823675379157), (26, 0.039874722715467215), (48, 0.04126297403126955), (21, 0.04128154320642352), (44, 0.04365543369203806), (47, 0.04396056896075606), (2, 0.045180163346230984), (0, 0.04717309633269906), (42, 0.051541577093303204), (40, 0.05163209931924939), (39, 0.05854543298482895), (4, 0.0631993031129241), (6, 0.06771954149007797), (7, 0.06830139085650444), (1, 0.07028156239539385), (8, 0.07900392170995474), (13, 0.07969519030302763), (10, 0.08018657192587852), (5, 0.08401755895465612), (15, 0.0859570661559701), (14, 0.08736639842391014), (11, 0.08832618501037359), (9, 0.09286332502961159), (12, 0.10178579296916723), (16, 0.10776908043771982), (17, 0.1228514015674591), (18, 0.3258810490369797), (36, 0.38200970739126205)]
computing accuracy for after removing block 51 . block score: 0.0275487476028502
removed block 51 current accuracy 0.9334 loss from initial  0.02100000000000002
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 52, with score 0.028915. All blocks and scores: [(52, 0.028915302827954292), (32, 0.02974785608239472), (20, 0.03013579803518951), (30, 0.03115989384241402), (29, 0.032106393948197365), (27, 0.032724648248404264), (31, 0.03288875613361597), (50, 0.03308894904330373), (3, 0.03385175112634897), (23, 0.03534567402675748), (46, 0.03561393963173032), (45, 0.03572366572916508), (25, 0.036471724044531584), (28, 0.036851031705737114), (22, 0.03699978021904826), (43, 0.03879823675379157), (26, 0.03987472224980593), (48, 0.041262974962592125), (21, 0.041281542740762234), (44, 0.04365543369203806), (47, 0.04396056896075606), (2, 0.04518016427755356), (0, 0.047173095401376486), (42, 0.05154157616198063), (40, 0.051632100716233253), (39, 0.0585454348474741), (4, 0.0631993031129241), (6, 0.06771954149007797), (7, 0.06830139271914959), (1, 0.07028156146407127), (8, 0.07900392450392246), (13, 0.0796951912343502), (10, 0.0801865691319108), (5, 0.08401756267994642), (15, 0.0859570661559701), (14, 0.08736639842391014), (11, 0.08832618501037359), (9, 0.09286332223564386), (12, 0.10178579296916723), (16, 0.10776908230036497), (17, 0.12285140249878168), (18, 0.3258810415863991), (36, 0.38200970366597176)]
computing accuracy for after removing block 52 . block score: 0.028915302827954292
removed block 52 current accuracy 0.9306 loss from initial  0.023800000000000043
training start
training epoch 0 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 1 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 2 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 3 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 4 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 5 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 6 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 9 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 12
[activation diff]: block to remove picked: 3, with score 0.033905. All blocks and scores: [(3, 0.03390528587624431), (20, 0.038660184014588594), (29, 0.03932322794571519), (2, 0.040419850032776594), (0, 0.04102796129882336), (23, 0.04184824740514159), (27, 0.04206733964383602), (31, 0.043138076551258564), (28, 0.043577495496720076), (26, 0.0442949035204947), (30, 0.0443171770311892), (22, 0.04478093422949314), (32, 0.04605349199846387), (25, 0.047513766679912806), (21, 0.04880202375352383), (43, 0.04890978895127773), (45, 0.05264508305117488), (40, 0.06281711999326944), (46, 0.06293326523154974), (44, 0.06405238900333643), (39, 0.06515391170978546), (42, 0.06719829048961401), (1, 0.06742522586137056), (4, 0.07028610538691282), (6, 0.07670377008616924), (10, 0.07758425269275904), (13, 0.07764298003166914), (7, 0.08115999680012465), (15, 0.084364403039217), (47, 0.08601505123078823), (14, 0.0878250515088439), (11, 0.091011181473732), (48, 0.0917259156703949), (5, 0.09491851646453142), (9, 0.0963773587718606), (12, 0.09780252538621426), (50, 0.09797498490661383), (8, 0.10537872463464737), (16, 0.11800888646394014), (17, 0.14814598485827446), (18, 0.35552267357707024), (36, 0.46285074949264526)]
computing accuracy for after removing block 3 . block score: 0.03390528587624431
removed block 3 current accuracy 0.9444 loss from initial  0.010000000000000009
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.038180. All blocks and scores: [(20, 0.03818025905638933), (29, 0.03828453365713358), (2, 0.040419851429760456), (0, 0.04102796083316207), (23, 0.04103956837207079), (27, 0.04198130266740918), (31, 0.04232572903856635), (30, 0.042981641832739115), (28, 0.04302833369001746), (26, 0.04374685836955905), (22, 0.043771935161203146), (32, 0.04549924982711673), (25, 0.046801289077848196), (21, 0.04826720664277673), (43, 0.048921083100140095), (45, 0.05117296287789941), (40, 0.06201487826183438), (46, 0.06216835929080844), (44, 0.0634309696033597), (39, 0.06424904614686966), (42, 0.06702655833214521), (1, 0.06742522399872541), (4, 0.07276377081871033), (13, 0.07410856802016497), (10, 0.07442232500761747), (6, 0.07736870925873518), (7, 0.08044202625751495), (15, 0.08225359208881855), (14, 0.08425137680023909), (47, 0.08585491869598627), (11, 0.08732421230524778), (48, 0.09059469401836395), (9, 0.09198563173413277), (12, 0.09497490525245667), (5, 0.09652544651180506), (50, 0.09692080970853567), (8, 0.10174782108515501), (16, 0.11321082059293985), (17, 0.1444673240184784), (18, 0.33177681267261505), (36, 0.44740980863571167)]
computing accuracy for after removing block 20 . block score: 0.03818025905638933
removed block 20 current accuracy 0.9384 loss from initial  0.016000000000000014
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 29, with score 0.036249. All blocks and scores: [(29, 0.03624880127608776), (27, 0.0381797943264246), (31, 0.039071149192750454), (23, 0.039432003162801266), (28, 0.03992370003834367), (26, 0.04025908838957548), (2, 0.04041985189542174), (30, 0.04052496748045087), (0, 0.041027961764484644), (22, 0.04167397040873766), (32, 0.04293179325759411), (25, 0.04444886511191726), (43, 0.04574791993945837), (21, 0.04742039041593671), (45, 0.049048272892832756), (40, 0.057919432409107685), (39, 0.058890384156256914), (46, 0.059179205913096666), (44, 0.06023911479860544), (42, 0.06206279434263706), (1, 0.06742522399872541), (4, 0.07276377081871033), (13, 0.07410856895148754), (10, 0.07442232500761747), (6, 0.07736871019005775), (7, 0.08044202905148268), (15, 0.08225359302014112), (47, 0.08265583775937557), (14, 0.08425137493759394), (48, 0.08647954929620028), (11, 0.08732421509921551), (9, 0.09198563173413277), (50, 0.09228302910923958), (12, 0.09497490432113409), (5, 0.09652545023709536), (8, 0.10174782108515501), (16, 0.11321081966161728), (17, 0.1444673277437687), (18, 0.33177680894732475), (36, 0.4038468785583973)]
computing accuracy for after removing block 29 . block score: 0.03624880127608776
removed block 29 current accuracy 0.9296 loss from initial  0.024800000000000044
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 31, with score 0.037836. All blocks and scores: [(31, 0.03783558402210474), (27, 0.03817979525774717), (23, 0.03943200455978513), (28, 0.03992370003834367), (26, 0.04025908838957548), (2, 0.04041985096409917), (30, 0.040565363597124815), (0, 0.04102796129882336), (22, 0.041673969477415085), (32, 0.04171057743951678), (43, 0.042780499905347824), (25, 0.04444886464625597), (45, 0.04627421358600259), (21, 0.04742039041593671), (39, 0.05447180150076747), (40, 0.0548858642578125), (46, 0.056578232906758785), (44, 0.05758985923603177), (42, 0.05790245672687888), (1, 0.06742522539570928), (4, 0.0727637680247426), (13, 0.07410856988281012), (10, 0.07442232500761747), (6, 0.07736871112138033), (47, 0.0779762789607048), (7, 0.08044203091412783), (48, 0.08207049127668142), (15, 0.08225359302014112), (14, 0.08425137773156166), (50, 0.08692638855427504), (11, 0.08732421230524778), (9, 0.09198563359677792), (12, 0.09497490245848894), (5, 0.09652545023709536), (8, 0.10174782201647758), (16, 0.11321081966161728), (17, 0.14446732588112354), (18, 0.33177681639790535), (36, 0.3781171031296253)]
computing accuracy for after removing block 31 . block score: 0.03783558402210474
removed block 31 current accuracy 0.9244 loss from initial  0.030000000000000027
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 27, with score 0.038180. All blocks and scores: [(27, 0.03817979525774717), (23, 0.03943200362846255), (43, 0.03984344145283103), (28, 0.039923700504004955), (26, 0.040259087923914194), (2, 0.04041985049843788), (30, 0.0405653640627861), (0, 0.04102796129882336), (32, 0.0413756868802011), (22, 0.0416739690117538), (45, 0.04283493058755994), (25, 0.044448867440223694), (21, 0.047420392744243145), (39, 0.05074281012639403), (40, 0.05155042512342334), (46, 0.05361630581319332), (42, 0.053890131413936615), (44, 0.05468770628795028), (1, 0.06742522679269314), (47, 0.07234890013933182), (4, 0.07276377081871033), (13, 0.07410856895148754), (10, 0.0744223240762949), (48, 0.07622599974274635), (6, 0.07736871019005775), (50, 0.07961696665734053), (7, 0.0804420281201601), (15, 0.08225359302014112), (14, 0.08425137586891651), (11, 0.08732421416789293), (9, 0.09198563266545534), (12, 0.09497490338981152), (5, 0.09652544744312763), (8, 0.10174781922250986), (16, 0.11321082059293985), (17, 0.14446732588112354), (18, 0.33177680522203445), (36, 0.35443973541259766)]
computing accuracy for after removing block 27 . block score: 0.03817979525774717
removed block 27 current accuracy 0.9128 loss from initial  0.04160000000000008
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 43, with score 0.037219. All blocks and scores: [(43, 0.03721943264827132), (28, 0.03898202581331134), (23, 0.03943200362846255), (30, 0.03960955888032913), (45, 0.040089437272399664), (26, 0.040259089320898056), (2, 0.04041985049843788), (32, 0.040777680929750204), (0, 0.04102796129882336), (22, 0.0416739690117538), (25, 0.044448865577578545), (21, 0.04742039041593671), (39, 0.04748218506574631), (40, 0.04877265403047204), (42, 0.050274334382265806), (46, 0.05086445342749357), (44, 0.05240303138270974), (47, 0.06702473387122154), (1, 0.06742522679269314), (48, 0.07056537363678217), (4, 0.07276376895606518), (50, 0.0735696917399764), (13, 0.07410857174545527), (10, 0.07442232593894005), (6, 0.07736871019005775), (7, 0.0804420281201601), (15, 0.0822535939514637), (14, 0.08425137400627136), (11, 0.08732421323657036), (9, 0.09198563173413277), (12, 0.09497490338981152), (5, 0.09652544558048248), (8, 0.10174781922250986), (16, 0.1132108187302947), (17, 0.14446732588112354), (18, 0.33177680894732475), (36, 0.3349785916507244)]
computing accuracy for after removing block 43 . block score: 0.03721943264827132
removed block 43 current accuracy 0.9078 loss from initial  0.046599999999999975
training start
training epoch 0 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 1 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 2 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 3 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 4 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 5 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 7 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.046276. All blocks and scores: [(23, 0.04627616610378027), (0, 0.04863756708800793), (22, 0.05485214199870825), (30, 0.058317968621850014), (45, 0.05878611421212554), (32, 0.061409282963722944), (25, 0.06243240972980857), (44, 0.06411332171410322), (28, 0.06587051879614592), (21, 0.06630758196115494), (46, 0.0666984198614955), (26, 0.06685136444866657), (40, 0.06999629084020853), (39, 0.07218815665692091), (2, 0.0723319249227643), (1, 0.07809564657509327), (42, 0.07920362241566181), (13, 0.07949036452919245), (7, 0.08110861107707024), (6, 0.08153312094509602), (47, 0.08887309581041336), (15, 0.0889006182551384), (11, 0.09079969022423029), (10, 0.0908748721703887), (4, 0.09224109537899494), (12, 0.09533188492059708), (14, 0.09773909859359264), (48, 0.10168718453496695), (5, 0.11194956954568624), (50, 0.11591233685612679), (8, 0.12068606354296207), (9, 0.12196519691497087), (16, 0.13604575209319592), (17, 0.17642376944422722), (18, 0.35361839830875397), (36, 0.48390551283955574)]
computing accuracy for after removing block 23 . block score: 0.04627616610378027
removed block 23 current accuracy 0.9414 loss from initial  0.013000000000000012
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 0, with score 0.048638. All blocks and scores: [(0, 0.048637565691024065), (22, 0.054852144327014685), (30, 0.05512326769530773), (45, 0.056302092038095), (32, 0.05688156979158521), (25, 0.06049968954175711), (44, 0.061011329758912325), (28, 0.06163244787603617), (26, 0.0632120743393898), (46, 0.0647459328174591), (21, 0.06630758568644524), (40, 0.06696164514869452), (39, 0.06782267428934574), (2, 0.07233192399144173), (42, 0.07504507526755333), (1, 0.07809564657509327), (13, 0.07949036732316017), (7, 0.08110861387103796), (6, 0.08153312094509602), (47, 0.08497609663754702), (15, 0.08890061732381582), (11, 0.09079968929290771), (10, 0.09087486751377583), (4, 0.09224109631031752), (12, 0.09533188585191965), (14, 0.09773910045623779), (48, 0.098170917481184), (50, 0.11159828118979931), (5, 0.11194956954568624), (8, 0.1206860626116395), (9, 0.12196519877761602), (16, 0.13604574650526047), (17, 0.17642376944422722), (18, 0.35361839085817337), (36, 0.4360506013035774)]
computing accuracy for after removing block 0 . block score: 0.048637565691024065
removed block 0 current accuracy 0.9378 loss from initial  0.01660000000000006
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 30, with score 0.052391. All blocks and scores: [(30, 0.05239093583077192), (22, 0.053644496481865644), (32, 0.05410788021981716), (45, 0.05447071138769388), (25, 0.05842484161257744), (44, 0.05917756957933307), (28, 0.0603069681674242), (26, 0.06133842980489135), (46, 0.0639655077829957), (40, 0.06407580338418484), (21, 0.0648330245167017), (39, 0.06564964726567268), (42, 0.07366971764713526), (13, 0.07552154269069433), (7, 0.07575241103768349), (2, 0.07719300873577595), (6, 0.07869121991097927), (1, 0.08281334303319454), (15, 0.0828199964016676), (47, 0.08332894835621119), (11, 0.08352302014827728), (10, 0.0852856058627367), (4, 0.08867689222097397), (12, 0.08907811716198921), (14, 0.0940809240564704), (48, 0.09616136364638805), (50, 0.10825383942574263), (5, 0.1085524084046483), (9, 0.11090629454702139), (8, 0.1120273806154728), (16, 0.12623324897140265), (17, 0.15995298884809017), (18, 0.32320231571793556), (36, 0.4158485718071461)]
computing accuracy for after removing block 30 . block score: 0.05239093583077192
removed block 30 current accuracy 0.9352 loss from initial  0.019199999999999995
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.050820. All blocks and scores: [(45, 0.050819508731365204), (32, 0.051607406698167324), (22, 0.05364449555054307), (44, 0.05540038179606199), (25, 0.058424840215593576), (40, 0.059136489406228065), (39, 0.05986474920064211), (28, 0.06030696723610163), (46, 0.06075600767508149), (26, 0.0613384279422462), (21, 0.06483302358537912), (42, 0.06793368421494961), (13, 0.07552153989672661), (7, 0.07575241196900606), (2, 0.07719300873577595), (47, 0.0781524907797575), (6, 0.07869121991097927), (1, 0.08281334303319454), (15, 0.08281999360769987), (11, 0.08352301735430956), (10, 0.08528560400009155), (4, 0.08867689222097397), (12, 0.08907811529934406), (48, 0.08993274345993996), (14, 0.09408092591911554), (50, 0.10078569687902927), (5, 0.10855240654200315), (9, 0.11090629454702139), (8, 0.11202737968415022), (16, 0.12623324990272522), (17, 0.15995299071073532), (18, 0.32320232316851616), (36, 0.37120121717453003)]
computing accuracy for after removing block 45 . block score: 0.050819508731365204
removed block 45 current accuracy 0.9296 loss from initial  0.024800000000000044
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 32, with score 0.051607. All blocks and scores: [(32, 0.051607404835522175), (46, 0.05167521769180894), (22, 0.05364449694752693), (44, 0.05540038272738457), (25, 0.058424840681254864), (40, 0.05913649033755064), (39, 0.059864749666303396), (28, 0.06030696863308549), (26, 0.06133842933923006), (47, 0.06437980476766825), (21, 0.06483302731066942), (42, 0.06793368048965931), (48, 0.07046686392277479), (13, 0.07552154175937176), (7, 0.07575241383165121), (2, 0.07719300966709852), (50, 0.07828064914792776), (6, 0.0786912189796567), (1, 0.08281334303319454), (15, 0.08281999547034502), (11, 0.08352301828563213), (10, 0.0852856058627367), (4, 0.0886768912896514), (12, 0.08907811716198921), (14, 0.09408092591911554), (5, 0.10855240281671286), (9, 0.11090629175305367), (8, 0.11202738154679537), (16, 0.12623324990272522), (17, 0.15995299443602562), (18, 0.32320231571793556), (36, 0.37120122089982033)]
computing accuracy for after removing block 32 . block score: 0.051607404835522175
removed block 32 current accuracy 0.9214 loss from initial  0.03300000000000003
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 46, with score 0.048437. All blocks and scores: [(46, 0.04843748128041625), (44, 0.05097902612760663), (40, 0.05332947755232453), (22, 0.05364449741318822), (39, 0.053786402102559805), (25, 0.05842483974993229), (47, 0.0589193576015532), (28, 0.0603069681674242), (42, 0.060820397455245256), (26, 0.06133842747658491), (48, 0.06434441590681672), (21, 0.06483302358537912), (50, 0.07092807814478874), (13, 0.07552154175937176), (7, 0.07575241196900606), (2, 0.0771930105984211), (6, 0.07869122177362442), (1, 0.08281334303319454), (15, 0.08281999826431274), (11, 0.08352302014827728), (10, 0.08528560679405928), (4, 0.08867689035832882), (12, 0.08907811250537634), (14, 0.09408092498779297), (5, 0.108552404679358), (9, 0.11090629175305367), (8, 0.1120273806154728), (16, 0.12623324897140265), (17, 0.15995298884809017), (18, 0.32320230454206467), (36, 0.3358139246702194)]
computing accuracy for after removing block 46 . block score: 0.04843748128041625
removed block 46 current accuracy 0.9146 loss from initial  0.03980000000000006
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.050352. All blocks and scores: [(47, 0.05035222927108407), (44, 0.05097902566194534), (48, 0.05161603959277272), (40, 0.053329477086663246), (22, 0.053644494619220495), (39, 0.05378640163689852), (50, 0.055098652839660645), (25, 0.058424840215593576), (28, 0.0603069681674242), (42, 0.060820396058261395), (26, 0.06133842887356877), (21, 0.0648330245167017), (13, 0.07552154082804918), (7, 0.07575241103768349), (2, 0.07719301152974367), (6, 0.07869122084230185), (1, 0.08281334396451712), (15, 0.08281999547034502), (11, 0.08352302107959986), (10, 0.08528560493141413), (4, 0.08867689222097397), (12, 0.08907811436802149), (14, 0.09408092591911554), (5, 0.10855240747332573), (9, 0.11090629268437624), (8, 0.11202737782150507), (16, 0.1262332508340478), (17, 0.15995299443602562), (18, 0.32320230454206467), (36, 0.3358139172196388)]
computing accuracy for after removing block 47 . block score: 0.05035222927108407
removed block 47 current accuracy 0.9008 loss from initial  0.05359999999999998
since last training loss: 0.04379999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.039682. All blocks and scores: [(48, 0.03968230914324522), (50, 0.040490337647497654), (44, 0.050979023333638906), (40, 0.05332947755232453), (22, 0.05364449741318822), (39, 0.05378640163689852), (25, 0.05842484114691615), (28, 0.060306969564408064), (42, 0.06082039652392268), (26, 0.061338428407907486), (21, 0.0648330245167017), (13, 0.07552154082804918), (7, 0.07575241290032864), (2, 0.07719300966709852), (6, 0.0786912189796567), (1, 0.08281334303319454), (15, 0.08281999547034502), (11, 0.08352301921695471), (10, 0.08528560493141413), (4, 0.08867689222097397), (12, 0.08907811529934406), (14, 0.09408092312514782), (5, 0.10855240374803543), (9, 0.11090628895908594), (8, 0.11202738340944052), (16, 0.1262332508340478), (17, 0.15995298512279987), (18, 0.32320230826735497), (36, 0.3358139209449291)]
computing accuracy for after removing block 48 . block score: 0.03968230914324522
removed block 48 current accuracy 0.8824 loss from initial  0.07200000000000006
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.036560. All blocks and scores: [(50, 0.036560455337166786), (44, 0.050979025196284056), (40, 0.05332947801798582), (22, 0.05364449601620436), (39, 0.05378640163689852), (25, 0.058424842078238726), (28, 0.060306967701762915), (42, 0.060820397455245256), (26, 0.061338427010923624), (21, 0.06483302358537912), (13, 0.07552154269069433), (7, 0.07575241196900606), (2, 0.07719300873577595), (6, 0.0786912189796567), (1, 0.08281334210187197), (15, 0.08281999453902245), (11, 0.08352302014827728), (10, 0.08528560493141413), (4, 0.0886768912896514), (12, 0.08907811529934406), (14, 0.0940809240564704), (5, 0.108552404679358), (9, 0.11090629268437624), (8, 0.11202738527208567), (16, 0.12623324897140265), (17, 0.15995298884809017), (18, 0.32320233061909676), (36, 0.3358139209449291)]
computing accuracy for after removing block 50 . block score: 0.036560455337166786
removed block 50 current accuracy 0.8358 loss from initial  0.11860000000000004
training start
training epoch 0 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 1 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 2 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 3 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 4 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 5 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 6 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 7 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 8 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 9 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 10 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
