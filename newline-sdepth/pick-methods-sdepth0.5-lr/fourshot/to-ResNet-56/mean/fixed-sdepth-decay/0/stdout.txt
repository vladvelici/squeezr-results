start iteration 0
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778), (53, 0.02245476096868515)]
computing accuracy for after removing block 53 . block score: 0.02245476096868515
removed block 53 current accuracy 0.9532 loss from initial  0.0011999999999999789
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347), (52, 0.023782813921570778)]
computing accuracy for after removing block 52 . block score: 0.023782813921570778
removed block 52 current accuracy 0.9534 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383), (51, 0.026051300577819347)]
computing accuracy for after removing block 51 . block score: 0.026051300577819347
removed block 51 current accuracy 0.953 loss from initial  0.0014000000000000679
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694), (50, 0.028078997507691383)]
computing accuracy for after removing block 50 . block score: 0.028078997507691383
removed block 50 current accuracy 0.951 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084), (49, 0.030814231373369694)]
computing accuracy for after removing block 49 . block score: 0.030814231373369694
removed block 49 current accuracy 0.9494 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.07136088237166405), (1, 0.0888589471578598), (2, 0.08127762749791145), (3, 0.08875898271799088), (4, 0.09609780460596085), (5, 0.09690440073609352), (6, 0.08746771141886711), (7, 0.09428361430764198), (8, 0.1031683050096035), (9, 0.10369560122489929), (10, 0.10174929723143578), (11, 0.09929701313376427), (12, 0.1021420769393444), (13, 0.09310123324394226), (14, 0.09316366165876389), (15, 0.09867966920137405), (16, 0.09818907082080841), (17, 0.09526941925287247), (18, 0.2880859076976776), (19, 0.07831832394003868), (20, 0.07700443267822266), (21, 0.07817058265209198), (22, 0.07501716166734695), (23, 0.0751398354768753), (24, 0.06952084228396416), (25, 0.0690668635070324), (26, 0.06911325268447399), (27, 0.06575516425073147), (28, 0.0639996137470007), (29, 0.06135444529354572), (30, 0.06023447401821613), (31, 0.05770525895059109), (32, 0.053539762273430824), (33, 0.05264761485159397), (34, 0.050709931179881096), (35, 0.049367547035217285), (36, 0.18950849026441574), (37, 0.054791899397969246), (38, 0.055474258959293365), (39, 0.05418492294847965), (40, 0.05264146812260151), (41, 0.05119327828288078), (42, 0.0500375609844923), (43, 0.04886435717344284), (44, 0.04579608142375946), (45, 0.04362349584698677), (46, 0.04001962952315807), (47, 0.03726085647940636), (48, 0.034880238585174084)]
computing accuracy for after removing block 48 . block score: 0.034880238585174084
removed block 48 current accuracy 0.9462 loss from initial  0.008199999999999985
training start
training epoch 0 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 1 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 2 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.1]
training epoch 3 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 4 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 5 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 6 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 7 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 8 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9514 topk_dict {'top1': 0.9514}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (35, 0.06678987108170986), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217), (44, 0.06410619802772999), (45, 0.05893553048372269), (46, 0.05429106578230858), (47, 0.04962170496582985)]
computing accuracy for after removing block 47 . block score: 0.04962170496582985
removed block 47 current accuracy 0.9488 loss from initial  0.005600000000000049
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (35, 0.06678987108170986), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217), (44, 0.06410619802772999), (45, 0.05893553048372269), (46, 0.05429106578230858)]
computing accuracy for after removing block 46 . block score: 0.05429106578230858
removed block 46 current accuracy 0.9456 loss from initial  0.00880000000000003
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (35, 0.06678987108170986), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217), (44, 0.06410619802772999), (45, 0.05893553048372269)]
computing accuracy for after removing block 45 . block score: 0.05893553048372269
removed block 45 current accuracy 0.9394 loss from initial  0.015000000000000013
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (35, 0.06678987108170986), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217), (44, 0.06410619802772999)]
computing accuracy for after removing block 44 . block score: 0.06410619802772999
removed block 44 current accuracy 0.9248 loss from initial  0.02960000000000007
since last training loss: 0.026600000000000068 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (35, 0.06678987108170986), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217)]
computing accuracy for after removing block 35 . block score: 0.06678987108170986
removed block 35 current accuracy 0.9252 loss from initial  0.029200000000000004
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.08853764086961746), (1, 0.11046847328543663), (2, 0.1042906641960144), (3, 0.10836436599493027), (4, 0.1278059184551239), (5, 0.1269000619649887), (6, 0.11944300681352615), (7, 0.12452816963195801), (8, 0.13749991357326508), (9, 0.13974881172180176), (10, 0.13857248425483704), (11, 0.1350458264350891), (12, 0.13846082985401154), (13, 0.12811900302767754), (14, 0.12981268763542175), (15, 0.13859889656305313), (16, 0.13570542261004448), (17, 0.13057779148221016), (18, 0.3926486074924469), (19, 0.1020851843059063), (20, 0.1001499816775322), (21, 0.1013859175145626), (22, 0.09752382710576057), (23, 0.09902378544211388), (24, 0.09172871336340904), (25, 0.08984234556555748), (26, 0.09069625288248062), (27, 0.08689625561237335), (28, 0.08367778733372688), (29, 0.0811506099998951), (30, 0.0793234333395958), (31, 0.07691875100135803), (32, 0.07097869738936424), (33, 0.07002728804945946), (34, 0.0669026393443346), (36, 0.25883813574910164), (37, 0.07533145323395729), (38, 0.07497019320726395), (39, 0.07381745800375938), (40, 0.07236303016543388), (41, 0.07014351338148117), (42, 0.06911728158593178), (43, 0.06753524020314217)]
computing accuracy for after removing block 34 . block score: 0.0669026393443346
removed block 34 current accuracy 0.9214 loss from initial  0.03300000000000003
training start
training epoch 0 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 1 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 2 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 3 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 4 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 5 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 6 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 7 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 8 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 9 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.950200)
finished training. finished 50 epochs. accuracy 0.9502 topk_dict {'top1': 0.9502}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (32, 0.07696834951639175), (33, 0.07510777190327644), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583), (41, 0.08071435242891312), (42, 0.07580697536468506), (43, 0.07131493650376797)]
computing accuracy for after removing block 43 . block score: 0.07131493650376797
removed block 43 current accuracy 0.9454 loss from initial  0.009000000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (32, 0.07696834951639175), (33, 0.07510777190327644), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583), (41, 0.08071435242891312), (42, 0.07580697536468506)]
computing accuracy for after removing block 33 . block score: 0.07510777190327644
removed block 33 current accuracy 0.9454 loss from initial  0.009000000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (32, 0.07696834951639175), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583), (41, 0.08071435242891312), (42, 0.07580697536468506)]
computing accuracy for after removing block 42 . block score: 0.07580697536468506
removed block 42 current accuracy 0.934 loss from initial  0.020399999999999974
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (32, 0.07696834951639175), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583), (41, 0.08071435242891312)]
computing accuracy for after removing block 32 . block score: 0.07696834951639175
removed block 32 current accuracy 0.9308 loss from initial  0.023600000000000065
since last training loss: 0.019400000000000084 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583), (41, 0.08071435242891312)]
computing accuracy for after removing block 41 . block score: 0.08071435242891312
removed block 41 current accuracy 0.9056 loss from initial  0.048800000000000066
since last training loss: 0.044600000000000084 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.08946745097637177), (1, 0.11079930141568184), (2, 0.10284606367349625), (3, 0.10938279703259468), (4, 0.12864254415035248), (5, 0.12788673490285873), (6, 0.12163382023572922), (7, 0.12725894898176193), (8, 0.13932380080223083), (9, 0.13924242556095123), (10, 0.13962212949991226), (11, 0.1364109218120575), (12, 0.14168183505535126), (13, 0.12898634001612663), (14, 0.1323421262204647), (15, 0.14040466398000717), (16, 0.14044874161481857), (17, 0.13307984918355942), (18, 0.4038603752851486), (19, 0.10402608290314674), (20, 0.10245928168296814), (21, 0.1048487238585949), (22, 0.10171480849385262), (23, 0.10275949910283089), (24, 0.09586097672581673), (25, 0.0963725820183754), (26, 0.09613939002156258), (27, 0.09255005419254303), (28, 0.08981019631028175), (29, 0.08659930154681206), (30, 0.08518031239509583), (31, 0.0819186419248581), (36, 0.27159853279590607), (37, 0.08414898440241814), (38, 0.08425212278962135), (39, 0.08402588218450546), (40, 0.08166423812508583)]
computing accuracy for after removing block 40 . block score: 0.08166423812508583
removed block 40 current accuracy 0.869 loss from initial  0.08540000000000003
training start
training epoch 0 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.1]
training epoch 1 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 2 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.1]
training epoch 3 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 4 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 5 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 6 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.1]
training epoch 7 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 8 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 9 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.08913667872548103), (1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (29, 0.09543437510728836), (30, 0.09346523135900497), (31, 0.09266778081655502), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213), (39, 0.09301892668008804)]
computing accuracy for after removing block 0 . block score: 0.08913667872548103
removed block 0 current accuracy 0.9424 loss from initial  0.01200000000000001
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (29, 0.09543437510728836), (30, 0.09346523135900497), (31, 0.09266778081655502), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213), (39, 0.09301892668008804)]
computing accuracy for after removing block 31 . block score: 0.09266778081655502
removed block 31 current accuracy 0.9392 loss from initial  0.015199999999999991
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (29, 0.09543437510728836), (30, 0.09346523135900497), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213), (39, 0.09301892668008804)]
computing accuracy for after removing block 39 . block score: 0.09301892668008804
removed block 39 current accuracy 0.9198 loss from initial  0.034600000000000075
since last training loss: 0.02740000000000009 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (29, 0.09543437510728836), (30, 0.09346523135900497), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213)]
computing accuracy for after removing block 30 . block score: 0.09346523135900497
removed block 30 current accuracy 0.9158 loss from initial  0.03860000000000008
since last training loss: 0.031400000000000095 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (29, 0.09543437510728836), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213)]
computing accuracy for after removing block 29 . block score: 0.09543437510728836
removed block 29 current accuracy 0.9012 loss from initial  0.053200000000000025
since last training loss: 0.04600000000000004 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (28, 0.09662314876914024), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213)]
computing accuracy for after removing block 28 . block score: 0.09662314876914024
removed block 28 current accuracy 0.8858 loss from initial  0.0686
since last training loss: 0.06140000000000001 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (36, 0.27935487031936646), (37, 0.10105251893401146), (38, 0.09786085039377213)]
computing accuracy for after removing block 38 . block score: 0.09786085039377213
removed block 38 current accuracy 0.821 loss from initial  0.13340000000000007
since last training loss: 0.1262000000000001 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (36, 0.27935487031936646), (37, 0.10105251893401146)]
computing accuracy for after removing block 37 . block score: 0.10105251893401146
removed block 37 current accuracy 0.7188 loss from initial  0.23560000000000003
since last training loss: 0.22840000000000005 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(1, 0.10822055116295815), (2, 0.10182075202465057), (3, 0.11103545874357224), (4, 0.13225091248750687), (5, 0.12876413017511368), (6, 0.12060961499810219), (7, 0.12621758878231049), (8, 0.14136339724063873), (9, 0.13812658935785294), (10, 0.13950110971927643), (11, 0.1361963152885437), (12, 0.1419677659869194), (13, 0.1311645805835724), (14, 0.13038790225982666), (15, 0.14223863929510117), (16, 0.13974462822079659), (17, 0.13691582903265953), (18, 0.41028328984975815), (19, 0.10876143723726273), (20, 0.10756279900670052), (21, 0.10942188650369644), (22, 0.10711696371436119), (23, 0.10824056714773178), (24, 0.10272426903247833), (25, 0.10267309471964836), (26, 0.1032244972884655), (27, 0.10187061131000519), (36, 0.27935487031936646)]
computing accuracy for after removing block 2 . block score: 0.10182075202465057
removed block 2 current accuracy 0.6972 loss from initial  0.2572
training start
training epoch 0 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.1]
training epoch 1 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.1]
training epoch 2 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 3 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.1]
training epoch 4 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 5 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 6 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 7 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 8 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 9 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.1]
training epoch 10 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
loading model_best from epoch 11 (acc 0.929600)
finished training. finished 50 epochs. accuracy 0.9296 topk_dict {'top1': 0.9296}
