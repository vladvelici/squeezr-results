start iteration 0
[activation mean]: block to remove picked: 35, with score 0.094478. All blocks and scores: [(35, 0.09447801485657692), (34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.14710238575935364), (19, 0.14895895309746265), (53, 0.1498922035098076), (52, 0.15163039043545723), (51, 0.1535380631685257), (13, 0.15705686062574387), (14, 0.16249225474894047), (38, 0.16445158794522285), (50, 0.16464474610984325), (49, 0.1657810639590025), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (40, 0.173427015542984), (16, 0.17345409654080868), (41, 0.17369753867387772), (11, 0.17475955933332443), (46, 0.17609802819788456), (45, 0.17827162519097328), (39, 0.1792436372488737), (44, 0.18025114387273788), (48, 0.18066065199673176), (42, 0.18066276982426643), (47, 0.18073148280382156), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (43, 0.189305879175663), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.23272303864359856), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 35 . block score: 0.09447801485657692
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.096040. All blocks and scores: [(34, 0.09604021441191435), (32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.1407872699201107), (53, 0.14861096628010273), (19, 0.14895895309746265), (52, 0.14969445951282978), (51, 0.1523898020386696), (13, 0.15705686062574387), (38, 0.15781539678573608), (14, 0.16249225474894047), (50, 0.16313881427049637), (49, 0.16411315463483334), (40, 0.1689014621078968), (41, 0.1690248530358076), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (7, 0.17230932973325253), (39, 0.17247052490711212), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (46, 0.17373871989548206), (11, 0.17475955933332443), (45, 0.17579046078026295), (42, 0.1771144587546587), (44, 0.17722493782639503), (47, 0.17847622744739056), (48, 0.1788573693484068), (8, 0.18169353157281876), (12, 0.18286443874239922), (43, 0.18561581149697304), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (36, 0.2266793828457594), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 34 . block score: 0.09604021441191435
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.097944. All blocks and scores: [(32, 0.09794430993497372), (33, 0.09876384120434523), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13551420159637928), (53, 0.14707430079579353), (52, 0.14760426990687847), (19, 0.14895895309746265), (51, 0.15091686882078648), (38, 0.1523499172180891), (13, 0.15705686062574387), (50, 0.16150624863803387), (14, 0.16249225474894047), (49, 0.1625587809830904), (40, 0.16517788171768188), (41, 0.16536311618983746), (39, 0.16688678227365017), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (46, 0.1715139839798212), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (45, 0.1736477129161358), (42, 0.1742321215569973), (11, 0.17475955933332443), (44, 0.1747924704104662), (47, 0.17631406895816326), (48, 0.17726918868720531), (8, 0.18169353157281876), (43, 0.1826457940042019), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (0, 0.21818812005221844), (4, 0.21831642091274261), (36, 0.221288425847888), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 32 . block score: 0.09794430993497372
removed block 32 current accuracy 0.945 loss from initial  0.009400000000000075
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 33, with score 0.096237. All blocks and scores: [(33, 0.0962365735322237), (31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (21, 0.1281397920101881), (37, 0.13045251369476318), (53, 0.14460941962897778), (52, 0.14462984167039394), (38, 0.1469358094036579), (51, 0.1486178170889616), (19, 0.14895895309746265), (13, 0.15705686062574387), (50, 0.15898261778056622), (49, 0.1601924430578947), (39, 0.1610004734247923), (41, 0.16117839701473713), (40, 0.16137539595365524), (14, 0.16249225474894047), (46, 0.16855736821889877), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (45, 0.1705855056643486), (42, 0.17088175937533379), (44, 0.17191905342042446), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (47, 0.17325890436768532), (16, 0.17345409654080868), (48, 0.1746351718902588), (11, 0.17475955933332443), (43, 0.17927574925124645), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21651554107666016), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 33 . block score: 0.0962365735322237
removed block 33 current accuracy 0.9408 loss from initial  0.013600000000000056
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 31, with score 0.106299. All blocks and scores: [(31, 0.10629933141171932), (27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (20, 0.12209091056138277), (37, 0.1261464450508356), (21, 0.1281397920101881), (52, 0.141027070581913), (53, 0.14170901477336884), (38, 0.14201517030596733), (51, 0.14598987624049187), (19, 0.14895895309746265), (39, 0.15555569157004356), (50, 0.15602300502359867), (13, 0.15705686062574387), (49, 0.15735810063779354), (41, 0.15751718543469906), (40, 0.15766894072294235), (14, 0.16249225474894047), (46, 0.16544132120907307), (45, 0.16723843477666378), (42, 0.16781402193009853), (44, 0.16861379332840443), (6, 0.16913926228880882), (47, 0.17008974589407444), (15, 0.17030494660139084), (3, 0.17048806883394718), (48, 0.17144453153014183), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (43, 0.1758242715150118), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.21325702220201492), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 31 . block score: 0.10629933141171932
removed block 31 current accuracy 0.9354 loss from initial  0.019000000000000017
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 27, with score 0.107886. All blocks and scores: [(27, 0.10788614861667156), (28, 0.10817730147391558), (26, 0.11042157281190157), (30, 0.11212856136262417), (24, 0.11232952307909727), (29, 0.11303758434951305), (25, 0.11343235615640879), (23, 0.11373872216790915), (22, 0.11607348453253508), (37, 0.12083858530968428), (20, 0.12209091056138277), (21, 0.1281397920101881), (38, 0.13578535057604313), (52, 0.13683941774070263), (53, 0.13806491903960705), (51, 0.1427531000226736), (39, 0.14883904717862606), (19, 0.14895895309746265), (50, 0.1524738073348999), (41, 0.15277637541294098), (40, 0.15300416387617588), (49, 0.15408698096871376), (13, 0.15705686062574387), (46, 0.16158179938793182), (14, 0.16249225474894047), (45, 0.16341477446258068), (42, 0.1641642488539219), (44, 0.16474203765392303), (47, 0.1662686076015234), (48, 0.16778318211436272), (6, 0.16913926228880882), (15, 0.17030494660139084), (3, 0.17048806883394718), (43, 0.17166327871382236), (7, 0.17230932973325253), (2, 0.17280340939760208), (10, 0.1728231180459261), (16, 0.17345409654080868), (11, 0.17475955933332443), (8, 0.18169353157281876), (12, 0.18286443874239922), (17, 0.18872835859656334), (9, 0.19659682922065258), (36, 0.2090455386787653), (0, 0.21818812005221844), (4, 0.21831642091274261), (5, 0.22163648903369904), (1, 0.2530518490821123), (18, 0.2581006772816181)]
computing accuracy for after removing block 27 . block score: 0.10788614861667156
removed block 27 current accuracy 0.924 loss from initial  0.030399999999999983
training start
training epoch 0 val accuracy 0.7352 topk_dict {'top1': 0.7352} is_best False lr [0.1]
training epoch 1 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best False lr [0.1]
training epoch 2 val accuracy 0.7628 topk_dict {'top1': 0.7628} is_best False lr [0.1]
training epoch 3 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 4 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 5 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 6 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 8 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 9 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 6
[activation mean]: block to remove picked: 28, with score 0.148462. All blocks and scores: [(28, 0.14846182242035866), (22, 0.15488664619624615), (25, 0.16352573037147522), (26, 0.16362916119396687), (29, 0.16632595472037792), (19, 0.16810337826609612), (24, 0.16835728101432323), (30, 0.174284303560853), (20, 0.1766368243843317), (2, 0.17698737978935242), (53, 0.17707878164947033), (3, 0.17811059020459652), (0, 0.17835295759141445), (23, 0.1788298264145851), (7, 0.1842323001474142), (21, 0.18466215208172798), (52, 0.18985609337687492), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (11, 0.20275738835334778), (15, 0.2087310291826725), (1, 0.2113904096186161), (51, 0.21596702560782433), (50, 0.21628381498157978), (49, 0.21950554847717285), (10, 0.22636812552809715), (4, 0.2304838690906763), (48, 0.2341015450656414), (12, 0.23569751344621181), (17, 0.23941286094486713), (16, 0.24062084965407848), (37, 0.24431194737553596), (8, 0.24822593107819557), (40, 0.2497171200811863), (43, 0.2503852117806673), (9, 0.2504796478897333), (5, 0.25083664432168007), (41, 0.25451743230223656), (46, 0.2555803060531616), (38, 0.2587707079946995), (45, 0.2596376799046993), (47, 0.2597152590751648), (39, 0.2621056139469147), (44, 0.2640637271106243), (42, 0.2647343538701534), (18, 0.3381791226565838), (36, 0.3652413785457611)]
computing accuracy for after removing block 28 . block score: 0.14846182242035866
removed block 28 current accuracy 0.9428 loss from initial  0.011600000000000055
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 22, with score 0.154887. All blocks and scores: [(22, 0.15488664619624615), (25, 0.16352573037147522), (26, 0.16362916119396687), (29, 0.16632588766515255), (19, 0.16810337826609612), (24, 0.16835728101432323), (30, 0.17022716253995895), (53, 0.1730287130922079), (20, 0.1766368243843317), (2, 0.17698737978935242), (3, 0.17811059020459652), (0, 0.17835295759141445), (23, 0.1788298264145851), (7, 0.1842323001474142), (21, 0.18466215208172798), (52, 0.1865836326032877), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (11, 0.20275738835334778), (15, 0.2087310291826725), (1, 0.2113904096186161), (51, 0.21361233480274677), (50, 0.21419929340481758), (49, 0.21707194298505783), (10, 0.22636812552809715), (4, 0.2304838690906763), (48, 0.23122665472328663), (12, 0.23569751344621181), (37, 0.23582278937101364), (17, 0.23941286094486713), (16, 0.24062084965407848), (40, 0.2438819520175457), (43, 0.24464586935937405), (41, 0.24635493755340576), (8, 0.24822593107819557), (38, 0.24920048378407955), (9, 0.2504796478897333), (5, 0.25083664432168007), (46, 0.2525061145424843), (45, 0.254660964012146), (39, 0.2558106631040573), (47, 0.2565017640590668), (42, 0.2585832215845585), (44, 0.2604830972850323), (18, 0.3381791226565838), (36, 0.3592291735112667)]
computing accuracy for after removing block 22 . block score: 0.15488664619624615
removed block 22 current accuracy 0.9372 loss from initial  0.017199999999999993
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.161415. All blocks and scores: [(26, 0.1614154763519764), (25, 0.16283420287072659), (29, 0.1637619063258171), (30, 0.16651743277907372), (24, 0.1671622283756733), (19, 0.16810337826609612), (53, 0.16966717690229416), (23, 0.17587967589497566), (20, 0.1766368243843317), (2, 0.17698737978935242), (3, 0.17811059020459652), (0, 0.17835295759141445), (52, 0.18383551388978958), (7, 0.1842323001474142), (21, 0.18466215208172798), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (11, 0.20275738835334778), (15, 0.2087310291826725), (51, 0.2112855464220047), (1, 0.2113904096186161), (50, 0.2127336710691452), (49, 0.21513969637453556), (10, 0.22636812552809715), (37, 0.22688917443156242), (48, 0.2290485892444849), (4, 0.2304838690906763), (12, 0.23569751344621181), (40, 0.2363787442445755), (41, 0.23928479477763176), (43, 0.23932419158518314), (17, 0.23941286094486713), (16, 0.24062084965407848), (38, 0.24076056480407715), (8, 0.24822593107819557), (39, 0.24946807883679867), (46, 0.24981693923473358), (45, 0.2503480724990368), (9, 0.2504796478897333), (5, 0.25083664432168007), (42, 0.2531932629644871), (47, 0.25356488674879074), (44, 0.25657209008932114), (18, 0.3381791226565838), (36, 0.3528258129954338)]
computing accuracy for after removing block 26 . block score: 0.1614154763519764
removed block 26 current accuracy 0.9342 loss from initial  0.020199999999999996
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.162834. All blocks and scores: [(25, 0.16283420287072659), (53, 0.16330523043870926), (29, 0.1634037960320711), (30, 0.1641128920018673), (24, 0.1671622283756733), (19, 0.16810337826609612), (23, 0.17587967589497566), (20, 0.1766368243843317), (2, 0.17698737978935242), (3, 0.17811059020459652), (52, 0.17811762914061546), (0, 0.17835295759141445), (7, 0.1842323001474142), (21, 0.18466215208172798), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (11, 0.20275738835334778), (51, 0.2062672208994627), (50, 0.20813594572246075), (15, 0.2087310291826725), (49, 0.21005205623805523), (1, 0.2113904096186161), (37, 0.21643357165157795), (48, 0.22325647808611393), (10, 0.22636812552809715), (40, 0.22869803756475449), (38, 0.22891331650316715), (41, 0.2298189364373684), (4, 0.2304838690906763), (43, 0.23146448843181133), (12, 0.23569751344621181), (17, 0.23941286094486713), (16, 0.24062084965407848), (39, 0.24090449139475822), (45, 0.24338851682841778), (42, 0.24425158463418484), (46, 0.2448477428406477), (47, 0.2474075723439455), (8, 0.24822593107819557), (9, 0.2504796478897333), (5, 0.25083664432168007), (44, 0.25086313486099243), (18, 0.3381791226565838), (36, 0.3438488319516182)]
computing accuracy for after removing block 25 . block score: 0.16283420287072659
removed block 25 current accuracy 0.9244 loss from initial  0.030000000000000027
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 53, with score 0.158179. All blocks and scores: [(53, 0.1581793613731861), (30, 0.16158635914325714), (29, 0.16334004141390324), (24, 0.1671622283756733), (19, 0.16810337826609612), (52, 0.17332695238292217), (23, 0.17587967589497566), (20, 0.1766368243843317), (2, 0.17698737978935242), (3, 0.17811059020459652), (0, 0.17835295759141445), (7, 0.1842323001474142), (21, 0.18466215208172798), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (51, 0.20206709764897823), (11, 0.20275738835334778), (50, 0.20496715418994427), (49, 0.20687375403940678), (37, 0.2073095478117466), (15, 0.2087310291826725), (1, 0.2113904096186161), (38, 0.21793435513973236), (48, 0.21910804510116577), (40, 0.22186492197215557), (41, 0.2225002832710743), (43, 0.226229477673769), (10, 0.22636812552809715), (4, 0.2304838690906763), (39, 0.2334747463464737), (12, 0.23569751344621181), (42, 0.2377416156232357), (45, 0.23840246722102165), (17, 0.23941286094486713), (16, 0.24062084965407848), (47, 0.24224902130663395), (46, 0.2423958983272314), (44, 0.24621405079960823), (8, 0.24822593107819557), (9, 0.2504796478897333), (5, 0.25083664432168007), (36, 0.3373907767236233), (18, 0.3381791226565838)]
computing accuracy for after removing block 53 . block score: 0.1581793613731861
removed block 53 current accuracy 0.9228 loss from initial  0.03160000000000007
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 30, with score 0.161586. All blocks and scores: [(30, 0.16158635914325714), (29, 0.16334004141390324), (24, 0.1671622283756733), (19, 0.16810337826609612), (52, 0.17332695238292217), (23, 0.17587967589497566), (20, 0.1766368243843317), (2, 0.17698737978935242), (3, 0.17811059020459652), (0, 0.17835295759141445), (7, 0.1842323001474142), (21, 0.18466215208172798), (13, 0.1932909656316042), (14, 0.1978212669491768), (6, 0.20060724020004272), (51, 0.20206709764897823), (11, 0.20275738835334778), (50, 0.20496715418994427), (49, 0.20687375403940678), (37, 0.2073095478117466), (15, 0.2087310291826725), (1, 0.2113904096186161), (38, 0.21793435513973236), (48, 0.21910804510116577), (40, 0.22186492197215557), (41, 0.2225002832710743), (43, 0.226229477673769), (10, 0.22636812552809715), (4, 0.2304838690906763), (39, 0.2334747463464737), (12, 0.23569751344621181), (42, 0.2377416156232357), (45, 0.23840246722102165), (17, 0.23941286094486713), (16, 0.24062084965407848), (47, 0.24224902130663395), (46, 0.2423958983272314), (44, 0.24621405079960823), (8, 0.24822593107819557), (9, 0.2504796478897333), (5, 0.25083664432168007), (36, 0.3373907767236233), (18, 0.3381791226565838)]
computing accuracy for after removing block 30 . block score: 0.16158635914325714
removed block 30 current accuracy 0.9108 loss from initial  0.04359999999999997
training start
training epoch 0 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 1 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 2 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 3 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 4 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 5 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 6 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 7 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 8 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 9 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 12
[activation mean]: block to remove picked: 0, with score 0.171869. All blocks and scores: [(0, 0.17186922952532768), (2, 0.1771756038069725), (19, 0.19182340055704117), (3, 0.19542529061436653), (20, 0.19926173985004425), (29, 0.20807874202728271), (7, 0.21121667325496674), (13, 0.21220956556499004), (14, 0.2136751487851143), (11, 0.21410904452204704), (1, 0.215551495552063), (6, 0.21676006726920605), (21, 0.21714812144637108), (23, 0.22181092575192451), (24, 0.23051631823182106), (52, 0.23129837028682232), (10, 0.23380653001368046), (15, 0.23425992392003536), (37, 0.2413722649216652), (12, 0.24625398963689804), (51, 0.24751090817153454), (5, 0.2475410234183073), (50, 0.24924609437584877), (49, 0.2517462484538555), (4, 0.25536689534783363), (16, 0.25618116557598114), (9, 0.2569131553173065), (48, 0.2578493282198906), (43, 0.26029039919376373), (38, 0.2605401687324047), (40, 0.2618883140385151), (8, 0.26200613379478455), (17, 0.26874708756804466), (45, 0.2700708247721195), (41, 0.2700730338692665), (39, 0.2753974236547947), (44, 0.2764104828238487), (46, 0.2764221169054508), (42, 0.2827697917819023), (47, 0.2861049398779869), (18, 0.3725159280002117), (36, 0.4110587351024151)]
computing accuracy for after removing block 0 . block score: 0.17186922952532768
removed block 0 current accuracy 0.9456 loss from initial  0.00880000000000003
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 2, with score 0.179284. All blocks and scores: [(2, 0.17928429320454597), (19, 0.1890154741704464), (3, 0.1955653540790081), (20, 0.1973157748579979), (29, 0.20627178438007832), (7, 0.20756244100630283), (13, 0.20837278850376606), (11, 0.20892416685819626), (14, 0.20982485823333263), (6, 0.21260036900639534), (23, 0.21739992313086987), (21, 0.2191100437194109), (1, 0.22362511418759823), (15, 0.22552683763206005), (24, 0.22596986033022404), (10, 0.2307091113179922), (52, 0.23075314238667488), (37, 0.2369849979877472), (12, 0.2381771970540285), (5, 0.24118980951607227), (51, 0.24539757706224918), (16, 0.2456963863223791), (50, 0.24680828489363194), (4, 0.24957522563636303), (49, 0.2508169151842594), (9, 0.252330020070076), (8, 0.2524063475430012), (38, 0.25716905668377876), (48, 0.257622130215168), (17, 0.2576398737728596), (43, 0.25782666727900505), (40, 0.2585551366209984), (45, 0.2665637545287609), (41, 0.2668971009552479), (39, 0.2707008346915245), (44, 0.27392636239528656), (46, 0.27542924508452415), (42, 0.2791377045214176), (47, 0.2812953069806099), (18, 0.3643532767891884), (36, 0.40076448768377304)]
computing accuracy for after removing block 2 . block score: 0.17928429320454597
removed block 2 current accuracy 0.9374 loss from initial  0.017000000000000015
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 19, with score 0.187764. All blocks and scores: [(19, 0.18776440806686878), (20, 0.19674360379576683), (13, 0.20331834442913532), (3, 0.2036080826073885), (29, 0.20513039082288742), (11, 0.2053084298968315), (14, 0.20744135230779648), (7, 0.20973864011466503), (6, 0.21298502013087273), (23, 0.21439429000020027), (15, 0.21957417204976082), (24, 0.22107025980949402), (21, 0.2226676642894745), (1, 0.22362511418759823), (10, 0.2248378824442625), (52, 0.22904938831925392), (12, 0.2307273130863905), (37, 0.23428412713110447), (5, 0.24101469479501247), (16, 0.24129114858806133), (51, 0.2421858999878168), (50, 0.24345201067626476), (8, 0.24358787015080452), (49, 0.24907870963215828), (9, 0.2498655505478382), (4, 0.2501165885478258), (17, 0.2510158810764551), (43, 0.2545172683894634), (40, 0.25534744188189507), (38, 0.2555055022239685), (48, 0.25614868476986885), (45, 0.26304518803954124), (41, 0.2632511034607887), (39, 0.26768071204423904), (44, 0.2725670374929905), (46, 0.27313896268606186), (42, 0.2755439765751362), (47, 0.2757898271083832), (18, 0.35903817415237427), (36, 0.3949797973036766)]
computing accuracy for after removing block 19 . block score: 0.18776440806686878
removed block 19 current accuracy 0.9316 loss from initial  0.022800000000000042
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 20, with score 0.193333. All blocks and scores: [(20, 0.193333450704813), (29, 0.19709222577512264), (13, 0.20331834442913532), (3, 0.2036080826073885), (23, 0.20401376113295555), (11, 0.2053084298968315), (14, 0.20744135230779648), (7, 0.20973864011466503), (6, 0.21298502013087273), (24, 0.2130303606390953), (37, 0.21935706958174706), (15, 0.21957417204976082), (21, 0.21973438560962677), (52, 0.22213542088866234), (1, 0.22362511418759823), (10, 0.2248378824442625), (12, 0.2307273130863905), (38, 0.23780476301908493), (51, 0.23831962049007416), (50, 0.2390758190304041), (5, 0.24101469479501247), (16, 0.24129114858806133), (40, 0.24133136309683323), (8, 0.24358787015080452), (43, 0.24483765475451946), (49, 0.245022464543581), (9, 0.2498655505478382), (4, 0.2501165885478258), (41, 0.2504948787391186), (48, 0.2506746780127287), (17, 0.2510158810764551), (39, 0.25354916602373123), (45, 0.2555340453982353), (42, 0.2593546397984028), (44, 0.264639925211668), (46, 0.26659130677580833), (47, 0.269228782504797), (18, 0.35903817415237427), (36, 0.37624477595090866)]
computing accuracy for after removing block 20 . block score: 0.193333450704813
removed block 20 current accuracy 0.9232 loss from initial  0.031200000000000006
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 29, with score 0.190513. All blocks and scores: [(29, 0.19051287323236465), (23, 0.19440838135778904), (13, 0.20331834442913532), (3, 0.2036080826073885), (37, 0.20384417474269867), (11, 0.2053084298968315), (24, 0.20614675991237164), (14, 0.20744135230779648), (7, 0.20973864011466503), (6, 0.21298502013087273), (52, 0.21308461390435696), (21, 0.2191696260124445), (15, 0.21957417204976082), (38, 0.2210109755396843), (1, 0.22362511418759823), (10, 0.2248378824442625), (40, 0.22548362612724304), (12, 0.2307273130863905), (51, 0.2317823637276888), (50, 0.23242900148034096), (43, 0.23356242664158344), (41, 0.23772329278290272), (39, 0.23939533904194832), (49, 0.23995284363627434), (5, 0.24101469479501247), (16, 0.24129114858806133), (8, 0.24358787015080452), (42, 0.24431481398642063), (48, 0.2445085570216179), (45, 0.24813474155962467), (9, 0.2498655505478382), (4, 0.2501165885478258), (17, 0.2510158810764551), (44, 0.2572431452572346), (46, 0.25995051115751266), (47, 0.2609233930706978), (36, 0.3587324470281601), (18, 0.35903817415237427)]
computing accuracy for after removing block 29 . block score: 0.19051287323236465
removed block 29 current accuracy 0.9102 loss from initial  0.04420000000000002
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 37, with score 0.189315. All blocks and scores: [(37, 0.189315065741539), (23, 0.19440838135778904), (13, 0.20331834442913532), (3, 0.2036080826073885), (38, 0.20511451549828053), (11, 0.2053084298968315), (52, 0.20577003248035908), (24, 0.20614675991237164), (14, 0.20744135230779648), (7, 0.20973864011466503), (40, 0.212410693988204), (6, 0.21298502013087273), (21, 0.2191696260124445), (15, 0.21957417204976082), (1, 0.22362511418759823), (10, 0.2248378824442625), (51, 0.224879814311862), (43, 0.22511873580515385), (39, 0.2257549650967121), (50, 0.22693579457700253), (41, 0.22873401269316673), (12, 0.2307273130863905), (42, 0.23375532776117325), (49, 0.23542077466845512), (48, 0.23873012885451317), (5, 0.24101469479501247), (16, 0.24129114858806133), (8, 0.24358787015080452), (45, 0.24372281320393085), (9, 0.2498655505478382), (4, 0.2501165885478258), (44, 0.25029237754642963), (17, 0.2510158810764551), (47, 0.25455503538250923), (46, 0.2573881670832634), (36, 0.3473326042294502), (18, 0.35903817415237427)]
computing accuracy for after removing block 37 . block score: 0.189315065741539
removed block 37 current accuracy 0.9054 loss from initial  0.049000000000000044
training start
training epoch 0 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 1 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 2 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 3 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 4 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 5 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 6 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 7 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 8 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 9 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 18
[activation mean]: block to remove picked: 7, with score 0.209019. All blocks and scores: [(7, 0.209018899127841), (13, 0.2254081889986992), (6, 0.22558463737368584), (10, 0.22574285231530666), (3, 0.2261703573167324), (14, 0.22688749805092812), (11, 0.22927283868193626), (52, 0.24210777319967747), (15, 0.24237307719886303), (12, 0.25029055401682854), (49, 0.2559470534324646), (23, 0.26153213903307915), (24, 0.26325269788503647), (50, 0.2643038257956505), (5, 0.2695652022957802), (4, 0.26992684230208397), (21, 0.2721036784350872), (51, 0.2726552188396454), (48, 0.27314067259430885), (16, 0.2738479971885681), (1, 0.27460235357284546), (17, 0.2752709649503231), (8, 0.2755456008017063), (9, 0.2791751027107239), (43, 0.2808191180229187), (40, 0.28154753521084785), (46, 0.2851993031799793), (45, 0.28866855427622795), (38, 0.2925456389784813), (44, 0.29381654784083366), (41, 0.2987124025821686), (47, 0.298805296421051), (42, 0.29966096207499504), (39, 0.31032923236489296), (18, 0.44216887280344963), (36, 0.48398997262120247)]
computing accuracy for after removing block 7 . block score: 0.209018899127841
removed block 7 current accuracy 0.9406 loss from initial  0.013800000000000034
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 14, with score 0.217770. All blocks and scores: [(14, 0.21777046285569668), (13, 0.21789331920444965), (11, 0.2245030216872692), (10, 0.22473273985087872), (6, 0.22558463737368584), (3, 0.2261703573167324), (15, 0.23039735853672028), (52, 0.2405879832804203), (12, 0.24249108508229256), (49, 0.2543143630027771), (23, 0.256703469902277), (24, 0.25862813740968704), (17, 0.2611570470035076), (50, 0.26153556257486343), (16, 0.2622944042086601), (5, 0.2695652022957802), (51, 0.269790668040514), (4, 0.26992684230208397), (48, 0.27016811072826385), (21, 0.27046503499150276), (1, 0.27460235357284546), (9, 0.2757459841668606), (43, 0.27688707411289215), (8, 0.279182780534029), (40, 0.28013036400079727), (46, 0.2826064005494118), (45, 0.2861425541341305), (44, 0.29001934826374054), (38, 0.29037966951727867), (47, 0.2928724028170109), (42, 0.29627976939082146), (41, 0.29684602096676826), (39, 0.30622098967432976), (18, 0.4356704019010067), (36, 0.47533608227968216)]
computing accuracy for after removing block 14 . block score: 0.21777046285569668
removed block 14 current accuracy 0.9322 loss from initial  0.022199999999999998
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 13, with score 0.217893. All blocks and scores: [(13, 0.21789331920444965), (11, 0.2245030216872692), (10, 0.22473273985087872), (6, 0.22558463737368584), (3, 0.2261703573167324), (52, 0.2378016598522663), (15, 0.23902058601379395), (12, 0.24249108508229256), (49, 0.2519255708903074), (23, 0.25261715054512024), (24, 0.25581661239266396), (50, 0.258435633033514), (17, 0.26168928667902946), (21, 0.2659887261688709), (48, 0.26678741350769997), (51, 0.26711516454815865), (16, 0.26878146827220917), (5, 0.2695652022957802), (4, 0.26992684230208397), (43, 0.2733663469552994), (1, 0.27460235357284546), (9, 0.2757459841668606), (46, 0.2783702053129673), (8, 0.279182780534029), (40, 0.280278705060482), (45, 0.2835884056985378), (44, 0.2872467711567879), (47, 0.28772056475281715), (38, 0.2903161607682705), (42, 0.29490356519818306), (41, 0.29640424624085426), (39, 0.30577879771590233), (18, 0.4311159811913967), (36, 0.4734579063951969)]
computing accuracy for after removing block 13 . block score: 0.21789331920444965
removed block 13 current accuracy 0.916 loss from initial  0.03839999999999999
since last training loss: 0.03079999999999994 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 11, with score 0.224503. All blocks and scores: [(11, 0.2245030216872692), (10, 0.22473273985087872), (6, 0.22558463737368584), (3, 0.2261703573167324), (52, 0.2331237643957138), (15, 0.23961962200701237), (12, 0.24249108508229256), (23, 0.24588648416101933), (49, 0.24768824502825737), (17, 0.2510185446590185), (24, 0.2517532706260681), (50, 0.25296173617243767), (21, 0.2609761990606785), (48, 0.2612176574766636), (51, 0.262289859354496), (16, 0.2676275260746479), (43, 0.2681601718068123), (5, 0.2695652022957802), (4, 0.26992684230208397), (46, 0.27257178723812103), (1, 0.27460235357284546), (9, 0.2757459841668606), (40, 0.2768929861485958), (45, 0.2791623882949352), (8, 0.279182780534029), (44, 0.2809833958745003), (47, 0.28121867403388023), (38, 0.28739167377352715), (42, 0.2900646738708019), (41, 0.29297005757689476), (39, 0.30188023298978806), (18, 0.42784395068883896), (36, 0.4682552106678486)]
computing accuracy for after removing block 11 . block score: 0.2245030216872692
removed block 11 current accuracy 0.874 loss from initial  0.08040000000000003
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 10, with score 0.224733. All blocks and scores: [(10, 0.22473273985087872), (52, 0.22504759952425957), (6, 0.22558463737368584), (3, 0.2261703573167324), (15, 0.23372425884008408), (23, 0.23572144471108913), (17, 0.23713467456400394), (49, 0.24109655991196632), (12, 0.24134911969304085), (50, 0.2429038193076849), (24, 0.24541481584310532), (48, 0.2529652267694473), (51, 0.253739919513464), (21, 0.25494684278964996), (43, 0.2600725479424), (16, 0.2601778283715248), (46, 0.2647990770637989), (40, 0.2685309909284115), (47, 0.26904598623514175), (5, 0.2695652022957802), (44, 0.2695995196700096), (45, 0.2697646729648113), (4, 0.26992684230208397), (1, 0.27460235357284546), (9, 0.2757459841668606), (38, 0.2791382297873497), (8, 0.279182780534029), (42, 0.2805246189236641), (41, 0.28485478460788727), (39, 0.2910783588886261), (18, 0.4244326911866665), (36, 0.45848969742655754)]
computing accuracy for after removing block 10 . block score: 0.22473273985087872
removed block 10 current accuracy 0.7954 loss from initial  0.15900000000000003
since last training loss: 0.15139999999999998 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 52, with score 0.214873. All blocks and scores: [(52, 0.21487250737845898), (17, 0.22302939742803574), (23, 0.2237750943750143), (6, 0.22558463737368584), (3, 0.2261703573167324), (15, 0.23086445592343807), (50, 0.23149501718580723), (49, 0.234441090375185), (24, 0.23679593205451965), (12, 0.24009791016578674), (48, 0.24293000809848309), (51, 0.2436857670545578), (21, 0.24762248434126377), (43, 0.24921060353517532), (46, 0.2551417909562588), (44, 0.2562410607933998), (47, 0.2566253989934921), (40, 0.2570132575929165), (45, 0.25778941065073013), (16, 0.25833388417959213), (38, 0.2662673257291317), (42, 0.2679411433637142), (5, 0.2695652022957802), (4, 0.26992684230208397), (41, 0.2721619941294193), (1, 0.27460235357284546), (39, 0.2757220230996609), (9, 0.2757459841668606), (8, 0.279182780534029), (18, 0.42074086889624596), (36, 0.44696370139718056)]
computing accuracy for after removing block 52 . block score: 0.21487250737845898
removed block 52 current accuracy 0.789 loss from initial  0.1654
since last training loss: 0.15779999999999994 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 17, with score 0.223029. All blocks and scores: [(17, 0.22302939742803574), (23, 0.2237750943750143), (6, 0.22558463737368584), (3, 0.2261703573167324), (15, 0.23086445592343807), (50, 0.23149501718580723), (49, 0.234441090375185), (24, 0.23679593205451965), (12, 0.24009791016578674), (48, 0.24293000809848309), (51, 0.2436857670545578), (21, 0.24762248434126377), (43, 0.24921060353517532), (46, 0.2551417909562588), (44, 0.2562410607933998), (47, 0.2566253989934921), (40, 0.2570132575929165), (45, 0.25778941065073013), (16, 0.25833388417959213), (38, 0.2662673257291317), (42, 0.2679411433637142), (5, 0.2695652022957802), (4, 0.26992684230208397), (41, 0.2721619941294193), (1, 0.27460235357284546), (39, 0.2757220230996609), (9, 0.2757459841668606), (8, 0.279182780534029), (18, 0.42074086889624596), (36, 0.44696370139718056)]
computing accuracy for after removing block 17 . block score: 0.22302939742803574
removed block 17 current accuracy 0.7216 loss from initial  0.2328
since last training loss: 0.22519999999999996 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 23, with score 0.219520. All blocks and scores: [(23, 0.21951955184340477), (50, 0.2254047840833664), (6, 0.22558463737368584), (3, 0.2261703573167324), (49, 0.22921093180775642), (24, 0.22996393218636513), (15, 0.23086445592343807), (48, 0.2345203198492527), (51, 0.2380317486822605), (21, 0.23813758231699467), (12, 0.24009791016578674), (43, 0.24363332614302635), (46, 0.24581653997302055), (44, 0.2505642119795084), (45, 0.2514479160308838), (47, 0.2520250529050827), (40, 0.25220099836587906), (16, 0.25833388417959213), (38, 0.26218246668577194), (42, 0.26264456659555435), (41, 0.26520146802067757), (5, 0.2695652022957802), (4, 0.26992684230208397), (39, 0.27223407477140427), (1, 0.27460235357284546), (9, 0.2757459841668606), (8, 0.279182780534029), (18, 0.4100237898528576), (36, 0.4480368234217167)]
computing accuracy for after removing block 23 . block score: 0.21951955184340477
removed block 23 current accuracy 0.6588 loss from initial  0.2956
since last training loss: 0.2879999999999999 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 50, with score 0.220546. All blocks and scores: [(50, 0.22054585814476013), (6, 0.22558463737368584), (3, 0.2261703573167324), (15, 0.23086445592343807), (49, 0.23175766877830029), (48, 0.23323452658951283), (24, 0.234269754961133), (40, 0.23428464494645596), (51, 0.23521007411181927), (43, 0.23621626012027264), (21, 0.23813758231699467), (12, 0.24009791016578674), (38, 0.24607175961136818), (44, 0.24725741147994995), (46, 0.24748300202190876), (45, 0.24900215864181519), (41, 0.24908395111560822), (42, 0.2511784639209509), (47, 0.2516389824450016), (39, 0.25622086599469185), (16, 0.25833388417959213), (5, 0.2695652022957802), (4, 0.26992684230208397), (1, 0.27460235357284546), (9, 0.2757459841668606), (8, 0.279182780534029), (18, 0.4100237898528576), (36, 0.43803146854043007)]
computing accuracy for after removing block 50 . block score: 0.22054585814476013
removed block 50 current accuracy 0.6498 loss from initial  0.3046
training start
training epoch 0 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.1]
training epoch 1 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 2 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 3 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 4 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 5 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 6 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 7 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 8 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 9 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
