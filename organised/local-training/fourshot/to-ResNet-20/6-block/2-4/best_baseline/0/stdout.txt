start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589383974671), (30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.013294660835526884), (29, 0.013421116629615426), (35, 0.015957689844071865), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019996491726487875), (46, 0.02059022570028901), (25, 0.022078294306993484), (23, 0.022228715708479285), (41, 0.022336416179314256), (44, 0.02314599882811308), (40, 0.02374959085136652), (45, 0.023975494550541043), (21, 0.024941089330241084), (48, 0.024957706686109304), (22, 0.025151390815153718), (50, 0.025287174386903644), (24, 0.02588058286346495), (49, 0.02591664856299758), (42, 0.02623223210684955), (20, 0.026848891517147422), (47, 0.028632949106395245), (38, 0.03134434437379241), (39, 0.031441295985132456), (15, 0.03205838426947594), (7, 0.03244550200179219), (19, 0.03254077769815922), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216024339199), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4361986331641674), (18, 0.5117433071136475), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013119243085384369), (29, 0.01342111686244607), (26, 0.016072140773758292), (35, 0.016093927202746272), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985268690623343), (46, 0.020300705451518297), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022977192420512438), (40, 0.023573831422254443), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.024941089330241084), (22, 0.0251513896510005), (49, 0.02557574026286602), (24, 0.025880583096295595), (42, 0.025893412763252854), (20, 0.026848891284316778), (47, 0.028072760673239827), (38, 0.03109118831343949), (39, 0.031191361136734486), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03797321254387498), (51, 0.04127101460471749), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.4339806139469147), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.012758882017806172), (29, 0.013421116396784782), (35, 0.015918421559035778), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01985046546906233), (46, 0.020411915611475706), (41, 0.02182762953452766), (25, 0.02207829407416284), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.02360257995314896), (45, 0.023770848754793406), (48, 0.02451987285166979), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.028052504174411297), (38, 0.0309358739759773), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464740499854), (52, 0.06441722763702273), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159845128655), (29, 0.013421116396784782), (35, 0.01591864973306656), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.023001376539468765), (40, 0.023739926517009735), (45, 0.023790168343111873), (48, 0.02435004455037415), (50, 0.02446310454979539), (21, 0.02494108979590237), (22, 0.025151390116661787), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027727573877200484), (38, 0.030746275326237082), (39, 0.031281794188544154), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479700446129), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756063178182), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693012356758), (18, 0.5117432847619057), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116513200104), (35, 0.01596891158260405), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055153653026), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022687324788421392), (40, 0.023569098440930247), (45, 0.023840721463784575), (48, 0.024108358891680837), (50, 0.024114209692925215), (49, 0.024870117427781224), (21, 0.02494108909741044), (42, 0.02504557534120977), (22, 0.025151390815153718), (24, 0.025880583794787526), (20, 0.026848891517147422), (47, 0.027423851657658815), (38, 0.030735649866983294), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003176480532), (17, 0.06132525345310569), (52, 0.06270107859745622), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692687153816223), (18, 0.5117432847619057), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302683813497424), (46, 0.02032419783063233), (41, 0.02196270367130637), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.023045077454298735), (48, 0.024024547543376684), (50, 0.024096973007544875), (40, 0.024156816070899367), (45, 0.024168408941477537), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.02588058332912624), (20, 0.026848891517147422), (47, 0.02756829489953816), (38, 0.03178726392798126), (15, 0.03205838426947594), (39, 0.032257913146167994), (7, 0.03244550200179219), (19, 0.03254077769815922), (51, 0.04008621396496892), (37, 0.040690730791538954), (9, 0.04337632888928056), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.061325253918766975), (52, 0.06221095006912947), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.44933701306581497), (18, 0.5117432922124863), (53, 0.827703095972538)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370510682463646), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019856704166159034), (46, 0.01998897618614137), (41, 0.021256204694509506), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02269203308969736), (48, 0.023521372815594077), (50, 0.02353389048948884), (40, 0.02361623989418149), (45, 0.023933293065056205), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.024941090028733015), (22, 0.02515139034949243), (24, 0.02588058216497302), (47, 0.02681345585733652), (20, 0.026848892215639353), (38, 0.03108373167924583), (39, 0.03205688809975982), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03907974902540445), (37, 0.04015214368700981), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003409311175), (52, 0.06036907434463501), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4432784393429756), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143200814724), (28, 0.016986021772027016), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700076198205352), (41, 0.020515799056738615), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022507572080940008), (48, 0.02289936924353242), (50, 0.022937727393582463), (40, 0.02305740211158991), (42, 0.023520407732576132), (45, 0.023633699398487806), (49, 0.024081918876618147), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582397803664), (47, 0.026322791818529367), (20, 0.026848892448469996), (38, 0.030149149242788553), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.03926890343427658), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992687404156), (52, 0.05846811970695853), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143200814724
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602130636573), (43, 0.018381991190835834), (27, 0.018769708462059498), (46, 0.01884230226278305), (41, 0.019016370875760913), (48, 0.021309157367795706), (50, 0.021624521119520068), (44, 0.02174885431304574), (40, 0.021916966885328293), (42, 0.0219303744379431), (25, 0.022078294772654772), (23, 0.022228715242817998), (45, 0.022736448794603348), (49, 0.022970063611865044), (21, 0.02494108979590237), (22, 0.025151389883831143), (47, 0.025355831487104297), (24, 0.02588058216497302), (20, 0.026848891517147422), (38, 0.028691887157037854), (39, 0.029624431626871228), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03601635713130236), (37, 0.03643036773428321), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241463959217), (2, 0.05457740556448698), (52, 0.05466857925057411), (3, 0.05784992594271898), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.41641608998179436), (18, 0.5117432922124863), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.01698602130636573
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.01835862430743873), (41, 0.018467807210981846), (27, 0.018769708927720785), (48, 0.020775508834049106), (42, 0.021206470439210534), (50, 0.0213024471886456), (44, 0.02158689615316689), (40, 0.02159272227436304), (25, 0.02207829523831606), (23, 0.022228715708479285), (45, 0.022315293783321977), (49, 0.02240756736136973), (47, 0.024609397165477276), (21, 0.02494108979590237), (22, 0.0251513896510005), (24, 0.025880582397803664), (20, 0.02684889198280871), (38, 0.02789032435975969), (39, 0.02919189492240548), (15, 0.03205838380381465), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03550667688250542), (37, 0.035919226706027985), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.04852241463959217), (52, 0.05337408138439059), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537236094475), (5, 0.10671143606305122), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.9067213013768196)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.01846780674532056), (27, 0.01876970869489014), (46, 0.01899468107149005), (42, 0.021206469740718603), (48, 0.021418895572423935), (50, 0.021441322285681963), (40, 0.021592722507193685), (25, 0.022078295005485415), (23, 0.02222871477715671), (49, 0.022339018061757088), (44, 0.02278283331543207), (45, 0.023323107045143843), (21, 0.024941089563071728), (22, 0.025151390815153718), (47, 0.025386077351868153), (24, 0.025880583096295595), (20, 0.026848892448469996), (38, 0.02789032505825162), (39, 0.029191894456744194), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03521771775558591), (37, 0.03591922810301185), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (52, 0.052133372984826565), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.061325252056121826), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4126182049512863), (18, 0.5117432847619057), (53, 0.9521221220493317)]
computing accuracy for after removing block 41 . block score: 0.01846780674532056
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 1 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 2 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 3 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 4 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 5 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.1]
training epoch 6 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.1]
training epoch 7 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.1]
training epoch 8 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.1]
training epoch 9 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.015413. All blocks and scores: [(46, 0.015412728185765445), (45, 0.016229181084781885), (44, 0.017153501277789474), (47, 0.017215114319697022), (23, 0.022531138267368078), (42, 0.023652573814615607), (40, 0.024328264640644193), (21, 0.02500910428352654), (22, 0.025320796761661768), (20, 0.02713494165800512), (50, 0.027401096420362592), (49, 0.028363020392134786), (48, 0.029273789143189788), (38, 0.030228309566155076), (27, 0.031116575933992863), (39, 0.03191492613404989), (15, 0.032164900097995996), (7, 0.03258828446269035), (25, 0.03262460418045521), (19, 0.03266407223418355), (24, 0.03402195777744055), (37, 0.04004705371335149), (51, 0.042863547801971436), (9, 0.04401751747354865), (6, 0.046412486117333174), (4, 0.046779912896454334), (14, 0.04804541729390621), (2, 0.054861605167388916), (3, 0.05734417634084821), (11, 0.059851102996617556), (13, 0.06004350678995252), (17, 0.06274762563407421), (0, 0.06355261104181409), (1, 0.06677198968827724), (52, 0.06705832108855247), (8, 0.07457569520920515), (10, 0.08163941372185946), (16, 0.08524955809116364), (12, 0.0906808665022254), (5, 0.10564813576638699), (18, 0.5137577503919601), (36, 0.5192224532365799), (53, 0.8029211983084679)]
computing accuracy for after removing block 46 . block score: 0.015412728185765445
removed block 46 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 45, with score 0.016229. All blocks and scores: [(45, 0.01622918131761253), (44, 0.01715350174345076), (47, 0.018636095803231), (23, 0.022531138034537435), (42, 0.02365257521159947), (40, 0.02432826580479741), (21, 0.025009104516357183), (22, 0.02532079699449241), (20, 0.027134943287819624), (50, 0.02812287351116538), (49, 0.029314826708287), (48, 0.02942240098491311), (38, 0.030228310031816363), (27, 0.031116576632484794), (39, 0.031914925668388605), (15, 0.032164900563657284), (7, 0.032588282600045204), (25, 0.03262460418045521), (19, 0.03266407363116741), (24, 0.03402195777744055), (37, 0.04004705557599664), (51, 0.04343371419236064), (9, 0.04401751700788736), (6, 0.046412486117333174), (4, 0.04677991382777691), (14, 0.04804541729390621), (2, 0.05486160423606634), (3, 0.05734417540952563), (11, 0.05985110532492399), (13, 0.06004350585862994), (17, 0.06274762796238065), (0, 0.06355261104181409), (1, 0.06677198875695467), (52, 0.06840676255524158), (8, 0.07457569614052773), (10, 0.08163941651582718), (16, 0.08524955995380878), (12, 0.0906808665022254), (5, 0.10564813669770956), (18, 0.5137577429413795), (36, 0.5192224383354187), (53, 0.8503579869866371)]
computing accuracy for after removing block 45 . block score: 0.01622918131761253
removed block 45 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.017154. All blocks and scores: [(44, 0.017153501510620117), (47, 0.019606993068009615), (23, 0.022531138034537435), (42, 0.023652574745938182), (40, 0.024328265571966767), (21, 0.02500910358503461), (22, 0.02532079629600048), (20, 0.027134943287819624), (50, 0.029476390685886145), (49, 0.029937298269942403), (38, 0.030228309333324432), (48, 0.03065789071843028), (27, 0.031116576166823506), (39, 0.03191492613404989), (15, 0.03216490102931857), (7, 0.03258828353136778), (25, 0.03262460511177778), (19, 0.032664073165506124), (24, 0.034021958243101835), (37, 0.04004705511033535), (51, 0.04315799055621028), (9, 0.0440175156109035), (6, 0.04641248658299446), (4, 0.04677991336211562), (14, 0.04804541729390621), (2, 0.0548616056330502), (3, 0.057344174943864346), (11, 0.05985110253095627), (13, 0.06004350632429123), (17, 0.06274762703105807), (0, 0.06355261243879795), (1, 0.06677198875695467), (52, 0.06721775326877832), (8, 0.07457569520920515), (10, 0.08163941651582718), (16, 0.08524956088513136), (12, 0.0906808665022254), (5, 0.10564813949167728), (18, 0.5137577503919601), (36, 0.5192224606871605), (53, 0.9121999070048332)]
computing accuracy for after removing block 44 . block score: 0.017153501510620117
removed block 44 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 47, with score 0.020284. All blocks and scores: [(47, 0.020283580757677555), (23, 0.022531138500198722), (42, 0.02365257521159947), (40, 0.024328264174982905), (21, 0.02500910311937332), (22, 0.025320796761661768), (20, 0.027134942589327693), (49, 0.029241815209388733), (50, 0.02988362987525761), (38, 0.03022830979898572), (48, 0.030466238502413034), (27, 0.031116575235500932), (39, 0.03191492520272732), (15, 0.032164900563657284), (7, 0.03258828213438392), (25, 0.03262460511177778), (19, 0.032664073165506124), (24, 0.03402195870876312), (37, 0.040047054179012775), (51, 0.04280989337712526), (9, 0.04401751467958093), (6, 0.04641248704865575), (4, 0.046779912896454334), (14, 0.04804541543126106), (2, 0.05486160470172763), (3, 0.057344174943864346), (11, 0.05985110439360142), (13, 0.060043507255613804), (17, 0.06274762703105807), (0, 0.06355261104181409), (52, 0.0653378376737237), (1, 0.0667719878256321), (8, 0.07457569520920515), (10, 0.08163941372185946), (16, 0.08524955715984106), (12, 0.09068086743354797), (5, 0.10564813762903214), (18, 0.5137577429413795), (36, 0.5192224606871605), (53, 0.9985681772232056)]
computing accuracy for after removing block 47 . block score: 0.020283580757677555
removed block 47 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.022531. All blocks and scores: [(23, 0.02253113780170679), (42, 0.023652574978768826), (40, 0.024328265571966767), (21, 0.02500910428352654), (22, 0.025320796761661768), (20, 0.027134942123666406), (49, 0.029359923908486962), (38, 0.03022830979898572), (48, 0.030694601126015186), (50, 0.030892620561644435), (27, 0.031116575235500932), (39, 0.03191492613404989), (15, 0.03216490102931857), (7, 0.03258828306570649), (25, 0.03262460511177778), (19, 0.03266407269984484), (24, 0.03402195870876312), (37, 0.04004705557599664), (51, 0.04312678845599294), (9, 0.04401751700788736), (6, 0.04641248704865575), (4, 0.046779912896454334), (14, 0.048045416828244925), (2, 0.0548616056330502), (3, 0.057344174943864346), (11, 0.059851104859262705), (13, 0.06004350632429123), (17, 0.06274762656539679), (0, 0.06355261104181409), (52, 0.06562938820570707), (1, 0.0667719878256321), (8, 0.07457569520920515), (10, 0.08163941465318203), (16, 0.08524955715984106), (12, 0.0906808665022254), (5, 0.10564813762903214), (18, 0.5137577652931213), (36, 0.5192224606871605), (53, 1.081425666809082)]
computing accuracy for after removing block 23 . block score: 0.02253113780170679
removed block 23 current accuracy 0.9136 loss from initial  0.037800000000000056
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.022378. All blocks and scores: [(42, 0.022377752466127276), (40, 0.023825141601264477), (21, 0.02500910311937332), (22, 0.025320796761661768), (20, 0.027134942123666406), (49, 0.02911943895742297), (38, 0.029669662471860647), (50, 0.029826632468029857), (48, 0.030081571079790592), (27, 0.030287341447547078), (25, 0.03153489576652646), (24, 0.03193912119604647), (39, 0.03196370042860508), (15, 0.03216490102931857), (7, 0.03258828306570649), (19, 0.03266407269984484), (37, 0.04096908075734973), (51, 0.04286840604618192), (9, 0.044017515145242214), (6, 0.046412487514317036), (4, 0.04677991382777691), (14, 0.04804541636258364), (2, 0.05486160283908248), (3, 0.057344174943864346), (11, 0.05985110346227884), (13, 0.06004350818693638), (17, 0.06274762703105807), (0, 0.06355261011049151), (52, 0.06396682979539037), (1, 0.06677198968827724), (8, 0.07457569520920515), (10, 0.08163941837847233), (16, 0.08524955902248621), (12, 0.09068086557090282), (5, 0.10564813390374184), (18, 0.5137577503919601), (36, 0.5158274248242378), (53, 1.089356318116188)]
computing accuracy for after removing block 42 . block score: 0.022377752466127276
removed block 42 current accuracy 0.8958 loss from initial  0.05559999999999998
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.023825. All blocks and scores: [(40, 0.023825141368433833), (21, 0.025009103352203965), (22, 0.02532079629600048), (20, 0.027134942822158337), (38, 0.029669662239030004), (49, 0.029806966427713633), (27, 0.03028734214603901), (48, 0.0314016779884696), (25, 0.03153489623218775), (50, 0.03162708110176027), (24, 0.03193912166170776), (39, 0.03196369996294379), (15, 0.03216490102931857), (7, 0.03258828306570649), (19, 0.03266407363116741), (37, 0.04096908122301102), (51, 0.0429558171890676), (9, 0.04401751607656479), (6, 0.046412485651671886), (4, 0.046779914759099483), (14, 0.048045416828244925), (2, 0.05486160470172763), (3, 0.057344174943864346), (11, 0.05985110346227884), (13, 0.060043507255613804), (17, 0.0627476298250258), (0, 0.06355261197313666), (52, 0.06578293349593878), (1, 0.06677198875695467), (8, 0.07457569520920515), (10, 0.08163941372185946), (16, 0.08524955809116364), (12, 0.09068086557090282), (5, 0.10564813669770956), (18, 0.5137577503919601), (36, 0.5158274248242378), (53, 1.1230022758245468)]
computing accuracy for after removing block 40 . block score: 0.023825141368433833
removed block 40 current accuracy 0.8816 loss from initial  0.06979999999999997
since last training loss: 0.061799999999999966 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.025009. All blocks and scores: [(21, 0.02500910358503461), (22, 0.025320796528831124), (20, 0.02713494305498898), (38, 0.029669662471860647), (49, 0.030227821553125978), (27, 0.03028734214603901), (48, 0.03152841445989907), (25, 0.03153489716351032), (50, 0.03189306636340916), (24, 0.03193912119604647), (39, 0.03196370089426637), (15, 0.03216490149497986), (7, 0.03258828306570649), (19, 0.032664071302860975), (37, 0.04096908029168844), (51, 0.043037717230618), (9, 0.04401751607656479), (6, 0.046412485651671886), (4, 0.04677991569042206), (14, 0.048045416828244925), (2, 0.05486160470172763), (3, 0.057344173546880484), (11, 0.059851102996617556), (13, 0.06004350585862994), (17, 0.0627476260997355), (0, 0.06355261011049151), (52, 0.06562715116888285), (1, 0.06677198689430952), (8, 0.0745756970718503), (10, 0.08163941465318203), (16, 0.08524955995380878), (12, 0.09068086557090282), (5, 0.10564813669770956), (18, 0.5137577503919601), (36, 0.5158274248242378), (53, 1.2250776588916779)]
computing accuracy for after removing block 21 . block score: 0.02500910358503461
removed block 21 current accuracy 0.8736 loss from initial  0.07779999999999998
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023561. All blocks and scores: [(22, 0.02356061222963035), (20, 0.027134942589327693), (38, 0.028042158810421824), (24, 0.02870291704311967), (48, 0.028905986109748483), (27, 0.029014892410486937), (49, 0.02909888862632215), (50, 0.029797558672726154), (25, 0.02994778146967292), (39, 0.03037675144150853), (15, 0.03216490102931857), (7, 0.03258828213438392), (19, 0.032664073165506124), (37, 0.038810198195278645), (51, 0.04107116162776947), (9, 0.04401751700788736), (6, 0.04641248658299446), (4, 0.046779914759099483), (14, 0.04804541543126106), (2, 0.05486160423606634), (3, 0.057344174943864346), (52, 0.05942464107647538), (11, 0.05985110253095627), (13, 0.06004350585862994), (17, 0.06274762703105807), (0, 0.06355261104181409), (1, 0.0667719878256321), (8, 0.07457569520920515), (10, 0.0816394155845046), (16, 0.08524955809116364), (12, 0.09068086463958025), (5, 0.10564813856035471), (36, 0.48683448508381844), (18, 0.513757735490799), (53, 1.2768161594867706)]
computing accuracy for after removing block 22 . block score: 0.02356061222963035
removed block 22 current accuracy 0.8518 loss from initial  0.09960000000000002
since last training loss: 0.09160000000000001 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.026194. All blocks and scores: [(24, 0.026194281643256545), (20, 0.027134942822158337), (48, 0.027378012659028172), (38, 0.027774707414209843), (27, 0.02779325726442039), (49, 0.02794693340547383), (50, 0.027960718842223287), (25, 0.02830125018954277), (39, 0.029407734982669353), (15, 0.03216490102931857), (7, 0.03258828353136778), (19, 0.032664073165506124), (37, 0.0394149674102664), (51, 0.040208916645497084), (9, 0.0440175156109035), (6, 0.046412486117333174), (4, 0.046779912896454334), (14, 0.048045416828244925), (2, 0.05486160656437278), (52, 0.05508485250174999), (3, 0.057344173546880484), (11, 0.059851102996617556), (13, 0.06004350399598479), (17, 0.06274762563407421), (0, 0.06355261011049151), (1, 0.0667719878256321), (8, 0.07457569614052773), (10, 0.0816394155845046), (16, 0.08524955809116364), (12, 0.09068086836487055), (5, 0.10564813762903214), (36, 0.47946566343307495), (18, 0.5137577503919601), (53, 1.290055975317955)]
computing accuracy for after removing block 24 . block score: 0.026194281643256545
removed block 24 current accuracy 0.82 loss from initial  0.13140000000000007
since last training loss: 0.12340000000000007 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.026605. All blocks and scores: [(50, 0.026604698970913887), (38, 0.026931373169645667), (20, 0.027134943520650268), (25, 0.02717735874466598), (48, 0.02721165819093585), (49, 0.027653635013848543), (27, 0.028015021001920104), (39, 0.029729454778134823), (15, 0.03216490149497986), (7, 0.03258828446269035), (19, 0.03266407223418355), (51, 0.03995272982865572), (37, 0.04075850825756788), (9, 0.0440175156109035), (6, 0.046412486117333174), (4, 0.046779914293438196), (14, 0.04804541636258364), (52, 0.051483419723808765), (2, 0.05486160470172763), (3, 0.05734417447820306), (11, 0.05985110253095627), (13, 0.06004350818693638), (17, 0.06274762703105807), (0, 0.06355261290445924), (1, 0.06677198875695467), (8, 0.07457569520920515), (10, 0.0816394155845046), (16, 0.08524955809116364), (12, 0.0906808665022254), (5, 0.10564814042299986), (36, 0.47873999923467636), (18, 0.5137577578425407), (53, 1.3291893005371094)]
computing accuracy for after removing block 50 . block score: 0.026604698970913887
removed block 50 current accuracy 0.8024 loss from initial  0.14900000000000002
training start
training epoch 0 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 1 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 2 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 3 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 4 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 5 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.1]
training epoch 6 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 7 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 8 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.1]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032233. All blocks and scores: [(15, 0.03223254391923547), (7, 0.03262699069455266), (9, 0.04390625562518835), (4, 0.0463035898283124), (6, 0.04645444871857762), (14, 0.04794731177389622), (19, 0.05061914911493659), (20, 0.05176647938787937), (49, 0.05316112330183387), (48, 0.054513612762093544), (2, 0.054731224197894335), (3, 0.057590974029153585), (51, 0.05919470265507698), (13, 0.0595337999984622), (11, 0.0597382728010416), (27, 0.062199891079217196), (17, 0.06287906691431999), (0, 0.06376117654144764), (25, 0.0659201592206955), (38, 0.06670376658439636), (1, 0.06691631767898798), (37, 0.07452949229627848), (8, 0.07470083143562078), (52, 0.07590037491172552), (39, 0.07598075456917286), (10, 0.08151932526379824), (16, 0.0859644990414381), (12, 0.09040416963398457), (5, 0.10741860419511795), (18, 0.5132035315036774), (36, 0.6149540916085243), (53, 1.3261878490447998)]
computing accuracy for after removing block 15 . block score: 0.03223254391923547
removed block 15 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032627. All blocks and scores: [(7, 0.03262699069455266), (9, 0.04390625609084964), (4, 0.04630358936265111), (6, 0.04645444918423891), (14, 0.04794731084257364), (20, 0.04820169880986214), (19, 0.05138086434453726), (49, 0.053157124668359756), (2, 0.05473122466355562), (48, 0.0562696079723537), (3, 0.05759097309783101), (13, 0.05953379860147834), (51, 0.05953657766804099), (11, 0.05973827000707388), (27, 0.06009325571358204), (25, 0.06266321381554008), (0, 0.06376117374747992), (38, 0.0666392957791686), (17, 0.06679529696702957), (1, 0.06691631488502026), (37, 0.07436580955982208), (8, 0.07470082864165306), (52, 0.07577792089432478), (39, 0.07643187697976828), (10, 0.08151932340115309), (12, 0.09040416777133942), (16, 0.0959984315559268), (5, 0.1074185986071825), (18, 0.5003703311085701), (36, 0.607661060988903), (53, 1.3387971073389053)]
computing accuracy for after removing block 7 . block score: 0.03262699069455266
removed block 7 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 9, with score 0.043828. All blocks and scores: [(9, 0.04382780473679304), (14, 0.04430852457880974), (20, 0.04595465958118439), (4, 0.04630358889698982), (6, 0.04645444918423891), (19, 0.05008538905531168), (13, 0.05153346713632345), (48, 0.052484717685729265), (49, 0.05302783567458391), (2, 0.0547312255948782), (11, 0.05643503973260522), (17, 0.05651749996468425), (27, 0.05738034751266241), (3, 0.05759097449481487), (51, 0.058550143614411354), (25, 0.05992303229868412), (0, 0.06376117561012506), (38, 0.06671313941478729), (1, 0.06691631767898798), (37, 0.06976157985627651), (8, 0.0726753156632185), (52, 0.07333453558385372), (39, 0.07554138544946909), (10, 0.08396292477846146), (12, 0.08455342333763838), (16, 0.08737438730895519), (5, 0.10741859674453735), (18, 0.4834275543689728), (36, 0.5890090987086296), (53, 1.3440056592226028)]
computing accuracy for after removing block 9 . block score: 0.04382780473679304
removed block 9 current accuracy 0.9214 loss from initial  0.030000000000000027
since last training loss: 0.021599999999999953 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 14, with score 0.040216. All blocks and scores: [(14, 0.04021550668403506), (4, 0.04630359075963497), (20, 0.04638366587460041), (6, 0.04645444778725505), (13, 0.04896391183137894), (48, 0.049664271995425224), (17, 0.05038494523614645), (49, 0.05119891418144107), (11, 0.05211011506617069), (19, 0.05357146309688687), (27, 0.05449364660307765), (2, 0.05473122466355562), (51, 0.05578348599374294), (25, 0.056520409882068634), (3, 0.0575909735634923), (37, 0.06350783910602331), (0, 0.06376117747277021), (38, 0.06492900848388672), (1, 0.06691631581634283), (52, 0.0685251085087657), (16, 0.07189712394028902), (8, 0.07267531845718622), (12, 0.07291983533650637), (39, 0.07399851828813553), (10, 0.08243949618190527), (5, 0.1074185986071825), (18, 0.4644453562796116), (36, 0.5543959811329842), (53, 1.3369238376617432)]
computing accuracy for after removing block 14 . block score: 0.04021550668403506
removed block 14 current accuracy 0.9094 loss from initial  0.04200000000000004
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.042119. All blocks and scores: [(20, 0.04211932420730591), (4, 0.046303591690957546), (6, 0.04645444918423891), (13, 0.0489639132283628), (48, 0.04914632299914956), (17, 0.04989672964438796), (49, 0.05038175918161869), (11, 0.05211011599749327), (27, 0.05269212555140257), (19, 0.05409543402493), (51, 0.05452649621292949), (25, 0.0546940010972321), (2, 0.054731224197894335), (3, 0.05759097496047616), (37, 0.06335909850895405), (38, 0.0636814683675766), (0, 0.06376117840409279), (52, 0.06438635615631938), (1, 0.0669163167476654), (8, 0.07267531845718622), (12, 0.07291983347386122), (39, 0.07341182883828878), (10, 0.08243949618190527), (16, 0.09481293521821499), (5, 0.10741859953850508), (18, 0.4618607796728611), (36, 0.5474346056580544), (53, 1.3599498718976974)]
computing accuracy for after removing block 20 . block score: 0.04211932420730591
removed block 20 current accuracy 0.8938 loss from initial  0.057599999999999985
since last training loss: 0.04919999999999991 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 48, with score 0.046045. All blocks and scores: [(48, 0.046045055612921715), (4, 0.04630359308794141), (6, 0.04645444871857762), (27, 0.04788817232474685), (13, 0.048963913694024086), (49, 0.04973670141771436), (17, 0.0498967282474041), (51, 0.05134947597980499), (11, 0.05211011506617069), (25, 0.052639457397162914), (19, 0.05409543542191386), (2, 0.054731224197894335), (3, 0.0575909735634923), (52, 0.05867421813309193), (38, 0.06225550267845392), (37, 0.06366121955215931), (0, 0.06376117654144764), (1, 0.06691631581634283), (39, 0.07210418209433556), (8, 0.07267531752586365), (12, 0.07291983347386122), (10, 0.08243949804455042), (16, 0.09481293987482786), (5, 0.1074186023324728), (18, 0.4618607945740223), (36, 0.536344401538372), (53, 1.3899962306022644)]
computing accuracy for after removing block 48 . block score: 0.046045055612921715
removed block 48 current accuracy 0.8724 loss from initial  0.07900000000000007
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 4, with score 0.046304. All blocks and scores: [(4, 0.046303591690957546), (6, 0.04645444918423891), (27, 0.047888172790408134), (13, 0.04896391276270151), (17, 0.04989673011004925), (51, 0.05110225034877658), (11, 0.05211011506617069), (25, 0.052639458794146776), (19, 0.05409543262794614), (2, 0.05473122512921691), (3, 0.0575909735634923), (49, 0.061201456002891064), (38, 0.062255504075437784), (37, 0.06366122048348188), (0, 0.06376117747277021), (1, 0.0669163167476654), (52, 0.0674590626731515), (39, 0.0721041802316904), (8, 0.07267531752586365), (12, 0.07291983626782894), (10, 0.08243949711322784), (16, 0.09481293801218271), (5, 0.10741860326379538), (18, 0.4618607722222805), (36, 0.5363443866372108), (53, 1.5353408306837082)]
computing accuracy for after removing block 4 . block score: 0.046303591690957546
removed block 4 current accuracy 0.8528 loss from initial  0.09860000000000002
since last training loss: 0.09019999999999995 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 27, with score 0.047936. All blocks and scores: [(27, 0.047935886308550835), (17, 0.04834801331162453), (11, 0.04844123451039195), (13, 0.04859267733991146), (51, 0.051031094044446945), (6, 0.05131946550682187), (25, 0.051438885275274515), (2, 0.05473122373223305), (3, 0.05759097635746002), (19, 0.058687117882072926), (49, 0.06032678624615073), (38, 0.061572154983878136), (0, 0.06376117747277021), (37, 0.06574306730180979), (1, 0.06691631581634283), (52, 0.06708747241646051), (39, 0.07158823497593403), (12, 0.07186649926006794), (8, 0.07549882587045431), (16, 0.08288757409900427), (10, 0.08320304099470377), (5, 0.11181017104536295), (18, 0.48103053867816925), (36, 0.5449833944439888), (53, 1.5746480971574783)]
computing accuracy for after removing block 27 . block score: 0.047935886308550835
removed block 27 current accuracy 0.8314 loss from initial  0.12
since last training loss: 0.11159999999999992 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 17, with score 0.048348. All blocks and scores: [(17, 0.048348015174269676), (11, 0.0484412363730371), (13, 0.04859267733991146), (51, 0.05016308696940541), (6, 0.051319466438144445), (25, 0.051438885275274515), (2, 0.054731226060539484), (3, 0.0575909735634923), (19, 0.05868712114170194), (49, 0.06019902182742953), (38, 0.06355648580938578), (0, 0.06376117654144764), (52, 0.06489993911236525), (1, 0.0669163167476654), (12, 0.07186649739742279), (39, 0.07417339365929365), (37, 0.07542223576456308), (8, 0.07549882307648659), (16, 0.08288757875561714), (10, 0.08320304285734892), (5, 0.11181017104536295), (18, 0.48103054240345955), (36, 0.5876694172620773), (53, 1.5859893560409546)]
computing accuracy for after removing block 17 . block score: 0.048348015174269676
removed block 17 current accuracy 0.8198 loss from initial  0.13160000000000005
since last training loss: 0.12319999999999998 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 11, with score 0.048441. All blocks and scores: [(11, 0.048441235441714525), (13, 0.04859267873689532), (25, 0.04882630705833435), (51, 0.049071675166487694), (6, 0.05131946736946702), (2, 0.05473122373223305), (49, 0.0569680486805737), (3, 0.057590972632169724), (38, 0.05944450804963708), (19, 0.060952515341341496), (52, 0.06124400580301881), (0, 0.06376117561012506), (1, 0.06691631861031055), (37, 0.07086358778178692), (12, 0.07186649646610022), (39, 0.07202456425875425), (8, 0.07549882493913174), (16, 0.08288757689297199), (10, 0.08320304099470377), (5, 0.11181017197668552), (18, 0.45348089188337326), (36, 0.550093300640583), (53, 1.5665405690670013)]
computing accuracy for after removing block 11 . block score: 0.048441235441714525
removed block 11 current accuracy 0.781 loss from initial  0.1704
since last training loss: 0.16199999999999992 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.045410. All blocks and scores: [(13, 0.045409885700792074), (25, 0.04783203266561031), (51, 0.048082795925438404), (6, 0.05131946597248316), (2, 0.054731226060539484), (3, 0.0575909735634923), (49, 0.05884419195353985), (52, 0.060829173773527145), (12, 0.06088507687672973), (38, 0.06155581399798393), (16, 0.06223475327715278), (0, 0.06376117747277021), (1, 0.0669163167476654), (19, 0.06737526319921017), (37, 0.07246132008731365), (39, 0.07306427229195833), (8, 0.07549882587045431), (10, 0.08320304192602634), (5, 0.11181017104536295), (18, 0.4638962559401989), (36, 0.5599821880459785), (53, 1.5465473681688309)]
computing accuracy for after removing block 13 . block score: 0.045409885700792074
removed block 13 current accuracy 0.6856 loss from initial  0.26580000000000004
training start
training epoch 0 val accuracy 0.7966 topk_dict {'top1': 0.7966} is_best True lr [0.1]
training epoch 1 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.1]
training epoch 2 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 3 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 4 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.1]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 6 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 7 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 9 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 10 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 33
[activation diff]: block to remove picked: 0, with score 0.063503. All blocks and scores: [(0, 0.0635026297532022), (1, 0.06609395053237677), (49, 0.07392824813723564), (2, 0.07809006981551647), (51, 0.08005736395716667), (38, 0.08161288220435381), (52, 0.09014836046844721), (39, 0.09098977223038673), (37, 0.0940944291651249), (6, 0.09778738860040903), (19, 0.10043042246252298), (3, 0.12046999949961901), (25, 0.12271932326257229), (8, 0.1342395655810833), (10, 0.18068022094666958), (5, 0.20218977145850658), (12, 0.23264277540147305), (16, 0.24991474486887455), (18, 0.5941886976361275), (36, 0.6404205039143562), (53, 1.3681580126285553)]
computing accuracy for after removing block 0 . block score: 0.0635026297532022
removed block 0 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.016800000000000037 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 1, with score 0.068312. All blocks and scores: [(1, 0.06831179186701775), (49, 0.0730723487213254), (51, 0.07750194985419512), (38, 0.07864748686552048), (2, 0.08367380406707525), (52, 0.08960531931370497), (39, 0.09149251971393824), (37, 0.09199988935142756), (3, 0.09542466793209314), (6, 0.09724241960793734), (19, 0.09855106472969055), (25, 0.11887052562087774), (8, 0.13038031943142414), (10, 0.17278015054762363), (5, 0.20264102518558502), (12, 0.22963231429457664), (16, 0.2417413704097271), (18, 0.5974110588431358), (36, 0.6256250739097595), (53, 1.369508758187294)]
computing accuracy for after removing block 1 . block score: 0.06831179186701775
removed block 1 current accuracy 0.8708 loss from initial  0.0806
since last training loss: 0.07079999999999997 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 49, with score 0.071022. All blocks and scores: [(49, 0.07102195546030998), (51, 0.07168425619602203), (38, 0.07353515177965164), (52, 0.07874209992587566), (3, 0.08336812257766724), (37, 0.08548177406191826), (39, 0.08672900591045618), (19, 0.08771821483969688), (2, 0.08825881592929363), (6, 0.08999259024858475), (25, 0.10612880624830723), (8, 0.11460648197680712), (10, 0.16437792964279652), (5, 0.20203550532460213), (16, 0.2113817986100912), (12, 0.21740026026964188), (18, 0.5861744359135628), (36, 0.5947729870676994), (53, 1.4048106223344803)]
computing accuracy for after removing block 49 . block score: 0.07102195546030998
removed block 49 current accuracy 0.8214 loss from initial  0.13
since last training loss: 0.12019999999999997 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 38, with score 0.073535. All blocks and scores: [(38, 0.07353515177965164), (51, 0.07671249099075794), (52, 0.08022241853177547), (3, 0.08336812444031239), (37, 0.08548177406191826), (39, 0.08672900311648846), (19, 0.08771821763366461), (2, 0.08825881686061621), (6, 0.08999258931726217), (25, 0.10612880997359753), (8, 0.11460648383945227), (10, 0.16437792219221592), (5, 0.20203550904989243), (16, 0.21138180047273636), (12, 0.21740026399493217), (18, 0.5861744433641434), (36, 0.5947729796171188), (53, 1.7538352310657501)]
computing accuracy for after removing block 38 . block score: 0.07353515177965164
removed block 38 current accuracy 0.7654 loss from initial  0.18600000000000005
since last training loss: 0.17620000000000002 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 51, with score 0.073251. All blocks and scores: [(51, 0.07325099408626556), (52, 0.07696460094302893), (3, 0.08336812350898981), (37, 0.08548177219927311), (19, 0.08771821949630976), (2, 0.08825881686061621), (6, 0.0899925883859396), (39, 0.0973783815279603), (25, 0.1061288071796298), (8, 0.11460648290812969), (10, 0.16437792591750622), (5, 0.20203551277518272), (16, 0.21138179674744606), (12, 0.21740026213228703), (18, 0.5861744210124016), (36, 0.59477299451828), (53, 2.055123805999756)]
computing accuracy for after removing block 51 . block score: 0.07325099408626556
removed block 51 current accuracy 0.6604 loss from initial  0.29100000000000004
since last training loss: 0.2812 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 3, with score 0.083368. All blocks and scores: [(3, 0.08336812350898981), (52, 0.0840915460139513), (37, 0.08548177219927311), (19, 0.08771821763366461), (2, 0.08825881686061621), (6, 0.08999258931726217), (39, 0.09737838245928288), (25, 0.1061288034543395), (8, 0.11460648942738771), (10, 0.16437792405486107), (5, 0.20203551091253757), (16, 0.21138180047273636), (12, 0.21740025840699673), (18, 0.5861744210124016), (36, 0.5947729870676994), (53, 2.494081526994705)]
computing accuracy for after removing block 3 . block score: 0.08336812350898981
removed block 3 current accuracy 0.4914 loss from initial  0.46
since last training loss: 0.4502 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 52, with score 0.080305. All blocks and scores: [(52, 0.08030539192259312), (19, 0.08269224409013987), (37, 0.0860985079780221), (2, 0.0882588205859065), (39, 0.09113968536257744), (6, 0.09553779754787683), (25, 0.09591337013989687), (8, 0.10900798067450523), (10, 0.16398226283490658), (16, 0.16736646369099617), (12, 0.19863571971654892), (5, 0.2194392178207636), (36, 0.5799834281206131), (18, 0.5829844921827316), (53, 2.5725075602531433)]
computing accuracy for after removing block 52 . block score: 0.08030539192259312
removed block 52 current accuracy 0.4328 loss from initial  0.5186
since last training loss: 0.5087999999999999 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 19, with score 0.082692. All blocks and scores: [(19, 0.08269224129617214), (37, 0.0860985117033124), (2, 0.08825881779193878), (39, 0.09113968536257744), (6, 0.09553779289126396), (25, 0.09591336827725172), (8, 0.10900798253715038), (10, 0.16398227028548717), (16, 0.16736646369099617), (12, 0.19863571971654892), (5, 0.2194392178207636), (36, 0.5799834281206131), (18, 0.5829844996333122), (53, 2.116463929414749)]
computing accuracy for after removing block 19 . block score: 0.08269224129617214
removed block 19 current accuracy 0.3616 loss from initial  0.5898000000000001
since last training loss: 0.5800000000000001 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 2, with score 0.088259. All blocks and scores: [(2, 0.0882588205859065), (25, 0.0901143979281187), (6, 0.09553779661655426), (39, 0.09607551153749228), (37, 0.10047442000359297), (8, 0.10900798067450523), (10, 0.16398227214813232), (16, 0.16736646182835102), (12, 0.19863572344183922), (5, 0.21943922527134418), (18, 0.5829844772815704), (36, 0.6174331456422806), (53, 2.1463897228240967)]
computing accuracy for after removing block 2 . block score: 0.0882588205859065
removed block 2 current accuracy 0.2592 loss from initial  0.6922
since last training loss: 0.6824 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 25, with score 0.078728. All blocks and scores: [(25, 0.07872815150767565), (6, 0.08554514963179827), (39, 0.08680243324488401), (37, 0.09500681888312101), (8, 0.1078891521319747), (16, 0.13746177218854427), (10, 0.16661929711699486), (12, 0.17373074032366276), (5, 0.23311899043619633), (18, 0.5542151033878326), (36, 0.5760113298892975), (53, 1.927690327167511)]
computing accuracy for after removing block 25 . block score: 0.07872815150767565
removed block 25 current accuracy 0.189 loss from initial  0.7624
since last training loss: 0.7525999999999999 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 6, with score 0.085545. All blocks and scores: [(6, 0.08554514870047569), (39, 0.08663424104452133), (8, 0.10788915120065212), (37, 0.13513830117881298), (16, 0.13746176660060883), (10, 0.1666192952543497), (12, 0.17373073659837246), (5, 0.23311899602413177), (18, 0.5542151108384132), (36, 0.6433157175779343), (53, 2.005176216363907)]
computing accuracy for after removing block 6 . block score: 0.08554514870047569
removed block 6 current accuracy 0.1358 loss from initial  0.8156
since last training loss: 0.8058 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 39, with score 0.082847. All blocks and scores: [(39, 0.08284689113497734), (8, 0.11763740982860327), (16, 0.11831032205373049), (37, 0.13541114889085293), (12, 0.1497490257024765), (10, 0.1733872927725315), (5, 0.23311898857355118), (18, 0.5405680686235428), (36, 0.633139856159687), (53, 1.7115299999713898)]
computing accuracy for after removing block 39 . block score: 0.08284689113497734
removed block 39 current accuracy 0.1206 loss from initial  0.8308
training start
training epoch 0 val accuracy 0.8066 topk_dict {'top1': 0.8066} is_best True lr [0.1]
training epoch 1 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best True lr [0.1]
training epoch 2 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best True lr [0.1]
training epoch 3 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.1]
training epoch 4 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 5 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 6 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 8 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 9 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 10 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.919000)
finished training. finished 50 epochs. accuracy 0.919 topk_dict {'top1': 0.919}
