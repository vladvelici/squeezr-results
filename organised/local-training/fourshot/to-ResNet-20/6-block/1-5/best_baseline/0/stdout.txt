start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.01329466060269624), (29, 0.013421116746030748), (35, 0.015957689378410578), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01999649149365723), (46, 0.02059022500179708), (25, 0.022078295005485415), (23, 0.02222871594130993), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.023749591084197164), (45, 0.023975495249032974), (21, 0.02494108909741044), (48, 0.024957707151770592), (22, 0.025151390815153718), (50, 0.025287175085395575), (24, 0.025880583096295595), (49, 0.025916647631675005), (42, 0.026232231641188264), (20, 0.026848891749978065), (47, 0.028632948640733957), (38, 0.03134434390813112), (39, 0.031441295985132456), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.0417875861749053), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013119243434630334), (29, 0.013421116396784782), (26, 0.016072141006588936), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019852686673402786), (46, 0.020300705451518297), (41, 0.02186027471907437), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.02297719311900437), (40, 0.02357383049093187), (45, 0.02364823827520013), (48, 0.02454021666198969), (50, 0.024770822376012802), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.02557574026286602), (24, 0.025880582397803664), (42, 0.025893412996083498), (20, 0.026848892448469996), (47, 0.028072760440409184), (38, 0.031091188080608845), (39, 0.031191361136734486), (15, 0.0320583856664598), (7, 0.032445501536130905), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4339805953204632), (18, 0.5117433071136475), (53, 0.8063970655202866)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187987402081), (31, 0.01023258117493242), (34, 0.01275888190139085), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464537739754), (46, 0.020411915378645062), (41, 0.02182762883603573), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.022891477681696415), (40, 0.02360258041881025), (45, 0.02377084968611598), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.025880583096295595), (20, 0.02684889198280871), (47, 0.028052503941580653), (38, 0.030935874674469233), (39, 0.03117303643375635), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03834319021552801), (51, 0.04113080911338329), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.057849929202347994), (13, 0.05914428923279047), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464461103082), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4350203089416027), (18, 0.5117432996630669), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187987402081
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159845128655), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636861884966493), (27, 0.019022797932848334), (43, 0.01986734988167882), (46, 0.020279743941500783), (41, 0.02175601990893483), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.02435004571452737), (50, 0.02446310594677925), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.02524693007580936), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.02772757480852306), (38, 0.03074627509340644), (39, 0.03128179511986673), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428876712918), (11, 0.0597000359557569), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06356755923479795), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4377693198621273), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687325486913323), (40, 0.023569098440930247), (45, 0.023840720532462), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.025045575108379126), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848891051486135), (47, 0.027423852123320103), (38, 0.030735649168491364), (39, 0.0314104245044291), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.04034593887627125), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.061325253918766975), (52, 0.06270107626914978), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43692684546113014), (18, 0.5117432996630669), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.020302683813497424), (46, 0.020324198063462973), (41, 0.021962703205645084), (25, 0.022078294306993484), (23, 0.022228715242817998), (44, 0.023045078152790666), (48, 0.024024546379223466), (50, 0.024096973007544875), (40, 0.024156817235052586), (45, 0.024168409407138824), (49, 0.02492237207479775), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.025880582397803664), (20, 0.02684889268130064), (47, 0.02756829559803009), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.03225791221484542), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241510525346), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.061325253918766975), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702051639557), (18, 0.5117432922124863), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.01637051161378622), (28, 0.017636860720813274), (27, 0.019022797234356403), (43, 0.019856703467667103), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078295471146703), (23, 0.022228714544326067), (44, 0.02269203239120543), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616240825504065), (45, 0.023933291900902987), (49, 0.02444991492666304), (42, 0.0248383276630193), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880583096295595), (47, 0.02681345585733652), (20, 0.026848891517147422), (38, 0.031083731912076473), (39, 0.032056888565421104), (15, 0.0320583856664598), (7, 0.03244550386443734), (19, 0.03254077909514308), (51, 0.03907974995672703), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003455877304), (52, 0.060369073413312435), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527505863457918), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4432784430682659), (18, 0.5117433071136475), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144015721977), (28, 0.016986021772027016), (27, 0.018769709393382072), (43, 0.019405571976676583), (46, 0.019700075965374708), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022507571848109365), (48, 0.02289936924353242), (50, 0.022937728092074394), (40, 0.02305740164592862), (42, 0.02352040889672935), (45, 0.023633700562641025), (49, 0.02408191841095686), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880582630634308), (47, 0.02632279321551323), (20, 0.026848893146961927), (38, 0.030149148777127266), (39, 0.031466697342693806), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03785192780196667), (37, 0.039268902968615294), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.05784992827102542), (52, 0.05846811830997467), (13, 0.05914428737014532), (11, 0.0597000359557569), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.43490004166960716), (18, 0.5117433071136475), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504144015721977
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.018769708229228854), (46, 0.01884230156429112), (41, 0.01901637064293027), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.021748854545876384), (40, 0.021916967118158937), (42, 0.021930374205112457), (25, 0.022078294539824128), (23, 0.022228715708479285), (45, 0.022736449725925922), (49, 0.022970063844695687), (21, 0.024941089330241084), (22, 0.025151390116661787), (47, 0.025355831254273653), (24, 0.02588058286346495), (20, 0.026848891284316778), (38, 0.028691886458545923), (39, 0.029624431626871228), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03601635713130236), (37, 0.03643036773428321), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241324260831), (2, 0.05457740370184183), (52, 0.054668578784912825), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143140643835), (36, 0.41641608625650406), (18, 0.5117432996630669), (53, 0.8948249071836472)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635219469666), (46, 0.01835862477310002), (41, 0.01846780744381249), (27, 0.018769708927720785), (48, 0.020775508601218462), (42, 0.021206470439210534), (50, 0.021302448119968176), (44, 0.021586895687505603), (40, 0.02159272227436304), (25, 0.022078295005485415), (23, 0.02222871547564864), (45, 0.02231529401615262), (49, 0.022407566430047154), (47, 0.024609396932646632), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.025880583096295595), (20, 0.026848891051486135), (38, 0.027890324126929045), (39, 0.02919189492240548), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03550667595118284), (37, 0.03591922763735056), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241277694702), (52, 0.053374080918729305), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.05970003129914403), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143233776093), (36, 0.412618201225996), (18, 0.5117433071136475), (53, 0.906721331179142)]
computing accuracy for after removing block 43 . block score: 0.017987635219469666
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708927720785), (46, 0.01899468107149005), (42, 0.02120647020637989), (48, 0.021418895572423935), (50, 0.021441322285681963), (40, 0.021592722740024328), (25, 0.02207829593680799), (23, 0.02222871594130993), (49, 0.022339017828926444), (44, 0.022782833082601428), (45, 0.023323106113821268), (21, 0.024941089330241084), (22, 0.02515139104798436), (47, 0.02538607711903751), (24, 0.025880583096295595), (20, 0.026848891749978065), (38, 0.02789032575674355), (39, 0.029191895155236125), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.035217716824263334), (37, 0.03591922717168927), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241324260831), (52, 0.05213337205350399), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.06132525159046054), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4126181975007057), (18, 0.5117432996630669), (53, 0.9521221145987511)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 1 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.1]
training epoch 2 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.1]
training epoch 3 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 4 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.1]
training epoch 5 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.1]
training epoch 6 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.1]
training epoch 7 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.1]
training epoch 8 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.1]
training epoch 9 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.014735. All blocks and scores: [(48, 0.014734541531652212), (46, 0.01661353698000312), (45, 0.018070526653900743), (47, 0.01972347521223128), (44, 0.020583401899784803), (23, 0.022484155371785164), (40, 0.02476691105403006), (21, 0.025216101901605725), (22, 0.025462066987529397), (42, 0.025609499076381326), (24, 0.02625181875191629), (20, 0.027297692373394966), (50, 0.027817753376439214), (49, 0.02892888500355184), (39, 0.031583128962665796), (38, 0.03221105434931815), (15, 0.03227354399859905), (7, 0.03239231463521719), (19, 0.03276885999366641), (25, 0.033405430149286985), (27, 0.03531320719048381), (37, 0.038716566283255816), (51, 0.0430982718244195), (9, 0.04377228207886219), (4, 0.04624181566759944), (6, 0.04639632301405072), (14, 0.04811575869098306), (2, 0.054869086015969515), (3, 0.057840141002088785), (13, 0.05968048237264156), (11, 0.0598190613090992), (17, 0.0627874806523323), (0, 0.06389168184250593), (1, 0.0665878402069211), (52, 0.06878727674484253), (8, 0.07488250732421875), (10, 0.08146288804709911), (16, 0.08632469084113836), (12, 0.0909075802192092), (5, 0.10646802373230457), (18, 0.5151503011584282), (36, 0.524442233145237), (53, 0.8081484586000443)]
computing accuracy for after removing block 48 . block score: 0.014734541531652212
removed block 48 current accuracy 0.943 loss from initial  0.008400000000000074
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.016614. All blocks and scores: [(46, 0.016613537445664406), (45, 0.0180705264210701), (47, 0.019723475445061922), (44, 0.020583401434123516), (23, 0.022484155604615808), (40, 0.024766910821199417), (21, 0.025216101203113794), (22, 0.025462066289037466), (42, 0.02560949930921197), (24, 0.02625181875191629), (20, 0.02729769144207239), (50, 0.0315171901602298), (39, 0.03158312849700451), (49, 0.031921134097501636), (38, 0.032211054814979434), (15, 0.03227354446426034), (7, 0.03239231510087848), (19, 0.03276885952800512), (25, 0.033405430149286985), (27, 0.035313207656145096), (37, 0.038716566283255816), (51, 0.042156802490353584), (9, 0.043772283010184765), (4, 0.04624181520193815), (6, 0.046396324411034584), (14, 0.04811576008796692), (2, 0.054869086015969515), (3, 0.057840139139443636), (13, 0.05968048423528671), (11, 0.05981906317174435), (17, 0.06278747972100973), (0, 0.06389168091118336), (1, 0.06658784206956625), (8, 0.07488250825554132), (52, 0.07491892203688622), (10, 0.08146289084106684), (16, 0.08632468897849321), (12, 0.09090757928788662), (5, 0.10646802466362715), (18, 0.5151503011584282), (36, 0.524442233145237), (53, 0.8436633571982384)]
computing accuracy for after removing block 46 . block score: 0.016613537445664406
removed block 46 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.018071. All blocks and scores: [(45, 0.018070526188239455), (44, 0.02058340166695416), (47, 0.0220395780634135), (23, 0.022484155604615808), (40, 0.02476691105403006), (21, 0.02521610166877508), (22, 0.025462066754698753), (42, 0.025609499542042613), (24, 0.026251818984746933), (20, 0.027297692140564322), (39, 0.03158312803134322), (38, 0.03221105458214879), (15, 0.032273543532937765), (7, 0.032392315566539764), (19, 0.03276885999366641), (50, 0.03284364566206932), (25, 0.033405432011932135), (49, 0.034159512259066105), (27, 0.03531320812180638), (37, 0.038716566283255816), (51, 0.043634818866848946), (9, 0.04377228347584605), (4, 0.04624181566759944), (6, 0.04639632347971201), (14, 0.04811575962230563), (2, 0.05486908555030823), (3, 0.05784014007076621), (13, 0.05968048283830285), (11, 0.05981906037777662), (17, 0.06278748018667102), (0, 0.06389168184250593), (1, 0.0665878402069211), (8, 0.07488251011818647), (52, 0.0776270367205143), (10, 0.08146288897842169), (16, 0.08632468897849321), (12, 0.09090757742524147), (5, 0.1064680265262723), (18, 0.5151503086090088), (36, 0.5244422182440758), (53, 0.8969239369034767)]
computing accuracy for after removing block 45 . block score: 0.018070526188239455
removed block 45 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.020583. All blocks and scores: [(44, 0.020583401899784803), (23, 0.02248415630310774), (47, 0.023422181140631437), (40, 0.024766910588368773), (21, 0.02521610166877508), (22, 0.025462066754698753), (42, 0.025609499076381326), (24, 0.026251818519085646), (20, 0.027297692140564322), (39, 0.03158312803134322), (38, 0.03221105504781008), (15, 0.032273543532937765), (7, 0.03239231510087848), (19, 0.032768860924988985), (25, 0.03340543061494827), (50, 0.03433351032435894), (49, 0.03510885965079069), (27, 0.035313207656145096), (37, 0.0387165667489171), (51, 0.04282898548990488), (9, 0.043772281147539616), (4, 0.04624181380495429), (6, 0.0463963239453733), (14, 0.048115757293999195), (2, 0.05486908694729209), (3, 0.057840137742459774), (13, 0.05968048423528671), (11, 0.059819061774760485), (17, 0.0627874806523323), (0, 0.06389168184250593), (1, 0.06658784206956625), (8, 0.07488250825554132), (52, 0.07628674153238535), (10, 0.08146288897842169), (16, 0.08632468990981579), (12, 0.09090757928788662), (5, 0.1064680265262723), (18, 0.5151503011584282), (36, 0.5244422107934952), (53, 0.9661389291286469)]
computing accuracy for after removing block 44 . block score: 0.020583401899784803
removed block 44 current accuracy 0.9236 loss from initial  0.027800000000000047
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.022484. All blocks and scores: [(23, 0.022484156535938382), (47, 0.02430760394781828), (40, 0.024766910588368773), (21, 0.02521610166877508), (22, 0.02546206652186811), (42, 0.025609499076381326), (24, 0.026251818519085646), (20, 0.02729769190773368), (39, 0.03158312733285129), (38, 0.03221105458214879), (15, 0.032273543532937765), (7, 0.03239231603220105), (19, 0.032768860924988985), (25, 0.03340543061494827), (49, 0.03418136714026332), (50, 0.03530289977788925), (27, 0.035313206259161234), (37, 0.038716564886271954), (51, 0.042264627292752266), (9, 0.0437722816132009), (4, 0.04624181520193815), (6, 0.04639632347971201), (14, 0.04811575822532177), (2, 0.05486908555030823), (3, 0.0578401405364275), (13, 0.05968048283830285), (11, 0.05981906317174435), (17, 0.06278747972100973), (0, 0.0638916827738285), (1, 0.06658783927559853), (52, 0.07381070870906115), (8, 0.07488251104950905), (10, 0.08146288804709911), (16, 0.08632469084113836), (12, 0.09090757742524147), (5, 0.10646802186965942), (18, 0.5151502937078476), (36, 0.524442233145237), (53, 1.050583302974701)]
computing accuracy for after removing block 23 . block score: 0.022484156535938382
removed block 23 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 47, with score 0.023511. All blocks and scores: [(47, 0.0235113138332963), (40, 0.023944810032844543), (42, 0.02475881204009056), (24, 0.02489073178730905), (21, 0.025216100737452507), (22, 0.02546206652186811), (20, 0.027297691674903035), (38, 0.03145477594807744), (39, 0.031487243017181754), (15, 0.032273543532937765), (7, 0.032392315566539764), (25, 0.03251437097787857), (19, 0.0327688604593277), (27, 0.034060338512063026), (49, 0.03411340434104204), (50, 0.03437845315784216), (37, 0.039813697803765535), (51, 0.04178127273917198), (9, 0.04377228207886219), (4, 0.046241814736276865), (6, 0.04639632301405072), (14, 0.04811576008796692), (2, 0.05486908368766308), (3, 0.057840139139443636), (13, 0.059680481906980276), (11, 0.05981906224042177), (17, 0.06278747925534844), (0, 0.06389168184250593), (1, 0.06658784113824368), (52, 0.07193746697157621), (8, 0.07488250639289618), (10, 0.08146289270371199), (16, 0.08632468990981579), (12, 0.09090757835656404), (5, 0.10646802745759487), (18, 0.5151502937078476), (36, 0.521213635802269), (53, 1.0600278675556183)]
computing accuracy for after removing block 47 . block score: 0.0235113138332963
removed block 47 current accuracy 0.8918 loss from initial  0.059599999999999986
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.023945. All blocks and scores: [(40, 0.023944810265675187), (42, 0.024758811807259917), (24, 0.024890731554478407), (21, 0.02521610166877508), (22, 0.025462066056206822), (20, 0.027297692373394966), (38, 0.03145477641373873), (39, 0.03148724348284304), (15, 0.032273543532937765), (7, 0.032392315566539764), (25, 0.03251437097787857), (19, 0.032768860924988985), (27, 0.034060338512063026), (49, 0.03530458314344287), (50, 0.03610334638506174), (37, 0.03981369873508811), (51, 0.04261940298601985), (9, 0.043772281147539616), (4, 0.04624181520193815), (6, 0.0463963239453733), (14, 0.048115761019289494), (2, 0.05486908555030823), (3, 0.05784014146775007), (13, 0.05968048330396414), (11, 0.05981906084343791), (17, 0.06278748158365488), (0, 0.06389168091118336), (1, 0.06658784206956625), (52, 0.07244980242103338), (8, 0.07488250732421875), (10, 0.08146288897842169), (16, 0.08632468990981579), (12, 0.09090757835656404), (5, 0.10646802466362715), (18, 0.5151503086090088), (36, 0.5212136432528496), (53, 1.1615757048130035)]
computing accuracy for after removing block 40 . block score: 0.023944810265675187
removed block 40 current accuracy 0.8836 loss from initial  0.06779999999999997
since last training loss: 0.06419999999999992 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 42, with score 0.024812. All blocks and scores: [(42, 0.02481191186234355), (24, 0.024890732718631625), (21, 0.02521610166877508), (22, 0.025462066754698753), (20, 0.02729769144207239), (38, 0.031454776879400015), (39, 0.031487243715673685), (15, 0.03227354306727648), (7, 0.03239231510087848), (25, 0.03251437144353986), (19, 0.03276885859668255), (27, 0.034060338977724314), (49, 0.03544952534139156), (50, 0.036209814716130495), (37, 0.03981369873508811), (51, 0.042445136699825525), (9, 0.04377228254452348), (4, 0.046241814736276865), (6, 0.0463963239453733), (14, 0.048115759156644344), (2, 0.0548690864816308), (3, 0.05784013960510492), (13, 0.05968048283830285), (11, 0.05981906224042177), (17, 0.0627874773927033), (0, 0.0638916827738285), (1, 0.06658784206956625), (52, 0.07313373405486345), (8, 0.07488251011818647), (10, 0.08146289084106684), (16, 0.08632469177246094), (12, 0.09090757928788662), (5, 0.106468022800982), (18, 0.5151503011584282), (36, 0.5212136432528496), (53, 1.2262512147426605)]
computing accuracy for after removing block 42 . block score: 0.02481191186234355
removed block 42 current accuracy 0.8602 loss from initial  0.09120000000000006
since last training loss: 0.08760000000000001 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.024891. All blocks and scores: [(24, 0.024890732020139694), (21, 0.025216101435944438), (22, 0.025462066056206822), (20, 0.027297692373394966), (38, 0.031454776879400015), (39, 0.03148724348284304), (15, 0.03227354446426034), (7, 0.0323923141695559), (25, 0.03251437144353986), (19, 0.0327688604593277), (27, 0.03406033758074045), (49, 0.03729014424607158), (37, 0.03981369826942682), (50, 0.04013603925704956), (51, 0.04258508561179042), (9, 0.04377228254452348), (4, 0.04624181427061558), (6, 0.04639632534235716), (14, 0.04811575962230563), (2, 0.05486908508464694), (3, 0.05784014146775007), (13, 0.05968048423528671), (11, 0.05981906317174435), (17, 0.06278748251497746), (0, 0.0638916827738285), (1, 0.0665878402069211), (8, 0.07488250825554132), (52, 0.07744743674993515), (10, 0.08146289084106684), (16, 0.08632469084113836), (12, 0.0909075802192092), (5, 0.10646802466362715), (18, 0.5151503011584282), (36, 0.5212136432528496), (53, 1.2455252259969711)]
computing accuracy for after removing block 24 . block score: 0.024890732020139694
removed block 24 current accuracy 0.845 loss from initial  0.10640000000000005
since last training loss: 0.1028 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.025216. All blocks and scores: [(21, 0.02521610097028315), (22, 0.02546206652186811), (20, 0.027297692140564322), (38, 0.03032379108481109), (39, 0.030509903095662594), (25, 0.030786701245233417), (15, 0.03227354306727648), (7, 0.03239231510087848), (19, 0.0327688604593277), (27, 0.03320549428462982), (49, 0.03519338369369507), (50, 0.03689502412453294), (37, 0.038823087234050035), (51, 0.04013925977051258), (9, 0.04377228207886219), (4, 0.046241816598922014), (6, 0.04639632347971201), (14, 0.048115759156644344), (2, 0.05486908694729209), (3, 0.0578401405364275), (13, 0.059680484700948), (11, 0.059819061774760485), (17, 0.06278747972100973), (0, 0.06389168370515108), (1, 0.06658784206956625), (52, 0.0709982868283987), (8, 0.07488250825554132), (10, 0.08146288804709911), (16, 0.08632468897849321), (12, 0.0909075802192092), (5, 0.10646802466362715), (36, 0.5000757947564125), (18, 0.5151503086090088), (53, 1.2912036031484604)]
computing accuracy for after removing block 21 . block score: 0.02521610097028315
removed block 21 current accuracy 0.8298 loss from initial  0.12160000000000004
since last training loss: 0.118 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.023693. All blocks and scores: [(22, 0.02369316085241735), (20, 0.027297692373394966), (38, 0.02843774505890906), (25, 0.028957537841051817), (39, 0.029127074172720313), (27, 0.032124679535627365), (15, 0.03227354260161519), (7, 0.032392315566539764), (19, 0.032768860924988985), (49, 0.0341496174223721), (50, 0.03458178974688053), (37, 0.03724451782181859), (51, 0.038202350959181786), (9, 0.04377228254452348), (4, 0.04624181613326073), (6, 0.04639632487669587), (14, 0.048115761019289494), (2, 0.05486908461898565), (3, 0.05784014333039522), (13, 0.05968048330396414), (11, 0.05981906224042177), (17, 0.06278747972100973), (0, 0.0638916827738285), (52, 0.06432082410901785), (1, 0.0665878439322114), (8, 0.07488250732421875), (10, 0.08146288990974426), (16, 0.08632469084113836), (12, 0.09090757835656404), (5, 0.10646802373230457), (36, 0.47458700835704803), (18, 0.515150286257267), (53, 1.3510314524173737)]
computing accuracy for after removing block 22 . block score: 0.02369316085241735
removed block 22 current accuracy 0.7926 loss from initial  0.15880000000000005
training start
training epoch 0 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 1 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.1]
training epoch 2 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 3 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 4 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.1]
training epoch 5 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 6 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 7 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.1]
training epoch 8 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 9 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032084. All blocks and scores: [(15, 0.03208390669897199), (7, 0.03269972279667854), (19, 0.03292286302894354), (9, 0.044237174559384584), (6, 0.046920045744627714), (50, 0.046994118951261044), (14, 0.048272290267050266), (4, 0.04849397065117955), (51, 0.055328876711428165), (2, 0.05539589934051037), (49, 0.05646286252886057), (3, 0.05842542089521885), (11, 0.06017252616584301), (13, 0.06026966031640768), (17, 0.06250999262556434), (0, 0.0629826239310205), (27, 0.06422259751707315), (20, 0.06433621142059565), (1, 0.06658440362662077), (38, 0.06740070506930351), (25, 0.06908927205950022), (52, 0.07120273821055889), (8, 0.07516315206885338), (37, 0.0762035446241498), (39, 0.07822472043335438), (10, 0.08087459485977888), (16, 0.0863540368154645), (12, 0.09102066699415445), (5, 0.10691646952182055), (18, 0.5135556906461716), (36, 0.595128744840622), (53, 1.3903887122869492)]
computing accuracy for after removing block 15 . block score: 0.03208390669897199
removed block 15 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032700. All blocks and scores: [(7, 0.03269972326233983), (19, 0.033180182334035635), (9, 0.04423717549070716), (6, 0.046920046210289), (50, 0.04782339185476303), (14, 0.048272290732711554), (4, 0.04849397158250213), (2, 0.055395897943526506), (51, 0.05582658387720585), (49, 0.055920921731740236), (3, 0.0584254190325737), (11, 0.06017252570018172), (13, 0.06026966217905283), (27, 0.06154467957094312), (20, 0.06158977560698986), (0, 0.06298262299969792), (17, 0.06632331945002079), (1, 0.0665844026952982), (25, 0.06734167411923409), (38, 0.06794129963964224), (52, 0.06966772768646479), (8, 0.07516315206885338), (37, 0.07663706876337528), (39, 0.07775650639086962), (10, 0.08087459299713373), (12, 0.0910206688567996), (16, 0.09649490844458342), (5, 0.1069164676591754), (18, 0.5006487742066383), (36, 0.5818815603852272), (53, 1.412548765540123)]
computing accuracy for after removing block 7 . block score: 0.03269972326233983
removed block 7 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 19, with score 0.032888. All blocks and scores: [(19, 0.03288834169507027), (9, 0.04404305852949619), (14, 0.044618433341383934), (50, 0.045392288826406), (6, 0.04692004760727286), (4, 0.04849397297948599), (13, 0.05207673227414489), (51, 0.05397119838744402), (49, 0.054965412709861994), (2, 0.055395899806171656), (17, 0.05613475292921066), (11, 0.056843106634914875), (27, 0.057915572077035904), (3, 0.05842541949823499), (20, 0.058575787115842104), (0, 0.06298262346535921), (25, 0.0638448866084218), (1, 0.0665844026952982), (52, 0.06685152184218168), (38, 0.06753907259553671), (37, 0.07129632588475943), (8, 0.07309618592262268), (39, 0.07618094328790903), (10, 0.08322233613580465), (12, 0.08500137459486723), (16, 0.0878711175173521), (5, 0.10691647045314312), (18, 0.48354287818074226), (36, 0.5595061928033829), (53, 1.417145699262619)]
computing accuracy for after removing block 19 . block score: 0.03288834169507027
removed block 19 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 50, with score 0.043156. All blocks and scores: [(50, 0.04315646691247821), (9, 0.04404305852949619), (14, 0.044618433341383934), (6, 0.04692004667595029), (4, 0.04849397158250213), (13, 0.0520767318084836), (51, 0.052434863056987524), (49, 0.052759542129933834), (27, 0.05379670951515436), (20, 0.055367955937981606), (2, 0.05539589701220393), (17, 0.056134751066565514), (11, 0.05684310523793101), (3, 0.058425419963896275), (25, 0.059052095748484135), (52, 0.06278126314282417), (0, 0.06298262253403664), (38, 0.06518494430929422), (1, 0.06658440176397562), (37, 0.07163633219897747), (8, 0.07309618778526783), (39, 0.0736349243670702), (10, 0.0832223342731595), (12, 0.0850013718008995), (16, 0.08787111658602953), (5, 0.10691646672785282), (18, 0.48354286700487137), (36, 0.5475999638438225), (53, 1.4209785759449005)]
computing accuracy for after removing block 50 . block score: 0.04315646691247821
removed block 50 current accuracy 0.905 loss from initial  0.0464
since last training loss: 0.035599999999999965 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.044043. All blocks and scores: [(9, 0.04404305852949619), (14, 0.044618433341383934), (6, 0.04692004434764385), (4, 0.0484939725138247), (13, 0.05207673227414489), (49, 0.052759542129933834), (27, 0.05379670765250921), (20, 0.055367954540997744), (2, 0.055395898409187794), (17, 0.05613475013524294), (11, 0.05684310616925359), (51, 0.05706679727882147), (3, 0.05842541949823499), (25, 0.05905209667980671), (0, 0.06298262299969792), (38, 0.06518494337797165), (1, 0.0665844026952982), (37, 0.07163633313030005), (8, 0.07309618592262268), (39, 0.07363492529839277), (52, 0.07439798396080732), (10, 0.08322233520448208), (12, 0.08500137459486723), (16, 0.08787111844867468), (5, 0.1069164676591754), (18, 0.48354287073016167), (36, 0.5475999489426613), (53, 1.7266070693731308)]
computing accuracy for after removing block 9 . block score: 0.04404305852949619
removed block 9 current accuracy 0.8944 loss from initial  0.05700000000000005
since last training loss: 0.04620000000000002 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 14, with score 0.040452. All blocks and scores: [(14, 0.040452143643051386), (6, 0.046920047141611576), (4, 0.04849397158250213), (13, 0.049493972677737474), (17, 0.050063634756952524), (49, 0.05027145333588123), (27, 0.050292020197957754), (11, 0.05243039969354868), (51, 0.05383849097415805), (2, 0.05539589701220393), (25, 0.055810806807130575), (20, 0.056549645494669676), (3, 0.058425419963896275), (38, 0.06280998745933175), (0, 0.06298262299969792), (37, 0.06387709267437458), (1, 0.06658440455794334), (52, 0.06981733813881874), (39, 0.07185209542512894), (16, 0.07226777728646994), (12, 0.07306495867669582), (8, 0.07309618592262268), (10, 0.08165563456714153), (5, 0.1069164676591754), (18, 0.46428752318024635), (36, 0.5065195634961128), (53, 1.7139412760734558)]
computing accuracy for after removing block 14 . block score: 0.040452143643051386
removed block 14 current accuracy 0.8672 loss from initial  0.08420000000000005
since last training loss: 0.07340000000000002 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 6, with score 0.046920. All blocks and scores: [(6, 0.046920045744627714), (4, 0.04849397158250213), (27, 0.04854165995493531), (49, 0.048780929297208786), (13, 0.049493972677737474), (17, 0.04958850285038352), (51, 0.05219925660640001), (11, 0.05243039969354868), (20, 0.053493335377424955), (25, 0.054423862136900425), (2, 0.055395897943526506), (3, 0.05842542042955756), (38, 0.06236982299014926), (0, 0.06298262253403664), (37, 0.0630917027592659), (52, 0.06496995780616999), (1, 0.06658440083265305), (39, 0.07008012384176254), (12, 0.07306495774537325), (8, 0.07309618592262268), (10, 0.08165563084185123), (16, 0.09537739306688309), (5, 0.10691646486520767), (18, 0.46120675280690193), (36, 0.49512533843517303), (53, 1.73788982629776)]
computing accuracy for after removing block 6 . block score: 0.046920045744627714
removed block 6 current accuracy 0.8232 loss from initial  0.12819999999999998
since last training loss: 0.11739999999999995 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 27, with score 0.045374. All blocks and scores: [(27, 0.04537402046844363), (17, 0.04609754169359803), (49, 0.04646268580108881), (13, 0.046683250926434994), (11, 0.0479797413572669), (4, 0.04849397297948599), (51, 0.049753136932849884), (25, 0.0519701698794961), (20, 0.05212575802579522), (2, 0.055395898409187794), (3, 0.0584254190325737), (52, 0.059305211529135704), (38, 0.06091470830142498), (37, 0.0624442882835865), (0, 0.06298262113705277), (1, 0.06658440362662077), (39, 0.06719424203038216), (12, 0.06799960881471634), (8, 0.07205895613878965), (16, 0.07847990933805704), (10, 0.08533370587974787), (5, 0.10691647045314312), (18, 0.4554043523967266), (36, 0.4792593643069267), (53, 1.7757205069065094)]
computing accuracy for after removing block 27 . block score: 0.04537402046844363
removed block 27 current accuracy 0.7694 loss from initial  0.18200000000000005
since last training loss: 0.17120000000000002 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.045498. All blocks and scores: [(49, 0.04549753665924072), (17, 0.04609754029661417), (13, 0.04668324952945113), (11, 0.04797973996028304), (4, 0.048493972048163414), (51, 0.04873089538887143), (25, 0.05197017081081867), (20, 0.052125757560133934), (2, 0.05539589608088136), (52, 0.05784131772816181), (3, 0.058425418101251125), (38, 0.06202777894213796), (0, 0.06298262346535921), (1, 0.0665844026952982), (39, 0.06789274699985981), (12, 0.06799960881471634), (8, 0.07205895334482193), (37, 0.07298272754997015), (16, 0.07847990840673447), (10, 0.085333701223135), (5, 0.10691646859049797), (18, 0.4554043561220169), (36, 0.5259440019726753), (53, 1.9196574985980988)]
computing accuracy for after removing block 49 . block score: 0.04549753665924072
removed block 49 current accuracy 0.6958 loss from initial  0.25560000000000005
since last training loss: 0.24480000000000002 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.046098. All blocks and scores: [(17, 0.046097541227936745), (13, 0.046683250460773706), (11, 0.04797973996028304), (4, 0.048493972048163414), (51, 0.05052779754623771), (25, 0.05197017174214125), (20, 0.052125757560133934), (2, 0.055395894683897495), (3, 0.05842542042955756), (38, 0.06202777847647667), (0, 0.06298262299969792), (52, 0.06506365723907948), (1, 0.06658440176397562), (39, 0.06789274886250496), (12, 0.06799960695207119), (8, 0.07205895520746708), (37, 0.07298272848129272), (16, 0.07847990747541189), (10, 0.08533370215445757), (5, 0.1069164676591754), (18, 0.4554043598473072), (36, 0.5259439870715141), (53, 2.180619567632675)]
computing accuracy for after removing block 17 . block score: 0.046097541227936745
removed block 17 current accuracy 0.696 loss from initial  0.25540000000000007
since last training loss: 0.24460000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.046683. All blocks and scores: [(13, 0.04668325278908014), (11, 0.047979740891605616), (4, 0.048493972048163414), (51, 0.04899062542244792), (25, 0.05043400311842561), (20, 0.051638743840157986), (2, 0.055395898409187794), (3, 0.058425419963896275), (38, 0.060207277070730925), (52, 0.06207903241738677), (0, 0.06298262067139149), (39, 0.06527293752878904), (1, 0.06658440176397562), (12, 0.06799960695207119), (37, 0.06854117009788752), (8, 0.0720589542761445), (16, 0.07847990840673447), (10, 0.08533370215445757), (5, 0.10691646952182055), (18, 0.4301079250872135), (36, 0.4923730306327343), (53, 2.1167261004447937)]
computing accuracy for after removing block 13 . block score: 0.04668325278908014
removed block 13 current accuracy 0.5646 loss from initial  0.38680000000000003
training start
training epoch 0 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best True lr [0.1]
training epoch 1 val accuracy 0.7902 topk_dict {'top1': 0.7902} is_best False lr [0.1]
training epoch 2 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 3 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 4 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 7 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 8 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 9 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.049243. All blocks and scores: [(4, 0.04924266738817096), (2, 0.05510553624480963), (3, 0.058990503661334515), (0, 0.06465880759060383), (1, 0.06676215771585703), (38, 0.08295813389122486), (51, 0.08596486318856478), (37, 0.09069546405225992), (52, 0.09112735372036695), (39, 0.10269569046795368), (11, 0.10834628157317638), (20, 0.11582293082028627), (8, 0.12240485660731792), (25, 0.12752316892147064), (10, 0.13000352680683136), (5, 0.19063790701329708), (16, 0.22652970254421234), (12, 0.22965048998594284), (18, 0.5895393639802933), (36, 0.6245767995715141), (53, 1.3904910683631897)]
computing accuracy for after removing block 4 . block score: 0.04924266738817096
removed block 4 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.006799999999999917 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.055106. All blocks and scores: [(2, 0.05510553438216448), (3, 0.058990505523979664), (0, 0.06465880572795868), (1, 0.06676215678453445), (38, 0.08392031583935022), (51, 0.08596558589488268), (52, 0.09008663520216942), (37, 0.09249419718980789), (39, 0.10217162128537893), (11, 0.10316848289221525), (20, 0.11536845937371254), (25, 0.1259105782955885), (10, 0.12815588526427746), (8, 0.12961654551327229), (5, 0.20516709424555302), (16, 0.20783829130232334), (12, 0.21731575764715672), (18, 0.5961028784513474), (36, 0.6263472065329552), (53, 1.3752751052379608)]
computing accuracy for after removing block 2 . block score: 0.05510553438216448
removed block 2 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.053811. All blocks and scores: [(3, 0.053811402060091496), (0, 0.06465880386531353), (1, 0.0667621586471796), (38, 0.08006975799798965), (51, 0.08245628606528044), (52, 0.08470362517982721), (37, 0.08503060787916183), (11, 0.09642443619668484), (39, 0.0970832584425807), (20, 0.10484589915722609), (25, 0.11225843243300915), (10, 0.12490817066282034), (8, 0.12856793776154518), (16, 0.18896486051380634), (5, 0.19999444670975208), (12, 0.2008239757269621), (18, 0.5426990985870361), (36, 0.5796579793095589), (53, 1.370463639497757)]
computing accuracy for after removing block 3 . block score: 0.053811402060091496
removed block 3 current accuracy 0.8632 loss from initial  0.08820000000000006
since last training loss: 0.0756 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.064659. All blocks and scores: [(0, 0.06465880572795868), (1, 0.06676215678453445), (38, 0.07635088264942169), (52, 0.07723231706768274), (51, 0.07801696937531233), (37, 0.08146465290337801), (39, 0.09011263493448496), (11, 0.09156078100204468), (20, 0.09543667733669281), (25, 0.09930840879678726), (8, 0.1239780355244875), (10, 0.12513614911586046), (16, 0.1590217761695385), (12, 0.18791315332055092), (5, 0.20917585864663124), (18, 0.5036021508276463), (36, 0.5457253307104111), (53, 1.3136414289474487)]
computing accuracy for after removing block 0 . block score: 0.06465880572795868
removed block 0 current accuracy 0.7736 loss from initial  0.17780000000000007
since last training loss: 0.1652 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 1, with score 0.069115. All blocks and scores: [(1, 0.06911460775882006), (52, 0.07311153598129749), (38, 0.07461656536906958), (51, 0.07598552573472261), (37, 0.07895932998508215), (39, 0.08514245133846998), (11, 0.08873284514993429), (20, 0.09269102476537228), (25, 0.09478310123085976), (8, 0.1200528210029006), (10, 0.12330726999789476), (16, 0.14232930913567543), (12, 0.19143844582140446), (5, 0.2049141675233841), (18, 0.5203244313597679), (36, 0.5343899801373482), (53, 1.3234678506851196)]
computing accuracy for after removing block 1 . block score: 0.06911460775882006
removed block 1 current accuracy 0.5774 loss from initial  0.374
since last training loss: 0.36139999999999994 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 52, with score 0.062933. All blocks and scores: [(52, 0.06293298583477736), (51, 0.07214860897511244), (37, 0.07246940955519676), (38, 0.07340426743030548), (39, 0.07512144930660725), (11, 0.07821507006883621), (25, 0.0851230239495635), (20, 0.08714677859097719), (8, 0.11047930642962456), (10, 0.11786552239209414), (16, 0.11897228471934795), (12, 0.17370162531733513), (5, 0.20016907528042793), (18, 0.5192850008606911), (36, 0.5332234650850296), (53, 1.310915619134903)]
computing accuracy for after removing block 52 . block score: 0.06293298583477736
removed block 52 current accuracy 0.4316 loss from initial  0.5198
since last training loss: 0.5072 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 51, with score 0.072149. All blocks and scores: [(51, 0.07214861083775759), (37, 0.07246940862387419), (38, 0.07340426556766033), (39, 0.07512145023792982), (11, 0.07821507006883621), (25, 0.0851230202242732), (20, 0.08714678231626749), (8, 0.11047931201756), (10, 0.11786552239209414), (16, 0.11897228099405766), (12, 0.17370162531733513), (5, 0.20016907528042793), (18, 0.5192849859595299), (36, 0.5332234799861908), (53, 1.3116643577814102)]
computing accuracy for after removing block 51 . block score: 0.07214861083775759
removed block 51 current accuracy 0.356 loss from initial  0.5954
since last training loss: 0.5828 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 37, with score 0.072469. All blocks and scores: [(37, 0.07246940862387419), (38, 0.07340426836162806), (39, 0.07512144837528467), (11, 0.07821506913751364), (25, 0.08512301929295063), (20, 0.08714678138494492), (8, 0.11047930736094713), (10, 0.11786552239209414), (16, 0.11897228099405766), (12, 0.17370163090527058), (5, 0.20016907714307308), (18, 0.5192849859595299), (36, 0.5332234650850296), (53, 1.652538076043129)]
computing accuracy for after removing block 37 . block score: 0.07246940862387419
removed block 37 current accuracy 0.348 loss from initial  0.6034
since last training loss: 0.5908 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 39, with score 0.074244. All blocks and scores: [(39, 0.07424377463757992), (11, 0.07821507100015879), (25, 0.0851230202242732), (20, 0.08714678417891264), (38, 0.08726125210523605), (8, 0.11047930549830198), (10, 0.11786552611738443), (16, 0.11897228006273508), (12, 0.17370163090527058), (5, 0.20016907528042793), (18, 0.5192849859595299), (36, 0.5332234650850296), (53, 1.608770728111267)]
computing accuracy for after removing block 39 . block score: 0.07424377463757992
removed block 39 current accuracy 0.2978 loss from initial  0.6536
since last training loss: 0.641 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 11, with score 0.078215. All blocks and scores: [(11, 0.07821506913751364), (25, 0.08512301929295063), (20, 0.08714678138494492), (38, 0.08726125117391348), (8, 0.1104793082922697), (10, 0.11786552052944899), (16, 0.11897228192538023), (12, 0.17370162717998028), (5, 0.20016907341778278), (18, 0.5192849934101105), (36, 0.5332234650850296), (53, 1.978730246424675)]
computing accuracy for after removing block 11 . block score: 0.07821506913751364
removed block 11 current accuracy 0.3002 loss from initial  0.6512
since last training loss: 0.6386 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 25, with score 0.079393. All blocks and scores: [(25, 0.0793931744992733), (20, 0.08867285307496786), (38, 0.08891748264431953), (16, 0.09559204056859016), (8, 0.11047931201756), (10, 0.11786552239209414), (12, 0.15159322135150433), (5, 0.20016907900571823), (36, 0.5066791474819183), (18, 0.520392082631588), (53, 1.6035817116498947)]
computing accuracy for after removing block 25 . block score: 0.0793931744992733
removed block 25 current accuracy 0.1926 loss from initial  0.7588
since last training loss: 0.7462 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 20, with score 0.088673. All blocks and scores: [(20, 0.08867285307496786), (38, 0.09049098566174507), (16, 0.09559204056859016), (8, 0.11047930363565683), (10, 0.11786552425473928), (12, 0.15159322507679462), (5, 0.20016907714307308), (18, 0.5203920751810074), (36, 0.5494526103138924), (53, 2.2989165484905243)]
computing accuracy for after removing block 20 . block score: 0.08867285307496786
removed block 20 current accuracy 0.2128 loss from initial  0.7386
training start
training epoch 0 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best True lr [0.1]
training epoch 1 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best False lr [0.1]
training epoch 2 val accuracy 0.8144 topk_dict {'top1': 0.8144} is_best False lr [0.1]
training epoch 3 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.1]
training epoch 4 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.1]
training epoch 5 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 6 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 7 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.1]
training epoch 8 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best True lr [0.1]
training epoch 9 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.1]
training epoch 10 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.923800)
finished training. finished 50 epochs. accuracy 0.9238 topk_dict {'top1': 0.9238}
