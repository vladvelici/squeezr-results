start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.01023258175700903), (34, 0.013294660951942205), (29, 0.013421116978861392), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.01999649195931852), (46, 0.020590225467458367), (25, 0.022078294539824128), (23, 0.02222871477715671), (41, 0.022336416179314256), (44, 0.023145999293774366), (40, 0.023749590385705233), (45, 0.023975495481863618), (21, 0.024941089563071728), (48, 0.024957706918939948), (22, 0.025151390815153718), (50, 0.025287174386903644), (24, 0.025880582397803664), (49, 0.02591664926148951), (42, 0.02623223210684955), (20, 0.026848892215639353), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129551947117), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077956080437), (37, 0.03791803075000644), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740277051926), (3, 0.05784992501139641), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464833632112), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.8053385391831398)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.0131192437838763), (29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019852687371894717), (46, 0.02030070568434894), (41, 0.021860275184735656), (25, 0.022078295703977346), (23, 0.022228715009987354), (44, 0.022977192886173725), (40, 0.02357383049093187), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.024770822608843446), (21, 0.024941089563071728), (22, 0.0251513896510005), (49, 0.02557574096135795), (24, 0.025880583096295595), (42, 0.025893412763252854), (20, 0.026848891749978065), (47, 0.028072760673239827), (38, 0.031091188080608845), (39, 0.031191360903903842), (15, 0.03205838659778237), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992966800928), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.06493351561948657), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143420040607), (36, 0.4339806139469147), (18, 0.5117432996630669), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850465236231685), (46, 0.020411916309967637), (41, 0.021827629068866372), (25, 0.022078294306993484), (23, 0.022228715242817998), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.02377084898762405), (48, 0.024519873317331076), (50, 0.024639350594952703), (21, 0.024941089563071728), (22, 0.025151390815153718), (49, 0.0253925493452698), (42, 0.025712220929563046), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.02805250440724194), (38, 0.030935873743146658), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.038343191146850586), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441722949966788), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.435020312666893), (18, 0.5117432847619057), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159728713334), (29, 0.013421117095276713), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019867350347340107), (46, 0.020279744639992714), (41, 0.021756020141765475), (25, 0.022078295703977346), (23, 0.022228715242817998), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016880877316), (48, 0.024350045481696725), (50, 0.02446310594677925), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.02524693007580936), (42, 0.02527355100028217), (24, 0.02588058216497302), (20, 0.026848892215639353), (47, 0.027727574110031128), (38, 0.030746274860575795), (39, 0.031281795585528016), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03895266819745302), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756202876568), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232014857233), (29, 0.01342111686244607), (35, 0.015968911815434694), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.020137188024818897), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569098440930247), (45, 0.023840720765292645), (48, 0.02410835982300341), (50, 0.02411420946009457), (49, 0.024870116962119937), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.025151390815153718), (24, 0.025880583794787526), (20, 0.026848891517147422), (47, 0.02742385142482817), (38, 0.030735649168491364), (39, 0.031410424038767815), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.039083510637283325), (51, 0.04034593794494867), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897723503410816), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525345310569), (52, 0.06270107766613364), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537981152534), (5, 0.10671143420040607), (36, 0.43692685663700104), (18, 0.5117432847619057), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232014857233
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.02030268427915871), (46, 0.02032419736497104), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02304507838562131), (48, 0.024024546379223466), (50, 0.02409697324037552), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922373006120324), (21, 0.02494108909741044), (22, 0.0251513896510005), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.027568295132368803), (38, 0.031787264393642545), (15, 0.03205838520079851), (39, 0.03225791407749057), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.04008621396496892), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.061325253918766975), (52, 0.06221094960346818), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537888020277), (5, 0.10671143978834152), (36, 0.44933702424168587), (18, 0.5117432996630669), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019856703700497746), (46, 0.019988975720480084), (41, 0.02125620492734015), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.02269203355535865), (48, 0.023521370952948928), (50, 0.023533890722319484), (40, 0.023616240825504065), (45, 0.02393329283222556), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.024941088864579797), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.026813456555828452), (20, 0.026848891517147422), (38, 0.03108373167924583), (39, 0.03205688903108239), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077769815922), (51, 0.039079748559743166), (37, 0.0401521441526711), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.059700032230466604), (52, 0.06036907434463501), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4432784393429756), (18, 0.5117432922124863), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144015721977), (28, 0.016986022237688303), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700075965374708), (41, 0.02051579882390797), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022507572313770652), (48, 0.022899368777871132), (50, 0.022937727626413107), (40, 0.023057402344420552), (42, 0.023520407965406775), (45, 0.023633699398487806), (49, 0.024081918643787503), (21, 0.02494108909741044), (22, 0.025151389883831143), (24, 0.025880583096295595), (47, 0.026322791818529367), (20, 0.02684889198280871), (38, 0.030149149941280484), (39, 0.03146669757552445), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.039268902968615294), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.057849927339702845), (52, 0.05846811877563596), (13, 0.05914428923279047), (11, 0.05970003269612789), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.43490004539489746), (18, 0.5117432922124863), (53, 0.8595061227679253)]
computing accuracy for after removing block 35 . block score: 0.015504144015721977
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381991190835834), (27, 0.018769708927720785), (46, 0.018842301797121763), (41, 0.019016370410099626), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.021748854545876384), (40, 0.021916967118158937), (42, 0.0219303744379431), (25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.02273644949309528), (49, 0.022970063611865044), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02535583171993494), (24, 0.025880583096295595), (20, 0.026848892215639353), (38, 0.028691887157037854), (39, 0.029624432092532516), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03601635713130236), (37, 0.03643036866560578), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.054577403236180544), (52, 0.05466857925057411), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.41641609370708466), (18, 0.5117432847619057), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987634986639023), (46, 0.01835862477310002), (41, 0.018467806978151202), (27, 0.018769708927720785), (48, 0.02077550906687975), (42, 0.02120647020637989), (50, 0.02130244835279882), (44, 0.021586895687505603), (40, 0.021592722507193685), (25, 0.02207829523831606), (23, 0.02222871594130993), (45, 0.022315293550491333), (49, 0.022407567128539085), (47, 0.024609396932646632), (21, 0.02494108909741044), (22, 0.025151390582323074), (24, 0.02588058332912624), (20, 0.02684889081865549), (38, 0.027890325523912907), (39, 0.029191895853728056), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03550667641684413), (37, 0.035919226706027985), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.04852241324260831), (52, 0.053374082781374454), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126182049512863), (18, 0.5117433071136475), (53, 0.906721331179142)]
computing accuracy for after removing block 43 . block score: 0.017987634986639023
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467807210981846), (27, 0.018769709393382072), (46, 0.01899468107149005), (42, 0.021206469973549247), (48, 0.021418895572423935), (50, 0.021441322285681963), (40, 0.02159272227436304), (25, 0.022078294772654772), (23, 0.022228715708479285), (49, 0.022339017363265157), (44, 0.022782833548262715), (45, 0.023323106346651912), (21, 0.024941089330241084), (22, 0.025151389418169856), (47, 0.02538607711903751), (24, 0.02588058216497302), (20, 0.026848891749978065), (38, 0.027890324592590332), (39, 0.029191894456744194), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540780026465654), (51, 0.03521771775558591), (37, 0.03591922763735056), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (52, 0.0521333715878427), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525531575084), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.9521221145987511)]
computing accuracy for after removing block 41 . block score: 0.018467807210981846
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 1 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 2 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 3 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.1]
training epoch 4 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 5 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.1]
training epoch 6 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 7 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 8 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.1]
training epoch 9 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 11
[activation diff]: block to remove picked: 45, with score 0.014022. All blocks and scores: [(45, 0.014021693845279515), (44, 0.015383037040010095), (42, 0.017824900802224874), (40, 0.019352877978235483), (46, 0.024973779683932662), (21, 0.025195028632879257), (38, 0.026352190179750323), (23, 0.027043659007176757), (50, 0.027053992729634047), (20, 0.027430775808170438), (49, 0.027743331622332335), (48, 0.0278849215246737), (39, 0.027891590492799878), (22, 0.028567428467795253), (24, 0.02890791743993759), (27, 0.029466084204614162), (25, 0.030642209807410836), (15, 0.032212874852120876), (7, 0.032637824304401875), (19, 0.032660111784935), (47, 0.03273128578439355), (37, 0.033356983214616776), (51, 0.04251033766195178), (9, 0.04416582500562072), (6, 0.0462613832205534), (14, 0.04773611016571522), (4, 0.04912700457498431), (2, 0.055108210537582636), (3, 0.05850438121706247), (11, 0.05949306022375822), (13, 0.059584285132586956), (17, 0.06240604119375348), (0, 0.06429524254053831), (1, 0.06666550505906343), (52, 0.06763098109513521), (8, 0.07463330309838057), (10, 0.08122376259416342), (16, 0.08611145615577698), (12, 0.09019715711474419), (5, 0.10611296258866787), (36, 0.4772009626030922), (18, 0.5140857696533203), (53, 0.8096413463354111)]
computing accuracy for after removing block 45 . block score: 0.014021693845279515
removed block 45 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 44, with score 0.015383. All blocks and scores: [(44, 0.015383037040010095), (42, 0.017824900802224874), (40, 0.01935287844389677), (21, 0.02519502816721797), (46, 0.025444459868595004), (38, 0.02635218924842775), (23, 0.027043658774346113), (49, 0.027253273408859968), (48, 0.027385477907955647), (50, 0.0274095069617033), (20, 0.027430776972323656), (39, 0.027891591424122453), (22, 0.02856742893345654), (24, 0.02890791743993759), (27, 0.02946608467027545), (25, 0.03064221004024148), (15, 0.032212875317782164), (7, 0.03263782383874059), (19, 0.032660112250596285), (37, 0.03335698368027806), (47, 0.03354328125715256), (51, 0.04241900285705924), (9, 0.04416582453995943), (6, 0.0462613832205534), (14, 0.04773610970005393), (4, 0.04912700457498431), (2, 0.055108210537582636), (3, 0.058504380751401186), (11, 0.059493061155080795), (13, 0.059584283735603094), (17, 0.062406040262430906), (0, 0.06429524160921574), (1, 0.06666550599038601), (52, 0.06709450110793114), (8, 0.07463330216705799), (10, 0.08122376073151827), (16, 0.08611145708709955), (12, 0.09019715338945389), (5, 0.1061129616573453), (36, 0.4772009663283825), (18, 0.5140857696533203), (53, 0.8715609759092331)]
computing accuracy for after removing block 44 . block score: 0.015383037040010095
removed block 44 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.017825. All blocks and scores: [(42, 0.017824901035055518), (40, 0.019352878211066127), (21, 0.025195028632879257), (49, 0.026180958608165383), (46, 0.026277326280251145), (38, 0.026352190179750323), (23, 0.027043659007176757), (48, 0.027314575854688883), (20, 0.02743077650666237), (50, 0.027657770784571767), (39, 0.027891590259969234), (22, 0.028567427536472678), (24, 0.028907917672768235), (27, 0.029466084903106093), (25, 0.030642210273072124), (15, 0.03221287438645959), (7, 0.03263782383874059), (19, 0.032660111784935), (37, 0.0333569822832942), (47, 0.035134433303028345), (51, 0.042685342486947775), (9, 0.04416582453995943), (6, 0.04626138275489211), (14, 0.04773611016571522), (4, 0.0491270050406456), (2, 0.0551082119345665), (3, 0.05850438168272376), (11, 0.05949306068941951), (13, 0.05958428652957082), (17, 0.062406040262430906), (0, 0.06429524254053831), (1, 0.06666550505906343), (52, 0.06726222205907106), (8, 0.07463330216705799), (10, 0.08122376352548599), (16, 0.0861114552244544), (12, 0.09019715804606676), (5, 0.10611295886337757), (36, 0.4772009663283825), (18, 0.5140857771039009), (53, 0.9381062760949135)]
computing accuracy for after removing block 42 . block score: 0.017824901035055518
removed block 42 current accuracy 0.9336 loss from initial  0.017800000000000038
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.019353. All blocks and scores: [(40, 0.019352878211066127), (21, 0.025195028632879257), (38, 0.026352189714089036), (49, 0.02685400960035622), (23, 0.027043659705668688), (20, 0.027430776739493012), (46, 0.02755833906121552), (39, 0.027891590492799878), (48, 0.02849791944026947), (22, 0.028567428700625896), (50, 0.02879255753941834), (24, 0.028907917207106948), (27, 0.02946608467027545), (25, 0.030642209108918905), (15, 0.03221287438645959), (7, 0.03263782477006316), (19, 0.03266011318191886), (37, 0.033356983214616776), (47, 0.03767269290983677), (51, 0.04343441594392061), (9, 0.04416582686826587), (6, 0.046261383686214685), (14, 0.04773611016571522), (4, 0.0491270050406456), (2, 0.055108212400227785), (3, 0.058504380751401186), (11, 0.05949306022375822), (13, 0.059584285132586956), (17, 0.062406038865447044), (0, 0.06429524067789316), (1, 0.06666550505906343), (52, 0.07124471198767424), (8, 0.07463330309838057), (10, 0.08122376352548599), (16, 0.08611145336180925), (12, 0.09019715711474419), (5, 0.106112957932055), (36, 0.4772009551525116), (18, 0.5140857696533203), (53, 0.9640031829476357)]
computing accuracy for after removing block 40 . block score: 0.019352878211066127
removed block 40 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 21, with score 0.025195. All blocks and scores: [(21, 0.02519502816721797), (38, 0.026352189481258392), (49, 0.026561648584902287), (23, 0.02704365854151547), (46, 0.027265782933682203), (20, 0.027430776739493012), (39, 0.027891590259969234), (50, 0.028009950881823897), (48, 0.02854627836495638), (22, 0.028567429864779115), (24, 0.028907916508615017), (27, 0.029466084437444806), (25, 0.030642209574580193), (15, 0.03221287438645959), (7, 0.03263782290741801), (19, 0.032660111784935), (37, 0.03335698274895549), (47, 0.03909776173532009), (51, 0.04331591073423624), (9, 0.04416582314297557), (6, 0.04626138415187597), (14, 0.04773611016571522), (4, 0.0491270050406456), (2, 0.05510821100324392), (3, 0.05850438307970762), (11, 0.05949306068941951), (13, 0.05958428326994181), (17, 0.06240603933110833), (0, 0.06429524533450603), (1, 0.06666550505906343), (52, 0.07187789026647806), (8, 0.07463330402970314), (10, 0.0812237598001957), (16, 0.08611145988106728), (12, 0.09019715711474419), (5, 0.10611296258866787), (36, 0.4772009626030922), (18, 0.5140857622027397), (53, 1.024397000670433)]
computing accuracy for after removing block 21 . block score: 0.02519502816721797
removed block 21 current accuracy 0.9234 loss from initial  0.028000000000000025
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.024604. All blocks and scores: [(23, 0.02460367837920785), (46, 0.025034507736563683), (38, 0.025106467539444566), (24, 0.02548464317806065), (49, 0.025652455165982246), (48, 0.02590745477937162), (50, 0.02607685374096036), (22, 0.026711682323366404), (39, 0.02678181603550911), (20, 0.0274307772051543), (27, 0.027979875449091196), (25, 0.028629928594455123), (37, 0.03193356841802597), (15, 0.032212875317782164), (7, 0.032637824304401875), (19, 0.032660112250596285), (47, 0.03658326808363199), (51, 0.041359610855579376), (9, 0.04416582686826587), (6, 0.04626138275489211), (14, 0.04773611016571522), (4, 0.04912700643762946), (2, 0.05510820960626006), (3, 0.0585043802857399), (11, 0.059493061155080795), (13, 0.05958428466692567), (17, 0.06240604119375348), (0, 0.06429524254053831), (52, 0.0648533208295703), (1, 0.06666550785303116), (8, 0.07463330402970314), (10, 0.08122376073151827), (16, 0.08611145708709955), (12, 0.09019715804606676), (5, 0.10611296445131302), (36, 0.4497433453798294), (18, 0.5140857771039009), (53, 1.0687014609575272)]
computing accuracy for after removing block 23 . block score: 0.02460367837920785
removed block 23 current accuracy 0.9146 loss from initial  0.036800000000000055
since last training loss: 0.03160000000000007 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 24, with score 0.024191. All blocks and scores: [(24, 0.024190737633034587), (46, 0.02518914476968348), (38, 0.025832170620560646), (49, 0.026342616183683276), (48, 0.026398332556709647), (22, 0.026711681624874473), (50, 0.02677624672651291), (27, 0.02727335668168962), (20, 0.02743077650666237), (39, 0.027816240675747395), (25, 0.028221426531672478), (15, 0.032212874852120876), (7, 0.03263782383874059), (19, 0.03266011131927371), (37, 0.03490841202437878), (47, 0.035871855448931456), (51, 0.04215454822406173), (9, 0.04416582500562072), (6, 0.046261383686214685), (14, 0.04773610923439264), (4, 0.04912700457498431), (2, 0.0551082119345665), (3, 0.058504379354417324), (11, 0.05949306208640337), (13, 0.05958428326994181), (17, 0.06240603979676962), (0, 0.06429524160921574), (52, 0.06623742915689945), (1, 0.06666550692170858), (8, 0.07463330216705799), (10, 0.08122376352548599), (16, 0.08611145429313183), (12, 0.09019715711474419), (5, 0.10611296351999044), (36, 0.4653465710580349), (18, 0.5140857771039009), (53, 1.0709591954946518)]
computing accuracy for after removing block 24 . block score: 0.024190737633034587
removed block 24 current accuracy 0.906 loss from initial  0.045399999999999996
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.023125. All blocks and scores: [(46, 0.023124803556129336), (50, 0.02454223856329918), (48, 0.024682377697899938), (49, 0.02497671893797815), (38, 0.025120909325778484), (39, 0.02658980176784098), (22, 0.026711679995059967), (25, 0.027351669035851955), (20, 0.02743077604100108), (27, 0.027721804566681385), (15, 0.032212874852120876), (7, 0.032637824304401875), (19, 0.032660112250596285), (47, 0.03328087134286761), (37, 0.03377510281279683), (51, 0.039960701018571854), (9, 0.04416582640260458), (6, 0.04626138275489211), (14, 0.04773611156269908), (4, 0.049127004109323025), (2, 0.055108212400227785), (3, 0.058504380751401186), (52, 0.05938731925562024), (11, 0.05949305836111307), (13, 0.05958428559824824), (17, 0.062406040262430906), (0, 0.06429524347186089), (1, 0.06666550599038601), (8, 0.07463330496102571), (10, 0.08122376073151827), (16, 0.08611145708709955), (12, 0.09019715618342161), (5, 0.1061129616573453), (36, 0.44852345809340477), (18, 0.5140857696533203), (53, 1.1136020123958588)]
computing accuracy for after removing block 46 . block score: 0.023124803556129336
removed block 46 current accuracy 0.887 loss from initial  0.06440000000000001
since last training loss: 0.05920000000000003 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 38, with score 0.025121. All blocks and scores: [(38, 0.025120910489931703), (50, 0.025375118479132652), (48, 0.02541245287284255), (49, 0.026116208638995886), (39, 0.0265898029319942), (22, 0.026711681624874473), (25, 0.027351670432835817), (20, 0.027430776739493012), (27, 0.02772180619649589), (15, 0.032212875317782164), (7, 0.0326378233730793), (19, 0.032660111784935), (37, 0.033775102347135544), (47, 0.03492684569209814), (51, 0.0404846235178411), (9, 0.044165825471282005), (6, 0.0462613832205534), (14, 0.04773611016571522), (4, 0.04912700317800045), (2, 0.0551082119345665), (3, 0.0585043802857399), (11, 0.05949306162074208), (13, 0.05958428466692567), (52, 0.05984281515702605), (17, 0.062406040262430906), (0, 0.06429524347186089), (1, 0.06666550692170858), (8, 0.07463330309838057), (10, 0.08122376166284084), (16, 0.08611145708709955), (12, 0.09019715525209904), (5, 0.10611296072602272), (36, 0.44852346181869507), (18, 0.5140857845544815), (53, 1.2369838058948517)]
computing accuracy for after removing block 38 . block score: 0.025120910489931703
removed block 38 current accuracy 0.8734 loss from initial  0.07800000000000007
since last training loss: 0.07280000000000009 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.024422. All blocks and scores: [(50, 0.02442227629944682), (48, 0.0246074500028044), (49, 0.025415044743567705), (22, 0.026711681857705116), (25, 0.027351670200005174), (20, 0.027430776972323656), (27, 0.02772180549800396), (39, 0.02883684285916388), (15, 0.032212874852120876), (7, 0.0326378233730793), (19, 0.032660111784935), (47, 0.033485000021755695), (37, 0.03377510281279683), (51, 0.03955573122948408), (9, 0.044165825471282005), (6, 0.046261382289230824), (14, 0.04773610923439264), (4, 0.04912700690329075), (2, 0.05510821286588907), (52, 0.05596293183043599), (3, 0.05850438121706247), (11, 0.05949306208640337), (13, 0.05958428559824824), (17, 0.06240603979676962), (0, 0.06429524440318346), (1, 0.06666550692170858), (8, 0.07463330309838057), (10, 0.08122376445680857), (16, 0.0861114589497447), (12, 0.09019715618342161), (5, 0.10611296631395817), (36, 0.4485234506428242), (18, 0.5140857771039009), (53, 1.3255501687526703)]
computing accuracy for after removing block 50 . block score: 0.02442227629944682
removed block 50 current accuracy 0.8526 loss from initial  0.0988
since last training loss: 0.09360000000000002 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.024607. All blocks and scores: [(48, 0.024607449071481824), (49, 0.025415044277906418), (22, 0.02671168139204383), (25, 0.027351670200005174), (20, 0.027430776739493012), (27, 0.02772180433385074), (39, 0.028836842626333237), (15, 0.032212874852120876), (7, 0.0326378233730793), (19, 0.03266011271625757), (47, 0.03348500048741698), (37, 0.03377510281279683), (51, 0.042992806527763605), (9, 0.04416582453995943), (6, 0.046261383686214685), (14, 0.047736108768731356), (4, 0.04912700550630689), (2, 0.05510821333155036), (3, 0.05850438121706247), (11, 0.05949306162074208), (13, 0.05958428466692567), (17, 0.06240604119375348), (0, 0.06429524440318346), (52, 0.06504616141319275), (1, 0.06666550505906343), (8, 0.07463330402970314), (10, 0.08122376352548599), (16, 0.08611145336180925), (12, 0.09019715804606676), (5, 0.10611296072602272), (36, 0.44852346554398537), (18, 0.5140857622027397), (53, 1.5367610156536102)]
computing accuracy for after removing block 48 . block score: 0.024607449071481824
removed block 48 current accuracy 0.8136 loss from initial  0.13780000000000003
training start
training epoch 0 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best True lr [0.1]
training epoch 1 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.1]
training epoch 2 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.1]
training epoch 3 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.1]
training epoch 4 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 5 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.1]
training epoch 6 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.1]
training epoch 7 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 8 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 9 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.031978. All blocks and scores: [(15, 0.03197760879993439), (7, 0.0325128142721951), (9, 0.04385413974523544), (6, 0.046792912762612104), (14, 0.04765037400647998), (4, 0.04800355667248368), (17, 0.050007847137749195), (20, 0.0527028813958168), (2, 0.054614356718957424), (49, 0.055320311803370714), (19, 0.05551520548760891), (3, 0.058094245847314596), (11, 0.05930376471951604), (13, 0.05950881168246269), (51, 0.06234861025586724), (0, 0.06354285776615143), (47, 0.06623329408466816), (1, 0.06640846282243729), (27, 0.0690161194652319), (8, 0.07401890307664871), (25, 0.07961009442806244), (22, 0.08061753585934639), (10, 0.08073394745588303), (39, 0.08432843536138535), (16, 0.08541299495846033), (37, 0.08741115126758814), (12, 0.09038390684872866), (52, 0.09500515926629305), (5, 0.10636501852422953), (36, 0.5688568353652954), (18, 0.6227900758385658), (53, 0.792083851993084)]
computing accuracy for after removing block 15 . block score: 0.03197760879993439
removed block 15 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032513. All blocks and scores: [(7, 0.03251281473785639), (9, 0.04385413974523544), (6, 0.046792914625257254), (14, 0.04765037354081869), (4, 0.048003556206822395), (20, 0.04984336579218507), (17, 0.05163818597793579), (49, 0.054163724184036255), (2, 0.054614356718957424), (19, 0.05606193235144019), (3, 0.05809424491599202), (11, 0.05930376471951604), (13, 0.05950881168246269), (51, 0.06273996038362384), (0, 0.06354285962879658), (27, 0.06577768549323082), (1, 0.06640846747905016), (47, 0.06720808707177639), (8, 0.07401890307664871), (22, 0.07561593968421221), (25, 0.07726519741117954), (10, 0.08073394652456045), (39, 0.08334261737763882), (37, 0.08745478838682175), (12, 0.09038390591740608), (52, 0.09385550674051046), (16, 0.0952890245243907), (5, 0.10636502224951982), (36, 0.5538651570677757), (18, 0.6048698276281357), (53, 0.7912540435791016)]
computing accuracy for after removing block 7 . block score: 0.03251281473785639
removed block 7 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 17, with score 0.043674. All blocks and scores: [(17, 0.04367370577529073), (9, 0.043775664176791906), (14, 0.04404378356412053), (6, 0.046792912762612104), (20, 0.04681825917214155), (4, 0.04800355760380626), (13, 0.051561951637268066), (49, 0.05288822064176202), (19, 0.054103365167975426), (2, 0.05461435578763485), (11, 0.05603858130052686), (3, 0.05809424538165331), (51, 0.059632373973727226), (27, 0.0628143330104649), (0, 0.06354285683482885), (1, 0.06640846561640501), (47, 0.06653235759586096), (8, 0.07191533967852592), (22, 0.07217419426888227), (25, 0.07488320115953684), (37, 0.08200265560299158), (39, 0.08270522579550743), (10, 0.08299052808433771), (12, 0.08438610006123781), (16, 0.0867629423737526), (52, 0.08802681136876345), (5, 0.1063650194555521), (36, 0.5376565605401993), (18, 0.5820018872618675), (53, 0.8075014874339104)]
computing accuracy for after removing block 17 . block score: 0.04367370577529073
removed block 17 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 9, with score 0.043776. All blocks and scores: [(9, 0.04377566324546933), (14, 0.044043784495443106), (20, 0.046766070649027824), (6, 0.04679291229695082), (4, 0.04800355527549982), (49, 0.04987902520224452), (13, 0.051561952102929354), (2, 0.05461435578763485), (11, 0.05603858083486557), (19, 0.056983194313943386), (51, 0.057191023137420416), (3, 0.05809424491599202), (27, 0.062423009891062975), (0, 0.06354285776615143), (47, 0.06558159552514553), (1, 0.06640846468508244), (22, 0.06957266200333834), (8, 0.07191534154117107), (25, 0.07302478514611721), (37, 0.07770856842398643), (39, 0.07967656012624502), (52, 0.08207330573350191), (10, 0.08299052715301514), (12, 0.08438609633594751), (16, 0.08676294330507517), (5, 0.10636502224951982), (36, 0.513621985912323), (18, 0.563785508275032), (53, 0.8177737817168236)]
computing accuracy for after removing block 9 . block score: 0.04377566324546933
removed block 9 current accuracy 0.9154 loss from initial  0.03600000000000003
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 14, with score 0.039970. All blocks and scores: [(14, 0.039969701785594225), (49, 0.046515997499227524), (6, 0.046792912762612104), (20, 0.04681169521063566), (4, 0.04800355667248368), (13, 0.04895279370248318), (11, 0.05180639075115323), (51, 0.05244912812486291), (2, 0.05461435765028), (3, 0.058094245847314596), (27, 0.06076030246913433), (19, 0.061374700628221035), (0, 0.06354285776615143), (22, 0.06461159512400627), (47, 0.06578252837061882), (1, 0.06640846468508244), (37, 0.06993632763624191), (25, 0.07032606285065413), (16, 0.07138883508741856), (8, 0.07191533967852592), (12, 0.07259435951709747), (52, 0.07306356355547905), (39, 0.07847939990460873), (10, 0.08138800784945488), (5, 0.10636502038687468), (36, 0.4824287034571171), (18, 0.5471679270267487), (53, 0.8252606391906738)]
computing accuracy for after removing block 14 . block score: 0.039969701785594225
removed block 14 current accuracy 0.899 loss from initial  0.0524
since last training loss: 0.044399999999999995 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.044039. All blocks and scores: [(20, 0.04403877630829811), (49, 0.04504365986213088), (6, 0.04679291322827339), (4, 0.048003556206822395), (13, 0.0489527927711606), (51, 0.051539172418415546), (11, 0.051806389819830656), (2, 0.05461435532197356), (27, 0.05790849355980754), (3, 0.05809424398466945), (22, 0.06165105616673827), (19, 0.06171769555658102), (0, 0.06354285683482885), (47, 0.06611926294863224), (1, 0.06640846468508244), (25, 0.06910605169832706), (52, 0.0693101305514574), (37, 0.06990975327789783), (8, 0.07191533874720335), (12, 0.07259435951709747), (39, 0.07750704512000084), (10, 0.081388003192842), (16, 0.09397488180547953), (5, 0.1063650194555521), (36, 0.4737568572163582), (18, 0.5452998578548431), (53, 0.8233765438199043)]
computing accuracy for after removing block 20 . block score: 0.04403877630829811
removed block 20 current accuracy 0.8918 loss from initial  0.059599999999999986
since last training loss: 0.05159999999999998 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 49, with score 0.043447. All blocks and scores: [(49, 0.04344651196151972), (6, 0.04679291369393468), (4, 0.04800355667248368), (51, 0.04852473409846425), (13, 0.048952792305499315), (11, 0.05180639028549194), (27, 0.05444023106247187), (2, 0.05461435718461871), (3, 0.058094246312975883), (22, 0.06059006508439779), (52, 0.060772256925702095), (19, 0.06171769695356488), (47, 0.06276815291494131), (0, 0.063542858697474), (25, 0.06531949806958437), (1, 0.06640846468508244), (37, 0.0693896608427167), (8, 0.07191533781588078), (12, 0.07259435951709747), (39, 0.0750176701694727), (10, 0.08138800412416458), (16, 0.09397488459944725), (5, 0.1063650194555521), (36, 0.45409753173589706), (18, 0.5452998578548431), (53, 0.840448409318924)]
computing accuracy for after removing block 49 . block score: 0.04344651196151972
removed block 49 current accuracy 0.8754 loss from initial  0.07600000000000007
since last training loss: 0.06800000000000006 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 6, with score 0.046793. All blocks and scores: [(6, 0.04679291322827339), (4, 0.04800355527549982), (13, 0.04895279323682189), (51, 0.04939643293619156), (11, 0.05180639028549194), (27, 0.05444023199379444), (2, 0.05461435578763485), (3, 0.05809424538165331), (22, 0.06059006555005908), (19, 0.06171769788488746), (47, 0.0627681533806026), (0, 0.06354285776615143), (52, 0.06402726145461202), (25, 0.06531949434429407), (1, 0.06640846282243729), (37, 0.06938966177403927), (8, 0.07191533502191305), (12, 0.07259436044842005), (39, 0.0750176701694727), (10, 0.08138800598680973), (16, 0.0939748827368021), (5, 0.10636502131819725), (36, 0.45409753546118736), (18, 0.5452998578548431), (53, 0.9819632098078728)]
computing accuracy for after removing block 6 . block score: 0.04679291322827339
removed block 6 current accuracy 0.8386 loss from initial  0.11280000000000001
since last training loss: 0.1048 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 13, with score 0.046122. All blocks and scores: [(13, 0.04612237913534045), (51, 0.046712093986570835), (11, 0.04737560637295246), (4, 0.04800355527549982), (27, 0.050369310192763805), (2, 0.054614354856312275), (52, 0.057225740514695644), (22, 0.05770395416766405), (3, 0.05809424817562103), (47, 0.0624899547547102), (25, 0.06308097625151277), (0, 0.06354285776615143), (19, 0.0641791308298707), (1, 0.06640846282243729), (12, 0.06763770803809166), (37, 0.06780452001839876), (8, 0.07092680037021637), (39, 0.07269146014004946), (16, 0.07742181234061718), (10, 0.08501136675477028), (5, 0.10636501666158438), (36, 0.44456635043025017), (18, 0.537331111729145), (53, 0.9907362759113312)]
computing accuracy for after removing block 13 . block score: 0.04612237913534045
removed block 13 current accuracy 0.77 loss from initial  0.1814
since last training loss: 0.1734 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.044905. All blocks and scores: [(51, 0.04490463761612773), (11, 0.04737560637295246), (4, 0.04800355667248368), (27, 0.04832630045711994), (52, 0.0499897301197052), (22, 0.053282064851373434), (2, 0.05461435532197356), (3, 0.058094244450330734), (47, 0.06056830706074834), (25, 0.06305932207033038), (0, 0.06354285776615143), (1, 0.06640846468508244), (12, 0.06763770896941423), (37, 0.06795349717140198), (39, 0.06895523797720671), (8, 0.07092679850757122), (19, 0.07236812449991703), (10, 0.08501136396080256), (16, 0.09359049797058105), (5, 0.10636502038687468), (36, 0.42980558425188065), (18, 0.5519508123397827), (53, 0.9863809794187546)]
computing accuracy for after removing block 51 . block score: 0.04490463761612773
removed block 51 current accuracy 0.6736 loss from initial  0.27780000000000005
since last training loss: 0.26980000000000004 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 11, with score 0.047376. All blocks and scores: [(11, 0.04737560451030731), (4, 0.04800355853512883), (27, 0.048326301388442516), (52, 0.052586701698601246), (22, 0.05328206531703472), (2, 0.05461435625329614), (3, 0.05809424491599202), (47, 0.06056830706074834), (25, 0.06305932020768523), (0, 0.06354285962879658), (1, 0.06640846468508244), (12, 0.06763770896941423), (37, 0.06795349810272455), (39, 0.06895523797720671), (8, 0.0709268031641841), (19, 0.07236812356859446), (10, 0.08501136396080256), (16, 0.09359049703925848), (5, 0.10636502131819725), (36, 0.42980558425188065), (18, 0.5519507825374603), (53, 1.2024161517620087)]
computing accuracy for after removing block 11 . block score: 0.04737560451030731
removed block 11 current accuracy 0.6238 loss from initial  0.3276
training start
training epoch 0 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 1 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 2 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 3 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 4 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.1]
training epoch 5 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 6 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 7 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 8 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 9 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 13 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
start iteration 33
[activation diff]: block to remove picked: 19, with score 0.059950. All blocks and scores: [(19, 0.05994964251294732), (4, 0.06270430888980627), (0, 0.063714899122715), (25, 0.0655233645811677), (1, 0.0659622447565198), (27, 0.0686731357127428), (22, 0.06996898725628853), (2, 0.08617036044597626), (47, 0.09332549013197422), (52, 0.09736694488674402), (37, 0.10009856522083282), (39, 0.10357275139540434), (3, 0.1087898276746273), (8, 0.17727453261613846), (10, 0.18593078665435314), (12, 0.23196393623948097), (5, 0.24905058182775974), (16, 0.27777033671736717), (18, 0.482851043343544), (36, 0.6051443293690681), (53, 1.2086326777935028)]
computing accuracy for after removing block 19 . block score: 0.05994964251294732
removed block 19 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.062704. All blocks and scores: [(4, 0.06270430702716112), (25, 0.06289968360215425), (0, 0.06371489819139242), (27, 0.06581054348498583), (1, 0.06596224661916494), (22, 0.0726911723613739), (2, 0.08617036044597626), (47, 0.08972487226128578), (52, 0.09205700270831585), (39, 0.1030298350378871), (37, 0.10705675277858973), (3, 0.10878983046859503), (8, 0.17727453261613846), (10, 0.18593077920377254), (12, 0.23196395486593246), (5, 0.24905058182775974), (16, 0.2777703255414963), (18, 0.4828510582447052), (36, 0.6001017615199089), (53, 1.1727966517210007)]
computing accuracy for after removing block 4 . block score: 0.06270430702716112
removed block 4 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 25, with score 0.061637. All blocks and scores: [(25, 0.06163722462952137), (0, 0.063714899122715), (27, 0.06461819354444742), (1, 0.06596224661916494), (22, 0.06969337910413742), (2, 0.08617036044597626), (47, 0.08776517305523157), (52, 0.08813185803592205), (39, 0.1010076180100441), (37, 0.10510270204395056), (3, 0.108789823949337), (10, 0.1772550493478775), (8, 0.17897138744592667), (12, 0.21520819328725338), (16, 0.2575136236846447), (5, 0.2658456414937973), (18, 0.4756440408527851), (36, 0.5878585055470467), (53, 1.132126361131668)]
computing accuracy for after removing block 25 . block score: 0.06163722462952137
removed block 25 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.036799999999999944 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.063715. All blocks and scores: [(0, 0.06371490005403757), (1, 0.06596224568784237), (27, 0.06816751230508089), (22, 0.06969337910413742), (52, 0.0795462941750884), (47, 0.08055245596915483), (2, 0.08617036137729883), (39, 0.10300721228122711), (3, 0.10878982674330473), (37, 0.1253916211426258), (10, 0.1772550530731678), (8, 0.17897138744592667), (12, 0.21520819328725338), (16, 0.2575136199593544), (5, 0.2658456526696682), (18, 0.4756440557539463), (36, 0.6280681267380714), (53, 1.1174827069044113)]
computing accuracy for after removing block 0 . block score: 0.06371490005403757
removed block 0 current accuracy 0.8808 loss from initial  0.0706
since last training loss: 0.06019999999999992 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 27, with score 0.064462. All blocks and scores: [(27, 0.06446168199181557), (22, 0.06748584657907486), (1, 0.06822016648948193), (52, 0.07767637632787228), (47, 0.08047788962721825), (2, 0.09275441151112318), (3, 0.09369628876447678), (39, 0.10074848681688309), (37, 0.1239841328933835), (10, 0.16681954450905323), (8, 0.16692632250487804), (12, 0.21691136807203293), (16, 0.2376719806343317), (5, 0.2649715691804886), (18, 0.4718448966741562), (36, 0.6136357635259628), (53, 1.1163008362054825)]
computing accuracy for after removing block 27 . block score: 0.06446168199181557
removed block 27 current accuracy 0.8212 loss from initial  0.13019999999999998
since last training loss: 0.1197999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 22, with score 0.067486. All blocks and scores: [(22, 0.06748584751039743), (1, 0.06822016555815935), (52, 0.06908273976296186), (47, 0.07416921854019165), (2, 0.09275441244244576), (3, 0.09369628969579935), (39, 0.10117469821125269), (37, 0.13782725669443607), (10, 0.16681954264640808), (8, 0.1669263169169426), (12, 0.21691136062145233), (16, 0.23767197877168655), (5, 0.2649715580046177), (18, 0.4718449003994465), (36, 0.6170694008469582), (53, 1.0686582922935486)]
computing accuracy for after removing block 22 . block score: 0.06748584751039743
removed block 22 current accuracy 0.7238 loss from initial  0.22760000000000002
since last training loss: 0.21719999999999995 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 52, with score 0.064840. All blocks and scores: [(52, 0.06484020501375198), (1, 0.0682201674208045), (47, 0.07173181977123022), (2, 0.09275441244244576), (3, 0.09369628876447678), (39, 0.10575331188738346), (10, 0.16681955195963383), (8, 0.1669263169169426), (37, 0.16704493947327137), (12, 0.21691137552261353), (16, 0.2376719731837511), (5, 0.2649715654551983), (18, 0.4718449003994465), (36, 0.6667231172323227), (53, 0.9765383154153824)]
computing accuracy for after removing block 52 . block score: 0.06484020501375198
removed block 52 current accuracy 0.6264 loss from initial  0.32500000000000007
since last training loss: 0.3146 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 1, with score 0.068220. All blocks and scores: [(1, 0.06822016462683678), (47, 0.07173181977123022), (2, 0.09275441616773605), (3, 0.09369628503918648), (39, 0.10575331002473831), (10, 0.16681955009698868), (8, 0.16692631505429745), (37, 0.16704493574798107), (12, 0.21691135875880718), (16, 0.2376719769090414), (5, 0.2649715654551983), (18, 0.4718449115753174), (36, 0.6667231172323227), (53, 1.0130625218153)]
computing accuracy for after removing block 1 . block score: 0.06822016462683678
removed block 1 current accuracy 0.4722 loss from initial  0.4792
since last training loss: 0.46879999999999994 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 47, with score 0.071809. All blocks and scores: [(47, 0.07180890999734402), (3, 0.08692954946309328), (2, 0.09722793940454721), (39, 0.10174423735588789), (8, 0.14444884657859802), (10, 0.15240537375211716), (37, 0.167203014716506), (12, 0.1995078455656767), (16, 0.20303049311041832), (5, 0.24769113771617413), (18, 0.44761596992611885), (36, 0.6725821942090988), (53, 1.0426259338855743)]
computing accuracy for after removing block 47 . block score: 0.07180890999734402
removed block 47 current accuracy 0.3512 loss from initial  0.6002000000000001
since last training loss: 0.5897999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 3, with score 0.086930. All blocks and scores: [(3, 0.08692955132573843), (2, 0.09722794033586979), (39, 0.10174423921853304), (8, 0.14444884471595287), (10, 0.15240537747740746), (37, 0.167203014716506), (12, 0.19950785674154758), (16, 0.20303048938512802), (5, 0.24769114702939987), (18, 0.44761595875024796), (36, 0.6725822165608406), (53, 1.503342017531395)]
computing accuracy for after removing block 3 . block score: 0.08692955132573843
removed block 3 current accuracy 0.2604 loss from initial  0.6910000000000001
since last training loss: 0.6805999999999999 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 39, with score 0.091427. All blocks and scores: [(39, 0.09142688475549221), (2, 0.09722793940454721), (8, 0.13930076733231544), (10, 0.14131382666528225), (37, 0.15507613494992256), (16, 0.1621394082903862), (12, 0.1810851562768221), (5, 0.27129146084189415), (18, 0.41045448929071426), (36, 0.6314617767930031), (53, 1.52364020049572)]
computing accuracy for after removing block 39 . block score: 0.09142688475549221
removed block 39 current accuracy 0.2344 loss from initial  0.7170000000000001
since last training loss: 0.7065999999999999 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 2, with score 0.097228. All blocks and scores: [(2, 0.09722793847322464), (8, 0.13930077105760574), (10, 0.1413138248026371), (37, 0.1550761368125677), (16, 0.16213941015303135), (12, 0.18108515441417694), (5, 0.27129146456718445), (18, 0.41045447811484337), (36, 0.6314617767930031), (53, 2.038723811507225)]
computing accuracy for after removing block 2 . block score: 0.09722793847322464
removed block 2 current accuracy 0.1966 loss from initial  0.7548
training start
training epoch 0 val accuracy 0.805 topk_dict {'top1': 0.805} is_best True lr [0.1]
training epoch 1 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.1]
training epoch 2 val accuracy 0.812 topk_dict {'top1': 0.812} is_best False lr [0.1]
training epoch 3 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.1]
training epoch 4 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.1]
training epoch 5 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best True lr [0.1]
training epoch 7 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 8 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 9 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 10 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.921000)
finished training. finished 50 epochs. accuracy 0.921 topk_dict {'top1': 0.921}
