start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.015957689844071865), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.01999649149365723), (46, 0.02059022570028901), (25, 0.02207829523831606), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749590618535876), (45, 0.023975495947524905), (21, 0.02494108979590237), (48, 0.02495770645327866), (22, 0.025151390582323074), (50, 0.025287174619734287), (24, 0.02588058286346495), (49, 0.025916648330166936), (42, 0.02623223257251084), (20, 0.026848891749978065), (47, 0.028632949339225888), (38, 0.03134434390813112), (39, 0.03144129575230181), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03791803168132901), (51, 0.04178758803755045), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104411184788), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013119243551045656), (29, 0.013421116163954139), (26, 0.016072141705080867), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.01985268690623343), (46, 0.020300705218687654), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02297719311900437), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.02454021666198969), (50, 0.024770823074504733), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.02588058216497302), (42, 0.025893412763252854), (20, 0.02684889198280871), (47, 0.02807276090607047), (38, 0.031091188546270132), (39, 0.031191361136734486), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03797321021556854), (51, 0.04127101367339492), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06493351934477687), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4339805990457535), (18, 0.5117432996630669), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.01023258175700903), (34, 0.012758882134221494), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022891478845849633), (40, 0.02360257995314896), (45, 0.023770849918946624), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.024941090494394302), (22, 0.025151390116661787), (49, 0.0253925493452698), (42, 0.025712220696732402), (24, 0.025880582630634308), (20, 0.02684889268130064), (47, 0.02805250510573387), (38, 0.030935873510316014), (39, 0.031173036666586995), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.06132525345310569), (0, 0.06337464740499854), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824108667672), (34, 0.012400159845128655), (29, 0.013421116978861392), (35, 0.015918649500235915), (26, 0.01607214054092765), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01986735058017075), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.02222871594130993), (44, 0.023001375840976834), (40, 0.023739925818517804), (45, 0.02379016764461994), (48, 0.024350045481696725), (50, 0.024463106179609895), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025246929842978716), (42, 0.025273550767451525), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.02772757550701499), (38, 0.030746274394914508), (39, 0.031281795585528016), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.038952667731791735), (51, 0.040824799332767725), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464693933725), (52, 0.06356756389141083), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693124115467), (18, 0.5117433071136475), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824108667672
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.013421116163954139), (35, 0.01596891228109598), (26, 0.016072141705080867), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.020137187326326966), (41, 0.0215840560849756), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022687325486913323), (40, 0.023569098440930247), (45, 0.023840720765292645), (48, 0.02410835842601955), (50, 0.024114209227263927), (49, 0.024870117427781224), (21, 0.02494108909741044), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.02742385189048946), (38, 0.030735649401322007), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034594027325511), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525485008955), (52, 0.06270107673481107), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43692685291171074), (18, 0.5117432922124863), (53, 0.8283701613545418)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141705080867), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.020302684046328068), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.023045078152790666), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.024156817002221942), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.02494108979590237), (22, 0.025151390116661787), (42, 0.02581606013700366), (24, 0.02588058216497302), (20, 0.026848890585824847), (47, 0.027568295132368803), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.040690732188522816), (9, 0.043376325629651546), (6, 0.046823694836348295), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.06132525438442826), (52, 0.06221094913780689), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.44933702424168587), (18, 0.5117432922124863), (53, 0.8277030512690544)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511380955577), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019856703467667103), (46, 0.019988976884633303), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022692032856866717), (48, 0.023521371884271502), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.023933293065056205), (49, 0.024449915625154972), (42, 0.024838327197358012), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026813455624505877), (20, 0.026848891051486135), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974995672703), (37, 0.0401521441526711), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003176480532), (52, 0.06036907434463501), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4432784505188465), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.016986021772027016), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700076198205352), (41, 0.020515799056738615), (25, 0.022078294772654772), (23, 0.022228716174140573), (44, 0.022507572546601295), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.023057401413097978), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.024081919342279434), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880583794787526), (47, 0.026322792284190655), (20, 0.02684889198280871), (38, 0.030149149242788553), (39, 0.03146669687703252), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03785192780196667), (37, 0.039268902968615294), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992873668671), (52, 0.05846812017261982), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.43490003794431686), (18, 0.5117433071136475), (53, 0.8595060706138611)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381991190835834), (27, 0.018769708927720785), (46, 0.018842302029952407), (41, 0.01901637064293027), (48, 0.021309158066287637), (50, 0.021624521585181355), (44, 0.021748854545876384), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.02207829523831606), (23, 0.02222871547564864), (45, 0.022736448794603348), (49, 0.022970063611865044), (21, 0.024941088864579797), (22, 0.025151390815153718), (47, 0.025355831952765584), (24, 0.025880582630634308), (20, 0.026848891749978065), (38, 0.028691887157037854), (39, 0.029624432092532516), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03601635713130236), (37, 0.036430368199944496), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (52, 0.054668578784912825), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.41641608625650406), (18, 0.5117432922124863), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.018358625005930662), (41, 0.018467807210981846), (27, 0.01876970869489014), (48, 0.020775508135557175), (42, 0.02120647020637989), (50, 0.021302447887137532), (44, 0.02158689615316689), (40, 0.021592722740024328), (25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.022315292851999402), (49, 0.022407566430047154), (47, 0.024609397863969207), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.025880583561956882), (20, 0.026848891517147422), (38, 0.02789032575674355), (39, 0.02919189492240548), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03550667641684413), (37, 0.03591922763735056), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241277694702), (52, 0.053374080918729305), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4126182049512863), (18, 0.5117433071136475), (53, 0.9067213088274002)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708927720785), (46, 0.01899468107149005), (42, 0.021206469740718603), (48, 0.02141889580525458), (50, 0.021441322285681963), (40, 0.02159272227436304), (25, 0.022078295005485415), (23, 0.022228715708479285), (49, 0.0223390175960958), (44, 0.022782832849770784), (45, 0.023323106579482555), (21, 0.02494108979590237), (22, 0.025151389883831143), (47, 0.025386077584698796), (24, 0.025880582397803664), (20, 0.02684889198280871), (38, 0.02789032575674355), (39, 0.029191895853728056), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.035217716824263334), (37, 0.0359192262403667), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522412311285734), (52, 0.05213337251916528), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361857950687), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.412618201225996), (18, 0.5117432922124863), (53, 0.9521221071481705)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 1 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 2 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 3 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 4 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 5 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.1]
training epoch 6 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 7 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 8 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 9 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.011892. All blocks and scores: [(46, 0.011891501490026712), (45, 0.015077052870765328), (44, 0.016260208562016487), (42, 0.020505970576778054), (40, 0.020613024476915598), (21, 0.025083667365834117), (22, 0.025353909004479647), (38, 0.027227218728512526), (23, 0.027351276949048042), (20, 0.02736808336339891), (50, 0.02759032160975039), (49, 0.028176696272566915), (24, 0.028596265241503716), (48, 0.02860510442405939), (39, 0.028839352075010538), (25, 0.03061742801219225), (27, 0.031236677896231413), (15, 0.03205894539132714), (7, 0.03240311844274402), (19, 0.03273599408566952), (47, 0.03325876500457525), (37, 0.03774499148130417), (51, 0.0436685117892921), (9, 0.0438760444521904), (6, 0.046583487186580896), (4, 0.04774952866137028), (14, 0.047820787876844406), (2, 0.05487355124205351), (3, 0.05736021790653467), (11, 0.05946161225438118), (13, 0.05948922410607338), (17, 0.06188945984467864), (0, 0.06335367728024721), (1, 0.06620592437684536), (52, 0.06914693117141724), (8, 0.0742899477481842), (10, 0.08088330551981926), (16, 0.08491486497223377), (12, 0.0902046887204051), (5, 0.10629780124872923), (36, 0.48775364831089973), (18, 0.5127412304282188), (53, 0.8003146797418594)]
computing accuracy for after removing block 46 . block score: 0.011891501490026712
removed block 46 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 45, with score 0.015077. All blocks and scores: [(45, 0.015077052870765328), (44, 0.016260209027677774), (42, 0.02050597034394741), (40, 0.020613024244084954), (21, 0.025083667133003473), (22, 0.02535390923731029), (38, 0.027227218728512526), (23, 0.027351277647539973), (20, 0.02736808406189084), (24, 0.028596264775842428), (50, 0.02866079448722303), (48, 0.028751950711011887), (39, 0.02883935160934925), (49, 0.029287138022482395), (25, 0.03061742871068418), (27, 0.03123667766340077), (15, 0.03205894632264972), (7, 0.032403118908405304), (19, 0.032735994551330805), (47, 0.035476052202284336), (37, 0.03774499008432031), (9, 0.04387604584917426), (51, 0.04445838509127498), (6, 0.04658348672091961), (4, 0.04774952819570899), (14, 0.04782078834250569), (2, 0.05487355263903737), (3, 0.057360218837857246), (11, 0.05946161365136504), (13, 0.059489225037395954), (17, 0.0618894612416625), (0, 0.06335367634892464), (1, 0.06620592251420021), (52, 0.0713443923741579), (8, 0.0742899477481842), (10, 0.08088330738246441), (16, 0.08491486310958862), (12, 0.09020468685775995), (5, 0.10629779752343893), (36, 0.48775365948677063), (18, 0.5127412527799606), (53, 0.8292364403605461)]
computing accuracy for after removing block 45 . block score: 0.015077052870765328
removed block 45 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.016260. All blocks and scores: [(44, 0.01626020879484713), (42, 0.020505970576778054), (40, 0.020613024476915598), (21, 0.025083667133003473), (22, 0.025353909470140934), (38, 0.027227218262851238), (23, 0.0273512767162174), (20, 0.027368083596229553), (24, 0.028596265939995646), (39, 0.028839351143687963), (48, 0.02939868299290538), (50, 0.02941999491304159), (49, 0.029686589958146214), (25, 0.030617430107668042), (27, 0.03123667766340077), (15, 0.03205894539132714), (7, 0.032403118908405304), (19, 0.03273599408566952), (47, 0.03667677566409111), (37, 0.037744991946965456), (51, 0.04354214994236827), (9, 0.04387604398652911), (6, 0.046583485789597034), (4, 0.047749527264386415), (14, 0.04782078880816698), (2, 0.054873551707714796), (3, 0.05736021837219596), (11, 0.05946161411702633), (13, 0.05948922550305724), (17, 0.061889460776001215), (0, 0.06335367728024721), (1, 0.06620592344552279), (52, 0.07053154427558184), (8, 0.07428994588553905), (10, 0.08088330551981926), (16, 0.08491486590355635), (12, 0.09020468592643738), (5, 0.10629779752343893), (36, 0.48775364831089973), (18, 0.5127412304282188), (53, 0.8853461742401123)]
computing accuracy for after removing block 44 . block score: 0.01626020879484713
removed block 44 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.020506. All blocks and scores: [(42, 0.020505969878286123), (40, 0.020613024476915598), (21, 0.02508366829715669), (22, 0.025353908771649003), (38, 0.027227219194173813), (23, 0.02735127741470933), (20, 0.027368083829060197), (24, 0.028596265241503716), (49, 0.02881405083462596), (39, 0.028839351376518607), (48, 0.028958770679309964), (50, 0.02970547042787075), (25, 0.030617429176345468), (27, 0.031236677197739482), (15, 0.03205894585698843), (7, 0.032403118908405304), (19, 0.032735994551330805), (37, 0.037744990549981594), (47, 0.0380388293415308), (51, 0.04325690632686019), (9, 0.04387604398652911), (6, 0.046583487186580896), (4, 0.047749527264386415), (14, 0.04782079020515084), (2, 0.054873551707714796), (3, 0.0573602169752121), (11, 0.05946161365136504), (13, 0.05948922550305724), (17, 0.0618894612416625), (0, 0.06335367914289236), (1, 0.06620592530816793), (52, 0.06987137626856565), (8, 0.0742899477481842), (10, 0.08088330738246441), (16, 0.08491486497223377), (12, 0.09020468685775995), (5, 0.1062977984547615), (36, 0.48775365948677063), (18, 0.5127412378787994), (53, 0.9419286921620369)]
computing accuracy for after removing block 42 . block score: 0.020505969878286123
removed block 42 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.020613. All blocks and scores: [(40, 0.020613023545593023), (21, 0.025083668064326048), (22, 0.025353908771649003), (38, 0.027227219194173813), (23, 0.027351277880370617), (20, 0.02736808336339891), (24, 0.028596265939995646), (39, 0.028839351842179894), (49, 0.029860059963539243), (25, 0.030617429176345468), (48, 0.0311188951600343), (27, 0.031236677197739482), (50, 0.031504621962085366), (15, 0.03205894585698843), (7, 0.03240311937406659), (19, 0.03273599362000823), (37, 0.037744990549981594), (47, 0.04209274146705866), (51, 0.0438013281673193), (9, 0.043876045383512974), (6, 0.04658348485827446), (4, 0.047749527264386415), (14, 0.04782079020515084), (2, 0.054873548448085785), (3, 0.05736021790653467), (11, 0.059461613185703754), (13, 0.059489225037395954), (17, 0.06188946217298508), (0, 0.06335367728024721), (1, 0.06620592437684536), (52, 0.0738049503415823), (8, 0.0742899440228939), (10, 0.08088330738246441), (16, 0.08491486217826605), (12, 0.0902046887204051), (5, 0.10629780031740665), (36, 0.48775364831089973), (18, 0.5127412229776382), (53, 0.9626555368304253)]
computing accuracy for after removing block 40 . block score: 0.020613023545593023
removed block 40 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.025084. All blocks and scores: [(21, 0.02508366759866476), (22, 0.025353909702971578), (38, 0.027227219194173813), (23, 0.027351277647539973), (20, 0.027368082897737622), (24, 0.028596265707165003), (39, 0.028839351842179894), (49, 0.030298630008473992), (25, 0.03061742871068418), (27, 0.031236677896231413), (48, 0.03153294092044234), (50, 0.03155485657043755), (15, 0.032058944925665855), (7, 0.03240311844274402), (19, 0.032735994551330805), (37, 0.03774499148130417), (47, 0.04315115977078676), (9, 0.04387604584917426), (51, 0.04455407476052642), (6, 0.046583487186580896), (4, 0.0477495277300477), (14, 0.04782078834250569), (2, 0.05487355263903737), (3, 0.057360215578228235), (11, 0.05946161365136504), (13, 0.05948922270908952), (17, 0.06188946217298508), (0, 0.06335367821156979), (1, 0.06620592437684536), (8, 0.07428994495421648), (52, 0.0743594253435731), (10, 0.08088330924510956), (16, 0.08491486217826605), (12, 0.09020468592643738), (5, 0.10629779659211636), (36, 0.48775364458560944), (18, 0.5127412378787994), (53, 1.0461716055870056)]
computing accuracy for after removing block 21 . block score: 0.02508366759866476
removed block 21 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.023601. All blocks and scores: [(22, 0.023601411608979106), (24, 0.024820680962875485), (23, 0.02496615331619978), (38, 0.02578295604325831), (39, 0.02728949557058513), (20, 0.02736808266490698), (48, 0.028025942156091332), (25, 0.02844248036853969), (50, 0.028743754606693983), (49, 0.029134598094969988), (27, 0.030032212613150477), (15, 0.032058944925665855), (7, 0.03240311844274402), (19, 0.03273599408566952), (37, 0.035289281979203224), (47, 0.040428850799798965), (51, 0.04235154064372182), (9, 0.043876044917851686), (6, 0.04658348625525832), (4, 0.04774952866137028), (14, 0.04782078927382827), (2, 0.05487355217337608), (3, 0.05736021790653467), (11, 0.059461613185703754), (13, 0.059489225037395954), (17, 0.06188946170732379), (0, 0.06335367634892464), (52, 0.06592688988894224), (1, 0.06620592530816793), (8, 0.07428994681686163), (10, 0.08088330831378698), (16, 0.0849148640409112), (12, 0.0902046887204051), (5, 0.10629780031740665), (36, 0.45392370969057083), (18, 0.5127412304282188), (53, 1.1059470474720001)]
computing accuracy for after removing block 22 . block score: 0.023601411608979106
removed block 22 current accuracy 0.904 loss from initial  0.0474
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.022176. All blocks and scores: [(24, 0.022176138823851943), (23, 0.022967826342210174), (38, 0.024905697209760547), (48, 0.025827116798609495), (39, 0.02630448737181723), (50, 0.026469381293281913), (25, 0.0267766616307199), (20, 0.027368083596229553), (49, 0.027871739817783237), (27, 0.0287339820060879), (15, 0.03205894585698843), (7, 0.03240311844274402), (19, 0.03273599362000823), (37, 0.035258287098258734), (47, 0.03742146771401167), (51, 0.04046582244336605), (9, 0.04387604258954525), (6, 0.046583485789597034), (4, 0.047749527264386415), (14, 0.047820789739489555), (2, 0.05487355217337608), (3, 0.05736021604388952), (11, 0.059461614582687616), (13, 0.05948922410607338), (52, 0.060033338610082865), (17, 0.0618894612416625), (0, 0.06335368007421494), (1, 0.06620592344552279), (8, 0.07428994867950678), (10, 0.08088330738246441), (16, 0.08491486590355635), (12, 0.09020468965172768), (5, 0.10629780124872923), (36, 0.4387088865041733), (18, 0.51274124532938), (53, 1.1396494358778)]
computing accuracy for after removing block 24 . block score: 0.022176138823851943
removed block 24 current accuracy 0.8932 loss from initial  0.05820000000000003
since last training loss: 0.05300000000000005 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.022968. All blocks and scores: [(23, 0.02296782610937953), (38, 0.023849599063396454), (48, 0.024143991293385625), (50, 0.024566746084019542), (25, 0.025490268133580685), (39, 0.0257854035589844), (49, 0.026647938648238778), (20, 0.027368084294721484), (27, 0.028571531176567078), (15, 0.03205894585698843), (7, 0.03240311797708273), (19, 0.03273599408566952), (37, 0.03370727691799402), (47, 0.034778119530528784), (51, 0.03860316704958677), (9, 0.0438760444521904), (6, 0.046583487186580896), (4, 0.047749529127031565), (14, 0.047820789739489555), (52, 0.05415361747145653), (2, 0.054873551707714796), (3, 0.057360217440873384), (11, 0.05946161225438118), (13, 0.05948922364041209), (17, 0.061889460776001215), (0, 0.06335367728024721), (1, 0.06620592530816793), (8, 0.07428994588553905), (10, 0.08088330738246441), (16, 0.0849148640409112), (12, 0.09020469058305025), (5, 0.10629779659211636), (36, 0.42776256054639816), (18, 0.51274124532938), (53, 1.1962914615869522)]
computing accuracy for after removing block 23 . block score: 0.02296782610937953
removed block 23 current accuracy 0.8672 loss from initial  0.08420000000000005
since last training loss: 0.07900000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.023934. All blocks and scores: [(38, 0.02393353171646595), (48, 0.024621322518214583), (50, 0.024884442798793316), (25, 0.025045141577720642), (39, 0.02622233028523624), (49, 0.027363613713532686), (20, 0.02736808476038277), (27, 0.028290971415117383), (15, 0.03205894585698843), (7, 0.032403118908405304), (19, 0.03273599408566952), (47, 0.033921611960977316), (37, 0.03714736644178629), (51, 0.03975763591006398), (9, 0.0438760444521904), (6, 0.04658348532393575), (4, 0.04774952959269285), (14, 0.04782078834250569), (52, 0.054274522233754396), (2, 0.05487355217337608), (3, 0.05736021790653467), (11, 0.05946161411702633), (13, 0.05948922457173467), (17, 0.0618894612416625), (0, 0.06335367634892464), (1, 0.06620592530816793), (8, 0.07428994681686163), (10, 0.08088330738246441), (16, 0.08491486310958862), (12, 0.0902046887204051), (5, 0.10629780031740665), (36, 0.44593123346567154), (18, 0.5127412378787994), (53, 1.205638825893402)]
computing accuracy for after removing block 38 . block score: 0.02393353171646595
removed block 38 current accuracy 0.8468 loss from initial  0.10460000000000003
since last training loss: 0.09940000000000004 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.023682. All blocks and scores: [(48, 0.023682388942688704), (50, 0.023847543401643634), (25, 0.02504514134489), (49, 0.026617338648065925), (20, 0.027368083596229553), (39, 0.027666145004332066), (27, 0.028290971647948027), (15, 0.03205894539132714), (7, 0.03240311937406659), (47, 0.03253358602523804), (19, 0.03273599408566952), (37, 0.037147365976125), (51, 0.03907500207424164), (9, 0.043876043520867825), (6, 0.046583487186580896), (4, 0.047749529127031565), (14, 0.04782078834250569), (52, 0.051367273554205894), (2, 0.054873551707714796), (3, 0.05736021604388952), (11, 0.05946161225438118), (13, 0.05948922224342823), (17, 0.0618894612416625), (0, 0.06335367728024721), (1, 0.06620592344552279), (8, 0.0742899477481842), (10, 0.08088330924510956), (16, 0.08491486217826605), (12, 0.09020468685775995), (5, 0.10629779938608408), (36, 0.44593124464154243), (18, 0.5127412378787994), (53, 1.265663519501686)]
computing accuracy for after removing block 48 . block score: 0.023682388942688704
removed block 48 current accuracy 0.826 loss from initial  0.12540000000000007
training start
training epoch 0 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best True lr [0.1]
training epoch 1 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 2 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 3 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best True lr [0.1]
training epoch 4 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.1]
training epoch 5 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 6 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 7 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 9 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 10 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032217. All blocks and scores: [(15, 0.03221742855384946), (7, 0.03277842653915286), (50, 0.03442821325734258), (51, 0.040072616189718246), (49, 0.04355027712881565), (9, 0.044006521347910166), (6, 0.04699670197442174), (4, 0.04770267195999622), (14, 0.04803125141188502), (2, 0.055011091753840446), (3, 0.05862011108547449), (13, 0.05949448375031352), (11, 0.059519386384636164), (47, 0.06188043858855963), (17, 0.06270811939612031), (20, 0.06417187862098217), (19, 0.06430223118513823), (0, 0.06460123602300882), (1, 0.06747451424598694), (52, 0.06865761801600456), (8, 0.07503412943333387), (10, 0.08123093843460083), (39, 0.0837342282757163), (27, 0.0850647771731019), (16, 0.08633750211447477), (37, 0.08796126861125231), (25, 0.08938152249902487), (12, 0.09030203707516193), (5, 0.10762080829590559), (36, 0.5876570791006088), (18, 0.6590578854084015), (53, 0.8243758603930473)]
computing accuracy for after removing block 15 . block score: 0.03221742855384946
removed block 15 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032778. All blocks and scores: [(7, 0.03277842653915286), (50, 0.03490690095350146), (51, 0.04070517607033253), (49, 0.04304231842979789), (9, 0.04400652181357145), (6, 0.04699670244008303), (4, 0.047702671494334936), (14, 0.04803125141188502), (2, 0.05501109128817916), (3, 0.05862011108547449), (13, 0.05949448561295867), (11, 0.05951938731595874), (20, 0.06094147032126784), (47, 0.06339516630396247), (19, 0.06447929423302412), (0, 0.06460123416036367), (17, 0.0665831658989191), (1, 0.06747451703995466), (52, 0.06893967464566231), (8, 0.07503413036465645), (10, 0.08123093750327826), (27, 0.08225577976554632), (39, 0.08333468250930309), (25, 0.0866964589804411), (37, 0.0869209785014391), (12, 0.09030203986912966), (16, 0.0963712353259325), (5, 0.10762080643326044), (36, 0.5733421966433525), (18, 0.6430735066533089), (53, 0.8286712765693665)]
computing accuracy for after removing block 7 . block score: 0.03277842653915286
removed block 7 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.033165. All blocks and scores: [(50, 0.03316484438255429), (51, 0.03913390729576349), (49, 0.042116731870919466), (9, 0.04388319235295057), (14, 0.04437493812292814), (6, 0.04699670057743788), (4, 0.047702671494334936), (13, 0.05154196498915553), (2, 0.05501109268516302), (11, 0.05623855208978057), (17, 0.05639014067128301), (20, 0.05806634854525328), (3, 0.058620112016797066), (19, 0.06181614613160491), (47, 0.06193787697702646), (0, 0.0646012332290411), (52, 0.06525396462529898), (1, 0.06747451983392239), (8, 0.0730256475508213), (27, 0.07763397321105003), (39, 0.08238361310213804), (25, 0.08270762115716934), (37, 0.08281622175127268), (10, 0.0836491510272026), (12, 0.08440728485584259), (16, 0.08776922430843115), (5, 0.10762080922722816), (36, 0.5532878786325455), (18, 0.6197592914104462), (53, 0.8437682092189789)]
computing accuracy for after removing block 50 . block score: 0.03316484438255429
removed block 50 current accuracy 0.9176 loss from initial  0.03380000000000005
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.042117. All blocks and scores: [(49, 0.04211673093959689), (51, 0.043004289735108614), (9, 0.04388319281861186), (14, 0.04437493719160557), (6, 0.04699670057743788), (4, 0.04770267242565751), (13, 0.051541965920478106), (2, 0.055011092219501734), (11, 0.05623855581507087), (17, 0.05639014299958944), (20, 0.05806634807959199), (3, 0.05862011155113578), (19, 0.06181614566594362), (47, 0.06193787883967161), (0, 0.06460123602300882), (1, 0.06747451703995466), (52, 0.07294265180826187), (8, 0.0730256475508213), (27, 0.07763397134840488), (39, 0.08238361403346062), (25, 0.08270761836320162), (37, 0.0828162208199501), (10, 0.08364915382117033), (12, 0.08440728485584259), (16, 0.08776922337710857), (5, 0.10762080922722816), (36, 0.5532878711819649), (18, 0.6197592988610268), (53, 0.9784341976046562)]
computing accuracy for after removing block 49 . block score: 0.04211673093959689
removed block 49 current accuracy 0.8996 loss from initial  0.05180000000000007
since last training loss: 0.04360000000000008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.043883. All blocks and scores: [(9, 0.04388319281861186), (14, 0.04437493858858943), (51, 0.04591529909521341), (6, 0.046996702905744314), (4, 0.04770267242565751), (13, 0.051541965920478106), (2, 0.055011090356856585), (11, 0.05623855395242572), (17, 0.05639014067128301), (20, 0.058066349010914564), (3, 0.058620110619813204), (19, 0.06181614426895976), (47, 0.06193787883967161), (0, 0.06460123509168625), (1, 0.06747451517730951), (8, 0.07302564848214388), (52, 0.0754073029384017), (27, 0.07763397321105003), (39, 0.08238361310213804), (25, 0.08270761836320162), (37, 0.08281622268259525), (10, 0.08364915288984776), (12, 0.08440728299319744), (16, 0.08776922430843115), (5, 0.10762080736458302), (36, 0.5532878786325455), (18, 0.6197593063116074), (53, 1.1061799973249435)]
computing accuracy for after removing block 9 . block score: 0.04388319281861186
removed block 9 current accuracy 0.885 loss from initial  0.06640000000000001
since last training loss: 0.05820000000000003 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 14, with score 0.040280. All blocks and scores: [(14, 0.04028003849089146), (51, 0.04433599952608347), (6, 0.04699670150876045), (4, 0.04770267056301236), (13, 0.04894845047965646), (17, 0.05030354578047991), (11, 0.05198180302977562), (2, 0.0550110898911953), (20, 0.05591756058856845), (3, 0.058620110154151917), (47, 0.0631387890316546), (19, 0.06433216109871864), (0, 0.06460123416036367), (1, 0.06747451424598694), (52, 0.07062131445854902), (16, 0.07225487846881151), (12, 0.07269937451928854), (8, 0.07302564848214388), (27, 0.0735701946541667), (37, 0.07501891162246466), (25, 0.07924806419759989), (39, 0.07989954296499491), (10, 0.08212021086364985), (5, 0.10762080457061529), (36, 0.5159945711493492), (18, 0.6001425683498383), (53, 1.1227848678827286)]
computing accuracy for after removing block 14 . block score: 0.04028003849089146
removed block 14 current accuracy 0.8658 loss from initial  0.08560000000000001
since last training loss: 0.07740000000000002 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.044269. All blocks and scores: [(51, 0.04426944721490145), (6, 0.04699670057743788), (4, 0.04770267242565751), (13, 0.048948450945317745), (17, 0.049828687217086554), (11, 0.05198180116713047), (20, 0.05313829053193331), (2, 0.0550110898911953), (3, 0.05862011341378093), (47, 0.06379512045532465), (0, 0.06460123602300882), (19, 0.06654935516417027), (1, 0.06747451610863209), (52, 0.06810423638671637), (27, 0.07127607613801956), (12, 0.07269937731325626), (8, 0.07302564848214388), (37, 0.07378321420401335), (25, 0.07635173574090004), (39, 0.07973406091332436), (10, 0.082120212726295), (16, 0.0952026154845953), (5, 0.10762080736458302), (36, 0.5087840557098389), (18, 0.5987367779016495), (53, 1.1212953925132751)]
computing accuracy for after removing block 51 . block score: 0.04426944721490145
removed block 51 current accuracy 0.759 loss from initial  0.19240000000000002
since last training loss: 0.18420000000000003 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 6, with score 0.046997. All blocks and scores: [(6, 0.046996702905744314), (4, 0.047702673356980085), (13, 0.048948450945317745), (17, 0.04982868814840913), (11, 0.05198180116713047), (20, 0.05313829146325588), (2, 0.0550110898911953), (3, 0.05862011155113578), (47, 0.06379511952400208), (0, 0.0646012369543314), (19, 0.06654935609549284), (1, 0.06747451424598694), (27, 0.07127607706934214), (12, 0.07269937638193369), (8, 0.07302564661949873), (37, 0.07378321420401335), (25, 0.07635173760354519), (39, 0.07973406184464693), (52, 0.08184364903718233), (10, 0.08212021365761757), (16, 0.09520261641591787), (5, 0.10762080829590559), (36, 0.5087840631604195), (18, 0.5987367928028107), (53, 1.2922921776771545)]
computing accuracy for after removing block 6 . block score: 0.046996702905744314
removed block 6 current accuracy 0.6794 loss from initial  0.272
since last training loss: 0.26380000000000003 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 13, with score 0.046147. All blocks and scores: [(13, 0.046147394459694624), (17, 0.04632867267355323), (11, 0.0475700031965971), (4, 0.04770267056301236), (20, 0.048796769231557846), (2, 0.05501108942553401), (3, 0.05862011155113578), (47, 0.06426979415118694), (0, 0.0646012369543314), (27, 0.06659275759011507), (19, 0.06738740857690573), (1, 0.06747451517730951), (12, 0.06781116686761379), (37, 0.07070678006857634), (8, 0.0719465147703886), (25, 0.07197501510381699), (52, 0.07472207956016064), (39, 0.07746504433453083), (16, 0.07839020062237978), (10, 0.08584354165941477), (5, 0.10762080550193787), (36, 0.49210789799690247), (18, 0.592526376247406), (53, 1.322228655219078)]
computing accuracy for after removing block 13 . block score: 0.046147394459694624
removed block 13 current accuracy 0.5936 loss from initial  0.3578
since last training loss: 0.3496 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.047085. All blocks and scores: [(20, 0.04708455549553037), (11, 0.047570004127919674), (4, 0.04770267056301236), (17, 0.05174605129286647), (2, 0.055011091753840446), (3, 0.05862011155113578), (47, 0.0636232141405344), (27, 0.06404411885887384), (0, 0.06460123509168625), (52, 0.06706523057073355), (1, 0.06747451517730951), (37, 0.06754655204713345), (12, 0.06781116593629122), (25, 0.07185336574912071), (8, 0.0719465147703886), (39, 0.0766098527237773), (19, 0.07739280443638563), (10, 0.08584354165941477), (16, 0.09477231185883284), (5, 0.10762080550193787), (36, 0.479789812117815), (18, 0.6099879592657089), (53, 1.3876338750123978)]
computing accuracy for after removing block 20 . block score: 0.04708455549553037
removed block 20 current accuracy 0.5438 loss from initial  0.4076000000000001
since last training loss: 0.3994000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 11, with score 0.047570. All blocks and scores: [(11, 0.04757000366225839), (4, 0.0477026728913188), (17, 0.05174605082720518), (2, 0.05501109082251787), (27, 0.058340410236269236), (3, 0.05862011155113578), (47, 0.061189721804112196), (52, 0.06270316988229752), (0, 0.06460123602300882), (1, 0.06747451610863209), (12, 0.06781116593629122), (25, 0.06903546955436468), (37, 0.06904539559036493), (8, 0.07194651663303375), (39, 0.0757470615208149), (19, 0.0773928053677082), (10, 0.08584354259073734), (16, 0.09477231558412313), (5, 0.10762080643326044), (36, 0.4668888784945011), (18, 0.6099879592657089), (53, 1.481799691915512)]
computing accuracy for after removing block 11 . block score: 0.04757000366225839
removed block 11 current accuracy 0.4908 loss from initial  0.4606
training start
training epoch 0 val accuracy 0.8226 topk_dict {'top1': 0.8226} is_best True lr [0.1]
training epoch 1 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 2 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.1]
training epoch 3 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 4 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.1]
training epoch 5 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 6 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.1]
training epoch 7 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 8 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 9 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 10 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.937600)
finished training. finished 50 epochs. accuracy 0.9376 topk_dict {'top1': 0.9376}
start iteration 33
[activation diff]: block to remove picked: 2, with score 0.054805. All blocks and scores: [(2, 0.0548045109026134), (0, 0.06435720156878233), (1, 0.06631229165941477), (4, 0.07126197963953018), (52, 0.09224739763885736), (47, 0.09726022742688656), (37, 0.10180354211479425), (27, 0.10398745350539684), (3, 0.10598331317305565), (19, 0.10609353892505169), (39, 0.10711413249373436), (25, 0.11343013681471348), (17, 0.1318174283951521), (8, 0.16101084649562836), (16, 0.17680259607732296), (10, 0.17913281172513962), (12, 0.20492958649992943), (5, 0.2130523081868887), (36, 0.5551306456327438), (18, 0.6788745224475861), (53, 1.3671966791152954)]
computing accuracy for after removing block 2 . block score: 0.0548045109026134
removed block 2 current accuracy 0.927 loss from initial  0.024399999999999977
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 0, with score 0.064357. All blocks and scores: [(0, 0.06435720063745975), (1, 0.0663122907280922), (4, 0.06727257743477821), (52, 0.08625268470495939), (3, 0.09275399893522263), (37, 0.0943598710000515), (47, 0.09509579092264175), (19, 0.09582709707319736), (27, 0.09718106035143137), (25, 0.09932384639978409), (39, 0.10065537318587303), (17, 0.11895138677209616), (8, 0.15936407260596752), (16, 0.160540159791708), (10, 0.1747612040489912), (12, 0.19135064259171486), (5, 0.21094881743192673), (36, 0.5103159695863724), (18, 0.6079429313540459), (53, 1.343707412481308)]
computing accuracy for after removing block 0 . block score: 0.06435720063745975
removed block 0 current accuracy 0.9006 loss from initial  0.05080000000000007
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 4, with score 0.059189. All blocks and scores: [(4, 0.05918938433751464), (1, 0.06866413168609142), (3, 0.0778363486751914), (52, 0.0796956717967987), (27, 0.08978323731571436), (19, 0.09182597883045673), (37, 0.09185271244496107), (25, 0.09268277231603861), (47, 0.09287105407565832), (39, 0.09556164871901274), (17, 0.11608507949858904), (16, 0.15159225463867188), (8, 0.1588244903832674), (10, 0.16895493492484093), (12, 0.18883877247571945), (5, 0.20808463729918003), (36, 0.48565685003995895), (18, 0.6034591197967529), (53, 1.3193672448396683)]
computing accuracy for after removing block 4 . block score: 0.05918938433751464
removed block 4 current accuracy 0.8874 loss from initial  0.06400000000000006
since last training loss: 0.05020000000000002 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 1, with score 0.068664. All blocks and scores: [(1, 0.06866413168609142), (52, 0.0759950503706932), (3, 0.07783635053783655), (25, 0.08826457243412733), (37, 0.08829797804355621), (27, 0.08876784890890121), (39, 0.09211582038551569), (47, 0.09217877313494682), (19, 0.09541656915098429), (17, 0.11073745228350163), (16, 0.1351116355508566), (10, 0.1587732993066311), (8, 0.15944166108965874), (12, 0.17045925557613373), (5, 0.22206810489296913), (36, 0.46478405222296715), (18, 0.5884205251932144), (53, 1.2920115441083908)]
computing accuracy for after removing block 1 . block score: 0.06866413168609142
removed block 1 current accuracy 0.781 loss from initial  0.1704
since last training loss: 0.15659999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 52, with score 0.065403. All blocks and scores: [(52, 0.06540349312126637), (3, 0.07271196506917477), (27, 0.0752910366281867), (25, 0.07944427337497473), (37, 0.08366070967167616), (19, 0.08421561773866415), (39, 0.08519371412694454), (47, 0.08909398689866066), (17, 0.09282580763101578), (16, 0.11763740237802267), (8, 0.14250843971967697), (10, 0.14562466740608215), (12, 0.16131382249295712), (5, 0.2183972354978323), (36, 0.450469184666872), (18, 0.5721255019307137), (53, 1.2154033333063126)]
computing accuracy for after removing block 52 . block score: 0.06540349312126637
removed block 52 current accuracy 0.6682 loss from initial  0.2832
since last training loss: 0.2694 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 3, with score 0.072712. All blocks and scores: [(3, 0.07271196972578764), (27, 0.07529103569686413), (25, 0.07944427244365215), (37, 0.08366070967167616), (19, 0.08421562053263187), (39, 0.08519371878355742), (47, 0.08909398596733809), (17, 0.09282580763101578), (16, 0.1176374051719904), (8, 0.14250843785703182), (10, 0.145624665543437), (12, 0.16131382435560226), (5, 0.2183972429484129), (36, 0.4504691772162914), (18, 0.5721255019307137), (53, 1.3246560990810394)]
computing accuracy for after removing block 3 . block score: 0.07271196972578764
removed block 3 current accuracy 0.5642 loss from initial  0.3872
since last training loss: 0.37339999999999995 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 25, with score 0.070909. All blocks and scores: [(25, 0.07090899907052517), (27, 0.07375497184693813), (39, 0.07654513139277697), (37, 0.08471401780843735), (19, 0.08647971600294113), (47, 0.08716611377894878), (16, 0.0892751282081008), (17, 0.09049317706376314), (8, 0.12954198196530342), (10, 0.135743061080575), (12, 0.14575357921421528), (5, 0.24070434272289276), (36, 0.4249795787036419), (18, 0.5308573469519615), (53, 1.2467211931943893)]
computing accuracy for after removing block 25 . block score: 0.07090899907052517
removed block 25 current accuracy 0.4766 loss from initial  0.4748
since last training loss: 0.46099999999999997 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 27, with score 0.070245. All blocks and scores: [(27, 0.0702445562928915), (39, 0.07613459322601557), (47, 0.07820585556328297), (37, 0.08288183994591236), (19, 0.08647971320897341), (16, 0.0892751244828105), (17, 0.09049317240715027), (8, 0.12954197637736797), (10, 0.13574306294322014), (12, 0.14575358666479588), (5, 0.2407043445855379), (36, 0.42480356246232986), (18, 0.5308573544025421), (53, 1.1495469808578491)]
computing accuracy for after removing block 27 . block score: 0.0702445562928915
removed block 27 current accuracy 0.3756 loss from initial  0.5758000000000001
since last training loss: 0.562 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 47, with score 0.073705. All blocks and scores: [(47, 0.07370501663535833), (39, 0.07379590068012476), (19, 0.08647971320897341), (16, 0.0892751282081008), (37, 0.09024891536682844), (17, 0.09049317520111799), (8, 0.12954198196530342), (10, 0.1357430648058653), (12, 0.14575358107686043), (5, 0.2407043408602476), (36, 0.4660154990851879), (18, 0.5308573544025421), (53, 1.2128358781337738)]
computing accuracy for after removing block 47 . block score: 0.07370501663535833
removed block 47 current accuracy 0.282 loss from initial  0.6694
since last training loss: 0.6556 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 39, with score 0.073796. All blocks and scores: [(39, 0.07379589974880219), (19, 0.08647971414029598), (16, 0.08927512727677822), (37, 0.09024891443550587), (17, 0.09049317426979542), (8, 0.12954197637736797), (10, 0.13574306294322014), (12, 0.14575357921421528), (5, 0.24070434644818306), (36, 0.4660155028104782), (18, 0.5308573395013809), (53, 1.306455135345459)]
computing accuracy for after removing block 39 . block score: 0.07379589974880219
removed block 39 current accuracy 0.2294 loss from initial  0.722
since last training loss: 0.7081999999999999 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 19, with score 0.086480. All blocks and scores: [(19, 0.08647971507161856), (16, 0.08927512355148792), (37, 0.09024891443550587), (17, 0.09049317706376314), (8, 0.12954197451472282), (10, 0.13574306666851044), (12, 0.14575358107686043), (5, 0.24070433899760246), (36, 0.4660154990851879), (18, 0.5308573544025421), (53, 1.3862987458705902)]
computing accuracy for after removing block 19 . block score: 0.08647971507161856
removed block 19 current accuracy 0.2142 loss from initial  0.7372000000000001
since last training loss: 0.7234 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 16, with score 0.089275. All blocks and scores: [(16, 0.08927512913942337), (17, 0.09049317706376314), (37, 0.11549030803143978), (8, 0.12954197824001312), (10, 0.13574306294322014), (12, 0.14575358107686043), (5, 0.24070434644818306), (36, 0.5024024173617363), (18, 0.5308573395013809), (53, 1.4326064139604568)]
computing accuracy for after removing block 16 . block score: 0.08927512913942337
removed block 16 current accuracy 0.1752 loss from initial  0.7762
training start
training epoch 0 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best True lr [0.1]
training epoch 1 val accuracy 0.7746 topk_dict {'top1': 0.7746} is_best False lr [0.1]
training epoch 2 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best True lr [0.1]
training epoch 3 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 4 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best True lr [0.1]
training epoch 5 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 6 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 7 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 8 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.1]
training epoch 9 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.921200)
finished training. finished 50 epochs. accuracy 0.9212 topk_dict {'top1': 0.9212}
