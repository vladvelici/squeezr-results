start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013294660719111562), (29, 0.013421116978861392), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01999649149365723), (46, 0.020590225234627724), (25, 0.022078295471146703), (23, 0.022228715242817998), (41, 0.022336415946483612), (44, 0.02314600022509694), (40, 0.023749590618535876), (45, 0.023975495249032974), (21, 0.02494108979590237), (48, 0.02495770575478673), (22, 0.025151390116661787), (50, 0.025287174154073), (24, 0.025880582397803664), (49, 0.02591664856299758), (42, 0.026232233038172126), (20, 0.026848891284316778), (47, 0.0286329488735646), (38, 0.03134434390813112), (39, 0.031441295286640525), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.037918031215667725), (51, 0.041787587106227875), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589849635959), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119244133122265), (29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.0235738311894238), (45, 0.023648238508030772), (48, 0.02454021736048162), (50, 0.024770822608843446), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02557574096135795), (24, 0.02588058332912624), (42, 0.025893412763252854), (20, 0.026848891517147422), (47, 0.028072761138901114), (38, 0.0310911878477782), (39, 0.031191361602395773), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03797321068122983), (51, 0.04127101460471749), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.054577403236180544), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06493351701647043), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4339806139469147), (18, 0.5117433071136475), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589849635959
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.013421116978861392), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.02222871477715671), (44, 0.022891477681696415), (40, 0.023602579487487674), (45, 0.023770848521962762), (48, 0.024519873317331076), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.025392550509423018), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.02805250370875001), (38, 0.030935874208807945), (39, 0.03117303573526442), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4350202940404415), (18, 0.5117433071136475), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.01024482469074428), (34, 0.012400159961543977), (29, 0.013421116746030748), (35, 0.015918649034574628), (26, 0.01607214054092765), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019867350347340107), (46, 0.020279744174331427), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.02222871477715671), (44, 0.023001376539468765), (40, 0.02373992674984038), (45, 0.02379016880877316), (48, 0.024350045016035438), (50, 0.02446310594677925), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.02524693007580936), (42, 0.025273551931604743), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.02772757480852306), (38, 0.030746274162083864), (39, 0.031281794887036085), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03895266866311431), (51, 0.04082479979842901), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464554235339), (52, 0.06356756389141083), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143978834152), (36, 0.4377693086862564), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.01024482469074428
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116746030748), (35, 0.01596891158260405), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837009022012353), (46, 0.020137187326326966), (41, 0.0215840560849756), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02268732455559075), (40, 0.023569098440930247), (45, 0.023840720998123288), (48, 0.024108359357342124), (50, 0.02411420992575586), (49, 0.02487011789344251), (21, 0.02494108909741044), (42, 0.025045574409887195), (22, 0.025151390582323074), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.027423852356150746), (38, 0.030735648004338145), (39, 0.03141042543575168), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.04034594027325511), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325253918766975), (52, 0.06270107813179493), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143978834152), (36, 0.43692686036229134), (18, 0.5117432996630669), (53, 0.8283701539039612)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141472250223), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.022078295005485415), (23, 0.02222871477715671), (44, 0.02304507838562131), (48, 0.02402454731054604), (50, 0.02409697277471423), (40, 0.024156817002221942), (45, 0.024168409407138824), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151389883831143), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.027568294433876872), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.04008621256798506), (37, 0.040690730791538954), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.06132525438442826), (52, 0.06221095006912947), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299865782261), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.44933702424168587), (18, 0.5117432847619057), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511380955577), (28, 0.017636860720813274), (27, 0.019022797234356403), (43, 0.01985670323483646), (46, 0.01998897665180266), (41, 0.021256204694509506), (25, 0.02207829593680799), (23, 0.02222871547564864), (44, 0.02269203308969736), (48, 0.023521372117102146), (50, 0.02353389118798077), (40, 0.023616239661350846), (45, 0.023933292599394917), (49, 0.02444991492666304), (42, 0.024838327895849943), (21, 0.02494108979590237), (22, 0.025151390582323074), (24, 0.02588058216497302), (47, 0.026813456555828452), (20, 0.02684889081865549), (38, 0.0310837309807539), (39, 0.032056890428066254), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03907974949106574), (37, 0.0401521441526711), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003409311175), (52, 0.06036907434463501), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537329226732), (5, 0.1067114369943738), (36, 0.4432784356176853), (18, 0.5117432847619057), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.016986021772027016), (27, 0.01876970916055143), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.020515799056738615), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022507572313770652), (48, 0.022899369476363063), (50, 0.022937727626413107), (40, 0.02305740211158991), (42, 0.023520409129559994), (45, 0.023633699398487806), (49, 0.02408191910944879), (21, 0.02494108909741044), (22, 0.025151390116661787), (24, 0.025880583561956882), (47, 0.0263227925170213), (20, 0.026848891284316778), (38, 0.030149149475619197), (39, 0.031466696644201875), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.037851928267627954), (37, 0.039268902968615294), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849929202347994), (52, 0.05846811877563596), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143885701895), (36, 0.43490004166960716), (18, 0.5117432922124863), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381991190835834), (27, 0.018769708229228854), (46, 0.018842301797121763), (41, 0.01901637064293027), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.021748854080215096), (40, 0.021916967118158937), (42, 0.021930373972281814), (25, 0.02207829523831606), (23, 0.022228715009987354), (45, 0.02273644949309528), (49, 0.022970063611865044), (21, 0.024941089330241084), (22, 0.02515139034949243), (47, 0.025355831952765584), (24, 0.025880583794787526), (20, 0.026848892215639353), (38, 0.028691887157037854), (39, 0.02962443116120994), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.036016357596963644), (37, 0.03643036773428321), (9, 0.04337632795795798), (6, 0.046823698095977306), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (52, 0.05466858018189669), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.0597000359557569), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299400120974), (16, 0.0852750651538372), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.41641608998179436), (18, 0.5117432922124863), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635219469666), (46, 0.01835862477310002), (41, 0.018467807210981846), (27, 0.018769708462059498), (48, 0.020775508135557175), (42, 0.02120647020637989), (50, 0.02130244765430689), (44, 0.021586895920336246), (40, 0.02159272227436304), (25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.02231529331766069), (49, 0.02240756689570844), (47, 0.024609397165477276), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.025880583561956882), (20, 0.02684889198280871), (38, 0.027890325291082263), (39, 0.02919189492240548), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03550667641684413), (37, 0.035919226706027985), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.04852241277694702), (52, 0.05337408324703574), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4126181975007057), (18, 0.5117433071136475), (53, 0.906721331179142)]
computing accuracy for after removing block 43 . block score: 0.017987635219469666
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467807210981846), (27, 0.018769708927720785), (46, 0.01899468107149005), (42, 0.02120647020637989), (48, 0.021418894873932004), (50, 0.02144132275134325), (40, 0.021592722041532397), (25, 0.022078295471146703), (23, 0.022228715708479285), (49, 0.022339017828926444), (44, 0.02278283331543207), (45, 0.023323106346651912), (21, 0.02494108909741044), (22, 0.025151390116661787), (47, 0.025386076886206865), (24, 0.02588058332912624), (20, 0.026848891517147422), (38, 0.027890325523912907), (39, 0.029191894689574838), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.035217716824263334), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.052133372984826565), (2, 0.054577404633164406), (3, 0.05784992501139641), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.061325255781412125), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4126182049512863), (18, 0.5117432922124863), (53, 0.9521221220493317)]
computing accuracy for after removing block 41 . block score: 0.018467807210981846
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 1 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 2 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.1]
training epoch 3 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 4 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.1]
training epoch 5 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 6 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.1]
training epoch 7 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.1]
training epoch 8 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.1]
training epoch 9 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 11
[activation diff]: block to remove picked: 40, with score 0.017364. All blocks and scores: [(40, 0.017363915219902992), (42, 0.01948476117104292), (46, 0.02387218549847603), (38, 0.024472290882840753), (39, 0.02466842671856284), (22, 0.02555771078914404), (50, 0.026581600541248918), (49, 0.02736867661587894), (48, 0.027453939896076918), (23, 0.027604016242548823), (45, 0.028228167444467545), (21, 0.02825938817113638), (20, 0.028429768979549408), (44, 0.028433912666514516), (25, 0.029478159034624696), (27, 0.031262789852917194), (37, 0.03200300270691514), (47, 0.03205878380686045), (15, 0.032355118077248335), (19, 0.032597542740404606), (7, 0.03273383714258671), (24, 0.033000947907567024), (51, 0.0434063533321023), (9, 0.043995718471705914), (6, 0.04694892419502139), (4, 0.04819969506934285), (14, 0.0482971528545022), (2, 0.055171570274978876), (3, 0.05871674371883273), (13, 0.05967677477747202), (11, 0.06001760624349117), (17, 0.06291205249726772), (0, 0.06449167896062136), (1, 0.06688866205513477), (52, 0.06780154909938574), (8, 0.07493970263749361), (10, 0.08162363059818745), (16, 0.08710923511534929), (12, 0.09126620553433895), (5, 0.10757969971746206), (36, 0.45435331016778946), (18, 0.5169739574193954), (53, 0.8077996745705605)]
computing accuracy for after removing block 40 . block score: 0.017363915219902992
removed block 40 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.018806. All blocks and scores: [(42, 0.018806431675329804), (46, 0.024116465589031577), (38, 0.024472290417179465), (39, 0.024668426951393485), (22, 0.025557711953297257), (50, 0.026068442966789007), (48, 0.0266808676533401), (49, 0.027160329511389136), (23, 0.02760401670821011), (45, 0.028198832413181663), (21, 0.028259387938305736), (20, 0.028429768281057477), (25, 0.029478158801794052), (44, 0.029595196014270186), (27, 0.03126278962008655), (37, 0.03200300270691514), (15, 0.03235511761158705), (19, 0.03259754367172718), (7, 0.03273383621126413), (24, 0.03300094744190574), (47, 0.03355220425873995), (51, 0.043372513726353645), (9, 0.043995718471705914), (6, 0.046948923263698816), (4, 0.048199696000665426), (14, 0.0482971528545022), (2, 0.0551715693436563), (3, 0.05871674092486501), (13, 0.05967677477747202), (11, 0.06001760298386216), (17, 0.06291205435991287), (0, 0.06449167989194393), (1, 0.06688866391777992), (52, 0.06717877648770809), (8, 0.07493970356881618), (10, 0.08162363059818745), (16, 0.08710923418402672), (12, 0.09126620553433895), (5, 0.10757969785481691), (36, 0.45435332134366035), (18, 0.5169739574193954), (53, 0.8471058085560799)]
computing accuracy for after removing block 42 . block score: 0.018806431675329804
removed block 42 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 38, with score 0.024472. All blocks and scores: [(38, 0.024472290417179465), (39, 0.02466842718422413), (46, 0.024769985815510154), (22, 0.025557711254805326), (50, 0.02605393808335066), (49, 0.026485414942726493), (48, 0.026712187798693776), (23, 0.027604016242548823), (21, 0.028259387938305736), (20, 0.028429768281057477), (45, 0.029084941372275352), (25, 0.0294781606644392), (27, 0.031262789852917194), (44, 0.03138507204130292), (37, 0.03200300224125385), (15, 0.032355118077248335), (19, 0.032597542740404606), (7, 0.032733835745602846), (24, 0.03300094697624445), (47, 0.033843887504190207), (51, 0.043442798778414726), (9, 0.043995718471705914), (6, 0.046948923263698816), (4, 0.048199696000665426), (14, 0.04829715332016349), (2, 0.05517157074064016), (3, 0.05871674278751016), (13, 0.059676775708794594), (11, 0.06001760484650731), (17, 0.06291205249726772), (0, 0.06449167896062136), (1, 0.0668886611238122), (52, 0.06797633226960897), (8, 0.07493970356881618), (10, 0.08162363059818745), (16, 0.08710923697799444), (12, 0.0912662073969841), (5, 0.10757969878613949), (36, 0.45435331016778946), (18, 0.5169739425182343), (53, 0.8725919872522354)]
computing accuracy for after removing block 38 . block score: 0.024472290417179465
removed block 38 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 46, with score 0.023193. All blocks and scores: [(46, 0.023193460889160633), (50, 0.02441517566330731), (48, 0.02466860879212618), (22, 0.025557710323482752), (49, 0.025585142895579338), (39, 0.02714491030201316), (23, 0.02760401531122625), (21, 0.02825938700698316), (20, 0.02842976711690426), (45, 0.02874038345180452), (25, 0.02947815926745534), (27, 0.031262790551409125), (47, 0.031421403400599957), (44, 0.03174149477854371), (37, 0.03200300270691514), (15, 0.03235511761158705), (19, 0.03259754227474332), (7, 0.03273383621126413), (24, 0.03300094744190574), (51, 0.041835897602140903), (9, 0.0439957189373672), (6, 0.046948923263698816), (4, 0.04819969553500414), (14, 0.04829715425148606), (2, 0.055171570274978876), (3, 0.05871674278751016), (13, 0.059676775708794594), (11, 0.06001760670915246), (17, 0.06291205063462257), (52, 0.064306256826967), (0, 0.06449167709797621), (1, 0.0668886611238122), (8, 0.07493970263749361), (10, 0.0816236287355423), (16, 0.08710923790931702), (12, 0.09126620646566153), (5, 0.10757969599217176), (36, 0.45435331761837006), (18, 0.516973964869976), (53, 0.8998400270938873)]
computing accuracy for after removing block 46 . block score: 0.023193460889160633
removed block 46 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.025430. All blocks and scores: [(50, 0.02543036942370236), (22, 0.025557711720466614), (48, 0.025626756949350238), (49, 0.02671472169458866), (39, 0.027144909370690584), (23, 0.027604016475379467), (21, 0.02825938747264445), (20, 0.028429769445210695), (45, 0.02874038415029645), (25, 0.029478159733116627), (27, 0.03126278892159462), (44, 0.03174149431288242), (37, 0.03200300270691514), (15, 0.03235511761158705), (19, 0.03259754367172718), (7, 0.03273383667692542), (24, 0.03300094744190574), (47, 0.03388354042544961), (51, 0.04203703673556447), (9, 0.0439957189373672), (6, 0.046948923263698816), (4, 0.048199696466326714), (14, 0.04829715471714735), (2, 0.0551715693436563), (3, 0.05871674418449402), (13, 0.05967677151784301), (11, 0.06001760717481375), (17, 0.06291205110028386), (0, 0.06449168175458908), (52, 0.06493019126355648), (1, 0.06688866205513477), (8, 0.07493970356881618), (10, 0.08162363152951002), (16, 0.08710923697799444), (12, 0.09126620646566153), (5, 0.10757969785481691), (36, 0.45435331389307976), (18, 0.5169739574193954), (53, 0.9984669163823128)]
computing accuracy for after removing block 50 . block score: 0.02543036942370236
removed block 50 current accuracy 0.9156 loss from initial  0.035800000000000054
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.025558. All blocks and scores: [(22, 0.025557711254805326), (48, 0.0256267583463341), (49, 0.026714720530435443), (39, 0.027144909603521228), (23, 0.027604015544056892), (21, 0.028259386774152517), (20, 0.02842976781539619), (45, 0.028740383684635162), (25, 0.029478159500285983), (27, 0.031262789852917194), (44, 0.03174149477854371), (37, 0.03200300317257643), (15, 0.032355118077248335), (19, 0.03259754367172718), (7, 0.03273383527994156), (24, 0.033000947907567024), (47, 0.033883539494127035), (9, 0.043995718471705914), (51, 0.04485732410103083), (6, 0.046948923729360104), (4, 0.048199696466326714), (14, 0.0482971528545022), (2, 0.055171570274978876), (3, 0.05871674278751016), (13, 0.05967677338048816), (11, 0.06001760717481375), (17, 0.06291205249726772), (0, 0.0644916808232665), (1, 0.06688866298645735), (52, 0.07190032489597797), (8, 0.07493970263749361), (10, 0.08162362966686487), (16, 0.08710923604667187), (12, 0.09126620553433895), (5, 0.10757969971746206), (36, 0.45435331016778946), (18, 0.5169739499688148), (53, 1.1809257119894028)]
computing accuracy for after removing block 22 . block score: 0.025557711254805326
removed block 22 current accuracy 0.9134 loss from initial  0.038000000000000034
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.024723. All blocks and scores: [(48, 0.024723390117287636), (23, 0.025324134388938546), (49, 0.025976639473810792), (39, 0.026571016758680344), (25, 0.028088337276130915), (45, 0.02811258821748197), (21, 0.02825938817113638), (20, 0.028429768281057477), (24, 0.029660807689651847), (44, 0.030173032078891993), (27, 0.030628263717517257), (37, 0.03200523881241679), (47, 0.032194871455430984), (15, 0.03235511761158705), (19, 0.03259754227474332), (7, 0.032733835745602846), (51, 0.043021689634770155), (9, 0.043995718471705914), (6, 0.04694892419502139), (4, 0.04819969553500414), (14, 0.04829715332016349), (2, 0.055171568877995014), (3, 0.05871674371883273), (13, 0.059676773846149445), (11, 0.06001760624349117), (17, 0.06291205063462257), (0, 0.06449167802929878), (1, 0.06688866019248962), (52, 0.06720240879803896), (8, 0.07493970543146133), (10, 0.08162363339215517), (16, 0.08710923511534929), (12, 0.09126620553433895), (5, 0.10757969785481691), (36, 0.44428838789463043), (18, 0.5169739425182343), (53, 1.1826273798942566)]
computing accuracy for after removing block 48 . block score: 0.024723390117287636
removed block 48 current accuracy 0.9002 loss from initial  0.05120000000000002
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.025324. All blocks and scores: [(23, 0.025324134388938546), (39, 0.026571017457172275), (25, 0.028088337974622846), (45, 0.028112588683143258), (21, 0.028259387239813805), (20, 0.02842976851388812), (49, 0.028749809367582202), (24, 0.02966080722399056), (44, 0.03017303138040006), (27, 0.030628262786194682), (37, 0.03200523881241679), (47, 0.032194872852414846), (15, 0.03235511761158705), (19, 0.03259754180908203), (7, 0.03273383714258671), (51, 0.04283757274970412), (9, 0.04399571754038334), (6, 0.04694892279803753), (4, 0.048199696931988), (14, 0.048297153785824776), (2, 0.0551715693436563), (3, 0.05871674371883273), (13, 0.05967677664011717), (11, 0.060017604380846024), (17, 0.06291205063462257), (0, 0.06449167802929878), (1, 0.06688865926116705), (8, 0.07493970356881618), (52, 0.07503213081508875), (10, 0.0816236287355423), (16, 0.08710923418402672), (12, 0.09126620460301638), (5, 0.10757969971746206), (36, 0.4442883990705013), (18, 0.5169739574193954), (53, 1.2921283394098282)]
computing accuracy for after removing block 23 . block score: 0.025324134388938546
removed block 23 current accuracy 0.8906 loss from initial  0.060800000000000076
since last training loss: 0.05180000000000007 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.026825. All blocks and scores: [(39, 0.026825083885341883), (24, 0.028157089138403535), (25, 0.028184761758893728), (21, 0.028259387705475092), (45, 0.02838643710128963), (20, 0.028429768746718764), (49, 0.029000765411183238), (44, 0.029755213297903538), (27, 0.030479282373562455), (47, 0.031657019862905145), (15, 0.03235511668026447), (19, 0.032597542740404606), (7, 0.03273383667692542), (37, 0.03407143661752343), (51, 0.04284434486180544), (9, 0.043995718006044626), (6, 0.046948923729360104), (4, 0.048199696931988), (14, 0.04829715425148606), (2, 0.055171570274978876), (3, 0.058716743253171444), (13, 0.05967677477747202), (11, 0.06001760484650731), (17, 0.06291205156594515), (0, 0.06449167989194393), (1, 0.06688866298645735), (52, 0.07398795336484909), (8, 0.07493970170617104), (10, 0.08162363152951002), (16, 0.08710923604667187), (12, 0.09126620553433895), (5, 0.10757969878613949), (36, 0.45589448139071465), (18, 0.5169739574193954), (53, 1.306254893541336)]
computing accuracy for after removing block 39 . block score: 0.026825083885341883
removed block 39 current accuracy 0.8742 loss from initial  0.07720000000000005
since last training loss: 0.06820000000000004 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.028157. All blocks and scores: [(24, 0.028157090302556753), (25, 0.028184761991724372), (49, 0.02818816970102489), (21, 0.028259387239813805), (45, 0.028391745407134295), (20, 0.02842976851388812), (27, 0.03047928330488503), (47, 0.0308231667149812), (44, 0.03132269764319062), (15, 0.03235511854290962), (19, 0.03259754180908203), (7, 0.03273383714258671), (37, 0.03407143661752343), (51, 0.04098296258598566), (9, 0.043995718471705914), (6, 0.046948923263698816), (4, 0.048199696000665426), (14, 0.048297153785824776), (2, 0.0551715693436563), (3, 0.05871674185618758), (13, 0.059676775708794594), (11, 0.060017607640475035), (17, 0.06291205110028386), (0, 0.06449167709797621), (52, 0.0652967281639576), (1, 0.06688866298645735), (8, 0.07493970356881618), (10, 0.08162363152951002), (16, 0.08710923604667187), (12, 0.09126620553433895), (5, 0.10757969506084919), (36, 0.45589450374245644), (18, 0.5169739723205566), (53, 1.3768895864486694)]
computing accuracy for after removing block 24 . block score: 0.028157090302556753
removed block 24 current accuracy 0.8654 loss from initial  0.08600000000000008
since last training loss: 0.07700000000000007 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.026338. All blocks and scores: [(49, 0.026337852235883474), (45, 0.02692513493821025), (21, 0.028259387239813805), (20, 0.028429767349734902), (25, 0.028816563542932272), (47, 0.029084414476528764), (44, 0.029971417039632797), (27, 0.030818613711744547), (37, 0.03228368377313018), (15, 0.032355118077248335), (19, 0.03259754227474332), (7, 0.03273383621126413), (51, 0.03832385968416929), (9, 0.043995718471705914), (6, 0.04694892279803753), (4, 0.048199696000665426), (14, 0.0482971528545022), (2, 0.05517156980931759), (52, 0.05689755780622363), (3, 0.058716743253171444), (13, 0.05967677664011717), (11, 0.060017604380846024), (17, 0.06291205203160644), (0, 0.06449167802929878), (1, 0.06688866205513477), (8, 0.07493970263749361), (10, 0.08162362966686487), (16, 0.08710923418402672), (12, 0.09126620553433895), (5, 0.10757969878613949), (36, 0.4397880621254444), (18, 0.5169739574193954), (53, 1.4210934191942215)]
computing accuracy for after removing block 49 . block score: 0.026337852235883474
removed block 49 current accuracy 0.832 loss from initial  0.11940000000000006
training start
training epoch 0 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.1]
training epoch 1 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.1]
training epoch 2 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 4 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 5 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 6 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 7 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 8 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.1]
training epoch 9 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032108. All blocks and scores: [(15, 0.03210814204066992), (7, 0.03286759555339813), (47, 0.03885932778939605), (45, 0.04396535502746701), (9, 0.04407387040555477), (51, 0.04546142788603902), (6, 0.04692082293331623), (14, 0.047891669906675816), (4, 0.04938849341124296), (44, 0.05283609498292208), (17, 0.053788896184414625), (2, 0.055200114380568266), (3, 0.05911137443035841), (13, 0.05937757343053818), (11, 0.059959443751722574), (19, 0.06333383405581117), (0, 0.06476115249097347), (1, 0.0667572757229209), (52, 0.068817931227386), (8, 0.07479455787688494), (21, 0.07787499856203794), (20, 0.07883917726576328), (27, 0.08122928533703089), (10, 0.08129435870796442), (16, 0.08426491357386112), (25, 0.08429657015949488), (37, 0.08955536503344774), (12, 0.09028640110045671), (5, 0.10722483415156603), (36, 0.5314873978495598), (18, 0.7331585511565208), (53, 0.8195455148816109)]
computing accuracy for after removing block 15 . block score: 0.03210814204066992
removed block 15 current accuracy 0.935 loss from initial  0.01639999999999997
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032868. All blocks and scores: [(7, 0.03286759415641427), (47, 0.03915774589404464), (45, 0.043935643043369055), (9, 0.04407387040555477), (51, 0.045601257123053074), (6, 0.04692082339897752), (14, 0.0478916703723371), (4, 0.049388492945581675), (44, 0.05157336313277483), (2, 0.05520011391490698), (17, 0.05549745727330446), (3, 0.05911137256771326), (13, 0.05937757156789303), (11, 0.0599594428204), (19, 0.06319820415228605), (0, 0.06476115342229605), (1, 0.06675727665424347), (52, 0.06870839837938547), (20, 0.0740776052698493), (21, 0.07413060963153839), (8, 0.07479455415159464), (27, 0.07832289859652519), (10, 0.08129435777664185), (25, 0.08187619503587484), (16, 0.08945706393569708), (37, 0.09010199643671513), (12, 0.09028640482574701), (5, 0.1072248388081789), (36, 0.5215135291218758), (18, 0.7154307067394257), (53, 0.8307539969682693)]
computing accuracy for after removing block 7 . block score: 0.03286759415641427
removed block 7 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.038105. All blocks and scores: [(47, 0.038104608189314604), (45, 0.0425993874669075), (9, 0.044012587051838636), (51, 0.04415700398385525), (14, 0.044216317124664783), (6, 0.04692082339897752), (17, 0.04739647591486573), (4, 0.049388492945581675), (44, 0.05112889828160405), (13, 0.0514115453697741), (2, 0.05520011344924569), (11, 0.056598350405693054), (3, 0.05911137443035841), (19, 0.059270842000842094), (0, 0.06476115342229605), (52, 0.06503794621676207), (1, 0.0667572757229209), (20, 0.07046912144869566), (21, 0.07222958840429783), (8, 0.07285820040851831), (27, 0.07394244987517595), (25, 0.07851328793913126), (16, 0.07983639370650053), (10, 0.08368400391191244), (12, 0.08427658956497908), (37, 0.08560951240360737), (5, 0.10722483322024345), (36, 0.5060623809695244), (18, 0.6872556358575821), (53, 0.8389454931020737)]
computing accuracy for after removing block 47 . block score: 0.038104608189314604
removed block 47 current accuracy 0.913 loss from initial  0.03839999999999999
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.042599. All blocks and scores: [(45, 0.0425993874669075), (9, 0.044012587517499924), (14, 0.04421631805598736), (51, 0.045515929348766804), (6, 0.04692082293331623), (17, 0.047396477311849594), (4, 0.04938849247992039), (44, 0.05112889828160405), (13, 0.05141154769808054), (2, 0.05520011531189084), (11, 0.05659834900870919), (3, 0.05911137256771326), (19, 0.05927084153518081), (0, 0.06476115435361862), (1, 0.06675727479159832), (52, 0.06987449247390032), (20, 0.07046912238001823), (21, 0.07222958747297525), (8, 0.07285819947719574), (27, 0.07394244987517595), (25, 0.07851328700780869), (16, 0.07983639277517796), (10, 0.08368400856852531), (12, 0.0842765886336565), (37, 0.08560951333492994), (5, 0.10722483787685633), (36, 0.5060623958706856), (18, 0.6872556656599045), (53, 0.9773947671055794)]
computing accuracy for after removing block 45 . block score: 0.0425993874669075
removed block 45 current accuracy 0.8742 loss from initial  0.07720000000000005
since last training loss: 0.06540000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.044013. All blocks and scores: [(9, 0.04401258798316121), (51, 0.04409258812665939), (14, 0.04421631759032607), (6, 0.04692082433030009), (17, 0.04739647638052702), (4, 0.049388492945581675), (44, 0.05112889828160405), (13, 0.05141154630109668), (2, 0.05520011391490698), (11, 0.056598348543047905), (3, 0.05911137443035841), (19, 0.059270843397825956), (0, 0.06476115249097347), (1, 0.06675727479159832), (20, 0.07046912051737309), (52, 0.07104157190769911), (21, 0.07222959026694298), (8, 0.07285820133984089), (27, 0.07394244894385338), (25, 0.07851328793913126), (16, 0.07983639370650053), (10, 0.08368400391191244), (12, 0.08427658770233393), (37, 0.08560951240360737), (5, 0.1072248388081789), (36, 0.5060623958706856), (18, 0.6872556358575821), (53, 1.201029822230339)]
computing accuracy for after removing block 9 . block score: 0.04401258798316121
removed block 9 current accuracy 0.8456 loss from initial  0.1058
since last training loss: 0.09399999999999997 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 14, with score 0.040106. All blocks and scores: [(14, 0.040106127969920635), (51, 0.040652559604495764), (17, 0.04240868892520666), (6, 0.04692082526162267), (13, 0.04887221520766616), (4, 0.049388492945581675), (44, 0.050186989828944206), (11, 0.052205431275069714), (2, 0.05520011344924569), (3, 0.059111373499035835), (19, 0.06065563904121518), (0, 0.06476115435361862), (16, 0.06654499471187592), (1, 0.06675727851688862), (52, 0.06697865296155214), (20, 0.0686578219756484), (27, 0.06883080583065748), (12, 0.07254595775157213), (8, 0.07285819947719574), (21, 0.07398612517863512), (25, 0.07552370801568031), (37, 0.07829469535499811), (10, 0.08211077563464642), (5, 0.10722483415156603), (36, 0.4800580069422722), (18, 0.6617980152368546), (53, 1.2400642037391663)]
computing accuracy for after removing block 14 . block score: 0.040106127969920635
removed block 14 current accuracy 0.8148 loss from initial  0.13660000000000005
since last training loss: 0.12480000000000002 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.039062. All blocks and scores: [(51, 0.03906233794987202), (17, 0.04110721033066511), (6, 0.046920823864638805), (13, 0.04887221707031131), (4, 0.04938849341124296), (44, 0.04961901530623436), (11, 0.052205431275069714), (2, 0.05520011251792312), (19, 0.05871560936793685), (3, 0.05911137303337455), (52, 0.06321991793811321), (20, 0.06436315830796957), (0, 0.06476115342229605), (27, 0.06625091377645731), (1, 0.0667572757229209), (21, 0.07143279537558556), (12, 0.07254595682024956), (8, 0.07285820040851831), (25, 0.07289337553083897), (37, 0.07745554950088263), (10, 0.08211077284067869), (16, 0.08525089174509048), (5, 0.10722483322024345), (36, 0.475293654948473), (18, 0.6580713167786598), (53, 1.289917141199112)]
computing accuracy for after removing block 51 . block score: 0.03906233794987202
removed block 51 current accuracy 0.6968 loss from initial  0.25460000000000005
since last training loss: 0.24280000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 17, with score 0.041107. All blocks and scores: [(17, 0.041107209865003824), (6, 0.04692082339897752), (13, 0.04887221660465002), (4, 0.04938849247992039), (44, 0.04961901530623436), (11, 0.052205431275069714), (2, 0.05520011577755213), (19, 0.05871560936793685), (3, 0.059111375361680984), (52, 0.06264558481052518), (20, 0.06436315830796957), (0, 0.06476115342229605), (27, 0.06625091284513474), (1, 0.06675727665424347), (21, 0.0714327935129404), (12, 0.07254595682024956), (8, 0.07285819947719574), (25, 0.07289337553083897), (37, 0.07745554856956005), (10, 0.08211077190935612), (16, 0.08525089081376791), (5, 0.1072248388081789), (36, 0.47529366612434387), (18, 0.6580713391304016), (53, 1.5591864436864853)]
computing accuracy for after removing block 17 . block score: 0.041107209865003824
removed block 17 current accuracy 0.6878 loss from initial  0.26360000000000006
since last training loss: 0.2518 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.046921. All blocks and scores: [(6, 0.04692082433030009), (44, 0.048546028789132833), (13, 0.04887221613898873), (4, 0.04938849387690425), (11, 0.052205431275069714), (2, 0.05520011344924569), (19, 0.05894052982330322), (3, 0.05911137396469712), (52, 0.060886886436492205), (20, 0.06363942846655846), (27, 0.0646934611722827), (0, 0.06476115342229605), (1, 0.06675727386027575), (25, 0.07125404290854931), (21, 0.07243664376437664), (12, 0.07254595682024956), (8, 0.07285820040851831), (37, 0.07391976937651634), (10, 0.08211077190935612), (16, 0.08525088615715504), (5, 0.10722483694553375), (36, 0.4590597599744797), (18, 0.6417338252067566), (53, 1.5322620421648026)]
computing accuracy for after removing block 6 . block score: 0.04692082433030009
removed block 6 current accuracy 0.6006 loss from initial  0.3508
since last training loss: 0.33899999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 13, with score 0.046074. All blocks and scores: [(13, 0.04607368167489767), (11, 0.04777836613357067), (44, 0.04815689008682966), (4, 0.04938849341124296), (2, 0.05520011577755213), (52, 0.056230333633720875), (19, 0.057270513847470284), (20, 0.058858634904026985), (3, 0.05911137210205197), (27, 0.0604939479380846), (0, 0.06476115342229605), (1, 0.0667572757229209), (16, 0.06735195126384497), (12, 0.06755383219569921), (25, 0.06756839528679848), (37, 0.07105495594441891), (21, 0.07123606745153666), (8, 0.07181088346987963), (10, 0.08579988684505224), (5, 0.1072248388081789), (36, 0.44886578619480133), (18, 0.6372637003660202), (53, 1.5714234113693237)]
computing accuracy for after removing block 13 . block score: 0.04607368167489767
removed block 13 current accuracy 0.5068 loss from initial  0.4446
since last training loss: 0.43279999999999996 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 44, with score 0.047262. All blocks and scores: [(44, 0.0472616539336741), (11, 0.047778367064893246), (4, 0.04938849247992039), (52, 0.05154051631689072), (2, 0.05520011484622955), (20, 0.05525436345487833), (19, 0.05850983038544655), (27, 0.05903162294998765), (3, 0.05911137256771326), (0, 0.0647611515596509), (25, 0.06675070524215698), (1, 0.0667572757229209), (12, 0.06755383126437664), (37, 0.06835429091006517), (21, 0.07075103837996721), (8, 0.0718108844012022), (16, 0.07803756184875965), (10, 0.08579988963901997), (5, 0.10722483694553375), (36, 0.43411631137132645), (18, 0.6437123343348503), (53, 1.6485528945922852)]
computing accuracy for after removing block 44 . block score: 0.0472616539336741
removed block 44 current accuracy 0.3938 loss from initial  0.5576000000000001
training start
training epoch 0 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best True lr [0.1]
training epoch 1 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.1]
training epoch 2 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best True lr [0.1]
training epoch 3 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best True lr [0.1]
training epoch 4 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 5 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 6 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 7 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 8 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.1]
training epoch 10 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.933200)
finished training. finished 50 epochs. accuracy 0.9332 topk_dict {'top1': 0.9332}
start iteration 33
[activation diff]: block to remove picked: 19, with score 0.063226. All blocks and scores: [(19, 0.06322610471397638), (52, 0.06985727231949568), (4, 0.07713466137647629), (21, 0.09391559567302465), (0, 0.09741399809718132), (2, 0.09834218584001064), (20, 0.0997688490897417), (1, 0.10034924652427435), (27, 0.10124407522380352), (25, 0.10596187878400087), (37, 0.12325424794107676), (3, 0.12828815076500177), (11, 0.14399783313274384), (8, 0.17975510470569134), (10, 0.18568996526300907), (16, 0.25391238927841187), (5, 0.2747272923588753), (12, 0.2952127680182457), (36, 0.4567968510091305), (18, 0.7009202614426613), (53, 0.8312370553612709)]
computing accuracy for after removing block 19 . block score: 0.06322610471397638
removed block 19 current accuracy 0.9148 loss from initial  0.03660000000000008
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 52, with score 0.063890. All blocks and scores: [(52, 0.06389011861756444), (4, 0.07713466230779886), (21, 0.08819878753274679), (20, 0.09428923577070236), (25, 0.094773487187922), (27, 0.09503600280731916), (0, 0.09741399623453617), (2, 0.09834218770265579), (1, 0.10034924559295177), (37, 0.12335263937711716), (3, 0.12828815169632435), (11, 0.14399783499538898), (8, 0.17975509725511074), (10, 0.18568996153771877), (16, 0.2539123874157667), (5, 0.2747272960841656), (12, 0.2952127568423748), (36, 0.4453052245080471), (18, 0.7009202614426613), (53, 0.8418407216668129)]
computing accuracy for after removing block 52 . block score: 0.06389011861756444
removed block 52 current accuracy 0.859 loss from initial  0.09240000000000004
since last training loss: 0.07420000000000004 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 4, with score 0.077135. All blocks and scores: [(4, 0.07713466137647629), (21, 0.08819878753274679), (20, 0.09428923390805721), (25, 0.09477348811924458), (27, 0.09503600187599659), (0, 0.09741399716585875), (2, 0.09834218863397837), (1, 0.10034924745559692), (37, 0.1233526412397623), (3, 0.12828815542161465), (11, 0.14399783685803413), (8, 0.1797551028430462), (10, 0.18568996712565422), (16, 0.25391238555312157), (5, 0.274727288633585), (12, 0.2952127605676651), (36, 0.4453052282333374), (18, 0.7009202688932419), (53, 1.0080905705690384)]
computing accuracy for after removing block 4 . block score: 0.07713466137647629
removed block 4 current accuracy 0.844 loss from initial  0.10740000000000005
since last training loss: 0.08920000000000006 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 21, with score 0.085742. All blocks and scores: [(21, 0.08574185520410538), (20, 0.09040528535842896), (25, 0.09293225035071373), (27, 0.09341163374483585), (0, 0.09741399623453617), (2, 0.09834219049662352), (1, 0.10034924652427435), (37, 0.12115977425128222), (3, 0.12828815262764692), (11, 0.1356361173093319), (10, 0.18437692523002625), (8, 0.19104099832475185), (16, 0.2349365781992674), (12, 0.2724802643060684), (5, 0.28770336881279945), (36, 0.43601709231734276), (18, 0.6896590813994408), (53, 0.9685134142637253)]
computing accuracy for after removing block 21 . block score: 0.08574185520410538
removed block 21 current accuracy 0.8292 loss from initial  0.12219999999999998
since last training loss: 0.10399999999999998 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 27, with score 0.082194. All blocks and scores: [(27, 0.08219391759485006), (25, 0.08763952646404505), (20, 0.09040528628975153), (0, 0.09741400089114904), (2, 0.09834219049662352), (1, 0.10034924559295177), (37, 0.1123946774750948), (3, 0.12828815449029207), (11, 0.1356361135840416), (10, 0.1843769233673811), (8, 0.1910409927368164), (16, 0.2349365744739771), (12, 0.2724802643060684), (5, 0.28770337253808975), (36, 0.40516551584005356), (18, 0.689659096300602), (53, 0.8289553970098495)]
computing accuracy for after removing block 27 . block score: 0.08219391759485006
removed block 27 current accuracy 0.774 loss from initial  0.1774
since last training loss: 0.1592 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 25, with score 0.087640. All blocks and scores: [(25, 0.08763952553272247), (20, 0.09040528535842896), (0, 0.0974139953032136), (2, 0.09834219049662352), (1, 0.10034924559295177), (37, 0.11740674823522568), (3, 0.12828815449029207), (11, 0.13563611544668674), (10, 0.18437692523002625), (8, 0.19104099832475185), (16, 0.2349365781992674), (12, 0.2724802605807781), (5, 0.28770337253808975), (36, 0.4135524183511734), (18, 0.6896590813994408), (53, 0.8764439672231674)]
computing accuracy for after removing block 25 . block score: 0.08763952553272247
removed block 25 current accuracy 0.709 loss from initial  0.24240000000000006
since last training loss: 0.22420000000000007 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 20, with score 0.090405. All blocks and scores: [(20, 0.09040528535842896), (0, 0.09741399623453617), (2, 0.09834218770265579), (1, 0.1003492446616292), (37, 0.1248212568461895), (3, 0.12828815542161465), (11, 0.1356361135840416), (10, 0.1843769196420908), (8, 0.19104099832475185), (16, 0.2349365781992674), (12, 0.2724802568554878), (5, 0.28770337998867035), (36, 0.42814991250634193), (18, 0.689659059047699), (53, 0.8538854867219925)]
computing accuracy for after removing block 20 . block score: 0.09040528535842896
removed block 20 current accuracy 0.64 loss from initial  0.3114
since last training loss: 0.2932 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 0, with score 0.097414. All blocks and scores: [(0, 0.09741399809718132), (2, 0.09834218956530094), (1, 0.10034924559295177), (3, 0.1282881572842598), (11, 0.13563611544668674), (37, 0.13787134364247322), (10, 0.18437692150473595), (8, 0.19104099832475185), (16, 0.2349365781992674), (12, 0.272480271756649), (5, 0.28770337253808975), (36, 0.4587256498634815), (18, 0.6896590888500214), (53, 0.9063243716955185)]
computing accuracy for after removing block 0 . block score: 0.09741399809718132
removed block 0 current accuracy 0.5728 loss from initial  0.37860000000000005
since last training loss: 0.36040000000000005 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 1, with score 0.096944. All blocks and scores: [(1, 0.0969436764717102), (2, 0.10304367635399103), (3, 0.11490913853049278), (11, 0.13051720894873142), (37, 0.1381358727812767), (10, 0.16615665704011917), (8, 0.17496203817427158), (16, 0.21426072716712952), (5, 0.26213374733924866), (12, 0.2715335823595524), (36, 0.45953352749347687), (18, 0.6734954491257668), (53, 0.9380704015493393)]
computing accuracy for after removing block 1 . block score: 0.0969436764717102
removed block 1 current accuracy 0.4366 loss from initial  0.5148
since last training loss: 0.49660000000000004 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 3, with score 0.109923. All blocks and scores: [(3, 0.10992339067161083), (2, 0.11035315692424774), (11, 0.11587986350059509), (37, 0.138381140306592), (10, 0.14912398718297482), (8, 0.15485933981835842), (16, 0.169615363702178), (5, 0.2298882771283388), (12, 0.24357442744076252), (36, 0.45517589151859283), (18, 0.6504228562116623), (53, 0.9627981260418892)]
computing accuracy for after removing block 3 . block score: 0.10992339067161083
removed block 3 current accuracy 0.337 loss from initial  0.6144000000000001
since last training loss: 0.5962000000000001 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 11, with score 0.108355. All blocks and scores: [(11, 0.10835549142211676), (2, 0.11035315599292517), (37, 0.13093292899429798), (16, 0.13569721393287182), (8, 0.15735961869359016), (10, 0.15977586433291435), (12, 0.22725047171115875), (5, 0.24467510357499123), (36, 0.4313114434480667), (18, 0.6066097021102905), (53, 0.8986721262335777)]
computing accuracy for after removing block 11 . block score: 0.10835549142211676
removed block 11 current accuracy 0.2756 loss from initial  0.6758
since last training loss: 0.6576 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 2, with score 0.110353. All blocks and scores: [(2, 0.11035315971821547), (16, 0.11202068626880646), (37, 0.12753725983202457), (8, 0.15735961683094501), (10, 0.15977586433291435), (12, 0.23300303146243095), (5, 0.24467509053647518), (36, 0.4223146140575409), (18, 0.6174388378858566), (53, 0.9559691771864891)]
computing accuracy for after removing block 2 . block score: 0.11035315971821547
removed block 2 current accuracy 0.184 loss from initial  0.7674000000000001
training start
training epoch 0 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best True lr [0.1]
training epoch 1 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best True lr [0.1]
training epoch 2 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 3 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best False lr [0.1]
training epoch 4 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best True lr [0.1]
training epoch 5 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.1]
training epoch 6 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 7 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 8 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 9 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 10 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.919400)
finished training. finished 50 epochs. accuracy 0.9194 topk_dict {'top1': 0.9194}
