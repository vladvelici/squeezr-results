start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013294661301188171), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590224768966436), (25, 0.022078294772654772), (23, 0.02222871594130993), (41, 0.02233641571365297), (44, 0.023145999060943723), (40, 0.023749590385705233), (45, 0.023975495249032974), (21, 0.02494108909741044), (48, 0.02495770761743188), (22, 0.025151390582323074), (50, 0.025287173688411713), (24, 0.025880582630634308), (49, 0.02591664856299758), (42, 0.02623223257251084), (20, 0.026848892914131284), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129551947117), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0379180321469903), (51, 0.041787587106227875), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144290164113045), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.06606104224920273), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117432847619057), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589151144028), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013119243551045656), (29, 0.013421116746030748), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019852687371894717), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.02357383049093187), (45, 0.023648238042369485), (48, 0.0245402161963284), (50, 0.024770823074504733), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02557574026286602), (24, 0.025880582397803664), (42, 0.02589341322891414), (20, 0.02684889198280871), (47, 0.028072759974747896), (38, 0.031091188546270132), (39, 0.031191360903903842), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03797321068122983), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464367970824), (52, 0.0649335184134543), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671144165098667), (36, 0.4339806102216244), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589151144028
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581640593708), (34, 0.01275888190139085), (29, 0.013421116746030748), (35, 0.01591842109337449), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.02182762883603573), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.02377084968611598), (48, 0.024519873782992363), (50, 0.024639350594952703), (21, 0.024941090727224946), (22, 0.025151390116661787), (49, 0.025392549810931087), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848892448469996), (47, 0.028052504872903228), (38, 0.030935874208807945), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.03254077769815922), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06441722949966788), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.435020312666893), (18, 0.5117432996630669), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116513200104), (35, 0.01591864973306656), (26, 0.016072140773758292), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.019867350114509463), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.02435004524886608), (50, 0.024463105481117964), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025246930541470647), (42, 0.025273551233112812), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.02772757480852306), (38, 0.03074627462774515), (39, 0.03128179535269737), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540780026465654), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577403236180544), (3, 0.05784992827102542), (13, 0.05914428550750017), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06356756249442697), (1, 0.06593216303735971), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.4377692975103855), (18, 0.5117433145642281), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.01342111686244607), (35, 0.015968911815434694), (26, 0.01607214054092765), (28, 0.01763686165213585), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.020137187326326966), (41, 0.021584055153653026), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.02356909797526896), (45, 0.023840720998123288), (48, 0.024108358891680837), (50, 0.024114209692925215), (49, 0.024870117660611868), (21, 0.02494108979590237), (42, 0.02504557464271784), (22, 0.025151389883831143), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027423851657658815), (38, 0.030735649401322007), (39, 0.031410424038767815), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.039083510637283325), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525531575084), (52, 0.0627010790631175), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141472250223), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.023045077454298735), (48, 0.024024546146392822), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922372307628393), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027568296063691378), (38, 0.03178726346231997), (15, 0.0320583856664598), (39, 0.03225791407749057), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525485008955), (52, 0.06221094820648432), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019856703700497746), (46, 0.019988976418972015), (41, 0.021256205160170794), (25, 0.022078295703977346), (23, 0.02222871594130993), (44, 0.022692032624036074), (48, 0.023521370720118284), (50, 0.023533890256658196), (40, 0.023616241058334708), (45, 0.02393329213373363), (49, 0.024449915625154972), (42, 0.024838327895849943), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880583096295595), (47, 0.026813456090167165), (20, 0.026848892215639353), (38, 0.03108373167924583), (39, 0.032056889962404966), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03907974902540445), (37, 0.040152144618332386), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789771977812052), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.05970003269612789), (52, 0.06036907387897372), (17, 0.061325253918766975), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4432784505188465), (18, 0.5117432847619057), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143317230046), (28, 0.016986021539196372), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700076896697283), (41, 0.020515799522399902), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022507571382448077), (48, 0.02289936924353242), (50, 0.02293772785924375), (40, 0.023057402577251196), (42, 0.023520407499745488), (45, 0.023633699864149094), (49, 0.02408191910944879), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026322791818529367), (20, 0.026848892448469996), (38, 0.03014914900995791), (39, 0.03146669617854059), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.037851928267627954), (37, 0.039268902502954006), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992780536413), (52, 0.05846811877563596), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216396868229), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43490004166960716), (18, 0.5117432996630669), (53, 0.8595060780644417)]
computing accuracy for after removing block 35 . block score: 0.015504143317230046
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381991423666477), (27, 0.01876970916055143), (46, 0.018842301797121763), (41, 0.019016370177268982), (48, 0.021309157134965062), (50, 0.021624521585181355), (44, 0.021748854545876384), (40, 0.021916967118158937), (42, 0.02193037373945117), (25, 0.022078295005485415), (23, 0.022228716174140573), (45, 0.022736448794603348), (49, 0.022970063611865044), (21, 0.02494108909741044), (22, 0.025151390116661787), (47, 0.025355831254273653), (24, 0.025880582630634308), (20, 0.026848892215639353), (38, 0.028691887389868498), (39, 0.02962443232536316), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03601635713130236), (37, 0.03643036866560578), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789771977812052), (4, 0.04852241324260831), (2, 0.054577404633164406), (52, 0.054668578784912825), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.0613252529874444), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.41641608253121376), (18, 0.5117432996630669), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.018358625005930662), (41, 0.018467807676643133), (27, 0.01876970869489014), (48, 0.020775508601218462), (42, 0.021206470439210534), (50, 0.0213024471886456), (44, 0.021586895687505603), (40, 0.021592722507193685), (25, 0.022078294772654772), (23, 0.02222871547564864), (45, 0.02231529331766069), (49, 0.022407567594200373), (47, 0.024609397165477276), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.02588058286346495), (20, 0.026848891517147422), (38, 0.027890325989574194), (39, 0.02919189492240548), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03550667688250542), (37, 0.03591922763735056), (9, 0.043376325629651546), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241277694702), (52, 0.05337408231571317), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428876712918), (11, 0.059700032230466604), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.9067213088274002)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.01846780674532056), (27, 0.018769708229228854), (46, 0.018994681304320693), (42, 0.02120647020637989), (48, 0.02141889533959329), (50, 0.021441321587190032), (40, 0.021592722740024328), (25, 0.022078294539824128), (23, 0.022228715708479285), (49, 0.022339017828926444), (44, 0.02278283331543207), (45, 0.0233231068123132), (21, 0.024941088631749153), (22, 0.025151390582323074), (47, 0.025386078283190727), (24, 0.02588058332912624), (20, 0.02684889198280871), (38, 0.027890324592590332), (39, 0.029191894689574838), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (51, 0.03521771728992462), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.048522412311285734), (52, 0.05213337345048785), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4126182049512863), (18, 0.5117432922124863), (53, 0.9521221145987511)]
computing accuracy for after removing block 41 . block score: 0.01846780674532056
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 1 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.1]
training epoch 2 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 3 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.1]
training epoch 4 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.1]
training epoch 5 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.1]
training epoch 6 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.1]
training epoch 7 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.1]
training epoch 8 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.1]
training epoch 9 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.1]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 11
[activation diff]: block to remove picked: 45, with score 0.010822. All blocks and scores: [(45, 0.010822414653375745), (46, 0.011307732434943318), (44, 0.013952107285149395), (42, 0.01735051814466715), (40, 0.018981973873451352), (38, 0.02148972894065082), (23, 0.02228951407596469), (21, 0.025089521193876863), (22, 0.02520443662069738), (24, 0.026145859388634562), (37, 0.02656874363310635), (50, 0.026628291700035334), (49, 0.027152447029948235), (20, 0.027192406356334686), (48, 0.02844785782508552), (39, 0.03146768105216324), (15, 0.03209212655201554), (27, 0.032196590676903725), (19, 0.03258975641801953), (7, 0.03263504011556506), (47, 0.03313389513641596), (25, 0.03474484896287322), (51, 0.042133284732699394), (9, 0.043806318659335375), (4, 0.04604517761617899), (6, 0.046161666978150606), (14, 0.04795382125303149), (2, 0.05442681536078453), (3, 0.05732699017971754), (13, 0.059236782137304544), (11, 0.05960895773023367), (17, 0.062191763427108526), (0, 0.06356520717963576), (1, 0.06694106850773096), (52, 0.06797307636588812), (8, 0.07484674826264381), (10, 0.08077800460159779), (16, 0.0853508859872818), (12, 0.09036535862833261), (5, 0.10639385785907507), (36, 0.3944604881107807), (18, 0.5121545568108559), (53, 0.8010002225637436)]
computing accuracy for after removing block 45 . block score: 0.010822414653375745
removed block 45 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.011523. All blocks and scores: [(46, 0.011523093795403838), (44, 0.013952107052318752), (42, 0.01735051698051393), (40, 0.018981973407790065), (38, 0.02148972894065082), (23, 0.022289514308795333), (21, 0.02508952165953815), (22, 0.02520443662069738), (24, 0.02614585915580392), (37, 0.026568744098767638), (50, 0.02669872110709548), (49, 0.02701718406751752), (20, 0.027192406123504043), (48, 0.02847651205956936), (39, 0.03146768151782453), (15, 0.032092126086354256), (27, 0.032196590676903725), (19, 0.032589754555374384), (7, 0.032635039649903774), (47, 0.03363263653591275), (25, 0.03474484896287322), (51, 0.04147933982312679), (9, 0.04380631912499666), (4, 0.04604517901316285), (6, 0.04616166790947318), (14, 0.047953818924725056), (2, 0.054426818154752254), (3, 0.057326989248394966), (13, 0.05923678306862712), (11, 0.05960895773023367), (17, 0.06219176575541496), (0, 0.06356520811095834), (52, 0.06567252147942781), (1, 0.06694107037037611), (8, 0.07484674639999866), (10, 0.08077800367027521), (16, 0.0853508859872818), (12, 0.09036535862833261), (5, 0.1063938532024622), (36, 0.3944604694843292), (18, 0.5121545493602753), (53, 0.8621595948934555)]
computing accuracy for after removing block 46 . block score: 0.011523093795403838
removed block 46 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.013952. All blocks and scores: [(44, 0.013952107052318752), (42, 0.017350517213344574), (40, 0.01898197364062071), (38, 0.021489728474989533), (23, 0.022289515007287264), (21, 0.02508952165953815), (22, 0.02520443662069738), (24, 0.026145859621465206), (37, 0.026568743167445064), (20, 0.02719240658916533), (49, 0.027442493475973606), (50, 0.027871161699295044), (48, 0.028448137687519193), (39, 0.03146768198348582), (15, 0.03209212562069297), (27, 0.03219658974558115), (19, 0.032589754555374384), (7, 0.032635039649903774), (47, 0.034646175801754), (25, 0.03474484849721193), (51, 0.041354057379066944), (9, 0.04380631959065795), (4, 0.04604517761617899), (6, 0.046161666978150606), (14, 0.04795381939038634), (2, 0.05442681768909097), (3, 0.05732698971405625), (13, 0.059236783534288406), (11, 0.05960895726457238), (17, 0.062191763427108526), (0, 0.06356520485132933), (52, 0.06518727028742433), (1, 0.06694106850773096), (8, 0.07484675012528896), (10, 0.08077800273895264), (16, 0.0853508859872818), (12, 0.09036535955965519), (5, 0.1063938569277525), (36, 0.3944604732096195), (18, 0.5121545568108559), (53, 0.9031049832701683)]
computing accuracy for after removing block 44 . block score: 0.013952107052318752
removed block 44 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.017351. All blocks and scores: [(42, 0.017350517213344574), (40, 0.01898197364062071), (38, 0.021489729406312108), (23, 0.022289513610303402), (21, 0.025089522125199437), (22, 0.025204437552019954), (49, 0.025956187397241592), (24, 0.026145858922973275), (37, 0.026568744098767638), (20, 0.02719240658916533), (48, 0.02737289690412581), (50, 0.027391809970140457), (39, 0.03146768105216324), (15, 0.03209212562069297), (27, 0.03219658974558115), (19, 0.03258975548669696), (7, 0.03263503918424249), (25, 0.03474484896287322), (47, 0.035210035275667906), (51, 0.0407069674693048), (9, 0.04380632005631924), (4, 0.046045178547501564), (6, 0.046161665581166744), (14, 0.04795382032170892), (2, 0.05442681768909097), (3, 0.05732699017971754), (13, 0.05923678074032068), (11, 0.05960895912721753), (17, 0.0621917643584311), (0, 0.06356520624831319), (52, 0.06429827492684126), (1, 0.06694107130169868), (8, 0.07484674826264381), (10, 0.08077800273895264), (16, 0.08535088505595922), (12, 0.09036535583436489), (5, 0.10639385599642992), (36, 0.3944604881107807), (18, 0.5121545568108559), (53, 0.9925501421093941)]
computing accuracy for after removing block 42 . block score: 0.017350517213344574
removed block 42 current accuracy 0.927 loss from initial  0.024399999999999977
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.018982. All blocks and scores: [(40, 0.018981973407790065), (38, 0.02148972894065082), (23, 0.022289515007287264), (21, 0.02508952165953815), (22, 0.02520443662069738), (24, 0.026145860087126493), (49, 0.026245676912367344), (37, 0.026568744331598282), (20, 0.02719240658916533), (48, 0.027616257779300213), (50, 0.027778687421232462), (39, 0.03146768151782453), (15, 0.03209212655201554), (27, 0.03219658974558115), (19, 0.032589754555374384), (7, 0.03263504011556506), (25, 0.03474484896287322), (47, 0.0369850997813046), (51, 0.041034241672605276), (9, 0.04380632005631924), (4, 0.04604517808184028), (6, 0.04616166744381189), (14, 0.04795382032170892), (2, 0.05442681675776839), (3, 0.05732699064537883), (13, 0.059236782137304544), (11, 0.05960895819589496), (17, 0.06219176296144724), (0, 0.06356520811095834), (52, 0.06681825779378414), (1, 0.06694107130169868), (8, 0.07484674733132124), (10, 0.08077800367027521), (16, 0.08535088319331408), (12, 0.09036535862833261), (5, 0.10639385133981705), (36, 0.3944604732096195), (18, 0.5121545717120171), (53, 1.0520261824131012)]
computing accuracy for after removing block 40 . block score: 0.018981973407790065
removed block 40 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.021490. All blocks and scores: [(38, 0.02148972894065082), (23, 0.022289513843134046), (21, 0.025089521426707506), (22, 0.025204436853528023), (49, 0.025545679032802582), (24, 0.02614585915580392), (50, 0.026333034271374345), (37, 0.026568743865936995), (48, 0.026713797356933355), (20, 0.027192406821995974), (39, 0.03146768198348582), (15, 0.032092126086354256), (27, 0.032196588814258575), (19, 0.0325897540897131), (7, 0.03263504011556506), (25, 0.03474484896287322), (47, 0.03687514225021005), (51, 0.04000871069729328), (9, 0.043806318659335375), (4, 0.04604517947882414), (6, 0.04616166511550546), (14, 0.04795382032170892), (2, 0.05442681675776839), (3, 0.05732698831707239), (13, 0.05923678260296583), (11, 0.05960895819589496), (17, 0.0621917643584311), (0, 0.06356520531699061), (52, 0.06379725690931082), (1, 0.06694107037037611), (8, 0.07484675012528896), (10, 0.08077800180763006), (16, 0.08535088691860437), (12, 0.09036535769701004), (5, 0.1063938494771719), (36, 0.3944604657590389), (18, 0.5121545568108559), (53, 1.1324877589941025)]
computing accuracy for after removing block 38 . block score: 0.02148972894065082
removed block 38 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04159999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.022290. All blocks and scores: [(23, 0.02228951407596469), (50, 0.02462037792429328), (49, 0.024655173299834132), (21, 0.025089521892368793), (22, 0.025204436155036092), (48, 0.025236426619812846), (24, 0.026145858922973275), (37, 0.026568744564428926), (20, 0.027192407520487905), (15, 0.03209212655201554), (27, 0.03219658974558115), (19, 0.03258975548669696), (7, 0.032635039649903774), (39, 0.03428291529417038), (25, 0.03474484896287322), (47, 0.03523461800068617), (51, 0.038677198346704245), (9, 0.04380632005631924), (4, 0.04604517761617899), (6, 0.04616166604682803), (14, 0.04795382032170892), (2, 0.05442681722342968), (3, 0.05732698831707239), (52, 0.058911184314638376), (13, 0.059236783534288406), (11, 0.05960895726457238), (17, 0.06219176575541496), (0, 0.06356520624831319), (1, 0.06694106943905354), (8, 0.07484674826264381), (10, 0.08077800367027521), (16, 0.08535088505595922), (12, 0.09036536235362291), (5, 0.10639385506510735), (36, 0.3944604732096195), (18, 0.5121545717120171), (53, 1.1803010553121567)]
computing accuracy for after removing block 23 . block score: 0.02228951407596469
removed block 23 current accuracy 0.9002 loss from initial  0.05120000000000002
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.023931. All blocks and scores: [(50, 0.02393148303963244), (49, 0.02449153456836939), (48, 0.024715231033042073), (24, 0.02480463986285031), (21, 0.02508952165953815), (22, 0.025204435922205448), (37, 0.027059624902904034), (20, 0.027192406356334686), (27, 0.031397628830745816), (15, 0.032092126086354256), (19, 0.03258975548669696), (7, 0.03263503918424249), (25, 0.033059468027204275), (47, 0.03381182346493006), (39, 0.03429931774735451), (51, 0.03835880942642689), (9, 0.04380631912499666), (4, 0.04604517947882414), (6, 0.04616166651248932), (14, 0.04795381985604763), (2, 0.05442681582644582), (52, 0.057059822138398886), (3, 0.05732698831707239), (13, 0.059236782137304544), (11, 0.059608958661556244), (17, 0.062191763427108526), (0, 0.06356520764529705), (1, 0.06694107037037611), (8, 0.07484674919396639), (10, 0.08077800180763006), (16, 0.08535088691860437), (12, 0.09036536049097776), (5, 0.10639385599642992), (36, 0.3915047310292721), (18, 0.5121545493602753), (53, 1.193369835615158)]
computing accuracy for after removing block 50 . block score: 0.02393148303963244
removed block 50 current accuracy 0.8902 loss from initial  0.06120000000000003
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.024492. All blocks and scores: [(49, 0.02449153526686132), (48, 0.02471523080021143), (24, 0.024804640095680952), (21, 0.025089521426707506), (22, 0.025204436387866735), (37, 0.027059624902904034), (20, 0.027192405657842755), (27, 0.03139762789942324), (15, 0.03209212562069297), (19, 0.032589754555374384), (7, 0.032635039649903774), (25, 0.03305946895852685), (47, 0.03381182439625263), (39, 0.03429931774735451), (51, 0.04158993670716882), (9, 0.04380631726235151), (4, 0.046045178547501564), (6, 0.04616166651248932), (14, 0.04795381985604763), (2, 0.05442681862041354), (3, 0.05732698971405625), (13, 0.05923678260296583), (11, 0.059608958661556244), (17, 0.062191763892769814), (0, 0.0635652057826519), (52, 0.06584420800209045), (1, 0.06694106943905354), (8, 0.07484675012528896), (10, 0.08077800180763006), (16, 0.08535088691860437), (12, 0.09036535862833261), (5, 0.10639385785907507), (36, 0.3915047347545624), (18, 0.5121545642614365), (53, 1.4115101099014282)]
computing accuracy for after removing block 49 . block score: 0.02449153526686132
removed block 49 current accuracy 0.8622 loss from initial  0.08920000000000006
since last training loss: 0.08360000000000001 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 48, with score 0.024715. All blocks and scores: [(48, 0.024715230567380786), (24, 0.02480464056134224), (21, 0.025089521193876863), (22, 0.025204437552019954), (37, 0.027059624437242746), (20, 0.0271924058906734), (27, 0.03139762650243938), (15, 0.03209212562069297), (19, 0.03258975548669696), (7, 0.03263503918424249), (25, 0.03305946849286556), (47, 0.03381182253360748), (39, 0.03429931774735451), (51, 0.04325469397008419), (9, 0.04380631959065795), (4, 0.046045176684856415), (6, 0.04616166651248932), (14, 0.04795382032170892), (2, 0.05442681675776839), (3, 0.05732698971405625), (13, 0.05923678306862712), (11, 0.05960895819589496), (17, 0.06219176622107625), (0, 0.06356520717963576), (1, 0.06694107037037611), (52, 0.06753464788198471), (8, 0.07484674826264381), (10, 0.08077800367027521), (16, 0.08535088412463665), (12, 0.09036535955965519), (5, 0.10639385599642992), (36, 0.3915047347545624), (18, 0.5121545568108559), (53, 1.6032161563634872)]
computing accuracy for after removing block 48 . block score: 0.024715230567380786
removed block 48 current accuracy 0.8224 loss from initial  0.129
since last training loss: 0.12339999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.024805. All blocks and scores: [(24, 0.024804639630019665), (21, 0.025089521193876863), (22, 0.025204437086358666), (37, 0.02705962536856532), (20, 0.0271924058906734), (27, 0.03139762836508453), (15, 0.03209212655201554), (19, 0.03258975548669696), (7, 0.032635039649903774), (25, 0.033059468027204275), (47, 0.03381182253360748), (39, 0.03429931867867708), (51, 0.04244895000010729), (9, 0.04380632005631924), (4, 0.04604517947882414), (6, 0.046161665581166744), (14, 0.04795381939038634), (2, 0.054426818154752254), (3, 0.05732698878273368), (13, 0.05923678306862712), (11, 0.05960895773023367), (17, 0.06219176575541496), (0, 0.06356520531699061), (1, 0.06694106943905354), (8, 0.07484674826264381), (52, 0.07601307705044746), (10, 0.08077800273895264), (16, 0.0853508859872818), (12, 0.09036535955965519), (5, 0.10639385506510735), (36, 0.3915047384798527), (18, 0.5121545717120171), (53, 1.69520603120327)]
computing accuracy for after removing block 24 . block score: 0.024804639630019665
removed block 24 current accuracy 0.8084 loss from initial  0.14300000000000002
training start
training epoch 0 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 2 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 3 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.1]
training epoch 4 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.1]
training epoch 5 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 6 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 8 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 9 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.025080. All blocks and scores: [(21, 0.02508046361617744), (20, 0.027277448680251837), (15, 0.03230376774445176), (7, 0.032629520166665316), (19, 0.032692933920770884), (9, 0.0439580911770463), (6, 0.04675518628209829), (4, 0.04790989309549332), (14, 0.04812443535774946), (22, 0.04831487871706486), (2, 0.05470217810943723), (27, 0.05701420083642006), (3, 0.05804589716717601), (13, 0.059491151478141546), (11, 0.059644343331456184), (51, 0.06009179912507534), (17, 0.06205142196267843), (25, 0.06368146371096373), (0, 0.06395270582288504), (1, 0.06673616170883179), (47, 0.07415995839983225), (39, 0.07450821250677109), (8, 0.07478758692741394), (52, 0.07511560339480639), (10, 0.08153365831822157), (37, 0.08239463064819574), (16, 0.08580471575260162), (12, 0.09051614534109831), (5, 0.10662592202425003), (18, 0.5152595490217209), (36, 0.5193861722946167), (53, 1.4291212856769562)]
computing accuracy for after removing block 21 . block score: 0.02508046361617744
removed block 21 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.027277. All blocks and scores: [(20, 0.02727744751609862), (15, 0.03230376774445176), (7, 0.032629520166665316), (19, 0.03269293298944831), (22, 0.04369056271389127), (9, 0.043958090245723724), (6, 0.04675518674775958), (4, 0.047909894958138466), (14, 0.0481244376860559), (27, 0.05386130651459098), (2, 0.05470218090340495), (51, 0.05706573370844126), (3, 0.058045896235853434), (25, 0.05832424387335777), (13, 0.05949115054681897), (11, 0.05964434426277876), (17, 0.06205142196267843), (0, 0.06395270582288504), (1, 0.06673616077750921), (52, 0.0674626063555479), (47, 0.06880886480212212), (39, 0.07085468247532845), (8, 0.07478758785873652), (37, 0.07726891059428453), (10, 0.08153365552425385), (16, 0.08580471109598875), (12, 0.09051614254713058), (5, 0.10662592109292746), (36, 0.49089187756180763), (18, 0.5152595490217209), (53, 1.442118689417839)]
computing accuracy for after removing block 20 . block score: 0.02727744751609862
removed block 20 current accuracy 0.9238 loss from initial  0.02760000000000007
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032304. All blocks and scores: [(15, 0.03230376821011305), (7, 0.03262951970100403), (19, 0.03269293298944831), (22, 0.043610559310764074), (9, 0.0439580911770463), (6, 0.04675518628209829), (4, 0.04790989262983203), (14, 0.0481244376860559), (27, 0.05229712696745992), (2, 0.0547021790407598), (51, 0.055373209062963724), (25, 0.05631049582734704), (3, 0.05804589809849858), (13, 0.05949115240946412), (11, 0.059644341468811035), (17, 0.062051421497017145), (52, 0.06381740979850292), (0, 0.06395270675420761), (47, 0.06522048823535442), (1, 0.06673616170883179), (39, 0.069903832860291), (8, 0.07478758599609137), (37, 0.07815224956721067), (10, 0.08153365831822157), (16, 0.08580471482127905), (12, 0.09051614534109831), (5, 0.10662592202425003), (36, 0.488160889595747), (18, 0.5152595415711403), (53, 1.4107564836740494)]
computing accuracy for after removing block 15 . block score: 0.03230376821011305
removed block 15 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.02540000000000009 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032630. All blocks and scores: [(7, 0.032629520166665316), (19, 0.03295156080275774), (22, 0.041737405583262444), (9, 0.043958091642707586), (6, 0.04675518674775958), (4, 0.047909893561154604), (14, 0.0481244376860559), (27, 0.05067400773987174), (25, 0.05436983937397599), (2, 0.054702178575098515), (51, 0.055619383696466684), (3, 0.058045897632837296), (13, 0.05949115054681897), (11, 0.059644344728440046), (0, 0.06395270582288504), (52, 0.06437886040657759), (17, 0.06590329948812723), (47, 0.06609915010631084), (1, 0.06673616077750921), (39, 0.06980488821864128), (8, 0.07478758785873652), (37, 0.07902949955314398), (10, 0.08153365831822157), (12, 0.09051614813506603), (16, 0.09577640891075134), (5, 0.10662592109292746), (36, 0.4794757328927517), (18, 0.5026945061981678), (53, 1.4317169040441513)]
computing accuracy for after removing block 7 . block score: 0.032629520166665316
removed block 7 current accuracy 0.916 loss from initial  0.03539999999999999
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.032714. All blocks and scores: [(19, 0.032713633030653), (22, 0.03940201411023736), (9, 0.04385196138173342), (14, 0.044438254088163376), (6, 0.04675518674775958), (27, 0.04711203509941697), (4, 0.04790989402681589), (13, 0.05149685125797987), (25, 0.051919907331466675), (51, 0.0542141473852098), (2, 0.054702179972082376), (17, 0.055777665227651596), (11, 0.0563138872385025), (3, 0.058045895770192146), (52, 0.06240993179380894), (0, 0.06395270582288504), (47, 0.06434674188494682), (1, 0.06673615984618664), (39, 0.06898248847573996), (8, 0.07279177382588387), (37, 0.0732483547180891), (10, 0.08395146392285824), (12, 0.08459039684385061), (16, 0.08721952605992556), (5, 0.10662592016160488), (36, 0.4633636847138405), (18, 0.4859672598540783), (53, 1.4419661462306976)]
computing accuracy for after removing block 19 . block score: 0.032713633030653
removed block 19 current accuracy 0.8876 loss from initial  0.06380000000000008
since last training loss: 0.05460000000000009 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 22, with score 0.040446. All blocks and scores: [(22, 0.04044627118855715), (9, 0.04385196231305599), (14, 0.04443825501948595), (6, 0.046755185816437006), (27, 0.04685890534892678), (4, 0.04790989402681589), (25, 0.048753556329756975), (13, 0.05149685125797987), (51, 0.05353272706270218), (2, 0.054702178575098515), (17, 0.055777663830667734), (11, 0.05631388770416379), (3, 0.05804589809849858), (52, 0.05849530594423413), (47, 0.06060835067182779), (0, 0.06395270675420761), (1, 0.06673616170883179), (39, 0.06866404134780169), (8, 0.07279177382588387), (37, 0.07472168933600187), (10, 0.08395146299153566), (12, 0.08459039498120546), (16, 0.0872195279225707), (5, 0.10662592016160488), (36, 0.4697050489485264), (18, 0.4859672635793686), (53, 1.4143565446138382)]
computing accuracy for after removing block 22 . block score: 0.04044627118855715
removed block 22 current accuracy 0.8548 loss from initial  0.09660000000000002
since last training loss: 0.08740000000000003 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 27, with score 0.043445. All blocks and scores: [(27, 0.04344536503776908), (9, 0.043851961847394705), (14, 0.04443825455382466), (25, 0.04633842036128044), (6, 0.04675518628209829), (4, 0.04790989402681589), (51, 0.05085877003148198), (13, 0.051496852189302444), (52, 0.053627872839570045), (2, 0.05470218136906624), (17, 0.055777663830667734), (47, 0.0559982992708683), (11, 0.0563138872385025), (3, 0.05804589716717601), (0, 0.06395270675420761), (39, 0.06661869678646326), (1, 0.06673616077750921), (8, 0.07279177568852901), (37, 0.07672318816184998), (10, 0.08395146206021309), (12, 0.08459039218723774), (16, 0.08721952605992556), (5, 0.10662592109292746), (36, 0.4672979936003685), (18, 0.4859672859311104), (53, 1.4252129942178726)]
computing accuracy for after removing block 27 . block score: 0.04344536503776908
removed block 27 current accuracy 0.8282 loss from initial  0.12319999999999998
since last training loss: 0.11399999999999999 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043852. All blocks and scores: [(9, 0.043851961847394705), (14, 0.044438255950808525), (25, 0.04633842082694173), (6, 0.04675518535077572), (4, 0.047909894958138466), (51, 0.048818827606737614), (52, 0.050973852165043354), (13, 0.05149685079231858), (47, 0.054302494041621685), (2, 0.05470217950642109), (17, 0.05577766569331288), (11, 0.05631388770416379), (3, 0.05804589856415987), (0, 0.06395270489156246), (39, 0.066727289929986), (1, 0.06673616170883179), (8, 0.07279177475720644), (37, 0.08386568166315556), (10, 0.08395146206021309), (12, 0.08459039218723774), (16, 0.08721952885389328), (5, 0.10662592016160488), (36, 0.4761095158755779), (18, 0.4859672784805298), (53, 1.4622789770364761)]
computing accuracy for after removing block 9 . block score: 0.043851961847394705
removed block 9 current accuracy 0.7878 loss from initial  0.16360000000000008
since last training loss: 0.1544000000000001 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.040277. All blocks and scores: [(14, 0.04027724638581276), (25, 0.04398950096219778), (51, 0.04631899390369654), (6, 0.04675518628209829), (4, 0.04790989262983203), (13, 0.04887916427105665), (52, 0.04902096465229988), (17, 0.04973474983125925), (11, 0.051921356935054064), (47, 0.05458560911938548), (2, 0.05470217950642109), (3, 0.05804589530453086), (0, 0.06395270582288504), (39, 0.06551086530089378), (1, 0.06673616170883179), (16, 0.07172008883208036), (37, 0.0724291130900383), (12, 0.07276973780244589), (8, 0.07279177568852901), (10, 0.08237438462674618), (5, 0.10662592016160488), (36, 0.4483940415084362), (18, 0.4670753590762615), (53, 1.5008813440799713)]
computing accuracy for after removing block 14 . block score: 0.04027724638581276
removed block 14 current accuracy 0.7322 loss from initial  0.21920000000000006
since last training loss: 0.21000000000000008 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 25, with score 0.042371. All blocks and scores: [(25, 0.042371029034256935), (51, 0.04543639998883009), (6, 0.046755185816437006), (52, 0.047681538853794336), (4, 0.04790989449247718), (13, 0.048879165668040514), (17, 0.04928279435262084), (11, 0.051921358332037926), (47, 0.05393741838634014), (2, 0.0547021790407598), (3, 0.05804589670151472), (0, 0.06395270675420761), (39, 0.06480974331498146), (1, 0.06673616264015436), (12, 0.07276973966509104), (8, 0.07279177382588387), (37, 0.07440664898604155), (10, 0.08237438462674618), (16, 0.09443031344562769), (5, 0.10662591829895973), (36, 0.45090072974562645), (18, 0.4651275873184204), (53, 1.5386842787265778)]
computing accuracy for after removing block 25 . block score: 0.042371029034256935
removed block 25 current accuracy 0.6226 loss from initial  0.3288
since last training loss: 0.3196 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.046271. All blocks and scores: [(51, 0.04627132508903742), (6, 0.04675518535077572), (4, 0.04790989402681589), (52, 0.04804748622700572), (13, 0.048879165668040514), (17, 0.04928279621526599), (11, 0.05192135786637664), (2, 0.05470218136906624), (47, 0.05470758117735386), (3, 0.058045896235853434), (0, 0.06395270675420761), (1, 0.06673615984618664), (39, 0.06833710800856352), (12, 0.07276973966509104), (8, 0.07279177382588387), (10, 0.08237438835203648), (16, 0.09443031437695026), (37, 0.09445991273969412), (5, 0.1066259192302823), (18, 0.4651275984942913), (36, 0.5075673535466194), (53, 1.5860920697450638)]
computing accuracy for after removing block 51 . block score: 0.04627132508903742
removed block 51 current accuracy 0.4806 loss from initial  0.4708
training start
training epoch 0 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best True lr [0.1]
training epoch 1 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 2 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 3 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.1]
training epoch 5 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 6 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 9 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 10 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.935400)
finished training. finished 50 epochs. accuracy 0.9354 topk_dict {'top1': 0.9354}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.049259. All blocks and scores: [(4, 0.04925918439403176), (2, 0.054871350061148405), (3, 0.05760829756036401), (0, 0.06306771794334054), (1, 0.06640950962901115), (6, 0.07944364473223686), (11, 0.09451386611908674), (52, 0.09466754831373692), (47, 0.09887465741485357), (8, 0.10446213465183973), (5, 0.1057480238378048), (39, 0.1087996531277895), (37, 0.10889904387295246), (17, 0.12016456574201584), (13, 0.1216488154605031), (10, 0.1287588868290186), (12, 0.1596834845840931), (16, 0.1608305387198925), (18, 0.5633443668484688), (36, 0.570600114762783), (53, 1.545304611325264)]
computing accuracy for after removing block 4 . block score: 0.04925918439403176
removed block 4 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.054871. All blocks and scores: [(2, 0.05487134912982583), (3, 0.057608298026025295), (0, 0.06306771840900183), (1, 0.06640950869768858), (6, 0.08460696134716272), (11, 0.08823756873607635), (52, 0.09355285950005054), (47, 0.09788327571004629), (39, 0.10705961287021637), (37, 0.10995702724903822), (5, 0.11015359219163656), (8, 0.11031599435955286), (17, 0.11630922183394432), (13, 0.12084357813000679), (10, 0.12710724771022797), (16, 0.14717679470777512), (12, 0.1511496864259243), (18, 0.5619060918688774), (36, 0.5663180574774742), (53, 1.5024723559617996)]
computing accuracy for after removing block 2 . block score: 0.05487134912982583
removed block 2 current accuracy 0.909 loss from initial  0.04239999999999999
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.052680. All blocks and scores: [(3, 0.05267955036833882), (0, 0.06306771980598569), (1, 0.06640950869768858), (6, 0.07943291589617729), (11, 0.08207141607999802), (52, 0.08831454813480377), (47, 0.09459526743739843), (17, 0.09920217376202345), (37, 0.10060841497033834), (39, 0.1006385050714016), (5, 0.10693229641765356), (8, 0.1082090251147747), (13, 0.11673524603247643), (10, 0.12244751490652561), (16, 0.13611664436757565), (12, 0.13641272857785225), (18, 0.5088398605585098), (36, 0.5136928036808968), (53, 1.5138936191797256)]
computing accuracy for after removing block 3 . block score: 0.05267955036833882
removed block 3 current accuracy 0.8508 loss from initial  0.10060000000000002
since last training loss: 0.08460000000000001 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.063068. All blocks and scores: [(0, 0.06306772073730826), (1, 0.06640950962901115), (11, 0.07704299129545689), (6, 0.07823130767792463), (52, 0.0818139212206006), (17, 0.08768105041235685), (47, 0.09008644428104162), (39, 0.09275055583566427), (37, 0.0964333526790142), (8, 0.10271353740245104), (16, 0.10962696187198162), (5, 0.11057026125490665), (13, 0.11479651555418968), (10, 0.1257828688248992), (12, 0.12667832523584366), (18, 0.47215355560183525), (36, 0.47981052845716476), (53, 1.4898838698863983)]
computing accuracy for after removing block 0 . block score: 0.06306772073730826
removed block 0 current accuracy 0.7662 loss from initial  0.18520000000000003
since last training loss: 0.16920000000000002 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 1, with score 0.068582. All blocks and scores: [(1, 0.06858240906149149), (11, 0.07512604352086782), (52, 0.07851479668170214), (6, 0.08189671859145164), (17, 0.08500620443373919), (39, 0.09125491511076689), (47, 0.09284423943608999), (37, 0.0954383872449398), (8, 0.09895961266011), (16, 0.09946650266647339), (5, 0.10731243807822466), (13, 0.11609438993036747), (10, 0.11946936044842005), (12, 0.13636821322143078), (36, 0.4699391946196556), (18, 0.47312629222869873), (53, 1.5145820081233978)]
computing accuracy for after removing block 1 . block score: 0.06858240906149149
removed block 1 current accuracy 0.6066 loss from initial  0.3448
since last training loss: 0.3288 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.069810. All blocks and scores: [(11, 0.06981037650257349), (52, 0.07040799874812365), (17, 0.07442543469369411), (6, 0.08576217573136091), (39, 0.08932394720613956), (16, 0.08975379820913076), (8, 0.09187562298029661), (37, 0.09284321591258049), (47, 0.09320019651204348), (13, 0.09633204620331526), (5, 0.09703045152127743), (10, 0.11990671325474977), (12, 0.14153978787362576), (18, 0.44643134996294975), (36, 0.46133898571133614), (53, 1.4789169281721115)]
computing accuracy for after removing block 11 . block score: 0.06981037650257349
removed block 11 current accuracy 0.507 loss from initial  0.4444
since last training loss: 0.4284 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 52, with score 0.067930. All blocks and scores: [(52, 0.06793041247874498), (17, 0.07005493715405464), (16, 0.07688315119594336), (6, 0.08576217945665121), (39, 0.09007084649056196), (13, 0.09110361244529486), (8, 0.09187562391161919), (37, 0.0943374615162611), (5, 0.09703045152127743), (47, 0.1030128737911582), (10, 0.11990671418607235), (12, 0.13189814239740372), (18, 0.4399386793375015), (36, 0.45962678268551826), (53, 1.487502321600914)]
computing accuracy for after removing block 52 . block score: 0.06793041247874498
removed block 52 current accuracy 0.3994 loss from initial  0.552
since last training loss: 0.536 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.070055. All blocks and scores: [(17, 0.07005493622273207), (16, 0.07688315026462078), (6, 0.08576217666268349), (39, 0.09007084555923939), (13, 0.09110361151397228), (8, 0.09187562391161919), (37, 0.0943374615162611), (5, 0.09703045058995485), (47, 0.1030128737911582), (10, 0.11990671418607235), (12, 0.13189814053475857), (18, 0.4399386867880821), (36, 0.45962679013609886), (53, 1.293252781033516)]
computing accuracy for after removing block 17 . block score: 0.07005493622273207
removed block 17 current accuracy 0.341 loss from initial  0.6104
since last training loss: 0.5944 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 16, with score 0.076883. All blocks and scores: [(16, 0.0768831530585885), (39, 0.08287549577653408), (6, 0.08576217945665121), (13, 0.09110361244529486), (8, 0.09187562298029661), (5, 0.0970304524526), (37, 0.09837017022073269), (47, 0.10194373782724142), (10, 0.11990670952945948), (12, 0.13189814053475857), (18, 0.40822584182024), (36, 0.42827557772397995), (53, 1.3029531091451645)]
computing accuracy for after removing block 16 . block score: 0.0768831530585885
removed block 16 current accuracy 0.2166 loss from initial  0.7348
since last training loss: 0.7188 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 39, with score 0.082797. All blocks and scores: [(39, 0.08279713802039623), (6, 0.08576218131929636), (13, 0.09110361151397228), (8, 0.09187562577426434), (5, 0.09703045058995485), (47, 0.10812144540250301), (10, 0.1199067123234272), (37, 0.12106040492653847), (12, 0.13189814426004887), (18, 0.43855035305023193), (36, 0.4512980058789253), (53, 1.511974349617958)]
computing accuracy for after removing block 39 . block score: 0.08279713802039623
removed block 39 current accuracy 0.2102 loss from initial  0.7412000000000001
since last training loss: 0.7252000000000001 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 6, with score 0.085762. All blocks and scores: [(6, 0.08576217666268349), (13, 0.09110361244529486), (8, 0.09187562577426434), (5, 0.09703044965863228), (47, 0.1173408767208457), (10, 0.1199067123234272), (37, 0.12106040492653847), (12, 0.13189814426004887), (18, 0.43855035677552223), (36, 0.4512980058789253), (53, 1.5703568756580353)]
computing accuracy for after removing block 6 . block score: 0.08576217666268349
removed block 6 current accuracy 0.1988 loss from initial  0.7526
since last training loss: 0.7366 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 13, with score 0.074616. All blocks and scores: [(13, 0.07461570668965578), (8, 0.09140295628458261), (5, 0.09703045152127743), (10, 0.11180497612804174), (47, 0.11211284063756466), (12, 0.11742924433201551), (37, 0.11984119471162558), (36, 0.4251163899898529), (18, 0.43229278177022934), (53, 1.198425829410553)]
computing accuracy for after removing block 13 . block score: 0.07461570668965578
removed block 13 current accuracy 0.154 loss from initial  0.7974
training start
training epoch 0 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best True lr [0.1]
training epoch 1 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best True lr [0.1]
training epoch 2 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 3 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 4 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 5 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 6 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 7 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 8 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 9 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 10 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.926000)
finished training. finished 50 epochs. accuracy 0.926 topk_dict {'top1': 0.926}
