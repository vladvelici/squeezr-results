start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589733220637), (30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.013294660951942205), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01999649195931852), (46, 0.020590225467458367), (25, 0.02207829523831606), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.023145999060943723), (40, 0.02374959085136652), (45, 0.023975495481863618), (21, 0.024941090028733015), (48, 0.024957707384601235), (22, 0.02515139034949243), (50, 0.025287173688411713), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.026232233038172126), (20, 0.02684889198280871), (47, 0.02863294817507267), (38, 0.03134434390813112), (39, 0.03144129482097924), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.0417875861749053), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464647367597), (1, 0.06593216396868229), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.8053385019302368)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013119243667460978), (29, 0.013421116978861392), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019852688070386648), (46, 0.020300705451518297), (41, 0.021860274486243725), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02557574026286602), (24, 0.025880583096295595), (42, 0.025893412763252854), (20, 0.026848892448469996), (47, 0.028072759741917253), (38, 0.031091188080608845), (39, 0.031191361602395773), (15, 0.03205838659778237), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577403236180544), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06493351748213172), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750651538372), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339806102216244), (18, 0.5117432847619057), (53, 0.8063970282673836)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.012758882599882782), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.01607214054092765), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022891478147357702), (40, 0.023602580185979605), (45, 0.023770849220454693), (48, 0.02451987355016172), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.025392549578100443), (42, 0.025712220463901758), (24, 0.025880581932142377), (20, 0.026848892448469996), (47, 0.02805250510573387), (38, 0.030935874208807945), (39, 0.03117303689941764), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160077959299), (29, 0.013421116746030748), (35, 0.01591864973306656), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.019867350347340107), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.02446310641244054), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025246930541470647), (42, 0.02527355100028217), (24, 0.025880581932142377), (20, 0.026848892215639353), (47, 0.027727575041353703), (38, 0.03074627462774515), (39, 0.03128179511986673), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464554235339), (52, 0.06356756342574954), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4377693086862564), (18, 0.5117432847619057), (53, 0.8228829428553581)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.013421116629615426), (35, 0.015968912048265338), (26, 0.016072141472250223), (28, 0.01763686165213585), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055153653026), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02268732525408268), (40, 0.023569098440930247), (45, 0.023840721463784575), (48, 0.024108358891680837), (50, 0.024114208994433284), (49, 0.024870117660611868), (21, 0.024941089563071728), (42, 0.02504557464271784), (22, 0.025151390116661787), (24, 0.025880583096295595), (20, 0.026848891284316778), (47, 0.027423852356150746), (38, 0.030735648702830076), (39, 0.03141042543575168), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.03908350970596075), (51, 0.0403459407389164), (9, 0.04337632888928056), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.057849929202347994), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.06270107720047235), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143513172865), (36, 0.43692686781287193), (18, 0.5117433071136475), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141472250223), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302684511989355), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078294539824128), (23, 0.022228715009987354), (44, 0.02304507838562131), (48, 0.02402454731054604), (50, 0.024096972541883588), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922373006120324), (21, 0.024941089330241084), (22, 0.025151390116661787), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.026848892448469996), (47, 0.02756829559803009), (38, 0.03178726462647319), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.032445503398776054), (19, 0.03254077769815922), (51, 0.04008621396496892), (37, 0.040690730791538954), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.06132525438442826), (52, 0.06221094634383917), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.44933702051639557), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370510682463646), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019856703467667103), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022692032856866717), (48, 0.023521372815594077), (50, 0.023533890256658196), (40, 0.02361623919568956), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.02483832696452737), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582397803664), (47, 0.026813456090167165), (20, 0.026848891517147422), (38, 0.031083731446415186), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.039079748559743166), (37, 0.04015214368700981), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003455877304), (52, 0.0603690748102963), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4432784356176853), (18, 0.5117432922124863), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986022237688303), (27, 0.018769708462059498), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.020515799522399902), (25, 0.022078295703977346), (23, 0.022228716174140573), (44, 0.022507572080940008), (48, 0.022899368777871132), (50, 0.02293772785924375), (40, 0.02305740094743669), (42, 0.02352040819823742), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.026322792284190655), (20, 0.026848891517147422), (38, 0.030149148777127266), (39, 0.031466697342693806), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.037851928267627954), (37, 0.03926890203729272), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (52, 0.05846811877563596), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.061325255781412125), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.43490004539489746), (18, 0.5117433071136475), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381990725174546), (27, 0.01876970916055143), (46, 0.018842301797121763), (41, 0.01901637064293027), (48, 0.02130915760062635), (50, 0.021624521352350712), (44, 0.02174885431304574), (40, 0.021916967118158937), (42, 0.021930374205112457), (25, 0.022078295005485415), (23, 0.02222871663980186), (45, 0.022736449725925922), (49, 0.02297006407752633), (21, 0.02494108979590237), (22, 0.025151389883831143), (47, 0.025355831254273653), (24, 0.025880582397803664), (20, 0.026848892448469996), (38, 0.028691887855529785), (39, 0.02962443232536316), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.03254077769815922), (51, 0.03601635619997978), (37, 0.036430368199944496), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740416750312), (52, 0.05466857925057411), (3, 0.05784992966800928), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.41641608998179436), (18, 0.5117433145642281), (53, 0.8948248997330666)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987634986639023), (46, 0.018358624540269375), (41, 0.018467807210981846), (27, 0.018769708462059498), (48, 0.020775509299710393), (42, 0.021206470439210534), (50, 0.021302447887137532), (44, 0.02158689615316689), (40, 0.021592722507193685), (25, 0.02207829523831606), (23, 0.022228715009987354), (45, 0.022315293783321977), (49, 0.022407566662877798), (47, 0.024609396932646632), (21, 0.024941089563071728), (22, 0.025151390815153718), (24, 0.02588058286346495), (20, 0.026848891284316778), (38, 0.02789032505825162), (39, 0.029191894456744194), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03550667688250542), (37, 0.03591922717168927), (9, 0.043376329354941845), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241324260831), (52, 0.05337408231571317), (2, 0.05457740603014827), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4126182086765766), (18, 0.5117432996630669), (53, 0.9067213460803032)]
computing accuracy for after removing block 43 . block score: 0.017987634986639023
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708462059498), (46, 0.018994681304320693), (42, 0.021206470439210534), (48, 0.02141889533959329), (50, 0.021441323217004538), (40, 0.02159272157587111), (25, 0.022078295703977346), (23, 0.02222871594130993), (49, 0.022339018061757088), (44, 0.02278283261694014), (45, 0.023323106113821268), (21, 0.024941089330241084), (22, 0.025151389883831143), (47, 0.02538607781752944), (24, 0.025880582630634308), (20, 0.026848891284316778), (38, 0.027890325291082263), (39, 0.02919189492240548), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03521771775558591), (37, 0.03591922763735056), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241184562445), (52, 0.0521333715878427), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4126181975007057), (18, 0.5117432847619057), (53, 0.9521221145987511)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.1]
training epoch 1 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 2 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.1]
training epoch 3 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.1]
training epoch 4 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.1]
training epoch 5 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.1]
training epoch 6 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.1]
training epoch 7 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.1]
training epoch 8 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.1]
training epoch 9 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.010140. All blocks and scores: [(46, 0.010140205500647426), (45, 0.010420577018521726), (44, 0.012731309747323394), (42, 0.015673679648898542), (38, 0.019531464902684093), (25, 0.022276539355516434), (37, 0.022425131173804402), (23, 0.022635263158008456), (40, 0.02405018755234778), (21, 0.0250332267023623), (22, 0.02518795896321535), (24, 0.026047750608995557), (50, 0.027071066666394472), (20, 0.027273427229374647), (49, 0.027900128858163953), (48, 0.028534686425700784), (15, 0.032197126653045416), (39, 0.03222418203949928), (7, 0.03279910422861576), (19, 0.032885411754250526), (47, 0.0335392402485013), (27, 0.0411810171790421), (51, 0.041485426016151905), (9, 0.0441971798427403), (6, 0.0467467256821692), (14, 0.04763379134237766), (4, 0.04763712827116251), (2, 0.05481258640065789), (3, 0.057413126807659864), (13, 0.059603191912174225), (11, 0.059644707944244146), (17, 0.06260021682828665), (0, 0.06343444855883718), (52, 0.0668538361787796), (1, 0.0675304839387536), (8, 0.07452103681862354), (10, 0.0810063062235713), (16, 0.08552645053714514), (12, 0.09020304027944803), (5, 0.10596039798110723), (36, 0.3413784056901932), (18, 0.513276107609272), (53, 0.8040086254477501)]
computing accuracy for after removing block 46 . block score: 0.010140205500647426
removed block 46 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 45, with score 0.010421. All blocks and scores: [(45, 0.010420576785691082), (44, 0.012731309747323394), (42, 0.015673679648898542), (38, 0.01953146466985345), (25, 0.02227653912268579), (37, 0.022425131173804402), (23, 0.02263526222668588), (40, 0.02405018825083971), (21, 0.0250332267023623), (22, 0.02518795896321535), (24, 0.026047749910503626), (20, 0.02727342746220529), (50, 0.027425624197348952), (49, 0.028265336761251092), (48, 0.028670014813542366), (15, 0.03219712758436799), (39, 0.03222418203949928), (7, 0.03279910469427705), (19, 0.032885411754250526), (47, 0.03457924164831638), (27, 0.041181018110364676), (51, 0.04218796920031309), (9, 0.044197180308401585), (6, 0.04674672381952405), (14, 0.04763379134237766), (4, 0.04763712966814637), (2, 0.05481258360669017), (3, 0.05741312727332115), (13, 0.0596031928434968), (11, 0.059644708409905434), (17, 0.06260021775960922), (0, 0.06343444855883718), (52, 0.06661259662359953), (1, 0.0675304839387536), (8, 0.07452104054391384), (10, 0.08100630715489388), (16, 0.08552645239979029), (12, 0.09020303934812546), (5, 0.10596039704978466), (36, 0.3413783982396126), (18, 0.5132761001586914), (53, 0.8320344686508179)]
computing accuracy for after removing block 45 . block score: 0.010420576785691082
removed block 45 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.012731. All blocks and scores: [(44, 0.01273130951449275), (42, 0.015673679881729186), (38, 0.019531465135514736), (25, 0.02227653912268579), (37, 0.022425131406635046), (23, 0.022635263158008456), (40, 0.024050188483670354), (21, 0.02503322623670101), (22, 0.025187959196045995), (24, 0.02604775014333427), (50, 0.027135586366057396), (20, 0.027273427229374647), (49, 0.02796481945551932), (48, 0.028145369375124574), (15, 0.0321971271187067), (39, 0.032224183436483145), (7, 0.032799103762954473), (19, 0.03288541082292795), (47, 0.035256180446594954), (27, 0.04118101764470339), (51, 0.04170517483726144), (9, 0.044197180308401585), (6, 0.04674672381952405), (14, 0.0476337899453938), (4, 0.04763713013380766), (2, 0.05481258546933532), (3, 0.05741312960162759), (13, 0.05960319144651294), (11, 0.05964470701292157), (17, 0.06260021589696407), (0, 0.06343444716185331), (52, 0.0641332520172), (1, 0.0675304839387536), (8, 0.07452103961259127), (10, 0.081006302498281), (16, 0.08552645053714514), (12, 0.09020303934812546), (5, 0.10596039704978466), (36, 0.3413783982396126), (18, 0.5132760927081108), (53, 0.888060912489891)]
computing accuracy for after removing block 44 . block score: 0.01273130951449275
removed block 44 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.015674. All blocks and scores: [(42, 0.015673679066821933), (38, 0.019531464437022805), (25, 0.02227653982117772), (37, 0.02242513163946569), (23, 0.022635262459516525), (40, 0.024050188483670354), (21, 0.0250332267023623), (22, 0.025187958730384707), (24, 0.026047749910503626), (50, 0.026055346010252833), (49, 0.026703067822381854), (48, 0.026967748068273067), (20, 0.027273427229374647), (15, 0.03219712618738413), (39, 0.032224183436483145), (7, 0.0327991028316319), (19, 0.032885412219911814), (47, 0.035106174647808075), (51, 0.040414507035166025), (27, 0.041181018110364676), (9, 0.04419717798009515), (6, 0.046746724750846624), (14, 0.047633790876716375), (4, 0.04763712827116251), (2, 0.05481258314102888), (3, 0.057413128670305014), (13, 0.0596031928434968), (11, 0.059644708409905434), (52, 0.06113351322710514), (17, 0.06260021775960922), (0, 0.06343444669619203), (1, 0.06753048300743103), (8, 0.07452103961259127), (10, 0.08100630342960358), (16, 0.08552644960582256), (12, 0.09020303748548031), (5, 0.10596039518713951), (36, 0.3413783982396126), (18, 0.5132760778069496), (53, 0.9499115571379662)]
computing accuracy for after removing block 42 . block score: 0.015673679066821933
removed block 42 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 38, with score 0.019531. All blocks and scores: [(38, 0.019531463971361518), (25, 0.022276539588347077), (37, 0.02242513163946569), (23, 0.02263526269234717), (40, 0.024050188483670354), (21, 0.025033226935192943), (22, 0.025187958730384707), (50, 0.025530504994094372), (24, 0.026047750608995557), (49, 0.026349757332354784), (48, 0.026951007079333067), (20, 0.027273427229374647), (15, 0.03219712572172284), (39, 0.03222418250516057), (7, 0.032799103297293186), (19, 0.032885412219911814), (47, 0.035497121047228575), (51, 0.039185113273561), (27, 0.04118101857602596), (9, 0.04419717937707901), (6, 0.0467467256821692), (14, 0.04763379041105509), (4, 0.047637129202485085), (2, 0.054812585934996605), (3, 0.05741312773898244), (52, 0.0591408284381032), (13, 0.059603191912174225), (11, 0.059644708409905434), (17, 0.06260021822527051), (0, 0.06343444716185331), (1, 0.06753048487007618), (8, 0.07452103868126869), (10, 0.08100630529224873), (16, 0.08552645053714514), (12, 0.09020303748548031), (5, 0.10596039891242981), (36, 0.3413783982396126), (18, 0.5132760927081108), (53, 0.9798723384737968)]
computing accuracy for after removing block 38 . block score: 0.019531463971361518
removed block 38 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.022277. All blocks and scores: [(25, 0.02227653912268579), (37, 0.022425131406635046), (23, 0.02263526269234717), (50, 0.023852464044466615), (40, 0.024584682192653418), (49, 0.024633098859339952), (21, 0.02503322740085423), (22, 0.02518795756623149), (48, 0.025270653888583183), (24, 0.02604775014333427), (20, 0.027273426298052073), (15, 0.03219712618738413), (7, 0.03279910236597061), (19, 0.03288541082292795), (47, 0.034122382290661335), (39, 0.034833152778446674), (51, 0.03759314026683569), (27, 0.04118101904168725), (9, 0.04419717891141772), (6, 0.0467467256821692), (14, 0.04763379041105509), (4, 0.04763712827116251), (2, 0.05481258686631918), (52, 0.05507280118763447), (3, 0.0574131291359663), (13, 0.05960319237783551), (11, 0.05964470934122801), (17, 0.06260021775960922), (0, 0.06343444716185331), (1, 0.06753048487007618), (8, 0.07452103961259127), (10, 0.0810063062235713), (16, 0.08552645146846771), (12, 0.09020304307341576), (5, 0.10596039798110723), (36, 0.3413784056901932), (18, 0.5132760852575302), (53, 1.0211611986160278)]
computing accuracy for after removing block 25 . block score: 0.02227653912268579
removed block 25 current accuracy 0.9196 loss from initial  0.03180000000000005
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.022538. All blocks and scores: [(37, 0.02253831527195871), (23, 0.022635262459516525), (50, 0.022930073784664273), (49, 0.023791417479515076), (40, 0.024169687647372484), (48, 0.024857533629983664), (21, 0.025033227168023586), (22, 0.02518795896321535), (24, 0.026047749677672982), (20, 0.027273427229374647), (15, 0.03219712618738413), (7, 0.032799103297293186), (19, 0.032885412219911814), (47, 0.03298868564888835), (39, 0.03478844417259097), (51, 0.03660477139055729), (27, 0.041814970783889294), (9, 0.0441971798427403), (6, 0.0467467256821692), (14, 0.047633790876716375), (4, 0.0476371287368238), (52, 0.05294995428994298), (2, 0.05481258640065789), (3, 0.05741312727332115), (13, 0.05960319051519036), (11, 0.05964470701292157), (17, 0.06260021589696407), (0, 0.06343444576486945), (1, 0.0675304839387536), (8, 0.07452103961259127), (10, 0.08100630529224873), (16, 0.08552644867449999), (12, 0.09020304027944803), (5, 0.10596039518713951), (36, 0.33782540261745453), (18, 0.5132760852575302), (53, 1.0385696440935135)]
computing accuracy for after removing block 37 . block score: 0.02253831527195871
removed block 37 current accuracy 0.8994 loss from initial  0.052000000000000046
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.021400. All blocks and scores: [(50, 0.02139956154860556), (49, 0.02213050238788128), (23, 0.022635262925177813), (48, 0.02402622438967228), (40, 0.024418508633971214), (21, 0.02503322623670101), (22, 0.025187957799062133), (24, 0.026047750608995557), (20, 0.02727342746220529), (47, 0.031623694114387035), (15, 0.0321971271187067), (7, 0.03279910422861576), (19, 0.032885412219911814), (51, 0.03367659216746688), (39, 0.03754555666819215), (27, 0.04181496985256672), (9, 0.044197177048772573), (6, 0.046746724750846624), (14, 0.04763379180803895), (4, 0.047637129202485085), (52, 0.0492257853038609), (2, 0.05481258453801274), (3, 0.057413125410676), (13, 0.05960319237783551), (11, 0.05964470934122801), (17, 0.06260021775960922), (0, 0.06343444669619203), (1, 0.0675304839387536), (8, 0.07452104054391384), (10, 0.08100630529224873), (16, 0.08552644960582256), (12, 0.09020303934812546), (5, 0.10596039798110723), (36, 0.33782540261745453), (18, 0.5132761001586914), (53, 1.0934452563524246)]
computing accuracy for after removing block 50 . block score: 0.02139956154860556
removed block 50 current accuracy 0.8942 loss from initial  0.05720000000000003
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.022131. All blocks and scores: [(49, 0.02213050238788128), (23, 0.02263526269234717), (48, 0.024026224156841636), (40, 0.024418507935479283), (21, 0.0250332267023623), (22, 0.02518795826472342), (24, 0.026047749677672982), (20, 0.027273427695035934), (47, 0.03162369504570961), (15, 0.03219712618738413), (7, 0.032799103297293186), (19, 0.032885411754250526), (51, 0.03645008569583297), (39, 0.03754555666819215), (27, 0.04181496985256672), (9, 0.044197178445756435), (6, 0.046746724750846624), (14, 0.04763379041105509), (4, 0.0476371287368238), (2, 0.05481258453801274), (52, 0.05543917929753661), (3, 0.05741312634199858), (13, 0.0596031928434968), (11, 0.05964470701292157), (17, 0.06260021636262536), (0, 0.06343444576486945), (1, 0.06753048487007618), (8, 0.07452104147523642), (10, 0.08100630529224873), (16, 0.08552645146846771), (12, 0.09020304027944803), (5, 0.10596039518713951), (36, 0.3378254100680351), (18, 0.5132760927081108), (53, 1.315246969461441)]
computing accuracy for after removing block 49 . block score: 0.02213050238788128
removed block 49 current accuracy 0.8762 loss from initial  0.07520000000000004
since last training loss: 0.07020000000000004 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.022635. All blocks and scores: [(23, 0.0226352633908391), (48, 0.02402622369118035), (40, 0.02441850840114057), (21, 0.025033227168023586), (22, 0.02518795826472342), (24, 0.026047750608995557), (20, 0.027273426996544003), (47, 0.031623694812878966), (15, 0.032197128515690565), (7, 0.032799103762954473), (19, 0.032885411754250526), (39, 0.03754555620253086), (51, 0.037767079658806324), (27, 0.04181496938690543), (9, 0.044197180308401585), (6, 0.04674672381952405), (14, 0.04763379134237766), (4, 0.047637129202485085), (2, 0.05481258500367403), (3, 0.05741312727332115), (52, 0.05768888955935836), (13, 0.05960319330915809), (11, 0.059644708409905434), (17, 0.06260021682828665), (0, 0.06343444669619203), (1, 0.0675304839387536), (8, 0.07452103868126869), (10, 0.0810063062235713), (16, 0.08552644960582256), (12, 0.09020303934812546), (5, 0.10596039798110723), (36, 0.3378254100680351), (18, 0.5132760927081108), (53, 1.507139801979065)]
computing accuracy for after removing block 23 . block score: 0.0226352633908391
removed block 23 current accuracy 0.866 loss from initial  0.08540000000000003
since last training loss: 0.08040000000000003 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.023564. All blocks and scores: [(48, 0.023564450442790985), (40, 0.023823923896998167), (24, 0.024710374185815454), (21, 0.02503322623670101), (22, 0.02518795826472342), (20, 0.02727342746220529), (47, 0.03055467805825174), (15, 0.0321971271187067), (7, 0.032799103762954473), (19, 0.032885411754250526), (51, 0.037469623144716024), (39, 0.03753867419436574), (27, 0.041095944587141275), (9, 0.04419717751443386), (6, 0.0467467256821692), (14, 0.04763379227370024), (4, 0.047637129202485085), (2, 0.05481258314102888), (52, 0.05619848007336259), (3, 0.057413128204643726), (13, 0.05960319470614195), (11, 0.059644707944244146), (17, 0.06260021729394794), (0, 0.06343444716185331), (1, 0.0675304839387536), (8, 0.07452103868126869), (10, 0.08100630529224873), (16, 0.08552645053714514), (12, 0.09020303934812546), (5, 0.10596039611846209), (36, 0.33710312843322754), (18, 0.5132760852575302), (53, 1.5181378573179245)]
computing accuracy for after removing block 48 . block score: 0.023564450442790985
removed block 48 current accuracy 0.8402 loss from initial  0.11120000000000008
training start
training epoch 0 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best True lr [0.1]
training epoch 1 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.1]
training epoch 2 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.1]
training epoch 3 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 4 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 5 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 6 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 7 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 8 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 9 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.1]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.025100. All blocks and scores: [(21, 0.025099860271438956), (22, 0.02549223927780986), (20, 0.02733997511677444), (15, 0.03210394876077771), (7, 0.03245097724720836), (19, 0.03272499656304717), (9, 0.044139685574918985), (6, 0.046725808177143335), (4, 0.047420375514775515), (14, 0.04776386311277747), (2, 0.05467337043955922), (3, 0.057878604624420404), (13, 0.059024881571531296), (11, 0.05966823594644666), (51, 0.060232540126889944), (24, 0.06034128973260522), (17, 0.06194293452426791), (0, 0.06344980001449585), (47, 0.06480157189071178), (40, 0.06597672961652279), (1, 0.0665125772356987), (27, 0.07118537928909063), (8, 0.07452517375349998), (52, 0.07563303131610155), (10, 0.08034183830022812), (39, 0.08040856290608644), (16, 0.08554691635072231), (12, 0.08991819247603416), (5, 0.10549357160925865), (18, 0.5130248665809631), (36, 0.5308265164494514), (53, 1.4616865664720535)]
computing accuracy for after removing block 21 . block score: 0.025099860271438956
removed block 21 current accuracy 0.9384 loss from initial  0.013000000000000012
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.023736. All blocks and scores: [(22, 0.023736367002129555), (20, 0.02733997581526637), (15, 0.032103949226439), (7, 0.032450975850224495), (19, 0.03272499516606331), (9, 0.04413968604058027), (6, 0.04672580910846591), (4, 0.047420376911759377), (14, 0.047763862647116184), (2, 0.05467336950823665), (24, 0.05517911957576871), (51, 0.056428337469697), (3, 0.05787860555574298), (13, 0.05902488203719258), (11, 0.05966823361814022), (40, 0.05980731826275587), (47, 0.05986576108261943), (17, 0.06194293312728405), (0, 0.06344979908317327), (52, 0.06528470199555159), (1, 0.06651257816702127), (27, 0.0675646299496293), (8, 0.07452517468482256), (39, 0.07545301970094442), (10, 0.08034184388816357), (16, 0.08554691448807716), (12, 0.08991819340735674), (5, 0.10549356788396835), (36, 0.4952126741409302), (18, 0.5130248591303825), (53, 1.4840778708457947)]
computing accuracy for after removing block 22 . block score: 0.023736367002129555
removed block 22 current accuracy 0.9294 loss from initial  0.02200000000000002
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.027340. All blocks and scores: [(20, 0.02733997581526637), (15, 0.03210394876077771), (7, 0.03245097631588578), (19, 0.03272499516606331), (9, 0.04413968790322542), (6, 0.046725808177143335), (4, 0.04742037504911423), (14, 0.047763860784471035), (24, 0.050686095375567675), (51, 0.053784302435815334), (2, 0.05467336904257536), (47, 0.05581789370626211), (40, 0.05700436048209667), (3, 0.05787860555574298), (13, 0.05902488203719258), (52, 0.059434556402266026), (11, 0.05966823687776923), (17, 0.06194293266162276), (0, 0.06344980001449585), (27, 0.06452079117298126), (1, 0.06651257909834385), (39, 0.07407966256141663), (8, 0.07452517468482256), (10, 0.08034184388816357), (16, 0.08554691635072231), (12, 0.08991819433867931), (5, 0.1054935697466135), (36, 0.48215698823332787), (18, 0.5130248665809631), (53, 1.475587010383606)]
computing accuracy for after removing block 20 . block score: 0.02733997581526637
removed block 20 current accuracy 0.9158 loss from initial  0.035600000000000076
since last training loss: 0.02740000000000009 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.032104. All blocks and scores: [(15, 0.032103949692100286), (7, 0.032450975850224495), (19, 0.03272499470040202), (9, 0.04413968790322542), (6, 0.046725808177143335), (4, 0.047420375514775515), (14, 0.04776386171579361), (24, 0.0488369669765234), (51, 0.05195386568084359), (47, 0.05240968428552151), (2, 0.054673369973897934), (52, 0.055283615831285715), (40, 0.05695871636271477), (3, 0.05787860509008169), (13, 0.05902487970888615), (11, 0.05966823548078537), (27, 0.06186251016333699), (17, 0.061942932195961475), (0, 0.06344980001449585), (1, 0.06651257909834385), (39, 0.07016089092940092), (8, 0.07452517468482256), (10, 0.08034184295684099), (16, 0.08554691448807716), (12, 0.08991819340735674), (5, 0.10549356881529093), (36, 0.473696518689394), (18, 0.5130248591303825), (53, 1.4498643428087234)]
computing accuracy for after removing block 15 . block score: 0.032103949692100286
removed block 15 current accuracy 0.9074 loss from initial  0.04400000000000004
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.032451. All blocks and scores: [(7, 0.03245097491890192), (19, 0.03299401141703129), (9, 0.04413968790322542), (6, 0.04672580910846591), (24, 0.04727897001430392), (4, 0.047420375514775515), (14, 0.04776386125013232), (51, 0.05239272303879261), (47, 0.05376395350322127), (2, 0.05467336904257536), (52, 0.054992676712572575), (40, 0.05612502293661237), (3, 0.057878604624420404), (13, 0.05902488203719258), (11, 0.05966823501512408), (27, 0.059746052138507366), (0, 0.06344980094581842), (17, 0.06569213699549437), (1, 0.06651257816702127), (39, 0.07079012040048838), (8, 0.07452517189085484), (10, 0.08034184016287327), (12, 0.08991819247603416), (16, 0.0954530443996191), (5, 0.10549357160925865), (36, 0.47009066492319107), (18, 0.5002597272396088), (53, 1.4718625098466873)]
computing accuracy for after removing block 7 . block score: 0.03245097491890192
removed block 7 current accuracy 0.899 loss from initial  0.0524
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 19, with score 0.032809. All blocks and scores: [(19, 0.03280886961147189), (24, 0.04399867355823517), (9, 0.0440167672932148), (14, 0.044145393185317516), (6, 0.04672580864280462), (4, 0.04742037458345294), (51, 0.050684765446931124), (13, 0.05122962221503258), (52, 0.05271661980077624), (47, 0.05300841247662902), (40, 0.05361187504604459), (2, 0.05467337043955922), (17, 0.055638660211116076), (11, 0.05637521855533123), (27, 0.05662091262638569), (3, 0.05787860509008169), (0, 0.06344980001449585), (1, 0.0665125772356987), (39, 0.06839926820248365), (8, 0.07246785890311003), (10, 0.08263415843248367), (12, 0.083985835313797), (16, 0.08692113496363163), (5, 0.1054935697466135), (36, 0.4567674696445465), (18, 0.4837966784834862), (53, 1.4884271025657654)]
computing accuracy for after removing block 19 . block score: 0.03280886961147189
removed block 19 current accuracy 0.8692 loss from initial  0.08220000000000005
since last training loss: 0.07400000000000007 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 24, with score 0.041835. All blocks and scores: [(24, 0.04183471482247114), (9, 0.04401676869019866), (14, 0.044145393185317516), (6, 0.04672580864280462), (4, 0.0474203759804368), (52, 0.04922851221635938), (47, 0.049671771470457315), (51, 0.04973156377673149), (13, 0.051229620818048716), (40, 0.052476557437330484), (27, 0.05390508892014623), (2, 0.05467336950823665), (17, 0.0556386592797935), (11, 0.05637521855533123), (3, 0.05787860415875912), (0, 0.063449801877141), (39, 0.06594818364828825), (1, 0.06651257816702127), (8, 0.07246785704046488), (10, 0.0826341575011611), (12, 0.083985835313797), (16, 0.08692113310098648), (5, 0.10549356881529093), (36, 0.45390957966446877), (18, 0.4837966747581959), (53, 1.4667340070009232)]
computing accuracy for after removing block 24 . block score: 0.04183471482247114
removed block 24 current accuracy 0.817 loss from initial  0.13440000000000007
since last training loss: 0.1262000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.044017. All blocks and scores: [(9, 0.04401676869019866), (14, 0.04414539411664009), (6, 0.04672580864280462), (4, 0.04742037458345294), (52, 0.04779350385069847), (51, 0.049754487816244364), (47, 0.05095900688320398), (13, 0.051229620818048716), (27, 0.05348328314721584), (2, 0.054673368111252785), (17, 0.05563865974545479), (40, 0.0560342469252646), (11, 0.05637521902099252), (3, 0.05787860555574298), (0, 0.06344980094581842), (1, 0.0665125772356987), (39, 0.07203831057995558), (8, 0.0724678561091423), (10, 0.08263415656983852), (12, 0.08398583345115185), (16, 0.0869211358949542), (5, 0.10549356788396835), (18, 0.4837966561317444), (36, 0.486976470798254), (53, 1.5431807041168213)]
computing accuracy for after removing block 9 . block score: 0.04401676869019866
removed block 9 current accuracy 0.7758 loss from initial  0.17559999999999998
since last training loss: 0.1674 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.040070. All blocks and scores: [(14, 0.04006987810134888), (52, 0.04561725398525596), (6, 0.04672580864280462), (4, 0.04742037318646908), (51, 0.047561063431203365), (13, 0.048540664836764336), (27, 0.04916906636208296), (17, 0.04962522257119417), (47, 0.05169976316392422), (11, 0.052082113455981016), (40, 0.05283413315191865), (2, 0.054673371370881796), (3, 0.057878606021404266), (0, 0.06344980001449585), (1, 0.0665125772356987), (39, 0.06755555793642998), (16, 0.07145170029252768), (12, 0.07216570060700178), (8, 0.07246785704046488), (10, 0.0809681098908186), (5, 0.10549356881529093), (36, 0.4642224945127964), (18, 0.46515847370028496), (53, 1.5565245598554611)]
computing accuracy for after removing block 14 . block score: 0.04006987810134888
removed block 14 current accuracy 0.7172 loss from initial  0.23420000000000007
since last training loss: 0.2260000000000001 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 52, with score 0.043750. All blocks and scores: [(52, 0.04374968074262142), (6, 0.04672580910846591), (27, 0.04700331948697567), (51, 0.04733606847003102), (4, 0.047420375514775515), (13, 0.04854066530242562), (17, 0.0491560404188931), (11, 0.052082113455981016), (47, 0.05279857572168112), (40, 0.052960149478167295), (2, 0.05467336904257536), (3, 0.057878606021404266), (0, 0.063449801877141), (1, 0.06651257816702127), (39, 0.06710052490234375), (12, 0.0721656996756792), (8, 0.0724678561091423), (10, 0.08096810895949602), (16, 0.09409146662801504), (5, 0.1054935697466135), (18, 0.4628374017775059), (36, 0.4638182111084461), (53, 1.5467184484004974)]
computing accuracy for after removing block 52 . block score: 0.04374968074262142
removed block 52 current accuracy 0.6504 loss from initial  0.30100000000000005
since last training loss: 0.29280000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 6, with score 0.046726. All blocks and scores: [(6, 0.046725808177143335), (27, 0.04700332088395953), (51, 0.04733606847003102), (4, 0.047420375514775515), (13, 0.04854066530242562), (17, 0.049156040884554386), (11, 0.052082113455981016), (47, 0.05279857479035854), (40, 0.052960149478167295), (2, 0.05467336857691407), (3, 0.057878604624420404), (0, 0.06344979908317327), (1, 0.06651257816702127), (39, 0.06710052397102118), (12, 0.07216569874435663), (8, 0.0724678561091423), (10, 0.08096811175346375), (16, 0.09409146476536989), (5, 0.10549356695264578), (18, 0.4628373831510544), (36, 0.4638182036578655), (53, 1.4290489703416824)]
computing accuracy for after removing block 6 . block score: 0.046725808177143335
removed block 6 current accuracy 0.5392 loss from initial  0.4122
training start
training epoch 0 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best True lr [0.1]
training epoch 1 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 2 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 3 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 4 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 5 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 6 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 7 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 8 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 9 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 10 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.935000)
finished training. finished 50 epochs. accuracy 0.935 topk_dict {'top1': 0.935}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.046162. All blocks and scores: [(4, 0.0461619165726006), (2, 0.05404310906305909), (51, 0.055333174765110016), (13, 0.05740806646645069), (3, 0.057584617752581835), (39, 0.05805260268971324), (17, 0.05956979934126139), (47, 0.0610808995552361), (0, 0.06365507794544101), (1, 0.06647218018770218), (11, 0.06888230610638857), (40, 0.06917712837457657), (8, 0.0985368900001049), (5, 0.10653460584580898), (10, 0.10693319048732519), (16, 0.10708249919116497), (27, 0.13063611090183258), (12, 0.13742367550730705), (36, 0.356400303542614), (18, 0.5989570170640945), (53, 1.8694846779108047)]
computing accuracy for after removing block 4 . block score: 0.0461619165726006
removed block 4 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.054043. All blocks and scores: [(2, 0.05404310906305909), (51, 0.054639899637550116), (17, 0.05689420085400343), (3, 0.05758461728692055), (39, 0.05803124187514186), (13, 0.05893143638968468), (47, 0.06007329374551773), (0, 0.06365507794544101), (1, 0.0664721755310893), (11, 0.0667555732652545), (40, 0.0703887278214097), (16, 0.09813791792839766), (8, 0.10029056761413813), (10, 0.10415817890316248), (5, 0.11080214567482471), (27, 0.12864967621862888), (12, 0.13036742620170116), (36, 0.3570169545710087), (18, 0.6045672073960304), (53, 1.8189565986394882)]
computing accuracy for after removing block 2 . block score: 0.05404310906305909
removed block 2 current accuracy 0.9088 loss from initial  0.04259999999999997
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 17, with score 0.048779. All blocks and scores: [(17, 0.04877887945622206), (51, 0.05098288785666227), (3, 0.05262830527499318), (39, 0.05432688957080245), (13, 0.05735325068235397), (47, 0.05738756479695439), (11, 0.06132791982963681), (40, 0.06318481871858239), (0, 0.06365507887676358), (1, 0.06647218018770218), (16, 0.09120117966085672), (8, 0.09631689451634884), (10, 0.0993424691259861), (5, 0.1076255077496171), (27, 0.11678319051861763), (12, 0.12101839669048786), (36, 0.32787762209773064), (18, 0.5443402007222176), (53, 1.765279859304428)]
computing accuracy for after removing block 17 . block score: 0.04877887945622206
removed block 17 current accuracy 0.8938 loss from initial  0.057599999999999985
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 51, with score 0.048527. All blocks and scores: [(51, 0.048527094535529613), (39, 0.05059116519987583), (3, 0.052628304809331894), (47, 0.05469363695010543), (40, 0.05501008499413729), (13, 0.05735325068235397), (11, 0.06132792076095939), (0, 0.06365507887676358), (1, 0.06647217832505703), (16, 0.09120117966085672), (8, 0.09631689917296171), (10, 0.09934246446937323), (5, 0.10762550495564938), (27, 0.10991260968148708), (12, 0.12101840507239103), (36, 0.3001682795584202), (18, 0.5135773867368698), (53, 1.6401520818471909)]
computing accuracy for after removing block 51 . block score: 0.048527094535529613
removed block 51 current accuracy 0.7974 loss from initial  0.15400000000000003
since last training loss: 0.13760000000000006 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 39, with score 0.050591. All blocks and scores: [(39, 0.050591164734214544), (3, 0.05262830667197704), (47, 0.05469363834708929), (40, 0.05501008592545986), (13, 0.05735325068235397), (11, 0.061327921226620674), (0, 0.06365507701411843), (1, 0.0664721792563796), (16, 0.09120118245482445), (8, 0.09631690010428429), (10, 0.09934246353805065), (5, 0.1076255077496171), (27, 0.10991260968148708), (12, 0.12101840414106846), (36, 0.3001682832837105), (18, 0.513577401638031), (53, 2.0545955300331116)]
computing accuracy for after removing block 39 . block score: 0.050591164734214544
removed block 39 current accuracy 0.7452 loss from initial  0.20620000000000005
since last training loss: 0.18980000000000008 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 47, with score 0.050285. All blocks and scores: [(47, 0.050285255536437035), (3, 0.05262830574065447), (13, 0.05735324928537011), (40, 0.060969009064137936), (11, 0.0613279202952981), (0, 0.06365507887676358), (1, 0.0664721792563796), (16, 0.09120117966085672), (8, 0.09631689824163914), (10, 0.09934246819466352), (5, 0.10762551054358482), (27, 0.10991260502487421), (12, 0.12101840041577816), (36, 0.3001682832837105), (18, 0.5135774090886116), (53, 1.882030799984932)]
computing accuracy for after removing block 47 . block score: 0.050285255536437035
removed block 47 current accuracy 0.584 loss from initial  0.36740000000000006
since last training loss: 0.3510000000000001 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 3, with score 0.052628. All blocks and scores: [(3, 0.05262830574065447), (13, 0.05735325114801526), (40, 0.06096900859847665), (11, 0.06132791843265295), (0, 0.06365507980808616), (1, 0.0664721792563796), (16, 0.09120117966085672), (8, 0.09631689824163914), (10, 0.09934246260672808), (5, 0.1076255077496171), (27, 0.10991261433809996), (12, 0.12101840600371361), (36, 0.3001682870090008), (18, 0.5135774090886116), (53, 2.2545589804649353)]
computing accuracy for after removing block 3 . block score: 0.05262830574065447
removed block 3 current accuracy 0.4696 loss from initial  0.4818
since last training loss: 0.46540000000000004 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 40, with score 0.056606. All blocks and scores: [(40, 0.05660647060722113), (13, 0.05815998464822769), (11, 0.05829298635944724), (0, 0.06365507980808616), (1, 0.06647217832505703), (16, 0.07351817842572927), (8, 0.09518302977085114), (10, 0.09835288021713495), (27, 0.10020037367939949), (5, 0.11122597567737103), (12, 0.11205347441136837), (36, 0.2861320488154888), (18, 0.48347998410463333), (53, 2.3293204605579376)]
computing accuracy for after removing block 40 . block score: 0.05660647060722113
removed block 40 current accuracy 0.362 loss from initial  0.5894
since last training loss: 0.5730000000000001 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 13, with score 0.058160. All blocks and scores: [(13, 0.05815998371690512), (11, 0.05829298682510853), (0, 0.06365507794544101), (1, 0.06647217832505703), (16, 0.07351817935705185), (8, 0.09518302604556084), (10, 0.09835288301110268), (27, 0.10020037367939949), (5, 0.1112259766086936), (12, 0.11205347627401352), (36, 0.2861320562660694), (18, 0.48347998410463333), (53, 3.0467314422130585)]
computing accuracy for after removing block 13 . block score: 0.05815998371690512
removed block 13 current accuracy 0.2936 loss from initial  0.6577999999999999
since last training loss: 0.6414 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 11, with score 0.058293. All blocks and scores: [(11, 0.058292987290769815), (0, 0.06365507980808616), (1, 0.0664721792563796), (16, 0.09174798429012299), (27, 0.09370831307023764), (8, 0.09518303070217371), (10, 0.09835288114845753), (5, 0.11122597847133875), (12, 0.1120534772053361), (36, 0.2856259234249592), (18, 0.48415838181972504), (53, 3.2063602805137634)]
computing accuracy for after removing block 11 . block score: 0.058292987290769815
removed block 11 current accuracy 0.2702 loss from initial  0.6812
since last training loss: 0.6648000000000001 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 0, with score 0.063655. All blocks and scores: [(0, 0.06365508073940873), (1, 0.06647217739373446), (16, 0.06929261609911919), (27, 0.09011515881866217), (8, 0.09518302697688341), (10, 0.09835288114845753), (12, 0.10235299449414015), (5, 0.11122597940266132), (36, 0.28888680413365364), (18, 0.49779170006513596), (53, 2.714072972536087)]
computing accuracy for after removing block 0 . block score: 0.06365508073940873
removed block 0 current accuracy 0.2352 loss from initial  0.7162000000000001
since last training loss: 0.6998000000000001 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 16, with score 0.064052. All blocks and scores: [(16, 0.06405154708772898), (1, 0.06877652648836374), (27, 0.08551418408751488), (8, 0.08713521808385849), (10, 0.09446516260504723), (12, 0.10585705935955048), (5, 0.10790268052369356), (36, 0.29244334250688553), (18, 0.5174793154001236), (53, 2.835615187883377)]
computing accuracy for after removing block 16 . block score: 0.06405154708772898
removed block 16 current accuracy 0.1452 loss from initial  0.8062
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.1]
training epoch 1 val accuracy 0.7746 topk_dict {'top1': 0.7746} is_best False lr [0.1]
training epoch 2 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.1]
training epoch 3 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.1]
training epoch 4 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 5 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.1]
training epoch 6 val accuracy 0.8084 topk_dict {'top1': 0.8084} is_best False lr [0.1]
training epoch 7 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 8 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.1]
training epoch 9 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 10 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.918400)
finished training. finished 50 epochs. accuracy 0.9184 topk_dict {'top1': 0.9184}
