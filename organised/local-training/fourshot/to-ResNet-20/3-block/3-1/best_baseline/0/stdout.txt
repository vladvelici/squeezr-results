start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589383974671), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013294661417603493), (29, 0.013421116978861392), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.020590224768966436), (25, 0.022078294539824128), (23, 0.02222871547564864), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749591084197164), (45, 0.023975494783371687), (21, 0.024941090727224946), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174386903644), (24, 0.02588058216497302), (49, 0.025916648795828223), (42, 0.026232232339680195), (20, 0.02684889198280871), (47, 0.028632947243750095), (38, 0.031344343442469835), (39, 0.03144129575230181), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789771931245923), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525345310569), (0, 0.06337464647367597), (1, 0.06593215931206942), (52, 0.06606104224920273), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4361986331641674), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013119243667460978), (29, 0.013421116978861392), (26, 0.016072140773758292), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022977193584665656), (40, 0.02357383049093187), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025575740495696664), (24, 0.025880583096295595), (42, 0.02589341253042221), (20, 0.026848891749978065), (47, 0.028072760673239827), (38, 0.03109118901193142), (39, 0.031191361602395773), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.04127101367339492), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351748213172), (1, 0.06593216210603714), (8, 0.07466361299157143), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.806397020816803)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116978861392), (35, 0.015918420744128525), (26, 0.016072141705080867), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.02360257995314896), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712220231071115), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.028052504174411297), (38, 0.030935872811824083), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.03244550386443734), (19, 0.03254077862948179), (37, 0.038343189749866724), (51, 0.04113080678507686), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525345310569), (0, 0.06337464554235339), (52, 0.06441722670570016), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432922124863), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159845128655), (29, 0.013421116746030748), (35, 0.01591864926740527), (26, 0.016072140773758292), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.02175602037459612), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.023001375840976834), (40, 0.023739926982671022), (45, 0.02379016811028123), (48, 0.024350045481696725), (50, 0.024463105713948607), (21, 0.024941090028733015), (22, 0.025151390582323074), (49, 0.025246930308640003), (42, 0.025273551233112812), (24, 0.02588058216497302), (20, 0.026848892215639353), (47, 0.027727574575692415), (38, 0.030746274394914508), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693086862564), (18, 0.5117432773113251), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.015968911815434694), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.020137188024818897), (41, 0.021584055619314313), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02268732525408268), (40, 0.023569097742438316), (45, 0.023840720765292645), (48, 0.02410835842601955), (50, 0.02411420876160264), (49, 0.024870118126273155), (21, 0.024941089563071728), (42, 0.025045574409887195), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02742385258898139), (38, 0.030735648469999433), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.04034594027325511), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.05914428969845176), (11, 0.059700032230466604), (17, 0.06132525531575084), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.43692685663700104), (18, 0.5117432922124863), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016558773117139935), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.020302684046328068), (46, 0.020324198063462973), (41, 0.021962703438475728), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.023045078152790666), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922373238950968), (21, 0.02494108979590237), (22, 0.025151390582323074), (42, 0.02581606013700366), (24, 0.025880582397803664), (20, 0.026848892215639353), (47, 0.02756829489953816), (38, 0.03178726392798126), (15, 0.0320583856664598), (39, 0.03225791407749057), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.040086214896291494), (37, 0.04069073125720024), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.057849925477057695), (13, 0.05914428550750017), (11, 0.05970003455877304), (17, 0.06132525438442826), (52, 0.06221094774082303), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.44933703541755676), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370510682463646), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019856703002005816), (46, 0.019988976418972015), (41, 0.02125620562583208), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.022692032856866717), (48, 0.02352137118577957), (50, 0.023533890256658196), (40, 0.02361624059267342), (45, 0.023933291900902987), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089563071728), (22, 0.025151389883831143), (24, 0.02588058286346495), (47, 0.026813456090167165), (20, 0.02684889198280871), (38, 0.03108373237773776), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03907974902540445), (37, 0.04015214368700981), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003269612789), (52, 0.0603690748102963), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216396868229), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432996630669), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.01698602200485766), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295703977346), (23, 0.022228715009987354), (44, 0.022507572313770652), (48, 0.022899368312209845), (50, 0.022937727393582463), (40, 0.023057401878759265), (42, 0.023520409129559994), (45, 0.023633700096979737), (49, 0.02408191910944879), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.025880581699311733), (47, 0.026322792749851942), (20, 0.026848891517147422), (38, 0.03014914900995791), (39, 0.03146669617854059), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.039268902968615294), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (52, 0.058468119241297245), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.43490004166960716), (18, 0.5117433071136475), (53, 0.8595060706138611)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381991423666477), (27, 0.018769708927720785), (46, 0.01884230156429112), (41, 0.019016370177268982), (48, 0.02130915760062635), (50, 0.021624520886689425), (44, 0.021748854545876384), (40, 0.02191696735098958), (42, 0.0219303744379431), (25, 0.022078295005485415), (23, 0.022228715009987354), (45, 0.02273644902743399), (49, 0.0229700633790344), (21, 0.02494108979590237), (22, 0.025151390116661787), (47, 0.02535583171993494), (24, 0.025880581932142377), (20, 0.026848892215639353), (38, 0.028691887157037854), (39, 0.029624431394040585), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.036016357596963644), (37, 0.036430368199944496), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241463959217), (2, 0.054577406495809555), (52, 0.054668580647557974), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.05970003502443433), (17, 0.06132525345310569), (0, 0.06337464367970824), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.41641609370708466), (18, 0.5117432847619057), (53, 0.8948249071836472)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.018358624540269375), (41, 0.01846780674532056), (27, 0.018769708927720785), (48, 0.020775508601218462), (42, 0.021206469740718603), (50, 0.021302447887137532), (44, 0.021586895920336246), (40, 0.021592722740024328), (25, 0.022078295703977346), (23, 0.022228714544326067), (45, 0.022315293783321977), (49, 0.022407567128539085), (47, 0.02460939739830792), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880581932142377), (20, 0.026848892448469996), (38, 0.02789032505825162), (39, 0.02919189492240548), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.035506677348166704), (37, 0.03591922717168927), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241277694702), (52, 0.05337408231571317), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428969845176), (11, 0.05970003455877304), (17, 0.061325255781412125), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4126181900501251), (18, 0.5117432996630669), (53, 0.9067213013768196)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.01846780674532056), (27, 0.01876970869489014), (46, 0.01899468107149005), (42, 0.021206469973549247), (48, 0.02141889580525458), (50, 0.021441322285681963), (40, 0.021592722507193685), (25, 0.022078295471146703), (23, 0.02222871594130993), (49, 0.022339017828926444), (44, 0.02278283331543207), (45, 0.0233231068123132), (21, 0.024941089563071728), (22, 0.025151390116661787), (47, 0.02538607781752944), (24, 0.02588058286346495), (20, 0.026848892215639353), (38, 0.027890324825420976), (39, 0.029191895620897412), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03521771775558591), (37, 0.035919226706027985), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (52, 0.05213337251916528), (2, 0.05457740603014827), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4126182086765766), (18, 0.5117432847619057), (53, 0.9521221071481705)]
computing accuracy for after removing block 41 . block score: 0.01846780674532056
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 1 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 2 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 3 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.1]
training epoch 4 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.1]
training epoch 5 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.1]
training epoch 6 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.1]
training epoch 7 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.1]
training epoch 8 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.1]
training epoch 9 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 11
[activation diff]: block to remove picked: 44, with score 0.012645. All blocks and scores: [(44, 0.01264482643455267), (40, 0.014941209112294018), (42, 0.015029973932541907), (38, 0.01915611675940454), (39, 0.020012847613543272), (46, 0.024519017664715648), (21, 0.024864821694791317), (22, 0.025279402267187834), (50, 0.026706519536674023), (20, 0.02703339164145291), (49, 0.02750797080807388), (48, 0.027602666290476918), (25, 0.027896151412278414), (27, 0.028676297748461366), (23, 0.029383058659732342), (45, 0.029587473953142762), (24, 0.02959725819528103), (47, 0.032138640992343426), (15, 0.03218676568940282), (7, 0.03239218657836318), (19, 0.032435201574116945), (37, 0.03745060646906495), (51, 0.04219271847978234), (9, 0.043585913721472025), (6, 0.04647045163437724), (14, 0.0479250461794436), (4, 0.049449344631284475), (2, 0.05513156019151211), (3, 0.05776342982426286), (11, 0.05976018123328686), (13, 0.05980415875092149), (17, 0.06257259752601385), (0, 0.06344992481172085), (1, 0.0664931247010827), (52, 0.06717685982584953), (8, 0.07418756745755672), (10, 0.08159289136528969), (16, 0.08418935723602772), (12, 0.09095705859363079), (5, 0.10620257165282965), (36, 0.36130696907639503), (18, 0.5137163549661636), (53, 0.812412217259407)]
computing accuracy for after removing block 44 . block score: 0.01264482643455267
removed block 44 current accuracy 0.9384 loss from initial  0.013000000000000012
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 40, with score 0.014941. All blocks and scores: [(40, 0.014941209345124662), (42, 0.015029974048957229), (38, 0.01915611675940454), (39, 0.02001284738071263), (46, 0.024777447571977973), (21, 0.024864821461960673), (22, 0.025279402500018477), (49, 0.026403235271573067), (50, 0.026516251731663942), (48, 0.02670961059629917), (20, 0.027033391874283552), (25, 0.027896150248125196), (27, 0.02867629728280008), (45, 0.029263648437336087), (23, 0.029383060056716204), (24, 0.029597257496789098), (15, 0.03218676662072539), (47, 0.03238674160093069), (7, 0.03239218657836318), (19, 0.032435201574116945), (37, 0.03745060693472624), (51, 0.04139263415709138), (9, 0.043585915584117174), (6, 0.046470452565699816), (14, 0.04792504757642746), (4, 0.04944934416562319), (2, 0.05513155926018953), (3, 0.05776342889294028), (11, 0.05976017937064171), (13, 0.05980415781959891), (17, 0.06257259845733643), (0, 0.06344992201775312), (52, 0.06573427189141512), (1, 0.06649312376976013), (8, 0.0741875683888793), (10, 0.08159288950264454), (16, 0.08418935537338257), (12, 0.09095705952495337), (5, 0.10620256699621677), (36, 0.36130697280168533), (18, 0.5137163624167442), (53, 0.8535940572619438)]
computing accuracy for after removing block 40 . block score: 0.014941209345124662
removed block 40 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.013592. All blocks and scores: [(42, 0.01359154365491122), (38, 0.019156116293743253), (39, 0.020012847147881985), (46, 0.02426392026245594), (21, 0.024864821694791317), (22, 0.025279402500018477), (50, 0.02537178876809776), (49, 0.025549441808834672), (48, 0.02570115332491696), (20, 0.027033391408622265), (25, 0.027896150713786483), (27, 0.028676298214122653), (45, 0.029027149779722095), (23, 0.029383059591054916), (24, 0.029597258428111672), (15, 0.03218676568940282), (7, 0.03239218657836318), (19, 0.03243520110845566), (47, 0.032684295903891325), (37, 0.037450607400387526), (51, 0.04080424923449755), (9, 0.04358591325581074), (6, 0.0464704530313611), (14, 0.04792504757642746), (4, 0.049449344631284475), (2, 0.05513156158849597), (3, 0.05776343075558543), (11, 0.05976018030196428), (13, 0.05980415781959891), (17, 0.06257259845733643), (0, 0.06344992714002728), (52, 0.06386419851332903), (1, 0.06649312376976013), (8, 0.0741875683888793), (10, 0.08159288950264454), (16, 0.08418935723602772), (12, 0.09095706045627594), (5, 0.10620257165282965), (36, 0.36130697280168533), (18, 0.5137163624167442), (53, 0.9078950807452202)]
computing accuracy for after removing block 42 . block score: 0.01359154365491122
removed block 42 current accuracy 0.929 loss from initial  0.022399999999999975
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.019156. All blocks and scores: [(38, 0.019156116293743253), (39, 0.02001284807920456), (46, 0.02465680753812194), (21, 0.02486482122913003), (49, 0.02496083779260516), (50, 0.02500948333181441), (48, 0.025172463851049542), (22, 0.02527940273284912), (20, 0.027033391408622265), (25, 0.027896150946617126), (27, 0.028676297748461366), (23, 0.029383058659732342), (24, 0.02959725772961974), (45, 0.029598440509289503), (15, 0.03218676568940282), (7, 0.03239218797534704), (19, 0.032435201574116945), (47, 0.03313912358134985), (37, 0.03745060693472624), (51, 0.039892605040222406), (9, 0.04358591279014945), (6, 0.0464704530313611), (14, 0.047925046645104885), (4, 0.04944934416562319), (2, 0.05513156158849597), (3, 0.05776342935860157), (11, 0.05976018076762557), (13, 0.0598041582852602), (52, 0.062020980287343264), (17, 0.06257259752601385), (0, 0.063449926674366), (1, 0.06649312376976013), (8, 0.0741875683888793), (10, 0.08159289043396711), (16, 0.08418935723602772), (12, 0.09095705673098564), (5, 0.10620256885886192), (36, 0.36130696907639503), (18, 0.5137163773179054), (53, 0.9525902569293976)]
computing accuracy for after removing block 38 . block score: 0.019156116293743253
removed block 38 current accuracy 0.9226 loss from initial  0.028800000000000048
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 39, with score 0.020293. All blocks and scores: [(39, 0.020292943809181452), (50, 0.022723375586792827), (48, 0.022809276124462485), (46, 0.02314744028262794), (49, 0.02319993544369936), (21, 0.024864821461960673), (22, 0.025279402267187834), (20, 0.027033392572775483), (25, 0.02789615048095584), (45, 0.0285316975787282), (27, 0.02867629728280008), (23, 0.02938305982388556), (24, 0.029597257962450385), (47, 0.030424470780417323), (15, 0.032186766155064106), (7, 0.03239218797534704), (19, 0.032435201574116945), (37, 0.037450607400387526), (51, 0.03851229511201382), (9, 0.04358591418713331), (6, 0.04647045349702239), (14, 0.04792504571378231), (4, 0.0494493436999619), (2, 0.05513156112283468), (52, 0.056376686319708824), (3, 0.05776342982426286), (11, 0.059760179836302996), (13, 0.059804157353937626), (17, 0.06257259752601385), (0, 0.06344992481172085), (1, 0.0664931247010827), (8, 0.07418756745755672), (10, 0.08159289043396711), (16, 0.08418935723602772), (12, 0.09095705859363079), (5, 0.10620256792753935), (36, 0.36130697280168533), (18, 0.5137163698673248), (53, 0.987629272043705)]
computing accuracy for after removing block 39 . block score: 0.020292943809181452
removed block 39 current accuracy 0.9014 loss from initial  0.050000000000000044
since last training loss: 0.04259999999999997 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021029. All blocks and scores: [(50, 0.02102937246672809), (48, 0.021318054059520364), (49, 0.02206473145633936), (46, 0.02212563925422728), (21, 0.024864821461960673), (22, 0.025279402500018477), (20, 0.02703339164145291), (45, 0.027836038265377283), (25, 0.027896150015294552), (47, 0.028411216801032424), (27, 0.028676297748461366), (23, 0.029383060289546847), (24, 0.029597257263958454), (15, 0.03218676568940282), (7, 0.03239218657836318), (19, 0.03243520110845566), (51, 0.03716390812769532), (37, 0.03745060786604881), (9, 0.04358591418713331), (6, 0.046470454428344965), (14, 0.047925046645104885), (4, 0.04944934509694576), (52, 0.0507526034489274), (2, 0.05513155926018953), (3, 0.05776343075558543), (11, 0.05976018076762557), (13, 0.05980415781959891), (17, 0.06257259706035256), (0, 0.06344992388039827), (1, 0.06649312376976013), (8, 0.07418756559491158), (10, 0.08159288857132196), (16, 0.08418935630470514), (12, 0.09095705859363079), (5, 0.1062025697901845), (36, 0.36130696162581444), (18, 0.5137163773179054), (53, 1.0261726677417755)]
computing accuracy for after removing block 50 . block score: 0.02102937246672809
removed block 50 current accuracy 0.8982 loss from initial  0.053200000000000025
since last training loss: 0.04579999999999995 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.021318. All blocks and scores: [(48, 0.02131805382668972), (49, 0.022064731922000647), (46, 0.02212563855573535), (21, 0.024864820996299386), (22, 0.025279401801526546), (20, 0.027033390942960978), (45, 0.027836038498207927), (25, 0.027896150946617126), (47, 0.028411216801032424), (27, 0.028676298214122653), (23, 0.029383059358224273), (24, 0.029597257962450385), (15, 0.03218676522374153), (7, 0.03239218657836318), (19, 0.03243520110845566), (37, 0.037450607400387526), (51, 0.03957813559100032), (9, 0.04358591511845589), (6, 0.04647045396268368), (14, 0.047925044782459736), (4, 0.049449344631284475), (2, 0.05513155926018953), (52, 0.056226278655231), (3, 0.05776342796161771), (11, 0.05976018076762557), (13, 0.059804159216582775), (17, 0.06257259799167514), (0, 0.06344992481172085), (1, 0.06649312376976013), (8, 0.07418756745755672), (10, 0.08159288763999939), (16, 0.08418935630470514), (12, 0.09095706045627594), (5, 0.10620256885886192), (36, 0.36130697280168533), (18, 0.5137163624167442), (53, 1.2542968541383743)]
computing accuracy for after removing block 48 . block score: 0.02131805382668972
removed block 48 current accuracy 0.885 loss from initial  0.06640000000000001
since last training loss: 0.05899999999999994 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.022126. All blocks and scores: [(46, 0.022125639021396637), (49, 0.02454155241139233), (21, 0.02486482122913003), (22, 0.025279402500018477), (20, 0.027033392107114196), (45, 0.02783603803254664), (25, 0.027896150015294552), (47, 0.02841121586970985), (27, 0.028676297049969435), (23, 0.029383058892562985), (24, 0.029597257962450385), (15, 0.03218676568940282), (7, 0.032392187509685755), (19, 0.03243520203977823), (37, 0.03745060693472624), (51, 0.039171979296952486), (9, 0.04358591325581074), (6, 0.04647045489400625), (14, 0.04792504571378231), (4, 0.04944934416562319), (2, 0.05513156019151211), (3, 0.057763428427278996), (11, 0.05976018123328686), (13, 0.059804159216582775), (52, 0.060112879145890474), (17, 0.06257259752601385), (0, 0.0634499229490757), (1, 0.0664931247010827), (8, 0.0741875683888793), (10, 0.08159289043396711), (16, 0.08418935816735029), (12, 0.09095705952495337), (5, 0.10620256699621677), (36, 0.36130697280168533), (18, 0.5137163698673248), (53, 1.3981351405382156)]
computing accuracy for after removing block 46 . block score: 0.022125639021396637
removed block 46 current accuracy 0.8628 loss from initial  0.08860000000000001
since last training loss: 0.08119999999999994 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.024865. All blocks and scores: [(21, 0.02486482192762196), (22, 0.02527940319851041), (49, 0.02598408400081098), (20, 0.02703339117579162), (45, 0.02783603803254664), (25, 0.027896150946617126), (27, 0.02867629798129201), (23, 0.029383058426901698), (24, 0.029597257263958454), (47, 0.031193481758236885), (15, 0.032186766155064106), (7, 0.03239218704402447), (19, 0.03243520110845566), (37, 0.037450607400387526), (51, 0.039887182880192995), (9, 0.04358591511845589), (6, 0.04647045349702239), (14, 0.047925046645104885), (4, 0.04944934416562319), (2, 0.055131558794528246), (3, 0.05776342889294028), (11, 0.05976018123328686), (13, 0.05980415968224406), (52, 0.06143249711021781), (17, 0.06257259706035256), (0, 0.06344992620870471), (1, 0.06649312190711498), (8, 0.0741875683888793), (10, 0.08159288950264454), (16, 0.08418935630470514), (12, 0.09095705859363079), (5, 0.1062025697901845), (36, 0.36130697652697563), (18, 0.5137163624167442), (53, 1.55510114133358)]
computing accuracy for after removing block 21 . block score: 0.02486482192762196
removed block 21 current accuracy 0.8618 loss from initial  0.08960000000000001
since last training loss: 0.08219999999999994 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.023535. All blocks and scores: [(22, 0.023535357555374503), (49, 0.025159900542348623), (25, 0.02589151239953935), (24, 0.025988046545535326), (45, 0.0269687888212502), (20, 0.02703339164145291), (23, 0.027380504412576556), (27, 0.027633009245619178), (47, 0.02943208417855203), (15, 0.03218676662072539), (7, 0.03239218704402447), (19, 0.03243520250543952), (37, 0.036046617198735476), (51, 0.0378369465470314), (9, 0.043585913721472025), (6, 0.046470452565699816), (14, 0.04792504524812102), (4, 0.04944934416562319), (52, 0.05493173375725746), (2, 0.05513156112283468), (3, 0.05776342889294028), (11, 0.05976018123328686), (13, 0.0598041582852602), (17, 0.06257259659469128), (0, 0.06344992388039827), (1, 0.06649312563240528), (8, 0.07418756652623415), (10, 0.08159288391470909), (16, 0.08418935537338257), (12, 0.09095705952495337), (5, 0.1062025697901845), (36, 0.3435835689306259), (18, 0.5137163698673248), (53, 1.5695181339979172)]
computing accuracy for after removing block 22 . block score: 0.023535357555374503
removed block 22 current accuracy 0.8508 loss from initial  0.10060000000000002
since last training loss: 0.09319999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.023547. All blocks and scores: [(24, 0.023546941811218858), (25, 0.02400667918846011), (49, 0.024445127230137587), (23, 0.025532323168590665), (45, 0.026067185448482633), (27, 0.02691332600079477), (20, 0.027033391874283552), (47, 0.027575738029554486), (15, 0.03218676568940282), (7, 0.03239218704402447), (19, 0.03243520203977823), (51, 0.03629003372043371), (37, 0.03645515022799373), (9, 0.04358591511845589), (6, 0.04647045396268368), (14, 0.04792504524812102), (4, 0.0494493436999619), (52, 0.0510274120606482), (2, 0.055131560657173395), (3, 0.05776342796161771), (11, 0.05976018076762557), (13, 0.05980415781959891), (17, 0.06257259799167514), (0, 0.06344992481172085), (1, 0.06649312283843756), (8, 0.07418756745755672), (10, 0.08159289136528969), (16, 0.08418935909867287), (12, 0.09095706045627594), (5, 0.10620257072150707), (36, 0.3368243835866451), (18, 0.513716384768486), (53, 1.5481527596712112)]
computing accuracy for after removing block 24 . block score: 0.023546941811218858
removed block 24 current accuracy 0.827 loss from initial  0.12440000000000007
training start
training epoch 0 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.1]
training epoch 1 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.1]
training epoch 2 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.1]
training epoch 3 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 4 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.1]
training epoch 5 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 6 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 7 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 8 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 9 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 10 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032129. All blocks and scores: [(15, 0.03212899575009942), (7, 0.03255956340581179), (51, 0.04097792459651828), (49, 0.0415994799695909), (9, 0.04425756260752678), (6, 0.04648655652999878), (14, 0.04780443385243416), (4, 0.04861625097692013), (2, 0.05502765439450741), (45, 0.056978498585522175), (3, 0.05824009468778968), (13, 0.0594333834014833), (11, 0.05963814305141568), (47, 0.060546206310391426), (20, 0.06107345083728433), (17, 0.062109665013849735), (0, 0.06360903661698103), (19, 0.06499437149614096), (1, 0.06633521616458893), (52, 0.06720015872269869), (8, 0.07423356268554926), (25, 0.07745938561856747), (10, 0.08059235289692879), (27, 0.08242227137088776), (23, 0.08433778956532478), (16, 0.08626402821391821), (12, 0.08993569202721119), (37, 0.09384733904153109), (5, 0.10576075408607721), (36, 0.5645354762673378), (18, 0.6977246701717377), (53, 0.8212247937917709)]
computing accuracy for after removing block 15 . block score: 0.03212899575009942
removed block 15 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032560. All blocks and scores: [(7, 0.03255956340581179), (49, 0.04160271491855383), (51, 0.042210149113088846), (9, 0.04425756400451064), (6, 0.04648655699566007), (14, 0.04780443478375673), (4, 0.04861625237390399), (2, 0.05502765532582998), (45, 0.05662562092766166), (3, 0.05824009608477354), (20, 0.05873466515913606), (13, 0.0594333834014833), (11, 0.05963814212009311), (47, 0.062269387766718864), (0, 0.06360903847962618), (19, 0.06532025430351496), (17, 0.06588319502770901), (1, 0.0663352133706212), (52, 0.06802932545542717), (25, 0.07398977689445019), (8, 0.07423356175422668), (27, 0.07970910053700209), (23, 0.08015414327383041), (10, 0.08059235010296106), (12, 0.08993569202721119), (37, 0.09376147482544184), (16, 0.09627995826303959), (5, 0.10576075315475464), (36, 0.5523468405008316), (18, 0.6742141097784042), (53, 0.8244820609688759)]
computing accuracy for after removing block 7 . block score: 0.03255956340581179
removed block 7 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 51, with score 0.040100. All blocks and scores: [(51, 0.04010003013536334), (49, 0.0404259143397212), (9, 0.04414075752720237), (14, 0.04418446449562907), (6, 0.046486557461321354), (4, 0.04861625097692013), (13, 0.05150012858211994), (2, 0.05502765532582998), (45, 0.05533978110179305), (17, 0.05577358650043607), (11, 0.05633334582671523), (20, 0.056559485383331776), (3, 0.058240097016096115), (47, 0.060907353181391954), (19, 0.06295625818893313), (0, 0.06360903568565845), (52, 0.06394236302003264), (1, 0.0663352133706212), (25, 0.07199030742049217), (8, 0.07225663028657436), (23, 0.073982710018754), (27, 0.07655752170830965), (10, 0.08287828508764505), (12, 0.08399476576596498), (16, 0.08768901415169239), (37, 0.08862892910838127), (5, 0.10576075781136751), (36, 0.531293660402298), (18, 0.6499226838350296), (53, 0.8363339900970459)]
computing accuracy for after removing block 51 . block score: 0.04010003013536334
removed block 51 current accuracy 0.8874 loss from initial  0.06400000000000006
since last training loss: 0.054200000000000026 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.040426. All blocks and scores: [(49, 0.040425913874059916), (9, 0.04414075659587979), (14, 0.04418446496129036), (6, 0.04648655792698264), (4, 0.048616251442581415), (13, 0.05150012718513608), (2, 0.05502765625715256), (45, 0.05533978063613176), (17, 0.05577358230948448), (11, 0.056333348620682955), (20, 0.05655948491767049), (3, 0.058240098878741264), (47, 0.060907355044037104), (19, 0.06295625632628798), (0, 0.06360903568565845), (1, 0.0663352133706212), (52, 0.06780225783586502), (25, 0.07199030835181475), (8, 0.07225662935525179), (23, 0.07398271281272173), (27, 0.07655752077698708), (10, 0.08287828229367733), (12, 0.08399476762861013), (16, 0.08768901135772467), (37, 0.0886289281770587), (5, 0.10576075688004494), (36, 0.5312936678528786), (18, 0.6499226614832878), (53, 1.026183806359768)]
computing accuracy for after removing block 49 . block score: 0.040425913874059916
removed block 49 current accuracy 0.8504 loss from initial  0.10099999999999998
since last training loss: 0.09119999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.044141. All blocks and scores: [(9, 0.04414075752720237), (14, 0.04418446449562907), (6, 0.04648655652999878), (4, 0.048616251442581415), (13, 0.05150012718513608), (2, 0.05502765439450741), (45, 0.05533977970480919), (17, 0.055773585103452206), (11, 0.05633334582671523), (20, 0.056559485383331776), (3, 0.05824009608477354), (47, 0.06090735411271453), (19, 0.06295625725761056), (0, 0.06360903708264232), (1, 0.06633521243929863), (25, 0.07199030835181475), (8, 0.07225662935525179), (23, 0.0739827137440443), (52, 0.07507691532373428), (27, 0.07655751891434193), (10, 0.08287828415632248), (12, 0.08399476855993271), (16, 0.08768901322036982), (37, 0.08862892724573612), (5, 0.10576075781136751), (36, 0.5312936455011368), (18, 0.6499226912856102), (53, 1.124354511499405)]
computing accuracy for after removing block 9 . block score: 0.04414075752720237
removed block 9 current accuracy 0.829 loss from initial  0.12240000000000006
since last training loss: 0.11260000000000003 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 14, with score 0.040071. All blocks and scores: [(14, 0.040071012917906046), (6, 0.04648655839264393), (4, 0.04861625237390399), (13, 0.04882758483290672), (17, 0.0497321430593729), (11, 0.05196287576109171), (45, 0.05450971284881234), (20, 0.05501558957621455), (2, 0.055027654860168695), (3, 0.05824009422212839), (47, 0.061107538640499115), (0, 0.06360903708264232), (19, 0.06611118745058775), (1, 0.06633521243929863), (25, 0.06830957345664501), (52, 0.07028432842344046), (23, 0.07091560587286949), (16, 0.07199460826814175), (12, 0.07211725320667028), (8, 0.07225662749260664), (27, 0.07432619854807854), (37, 0.08110387343913317), (10, 0.08121351059526205), (5, 0.10576075501739979), (36, 0.4987359531223774), (18, 0.627710148692131), (53, 1.1242649108171463)]
computing accuracy for after removing block 14 . block score: 0.040071012917906046
removed block 14 current accuracy 0.8058 loss from initial  0.14560000000000006
since last training loss: 0.13580000000000003 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 6, with score 0.046487. All blocks and scores: [(6, 0.04648655839264393), (4, 0.04861625097692013), (13, 0.048827582970261574), (17, 0.04927076166495681), (20, 0.051488704048097134), (11, 0.051962878089398146), (45, 0.053109034430235624), (2, 0.05502765579149127), (3, 0.05824009561911225), (47, 0.06142217433080077), (0, 0.06360903661698103), (25, 0.06587930023670197), (1, 0.0663352133706212), (19, 0.06736457999795675), (23, 0.06794042140245438), (52, 0.06849006656557322), (27, 0.07183621730655432), (12, 0.07211725134402514), (8, 0.07225662842392921), (10, 0.08121350686997175), (37, 0.08121509104967117), (16, 0.09487774409353733), (5, 0.10576075781136751), (36, 0.4924004301428795), (18, 0.6212265491485596), (53, 1.1142411828041077)]
computing accuracy for after removing block 6 . block score: 0.04648655839264393
removed block 6 current accuracy 0.7348 loss from initial  0.21660000000000001
since last training loss: 0.20679999999999998 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 17, with score 0.045843. All blocks and scores: [(17, 0.045843339525163174), (13, 0.046044541988521814), (11, 0.04756320919841528), (20, 0.048182208091020584), (4, 0.048616251442581415), (45, 0.05134689575061202), (2, 0.055027654860168695), (3, 0.058240097016096115), (47, 0.06058342754840851), (23, 0.06101533584296703), (25, 0.0625605396926403), (52, 0.0627087913453579), (0, 0.06360903708264232), (27, 0.06620605755597353), (1, 0.06633521523326635), (12, 0.067235192283988), (19, 0.06968091148883104), (8, 0.07125423848628998), (16, 0.07817801460623741), (37, 0.07829026319086552), (10, 0.08489532675594091), (5, 0.10576075688004494), (36, 0.47658712789416313), (18, 0.6138935312628746), (53, 1.118999570608139)]
computing accuracy for after removing block 17 . block score: 0.045843339525163174
removed block 17 current accuracy 0.6824 loss from initial  0.269
since last training loss: 0.2592 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 20, with score 0.045922. All blocks and scores: [(20, 0.04592233244329691), (13, 0.04604454431682825), (11, 0.047563210129737854), (45, 0.0484373876824975), (4, 0.0486162519082427), (2, 0.05502765439450741), (23, 0.05818202206864953), (3, 0.058240097016096115), (52, 0.059760584495961666), (25, 0.06004235055297613), (47, 0.06076452136039734), (0, 0.06360903708264232), (27, 0.06497635319828987), (1, 0.0663352133706212), (12, 0.06723519321531057), (8, 0.07125423848628998), (19, 0.0733150988817215), (37, 0.07699838373810053), (16, 0.07817801460623741), (10, 0.08489532768726349), (5, 0.10576075408607721), (36, 0.44645193219184875), (18, 0.5772882327437401), (53, 1.144398033618927)]
computing accuracy for after removing block 20 . block score: 0.04592233244329691
removed block 20 current accuracy 0.656 loss from initial  0.2954
since last training loss: 0.28559999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 13, with score 0.046045. All blocks and scores: [(13, 0.046044545248150826), (45, 0.04624813888221979), (11, 0.047563208267092705), (4, 0.04861625237390399), (23, 0.05273395078256726), (25, 0.05402096873149276), (2, 0.05502765625715256), (27, 0.05628051096573472), (52, 0.05638196459040046), (47, 0.05781858740374446), (3, 0.05824009561911225), (0, 0.0636090375483036), (1, 0.0663352133706212), (12, 0.06723519321531057), (8, 0.0712542375549674), (19, 0.07331509608775377), (37, 0.07576137501746416), (16, 0.07817801274359226), (10, 0.08489532768726349), (5, 0.10576075594872236), (36, 0.4222400300204754), (18, 0.5772882476449013), (53, 1.2001555114984512)]
computing accuracy for after removing block 13 . block score: 0.046044545248150826
removed block 13 current accuracy 0.5296 loss from initial  0.42180000000000006
since last training loss: 0.41200000000000003 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 45, with score 0.043869. All blocks and scores: [(45, 0.04386899387463927), (11, 0.047563208267092705), (4, 0.0486162519082427), (23, 0.04917295463383198), (52, 0.052547761239111423), (25, 0.05450259894132614), (27, 0.054514664225280285), (2, 0.05502765625715256), (47, 0.056757228914648294), (3, 0.05824009608477354), (0, 0.06360903568565845), (1, 0.06633521616458893), (12, 0.06723519135266542), (8, 0.07125423848628998), (37, 0.07727419584989548), (19, 0.08301079273223877), (10, 0.08489532675594091), (16, 0.0946301082149148), (5, 0.10576075408607721), (36, 0.4179929606616497), (18, 0.6002736836671829), (53, 1.254791647195816)]
computing accuracy for after removing block 45 . block score: 0.04386899387463927
removed block 45 current accuracy 0.4742 loss from initial  0.4772
training start
training epoch 0 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.1]
training epoch 1 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 3 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 5 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 6 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.1]
training epoch 7 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 8 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 9 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 10 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.935200)
finished training. finished 50 epochs. accuracy 0.9352 topk_dict {'top1': 0.9352}
start iteration 33
[activation diff]: block to remove picked: 2, with score 0.054323. All blocks and scores: [(2, 0.05432303808629513), (0, 0.06372489128261805), (23, 0.06461587827652693), (19, 0.0657762736082077), (1, 0.06624993123114109), (27, 0.06708724796772003), (4, 0.06742224376648664), (25, 0.07637179456651211), (3, 0.0911833168938756), (52, 0.1111562130972743), (47, 0.112618294544518), (11, 0.11330183688551188), (37, 0.12370304483920336), (8, 0.12569992523640394), (10, 0.13717066682875156), (5, 0.20456829480826855), (16, 0.22542361170053482), (12, 0.2522831931710243), (18, 0.46838321909308434), (36, 0.5361592173576355), (53, 0.8075343444943428)]
computing accuracy for after removing block 2 . block score: 0.05432303808629513
removed block 2 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 23, with score 0.060212. All blocks and scores: [(23, 0.06021164124831557), (19, 0.061222664546221495), (4, 0.061844805255532265), (0, 0.06372489221394062), (27, 0.06374166253954172), (25, 0.06520831491798162), (1, 0.06624992936849594), (3, 0.08011171873658895), (52, 0.10118393320590258), (11, 0.10635257791727781), (47, 0.1099109910428524), (37, 0.11360680311918259), (10, 0.12866543792188168), (8, 0.12993870489299297), (16, 0.19933791272342205), (5, 0.20255447924137115), (12, 0.22557629086077213), (18, 0.42242832854390144), (36, 0.49951690807938576), (53, 0.8101641535758972)]
computing accuracy for after removing block 23 . block score: 0.06021164124831557
removed block 23 current accuracy 0.915 loss from initial  0.03639999999999999
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 27, with score 0.060993. All blocks and scores: [(27, 0.0609927368350327), (19, 0.06122266594320536), (4, 0.06184480618685484), (0, 0.06372489221394062), (25, 0.06469355709850788), (1, 0.06624993029981852), (3, 0.0801117168739438), (52, 0.09261883329600096), (11, 0.10635257419198751), (47, 0.10782444570213556), (37, 0.11843057163059711), (10, 0.12866543978452682), (8, 0.12993870303034782), (16, 0.19933791644871235), (5, 0.20255447924137115), (12, 0.22557629644870758), (18, 0.42242831736803055), (36, 0.501056369394064), (53, 0.8235596045851707)]
computing accuracy for after removing block 27 . block score: 0.0609927368350327
removed block 27 current accuracy 0.8994 loss from initial  0.052000000000000046
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 19, with score 0.061223. All blocks and scores: [(19, 0.06122266501188278), (4, 0.06184480572119355), (0, 0.06372489128261805), (25, 0.0646935598924756), (1, 0.06624993029981852), (52, 0.07818896602839231), (3, 0.08011171780526638), (47, 0.09829109720885754), (11, 0.10635257698595524), (37, 0.11817792803049088), (10, 0.12866543419659138), (8, 0.12993870489299297), (16, 0.19933790527284145), (5, 0.20255447924137115), (12, 0.22557628899812698), (18, 0.42242832481861115), (36, 0.4826214089989662), (53, 0.8348142504692078)]
computing accuracy for after removing block 19 . block score: 0.06122266501188278
removed block 19 current accuracy 0.8498 loss from initial  0.10160000000000002
since last training loss: 0.08540000000000003 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 4, with score 0.061845. All blocks and scores: [(4, 0.06184480618685484), (25, 0.06270871870219707), (0, 0.06372489128261805), (1, 0.06624992936849594), (52, 0.07267108373343945), (3, 0.0801117168739438), (47, 0.09563770331442356), (11, 0.10635257791727781), (10, 0.12866543792188168), (8, 0.12993870489299297), (37, 0.13050814345479012), (16, 0.19933791272342205), (5, 0.2025544736534357), (12, 0.22557629272341728), (18, 0.42242831364274025), (36, 0.49261943623423576), (53, 0.8205109462141991)]
computing accuracy for after removing block 4 . block score: 0.06184480618685484
removed block 4 current accuracy 0.826 loss from initial  0.12540000000000007
since last training loss: 0.10920000000000007 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 25, with score 0.059913. All blocks and scores: [(25, 0.0599127346649766), (0, 0.06372489221394062), (1, 0.06624993123114109), (52, 0.06906631588935852), (3, 0.08011171873658895), (47, 0.09252878930419683), (11, 0.09932669438421726), (10, 0.12296396214514971), (37, 0.1235922696068883), (8, 0.1298962626606226), (16, 0.17650406435132027), (12, 0.20774996653199196), (5, 0.21574383974075317), (18, 0.4204705283045769), (36, 0.4830508306622505), (53, 0.8177589401602745)]
computing accuracy for after removing block 25 . block score: 0.0599127346649766
removed block 25 current accuracy 0.757 loss from initial  0.19440000000000002
since last training loss: 0.17820000000000003 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 0, with score 0.063725. All blocks and scores: [(0, 0.06372489221394062), (52, 0.06476524658501148), (1, 0.06624993123114109), (3, 0.0801117168739438), (47, 0.08591707237064838), (11, 0.09932669252157211), (10, 0.12296395748853683), (8, 0.1298962589353323), (37, 0.13674993813037872), (16, 0.17650405876338482), (12, 0.20774995908141136), (5, 0.21574383229017258), (18, 0.420470517128706), (36, 0.5093391314148903), (53, 0.8314435705542564)]
computing accuracy for after removing block 0 . block score: 0.06372489221394062
removed block 0 current accuracy 0.6278 loss from initial  0.3236
since last training loss: 0.3074 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 52, with score 0.061448. All blocks and scores: [(52, 0.061447858810424805), (3, 0.06635876279324293), (1, 0.06857310142368078), (47, 0.08308564219623804), (11, 0.10160916857421398), (10, 0.11478693224489689), (8, 0.12464419938623905), (37, 0.13734850846230984), (16, 0.1605934090912342), (5, 0.20886018872261047), (12, 0.21478115394711494), (18, 0.4167953319847584), (36, 0.5110277011990547), (53, 0.865110494196415)]
computing accuracy for after removing block 52 . block score: 0.061447858810424805
removed block 52 current accuracy 0.5124 loss from initial  0.43900000000000006
since last training loss: 0.42280000000000006 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 3, with score 0.066359. All blocks and scores: [(3, 0.06635876279324293), (1, 0.06857310049235821), (47, 0.08308564312756062), (11, 0.10160916857421398), (10, 0.11478693876415491), (8, 0.12464419566094875), (37, 0.1373485065996647), (16, 0.1605934128165245), (5, 0.20886019244790077), (12, 0.21478114649653435), (18, 0.4167953357100487), (36, 0.5110277235507965), (53, 1.1719639003276825)]
computing accuracy for after removing block 3 . block score: 0.06635876279324293
removed block 3 current accuracy 0.4054 loss from initial  0.546
since last training loss: 0.5298 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 1, with score 0.068573. All blocks and scores: [(1, 0.06857309862971306), (47, 0.07991951983422041), (11, 0.0958486758172512), (8, 0.11128527205437422), (10, 0.11936434917151928), (37, 0.1229478633031249), (16, 0.12947468273341656), (12, 0.2002557534724474), (5, 0.22551465965807438), (18, 0.3964438885450363), (36, 0.4894150123000145), (53, 1.113545998930931)]
computing accuracy for after removing block 1 . block score: 0.06857309862971306
removed block 1 current accuracy 0.2548 loss from initial  0.6966
since last training loss: 0.6804 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 47, with score 0.077709. All blocks and scores: [(47, 0.07770875096321106), (11, 0.08718403428792953), (8, 0.09878450632095337), (10, 0.11018943693488836), (16, 0.11466154083609581), (37, 0.11725624650716782), (12, 0.18425804935395718), (5, 0.21031404472887516), (18, 0.3923438973724842), (36, 0.49847908690571785), (53, 1.1852969378232956)]
computing accuracy for after removing block 47 . block score: 0.07770875096321106
removed block 47 current accuracy 0.2048 loss from initial  0.7466
since last training loss: 0.7304 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 11, with score 0.087184. All blocks and scores: [(11, 0.08718403242528439), (8, 0.09878450445830822), (10, 0.11018943972885609), (16, 0.11466154176741838), (37, 0.11725624557584524), (12, 0.18425805494189262), (5, 0.21031405217945576), (18, 0.3923438936471939), (36, 0.49847909063100815), (53, 1.8314164131879807)]
computing accuracy for after removing block 11 . block score: 0.08718403242528439
removed block 11 current accuracy 0.1946 loss from initial  0.7568
training start
training epoch 0 val accuracy 0.7712 topk_dict {'top1': 0.7712} is_best True lr [0.1]
training epoch 1 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.1]
training epoch 2 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best True lr [0.1]
training epoch 3 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 4 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.1]
training epoch 5 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 6 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best True lr [0.1]
training epoch 7 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 8 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.1]
training epoch 9 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best True lr [0.1]
training epoch 10 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.923800)
finished training. finished 50 epochs. accuracy 0.9238 topk_dict {'top1': 0.9238}
