start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589733220637), (30, 0.010011187405325472), (31, 0.010232581640593708), (34, 0.013294660835526884), (29, 0.01342111686244607), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.02059022570028901), (25, 0.022078295471146703), (23, 0.022228715242817998), (41, 0.02233641571365297), (44, 0.023145999060943723), (40, 0.023749590618535876), (45, 0.02397549571469426), (21, 0.024941089330241084), (48, 0.02495770645327866), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.025880582630634308), (49, 0.025916648795828223), (42, 0.02623223210684955), (20, 0.026848891749978065), (47, 0.028632948407903314), (38, 0.03134434390813112), (39, 0.031441295985132456), (15, 0.03205838380381465), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241184562445), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4361986517906189), (18, 0.5117433071136475), (53, 0.8053385391831398)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013119243900291622), (29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.024941088864579797), (22, 0.025151390582323074), (49, 0.025575740495696664), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.02684889198280871), (47, 0.02807276090607047), (38, 0.0310911878477782), (39, 0.031191361136734486), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101320773363), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.059700032230466604), (17, 0.06132525438442826), (0, 0.06337464461103082), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114332690835), (36, 0.4339806064963341), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.012758882134221494), (29, 0.013421116978861392), (35, 0.01591842179186642), (26, 0.01607214123941958), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.021827629767358303), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.022891478845849633), (40, 0.023602579720318317), (45, 0.023770849220454693), (48, 0.02451987355016172), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712220929563046), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.028052504174411297), (38, 0.030935873044654727), (39, 0.031173036666586995), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.041130808647722006), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241510525346), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.4350203052163124), (18, 0.5117432922124863), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116746030748), (35, 0.01591864973306656), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019867350347340107), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.02379016880877316), (48, 0.024350045947358012), (50, 0.024463104782626033), (21, 0.02494108979590237), (22, 0.025151390815153718), (49, 0.025246930308640003), (42, 0.025273551233112812), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.027727574575692415), (38, 0.03074627462774515), (39, 0.031281794887036085), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525624707341), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693012356758), (18, 0.5117432922124863), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421117328107357), (35, 0.015968911815434694), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019837008323520422), (46, 0.020137187093496323), (41, 0.02158405538648367), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.023840720532462), (48, 0.024108359357342124), (50, 0.02411420992575586), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.027423852123320103), (38, 0.03073564963415265), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992966800928), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464461103082), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43692685663700104), (18, 0.5117432996630669), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.01655877218581736), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.020302684511989355), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.023045078152790666), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156817235052586), (45, 0.024168408941477537), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151390116661787), (42, 0.025816060369834304), (24, 0.025880583096295595), (20, 0.02684889081865549), (47, 0.02756829629652202), (38, 0.03178726392798126), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.03244550246745348), (19, 0.03254077956080437), (51, 0.04008621349930763), (37, 0.040690732188522816), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221094727516174), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.44933701306581497), (18, 0.5117433071136475), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511148124933), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.019988976884633303), (41, 0.021256205160170794), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022692032624036074), (48, 0.02352137118577957), (50, 0.023533891420811415), (40, 0.023616239661350846), (45, 0.02393329283222556), (49, 0.02444991539232433), (42, 0.024838327895849943), (21, 0.024941090028733015), (22, 0.0251513896510005), (24, 0.025880582630634308), (47, 0.02681345632299781), (20, 0.026848892215639353), (38, 0.03108373167924583), (39, 0.032056890428066254), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.03907974949106574), (37, 0.040152144618332386), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241137996316), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.05970003455877304), (52, 0.0603690748102963), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4432784505188465), (18, 0.5117432996630669), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.016986021772027016), (27, 0.018769709626212716), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022507572080940008), (48, 0.022899368545040488), (50, 0.022937727626413107), (40, 0.02305740211158991), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.024081919342279434), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.025880582397803664), (47, 0.026322791818529367), (20, 0.02684889198280871), (38, 0.03014914900995791), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.039268902968615294), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992687404156), (52, 0.05846812063828111), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143885701895), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986022237688303), (43, 0.01838199165649712), (27, 0.018769708229228854), (46, 0.01884230156429112), (41, 0.01901637064293027), (48, 0.02130915760062635), (50, 0.021624520886689425), (44, 0.021748854545876384), (40, 0.021916967583820224), (42, 0.021930373972281814), (25, 0.02207829523831606), (23, 0.022228715708479285), (45, 0.02273644902743399), (49, 0.022970063844695687), (21, 0.02494108979590237), (22, 0.025151390582323074), (47, 0.025355831254273653), (24, 0.02588058216497302), (20, 0.026848891749978065), (38, 0.02869188622571528), (39, 0.029624431394040585), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03601635666564107), (37, 0.03643036866560578), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740370184183), (52, 0.05466858018189669), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.41641608998179436), (18, 0.5117433071136475), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.016986022237688303
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862477310002), (41, 0.018467807210981846), (27, 0.018769708927720785), (48, 0.02077550836838782), (42, 0.02120647020637989), (50, 0.02130244765430689), (44, 0.021586895920336246), (40, 0.021592722041532397), (25, 0.02207829523831606), (23, 0.022228715242817998), (45, 0.022315293783321977), (49, 0.022407566430047154), (47, 0.024609397631138563), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.025880581932142377), (20, 0.02684889198280871), (38, 0.027890325523912907), (39, 0.029191895155236125), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.035506677348166704), (37, 0.03591922717168927), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241277694702), (52, 0.053374082781374454), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.061325252521783113), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.08527505863457918), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.412618201225996), (18, 0.5117433071136475), (53, 0.9067213162779808)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708927720785), (46, 0.018994680838659406), (42, 0.02120647020637989), (48, 0.02141889533959329), (50, 0.021441322285681963), (40, 0.021592722041532397), (25, 0.02207829523831606), (23, 0.02222871547564864), (49, 0.022339017828926444), (44, 0.02278283261694014), (45, 0.023323106346651912), (21, 0.024941089330241084), (22, 0.025151389883831143), (47, 0.025386077584698796), (24, 0.025880582397803664), (20, 0.026848891749978065), (38, 0.02789032505825162), (39, 0.029191894689574838), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03521771775558591), (37, 0.03591922763735056), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (52, 0.052133372984826565), (2, 0.05457740370184183), (3, 0.05784992873668671), (13, 0.059144285041838884), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4126182086765766), (18, 0.5117432847619057), (53, 0.9521220624446869)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 1 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.1]
training epoch 2 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.1]
training epoch 3 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 4 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.1]
training epoch 5 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.1]
training epoch 6 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.1]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.1]
training epoch 8 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.1]
training epoch 9 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 14 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 11
[activation diff]: block to remove picked: 40, with score 0.013106. All blocks and scores: [(40, 0.013105686753988266), (42, 0.016673679230734706), (39, 0.018791551468893886), (38, 0.02251273230649531), (46, 0.022740990854799747), (21, 0.024928167928010225), (22, 0.025161322439089417), (23, 0.025618250481784344), (25, 0.0256231261882931), (50, 0.025697454577311873), (48, 0.02625391725450754), (49, 0.026588912354782224), (45, 0.02684212289750576), (20, 0.02716290974058211), (44, 0.027185238897800446), (27, 0.027671249583363533), (24, 0.02908925525844097), (47, 0.030801197048276663), (15, 0.031915716361254454), (19, 0.03243218641728163), (7, 0.032601756509393454), (37, 0.037656583823263645), (51, 0.04106354946270585), (9, 0.04427574435248971), (6, 0.0465741790831089), (14, 0.04769686656072736), (4, 0.04774530464783311), (2, 0.054324567783623934), (3, 0.05785390129312873), (13, 0.058950729202479124), (11, 0.05941091012209654), (17, 0.061282713897526264), (0, 0.06382793840020895), (1, 0.06642212718725204), (52, 0.06677758600562811), (8, 0.07374491821974516), (10, 0.08036823011934757), (16, 0.08495608437806368), (12, 0.08969809208065271), (5, 0.10551402624696493), (36, 0.42993131279945374), (18, 0.5112694352865219), (53, 0.8041778206825256)]
computing accuracy for after removing block 40 . block score: 0.013105686753988266
removed block 40 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.016825. All blocks and scores: [(42, 0.016824736958369613), (39, 0.018791551934555173), (38, 0.022512731608003378), (46, 0.023228628560900688), (21, 0.02492816816084087), (22, 0.02516132197342813), (23, 0.025618250481784344), (25, 0.02562312502413988), (50, 0.02613710891455412), (48, 0.026689172023907304), (49, 0.02678991435095668), (20, 0.027162909973412752), (45, 0.02737776027061045), (27, 0.027671249583363533), (24, 0.02908925642259419), (44, 0.0292040987405926), (47, 0.03165000304579735), (15, 0.03191571682691574), (19, 0.03243218595162034), (7, 0.03260175511240959), (37, 0.03765658242627978), (51, 0.04164097737520933), (9, 0.04427574435248971), (6, 0.04657417815178633), (14, 0.047696867026388645), (4, 0.047745305113494396), (2, 0.05432456638664007), (3, 0.05785390129312873), (13, 0.05895073292776942), (11, 0.05941091338172555), (17, 0.06128271296620369), (0, 0.06382793840020895), (1, 0.0664221290498972), (52, 0.06887038983404636), (8, 0.07374491915106773), (10, 0.08036823011934757), (16, 0.08495608624070883), (12, 0.08969808835536242), (5, 0.10551402810961008), (36, 0.42993130534887314), (18, 0.5112694576382637), (53, 0.8442060947418213)]
computing accuracy for after removing block 42 . block score: 0.016824736958369613
removed block 42 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 39, with score 0.018792. All blocks and scores: [(39, 0.018791552167385817), (38, 0.022512731608003378), (21, 0.024928168393671513), (46, 0.024941307492554188), (22, 0.02516132383607328), (23, 0.02561825094744563), (25, 0.02562312502413988), (20, 0.027162910206243396), (50, 0.027493553701788187), (27, 0.027671250514686108), (48, 0.02790512004867196), (49, 0.027908784337341785), (24, 0.029089256189763546), (45, 0.030022697057574987), (44, 0.0314578409306705), (15, 0.03191571682691574), (19, 0.0324321873486042), (7, 0.03260175511240959), (47, 0.033841636031866074), (37, 0.037656581960618496), (51, 0.04272366035729647), (9, 0.044275743421167135), (6, 0.04657417768612504), (14, 0.04769686749204993), (4, 0.04774530604481697), (2, 0.05432456871494651), (3, 0.057853902224451303), (13, 0.05895073153078556), (11, 0.059410910587757826), (17, 0.06128271343186498), (0, 0.06382793840020895), (1, 0.06642212718725204), (52, 0.07245507277548313), (8, 0.07374491915106773), (10, 0.08036823105067015), (16, 0.08495608437806368), (12, 0.08969809114933014), (5, 0.10551402624696493), (36, 0.42993132025003433), (18, 0.5112694501876831), (53, 0.8486353904008865)]
computing accuracy for after removing block 39 . block score: 0.018791552167385817
removed block 39 current accuracy 0.9294 loss from initial  0.02200000000000002
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.022513. All blocks and scores: [(38, 0.02251273184083402), (21, 0.024928168393671513), (22, 0.025161322439089417), (46, 0.02525592385791242), (23, 0.0256182502489537), (25, 0.025623125256970525), (50, 0.026851812610402703), (20, 0.02716290927492082), (48, 0.027321718633174896), (27, 0.02767125004902482), (49, 0.027883181581273675), (24, 0.029089255491271615), (45, 0.030191450845450163), (15, 0.03191571729257703), (19, 0.03243218641728163), (7, 0.03260175511240959), (47, 0.03338882653042674), (44, 0.033557746559381485), (37, 0.03765658289194107), (51, 0.04171666130423546), (9, 0.04427574388682842), (6, 0.04657417768612504), (14, 0.047696867026388645), (4, 0.047745305113494396), (2, 0.054324567317962646), (3, 0.05785390269011259), (13, 0.058950730599462986), (11, 0.05941091105341911), (17, 0.061282713897526264), (0, 0.06382793746888638), (1, 0.06642212625592947), (52, 0.07106135878711939), (8, 0.07374491821974516), (10, 0.08036822732537985), (16, 0.08495608530938625), (12, 0.08969809208065271), (5, 0.10551402531564236), (36, 0.42993132025003433), (18, 0.5112694427371025), (53, 0.9016420841217041)]
computing accuracy for after removing block 38 . block score: 0.02251273184083402
removed block 38 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.024800000000000044 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 21, with score 0.024928. All blocks and scores: [(21, 0.0249281688593328), (22, 0.025161323370411992), (23, 0.02561825094744563), (25, 0.025623125256970525), (46, 0.025926694506779313), (50, 0.026814378332346678), (20, 0.02716290974058211), (48, 0.027331517543643713), (27, 0.02767125121317804), (49, 0.02809101273305714), (24, 0.02908925525844097), (45, 0.030446361284703016), (15, 0.03191571682691574), (19, 0.0324321873486042), (7, 0.032601756509393454), (47, 0.03306124312803149), (44, 0.03686385275796056), (37, 0.037656581960618496), (51, 0.04235661029815674), (9, 0.04427574388682842), (6, 0.04657417815178633), (14, 0.047696867026388645), (4, 0.047745305113494396), (2, 0.05432456964626908), (3, 0.057853903621435165), (13, 0.0589507301338017), (11, 0.05941091105341911), (17, 0.061282713897526264), (0, 0.06382793746888638), (1, 0.06642212625592947), (52, 0.07114256080240011), (8, 0.07374491915106773), (10, 0.08036822732537985), (16, 0.0849560834467411), (12, 0.08969808928668499), (5, 0.10551402252167463), (36, 0.4299313314259052), (18, 0.5112694352865219), (53, 0.9171292185783386)]
computing accuracy for after removing block 21 . block score: 0.0249281688593328
removed block 21 current accuracy 0.9106 loss from initial  0.04080000000000006
since last training loss: 0.03260000000000007 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.023435. All blocks and scores: [(22, 0.023434593342244625), (23, 0.023504550103098154), (25, 0.02437121537514031), (46, 0.024658998241648078), (50, 0.02489091269671917), (24, 0.0256958135869354), (48, 0.025725893210619688), (27, 0.026238977909088135), (49, 0.026925462996587157), (20, 0.02716290974058211), (45, 0.02972311293706298), (47, 0.03153786389157176), (15, 0.03191571682691574), (19, 0.03243218827992678), (7, 0.032601756043732166), (44, 0.03438644437119365), (37, 0.0361039019189775), (51, 0.04066110774874687), (9, 0.044275745283812284), (6, 0.0465741790831089), (14, 0.04769686749204993), (4, 0.04774530604481697), (2, 0.05432456824928522), (3, 0.057853901758790016), (13, 0.058950732462108135), (11, 0.059410912450402975), (17, 0.06128271436318755), (52, 0.0638277642428875), (0, 0.06382793933153152), (1, 0.06642212718725204), (8, 0.07374491915106773), (10, 0.08036823105067015), (16, 0.08495608437806368), (12, 0.08969808928668499), (5, 0.10551402531564236), (36, 0.4060853496193886), (18, 0.5112694427371025), (53, 0.9399755001068115)]
computing accuracy for after removing block 22 . block score: 0.023434593342244625
removed block 22 current accuracy 0.8984 loss from initial  0.05300000000000005
since last training loss: 0.04480000000000006 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.021748. All blocks and scores: [(23, 0.021747626597061753), (25, 0.023393164156004786), (24, 0.0234108439181), (46, 0.02345000929199159), (50, 0.02356321387924254), (48, 0.024559288984164596), (27, 0.024568490218371153), (49, 0.02594677358865738), (20, 0.027162909507751465), (45, 0.02918182802386582), (47, 0.0298939049243927), (15, 0.031915716361254454), (19, 0.032432186882942915), (44, 0.03254232928156853), (7, 0.032601756509393454), (37, 0.03654815023764968), (51, 0.03904060600325465), (9, 0.044275743421167135), (6, 0.04657417954877019), (14, 0.04769686749204993), (4, 0.047745305579155684), (2, 0.054324569180607796), (3, 0.05785390082746744), (52, 0.05872562061995268), (13, 0.05895073106512427), (11, 0.059410910587757826), (17, 0.06128271343186498), (0, 0.06382794119417667), (1, 0.06642212718725204), (8, 0.07374491728842258), (10, 0.08036823198199272), (16, 0.08495608624070883), (12, 0.08969809021800756), (5, 0.10551402345299721), (36, 0.3977806158363819), (18, 0.5112694352865219), (53, 0.949063703417778)]
computing accuracy for after removing block 23 . block score: 0.021747626597061753
removed block 23 current accuracy 0.8884 loss from initial  0.06300000000000006
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.022084. All blocks and scores: [(24, 0.022084290627390146), (25, 0.023068628972396255), (50, 0.024021394085139036), (46, 0.024316874332726002), (27, 0.02511966461315751), (48, 0.02567621204070747), (20, 0.027162909973412752), (49, 0.02728719520382583), (47, 0.030181486625224352), (45, 0.031273245345801115), (15, 0.031915715895593166), (19, 0.03243218781426549), (7, 0.032601756043732166), (44, 0.03285332815721631), (51, 0.039575891103595495), (37, 0.04073952790349722), (9, 0.04427574388682842), (6, 0.04657417815178633), (14, 0.04769686795771122), (4, 0.04774530464783311), (2, 0.054324569180607796), (3, 0.05785390129312873), (13, 0.058950729202479124), (52, 0.05903963791206479), (11, 0.05941091338172555), (17, 0.0612827162258327), (0, 0.0638279365375638), (1, 0.0664221253246069), (8, 0.07374491635710001), (10, 0.08036822825670242), (16, 0.08495608530938625), (12, 0.08969808835536242), (5, 0.10551402531564236), (36, 0.41866156458854675), (18, 0.5112694278359413), (53, 0.9343820437788963)]
computing accuracy for after removing block 24 . block score: 0.022084290627390146
removed block 24 current accuracy 0.8746 loss from initial  0.07679999999999998
since last training loss: 0.0686 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.022330. All blocks and scores: [(50, 0.022330275271087885), (46, 0.022687155287712812), (25, 0.02321875048801303), (48, 0.024350258754566312), (27, 0.02458659838885069), (49, 0.026137314271181822), (20, 0.02716290974058211), (47, 0.02866161265410483), (45, 0.030614663613960147), (15, 0.03191571682691574), (44, 0.032032405491918325), (19, 0.032432186882942915), (7, 0.032601756509393454), (51, 0.037442104890942574), (37, 0.040121289901435375), (9, 0.044275745283812284), (6, 0.04657417954877019), (14, 0.04769686795771122), (4, 0.047745305113494396), (52, 0.052147204987704754), (2, 0.05432456824928522), (3, 0.057853902224451303), (13, 0.0589507301338017), (11, 0.059410912450402975), (17, 0.061282713897526264), (0, 0.06382793746888638), (1, 0.0664221253246069), (8, 0.07374491821974516), (10, 0.080368229188025), (16, 0.08495608624070883), (12, 0.08969809114933014), (5, 0.10551402531564236), (36, 0.4138493090867996), (18, 0.5112694352865219), (53, 0.9754997119307518)]
computing accuracy for after removing block 50 . block score: 0.022330275271087885
removed block 50 current accuracy 0.8598 loss from initial  0.09160000000000001
since last training loss: 0.08340000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 46, with score 0.022687. All blocks and scores: [(46, 0.02268715505488217), (25, 0.02321875048801303), (48, 0.024350257823243737), (27, 0.02458659838885069), (49, 0.02613731473684311), (20, 0.027162909507751465), (47, 0.028661613818258047), (45, 0.03061466454528272), (15, 0.03191571682691574), (44, 0.03203240595757961), (19, 0.03243218781426549), (7, 0.032601756043732166), (37, 0.04012128850445151), (51, 0.041258592158555984), (9, 0.04427574435248971), (6, 0.04657417954877019), (14, 0.04769686795771122), (4, 0.047745305113494396), (2, 0.054324567317962646), (3, 0.05785390408709645), (13, 0.058950730599462986), (11, 0.05941090872511268), (17, 0.06128271343186498), (52, 0.06166629120707512), (0, 0.06382793746888638), (1, 0.06642212625592947), (8, 0.07374491635710001), (10, 0.080368229188025), (16, 0.08495608530938625), (12, 0.08969808928668499), (5, 0.10551402624696493), (36, 0.4138493090867996), (18, 0.5112694427371025), (53, 1.1572779715061188)]
computing accuracy for after removing block 46 . block score: 0.02268715505488217
removed block 46 current accuracy 0.8466 loss from initial  0.1048
since last training loss: 0.09660000000000002 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.023219. All blocks and scores: [(25, 0.023218750022351742), (27, 0.024586598156020045), (48, 0.025827887933701277), (20, 0.02716290927492082), (49, 0.02758990228176117), (45, 0.030614664079621434), (47, 0.031282172771170735), (15, 0.03191571682691574), (44, 0.03203240595757961), (19, 0.03243218595162034), (7, 0.032601756509393454), (37, 0.04012128943577409), (51, 0.04219047678634524), (9, 0.044275743421167135), (6, 0.046574178617447615), (14, 0.04769686749204993), (4, 0.047745306976139545), (2, 0.05432456964626908), (3, 0.05785390129312873), (13, 0.0589507301338017), (11, 0.05941091105341911), (17, 0.06128271343186498), (52, 0.06294975848868489), (0, 0.06382793746888638), (1, 0.0664221253246069), (8, 0.07374491821974516), (10, 0.08036823011934757), (16, 0.08495608437806368), (12, 0.08969809021800756), (5, 0.10551402345299721), (36, 0.4138493053615093), (18, 0.5112694501876831), (53, 1.27320297062397)]
computing accuracy for after removing block 25 . block score: 0.023218750022351742
removed block 25 current accuracy 0.8214 loss from initial  0.13
training start
training epoch 0 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best True lr [0.1]
training epoch 1 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best True lr [0.1]
training epoch 2 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 3 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.1]
training epoch 4 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best True lr [0.1]
training epoch 5 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 6 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.1]
training epoch 7 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.1]
training epoch 8 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 9 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.027480. All blocks and scores: [(49, 0.027480052784085274), (48, 0.03012199979275465), (15, 0.03216340392827988), (7, 0.032639351673424244), (9, 0.04417166765779257), (51, 0.044729930348694324), (47, 0.04562577186152339), (45, 0.0458550532348454), (6, 0.046295423060655594), (4, 0.04676442500203848), (14, 0.04813042189925909), (2, 0.05482784518972039), (44, 0.05569036956876516), (3, 0.057669580448418856), (11, 0.05962313758209348), (13, 0.05983221996575594), (17, 0.06267806375399232), (0, 0.06396118924021721), (1, 0.0675857262685895), (52, 0.06960822734981775), (8, 0.07471760921180248), (20, 0.07933412864804268), (19, 0.08011369686573744), (10, 0.08104461338371038), (16, 0.08641314692795277), (12, 0.09053638577461243), (37, 0.09106302075088024), (27, 0.10294239968061447), (5, 0.10716359876096249), (36, 0.6087721884250641), (18, 0.6545513868331909), (53, 0.8135720863938332)]
computing accuracy for after removing block 49 . block score: 0.027480052784085274
removed block 49 current accuracy 0.9292 loss from initial  0.022199999999999998
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.030122. All blocks and scores: [(48, 0.030121999559924006), (15, 0.03216340532526374), (7, 0.03263935120776296), (9, 0.04417166765779257), (47, 0.0456257713958621), (45, 0.04585505276918411), (6, 0.04629542399197817), (4, 0.04676442453637719), (51, 0.04780361009761691), (14, 0.04813042236492038), (2, 0.05482784379273653), (44, 0.05569037143141031), (3, 0.05766957998275757), (11, 0.05962314084172249), (13, 0.05983221996575594), (17, 0.06267806235700846), (0, 0.06396119110286236), (1, 0.0675857262685895), (8, 0.07471760828047991), (20, 0.07933413051068783), (52, 0.07971186935901642), (19, 0.08011369872838259), (10, 0.08104461058974266), (16, 0.08641315065324306), (12, 0.09053638484328985), (37, 0.09106302168220282), (27, 0.10294240154325962), (5, 0.10716359876096249), (36, 0.6087721809744835), (18, 0.6545514166355133), (53, 0.8920548260211945)]
computing accuracy for after removing block 48 . block score: 0.030121999559924006
removed block 48 current accuracy 0.909 loss from initial  0.04239999999999999
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032163. All blocks and scores: [(15, 0.03216340485960245), (7, 0.032639351673424244), (9, 0.04417166719213128), (47, 0.045625770930200815), (45, 0.04585505509749055), (6, 0.04629542492330074), (4, 0.04676442500203848), (51, 0.04745475668460131), (14, 0.04813042329624295), (2, 0.054827844724059105), (44, 0.055690370965749025), (3, 0.05766957998275757), (11, 0.05962313571944833), (13, 0.059832219034433365), (17, 0.0626780609600246), (0, 0.06396118830889463), (1, 0.0675857262685895), (8, 0.07471760921180248), (20, 0.07933412492275238), (19, 0.08011369872838259), (10, 0.08104461431503296), (16, 0.08641314972192049), (12, 0.09053638391196728), (37, 0.09106301981955767), (52, 0.09419296495616436), (27, 0.10294239968061447), (5, 0.10716359596699476), (36, 0.6087721660733223), (18, 0.6545513719320297), (53, 0.9501088261604309)]
computing accuracy for after removing block 15 . block score: 0.03216340485960245
removed block 15 current accuracy 0.8978 loss from initial  0.05359999999999998
since last training loss: 0.04499999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032639. All blocks and scores: [(7, 0.03263935213908553), (9, 0.044171666726469994), (45, 0.04598031658679247), (6, 0.04629542352631688), (4, 0.046764424070715904), (47, 0.04719371162354946), (51, 0.04738169442862272), (14, 0.04813042189925909), (2, 0.05482784425839782), (44, 0.05493254167959094), (3, 0.05766957951709628), (11, 0.0596231366507709), (13, 0.05983221996575594), (0, 0.06396119017153978), (17, 0.0665555726736784), (1, 0.06758572533726692), (8, 0.07471760921180248), (20, 0.07499817851930857), (19, 0.08041752874851227), (10, 0.08104461152106524), (12, 0.09053638577461243), (37, 0.09068265836685896), (52, 0.0959518076851964), (16, 0.0964398616924882), (27, 0.09743099100887775), (5, 0.10716359782963991), (36, 0.599677100777626), (18, 0.6360784396529198), (53, 0.9599478840827942)]
computing accuracy for after removing block 7 . block score: 0.03263935213908553
removed block 7 current accuracy 0.8868 loss from initial  0.06459999999999999
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.044058. All blocks and scores: [(9, 0.04405820369720459), (14, 0.044468531385064125), (45, 0.045129832811653614), (47, 0.04624704550951719), (51, 0.04625303950160742), (6, 0.04629542399197817), (4, 0.04676442360505462), (13, 0.051800364162772894), (44, 0.05447253864258528), (2, 0.05482784425839782), (11, 0.056340092327445745), (17, 0.0563555583357811), (3, 0.05766957998275757), (0, 0.06396118924021721), (1, 0.06758572719991207), (20, 0.07072320021688938), (8, 0.0727309724316001), (19, 0.07662497740238905), (10, 0.08345026429742575), (12, 0.08460106328129768), (16, 0.08782151248306036), (37, 0.08808380179107189), (52, 0.09102967288345098), (27, 0.09253049455583096), (5, 0.10716360062360764), (36, 0.5853838175535202), (18, 0.6146606653928757), (53, 0.9828273952007294)]
computing accuracy for after removing block 9 . block score: 0.04405820369720459
removed block 9 current accuracy 0.8688 loss from initial  0.0826
since last training loss: 0.07399999999999995 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 14, with score 0.040309. All blocks and scores: [(14, 0.04030856629833579), (51, 0.04313459387049079), (45, 0.04494002601131797), (6, 0.046295423060655594), (4, 0.04676442500203848), (47, 0.04698585160076618), (13, 0.049162760842591524), (17, 0.05023615946993232), (11, 0.05200489843264222), (44, 0.05346807558089495), (2, 0.054827842861413956), (3, 0.05766957951709628), (0, 0.06396118737757206), (1, 0.06758572719991207), (20, 0.06881358753889799), (16, 0.07222366239875555), (8, 0.0727309724316001), (12, 0.07276657223701477), (19, 0.07582542859017849), (37, 0.08139763213694096), (10, 0.08185289148241282), (52, 0.08541242126375437), (27, 0.08791116438806057), (5, 0.10716359503567219), (36, 0.555351011455059), (18, 0.5946719273924828), (53, 0.9996991381049156)]
computing accuracy for after removing block 14 . block score: 0.04030856629833579
removed block 14 current accuracy 0.8406 loss from initial  0.11080000000000001
since last training loss: 0.10219999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.041573. All blocks and scores: [(51, 0.04157274076715112), (45, 0.043806974310427904), (6, 0.046295423060655594), (4, 0.04676442360505462), (47, 0.04778198944404721), (13, 0.04916276130825281), (17, 0.04976200545206666), (11, 0.05200489703565836), (44, 0.05237375712022185), (2, 0.05482784518972039), (3, 0.057669578585773706), (0, 0.06396118737757206), (20, 0.06451300624758005), (1, 0.06758572719991207), (8, 0.07273097150027752), (12, 0.07276657409965992), (19, 0.07490182854235172), (37, 0.08174684271216393), (10, 0.08185289148241282), (52, 0.08337374590337276), (27, 0.08408032730221748), (16, 0.09511845745146275), (5, 0.10716359876096249), (36, 0.5524495169520378), (18, 0.5924904569983482), (53, 1.0078586339950562)]
computing accuracy for after removing block 51 . block score: 0.04157274076715112
removed block 51 current accuracy 0.7598 loss from initial  0.1916
since last training loss: 0.18299999999999994 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 45, with score 0.043807. All blocks and scores: [(45, 0.04380697477608919), (6, 0.04629542399197817), (4, 0.04676442500203848), (47, 0.04778198804706335), (13, 0.049162762239575386), (17, 0.04976200358942151), (11, 0.052004897966980934), (44, 0.05237375572323799), (2, 0.05482784332707524), (3, 0.05766957765445113), (0, 0.06396118924021721), (20, 0.06451300531625748), (1, 0.06758572719991207), (8, 0.07273097056895494), (12, 0.07276657409965992), (52, 0.07423700112849474), (19, 0.07490183040499687), (37, 0.0817468436434865), (10, 0.08185289148241282), (27, 0.08408032637089491), (16, 0.0951184593141079), (5, 0.10716359689831734), (36, 0.5524495095014572), (18, 0.5924904644489288), (53, 1.2349212169647217)]
computing accuracy for after removing block 45 . block score: 0.04380697477608919
removed block 45 current accuracy 0.7066 loss from initial  0.24480000000000002
since last training loss: 0.23619999999999997 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.046295. All blocks and scores: [(6, 0.04629542399197817), (4, 0.04676442500203848), (13, 0.04916276130825281), (17, 0.04976200731471181), (11, 0.052004897966980934), (44, 0.05237375712022185), (47, 0.05256034806370735), (2, 0.05482784565538168), (3, 0.05766957998275757), (0, 0.06396119017153978), (20, 0.0645130043849349), (1, 0.0675857262685895), (8, 0.07273097056895494), (12, 0.07276657316833735), (52, 0.07333656121045351), (19, 0.07490183040499687), (37, 0.08174684271216393), (10, 0.08185289148241282), (27, 0.08408032450824976), (16, 0.09511846024543047), (5, 0.10716359876096249), (36, 0.552449494600296), (18, 0.5924904644489288), (53, 1.3616441041231155)]
computing accuracy for after removing block 6 . block score: 0.04629542399197817
removed block 6 current accuracy 0.6096 loss from initial  0.3418
since last training loss: 0.33319999999999994 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.046261. All blocks and scores: [(17, 0.04626091476529837), (13, 0.04634186951443553), (4, 0.046764424070715904), (11, 0.04758051596581936), (44, 0.05084448354318738), (47, 0.05190701363608241), (2, 0.05482784379273653), (3, 0.05766958137974143), (20, 0.05955833429470658), (0, 0.06396118737757206), (1, 0.06758572533726692), (12, 0.0678053330630064), (52, 0.06820787861943245), (8, 0.07161247450858355), (19, 0.07363022305071354), (27, 0.0769213791936636), (16, 0.07840605080127716), (37, 0.07927461061626673), (10, 0.08558167517185211), (5, 0.10716360341757536), (36, 0.5392083078622818), (18, 0.5879260525107384), (53, 1.3841292411088943)]
computing accuracy for after removing block 17 . block score: 0.04626091476529837
removed block 17 current accuracy 0.5778 loss from initial  0.37360000000000004
since last training loss: 0.365 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.046342. All blocks and scores: [(13, 0.046341868583112955), (4, 0.046764424070715904), (11, 0.04758051410317421), (44, 0.04810293996706605), (47, 0.05114181386306882), (2, 0.05482784518972039), (20, 0.05765112256631255), (3, 0.05766958091408014), (0, 0.06396119203418493), (52, 0.06558427028357983), (1, 0.06758572533726692), (12, 0.0678053330630064), (19, 0.07145290914922953), (8, 0.07161247730255127), (37, 0.07410992216318846), (27, 0.07468930445611477), (16, 0.07840605173259974), (10, 0.08558167610317469), (5, 0.10716359410434961), (36, 0.49727705121040344), (18, 0.557920940220356), (53, 1.3942347019910812)]
computing accuracy for after removing block 13 . block score: 0.046341868583112955
removed block 13 current accuracy 0.4536 loss from initial  0.4978
training start
training epoch 0 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best True lr [0.1]
training epoch 1 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 2 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 3 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 4 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.1]
training epoch 5 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 6 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 9 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
loading model_best from epoch 24 (acc 0.939000)
finished training. finished 50 epochs. accuracy 0.939 topk_dict {'top1': 0.939}
start iteration 33
[activation diff]: block to remove picked: 2, with score 0.055007. All blocks and scores: [(2, 0.05500708054751158), (4, 0.0596378929913044), (0, 0.06482792552560568), (1, 0.06748437881469727), (52, 0.07066651247441769), (47, 0.07399019505828619), (44, 0.0797030096873641), (20, 0.08026874251663685), (19, 0.08118937723338604), (37, 0.09923662710934877), (3, 0.10276678670197725), (27, 0.10380370542407036), (11, 0.11581136845052242), (8, 0.13999748975038528), (10, 0.1673853863030672), (5, 0.21236043609678745), (16, 0.2134084291756153), (12, 0.2609044909477234), (36, 0.5189110413193703), (18, 0.6407739520072937), (53, 0.8209679052233696)]
computing accuracy for after removing block 2 . block score: 0.05500708054751158
removed block 2 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.057633. All blocks and scores: [(4, 0.05763284722343087), (52, 0.06481669377535582), (0, 0.0648279245942831), (1, 0.06748437602072954), (47, 0.07157891057431698), (20, 0.07301161531358957), (19, 0.07483410928398371), (44, 0.07532709743827581), (37, 0.09126002062112093), (3, 0.09193174913525581), (27, 0.09702122118324041), (11, 0.1082168435677886), (8, 0.1433490701019764), (10, 0.1622995100915432), (16, 0.18883150815963745), (5, 0.20677188783884048), (12, 0.23045642860233784), (36, 0.48411015421152115), (18, 0.5819646716117859), (53, 0.8357703983783722)]
computing accuracy for after removing block 4 . block score: 0.05763284722343087
removed block 4 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 52, with score 0.060769. All blocks and scores: [(52, 0.060768724884837866), (0, 0.06482792738825083), (1, 0.06748437881469727), (47, 0.0697897681966424), (20, 0.07202151324599981), (44, 0.07275724969804287), (19, 0.07607418857514858), (37, 0.08946535084396601), (3, 0.09193175286054611), (27, 0.09595858585089445), (11, 0.10210208967328072), (8, 0.14184400998055935), (10, 0.16267165914177895), (16, 0.17558600194752216), (5, 0.21371492557227612), (12, 0.2210268545895815), (36, 0.47231553867459297), (18, 0.5781792923808098), (53, 0.8210500255227089)]
computing accuracy for after removing block 52 . block score: 0.060768724884837866
removed block 52 current accuracy 0.8618 loss from initial  0.08960000000000001
since last training loss: 0.07719999999999994 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.064828. All blocks and scores: [(0, 0.06482792738825083), (1, 0.06748437788337469), (47, 0.0697897681966424), (20, 0.07202150952070951), (44, 0.07275725156068802), (19, 0.07607418764382601), (37, 0.08946534991264343), (3, 0.09193175099790096), (27, 0.09595858864486217), (11, 0.10210208967328072), (8, 0.1418440118432045), (10, 0.1626716647297144), (16, 0.1755860038101673), (5, 0.21371493116021156), (12, 0.22102684900164604), (36, 0.47231554239988327), (18, 0.5781792998313904), (53, 0.923275537788868)]
computing accuracy for after removing block 0 . block score: 0.06482792738825083
removed block 0 current accuracy 0.811 loss from initial  0.14039999999999997
since last training loss: 0.1279999999999999 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 20, with score 0.067934. All blocks and scores: [(20, 0.0679337028414011), (47, 0.06892369501292706), (1, 0.07001376338303089), (44, 0.07013126462697983), (19, 0.07410045247524977), (3, 0.07545363996177912), (27, 0.08812041860073805), (37, 0.0895959921181202), (11, 0.09985250886529684), (8, 0.1392471380531788), (10, 0.1537580918520689), (16, 0.1642950363457203), (5, 0.21056305058300495), (12, 0.21491713635623455), (36, 0.4629746191203594), (18, 0.5736429244279861), (53, 0.9061740040779114)]
computing accuracy for after removing block 20 . block score: 0.0679337028414011
removed block 20 current accuracy 0.8004 loss from initial  0.15100000000000002
since last training loss: 0.13859999999999995 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 44, with score 0.064739. All blocks and scores: [(44, 0.06473871786147356), (47, 0.06578604783862829), (1, 0.07001376058906317), (19, 0.07410045061260462), (3, 0.07545363996177912), (27, 0.0757131576538086), (37, 0.08865808788686991), (11, 0.09985251165926456), (8, 0.13924713619053364), (10, 0.1537580844014883), (16, 0.1642950288951397), (5, 0.2105630487203598), (12, 0.2149171344935894), (36, 0.44196662679314613), (18, 0.5736429244279861), (53, 0.7840624526143074)]
computing accuracy for after removing block 44 . block score: 0.06473871786147356
removed block 44 current accuracy 0.715 loss from initial  0.23640000000000005
since last training loss: 0.22399999999999998 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 1, with score 0.070014. All blocks and scores: [(1, 0.07001376152038574), (19, 0.07410045247524977), (3, 0.07545363903045654), (27, 0.07571316137909889), (47, 0.08177525084465742), (37, 0.08865808695554733), (11, 0.09985251072794199), (8, 0.13924713619053364), (10, 0.15375808253884315), (16, 0.16429503262043), (5, 0.2105630449950695), (12, 0.21491714194417), (36, 0.44196663424372673), (18, 0.5736429169774055), (53, 0.9274264201521873)]
computing accuracy for after removing block 1 . block score: 0.07001376152038574
removed block 1 current accuracy 0.5258 loss from initial  0.4256
since last training loss: 0.4131999999999999 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 27, with score 0.060728. All blocks and scores: [(27, 0.060727706644684076), (19, 0.061555941589176655), (3, 0.0686960257589817), (47, 0.07824600394815207), (37, 0.08769566472619772), (11, 0.09193743113428354), (8, 0.13406825810670853), (16, 0.13662999868392944), (10, 0.14213929139077663), (12, 0.1860520001500845), (5, 0.18875272385776043), (36, 0.4452384188771248), (18, 0.5700550153851509), (53, 0.851965881884098)]
computing accuracy for after removing block 27 . block score: 0.060727706644684076
removed block 27 current accuracy 0.4486 loss from initial  0.5028
since last training loss: 0.49039999999999995 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 19, with score 0.061556. All blocks and scores: [(19, 0.06155594205483794), (3, 0.06869602762162685), (47, 0.07828639820218086), (11, 0.09193743020296097), (37, 0.101638606749475), (8, 0.13406825438141823), (16, 0.136629993095994), (10, 0.14213929139077663), (12, 0.1860520001500845), (5, 0.18875271826982498), (36, 0.4905715398490429), (18, 0.5700550153851509), (53, 0.9353913217782974)]
computing accuracy for after removing block 19 . block score: 0.06155594205483794
removed block 19 current accuracy 0.384 loss from initial  0.5674
since last training loss: 0.5549999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 3, with score 0.068696. All blocks and scores: [(3, 0.06869602482765913), (47, 0.07574780192226171), (11, 0.09193742740899324), (37, 0.11009863764047623), (8, 0.13406825438141823), (16, 0.13662999868392944), (10, 0.14213929139077663), (12, 0.1860519926995039), (5, 0.18875272013247013), (36, 0.4997718036174774), (18, 0.5700550153851509), (53, 0.9221920371055603)]
computing accuracy for after removing block 3 . block score: 0.06869602482765913
removed block 3 current accuracy 0.282 loss from initial  0.6694
since last training loss: 0.657 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 47, with score 0.076162. All blocks and scores: [(47, 0.07616172451525927), (11, 0.08702756464481354), (37, 0.10692374501377344), (16, 0.11602299474179745), (8, 0.12174111884087324), (10, 0.14487002044916153), (12, 0.17671758122742176), (5, 0.1981219220906496), (36, 0.49150140956044197), (18, 0.5555869787931442), (53, 0.895446240901947)]
computing accuracy for after removing block 47 . block score: 0.07616172451525927
removed block 47 current accuracy 0.187 loss from initial  0.7644
since last training loss: 0.752 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 11, with score 0.087028. All blocks and scores: [(11, 0.08702756557613611), (37, 0.10692374128848314), (16, 0.1160229966044426), (8, 0.12174111790955067), (10, 0.14487001858651638), (12, 0.17671758122742176), (5, 0.1981219220906496), (36, 0.49150140956044197), (18, 0.5555869713425636), (53, 1.4631625413894653)]
computing accuracy for after removing block 11 . block score: 0.08702756557613611
removed block 11 current accuracy 0.172 loss from initial  0.7794000000000001
training start
training epoch 0 val accuracy 0.7808 topk_dict {'top1': 0.7808} is_best True lr [0.1]
training epoch 1 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best True lr [0.1]
training epoch 2 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 3 val accuracy 0.86 topk_dict {'top1': 0.86} is_best True lr [0.1]
training epoch 4 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 5 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best True lr [0.1]
training epoch 6 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best True lr [0.1]
training epoch 7 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 8 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.1]
training epoch 9 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 10 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9158 topk_dict {'top1': 0.9158}
