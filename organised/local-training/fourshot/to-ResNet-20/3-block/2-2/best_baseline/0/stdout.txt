start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589733220637), (30, 0.01001118787098676), (31, 0.010232581058517098), (34, 0.013294660835526884), (29, 0.013421116629615426), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.01999649195931852), (46, 0.02059022570028901), (25, 0.022078295005485415), (23, 0.022228716406971216), (41, 0.022336416644975543), (44, 0.02314599882811308), (40, 0.02374959015287459), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957706686109304), (22, 0.02515139034949243), (50, 0.025287175085395575), (24, 0.025880583096295595), (49, 0.025916648097336292), (42, 0.02623223140835762), (20, 0.026848891517147422), (47, 0.028632949572056532), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.06606104597449303), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4361986443400383), (18, 0.5117432847619057), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.013119244133122265), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016093928134068847), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.020300706150010228), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.02297719311900437), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.02454021736048162), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.02557574026286602), (24, 0.02588058216497302), (42, 0.025893413461744785), (20, 0.026848891749978065), (47, 0.028072760440409184), (38, 0.03109118831343949), (39, 0.031191361136734486), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.041271012742072344), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241091430187), (2, 0.05457740416750312), (3, 0.057849925477057695), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464461103082), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.012758882367052138), (29, 0.013421116629615426), (35, 0.01591842109337449), (26, 0.01607214054092765), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.02182762953452766), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.023602579021826386), (45, 0.023770849220454693), (48, 0.02451987285166979), (50, 0.02463935036212206), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712219532579184), (24, 0.025880581932142377), (20, 0.02684889198280871), (47, 0.02805250510573387), (38, 0.030935873044654727), (39, 0.031173036200925708), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077956080437), (37, 0.038343189749866724), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464926764369), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.4350202977657318), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.01591864926740527), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168343111873), (48, 0.0243500464130193), (50, 0.024463105713948607), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.02588058216497302), (20, 0.02684889081865549), (47, 0.027727575739845634), (38, 0.030746274394914508), (39, 0.03128179651685059), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03895266680046916), (51, 0.04082479886710644), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740696147084), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06356756296008825), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.437769316136837), (18, 0.5117433145642281), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116513200104), (35, 0.01596891228109598), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.022687325021252036), (40, 0.02356909797526896), (45, 0.023840721463784575), (48, 0.024108359590172768), (50, 0.024114209227263927), (49, 0.024870117427781224), (21, 0.02494108979590237), (42, 0.025045574875548482), (22, 0.025151390815153718), (24, 0.025880583096295595), (20, 0.026848892215639353), (47, 0.027423852123320103), (38, 0.03073564893566072), (39, 0.0314104245044291), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.039083508774638176), (51, 0.04034593841060996), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740603014827), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.0597000359557569), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421117211692035), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.02032419736497104), (41, 0.021962702739983797), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.023045077919960022), (48, 0.024024546844884753), (50, 0.024096972541883588), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151390815153718), (42, 0.025816060369834304), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.027568295830860734), (38, 0.031787265092134476), (15, 0.032058384735137224), (39, 0.03225791407749057), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.040690730791538954), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525485008955), (52, 0.06221094960346818), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.44933701679110527), (18, 0.5117433071136475), (53, 0.8277030512690544)]
computing accuracy for after removing block 29 . block score: 0.013421117211692035
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370511380955577), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01985670323483646), (46, 0.01998897548764944), (41, 0.021256205393001437), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02269203308969736), (48, 0.023521372117102146), (50, 0.023533890722319484), (40, 0.023616241058334708), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.024941088631749153), (22, 0.025151390116661787), (24, 0.02588058216497302), (47, 0.026813456090167165), (20, 0.026848891517147422), (38, 0.031083731912076473), (39, 0.03205688949674368), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.03907974902540445), (37, 0.04015214554965496), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772257208824), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428550750017), (11, 0.059700033627450466), (52, 0.06036907574161887), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537981152534), (5, 0.10671143420040607), (36, 0.4432784467935562), (18, 0.5117432922124863), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.016986022237688303), (27, 0.018769708462059498), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.02051579928956926), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.022507572313770652), (48, 0.022899368312209845), (50, 0.022937727626413107), (40, 0.023057401878759265), (42, 0.023520407965406775), (45, 0.02363370032981038), (49, 0.024081919342279434), (21, 0.024941088631749153), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026322791818529367), (20, 0.026848891749978065), (38, 0.03014914900995791), (39, 0.03146669687703252), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.03926890343427658), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (52, 0.05846812063828111), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.43490004166960716), (18, 0.5117432847619057), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.01838199095800519), (27, 0.018769708927720785), (46, 0.01884230226278305), (41, 0.019016370875760913), (48, 0.021309157367795706), (50, 0.021624520886689425), (44, 0.021748854778707027), (40, 0.021916966885328293), (42, 0.0219303744379431), (25, 0.022078294539824128), (23, 0.022228715242817998), (45, 0.02273644902743399), (49, 0.022970063611865044), (21, 0.024941089330241084), (22, 0.02515139034949243), (47, 0.025355831254273653), (24, 0.025880583096295595), (20, 0.026848891749978065), (38, 0.02869188622571528), (39, 0.02962443232536316), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077769815922), (51, 0.03601635806262493), (37, 0.03643036866560578), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740370184183), (52, 0.05466857925057411), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325255781412125), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.41641608998179436), (18, 0.5117432922124863), (53, 0.8948249369859695)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.018358625005930662), (41, 0.018467806978151202), (27, 0.01876970869489014), (48, 0.020775508601218462), (42, 0.02120647020637989), (50, 0.021302447887137532), (44, 0.021586894989013672), (40, 0.02159272227436304), (25, 0.02207829523831606), (23, 0.022228715708479285), (45, 0.02231529401615262), (49, 0.02240756689570844), (47, 0.024609397631138563), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880581233650446), (20, 0.02684889198280871), (38, 0.02789032575674355), (39, 0.029191895155236125), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03550667688250542), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241184562445), (52, 0.053374082781374454), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750651538372), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.412618201225996), (18, 0.5117432922124863), (53, 0.9067213460803032)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769709626212716), (46, 0.01899468107149005), (42, 0.021206469973549247), (48, 0.021418895106762648), (50, 0.02144132275134325), (40, 0.021592722041532397), (25, 0.02207829523831606), (23, 0.022228715242817998), (49, 0.022339018061757088), (44, 0.02278283331543207), (45, 0.023323107045143843), (21, 0.024941090028733015), (22, 0.025151391280815005), (47, 0.025386078050360084), (24, 0.02588058286346495), (20, 0.02684889198280871), (38, 0.02789032505825162), (39, 0.029191894689574838), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03521771728992462), (37, 0.03591922763735056), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241417393088), (52, 0.05213337345048785), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428550750017), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.412618201225996), (18, 0.5117433071136475), (53, 0.9521220698952675)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 1 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.1]
training epoch 2 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.1]
training epoch 3 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.1]
training epoch 4 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 5 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 6 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.1]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 8 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.1]
training epoch 9 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 11
[activation diff]: block to remove picked: 45, with score 0.012086. All blocks and scores: [(45, 0.012085966183803976), (44, 0.012474085437133908), (40, 0.0151393658015877), (42, 0.01560836413409561), (23, 0.022726083640009165), (46, 0.025098204147070646), (21, 0.025170552544295788), (22, 0.025543901370838284), (39, 0.025568536249920726), (50, 0.026597848162055016), (37, 0.026970835402607918), (49, 0.027231980580836535), (20, 0.027434169547632337), (48, 0.02808634750545025), (25, 0.03069355385378003), (24, 0.031119887251406908), (27, 0.03191897552460432), (15, 0.032223982736468315), (19, 0.03257038351148367), (38, 0.03257545595988631), (47, 0.03289578948169947), (7, 0.03290830086916685), (51, 0.04180932231247425), (9, 0.04394826991483569), (6, 0.04741221433505416), (14, 0.04816280910745263), (4, 0.04981236066669226), (2, 0.05545353889465332), (3, 0.05897902604192495), (13, 0.059242088347673416), (11, 0.06002802401781082), (17, 0.06198619259521365), (0, 0.06432518642395735), (1, 0.06773518584668636), (52, 0.06796220317482948), (8, 0.07543656323105097), (10, 0.08115739189088345), (16, 0.08612149488180876), (12, 0.09119799267500639), (5, 0.1070875097066164), (36, 0.3805130012333393), (18, 0.5156984850764275), (53, 0.800782099366188)]
computing accuracy for after removing block 45 . block score: 0.012085966183803976
removed block 45 current accuracy 0.9378 loss from initial  0.013600000000000056
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 44, with score 0.012474. All blocks and scores: [(44, 0.01247408555354923), (40, 0.015139365918003023), (42, 0.015608363901264966), (23, 0.02272608387283981), (46, 0.02493475889787078), (21, 0.025170552311465144), (22, 0.025543900672346354), (39, 0.025568536249920726), (37, 0.026970835169777274), (49, 0.0271298389416188), (50, 0.027374376077204943), (20, 0.027434168849140406), (48, 0.02854624530300498), (25, 0.030693553620949388), (24, 0.03111988794989884), (27, 0.031918976455926895), (15, 0.0322239832021296), (19, 0.03257038304582238), (38, 0.03257545595988631), (7, 0.03290830086916685), (47, 0.0330494181253016), (51, 0.04132927069440484), (9, 0.04394826991483569), (6, 0.04741221247240901), (14, 0.048162808641791344), (4, 0.04981236020103097), (2, 0.055453541688621044), (3, 0.058979025576263666), (13, 0.0592420888133347), (11, 0.06002802588045597), (17, 0.06198619492352009), (0, 0.06432518549263477), (52, 0.06743697356432676), (1, 0.06773518491536379), (8, 0.07543656323105097), (10, 0.08115739282220602), (16, 0.08612149674445391), (12, 0.09119798988103867), (5, 0.10708751063793898), (36, 0.3805130086839199), (18, 0.5156984627246857), (53, 0.8466870412230492)]
computing accuracy for after removing block 44 . block score: 0.01247408555354923
removed block 44 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.015139. All blocks and scores: [(40, 0.015139365452341735), (42, 0.015608364599756896), (23, 0.02272608340717852), (46, 0.025134747149422765), (21, 0.025170553009957075), (22, 0.025543901603668928), (39, 0.025568536249920726), (49, 0.026462717913091183), (37, 0.026970835402607918), (20, 0.027434169314801693), (50, 0.02754211099818349), (48, 0.028290877817198634), (25, 0.0306935531552881), (24, 0.031119887717068195), (27, 0.03191897505894303), (15, 0.032223982736468315), (19, 0.03257038304582238), (38, 0.032575455494225025), (7, 0.03290830086916685), (47, 0.033847587648779154), (51, 0.04110714979469776), (9, 0.04394827131181955), (6, 0.04741221573203802), (14, 0.04816280771046877), (4, 0.04981236066669226), (2, 0.05545353889465332), (3, 0.058979025576263666), (13, 0.05924209114164114), (11, 0.06002802541479468), (17, 0.06198619306087494), (0, 0.06432518642395735), (52, 0.0677170418202877), (1, 0.06773518398404121), (8, 0.07543656509369612), (10, 0.08115739095956087), (16, 0.08612149581313133), (12, 0.09119799267500639), (5, 0.10708751156926155), (36, 0.3805130086839199), (18, 0.5156984701752663), (53, 0.9125214591622353)]
computing accuracy for after removing block 40 . block score: 0.015139365452341735
removed block 40 current accuracy 0.9348 loss from initial  0.01660000000000006
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.014341. All blocks and scores: [(42, 0.01434052363038063), (23, 0.022726082941517234), (46, 0.02438862039707601), (21, 0.025170552311465144), (22, 0.02554390113800764), (39, 0.02556853578425944), (49, 0.025680927792564034), (50, 0.02667535748332739), (37, 0.02697083610109985), (20, 0.02743416838347912), (48, 0.027630529832094908), (25, 0.030693554086610675), (24, 0.031119887717068195), (27, 0.03191897552460432), (15, 0.03222398180514574), (19, 0.03257038211449981), (38, 0.03257545595988631), (7, 0.03290830133482814), (47, 0.034252708312124014), (51, 0.04097604099661112), (9, 0.04394827224314213), (6, 0.04741221433505416), (14, 0.04816280631348491), (4, 0.049812361132353544), (2, 0.05545353936031461), (3, 0.058979025576263666), (13, 0.059242088347673416), (11, 0.060028026811778545), (17, 0.06198619259521365), (0, 0.06432518549263477), (52, 0.06659491267055273), (1, 0.06773518491536379), (8, 0.07543656416237354), (10, 0.08115739095956087), (16, 0.08612149581313133), (12, 0.09119799360632896), (5, 0.10708751529455185), (36, 0.3805130161345005), (18, 0.5156984850764275), (53, 0.989689864218235)]
computing accuracy for after removing block 42 . block score: 0.01434052363038063
removed block 42 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.022726. All blocks and scores: [(23, 0.02272608270868659), (46, 0.02493939409032464), (21, 0.025170552311465144), (22, 0.025543901603668928), (39, 0.025568536249920726), (49, 0.025578698376193643), (37, 0.026970835402607918), (50, 0.027166838059201837), (20, 0.027434168616309762), (48, 0.028079533716663718), (25, 0.030693555250763893), (24, 0.031119887018576264), (27, 0.03191897599026561), (15, 0.03222398180514574), (19, 0.032570382580161095), (38, 0.0325754564255476), (7, 0.03290830133482814), (47, 0.03535922942683101), (51, 0.040804410353302956), (9, 0.04394827177748084), (6, 0.047412213403731585), (14, 0.048162808176130056), (4, 0.04981236020103097), (2, 0.055453541688621044), (3, 0.058979024179279804), (13, 0.0592420888133347), (11, 0.06002802634611726), (17, 0.06198619306087494), (0, 0.06432518549263477), (52, 0.06769988872110844), (1, 0.06773518398404121), (8, 0.07543656509369612), (10, 0.08115738909691572), (16, 0.08612149581313133), (12, 0.09119799267500639), (5, 0.1070875134319067), (36, 0.3805130161345005), (18, 0.5156984701752663), (53, 1.0308746248483658)]
computing accuracy for after removing block 23 . block score: 0.02272608270868659
removed block 23 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 46, with score 0.024338. All blocks and scores: [(46, 0.024338293354958296), (21, 0.025170552311465144), (49, 0.025389538146555424), (39, 0.025512328604236245), (22, 0.02554390113800764), (50, 0.026237791404128075), (37, 0.027247733436524868), (48, 0.02738546929322183), (20, 0.027434169314801693), (24, 0.029101216001436114), (25, 0.02992841647937894), (27, 0.03099611378274858), (38, 0.032055021263659), (15, 0.03222398180514574), (19, 0.032570382580161095), (7, 0.032908300403505564), (47, 0.03392800781875849), (51, 0.04012046521529555), (9, 0.043948270846158266), (6, 0.04741221433505416), (14, 0.048162808176130056), (4, 0.04981236020103097), (2, 0.05545354122295976), (3, 0.058979025576263666), (13, 0.05924208788201213), (11, 0.06002802588045597), (17, 0.061986193526536226), (0, 0.0643251845613122), (52, 0.06526145059615374), (1, 0.06773518491536379), (8, 0.07543656509369612), (10, 0.0811573900282383), (16, 0.08612149581313133), (12, 0.09119799267500639), (5, 0.10708751156926155), (36, 0.3764685019850731), (18, 0.5156984776258469), (53, 1.0440683364868164)]
computing accuracy for after removing block 46 . block score: 0.024338293354958296
removed block 46 current accuracy 0.9076 loss from initial  0.04380000000000006
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 21, with score 0.025171. All blocks and scores: [(21, 0.025170552544295788), (39, 0.025512328604236245), (22, 0.025543902069330215), (49, 0.026208223309367895), (50, 0.026870267931371927), (37, 0.02724773297086358), (20, 0.027434168849140406), (48, 0.028151861857622862), (24, 0.029101216234266758), (25, 0.029928416712209582), (27, 0.030996114248409867), (38, 0.03205502172932029), (15, 0.03222398227080703), (19, 0.03257038211449981), (7, 0.03290830133482814), (47, 0.03541618958115578), (51, 0.03965515363961458), (9, 0.04394827131181955), (6, 0.047412214800715446), (14, 0.04816280771046877), (4, 0.04981236159801483), (2, 0.055453539825975895), (3, 0.05897902511060238), (13, 0.059242088347673416), (11, 0.06002802588045597), (17, 0.06198619492352009), (52, 0.06432344019412994), (0, 0.06432518549263477), (1, 0.06773518491536379), (8, 0.07543656416237354), (10, 0.08115739189088345), (16, 0.08612149767577648), (12, 0.09119799174368382), (5, 0.10708751156926155), (36, 0.3764685168862343), (18, 0.5156984850764275), (53, 1.1803390234708786)]
computing accuracy for after removing block 21 . block score: 0.025170552544295788
removed block 21 current accuracy 0.9 loss from initial  0.0514
since last training loss: 0.041999999999999926 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 22, with score 0.023767. All blocks and scores: [(22, 0.023766613099724054), (39, 0.02438967186026275), (50, 0.025200253585353494), (37, 0.025484980549663305), (49, 0.02551190834492445), (48, 0.025649595307186246), (24, 0.025987142929807305), (20, 0.02743416908197105), (25, 0.028427455807104707), (27, 0.029490592190995812), (38, 0.030358363641425967), (15, 0.03222398227080703), (19, 0.032570382580161095), (7, 0.03290830133482814), (47, 0.03336211200803518), (51, 0.037638409063220024), (9, 0.043948270846158266), (6, 0.04741221433505416), (14, 0.048162808176130056), (4, 0.04981236066669226), (2, 0.055453539825975895), (52, 0.05850043334066868), (3, 0.05897902604192495), (13, 0.05924208648502827), (11, 0.06002802448347211), (17, 0.06198619492352009), (0, 0.0643251845613122), (1, 0.06773518305271864), (8, 0.07543656323105097), (10, 0.08115739282220602), (16, 0.08612149767577648), (12, 0.09119799826294184), (5, 0.10708751436322927), (36, 0.3537096828222275), (18, 0.5156984850764275), (53, 1.2233135998249054)]
computing accuracy for after removing block 22 . block score: 0.023766613099724054
removed block 22 current accuracy 0.8848 loss from initial  0.06659999999999999
since last training loss: 0.05719999999999992 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.023547. All blocks and scores: [(39, 0.02354666031897068), (24, 0.023774054367095232), (50, 0.02386148227378726), (48, 0.02402681647799909), (49, 0.024630876490846276), (37, 0.02526682708412409), (25, 0.02694544498808682), (20, 0.027434168616309762), (27, 0.028652663808315992), (38, 0.029873774154111743), (47, 0.031387556344270706), (15, 0.03222398227080703), (19, 0.032570382580161095), (7, 0.032908300403505564), (51, 0.03608275856822729), (9, 0.04394827224314213), (6, 0.047412215266376734), (14, 0.04816280724480748), (4, 0.04981236020103097), (52, 0.05429308954626322), (2, 0.055453541688621044), (3, 0.058979025576263666), (13, 0.059242086950689554), (11, 0.06002802448347211), (17, 0.061986193992197514), (0, 0.06432518549263477), (1, 0.06773518491536379), (8, 0.07543656323105097), (10, 0.08115739282220602), (16, 0.08612149860709906), (12, 0.09119799174368382), (5, 0.10708751529455185), (36, 0.3453311212360859), (18, 0.5156984776258469), (53, 1.245961144566536)]
computing accuracy for after removing block 39 . block score: 0.02354666031897068
removed block 39 current accuracy 0.868 loss from initial  0.08340000000000003
since last training loss: 0.07399999999999995 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.021910. All blocks and scores: [(50, 0.02191020781174302), (48, 0.022095066029578447), (49, 0.023277753265574574), (24, 0.023774054367095232), (37, 0.025266826851293445), (25, 0.02694544428959489), (20, 0.02743416791781783), (27, 0.028652664506807923), (38, 0.02987377461977303), (47, 0.03044700506143272), (15, 0.03222398180514574), (19, 0.032570382580161095), (7, 0.032908299937844276), (51, 0.03331220615655184), (9, 0.04394827131181955), (6, 0.047412214800715446), (14, 0.04816280724480748), (52, 0.04852932086214423), (4, 0.04981235973536968), (2, 0.05545354215428233), (3, 0.05897902371361852), (13, 0.059242088347673416), (11, 0.06002802588045597), (17, 0.061986193526536226), (0, 0.06432518549263477), (1, 0.06773518491536379), (8, 0.07543656416237354), (10, 0.08115739095956087), (16, 0.08612149953842163), (12, 0.09119799267500639), (5, 0.10708751156926155), (36, 0.3453311398625374), (18, 0.5156984776258469), (53, 1.340397208929062)]
computing accuracy for after removing block 50 . block score: 0.02191020781174302
removed block 50 current accuracy 0.8464 loss from initial  0.10499999999999998
since last training loss: 0.09559999999999991 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.022095. All blocks and scores: [(48, 0.022095066029578447), (49, 0.023277753731235862), (24, 0.023774055298417807), (37, 0.02526682708412409), (25, 0.026945444755256176), (20, 0.027434169314801693), (27, 0.02865266427397728), (38, 0.029873773688450456), (47, 0.030447004595771432), (15, 0.0322239832021296), (19, 0.03257038304582238), (7, 0.03290830133482814), (51, 0.036230670753866434), (9, 0.0439482731744647), (6, 0.047412215266376734), (14, 0.048162808176130056), (4, 0.049812361132353544), (2, 0.05545354122295976), (52, 0.056764944922178984), (3, 0.05897902511060238), (13, 0.05924209067597985), (11, 0.06002802448347211), (17, 0.061986193526536226), (0, 0.06432518735527992), (1, 0.06773518491536379), (8, 0.07543656416237354), (10, 0.08115739189088345), (16, 0.0861215004697442), (12, 0.09119798988103867), (5, 0.10708751622587442), (36, 0.3453311286866665), (18, 0.5156984850764275), (53, 1.6037623435258865)]
computing accuracy for after removing block 48 . block score: 0.022095066029578447
removed block 48 current accuracy 0.797 loss from initial  0.15439999999999998
training start
training epoch 0 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.1]
training epoch 1 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 2 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 3 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 4 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.1]
training epoch 5 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.1]
training epoch 6 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.1]
training epoch 7 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 8 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 9 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 22
[activation diff]: block to remove picked: 27, with score 0.031686. All blocks and scores: [(27, 0.0316859595477581), (15, 0.032166339457035065), (7, 0.03264946350827813), (49, 0.04287254251539707), (9, 0.0440828581340611), (20, 0.04588151117786765), (6, 0.04631870938464999), (4, 0.04675977677106857), (25, 0.046942001674324274), (14, 0.048007396049797535), (19, 0.05001112259924412), (51, 0.0502717518247664), (47, 0.051064131781458855), (2, 0.054533925373107195), (3, 0.058312732726335526), (13, 0.059101767372339964), (11, 0.05964029673486948), (24, 0.05968761723488569), (38, 0.0618013720959425), (17, 0.06225721584632993), (0, 0.06449566036462784), (37, 0.06623851601034403), (1, 0.06712591368705034), (8, 0.07475483231246471), (10, 0.08115136437118053), (52, 0.08349394332617521), (16, 0.08544940315186977), (12, 0.09020973462611437), (5, 0.10663225594907999), (36, 0.38223013654351234), (18, 0.5148924365639687), (53, 0.8040154650807381)]
computing accuracy for after removing block 27 . block score: 0.0316859595477581
removed block 27 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.032166. All blocks and scores: [(15, 0.032166339457035065), (7, 0.032649464439600706), (49, 0.04233486857265234), (9, 0.0440828581340611), (20, 0.045881510246545076), (6, 0.04631871031597257), (4, 0.046759774442762136), (25, 0.04694200027734041), (14, 0.048007396049797535), (47, 0.049453666899353266), (51, 0.049460371024906635), (19, 0.05001112166792154), (2, 0.05453392444178462), (3, 0.058312731329351664), (13, 0.05910176830366254), (11, 0.059640295803546906), (24, 0.05968761723488569), (17, 0.062257216311991215), (38, 0.06333412230014801), (0, 0.06449566036462784), (1, 0.06712591089308262), (8, 0.07475483138114214), (37, 0.07477931026369333), (52, 0.08039381820708513), (10, 0.08115136437118053), (16, 0.08544940408319235), (12, 0.09020973555743694), (5, 0.10663225501775742), (36, 0.40320582687854767), (18, 0.5148924514651299), (53, 0.8214151114225388)]
computing accuracy for after removing block 15 . block score: 0.032166339457035065
removed block 15 current accuracy 0.9324 loss from initial  0.019000000000000017
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.032649. All blocks and scores: [(7, 0.03264946350827813), (49, 0.04219889594241977), (20, 0.043424018658697605), (9, 0.04408285627141595), (25, 0.044248078018426895), (6, 0.04631870938464999), (4, 0.046759774442762136), (14, 0.048007396049797535), (19, 0.05036393739283085), (47, 0.050791614688932896), (51, 0.05139188654720783), (2, 0.05453392444178462), (24, 0.05606960179284215), (3, 0.05831273039802909), (13, 0.05910176783800125), (11, 0.05964029906317592), (38, 0.06392211839556694), (0, 0.06449566129595041), (17, 0.0660786023363471), (1, 0.06712590996176004), (8, 0.07475483231246471), (37, 0.07499651610851288), (10, 0.08115136530250311), (52, 0.08116617519408464), (12, 0.09020973183214664), (16, 0.09525217395275831), (5, 0.10663225594907999), (36, 0.39957476034760475), (18, 0.5024556405842304), (53, 0.8198339194059372)]
computing accuracy for after removing block 7 . block score: 0.03264946350827813
removed block 7 current accuracy 0.9268 loss from initial  0.024600000000000066
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 20, with score 0.040724. All blocks and scores: [(20, 0.040724115911871195), (49, 0.04099809564650059), (25, 0.042237069457769394), (9, 0.04398010531440377), (14, 0.04433765867725015), (6, 0.04631871031597257), (4, 0.04675977397710085), (19, 0.04803181253373623), (47, 0.04908491484820843), (51, 0.04958541924133897), (13, 0.05127766169607639), (24, 0.05165505921468139), (2, 0.05453392490744591), (17, 0.0559529853053391), (11, 0.056319399271160364), (3, 0.05831273039802909), (38, 0.06332108750939369), (0, 0.06449566129595041), (1, 0.06712591368705034), (37, 0.06939851585775614), (8, 0.07275445852428675), (52, 0.07593320123851299), (10, 0.08356479182839394), (12, 0.0842827707529068), (16, 0.08673743531107903), (5, 0.10663225501775742), (36, 0.3835643045604229), (18, 0.4859177730977535), (53, 0.8280424252152443)]
computing accuracy for after removing block 20 . block score: 0.040724115911871195
removed block 20 current accuracy 0.9142 loss from initial  0.03720000000000001
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.038924. All blocks and scores: [(49, 0.03892448265105486), (25, 0.0413647354580462), (9, 0.0439801043830812), (14, 0.044337660539895296), (6, 0.04631871031597257), (4, 0.04675977397710085), (47, 0.046902889385819435), (51, 0.04781342437490821), (19, 0.048031813465058804), (24, 0.04805191047489643), (13, 0.051277661230415106), (2, 0.05453392397612333), (17, 0.0559529853053391), (11, 0.056319399271160364), (3, 0.058312731329351664), (38, 0.06251127179712057), (52, 0.06368776131421328), (0, 0.06449565943330526), (1, 0.06712591368705034), (8, 0.07275445852428675), (37, 0.07367019727826118), (10, 0.08356479275971651), (12, 0.08428277168422937), (16, 0.08673743344843388), (5, 0.10663225408643484), (36, 0.38338665291666985), (18, 0.4859177768230438), (53, 0.838390477001667)]
computing accuracy for after removing block 49 . block score: 0.03892448265105486
removed block 49 current accuracy 0.8874 loss from initial  0.06400000000000006
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 25, with score 0.041365. All blocks and scores: [(25, 0.041364734061062336), (9, 0.04398010531440377), (14, 0.04433766100555658), (6, 0.046318712178617716), (4, 0.046759774908423424), (47, 0.046902891248464584), (51, 0.047281643841415644), (19, 0.048031813465058804), (24, 0.04805191047489643), (13, 0.05127766076475382), (2, 0.054533923510462046), (17, 0.055952985771000385), (11, 0.05631939833983779), (3, 0.05831273039802909), (52, 0.06247357185930014), (38, 0.06251127272844315), (0, 0.06449565943330526), (1, 0.06712591089308262), (8, 0.0727544566616416), (37, 0.07367019727826118), (10, 0.08356479462236166), (12, 0.0842827707529068), (16, 0.08673743344843388), (5, 0.10663225594907999), (36, 0.38338665664196014), (18, 0.4859177842736244), (53, 1.0852190256118774)]
computing accuracy for after removing block 25 . block score: 0.041364734061062336
removed block 25 current accuracy 0.8436 loss from initial  0.1078
since last training loss: 0.09599999999999997 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 47, with score 0.042623. All blocks and scores: [(47, 0.0426230663433671), (9, 0.043980104848742485), (14, 0.044337660539895296), (51, 0.046208790969103575), (6, 0.04631870985031128), (4, 0.04675977397710085), (19, 0.048031813465058804), (24, 0.04805191187188029), (13, 0.05127766169607639), (2, 0.05453392397612333), (17, 0.055952985771000385), (11, 0.05631939973682165), (52, 0.0567352413199842), (3, 0.05831273039802909), (0, 0.06449566036462784), (38, 0.06457140389829874), (1, 0.06712591275572777), (8, 0.0727544566616416), (10, 0.08356479462236166), (12, 0.0842827707529068), (16, 0.086737428791821), (37, 0.09106238558888435), (5, 0.10663225501775742), (36, 0.41978323459625244), (18, 0.4859177693724632), (53, 1.11043381690979)]
computing accuracy for after removing block 47 . block score: 0.0426230663433671
removed block 47 current accuracy 0.754 loss from initial  0.19740000000000002
since last training loss: 0.1856 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043980. All blocks and scores: [(9, 0.043980104848742485), (14, 0.04433766100555658), (6, 0.04631870938464999), (4, 0.04675977351143956), (51, 0.046959283761680126), (19, 0.04803181393072009), (24, 0.04805191047489643), (13, 0.051277661230415106), (2, 0.05453392257913947), (17, 0.0559529853053391), (11, 0.05631939880549908), (3, 0.05831273179501295), (52, 0.058433786034584045), (0, 0.06449565943330526), (38, 0.06457140296697617), (1, 0.0671259118244052), (8, 0.07275445852428675), (10, 0.08356479275971651), (12, 0.08428276889026165), (16, 0.0867374325171113), (37, 0.0910623837262392), (5, 0.10663225408643484), (36, 0.41978323087096214), (18, 0.48591776564717293), (53, 1.3782177120447159)]
computing accuracy for after removing block 9 . block score: 0.043980104848742485
removed block 9 current accuracy 0.7288 loss from initial  0.22260000000000002
since last training loss: 0.2108 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.040237. All blocks and scores: [(14, 0.040237114299088717), (51, 0.043933394365012646), (24, 0.04517587274312973), (6, 0.04631871031597257), (4, 0.046759775839746), (13, 0.0486166151240468), (17, 0.049913589376956224), (19, 0.05057850806042552), (11, 0.05197504349052906), (2, 0.054533923510462046), (52, 0.05597148323431611), (3, 0.058312730863690376), (38, 0.06162027129903436), (0, 0.06449566036462784), (1, 0.06712591461837292), (16, 0.07137819193303585), (12, 0.07251157332211733), (8, 0.0727544566616416), (37, 0.07458505593240261), (10, 0.08202159963548183), (5, 0.10663225781172514), (36, 0.3812366984784603), (18, 0.4672973155975342), (53, 1.4127042889595032)]
computing accuracy for after removing block 14 . block score: 0.040237114299088717
removed block 14 current accuracy 0.671 loss from initial  0.2804
since last training loss: 0.26859999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 24, with score 0.042456. All blocks and scores: [(24, 0.04245648207142949), (51, 0.043223871383816004), (6, 0.046318708918988705), (4, 0.04675977351143956), (13, 0.0486166151240468), (17, 0.049433992709964514), (19, 0.05030313180759549), (11, 0.051975041162222624), (52, 0.0538186919875443), (2, 0.05453392444178462), (3, 0.058312731329351664), (38, 0.06202129228040576), (0, 0.06449565850198269), (1, 0.0671259118244052), (12, 0.07251157145947218), (8, 0.07275445945560932), (37, 0.07569864578545094), (10, 0.08202160149812698), (16, 0.09389603696763515), (5, 0.10663225315511227), (36, 0.38328615948557854), (18, 0.4654921367764473), (53, 1.4678396433591843)]
computing accuracy for after removing block 24 . block score: 0.04245648207142949
removed block 24 current accuracy 0.485 loss from initial  0.46640000000000004
since last training loss: 0.4546 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.042370. All blocks and scores: [(51, 0.04237004788592458), (52, 0.046216180082410574), (6, 0.04631870985031128), (4, 0.046759774442762136), (13, 0.04861661558970809), (17, 0.04943399177864194), (19, 0.05030313320457935), (11, 0.05197504302486777), (2, 0.05453392583876848), (3, 0.0583127336576581), (38, 0.05966832861304283), (0, 0.06449566315859556), (1, 0.0671259118244052), (12, 0.07251157332211733), (8, 0.07275445759296417), (10, 0.08202159777283669), (37, 0.08443934936076403), (16, 0.09389603510499), (5, 0.10663225781172514), (36, 0.3973170258104801), (18, 0.4654921367764473), (53, 1.6685031056404114)]
computing accuracy for after removing block 51 . block score: 0.04237004788592458
removed block 51 current accuracy 0.3966 loss from initial  0.5548
training start
training epoch 0 val accuracy 0.8102 topk_dict {'top1': 0.8102} is_best True lr [0.1]
training epoch 1 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best True lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.1]
training epoch 3 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 4 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.1]
training epoch 5 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.1]
training epoch 6 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 7 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 8 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.046423. All blocks and scores: [(4, 0.046422765124589205), (2, 0.0549822305329144), (3, 0.05737082287669182), (0, 0.06247181864455342), (1, 0.06576099712401628), (6, 0.07063624635338783), (11, 0.08897509332746267), (17, 0.10042211413383484), (13, 0.10155293252319098), (8, 0.10698242671787739), (37, 0.10983759444206953), (38, 0.1187023650854826), (52, 0.11988334637135267), (10, 0.1276806052774191), (19, 0.14071447029709816), (16, 0.14145903661847115), (5, 0.14845972694456577), (12, 0.15345936827361584), (36, 0.47731631249189377), (18, 0.5520891025662422), (53, 1.4102634936571121)]
computing accuracy for after removing block 4 . block score: 0.046422765124589205
removed block 4 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.054982. All blocks and scores: [(2, 0.05498223099857569), (3, 0.057370821945369244), (0, 0.062471820041537285), (1, 0.06576099898666143), (6, 0.07725758198648691), (11, 0.0829279376193881), (17, 0.09815195295959711), (13, 0.09858733881264925), (8, 0.1095614843070507), (37, 0.11158221401274204), (38, 0.11895376723259687), (52, 0.11908144503831863), (10, 0.12708589620888233), (16, 0.1287813726812601), (12, 0.14146153815090656), (19, 0.14485498890280724), (5, 0.162183390930295), (36, 0.4800940379500389), (18, 0.5590329095721245), (53, 1.378905862569809)]
computing accuracy for after removing block 2 . block score: 0.05498223099857569
removed block 2 current accuracy 0.9206 loss from initial  0.03080000000000005
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.052478. All blocks and scores: [(3, 0.05247846711426973), (0, 0.062471819575876), (1, 0.06576099712401628), (11, 0.07460220623761415), (6, 0.07679647300392389), (17, 0.08609437476843596), (13, 0.09162322152405977), (37, 0.09885081369429827), (8, 0.10720395855605602), (52, 0.11015453562140465), (38, 0.1156565835699439), (16, 0.11989117786288261), (10, 0.12613554298877716), (12, 0.1265986803919077), (19, 0.12809186801314354), (5, 0.15782557427883148), (36, 0.4370562732219696), (18, 0.5104293152689934), (53, 1.365933358669281)]
computing accuracy for after removing block 3 . block score: 0.05247846711426973
removed block 3 current accuracy 0.8694 loss from initial  0.08200000000000007
since last training loss: 0.06740000000000002 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 0, with score 0.062472. All blocks and scores: [(0, 0.062471818178892136), (1, 0.06576099712401628), (11, 0.06947722844779491), (17, 0.07981651462614536), (6, 0.0813982980325818), (13, 0.08481560833752155), (37, 0.0921483663842082), (16, 0.0979096433147788), (52, 0.10144586954265833), (8, 0.10162385832518339), (38, 0.11311147455126047), (19, 0.11776797287166119), (12, 0.11853882297873497), (10, 0.12754248641431332), (5, 0.16955051757395267), (36, 0.41390541195869446), (18, 0.47827960178256035), (53, 1.3109374195337296)]
computing accuracy for after removing block 0 . block score: 0.062471818178892136
removed block 0 current accuracy 0.777 loss from initial  0.1744
since last training loss: 0.15979999999999994 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.064552. All blocks and scores: [(11, 0.06455192994326353), (1, 0.06764956470578909), (17, 0.07809011731296778), (13, 0.08396738022565842), (6, 0.08459627721458673), (37, 0.08675252739340067), (16, 0.0894036116078496), (52, 0.09504083544015884), (8, 0.09542468283325434), (19, 0.11316444538533688), (38, 0.11386578250676394), (10, 0.12165097333490849), (12, 0.13301112689077854), (5, 0.17167524993419647), (36, 0.4046987369656563), (18, 0.49015453457832336), (53, 1.2887916713953018)]
computing accuracy for after removing block 11 . block score: 0.06455192994326353
removed block 11 current accuracy 0.7384 loss from initial  0.21300000000000008
since last training loss: 0.19840000000000002 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 1, with score 0.067650. All blocks and scores: [(1, 0.06764956284314394), (17, 0.0739351250231266), (16, 0.07782564032822847), (6, 0.08459627814590931), (37, 0.08543727360665798), (52, 0.09354021586477757), (13, 0.09457616321742535), (8, 0.09542468283325434), (19, 0.11098390445113182), (38, 0.12078228034079075), (10, 0.12165097333490849), (12, 0.14700622484087944), (5, 0.17167524062097073), (36, 0.41449932008981705), (18, 0.5106557682156563), (53, 1.2589408159255981)]
computing accuracy for after removing block 1 . block score: 0.06764956284314394
removed block 1 current accuracy 0.465 loss from initial  0.4864
since last training loss: 0.47179999999999994 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 17, with score 0.065992. All blocks and scores: [(17, 0.06599161867052317), (16, 0.07225838955491781), (37, 0.07664793729782104), (52, 0.07973215822130442), (13, 0.08258968219161034), (8, 0.08416929934173822), (6, 0.08916702400892973), (19, 0.09915264137089252), (10, 0.11459412705153227), (38, 0.12747145257890224), (5, 0.1717186700552702), (12, 0.19515548273921013), (36, 0.4199007749557495), (18, 0.5089294016361237), (53, 1.1919531971216202)]
computing accuracy for after removing block 17 . block score: 0.06599161867052317
removed block 17 current accuracy 0.4478 loss from initial  0.5036
since last training loss: 0.489 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 16, with score 0.072258. All blocks and scores: [(16, 0.07225838769227266), (37, 0.07328777480870485), (52, 0.07651025056838989), (13, 0.08258968405425549), (8, 0.08416929747909307), (6, 0.08916702587157488), (19, 0.0903540113940835), (10, 0.11459412705153227), (38, 0.12766140699386597), (5, 0.1717186663299799), (12, 0.19515548273921013), (36, 0.3837911784648895), (18, 0.4607539437711239), (53, 1.1375902742147446)]
computing accuracy for after removing block 16 . block score: 0.07225838769227266
removed block 16 current accuracy 0.2598 loss from initial  0.6916
since last training loss: 0.677 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 52, with score 0.074455. All blocks and scores: [(52, 0.07445549219846725), (13, 0.08258968405425549), (37, 0.08385003823786974), (8, 0.0841693002730608), (6, 0.0891670249402523), (19, 0.09766089916229248), (10, 0.11459412798285484), (38, 0.11527443118393421), (5, 0.17171867191791534), (12, 0.19515549018979073), (36, 0.3974987678229809), (18, 0.4952833950519562), (53, 1.2869115471839905)]
computing accuracy for after removing block 52 . block score: 0.07445549219846725
removed block 52 current accuracy 0.202 loss from initial  0.7494000000000001
since last training loss: 0.7347999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.082590. All blocks and scores: [(13, 0.08258968405425549), (37, 0.08385003916919231), (8, 0.08416930120438337), (6, 0.08916702587157488), (19, 0.0976609019562602), (10, 0.11459412332624197), (38, 0.11527443397790194), (5, 0.17171866819262505), (12, 0.19515548273921013), (36, 0.3974987789988518), (18, 0.4952833876013756), (53, 1.1998083293437958)]
computing accuracy for after removing block 13 . block score: 0.08258968405425549
removed block 13 current accuracy 0.154 loss from initial  0.7974
since last training loss: 0.7827999999999999 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 8, with score 0.084169. All blocks and scores: [(8, 0.08416930120438337), (6, 0.08916702680289745), (19, 0.10037379059940577), (38, 0.10854414571076632), (10, 0.1145941261202097), (37, 0.11863502208143473), (5, 0.17171866819262505), (12, 0.19515548460185528), (36, 0.47521113604307175), (18, 0.6058117225766182), (53, 1.3175585567951202)]
computing accuracy for after removing block 8 . block score: 0.08416930120438337
removed block 8 current accuracy 0.1366 loss from initial  0.8148
since last training loss: 0.8002 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 6, with score 0.089167. All blocks and scores: [(6, 0.08916702773422003), (19, 0.10784549359232187), (38, 0.11721743457019329), (10, 0.13675306551158428), (37, 0.14705196395516396), (5, 0.17171866819262505), (12, 0.20224272087216377), (36, 0.5549392104148865), (18, 0.709585651755333), (53, 1.3399459272623062)]
computing accuracy for after removing block 6 . block score: 0.08916702773422003
removed block 6 current accuracy 0.1232 loss from initial  0.8282
training start
training epoch 0 val accuracy 0.839 topk_dict {'top1': 0.839} is_best True lr [0.1]
training epoch 1 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 2 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 3 val accuracy 0.8346 topk_dict {'top1': 0.8346} is_best False lr [0.1]
training epoch 4 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 5 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 6 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 7 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.1]
training epoch 8 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 9 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 10 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.929600)
finished training. finished 50 epochs. accuracy 0.9296 topk_dict {'top1': 0.9296}
