start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843464367092), (32, 0.009399589616805315), (30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.013294661184772849), (29, 0.013421116629615426), (35, 0.015957689378410578), (26, 0.01607214054092765), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.02059022570028901), (25, 0.022078295471146703), (23, 0.022228715708479285), (41, 0.02233641571365297), (44, 0.023145998362451792), (40, 0.02374959085136652), (45, 0.02397549501620233), (21, 0.024941088864579797), (48, 0.02495770645327866), (22, 0.025151390116661787), (50, 0.025287174386903644), (24, 0.025880582397803664), (49, 0.02591664926148951), (42, 0.02623223257251084), (20, 0.026848891051486135), (47, 0.02863294817507267), (38, 0.031344343442469835), (39, 0.03144129482097924), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.04178758757188916), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671144165098667), (36, 0.4361986294388771), (18, 0.5117432996630669), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843464367092
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187405325472), (31, 0.01023258117493242), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072140773758292), (35, 0.016093927435576916), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985268690623343), (46, 0.02030070568434894), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192187681794), (40, 0.02357383188791573), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.024770821910351515), (21, 0.024941088864579797), (22, 0.025151390116661787), (49, 0.02557574096135795), (24, 0.02588058216497302), (42, 0.02589341253042221), (20, 0.026848891051486135), (47, 0.02807276090607047), (38, 0.031091188080608845), (39, 0.031191361602395773), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464461103082), (52, 0.0649335184134543), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43398062139749527), (18, 0.5117433071136475), (53, 0.8063970729708672)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118728891015), (31, 0.01023258117493242), (34, 0.012758881668560207), (29, 0.013421116629615426), (35, 0.015918422024697065), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.021827629301697016), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.02289147791452706), (40, 0.02360257995314896), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.024639350827783346), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025392549810931087), (42, 0.025712220231071115), (24, 0.025880582630634308), (20, 0.02684889268130064), (47, 0.028052504174411297), (38, 0.030935873743146658), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.0597000359557569), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166483163834)]
computing accuracy for after removing block 30 . block score: 0.01001118728891015
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744174331427), (41, 0.021756020840257406), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.02300137630663812), (40, 0.023739926517009735), (45, 0.023790168575942516), (48, 0.024350046878680587), (50, 0.024463105481117964), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027727574575692415), (38, 0.03074627462774515), (39, 0.03128179511986673), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.040824799332767725), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464833632112), (52, 0.06356756435707211), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693049609661), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232713349164), (29, 0.013421116629615426), (35, 0.015968911349773407), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.02013718686066568), (41, 0.021584055619314313), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02268732455559075), (40, 0.02356909797526896), (45, 0.023840721230953932), (48, 0.024108359590172768), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.025045574409887195), (22, 0.025151390582323074), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.027423852356150746), (38, 0.03073564823716879), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.039083508774638176), (51, 0.0403459407389164), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577406495809555), (3, 0.05784992640838027), (13, 0.0591442845761776), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.06270107766613364), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43692685291171074), (18, 0.5117432922124863), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232713349164
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302684511989355), (46, 0.020324197597801685), (41, 0.021962703904137015), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.023045078152790666), (48, 0.024024547077715397), (50, 0.02409697277471423), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922373238950968), (21, 0.024941090028733015), (22, 0.02515139034949243), (42, 0.025816060369834304), (24, 0.025880583096295595), (20, 0.026848892215639353), (47, 0.02756829559803009), (38, 0.03178726346231997), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.04008621396496892), (37, 0.040690732188522816), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.0613252529874444), (52, 0.06221094774082303), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.44933703541755676), (18, 0.5117432922124863), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.1]
training epoch 1 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.1]
training epoch 2 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.1]
training epoch 3 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.1]
training epoch 4 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.1]
training epoch 5 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.1]
training epoch 6 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.1]
training epoch 7 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.1]
training epoch 8 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.1]
training epoch 9 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.1]
training epoch 10 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.948600)
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.013965. All blocks and scores: [(26, 0.013964731013402343), (28, 0.014015169464983046), (35, 0.01651855232194066), (27, 0.016963178757578135), (25, 0.0178587946575135), (23, 0.019088684115558863), (24, 0.019706126768141985), (43, 0.019854489713907242), (46, 0.02076461212709546), (41, 0.022239285288378596), (44, 0.02327974629588425), (40, 0.02357822866179049), (45, 0.023903258610516787), (50, 0.025044168112799525), (21, 0.02516158646903932), (48, 0.025195037247613072), (22, 0.025336498394608498), (49, 0.02566732745617628), (42, 0.025686041451990604), (20, 0.02714999718591571), (47, 0.028337300987914205), (38, 0.03092295886017382), (39, 0.031396274687722325), (15, 0.0322032761760056), (19, 0.03254366898909211), (7, 0.032720299903303385), (37, 0.03794890223070979), (51, 0.04178104316815734), (9, 0.0439148903824389), (6, 0.046870213001966476), (14, 0.047984767239540815), (4, 0.04873769311234355), (2, 0.0549702188000083), (3, 0.05828601773828268), (13, 0.05945862550288439), (11, 0.05965413153171539), (17, 0.062156857922673225), (0, 0.06374167092144489), (52, 0.06458823336288333), (1, 0.06696308124810457), (8, 0.07421958073973656), (10, 0.08139985892921686), (16, 0.08561852388083935), (12, 0.09027372859418392), (5, 0.10608604177832603), (36, 0.43375638872385025), (18, 0.5138366967439651), (53, 0.798886701464653)]
computing accuracy for after removing block 26 . block score: 0.013964731013402343
removed block 26 current accuracy 0.9428 loss from initial  0.008600000000000052
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.013910. All blocks and scores: [(28, 0.013910263776779175), (35, 0.01601671613752842), (27, 0.016953567741438746), (25, 0.017858795123174787), (23, 0.019088684115558863), (43, 0.019584705121815205), (24, 0.01970612700097263), (46, 0.02049199165776372), (41, 0.021937406389042735), (40, 0.02334837056696415), (44, 0.023636404890567064), (45, 0.023715538205578923), (50, 0.02449267660267651), (48, 0.02467354922555387), (42, 0.024729714496061206), (21, 0.025161586701869965), (22, 0.025336498394608498), (49, 0.02550897910259664), (20, 0.02714999718591571), (47, 0.027780381496995687), (38, 0.03068303200416267), (39, 0.03109143814072013), (15, 0.032203277107328176), (19, 0.0325436694547534), (7, 0.03272029897198081), (37, 0.03821501228958368), (51, 0.04068571235984564), (9, 0.043914890848100185), (6, 0.04687021393328905), (14, 0.04798476817086339), (4, 0.04873769357800484), (2, 0.0549702188000083), (3, 0.058286013547331095), (13, 0.05945862550288439), (11, 0.059654131066054106), (17, 0.06215685745701194), (52, 0.06302989413961768), (0, 0.06374166905879974), (1, 0.066963080316782), (8, 0.07421957887709141), (10, 0.08139985986053944), (16, 0.08561852388083935), (12, 0.09027372486889362), (5, 0.10608604364097118), (36, 0.4341319054365158), (18, 0.5138366967439651), (53, 0.8183643594384193)]
computing accuracy for after removing block 28 . block score: 0.013910263776779175
removed block 28 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 35, with score 0.015938. All blocks and scores: [(35, 0.015937853488139808), (27, 0.016953567741438746), (25, 0.017858794424682856), (23, 0.019088684115558863), (43, 0.019321017200127244), (24, 0.019706126768141985), (46, 0.020138880237936974), (41, 0.021938683232292533), (40, 0.023294744547456503), (45, 0.023716629249975085), (44, 0.02401796099729836), (50, 0.02414565603248775), (48, 0.024327227380126715), (42, 0.024492604425176978), (21, 0.025161586003378034), (49, 0.02526882174424827), (22, 0.025336497696116567), (47, 0.027129362802952528), (20, 0.027149996487423778), (38, 0.030634459806606174), (39, 0.03097354806959629), (15, 0.032203277572989464), (19, 0.03254366898909211), (7, 0.0327202994376421), (37, 0.03824812872335315), (51, 0.04005839955061674), (9, 0.0439148903824389), (6, 0.046870214864611626), (14, 0.04798476677387953), (4, 0.04873769311234355), (2, 0.05497021786868572), (3, 0.05828601587563753), (13, 0.05945862643420696), (11, 0.059654129203408957), (52, 0.062109317630529404), (17, 0.062156857922673225), (0, 0.06374167092144489), (1, 0.06696308124810457), (8, 0.07421958073973656), (10, 0.08139985706657171), (16, 0.08561852481216192), (12, 0.09027373045682907), (5, 0.10608603991568089), (36, 0.4369577430188656), (18, 0.5138367041945457), (53, 0.8310785293579102)]
computing accuracy for after removing block 35 . block score: 0.015937853488139808
removed block 35 current accuracy 0.9384 loss from initial  0.013000000000000012
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 27, with score 0.016954. All blocks and scores: [(27, 0.016953568207100034), (25, 0.0178587946575135), (43, 0.018010383704677224), (46, 0.018981349654495716), (23, 0.01908868458122015), (24, 0.019706126069650054), (41, 0.01982132066041231), (40, 0.02179461671039462), (42, 0.022271172143518925), (48, 0.022273273905739188), (50, 0.022438953863456845), (45, 0.022658708738163114), (44, 0.023038016166538), (49, 0.02390917856246233), (21, 0.02516158646903932), (22, 0.02533649862743914), (47, 0.025964293163269758), (20, 0.027149996487423778), (39, 0.028815423138439655), (38, 0.028842001454904675), (15, 0.03220327664166689), (19, 0.032543668523430824), (7, 0.03272029897198081), (37, 0.03512017847970128), (51, 0.03777468437328935), (9, 0.043914890848100185), (6, 0.046870213001966476), (14, 0.04798476677387953), (4, 0.04873769637197256), (2, 0.05497021973133087), (52, 0.05734774749726057), (3, 0.05828601634129882), (13, 0.0594586250372231), (11, 0.05965413060039282), (17, 0.06215685838833451), (0, 0.06374166812747717), (1, 0.066963080316782), (8, 0.07421957887709141), (10, 0.08139985799789429), (16, 0.0856185257434845), (12, 0.0902737295255065), (5, 0.10608604364097118), (36, 0.415569793432951), (18, 0.5138366967439651), (53, 0.8745588064193726)]
computing accuracy for after removing block 27 . block score: 0.016953568207100034
removed block 27 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 25, with score 0.017859. All blocks and scores: [(25, 0.017858794424682856), (43, 0.018317106878384948), (46, 0.018957680091261864), (23, 0.019088683649897575), (24, 0.01970612653531134), (41, 0.020166767295449972), (48, 0.02195803401991725), (40, 0.022000046214088798), (50, 0.02214362216182053), (42, 0.022741821827366948), (45, 0.02287250687368214), (44, 0.023302890127524734), (49, 0.02369017549790442), (21, 0.02516158646903932), (22, 0.02533649792894721), (47, 0.02534860768355429), (20, 0.02714999718591571), (38, 0.02913577714934945), (39, 0.02927903737872839), (15, 0.032203277572989464), (19, 0.0325436694547534), (7, 0.03272030036896467), (37, 0.03664706228300929), (51, 0.03713457006961107), (9, 0.04391489224508405), (6, 0.04687021533027291), (14, 0.047984767239540815), (4, 0.04873769450932741), (2, 0.054970217403024435), (52, 0.05597325414419174), (3, 0.058286015409976244), (13, 0.0594586250372231), (11, 0.05965413060039282), (17, 0.06215685559436679), (0, 0.06374166999012232), (1, 0.066963080316782), (8, 0.07421957980841398), (10, 0.08139985613524914), (16, 0.0856185257434845), (12, 0.09027372859418392), (5, 0.10608604084700346), (36, 0.42596689611673355), (18, 0.5138367190957069), (53, 0.8840208128094673)]
computing accuracy for after removing block 25 . block score: 0.017858794424682856
removed block 25 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.018633. All blocks and scores: [(43, 0.01863290020264685), (46, 0.018854898400604725), (23, 0.019088684115558863), (24, 0.019706126069650054), (41, 0.02047356008552015), (48, 0.021866551600396633), (50, 0.021877270890399814), (40, 0.0221753790974617), (42, 0.022820094833150506), (45, 0.02300167316570878), (49, 0.0233701691031456), (44, 0.023433112306520343), (47, 0.024973108433187008), (21, 0.025161586934700608), (22, 0.02533649792894721), (20, 0.027149996254593134), (38, 0.029465094907209277), (39, 0.0301216347143054), (15, 0.032203275710344315), (19, 0.032543668523430824), (7, 0.03272030036896467), (51, 0.036445769015699625), (37, 0.03840269520878792), (9, 0.04391488991677761), (6, 0.046870213467627764), (14, 0.04798476630821824), (4, 0.048737695440649986), (52, 0.054477124474942684), (2, 0.05497021693736315), (3, 0.05828601634129882), (13, 0.059458625968545675), (11, 0.05965413013473153), (17, 0.062156859785318375), (0, 0.06374166999012232), (1, 0.06696308217942715), (8, 0.07421957980841398), (10, 0.08139985986053944), (16, 0.08561852481216192), (12, 0.09027373045682907), (5, 0.10608604084700346), (36, 0.4367382526397705), (18, 0.5138366967439651), (53, 0.8921619057655334)]
computing accuracy for after removing block 43 . block score: 0.01863290020264685
removed block 43 current accuracy 0.9246 loss from initial  0.026800000000000046
training start
training epoch 0 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 1 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.1]
training epoch 2 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 3 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.1]
training epoch 4 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.1]
training epoch 5 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.1]
training epoch 6 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.1]
training epoch 7 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 8 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.1]
training epoch 9 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.012027. All blocks and scores: [(41, 0.01202673395164311), (42, 0.013464395888149738), (40, 0.01368517754599452), (39, 0.019166146405041218), (38, 0.021377082681283355), (46, 0.02334705600515008), (50, 0.02630152669735253), (37, 0.026444626040756702), (48, 0.026688682148233056), (49, 0.027234388748183846), (45, 0.027753306785598397), (44, 0.028868684777989984), (47, 0.03153022727929056), (15, 0.03209314029663801), (7, 0.032875973265618086), (23, 0.0343165579251945), (19, 0.0343178641051054), (24, 0.03440926084294915), (21, 0.03580240113660693), (20, 0.03783641895279288), (22, 0.04106032894924283), (51, 0.04228192754089832), (9, 0.044291955418884754), (6, 0.04688811954110861), (4, 0.0472078463062644), (14, 0.04807541938498616), (2, 0.05501457117497921), (3, 0.058065516874194145), (13, 0.059640008956193924), (11, 0.05994498077780008), (17, 0.062290530651807785), (0, 0.06447565089911222), (1, 0.06789342127740383), (52, 0.06807659659534693), (8, 0.07435232773423195), (10, 0.08172236941754818), (16, 0.08606419619172812), (12, 0.09122469369322062), (5, 0.10701633244752884), (36, 0.43663884699344635), (18, 0.5161413997411728), (53, 0.8167056366801262)]
computing accuracy for after removing block 41 . block score: 0.01202673395164311
removed block 41 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.013234. All blocks and scores: [(42, 0.013234303565695882), (40, 0.013685177313163877), (39, 0.019166145473718643), (38, 0.021377082681283355), (46, 0.022850603330880404), (48, 0.025709674460813403), (50, 0.025887019466608763), (37, 0.026444625575095415), (49, 0.02684145257808268), (45, 0.02844919147901237), (44, 0.029211189597845078), (47, 0.031537237111479044), (15, 0.0320931407622993), (7, 0.03287597373127937), (23, 0.03431655699387193), (19, 0.034317863173782825), (24, 0.034409260377287865), (21, 0.035802400670945644), (20, 0.037836420349776745), (22, 0.04106033081188798), (51, 0.041428023017942905), (9, 0.044291955418884754), (6, 0.04688812093809247), (4, 0.047207847237586975), (14, 0.04807542031630874), (2, 0.055014570243656635), (3, 0.05806551733985543), (13, 0.0596400061622262), (11, 0.05994497984647751), (17, 0.06229053484275937), (0, 0.06447564996778965), (52, 0.06632143259048462), (1, 0.06789342314004898), (8, 0.07435232680290937), (10, 0.0817223684862256), (16, 0.08606420084834099), (12, 0.09122469462454319), (5, 0.10701633337885141), (36, 0.43663886189460754), (18, 0.5161413997411728), (53, 0.8461621180176735)]
computing accuracy for after removing block 42 . block score: 0.013234303565695882
removed block 42 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.013685. All blocks and scores: [(40, 0.01368517754599452), (39, 0.019166145473718643), (38, 0.021377083379775286), (46, 0.023862758884206414), (50, 0.0260044455062598), (48, 0.026065316051244736), (37, 0.02644462650641799), (49, 0.02668328699655831), (45, 0.029209898551926017), (44, 0.0303596961311996), (47, 0.0317655059043318), (15, 0.0320931407622993), (7, 0.03287597233429551), (23, 0.03431655839085579), (19, 0.03431786457076669), (24, 0.03440926084294915), (21, 0.035802402067929506), (20, 0.03783641895279288), (22, 0.04106032848358154), (51, 0.04125651391223073), (9, 0.04429195635020733), (6, 0.046888120006769896), (4, 0.04720784770324826), (14, 0.04807542124763131), (2, 0.055014570243656635), (3, 0.05806551827117801), (13, 0.059640010353177786), (11, 0.059944980312138796), (17, 0.062290532514452934), (0, 0.06447565089911222), (52, 0.06757460441440344), (1, 0.06789341941475868), (8, 0.07435232773423195), (10, 0.0817223684862256), (16, 0.08606420084834099), (12, 0.09122469369322062), (5, 0.10701633431017399), (36, 0.43663886561989784), (18, 0.5161413997411728), (53, 0.8573095872998238)]
computing accuracy for after removing block 40 . block score: 0.01368517754599452
removed block 40 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.006799999999999917 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 39, with score 0.019166. All blocks and scores: [(39, 0.019166145008057356), (38, 0.021377083146944642), (46, 0.023788695689290762), (50, 0.025165800703689456), (48, 0.02541735698468983), (49, 0.02595632802695036), (37, 0.026444626273587346), (45, 0.029033684637397528), (44, 0.031514415983110666), (47, 0.03201101440936327), (15, 0.0320931407622993), (7, 0.0328759727999568), (23, 0.03431655839085579), (19, 0.03431786363944411), (24, 0.034409260377287865), (21, 0.03580239927396178), (20, 0.03783641895279288), (22, 0.04106032941490412), (51, 0.041071837302297354), (9, 0.044291955418884754), (6, 0.046888120006769896), (4, 0.04720784677192569), (14, 0.048075420781970024), (2, 0.05501456977799535), (3, 0.058065518736839294), (13, 0.0596400061622262), (11, 0.05994497938081622), (17, 0.06229053344577551), (0, 0.06447565089911222), (52, 0.06539032328873873), (1, 0.06789342034608126), (8, 0.0743523258715868), (10, 0.08172236755490303), (16, 0.08606419805437326), (12, 0.09122469462454319), (5, 0.10701633524149656), (36, 0.43663886561989784), (18, 0.5161413997411728), (53, 0.904352031648159)]
computing accuracy for after removing block 39 . block score: 0.019166145008057356
removed block 39 current accuracy 0.924 loss from initial  0.02739999999999998
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.021377. All blocks and scores: [(38, 0.02137708244845271), (46, 0.023140403674915433), (50, 0.023643084801733494), (48, 0.024021656485274434), (49, 0.025005986914038658), (37, 0.02644462580792606), (45, 0.02836222806945443), (47, 0.03052906272932887), (44, 0.032038685865700245), (15, 0.03209314029663801), (7, 0.03287597233429551), (23, 0.03431655839085579), (19, 0.03431786363944411), (24, 0.034409260377287865), (21, 0.03580240020528436), (20, 0.03783641988411546), (51, 0.04016290744766593), (22, 0.041060329880565405), (9, 0.04429195635020733), (6, 0.04688812093809247), (4, 0.04720784677192569), (14, 0.048075420781970024), (2, 0.05501457070931792), (3, 0.05806551780551672), (13, 0.05964000802487135), (11, 0.05994498170912266), (52, 0.06125916773453355), (17, 0.06229053344577551), (0, 0.0644756518304348), (1, 0.06789342034608126), (8, 0.0743523258715868), (10, 0.08172237128019333), (16, 0.08606419898569584), (12, 0.09122469369322062), (5, 0.10701633431017399), (36, 0.43663886189460754), (18, 0.5161413997411728), (53, 0.9649433493614197)]
computing accuracy for after removing block 38 . block score: 0.02137708244845271
removed block 38 current accuracy 0.9124 loss from initial  0.039000000000000035
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.022534. All blocks and scores: [(50, 0.022534009302034974), (46, 0.022548547945916653), (48, 0.023079403210431337), (49, 0.024246208602562547), (37, 0.026444626273587346), (45, 0.02698209136724472), (47, 0.02909898664802313), (15, 0.032093139830976725), (7, 0.032875973265618086), (44, 0.032881506718695164), (23, 0.03431655839085579), (19, 0.03431786363944411), (24, 0.034409260377287865), (21, 0.03580240020528436), (20, 0.037836418487131596), (51, 0.040032907854765654), (22, 0.041060328017920256), (9, 0.0442919572815299), (6, 0.04688812047243118), (4, 0.04720784770324826), (14, 0.04807542031630874), (2, 0.055014572106301785), (3, 0.058065518736839294), (52, 0.05941196111962199), (13, 0.05964000662788749), (11, 0.05994498124346137), (17, 0.062290532514452934), (0, 0.06447565089911222), (1, 0.06789341848343611), (8, 0.07435232680290937), (10, 0.08172236755490303), (16, 0.08606419712305069), (12, 0.09122469555586576), (5, 0.10701633337885141), (36, 0.43663886189460754), (18, 0.5161414071917534), (53, 0.9891980439424515)]
computing accuracy for after removing block 50 . block score: 0.022534009302034974
removed block 50 current accuracy 0.9028 loss from initial  0.04859999999999998
training start
training epoch 0 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 1 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 2 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.1]
training epoch 3 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.1]
training epoch 4 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 5 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.1]
training epoch 6 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.1]
training epoch 7 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 8 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 9 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 18
[activation diff]: block to remove picked: 48, with score 0.025015. All blocks and scores: [(48, 0.02501455438323319), (49, 0.0252084422390908), (15, 0.03228232776746154), (7, 0.03263591416180134), (46, 0.03295801253989339), (19, 0.03442985750734806), (45, 0.03656392823904753), (47, 0.036720409989356995), (20, 0.03800575854256749), (23, 0.03973793424665928), (44, 0.0422277650795877), (9, 0.04391347477212548), (51, 0.04418358579277992), (24, 0.04429037822410464), (21, 0.04553082725033164), (6, 0.04707366833463311), (4, 0.047921613324433565), (22, 0.048093503806740046), (14, 0.04826686065644026), (2, 0.05514105223119259), (3, 0.058587513864040375), (13, 0.05936817359179258), (11, 0.0601737922988832), (17, 0.06213659094646573), (0, 0.06423292309045792), (1, 0.06664411164820194), (52, 0.07105965353548527), (8, 0.07497039623558521), (10, 0.0813461784273386), (16, 0.08610157482326031), (37, 0.0902398731559515), (12, 0.09112040046602488), (5, 0.10730154626071453), (18, 0.5166036039590836), (36, 0.5675306767225266), (53, 0.8218118622899055)]
computing accuracy for after removing block 48 . block score: 0.02501455438323319
removed block 48 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.028792. All blocks and scores: [(49, 0.02879229048267007), (15, 0.032282326836138964), (7, 0.032635914627462626), (46, 0.0329580120742321), (19, 0.03442985704168677), (45, 0.0365639291703701), (47, 0.03672040719538927), (20, 0.038005759473890066), (23, 0.03973793378099799), (44, 0.04222776461392641), (9, 0.043913474306464195), (24, 0.04429038008674979), (21, 0.04553082678467035), (6, 0.047073669731616974), (51, 0.04769505700096488), (4, 0.04792161379009485), (22, 0.04809350147843361), (14, 0.048266861122101545), (2, 0.05514105083420873), (3, 0.05858751526102424), (13, 0.05936817359179258), (11, 0.06017379183322191), (17, 0.06213659048080444), (0, 0.06423292495310307), (1, 0.06664411257952452), (8, 0.07497039530426264), (10, 0.08134617935866117), (16, 0.08610157668590546), (52, 0.08678631577640772), (37, 0.09023987129330635), (12, 0.0911204032599926), (5, 0.10730154905468225), (18, 0.5166036039590836), (36, 0.567530669271946), (53, 0.8999972939491272)]
computing accuracy for after removing block 49 . block score: 0.02879229048267007
removed block 49 current accuracy 0.9136 loss from initial  0.037800000000000056
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.032282. All blocks and scores: [(15, 0.03228232776746154), (7, 0.032635912764817476), (46, 0.03295801114290953), (19, 0.03442985704168677), (45, 0.036563928704708815), (47, 0.036720408126711845), (20, 0.03800575993955135), (23, 0.03973793378099799), (44, 0.04222776461392641), (9, 0.043913474306464195), (24, 0.044290379621088505), (21, 0.045530826319009066), (6, 0.04707366926595569), (4, 0.047921613324433565), (22, 0.04809350147843361), (14, 0.04826686251908541), (51, 0.0528722177259624), (2, 0.055141051299870014), (3, 0.0585875129327178), (13, 0.05936817219480872), (11, 0.06017379183322191), (17, 0.06213659327477217), (0, 0.06423292495310307), (1, 0.06664411444216967), (8, 0.07497039716690779), (10, 0.08134617749601603), (16, 0.08610157761722803), (37, 0.09023986849933863), (12, 0.09112040232867002), (52, 0.10234167240560055), (5, 0.1073015471920371), (18, 0.5166036188602448), (36, 0.567530669271946), (53, 0.998935379087925)]
computing accuracy for after removing block 15 . block score: 0.03228232776746154
removed block 15 current accuracy 0.9134 loss from initial  0.038000000000000034
since last training loss: 0.027800000000000047 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 7, with score 0.032636. All blocks and scores: [(7, 0.032635913230478764), (46, 0.033523515332490206), (19, 0.03436816390603781), (20, 0.035692266654223204), (45, 0.03692622482776642), (47, 0.03702637227252126), (23, 0.03780767787247896), (44, 0.0411250670440495), (24, 0.04252358339726925), (21, 0.04314607195556164), (9, 0.04391347384080291), (22, 0.04569416446611285), (6, 0.047073667868971825), (4, 0.047921613324433565), (14, 0.04826686065644026), (51, 0.053429129999130964), (2, 0.055141051299870014), (3, 0.058587512001395226), (13, 0.05936817359179258), (11, 0.06017379090189934), (0, 0.06423292402178049), (17, 0.06595866847783327), (1, 0.06664411164820194), (8, 0.07497039716690779), (10, 0.08134617749601603), (12, 0.09112040605396032), (37, 0.09219320118427277), (16, 0.09617602173238993), (52, 0.10400677658617496), (5, 0.10730154626071453), (18, 0.5037037581205368), (36, 0.5650759190320969), (53, 0.9957980886101723)]
computing accuracy for after removing block 7 . block score: 0.032635913230478764
removed block 7 current accuracy 0.905 loss from initial  0.0464
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.031731. All blocks and scores: [(46, 0.03173083649016917), (19, 0.03392218938097358), (20, 0.03403744054958224), (23, 0.03495300142094493), (47, 0.036436236929148436), (45, 0.03661687020212412), (44, 0.039950497448444366), (24, 0.03998719062656164), (21, 0.04213321581482887), (22, 0.04300032556056976), (9, 0.043793100863695145), (14, 0.04459421802312136), (6, 0.04707366647198796), (4, 0.047921613324433565), (13, 0.05148443207144737), (51, 0.05173206748440862), (2, 0.05514105223119259), (17, 0.05585049791261554), (11, 0.056828062515705824), (3, 0.058587512001395226), (0, 0.06423292588442564), (1, 0.06664411630481482), (8, 0.07298850547522306), (10, 0.08373814634978771), (12, 0.0850669639185071), (16, 0.08758407551795244), (37, 0.08822895959019661), (52, 0.09817502275109291), (5, 0.1073015471920371), (18, 0.48684921115636826), (36, 0.5461191013455391), (53, 1.0245348885655403)]
computing accuracy for after removing block 46 . block score: 0.03173083649016917
removed block 46 current accuracy 0.8812 loss from initial  0.07020000000000004
since last training loss: 0.06000000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 19, with score 0.033922. All blocks and scores: [(19, 0.033922189846634865), (20, 0.03403744101524353), (23, 0.03495300142094493), (45, 0.036616869270801544), (44, 0.039950497914105654), (24, 0.039987190160900354), (47, 0.04105631308630109), (21, 0.0421332148835063), (22, 0.04300032602623105), (9, 0.043793100863695145), (14, 0.04459421802312136), (6, 0.04707366926595569), (4, 0.04792161425575614), (13, 0.05148442881181836), (51, 0.05208698334172368), (2, 0.055141051299870014), (17, 0.05585049604997039), (11, 0.05682806018739939), (3, 0.058587510604411364), (0, 0.06423292402178049), (1, 0.06664411537349224), (8, 0.07298850454390049), (10, 0.08373814262449741), (12, 0.0850669639185071), (16, 0.08758407738059759), (37, 0.08822896052151918), (52, 0.09642697405070066), (5, 0.10730154905468225), (18, 0.48684921860694885), (36, 0.5461190938949585), (53, 1.1244387477636337)]
computing accuracy for after removing block 19 . block score: 0.033922189846634865
removed block 19 current accuracy 0.868 loss from initial  0.08340000000000003
since last training loss: 0.07320000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 23, with score 0.031801. All blocks and scores: [(23, 0.03180127032101154), (20, 0.032416872680187225), (45, 0.036206324119120836), (24, 0.0368905384093523), (44, 0.03778840461745858), (47, 0.039472824428230524), (21, 0.04073983244597912), (22, 0.041621316224336624), (9, 0.04379310132935643), (14, 0.044594218488782644), (6, 0.047073667868971825), (4, 0.04792161425575614), (51, 0.051290512550622225), (13, 0.05148443067446351), (2, 0.05514105036854744), (17, 0.05585049791261554), (11, 0.056828060653060675), (3, 0.05858751432970166), (0, 0.06423292495310307), (1, 0.06664411444216967), (8, 0.07298850640654564), (10, 0.08373814355581999), (12, 0.08506696298718452), (16, 0.08758407738059759), (52, 0.09007631335407495), (37, 0.09180544968694448), (5, 0.10730154812335968), (18, 0.48684921860694885), (36, 0.5385024398565292), (53, 1.1390243470668793)]
computing accuracy for after removing block 23 . block score: 0.03180127032101154
removed block 23 current accuracy 0.8578 loss from initial  0.09360000000000002
since last training loss: 0.08340000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 20, with score 0.032417. All blocks and scores: [(20, 0.03241687174886465), (45, 0.035721694119274616), (47, 0.03675402468070388), (24, 0.037053144071251154), (44, 0.037846921011805534), (21, 0.040739832911640406), (22, 0.04162131529301405), (9, 0.04379309993237257), (14, 0.04459421942010522), (6, 0.047073669731616974), (4, 0.04792161425575614), (51, 0.05085505871102214), (13, 0.051484429743140936), (2, 0.05514104990288615), (17, 0.05585049791261554), (11, 0.056828062515705824), (3, 0.05858751432970166), (0, 0.06423292495310307), (1, 0.06664411444216967), (8, 0.07298850547522306), (10, 0.08373814355581999), (12, 0.08506696298718452), (16, 0.08758407831192017), (52, 0.0884024165570736), (37, 0.09632747434079647), (5, 0.10730154626071453), (18, 0.48684922233223915), (36, 0.5564763769507408), (53, 1.14885812997818)]
computing accuracy for after removing block 20 . block score: 0.03241687174886465
removed block 20 current accuracy 0.8428 loss from initial  0.10860000000000003
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.033838. All blocks and scores: [(24, 0.03383792657405138), (45, 0.03580667870119214), (47, 0.036106289364397526), (44, 0.037394847720861435), (21, 0.04070134833455086), (22, 0.04175402829423547), (9, 0.04379309993237257), (14, 0.04459421802312136), (6, 0.0470736688002944), (4, 0.04792161379009485), (51, 0.049927685875445604), (13, 0.05148443067446351), (2, 0.05514104990288615), (17, 0.0558504993095994), (11, 0.05682806018739939), (3, 0.05858751432970166), (0, 0.06423292309045792), (1, 0.06664411444216967), (8, 0.07298850640654564), (52, 0.08257043175399303), (10, 0.08373814355581999), (12, 0.0850669639185071), (16, 0.08758407644927502), (37, 0.10290196910500526), (5, 0.1073015471920371), (18, 0.48684919625520706), (36, 0.5667210444808006), (53, 1.1681695133447647)]
computing accuracy for after removing block 24 . block score: 0.03383792657405138
removed block 24 current accuracy 0.793 loss from initial  0.15839999999999999
training start
training epoch 0 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best True lr [0.1]
training epoch 1 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best True lr [0.1]
training epoch 2 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 3 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.1]
training epoch 4 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.1]
training epoch 5 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 6 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 7 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 8 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 9 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
