start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013294660835526884), (29, 0.013421116978861392), (35, 0.01595768961124122), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019996492192149162), (46, 0.020590225933119655), (25, 0.022078294539824128), (23, 0.022228715242817998), (41, 0.022336415946483612), (44, 0.023145998362451792), (40, 0.02374959085136652), (45, 0.023975495481863618), (21, 0.02494109026156366), (48, 0.024957707850262523), (22, 0.02515139104798436), (50, 0.025287174154073), (24, 0.025880582630634308), (49, 0.02591664856299758), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.031441295985132456), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216303735971), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013119244133122265), (29, 0.013421116746030748), (26, 0.016072141006588936), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.024770822376012802), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.026848891051486135), (47, 0.02807276020757854), (38, 0.031091188080608845), (39, 0.031191362533718348), (15, 0.0320583856664598), (7, 0.032445501536130905), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.041271014139056206), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241137996316), (2, 0.05457740509882569), (3, 0.05784992966800928), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.06132525531575084), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806139469147), (18, 0.5117432996630669), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.012758882017806172), (29, 0.013421116746030748), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022891478380188346), (40, 0.023602580884471536), (45, 0.023770849453285336), (48, 0.024519873084500432), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.0253925493452698), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848891051486135), (47, 0.02805250510573387), (38, 0.030935874208807945), (39, 0.03117303689941764), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216024339199), (8, 0.07466361299157143), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537236094475), (5, 0.1067114369943738), (36, 0.4350203163921833), (18, 0.5117432847619057), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160077959299), (29, 0.013421116746030748), (35, 0.015918649034574628), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019867350813001394), (46, 0.020279744174331427), (41, 0.02175602037459612), (25, 0.022078293841332197), (23, 0.02222871594130993), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025246929842978716), (42, 0.025273551465943456), (24, 0.02588058216497302), (20, 0.026848892215639353), (47, 0.02772757550701499), (38, 0.030746275326237082), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03895266819745302), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06356756389141083), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117432996630669), (53, 0.8228829354047775)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.01342111686244607), (35, 0.015968912048265338), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019837007857859135), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078294772654772), (23, 0.022228714544326067), (44, 0.02268732525408268), (40, 0.023569098208099604), (45, 0.023840720299631357), (48, 0.024108358658850193), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.025045575108379126), (22, 0.025151390815153718), (24, 0.025880582397803664), (20, 0.02684889268130064), (47, 0.027423852356150746), (38, 0.030735648702830076), (39, 0.03141042543575168), (15, 0.03205838426947594), (7, 0.03244550386443734), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.040345939341932535), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992454573512), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.061325255781412125), (52, 0.06270107813179493), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43692687153816223), (18, 0.5117432922124863), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421117211692035), (26, 0.01607214123941958), (35, 0.01655877218581736), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.02030268474482), (46, 0.020324197132140398), (41, 0.02196270227432251), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.023045077454298735), (48, 0.024024547543376684), (50, 0.024096972541883588), (40, 0.02415681630373001), (45, 0.02416840917430818), (49, 0.024922373704612255), (21, 0.024941088864579797), (22, 0.025151390582323074), (42, 0.025816059671342373), (24, 0.025880582397803664), (20, 0.02684889268130064), (47, 0.027568295132368803), (38, 0.03178726346231997), (15, 0.03205838426947594), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.04008621443063021), (37, 0.0406907326541841), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428923279047), (11, 0.059700035490095615), (17, 0.06132525438442826), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.44933701679110527), (18, 0.5117432773113251), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421117211692035
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 1 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.1]
training epoch 2 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.1]
training epoch 3 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.1]
training epoch 4 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.1]
training epoch 5 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.1]
training epoch 6 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 8 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 9 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.1]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.010013. All blocks and scores: [(26, 0.010013246675953269), (35, 0.010302759241312742), (28, 0.012735330616123974), (27, 0.0150487229693681), (25, 0.017402702942490578), (43, 0.02010162896476686), (46, 0.0206059361808002), (23, 0.022439037915319204), (41, 0.022509667091071606), (44, 0.023105068365111947), (45, 0.02356182551011443), (40, 0.02420243015512824), (48, 0.02462012693285942), (21, 0.025066637666895986), (22, 0.025324424961581826), (50, 0.02536557475104928), (49, 0.025974529795348644), (42, 0.02600619406439364), (24, 0.02604533382691443), (20, 0.02713565807789564), (47, 0.028375311754643917), (39, 0.03203350305557251), (15, 0.032118053175508976), (7, 0.03244923986494541), (38, 0.03275571670383215), (19, 0.03281733486801386), (37, 0.03985977917909622), (51, 0.04038068978115916), (9, 0.04354358185082674), (6, 0.04651216929778457), (4, 0.04735022550448775), (14, 0.048016182612627745), (2, 0.05483414465561509), (3, 0.05797174572944641), (11, 0.059633173048496246), (13, 0.059659975580871105), (17, 0.061724703293293715), (0, 0.06324702966958284), (52, 0.06542866863310337), (1, 0.06575881969183683), (8, 0.07473709341138601), (10, 0.0807598577812314), (16, 0.08615369815379381), (12, 0.0902909617871046), (5, 0.10527311079204082), (36, 0.3562903366982937), (18, 0.5131314024329185), (53, 0.7836053967475891)]
computing accuracy for after removing block 26 . block score: 0.010013246675953269
removed block 26 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.009832. All blocks and scores: [(35, 0.009832353563979268), (28, 0.012531602755188942), (27, 0.015172425657510757), (25, 0.017402702709659934), (43, 0.020002941833809018), (46, 0.020310224033892155), (41, 0.02213350823149085), (23, 0.022439038148149848), (44, 0.023249804507941008), (45, 0.023552867583930492), (40, 0.023974613286554813), (48, 0.024462409550324082), (21, 0.0250666372012347), (42, 0.025106115732342005), (50, 0.025111062452197075), (22, 0.02532442449592054), (49, 0.025878071784973145), (24, 0.02604533452540636), (20, 0.02713565737940371), (47, 0.028062466764822602), (15, 0.0321180522441864), (39, 0.03237979719415307), (7, 0.032449239399284124), (38, 0.03280928451567888), (19, 0.032817333936691284), (51, 0.03977468516677618), (37, 0.040385793428868055), (9, 0.04354358045384288), (6, 0.046512171626091), (4, 0.047350225038826466), (14, 0.04801618214696646), (2, 0.05483414605259895), (3, 0.057971746660768986), (11, 0.05963317211717367), (13, 0.05965997837483883), (17, 0.06172470562160015), (0, 0.06324703060090542), (52, 0.06451941886916757), (1, 0.06575881969183683), (8, 0.07473709341138601), (10, 0.08075985684990883), (16, 0.08615369722247124), (12, 0.09029095806181431), (5, 0.10527311265468597), (36, 0.3583262301981449), (18, 0.5131313875317574), (53, 0.7987919598817825)]
computing accuracy for after removing block 35 . block score: 0.009832353563979268
removed block 35 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012532. All blocks and scores: [(28, 0.012531602405942976), (27, 0.015172425657510757), (25, 0.01740270317532122), (43, 0.01939235720783472), (46, 0.019535457249730825), (41, 0.021052173571661115), (23, 0.022439037449657917), (45, 0.022979753790423274), (44, 0.02304783696308732), (40, 0.023383522871881723), (48, 0.02339904266409576), (42, 0.02380327763967216), (50, 0.023966478183865547), (21, 0.025066636968404055), (49, 0.025067694950848818), (22, 0.02532442519441247), (24, 0.02604533452540636), (20, 0.02713565668091178), (47, 0.02735650958493352), (39, 0.030943834455683827), (38, 0.03192723006941378), (15, 0.032118053175508976), (7, 0.03244923986494541), (19, 0.03281733300536871), (51, 0.03830559132620692), (37, 0.03909226460382342), (9, 0.04354357998818159), (6, 0.046512171160429716), (4, 0.047350225038826466), (14, 0.04801618214696646), (2, 0.054834144189953804), (3, 0.0579717461951077), (11, 0.05963317258283496), (13, 0.05965997604653239), (52, 0.061299048364162445), (17, 0.061724703758955), (0, 0.06324702966958284), (1, 0.06575881969183683), (8, 0.07473709713667631), (10, 0.08075985591858625), (16, 0.08615369722247124), (12, 0.0902909617871046), (5, 0.10527311451733112), (36, 0.3511274829506874), (18, 0.5131313875317574), (53, 0.8227331340312958)]
computing accuracy for after removing block 28 . block score: 0.012531602405942976
removed block 28 current accuracy 0.9378 loss from initial  0.013600000000000056
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 27, with score 0.015172. All blocks and scores: [(27, 0.01517242577392608), (25, 0.01740270364098251), (46, 0.019250529119744897), (43, 0.019781062845140696), (41, 0.02125658909790218), (23, 0.022439037216827273), (45, 0.022921816678717732), (44, 0.023105332627892494), (48, 0.023228286765515804), (40, 0.02336213062517345), (50, 0.023875086568295956), (42, 0.024125329218804836), (49, 0.024716853396967053), (21, 0.025066637666895986), (22, 0.025324425660073757), (24, 0.02604533452540636), (47, 0.026782269356772304), (20, 0.027135657146573067), (39, 0.03153585712425411), (15, 0.032118053175508976), (7, 0.0324492403306067), (38, 0.032565895933657885), (19, 0.03281733347103), (51, 0.03832331206649542), (37, 0.04091979609802365), (9, 0.04354358138516545), (6, 0.04651216929778457), (4, 0.047350226901471615), (14, 0.04801618214696646), (2, 0.054834144189953804), (3, 0.057971744798123837), (11, 0.0596331711858511), (13, 0.059659977443516254), (52, 0.06149164494127035), (17, 0.061724704690277576), (0, 0.06324703060090542), (1, 0.06575881969183683), (8, 0.07473709620535374), (10, 0.08075985684990883), (16, 0.08615369629114866), (12, 0.0902909617871046), (5, 0.10527311265468597), (36, 0.36217453330755234), (18, 0.5131313800811768), (53, 0.8282105699181557)]
computing accuracy for after removing block 27 . block score: 0.01517242577392608
removed block 27 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 25, with score 0.017403. All blocks and scores: [(25, 0.017402702942490578), (46, 0.01884674746543169), (43, 0.0199685450643301), (41, 0.021274789236485958), (23, 0.02243903768248856), (48, 0.022813638439401984), (45, 0.02285422384738922), (44, 0.022916321409866214), (40, 0.02300225174985826), (50, 0.023391072172671556), (49, 0.024069742066785693), (42, 0.02430897206068039), (21, 0.025066636502742767), (22, 0.025324424728751183), (47, 0.02602453646250069), (24, 0.02604533452540636), (20, 0.027135657845064998), (39, 0.031559457536786795), (15, 0.0321180522441864), (7, 0.032449239399284124), (19, 0.032817333936691284), (38, 0.03299865499138832), (51, 0.03767170989885926), (37, 0.04239053372293711), (9, 0.04354358045384288), (6, 0.04651217069476843), (4, 0.047350226901471615), (14, 0.04801618214696646), (2, 0.05483414651826024), (3, 0.05797174572944641), (11, 0.0596331711858511), (13, 0.05965997651219368), (52, 0.060081420466303825), (17, 0.061724704690277576), (0, 0.06324702966958284), (1, 0.06575882155448198), (8, 0.07473709341138601), (10, 0.0807598577812314), (16, 0.08615369629114866), (12, 0.0902909617871046), (5, 0.10527311358600855), (36, 0.36947449669241905), (18, 0.5131313800811768), (53, 0.8418133035302162)]
computing accuracy for after removing block 25 . block score: 0.017402702942490578
removed block 25 current accuracy 0.93 loss from initial  0.021399999999999975
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.018370. All blocks and scores: [(46, 0.018370249308645725), (43, 0.019844577880576253), (41, 0.021118259988725185), (48, 0.022205985384061933), (23, 0.02243903768248856), (50, 0.02256344654597342), (40, 0.02268677414394915), (44, 0.022729617543518543), (45, 0.0227937123272568), (49, 0.023347750771790743), (42, 0.023907829774543643), (21, 0.025066638132557273), (22, 0.02532442519441247), (47, 0.025450073881074786), (24, 0.026045335456728935), (20, 0.02713565807789564), (15, 0.032118053175508976), (39, 0.03223201306536794), (7, 0.03244923986494541), (19, 0.03281733440235257), (38, 0.03327667806297541), (51, 0.03677371796220541), (9, 0.04354358231648803), (37, 0.04393599182367325), (6, 0.046512169763445854), (4, 0.04735022457316518), (14, 0.04801618121564388), (2, 0.05483414605259895), (52, 0.057463372591882944), (3, 0.05797174572944641), (11, 0.059633173048496246), (13, 0.05965997697785497), (17, 0.061724703293293715), (0, 0.06324703060090542), (1, 0.06575882248580456), (8, 0.07473709527403116), (10, 0.08075985498726368), (16, 0.08615369908511639), (12, 0.09029096085578203), (5, 0.10527311358600855), (36, 0.3762243613600731), (18, 0.5131314024329185), (53, 0.8630808368325233)]
computing accuracy for after removing block 46 . block score: 0.018370249308645725
removed block 46 current accuracy 0.9246 loss from initial  0.026800000000000046
training start
training epoch 0 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 1 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 2 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 3 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.1]
training epoch 4 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 5 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.1]
training epoch 6 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.1]
training epoch 7 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.1]
training epoch 8 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 9 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.009661. All blocks and scores: [(43, 0.009660848532803357), (48, 0.009947348269633949), (44, 0.010998998186551034), (45, 0.011205362272448838), (42, 0.01334888837300241), (47, 0.01412803994026035), (37, 0.019504755036905408), (41, 0.021931403782218695), (40, 0.02387984679080546), (20, 0.027049089316278696), (50, 0.027222833829000592), (49, 0.028540715808048844), (39, 0.03203343180939555), (15, 0.032366592437028885), (7, 0.032630572095513344), (19, 0.03274219809100032), (38, 0.03299560584127903), (21, 0.03436044417321682), (22, 0.0350439022295177), (23, 0.037206508219242096), (51, 0.0422868593595922), (24, 0.042701452039182186), (9, 0.043971065897494555), (6, 0.04643907165154815), (4, 0.04726100293919444), (14, 0.04821922164410353), (2, 0.0546145080588758), (3, 0.0579031459055841), (13, 0.05967356404289603), (11, 0.05974343651905656), (17, 0.06298070307821035), (0, 0.06418282724916935), (52, 0.06682070065289736), (1, 0.06698898039758205), (8, 0.07520102337002754), (10, 0.08168404456228018), (16, 0.08519775979220867), (12, 0.09114860650151968), (5, 0.10688882041722536), (36, 0.2798495516180992), (18, 0.5162681341171265), (53, 0.8009321838617325)]
computing accuracy for after removing block 43 . block score: 0.009660848532803357
removed block 43 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.010089. All blocks and scores: [(48, 0.010089383460581303), (44, 0.011032703332602978), (45, 0.011422836454585195), (42, 0.01334888837300241), (47, 0.0136392138665542), (37, 0.019504755502566695), (41, 0.02193140471354127), (40, 0.023879847954958677), (50, 0.026211607735604048), (20, 0.027049088152125478), (49, 0.027503809425979853), (39, 0.03203343087807298), (15, 0.0323665919713676), (7, 0.032630571629852057), (19, 0.03274219809100032), (38, 0.03299560584127903), (21, 0.034360443241894245), (22, 0.0350439022295177), (23, 0.03720650961622596), (51, 0.040104967541992664), (24, 0.0427014515735209), (9, 0.04397106543183327), (6, 0.04643907165154815), (4, 0.04726100480183959), (14, 0.04821922071278095), (2, 0.05461450619623065), (3, 0.05790314683690667), (13, 0.059673563577234745), (11, 0.059743436984717846), (52, 0.060950849670916796), (17, 0.0629807049408555), (0, 0.06418283097445965), (1, 0.06698897946625948), (8, 0.07520102243870497), (10, 0.08168404456228018), (16, 0.08519776072353125), (12, 0.09114860743284225), (5, 0.10688881855458021), (36, 0.2798495553433895), (18, 0.5162681117653847), (53, 0.8384781405329704)]
computing accuracy for after removing block 48 . block score: 0.010089383460581303
removed block 48 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.011033. All blocks and scores: [(44, 0.011032703332602978), (45, 0.011422836221754551), (42, 0.013348888489417732), (47, 0.013639213750138879), (37, 0.01950475526973605), (41, 0.021931404247879982), (40, 0.02387984748929739), (20, 0.02704908954910934), (50, 0.028803564608097076), (49, 0.029739650897681713), (39, 0.03203343180939555), (15, 0.0323665919713676), (7, 0.032630571629852057), (19, 0.032742198556661606), (38, 0.03299560584127903), (21, 0.03436044277623296), (22, 0.035043900832533836), (23, 0.03720650915056467), (51, 0.04066772386431694), (24, 0.042701452039182186), (9, 0.04397106450051069), (6, 0.04643907072022557), (4, 0.04726100340485573), (14, 0.04821922071278095), (2, 0.05461450666189194), (3, 0.05790314730256796), (13, 0.05967356124892831), (11, 0.05974343745037913), (17, 0.06298070261254907), (0, 0.06418282818049192), (52, 0.06505910865962505), (1, 0.06698898132890463), (8, 0.07520102430135012), (10, 0.08168404549360275), (16, 0.0851977588608861), (12, 0.09114860650151968), (5, 0.10688882414251566), (36, 0.2798495590686798), (18, 0.5162681415677071), (53, 0.8865884840488434)]
computing accuracy for after removing block 44 . block score: 0.011032703332602978
removed block 44 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.011271. All blocks and scores: [(45, 0.011271180934272707), (47, 0.013125600526109338), (42, 0.013348888256587088), (37, 0.01950475526973605), (41, 0.021931404480710626), (40, 0.02387984748929739), (20, 0.027049089781939983), (50, 0.027537457877770066), (49, 0.02846412267535925), (39, 0.032033431343734264), (15, 0.03236659336835146), (7, 0.032630571629852057), (19, 0.03274219809100032), (38, 0.032995604909956455), (21, 0.03436044417321682), (22, 0.03504390176385641), (23, 0.037206508219242096), (51, 0.04007089510560036), (24, 0.04270145343616605), (9, 0.043971065897494555), (6, 0.04643906932324171), (4, 0.04726100340485573), (14, 0.048219220247119665), (2, 0.05461450619623065), (3, 0.05790314916521311), (13, 0.05967356311157346), (11, 0.05974343745037913), (52, 0.061461975798010826), (17, 0.0629807049408555), (0, 0.06418282724916935), (1, 0.06698898039758205), (8, 0.07520102337002754), (10, 0.0816840436309576), (16, 0.08519775979220867), (12, 0.09114860463887453), (5, 0.10688882321119308), (36, 0.2798495590686798), (18, 0.5162681192159653), (53, 0.9695425853133202)]
computing accuracy for after removing block 45 . block score: 0.011271180934272707
removed block 45 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.013349. All blocks and scores: [(42, 0.013348888140171766), (47, 0.01335951080545783), (37, 0.01950475526973605), (41, 0.021931403782218695), (40, 0.023879847722128034), (20, 0.027049089083448052), (50, 0.02733226423151791), (49, 0.027947100810706615), (39, 0.03203343180939555), (15, 0.03236659336835146), (7, 0.032630571629852057), (19, 0.03274219762533903), (38, 0.03299560444429517), (21, 0.034360443241894245), (22, 0.035043901298195124), (23, 0.037206510081887245), (51, 0.03803122555837035), (24, 0.042701452039182186), (9, 0.04397106496617198), (6, 0.046439070254564285), (4, 0.047261003870517015), (14, 0.04821921978145838), (2, 0.0546145080588758), (52, 0.05628774734213948), (3, 0.057903146371245384), (13, 0.05967356264591217), (11, 0.059743436984717846), (17, 0.06298070354387164), (0, 0.06418282724916935), (1, 0.06698898132890463), (8, 0.07520102430135012), (10, 0.08168404269963503), (16, 0.08519776072353125), (12, 0.09114860650151968), (5, 0.10688882227987051), (36, 0.2798495590686798), (18, 0.5162681415677071), (53, 1.0495631694793701)]
computing accuracy for after removing block 42 . block score: 0.013348888140171766
removed block 42 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 47, with score 0.013122. All blocks and scores: [(47, 0.013122358359396458), (37, 0.019504754804074764), (41, 0.021931404480710626), (40, 0.023879847023636103), (50, 0.02599234040826559), (49, 0.027019777102395892), (20, 0.02704908885061741), (39, 0.03203343227505684), (15, 0.0323665919713676), (7, 0.032630571629852057), (19, 0.032742197159677744), (38, 0.03299560584127903), (21, 0.034360443241894245), (22, 0.03504390176385641), (51, 0.03687095968052745), (23, 0.03720650915056467), (24, 0.042701452039182186), (9, 0.04397106496617198), (6, 0.046439070254564285), (4, 0.0472610043361783), (14, 0.04821922071278095), (52, 0.05324172135442495), (2, 0.0546145080588758), (3, 0.05790314823389053), (13, 0.05967356218025088), (11, 0.059743436984717846), (17, 0.0629807049408555), (0, 0.0641828291118145), (1, 0.06698897946625948), (8, 0.07520102337002754), (10, 0.0816840436309576), (16, 0.0851977588608861), (12, 0.09114860463887453), (5, 0.10688882321119308), (36, 0.2798495590686798), (18, 0.5162681415677071), (53, 1.1081335097551346)]
computing accuracy for after removing block 47 . block score: 0.013122358359396458
removed block 47 current accuracy 0.9036 loss from initial  0.047800000000000065
training start
training epoch 0 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 1 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.1]
training epoch 2 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 3 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.1]
training epoch 4 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.1]
training epoch 5 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.1]
training epoch 6 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.1]
training epoch 7 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.1]
training epoch 8 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.1]
training epoch 9 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 18
[activation diff]: block to remove picked: 37, with score 0.019549. All blocks and scores: [(37, 0.019549356075003743), (50, 0.021054236218333244), (41, 0.025617225095629692), (49, 0.026182961650192738), (20, 0.02712428499944508), (40, 0.027917203726246953), (15, 0.03229958191514015), (7, 0.03274057526141405), (19, 0.03286854503676295), (21, 0.03457639692351222), (39, 0.03512820927426219), (22, 0.03527491586282849), (38, 0.03580326121300459), (23, 0.03758628107607365), (24, 0.04271882213652134), (9, 0.04376391600817442), (51, 0.04463084042072296), (6, 0.04694297770038247), (4, 0.048261497635394335), (14, 0.04837771551683545), (2, 0.05514534004032612), (3, 0.05775389773771167), (13, 0.06000342406332493), (11, 0.06034237053245306), (17, 0.06271188985556364), (0, 0.06353125581517816), (1, 0.06707089859992266), (52, 0.06851296592503786), (8, 0.07530375570058823), (10, 0.08162885159254074), (16, 0.08677668403834105), (12, 0.09114138502627611), (5, 0.1069697942584753), (36, 0.2794151231646538), (18, 0.5164263918995857), (53, 0.8038586154580116)]
computing accuracy for after removing block 37 . block score: 0.019549356075003743
removed block 37 current accuracy 0.9336 loss from initial  0.017800000000000038
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.019720. All blocks and scores: [(50, 0.019720458425581455), (41, 0.023802986601367593), (49, 0.024013852700591087), (40, 0.027044170768931508), (20, 0.02712428499944508), (15, 0.03229958238080144), (7, 0.03274057665839791), (19, 0.03286854410544038), (39, 0.03445068281143904), (21, 0.03457639738917351), (22, 0.035274915397167206), (38, 0.03748492803424597), (23, 0.03758628107607365), (51, 0.03948518121615052), (24, 0.04271882167086005), (9, 0.04376391461119056), (6, 0.04694297909736633), (4, 0.04826149716973305), (14, 0.048377713188529015), (2, 0.05514534283429384), (3, 0.05775389866903424), (52, 0.059935450088232756), (13, 0.06000342359766364), (11, 0.0603423691354692), (17, 0.06271189171820879), (0, 0.06353125674650073), (1, 0.06707089953124523), (8, 0.07530375383794308), (10, 0.08162885345518589), (16, 0.08677668776363134), (12, 0.09114138595759869), (5, 0.10696979332715273), (36, 0.2794151343405247), (18, 0.5164264068007469), (53, 0.8210213035345078)]
computing accuracy for after removing block 50 . block score: 0.019720458425581455
removed block 50 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.02299999999999991 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 41, with score 0.023803. All blocks and scores: [(41, 0.023802986135706306), (49, 0.02401385293342173), (40, 0.027044170536100864), (20, 0.02712428499944508), (15, 0.03229958098381758), (7, 0.032740576192736626), (19, 0.03286854410544038), (39, 0.03445068281143904), (21, 0.034576397854834795), (22, 0.03527491586282849), (38, 0.037484928499907255), (23, 0.03758628247305751), (24, 0.042718823067843914), (51, 0.04330476699396968), (9, 0.04376391647383571), (6, 0.04694297816604376), (4, 0.04826149716973305), (14, 0.0483777136541903), (2, 0.05514534143730998), (3, 0.05775389960035682), (13, 0.060003423132002354), (11, 0.06034236866980791), (17, 0.06271189171820879), (0, 0.06353125348687172), (1, 0.0670709004625678), (52, 0.06835335493087769), (8, 0.07530375476926565), (10, 0.08162885624915361), (16, 0.0867766859009862), (12, 0.09114138875156641), (5, 0.1069697942584753), (36, 0.2794151306152344), (18, 0.5164263993501663), (53, 0.9704272076487541)]
computing accuracy for after removing block 41 . block score: 0.023802986135706306
removed block 41 current accuracy 0.8984 loss from initial  0.05300000000000005
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.025664. All blocks and scores: [(49, 0.02566363546065986), (40, 0.027044170070439577), (20, 0.027124285232275724), (15, 0.032299581449478865), (7, 0.03274057526141405), (19, 0.032868544571101665), (39, 0.03445068234577775), (21, 0.034576397854834795), (22, 0.03527491679415107), (38, 0.03748492756858468), (23, 0.03758628200739622), (51, 0.04045407194644213), (24, 0.04271882213652134), (9, 0.04376391600817442), (6, 0.046942977234721184), (4, 0.04826149670407176), (14, 0.04837771411985159), (2, 0.05514534190297127), (3, 0.057753896340727806), (13, 0.06000342359766364), (11, 0.06034237099811435), (17, 0.06271189078688622), (0, 0.0635312544181943), (52, 0.06699719466269016), (1, 0.06707089953124523), (8, 0.07530375383794308), (10, 0.08162885159254074), (16, 0.08677668310701847), (12, 0.09114138968288898), (5, 0.1069697942584753), (36, 0.2794151343405247), (18, 0.5164264142513275), (53, 1.0835918188095093)]
computing accuracy for after removing block 49 . block score: 0.02566363546065986
removed block 49 current accuracy 0.8586 loss from initial  0.0928
since last training loss: 0.08439999999999992 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 40, with score 0.027044. All blocks and scores: [(40, 0.02704417030327022), (20, 0.02712428430095315), (15, 0.03229958191514015), (7, 0.03274057572707534), (19, 0.03286854410544038), (39, 0.03445068281143904), (21, 0.03457639925181866), (22, 0.03527491586282849), (38, 0.03748492617160082), (23, 0.03758628107607365), (51, 0.04210365982726216), (24, 0.0427188235335052), (9, 0.043763916939496994), (6, 0.046942976769059896), (4, 0.048261497635394335), (14, 0.048377713188529015), (2, 0.055145340505987406), (3, 0.05775389773771167), (13, 0.06000342406332493), (11, 0.06034237053245306), (17, 0.06271188892424107), (0, 0.06353125581517816), (1, 0.06707090232521296), (52, 0.07116757705807686), (8, 0.0753037529066205), (10, 0.08162885159254074), (16, 0.08677668683230877), (12, 0.09114138968288898), (5, 0.10696979518979788), (36, 0.2794151268899441), (18, 0.5164263993501663), (53, 1.230283871293068)]
computing accuracy for after removing block 40 . block score: 0.02704417030327022
removed block 40 current accuracy 0.808 loss from initial  0.14339999999999997
since last training loss: 0.1349999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.027124. All blocks and scores: [(20, 0.02712428499944508), (15, 0.03229958284646273), (7, 0.03274057572707534), (19, 0.032868544571101665), (39, 0.034450683277100325), (21, 0.03457639692351222), (22, 0.035274915397167206), (38, 0.037484926637262106), (23, 0.037586281541734934), (51, 0.039305121172219515), (24, 0.0427188235335052), (9, 0.04376391554251313), (6, 0.04694297630339861), (4, 0.04826149670407176), (14, 0.0483777136541903), (2, 0.055145342368632555), (3, 0.05775389773771167), (13, 0.060003424528986216), (11, 0.06034237099811435), (17, 0.06271188985556364), (0, 0.063531253952533), (1, 0.0670709004625678), (8, 0.0753037529066205), (52, 0.07618587929755449), (10, 0.08162885252386332), (16, 0.08677668683230877), (12, 0.09114138595759869), (5, 0.106969790533185), (36, 0.2794151231646538), (18, 0.5164264068007469), (53, 1.4017159789800644)]
computing accuracy for after removing block 20 . block score: 0.02712428499944508
removed block 20 current accuracy 0.7984 loss from initial  0.15300000000000002
since last training loss: 0.14459999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032300. All blocks and scores: [(15, 0.03229958238080144), (7, 0.032740576192736626), (19, 0.03286854503676295), (39, 0.03446703404188156), (22, 0.03470161557197571), (21, 0.03501716163009405), (23, 0.03592438157647848), (38, 0.03682557726278901), (51, 0.03831521840766072), (24, 0.04165168618783355), (9, 0.04376391647383571), (6, 0.04694297816604376), (4, 0.0482614953070879), (14, 0.04837771411985159), (2, 0.05514534190297127), (3, 0.057753898203372955), (13, 0.060003423132002354), (11, 0.06034237006679177), (17, 0.06271189032122493), (0, 0.06353125581517816), (1, 0.06707090139389038), (52, 0.07244978006929159), (8, 0.07530375383794308), (10, 0.08162885438650846), (16, 0.08677668496966362), (12, 0.09114138782024384), (5, 0.106969790533185), (36, 0.279144961386919), (18, 0.5164263993501663), (53, 1.3898851424455643)]
computing accuracy for after removing block 15 . block score: 0.03229958238080144
removed block 15 current accuracy 0.7866 loss from initial  0.16480000000000006
since last training loss: 0.15639999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.032464. All blocks and scores: [(22, 0.03246360784396529), (7, 0.03274057758972049), (19, 0.033126093447208405), (21, 0.03318179165944457), (23, 0.03423273377120495), (39, 0.03454435057938099), (38, 0.03702553501352668), (51, 0.03799545345827937), (24, 0.03948857681825757), (9, 0.04376391600817442), (6, 0.04694297770038247), (4, 0.04826149670407176), (14, 0.0483777136541903), (2, 0.055145342368632555), (3, 0.05775389913469553), (13, 0.060003426391631365), (11, 0.060342367738485336), (0, 0.06353125488385558), (17, 0.06665607541799545), (1, 0.06707090139389038), (52, 0.07220212370157242), (8, 0.07530375383794308), (10, 0.08162885252386332), (12, 0.09114138968288898), (16, 0.09701188281178474), (5, 0.10696979332715273), (36, 0.2752690315246582), (18, 0.5034824945032597), (53, 1.4069885164499283)]
computing accuracy for after removing block 22 . block score: 0.03246360784396529
removed block 22 current accuracy 0.73 loss from initial  0.22140000000000004
since last training loss: 0.21299999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.032741. All blocks and scores: [(7, 0.032740576192736626), (23, 0.0331174829043448), (19, 0.03312609391286969), (21, 0.03318179165944457), (39, 0.035155846271663904), (24, 0.03702485607936978), (51, 0.03702989453449845), (38, 0.03811303619295359), (9, 0.043763916939496994), (6, 0.046942976769059896), (4, 0.04826149623841047), (14, 0.048377714585512877), (2, 0.055145342368632555), (3, 0.05775389960035682), (13, 0.06000342406332493), (11, 0.060342369601130486), (0, 0.06353125208988786), (17, 0.06665607821196318), (1, 0.0670709004625678), (52, 0.07289352547377348), (8, 0.07530375476926565), (10, 0.08162885531783104), (12, 0.09114138782024384), (16, 0.09701188374310732), (5, 0.10696979146450758), (36, 0.2829812653362751), (18, 0.5034825056791306), (53, 1.3754992336034775)]
computing accuracy for after removing block 7 . block score: 0.032740576192736626
removed block 7 current accuracy 0.7034 loss from initial  0.248
training start
training epoch 0 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best True lr [0.1]
training epoch 1 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.1]
training epoch 2 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 3 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 4 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 5 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 6 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 7 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 8 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 9 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 10 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
