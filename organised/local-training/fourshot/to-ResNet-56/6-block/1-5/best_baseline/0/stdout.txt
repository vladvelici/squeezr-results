start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589383974671), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294661184772849), (29, 0.01342111686244607), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019996491726487875), (46, 0.020590225234627724), (25, 0.022078295471146703), (23, 0.02222871594130993), (41, 0.02233641571365297), (44, 0.02314599952660501), (40, 0.023749589920043945), (45, 0.02397549571469426), (21, 0.024941089330241084), (48, 0.024957706686109304), (22, 0.025151390582323074), (50, 0.025287173921242356), (24, 0.025880582630634308), (49, 0.025916649028658867), (42, 0.026232232805341482), (20, 0.026848891749978065), (47, 0.028632949106395245), (38, 0.03134434437379241), (39, 0.031441295286640525), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.0379180321469903), (51, 0.0417875861749053), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216303735971), (52, 0.06606104411184788), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.00939958926755935), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.013421117211692035), (26, 0.016072140773758292), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019852687837556005), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022977193351835012), (40, 0.0235738311894238), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.024770822608843446), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.025880581932142377), (42, 0.025893412297591567), (20, 0.026848891749978065), (47, 0.028072760673239827), (38, 0.03109118831343949), (39, 0.0311913606710732), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.061325255781412125), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43398061767220497), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.00939958926755935
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.012758882250636816), (29, 0.013421116513200104), (35, 0.015918421559035778), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022891478147357702), (40, 0.02360258041881025), (45, 0.02377085038460791), (48, 0.02451987355016172), (50, 0.024639350129291415), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025392550509423018), (42, 0.025712220231071115), (24, 0.02588058332912624), (20, 0.026848891749978065), (47, 0.028052504872903228), (38, 0.03093587514013052), (39, 0.031173035269603133), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992454573512), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.0613252529874444), (0, 0.06337464647367597), (52, 0.06441722856834531), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4350203089416027), (18, 0.5117432922124863), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400160310789943), (29, 0.013421116629615426), (35, 0.01591864926740527), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350347340107), (46, 0.02027974440716207), (41, 0.021756020840257406), (25, 0.022078294539824128), (23, 0.022228715009987354), (44, 0.023001376073807478), (40, 0.023739925818517804), (45, 0.02379016880877316), (48, 0.024350045947358012), (50, 0.024463105713948607), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.02527355100028217), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.02772757434286177), (38, 0.03074627509340644), (39, 0.03128179535269737), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.038952667731791735), (51, 0.04082479979842901), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464600801468), (52, 0.06356756202876568), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143978834152), (36, 0.4377693124115467), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232014857233), (29, 0.013421116746030748), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01983700809068978), (46, 0.020137187093496323), (41, 0.021584055852144957), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022687324788421392), (40, 0.02356909797526896), (45, 0.023840721230953932), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.025151390116661787), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.027423851657658815), (38, 0.03073564963415265), (39, 0.03141042357310653), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.0627010790631175), (0, 0.06337464367970824), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43692686408758163), (18, 0.5117432922124863), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.012506232014857233
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.020302683813497424), (46, 0.020324197132140398), (41, 0.021962703205645084), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.023045078618451953), (48, 0.024024546379223466), (50, 0.024096972309052944), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922373238950968), (21, 0.024941089330241084), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02756829489953816), (38, 0.03178726346231997), (15, 0.03205838520079851), (39, 0.03225791221484542), (7, 0.03244550200179219), (19, 0.03254077909514308), (51, 0.04008621396496892), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.061325255781412125), (52, 0.06221094774082303), (0, 0.06337464274838567), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.1067114407196641), (36, 0.44933702051639557), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.1]
training epoch 1 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.1]
training epoch 2 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.1]
training epoch 3 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.1]
training epoch 4 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 5 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.1]
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.1]
training epoch 7 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.1]
training epoch 8 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.1]
training epoch 9 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.1]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.012824. All blocks and scores: [(35, 0.012823601951822639), (39, 0.013938803225755692), (38, 0.014458397752605379), (28, 0.014944210881367326), (26, 0.016219988465309143), (27, 0.01905781147070229), (37, 0.01962417270988226), (43, 0.021536249201744795), (46, 0.02156939171254635), (25, 0.02226779470220208), (23, 0.022407824406400323), (41, 0.024286792613565922), (44, 0.0244911122135818), (45, 0.025052375392988324), (22, 0.025099133839830756), (21, 0.025143397971987724), (50, 0.025432210881263018), (48, 0.02581450273282826), (24, 0.026131546590477228), (49, 0.026295498944818974), (40, 0.02641414012759924), (20, 0.02702820487320423), (42, 0.027635085629299283), (47, 0.029470390873029828), (15, 0.032144945580512285), (7, 0.032583814579993486), (19, 0.032765403389930725), (51, 0.04173308378085494), (9, 0.043847480323165655), (6, 0.04663177207112312), (4, 0.047506865579634905), (14, 0.04773138836026192), (2, 0.05482978606596589), (3, 0.058492989744991064), (13, 0.059178976342082024), (11, 0.05937315197661519), (17, 0.06191607564687729), (0, 0.06373993773013353), (1, 0.06600095052272081), (52, 0.06676861643791199), (8, 0.07426613848656416), (10, 0.08089172467589378), (16, 0.08529183734208345), (12, 0.09004710614681244), (5, 0.10627995152026415), (36, 0.37436066195368767), (18, 0.5120247900485992), (53, 0.776205912232399)]
computing accuracy for after removing block 35 . block score: 0.012823601951822639
removed block 35 current accuracy 0.9436 loss from initial  0.007800000000000029
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 39, with score 0.013362. All blocks and scores: [(39, 0.013361786492168903), (38, 0.014203237369656563), (28, 0.014944210648536682), (26, 0.016219988465309143), (37, 0.0189167489297688), (27, 0.019057811237871647), (46, 0.020855632843449712), (43, 0.020865292055532336), (25, 0.022267795400694013), (23, 0.02240782417356968), (41, 0.02282526809722185), (50, 0.024162810295820236), (44, 0.02421255293302238), (45, 0.024470151169225574), (48, 0.024562559323385358), (22, 0.02509913290850818), (21, 0.025143397273495793), (40, 0.02532289386726916), (49, 0.025551677914336324), (24, 0.026131546823307872), (42, 0.026422514114528894), (20, 0.027028205804526806), (47, 0.02875048154965043), (15, 0.032144945580512285), (7, 0.032583816442638636), (19, 0.032765403389930725), (51, 0.0402716095559299), (9, 0.04384748078882694), (6, 0.04663177207112312), (4, 0.04750686418265104), (14, 0.047731386963278055), (2, 0.054829785600304604), (3, 0.05849298927932978), (13, 0.05917897913604975), (11, 0.05937315011397004), (17, 0.061916075181216), (52, 0.0632130685262382), (0, 0.06373993679881096), (1, 0.06600094959139824), (8, 0.07426614128053188), (10, 0.08089172467589378), (16, 0.08529184013605118), (12, 0.09004710428416729), (5, 0.1062799533829093), (36, 0.3662809431552887), (18, 0.512024812400341), (53, 0.8026010394096375)]
computing accuracy for after removing block 39 . block score: 0.013361786492168903
removed block 39 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 38, with score 0.014203. All blocks and scores: [(38, 0.014203236903995275), (28, 0.014944211463443935), (26, 0.0162199882324785), (37, 0.0189167489297688), (27, 0.019057811237871647), (43, 0.01947357435710728), (46, 0.020343576790764928), (41, 0.02160070976242423), (25, 0.02226779516786337), (23, 0.02240782417356968), (50, 0.02260957658290863), (48, 0.023173237685114145), (45, 0.02356734685599804), (44, 0.02389666484668851), (49, 0.024575502378866076), (40, 0.024865895742550492), (22, 0.025099133141338825), (21, 0.025143397273495793), (42, 0.025231843115761876), (24, 0.026131545891985297), (20, 0.02702820487320423), (47, 0.027797504793852568), (15, 0.032144945114851), (7, 0.03258381597697735), (19, 0.03276540385559201), (51, 0.039571298751980066), (9, 0.043847480323165655), (6, 0.0466317730024457), (4, 0.04750686325132847), (14, 0.047731385100632906), (2, 0.05482978280633688), (3, 0.0584929883480072), (13, 0.05917897680774331), (11, 0.059373151045292616), (52, 0.06107120122760534), (17, 0.061916076112538576), (0, 0.06373993679881096), (1, 0.06600095052272081), (8, 0.07426614128053188), (10, 0.08089172188192606), (16, 0.0852918392047286), (12, 0.09004710521548986), (5, 0.106279949657619), (36, 0.3662809431552887), (18, 0.5120248049497604), (53, 0.8395729586482048)]
computing accuracy for after removing block 38 . block score: 0.014203236903995275
removed block 38 current accuracy 0.9372 loss from initial  0.01419999999999999
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.014944. All blocks and scores: [(28, 0.014944211579859257), (26, 0.016219988465309143), (43, 0.018539053853601217), (37, 0.018916749861091375), (27, 0.01905781147070229), (46, 0.019627233734354377), (41, 0.02050654008053243), (50, 0.021192098734900355), (48, 0.02158338134177029), (25, 0.022267795400694013), (45, 0.022384354379028082), (23, 0.022407824406400323), (44, 0.02320541115477681), (49, 0.023624329129233956), (42, 0.024019527016207576), (22, 0.02509913337416947), (40, 0.025127826258540154), (21, 0.025143397971987724), (24, 0.026131546823307872), (47, 0.026340562384575605), (20, 0.02702820487320423), (15, 0.03214494697749615), (7, 0.03258381551131606), (19, 0.03276540292426944), (51, 0.03894123900681734), (9, 0.04384747985750437), (6, 0.0466317730024457), (4, 0.04750686511397362), (14, 0.047731388825923204), (2, 0.054829783737659454), (52, 0.05733573483303189), (3, 0.058492987882345915), (13, 0.0591789772734046), (11, 0.05937315057963133), (17, 0.061916075181216), (0, 0.06373993586748838), (1, 0.06600095052272081), (8, 0.07426614221185446), (10, 0.08089172467589378), (16, 0.08529183827340603), (12, 0.09004710614681244), (5, 0.10627994872629642), (36, 0.3662809431552887), (18, 0.5120248049497604), (53, 0.863484337925911)]
computing accuracy for after removing block 28 . block score: 0.014944211579859257
removed block 28 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.016220. All blocks and scores: [(26, 0.01621998753398657), (27, 0.019057811703532934), (43, 0.019277499988675117), (46, 0.019608692498877645), (37, 0.020165513269603252), (41, 0.02102227183058858), (50, 0.021403691032901406), (48, 0.02206137077882886), (25, 0.022267795400694013), (23, 0.022407824406400323), (45, 0.0224612383171916), (44, 0.02354596834629774), (49, 0.023663654224947095), (42, 0.024461978347972035), (22, 0.025099133607000113), (21, 0.025143397273495793), (40, 0.025410497095435858), (47, 0.025936029385775328), (24, 0.026131546590477228), (20, 0.02702820533886552), (15, 0.032144945114851), (7, 0.03258381597697735), (19, 0.03276540385559201), (51, 0.03929846175014973), (9, 0.04384747985750437), (6, 0.046631771605461836), (4, 0.047506865579634905), (14, 0.047731388825923204), (2, 0.054829783737659454), (52, 0.05764205986633897), (3, 0.05849298927932978), (13, 0.05917897680774331), (11, 0.059373151045292616), (17, 0.061916075181216), (0, 0.06373993773013353), (1, 0.06600095145404339), (8, 0.07426613941788673), (10, 0.08089172467589378), (16, 0.0852918392047286), (12, 0.09004710335284472), (5, 0.106279949657619), (36, 0.3801388293504715), (18, 0.5120247900485992), (53, 0.8721831068396568)]
computing accuracy for after removing block 26 . block score: 0.01621998753398657
removed block 26 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018801. All blocks and scores: [(27, 0.018800909630954266), (43, 0.01885813008993864), (46, 0.019210016820579767), (37, 0.01969162584282458), (41, 0.020210018614307046), (50, 0.02077605645172298), (48, 0.021383431972935796), (45, 0.022110212361440063), (25, 0.022267795400694013), (23, 0.02240782417356968), (44, 0.023314177989959717), (49, 0.023348685819655657), (42, 0.023470331449061632), (40, 0.02471270994283259), (22, 0.02509913290850818), (21, 0.02514339773915708), (47, 0.025366087211295962), (24, 0.026131545659154654), (20, 0.02702820487320423), (15, 0.03214494604617357), (7, 0.03258381551131606), (19, 0.03276540292426944), (51, 0.037806044798344374), (9, 0.04384747939184308), (6, 0.0466317730024457), (4, 0.04750686418265104), (14, 0.047731386963278055), (2, 0.05482978653162718), (52, 0.05532773770391941), (3, 0.058492987882345915), (13, 0.05917897867038846), (11, 0.05937315057963133), (17, 0.061916076112538576), (0, 0.06373993679881096), (1, 0.06600095238536596), (8, 0.07426614221185446), (10, 0.08089172467589378), (16, 0.0852918354794383), (12, 0.09004710521548986), (5, 0.106279949657619), (36, 0.3717413581907749), (18, 0.5120248049497604), (53, 0.8985825926065445)]
computing accuracy for after removing block 27 . block score: 0.018800909630954266
removed block 27 current accuracy 0.9206 loss from initial  0.03080000000000005
training start
training epoch 0 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 1 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 2 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.1]
training epoch 3 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.1]
training epoch 4 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.1]
training epoch 5 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.1]
training epoch 6 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.1]
training epoch 7 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.1]
training epoch 8 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.1]
training epoch 9 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.014324. All blocks and scores: [(43, 0.014323848183266819), (42, 0.016396556748077273), (41, 0.016866232501342893), (44, 0.017183985095471144), (23, 0.022565077990293503), (40, 0.022930101258680224), (46, 0.024040238233283162), (21, 0.024951156694442034), (22, 0.025166750885546207), (24, 0.02607618668116629), (50, 0.026309228967875242), (49, 0.027006427757441998), (20, 0.027034432627260685), (48, 0.027981317369267344), (45, 0.02898532128892839), (47, 0.03161990107037127), (15, 0.032065693754702806), (19, 0.0325883524492383), (7, 0.032632991671562195), (37, 0.0387133420445025), (51, 0.04178965510800481), (9, 0.0438704714179039), (6, 0.04684844519942999), (4, 0.047669910825788975), (14, 0.048073300160467625), (25, 0.050061124842613935), (2, 0.05481752660125494), (3, 0.058141200337558985), (13, 0.05922745820134878), (11, 0.05986486608162522), (17, 0.0614293678663671), (0, 0.06394289620220661), (1, 0.06599481124430895), (52, 0.06693070102483034), (8, 0.07485313341021538), (10, 0.08132641110569239), (16, 0.08522709924727678), (12, 0.09092839527875185), (5, 0.10666284803301096), (36, 0.46748415008187294), (18, 0.5137306302785873), (53, 0.8036496937274933)]
computing accuracy for after removing block 43 . block score: 0.014323848183266819
removed block 43 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.016397. All blocks and scores: [(42, 0.016396556748077273), (41, 0.016866232501342893), (44, 0.018382819136604667), (23, 0.02256507845595479), (40, 0.022930100560188293), (46, 0.02492863335646689), (21, 0.02495115716010332), (22, 0.02516675111837685), (50, 0.026003808714449406), (24, 0.026076187379658222), (49, 0.026316442526876926), (20, 0.02703443355858326), (48, 0.02855443861335516), (45, 0.029934848193079233), (47, 0.03205756237730384), (15, 0.03206569328904152), (19, 0.03258835198357701), (7, 0.03263299120590091), (37, 0.0387133420445025), (51, 0.04154703253880143), (9, 0.0438704714179039), (6, 0.04684844706207514), (4, 0.0476699098944664), (14, 0.04807330155745149), (25, 0.05006112437695265), (2, 0.05481752660125494), (3, 0.05814120173454285), (13, 0.05922745866701007), (11, 0.05986486515030265), (17, 0.06142936646938324), (0, 0.06394289527088404), (1, 0.0659948131069541), (52, 0.0671461159363389), (8, 0.0748531324788928), (10, 0.08132641296833754), (16, 0.08522709924727678), (12, 0.09092839621007442), (5, 0.10666284710168839), (36, 0.46748413890600204), (18, 0.5137306228280067), (53, 0.8239750936627388)]
computing accuracy for after removing block 42 . block score: 0.016396556748077273
removed block 42 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 41, with score 0.016866. All blocks and scores: [(41, 0.016866232501342893), (44, 0.01898435759358108), (23, 0.022565078688785434), (40, 0.02293009962886572), (21, 0.02495115716010332), (22, 0.02516675111837685), (50, 0.025657700141891837), (46, 0.025661066872999072), (24, 0.02607618784531951), (49, 0.026339776813983917), (20, 0.027034433092921972), (48, 0.02819018135778606), (45, 0.030480566434562206), (15, 0.032065693754702806), (47, 0.03240298852324486), (19, 0.03258835198357701), (7, 0.03263299074023962), (37, 0.03871334111317992), (51, 0.04107952956110239), (9, 0.0438704714179039), (6, 0.04684844659641385), (4, 0.04766990942880511), (14, 0.04807330062612891), (25, 0.050061122979968786), (2, 0.05481752846390009), (3, 0.05814120173454285), (13, 0.05922746006399393), (11, 0.059864864218980074), (17, 0.06142936646938324), (0, 0.06394289433956146), (1, 0.06599481217563152), (52, 0.0665401890873909), (8, 0.07485313434153795), (10, 0.08132641483098269), (16, 0.08522709924727678), (12, 0.09092839621007442), (5, 0.10666284337639809), (36, 0.46748413518071175), (18, 0.5137306153774261), (53, 0.8443690612912178)]
computing accuracy for after removing block 41 . block score: 0.016866232501342893
removed block 41 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.019581. All blocks and scores: [(44, 0.01958076609298587), (23, 0.022565078223124146), (40, 0.022930099861696362), (21, 0.024951157392933965), (22, 0.025166751351207495), (50, 0.025514405919238925), (46, 0.02561981067992747), (24, 0.026076186448335648), (49, 0.02663352247327566), (20, 0.027034433092921972), (48, 0.02797309565357864), (45, 0.031025978736579418), (15, 0.032065694220364094), (19, 0.03258835291489959), (47, 0.03259533457458019), (7, 0.03263299120590091), (37, 0.03871334157884121), (51, 0.04018966155126691), (9, 0.043870472349226475), (6, 0.04684844519942999), (4, 0.0476699098944664), (14, 0.04807329969480634), (25, 0.050061124842613935), (2, 0.05481752986088395), (3, 0.058141200337558985), (13, 0.059227459132671356), (11, 0.05986486468464136), (17, 0.06142936646938324), (0, 0.06394289620220661), (1, 0.06599481217563152), (52, 0.06633558683097363), (8, 0.0748531324788928), (10, 0.08132641483098269), (16, 0.08522710017859936), (12, 0.09092839527875185), (5, 0.10666284896433353), (36, 0.46748414635658264), (18, 0.5137306451797485), (53, 0.8966262191534042)]
computing accuracy for after removing block 44 . block score: 0.01958076609298587
removed block 44 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.022565. All blocks and scores: [(23, 0.022565078688785434), (40, 0.022930100560188293), (21, 0.024951156927272677), (22, 0.02516675111837685), (50, 0.0252716694958508), (49, 0.025710856076329947), (24, 0.02607618714682758), (46, 0.02617164421826601), (20, 0.027034432627260685), (48, 0.02716256584972143), (45, 0.03134871879592538), (15, 0.032065694220364094), (19, 0.0325883524492383), (7, 0.03263299120590091), (47, 0.03304349631071091), (37, 0.03871334111317992), (51, 0.03948491532355547), (9, 0.043870472349226475), (6, 0.046848446130752563), (4, 0.04766991036012769), (14, 0.048073302023112774), (25, 0.050061122979968786), (2, 0.05481752892956138), (3, 0.05814120173454285), (13, 0.05922745680436492), (11, 0.05986486375331879), (17, 0.06142936833202839), (0, 0.06394289433956146), (1, 0.0659948131069541), (52, 0.06623374298214912), (8, 0.07485313154757023), (10, 0.08132641483098269), (16, 0.08522710017859936), (12, 0.09092839527875185), (5, 0.10666284430772066), (36, 0.46748415008187294), (18, 0.5137306451797485), (53, 0.9316603913903236)]
computing accuracy for after removing block 23 . block score: 0.022565078688785434
removed block 23 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.022379. All blocks and scores: [(40, 0.022378627909347415), (50, 0.024444334907457232), (24, 0.024700804613530636), (21, 0.024951156694442034), (22, 0.025166750187054276), (49, 0.02533459127880633), (46, 0.02552369562909007), (48, 0.026338397292420268), (20, 0.027034434024244547), (45, 0.031213821843266487), (47, 0.0318763698451221), (15, 0.032065693754702806), (19, 0.032588353380560875), (7, 0.03263299074023962), (51, 0.03877947898581624), (37, 0.03937648423016071), (9, 0.04387047328054905), (6, 0.04684844659641385), (4, 0.04766991129145026), (14, 0.04807330062612891), (25, 0.04939463548362255), (2, 0.05481752706691623), (3, 0.05814120313152671), (13, 0.05922745866701007), (11, 0.0598648632876575), (17, 0.0614293678663671), (52, 0.06319007789716125), (0, 0.06394289527088404), (1, 0.06599481403827667), (8, 0.07485313434153795), (10, 0.08132641296833754), (16, 0.08522710110992193), (12, 0.090928397141397), (5, 0.10666284337639809), (36, 0.46352580562233925), (18, 0.5137306302785873), (53, 0.9462161213159561)]
computing accuracy for after removing block 40 . block score: 0.022378627909347415
removed block 40 current accuracy 0.9134 loss from initial  0.038000000000000034
training start
training epoch 0 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 1 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 2 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 3 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.1]
training epoch 4 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.1]
training epoch 5 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.1]
training epoch 6 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.1]
training epoch 7 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 8 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 9 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.941400)
finished training. finished 50 epochs. accuracy 0.9414 topk_dict {'top1': 0.9414}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.022326. All blocks and scores: [(49, 0.022325858008116484), (48, 0.023056749487295747), (21, 0.024937598034739494), (20, 0.027215359266847372), (50, 0.0293390357401222), (46, 0.03146215411834419), (15, 0.03212791169062257), (7, 0.0324123278260231), (19, 0.0328049473464489), (47, 0.03419132810086012), (45, 0.03742861747741699), (22, 0.038241416215896606), (24, 0.04089047061279416), (9, 0.04371962742879987), (51, 0.044373754411935806), (6, 0.0466431574895978), (14, 0.04795276187360287), (4, 0.048345457296818495), (2, 0.05480842664837837), (3, 0.057835294399410486), (13, 0.05961953615769744), (11, 0.05980373499915004), (17, 0.062132049817591906), (0, 0.06302357511594892), (1, 0.06554997060447931), (52, 0.06933914497494698), (25, 0.0736253671348095), (8, 0.07412871345877647), (37, 0.0807832470163703), (10, 0.08094530645757914), (16, 0.08559629134833813), (12, 0.0904476922005415), (5, 0.10614266991615295), (18, 0.5121156424283981), (36, 0.5519074723124504), (53, 0.812884233891964)]
computing accuracy for after removing block 49 . block score: 0.022325858008116484
removed block 49 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 48, with score 0.023057. All blocks and scores: [(48, 0.023056749254465103), (21, 0.024937597569078207), (20, 0.027215359266847372), (50, 0.031277531292289495), (46, 0.03146215551532805), (15, 0.032127912156283855), (7, 0.032412328757345676), (19, 0.0328049473464489), (47, 0.034191328566521406), (45, 0.037428617011755705), (22, 0.038241416681557894), (24, 0.040890470147132874), (9, 0.04371962742879987), (51, 0.046314352191984653), (6, 0.04664315842092037), (14, 0.04795276327058673), (4, 0.04834545776247978), (2, 0.05480842664837837), (3, 0.05783529207110405), (13, 0.059619536623358727), (11, 0.059803737327456474), (17, 0.062132051680237055), (0, 0.06302357511594892), (1, 0.06554997246712446), (52, 0.0732421800494194), (25, 0.07362536434084177), (8, 0.07412871439009905), (37, 0.0807832470163703), (10, 0.08094530645757914), (16, 0.08559629041701555), (12, 0.09044769313186407), (5, 0.10614266991615295), (18, 0.5121156349778175), (36, 0.5519074872136116), (53, 0.8431972041726112)]
computing accuracy for after removing block 48 . block score: 0.023056749254465103
removed block 48 current accuracy 0.9178 loss from initial  0.033600000000000074
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.024938. All blocks and scores: [(21, 0.02493759850040078), (20, 0.02721535903401673), (46, 0.03146215435117483), (15, 0.03212791169062257), (7, 0.03241232689470053), (19, 0.0328049473464489), (47, 0.03419132810086012), (50, 0.035010692197829485), (45, 0.037428617011755705), (22, 0.038241416681557894), (24, 0.040890469681471586), (9, 0.043719626031816006), (51, 0.0463540805503726), (6, 0.04664316074922681), (14, 0.04795276280492544), (4, 0.04834545822814107), (2, 0.05480842757970095), (3, 0.05783529207110405), (13, 0.05961953802034259), (11, 0.05980373825877905), (17, 0.062132053542882204), (0, 0.06302357465028763), (1, 0.06554997060447931), (25, 0.07362536620348692), (8, 0.07412871439009905), (52, 0.07947283517569304), (37, 0.08078324981033802), (10, 0.08094530552625656), (16, 0.0855962922796607), (12, 0.09044769406318665), (5, 0.1061426717787981), (18, 0.5121156498789787), (36, 0.5519074872136116), (53, 0.8999152630567551)]
computing accuracy for after removing block 21 . block score: 0.02493759850040078
removed block 21 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 20, with score 0.027215. All blocks and scores: [(20, 0.027215360198169947), (46, 0.028892608592286706), (15, 0.03212791308760643), (47, 0.03222833713516593), (50, 0.03227280080318451), (7, 0.032412327360361814), (19, 0.03280494827777147), (22, 0.03542402293533087), (24, 0.036072706803679466), (45, 0.03610504465177655), (9, 0.04371962742879987), (51, 0.043970237486064434), (6, 0.046643157955259085), (14, 0.04795276187360287), (4, 0.048345457296818495), (2, 0.054808428045362234), (3, 0.057835293002426624), (13, 0.0596195375546813), (11, 0.059803735464811325), (17, 0.06213205447420478), (0, 0.0630235718563199), (1, 0.06554996874183416), (52, 0.06819442380219698), (25, 0.06944555975496769), (8, 0.07412871345877647), (37, 0.0764625957235694), (10, 0.08094530645757914), (16, 0.08559628948569298), (12, 0.09044769126921892), (5, 0.10614266712218523), (18, 0.5121156573295593), (36, 0.5195344910025597), (53, 0.9662447720766068)]
computing accuracy for after removing block 20 . block score: 0.027215360198169947
removed block 20 current accuracy 0.9036 loss from initial  0.047800000000000065
since last training loss: 0.037800000000000056 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.027916. All blocks and scores: [(46, 0.027916359715163708), (47, 0.030647421954199672), (50, 0.03101322054862976), (15, 0.03212791169062257), (7, 0.03241232829168439), (19, 0.03280494827777147), (24, 0.03413160517811775), (22, 0.034427126403898), (45, 0.03570569399744272), (51, 0.04238284332677722), (9, 0.043719626031816006), (6, 0.04664315888658166), (14, 0.047952763736248016), (4, 0.04834545589983463), (2, 0.05480842897668481), (3, 0.05783529253676534), (13, 0.059619537089020014), (11, 0.059803737327456474), (17, 0.06213205261155963), (0, 0.06302357418462634), (52, 0.06348710181191564), (1, 0.06554997153580189), (25, 0.0670675802975893), (8, 0.07412871345877647), (37, 0.07704878132790327), (10, 0.08094530459493399), (16, 0.0855962885543704), (12, 0.09044769313186407), (5, 0.10614266991615295), (18, 0.5121156424283981), (36, 0.5154982581734657), (53, 0.9727799594402313)]
computing accuracy for after removing block 46 . block score: 0.027916359715163708
removed block 46 current accuracy 0.8892 loss from initial  0.06220000000000003
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.031658. All blocks and scores: [(50, 0.03165814536623657), (15, 0.03212791169062257), (7, 0.0324123278260231), (19, 0.032804947812110186), (47, 0.03380347741767764), (24, 0.03413160610944033), (22, 0.034427127335220575), (45, 0.03570569399744272), (51, 0.042622370179742575), (9, 0.04371962649747729), (6, 0.046643157955259085), (14, 0.047952763736248016), (4, 0.048345457296818495), (2, 0.05480842664837837), (3, 0.057835293002426624), (13, 0.05961953802034259), (11, 0.059803737327456474), (17, 0.06213205121457577), (0, 0.06302357511594892), (52, 0.06400637701153755), (1, 0.06554997153580189), (25, 0.06706757936626673), (8, 0.0741287125274539), (37, 0.07704878225922585), (10, 0.08094530366361141), (16, 0.0855962885543704), (12, 0.09044768940657377), (5, 0.10614266991615295), (18, 0.5121156424283981), (36, 0.5154982581734657), (53, 1.0785217881202698)]
computing accuracy for after removing block 50 . block score: 0.03165814536623657
removed block 50 current accuracy 0.8466 loss from initial  0.1048
since last training loss: 0.0948 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032128. All blocks and scores: [(15, 0.03212791122496128), (7, 0.032412327360361814), (19, 0.03280494827777147), (47, 0.03380347741767764), (24, 0.03413160517811775), (22, 0.03442712593823671), (45, 0.03570569399744272), (9, 0.04371962649747729), (6, 0.046643157955259085), (51, 0.04786042356863618), (14, 0.04795276140794158), (4, 0.04834545776247978), (2, 0.05480842757970095), (3, 0.057835294865071774), (13, 0.059619538486003876), (11, 0.059803737327456474), (17, 0.06213205214589834), (0, 0.06302357697859406), (1, 0.06554997246712446), (25, 0.06706757843494415), (8, 0.0741287162527442), (37, 0.077048784121871), (52, 0.07778801303356886), (10, 0.08094530366361141), (16, 0.08559629041701555), (12, 0.09044769313186407), (5, 0.10614266619086266), (18, 0.5121156573295593), (36, 0.5154982656240463), (53, 1.2304670065641403)]
computing accuracy for after removing block 15 . block score: 0.03212791122496128
removed block 15 current accuracy 0.8246 loss from initial  0.12680000000000002
since last training loss: 0.11680000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.032024. All blocks and scores: [(24, 0.03202440030872822), (7, 0.0324123278260231), (22, 0.03298962954431772), (19, 0.03307931963354349), (47, 0.03445994947105646), (45, 0.03580076573416591), (9, 0.04371962649747729), (6, 0.0466431574895978), (14, 0.047952764201909304), (51, 0.04823677055537701), (4, 0.048345457296818495), (2, 0.05480842711403966), (3, 0.05783529253676534), (13, 0.059619536623358727), (11, 0.05980373779311776), (0, 0.06302357278764248), (25, 0.06496284808963537), (1, 0.06554997153580189), (17, 0.06595400348305702), (8, 0.07412871532142162), (37, 0.07682867348194122), (52, 0.07915181294083595), (10, 0.08094530459493399), (12, 0.09044769313186407), (16, 0.0955240624025464), (5, 0.1061426680535078), (18, 0.4994092173874378), (36, 0.511583223938942), (53, 1.2552624642848969)]
computing accuracy for after removing block 24 . block score: 0.03202440030872822
removed block 24 current accuracy 0.798 loss from initial  0.15339999999999998
since last training loss: 0.14339999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.032412. All blocks and scores: [(7, 0.03241232968866825), (22, 0.03298963000997901), (19, 0.03307931823655963), (47, 0.03451376873999834), (45, 0.03585675451904535), (9, 0.043719626031816006), (6, 0.0466431574895978), (51, 0.04682668810710311), (14, 0.047952763736248016), (4, 0.048345457296818495), (2, 0.05480842664837837), (3, 0.057835293002426624), (13, 0.05961953615769744), (11, 0.05980373593047261), (0, 0.06302357511594892), (25, 0.065048698335886), (1, 0.06554997246712446), (17, 0.06595400627702475), (8, 0.07412871532142162), (37, 0.07878601737320423), (52, 0.07919923961162567), (10, 0.08094530459493399), (12, 0.09044769126921892), (16, 0.09552406426519156), (5, 0.10614266991615295), (18, 0.49940919876098633), (36, 0.5190104246139526), (53, 1.285775512456894)]
computing accuracy for after removing block 7 . block score: 0.03241232968866825
removed block 7 current accuracy 0.7784 loss from initial  0.17300000000000004
training start
training epoch 0 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best True lr [0.1]
training epoch 1 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best True lr [0.1]
training epoch 2 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 3 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 4 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.1]
training epoch 5 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 6 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 7 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.1]
training epoch 8 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.1]
training epoch 9 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
