start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589733220637), (30, 0.01001118787098676), (31, 0.010232581058517098), (34, 0.013294661068357527), (29, 0.013421116978861392), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.01763686048798263), (27, 0.019022798165678978), (43, 0.01999649265781045), (46, 0.020590224768966436), (25, 0.022078295005485415), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.023145999293774366), (40, 0.023749590385705233), (45, 0.023975494783371687), (21, 0.024941088864579797), (48, 0.024957706220448017), (22, 0.025151390815153718), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916648795828223), (42, 0.026232231641188264), (20, 0.02684889268130064), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129575230181), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540780026465654), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740696147084), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700032230466604), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.4361986480653286), (18, 0.5117432996630669), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187987402081), (31, 0.01023258117493242), (34, 0.0131192437838763), (29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852686673402786), (46, 0.020300705451518297), (41, 0.021860275650396943), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02297719265334308), (40, 0.02357383049093187), (45, 0.023648237576708198), (48, 0.0245402161963284), (50, 0.024770823074504733), (21, 0.02494109026156366), (22, 0.02515139104798436), (49, 0.025575740495696664), (24, 0.02588058286346495), (42, 0.025893412763252854), (20, 0.02684889268130064), (47, 0.028072759741917253), (38, 0.03109118831343949), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03797321207821369), (51, 0.04127101320773363), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351701647043), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537981152534), (5, 0.1067114369943738), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.013421116978861392), (35, 0.01591842179186642), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464770570397), (46, 0.020411916309967637), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022891478845849633), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873317331076), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151389883831143), (49, 0.025392549578100443), (42, 0.025712220929563046), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02805250510573387), (38, 0.0309358739759773), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077956080437), (37, 0.038343189749866724), (51, 0.04113080771639943), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740603014827), (3, 0.057849929202347994), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464554235339), (52, 0.06441723043099046), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4350203089416027), (18, 0.5117432922124863), (53, 0.8136166930198669)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159728713334), (29, 0.013421117095276713), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022798631340265), (43, 0.019867350347340107), (46, 0.020279744872823358), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.023001376539468765), (40, 0.023739926051348448), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.024463105713948607), (21, 0.024941089563071728), (22, 0.025151389883831143), (49, 0.02524692937731743), (42, 0.025273551465943456), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.027727574575692415), (38, 0.030746274860575795), (39, 0.03128179511986673), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632656097412), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.01342111686244607), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.02013718755915761), (41, 0.02158405538648367), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.023840720998123288), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.024941089330241084), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.027423852356150746), (38, 0.03073564963415265), (39, 0.031410424038767815), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.04034593980759382), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.0613252529874444), (52, 0.06270107859745622), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43692684918642044), (18, 0.5117432847619057), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.02030268358066678), (46, 0.020324198296293616), (41, 0.02196270367130637), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02304507838562131), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.024168408708646894), (49, 0.024922373238950968), (21, 0.024941089330241084), (22, 0.02515139034949243), (42, 0.025816060369834304), (24, 0.02588058286346495), (20, 0.026848891051486135), (47, 0.027568295132368803), (38, 0.03178726346231997), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073172286153), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702424168587), (18, 0.5117432996630669), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 1 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.1]
training epoch 2 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.1]
training epoch 3 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.1]
training epoch 4 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 5 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.1]
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.1]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.1]
training epoch 8 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 9 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.1]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.010701. All blocks and scores: [(26, 0.010701481252908707), (35, 0.011530486051924527), (28, 0.01272646407596767), (27, 0.014574576867744327), (37, 0.016646341886371374), (43, 0.020593227818608284), (46, 0.02065542316995561), (25, 0.02205051272176206), (23, 0.022382405819371343), (41, 0.022873911540955305), (44, 0.02336583868600428), (45, 0.02366838720627129), (50, 0.024324314668774605), (40, 0.024522698717191815), (48, 0.02453188505023718), (21, 0.024859493132680655), (49, 0.024992972379550338), (22, 0.025054546538740396), (24, 0.025752114364877343), (42, 0.026251084869727492), (20, 0.027163890190422535), (47, 0.02815795294009149), (15, 0.03206307673826814), (7, 0.03241951856762171), (19, 0.032529876101762056), (39, 0.03299119556322694), (38, 0.03376419469714165), (51, 0.04139792127534747), (9, 0.043598472606390715), (6, 0.0464042485691607), (14, 0.04790577385574579), (4, 0.0483240713365376), (2, 0.05449478607624769), (3, 0.0581298372708261), (13, 0.059506483376026154), (11, 0.05975696677342057), (17, 0.06245184922590852), (0, 0.06420428678393364), (52, 0.06505755102261901), (1, 0.06654218956828117), (8, 0.0747555922716856), (10, 0.08099566958844662), (16, 0.08513358701020479), (12, 0.09043543320149183), (5, 0.10664597619324923), (36, 0.35294968634843826), (18, 0.5118408501148224), (53, 0.8003399521112442)]
computing accuracy for after removing block 26 . block score: 0.010701481252908707
removed block 26 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.011201. All blocks and scores: [(35, 0.011201306711882353), (28, 0.012808791361749172), (27, 0.014854798442684114), (37, 0.016643787967041135), (46, 0.02036815765313804), (43, 0.020600215066224337), (25, 0.02205051272176206), (23, 0.022382405819371343), (41, 0.022472209995612502), (44, 0.023491828935220838), (45, 0.02373105986043811), (50, 0.024090195074677467), (40, 0.024309146450832486), (48, 0.024510570568963885), (21, 0.02485949220135808), (49, 0.02493733959272504), (22, 0.025054547237232327), (42, 0.025235371431335807), (24, 0.0257521141320467), (20, 0.027163889491930604), (47, 0.02791537973098457), (15, 0.03206307766959071), (7, 0.03241951810196042), (19, 0.032529876101762056), (39, 0.03310401737689972), (38, 0.03345814719796181), (51, 0.040772068314254284), (9, 0.04359847120940685), (6, 0.04640424810349941), (14, 0.04790577385574579), (4, 0.04832407319918275), (2, 0.05449478700757027), (3, 0.058129838202148676), (13, 0.05950648384168744), (11, 0.059756969567388296), (17, 0.06245184829458594), (52, 0.06393417995423079), (0, 0.06420428398996592), (1, 0.06654219049960375), (8, 0.07475559320300817), (10, 0.08099566958844662), (16, 0.08513358701020479), (12, 0.09043543040752411), (5, 0.10664597805589437), (36, 0.35364942997694016), (18, 0.511840857565403), (53, 0.8124345913529396)]
computing accuracy for after removing block 35 . block score: 0.011201306711882353
removed block 35 current accuracy 0.94 loss from initial  0.011400000000000077
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012809. All blocks and scores: [(28, 0.01280879124533385), (27, 0.014854798093438148), (37, 0.01583110960200429), (46, 0.019276045262813568), (43, 0.019675620831549168), (41, 0.02067365776747465), (25, 0.02205051272176206), (23, 0.022382405819371343), (50, 0.022651298670098186), (45, 0.02276650513522327), (48, 0.02286211820319295), (44, 0.023056202102452517), (40, 0.0232374828774482), (42, 0.02348310872912407), (49, 0.023742277873679996), (21, 0.024859493132680655), (22, 0.025054546538740396), (24, 0.02575211483053863), (47, 0.0266064559109509), (20, 0.02716388856060803), (39, 0.031114053213968873), (38, 0.031666775699704885), (15, 0.03206307766959071), (7, 0.032419517170637846), (19, 0.03252987703308463), (51, 0.038604323752224445), (9, 0.043598470743745565), (6, 0.04640425043180585), (14, 0.04790577385574579), (4, 0.04832407319918275), (2, 0.0544947893358767), (3, 0.0581298372708261), (52, 0.05944986129179597), (13, 0.059506483376026154), (11, 0.059756968170404434), (17, 0.06245185201987624), (0, 0.06420428492128849), (1, 0.0665421886369586), (8, 0.07475559134036303), (10, 0.08099567051976919), (16, 0.08513358514755964), (12, 0.09043543133884668), (5, 0.10664597433060408), (36, 0.3439944237470627), (18, 0.5118408501148224), (53, 0.845766544342041)]
computing accuracy for after removing block 28 . block score: 0.01280879124533385
removed block 28 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 27, with score 0.014855. All blocks and scores: [(27, 0.014854798442684114), (37, 0.01608270569704473), (46, 0.019175733905285597), (43, 0.020109837176278234), (41, 0.02111435728147626), (25, 0.022050512488931417), (23, 0.022382406052201986), (50, 0.022433388978242874), (45, 0.02273196936585009), (48, 0.022852531168609858), (40, 0.023203734774142504), (44, 0.023317887680605054), (49, 0.023339991690590978), (42, 0.023778194561600685), (21, 0.02485949289985001), (22, 0.025054547237232327), (24, 0.025752113899216056), (47, 0.026110766222700477), (20, 0.027163889724761248), (39, 0.03152552689425647), (15, 0.032063077203929424), (38, 0.032101883087307215), (7, 0.032419519033282995), (19, 0.032529876567423344), (51, 0.03875955520197749), (9, 0.04359847214072943), (6, 0.04640424903482199), (14, 0.04790577106177807), (4, 0.048324072267860174), (2, 0.05449478700757027), (3, 0.05812983773648739), (13, 0.059506482910364866), (52, 0.05975641356781125), (11, 0.059756968170404434), (17, 0.06245185015723109), (0, 0.06420428398996592), (1, 0.06654218956828117), (8, 0.07475559506565332), (10, 0.08099566865712404), (16, 0.08513358607888222), (12, 0.09043543133884668), (5, 0.1066459771245718), (36, 0.3518935777246952), (18, 0.5118408501148224), (53, 0.8521927073597908)]
computing accuracy for after removing block 27 . block score: 0.014854798442684114
removed block 27 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 37, with score 0.016240. All blocks and scores: [(37, 0.01624042959883809), (46, 0.018877705559134483), (43, 0.020401432644575834), (41, 0.02103924914263189), (50, 0.022008115658536553), (25, 0.02205051272176206), (23, 0.022382405353710055), (48, 0.02247622120194137), (45, 0.022606882033869624), (40, 0.02287211106158793), (49, 0.022960881935432553), (44, 0.02320108236745), (42, 0.023625585483387113), (21, 0.02485949289985001), (22, 0.02505454677157104), (47, 0.02534589567221701), (24, 0.025752114364877343), (20, 0.027163889026269317), (39, 0.03144442103803158), (15, 0.03206307580694556), (38, 0.032176331616938114), (7, 0.032419519033282995), (19, 0.032529876101762056), (51, 0.03799503389745951), (9, 0.04359847120940685), (6, 0.046404249500483274), (14, 0.04790577292442322), (4, 0.048324072267860174), (2, 0.054494787473231554), (3, 0.058129836805164814), (52, 0.05823447369039059), (13, 0.05950648384168744), (11, 0.05975696770474315), (17, 0.062451849691569805), (0, 0.06420428678393364), (1, 0.06654219049960375), (8, 0.0747555922716856), (10, 0.08099566772580147), (16, 0.08513358421623707), (12, 0.09043543133884668), (5, 0.10664597619324923), (36, 0.3564477786421776), (18, 0.5118408501148224), (53, 0.8621751517057419)]
computing accuracy for after removing block 37 . block score: 0.01624042959883809
removed block 37 current accuracy 0.9266 loss from initial  0.024800000000000044
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.017050. All blocks and scores: [(46, 0.017050422728061676), (41, 0.01896147569641471), (43, 0.019076041877269745), (50, 0.01933455071412027), (48, 0.020114060025662184), (49, 0.020542227430269122), (45, 0.020669508259743452), (44, 0.021032329881563783), (40, 0.02132360963150859), (42, 0.021464590914547443), (25, 0.022050512954592705), (23, 0.0223824055865407), (47, 0.022819078294560313), (21, 0.024859493598341942), (22, 0.025054547237232327), (24, 0.0257521141320467), (20, 0.02716388925909996), (39, 0.029890780337154865), (15, 0.03206307766959071), (7, 0.03241951856762171), (19, 0.03252987563610077), (38, 0.032632941380143166), (51, 0.034835889004170895), (9, 0.04359847167506814), (6, 0.0464042485691607), (14, 0.047905773390084505), (4, 0.04832407319918275), (52, 0.05093335546553135), (2, 0.05449478840455413), (3, 0.05812983633950353), (13, 0.05950648104771972), (11, 0.05975696910172701), (17, 0.062451849691569805), (0, 0.06420428398996592), (1, 0.0665421886369586), (8, 0.07475559320300817), (10, 0.08099567051976919), (16, 0.08513358794152737), (12, 0.09043542947620153), (5, 0.10664597619324923), (36, 0.3564477637410164), (18, 0.5118408501148224), (53, 0.8808624893426895)]
computing accuracy for after removing block 46 . block score: 0.017050422728061676
removed block 46 current accuracy 0.9216 loss from initial  0.02980000000000005
training start
training epoch 0 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 1 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 2 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 3 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 4 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.1]
training epoch 5 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.1]
training epoch 6 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 7 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 8 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.1]
training epoch 9 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.012192. All blocks and scores: [(48, 0.012191834393888712), (49, 0.012657195678912103), (43, 0.01557880244217813), (44, 0.01565590954851359), (45, 0.015744484029710293), (40, 0.016099985223263502), (47, 0.019244177266955376), (41, 0.023084902670234442), (21, 0.0249007660895586), (22, 0.025229057297110558), (39, 0.025287149706855416), (42, 0.026353899855166674), (20, 0.026930684922263026), (50, 0.027771824272349477), (38, 0.02859382680617273), (15, 0.03208377631381154), (19, 0.03249444765970111), (7, 0.03279390884563327), (24, 0.03288106480613351), (23, 0.03508862853050232), (25, 0.03820918453857303), (51, 0.04347500158473849), (9, 0.044338816311210394), (6, 0.04669944103807211), (14, 0.04802099475637078), (4, 0.048308111261576414), (2, 0.05502075236290693), (3, 0.05841545341536403), (13, 0.05981486104428768), (11, 0.05989903584122658), (17, 0.06218423554673791), (0, 0.06467558536678553), (1, 0.06740375608205795), (52, 0.06779943872243166), (8, 0.07457178737968206), (10, 0.08119010273367167), (16, 0.08483240567147732), (12, 0.09049502294510603), (5, 0.10637132730334997), (36, 0.3956754393875599), (18, 0.5131525918841362), (53, 0.8154404163360596)]
computing accuracy for after removing block 48 . block score: 0.012191834393888712
removed block 48 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 49, with score 0.013585. All blocks and scores: [(49, 0.013584927655756474), (43, 0.015578802325762808), (44, 0.01565590943209827), (45, 0.015744484262540936), (40, 0.016099985223263502), (47, 0.0192441763356328), (41, 0.02308490313589573), (21, 0.02490076539106667), (22, 0.025229057064279914), (39, 0.025287149008363485), (42, 0.026353899855166674), (20, 0.02693068445660174), (38, 0.028593827039003372), (50, 0.029529867693781853), (15, 0.03208377584815025), (19, 0.03249444719403982), (7, 0.03279390884563327), (24, 0.032881065271794796), (23, 0.03508862899616361), (25, 0.03820918407291174), (51, 0.04301917506381869), (9, 0.04433881537988782), (6, 0.04669943964108825), (14, 0.04802099196240306), (4, 0.04830811079591513), (2, 0.05502074910327792), (3, 0.05841545481234789), (13, 0.05981486104428768), (11, 0.05989903537556529), (17, 0.062184234615415335), (0, 0.06467558536678553), (1, 0.06740375701338053), (52, 0.07004556432366371), (8, 0.07457178831100464), (10, 0.08119010087102652), (16, 0.08483240660279989), (12, 0.09049502294510603), (5, 0.10637132823467255), (36, 0.3956754356622696), (18, 0.5131525695323944), (53, 0.8807051107287407)]
computing accuracy for after removing block 49 . block score: 0.013584927655756474
removed block 49 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.015579. All blocks and scores: [(43, 0.015578802675008774), (44, 0.015655909664928913), (45, 0.015744484029710293), (40, 0.01609998499043286), (47, 0.019244177034124732), (41, 0.02308490313589573), (21, 0.024900765623897314), (22, 0.025229056598618627), (39, 0.025287149474024773), (42, 0.026353899855166674), (20, 0.026930685387924314), (38, 0.02859382680617273), (50, 0.03132056421600282), (15, 0.03208377677947283), (19, 0.03249444765970111), (7, 0.03279390977695584), (24, 0.03288106620311737), (23, 0.03508862853050232), (25, 0.03820918360725045), (9, 0.04433881724253297), (51, 0.045139437541365623), (6, 0.04669944103807211), (14, 0.04802099196240306), (4, 0.04830811219289899), (2, 0.05502074910327792), (3, 0.05841545481234789), (13, 0.05981485964730382), (11, 0.059899034444242716), (17, 0.06218423740938306), (0, 0.06467558536678553), (1, 0.0674037579447031), (52, 0.07329025771468878), (8, 0.07457178831100464), (10, 0.08119010180234909), (16, 0.08483240567147732), (12, 0.09049501921981573), (5, 0.10637132916599512), (36, 0.3956754393875599), (18, 0.5131525620818138), (53, 0.9426647126674652)]
computing accuracy for after removing block 43 . block score: 0.015578802675008774
removed block 43 current accuracy 0.928 loss from initial  0.023399999999999976
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.015711. All blocks and scores: [(44, 0.015711385407485068), (45, 0.015933102695271373), (40, 0.016099985223263502), (47, 0.019270822871476412), (41, 0.02308490313589573), (21, 0.024900765623897314), (22, 0.025229057297110558), (39, 0.025287149008363485), (42, 0.02635390032082796), (20, 0.026930685387924314), (38, 0.02859382680617273), (50, 0.03003800311125815), (15, 0.032083775382488966), (19, 0.03249444765970111), (7, 0.03279390884563327), (24, 0.03288106573745608), (23, 0.03508862899616361), (25, 0.038209185004234314), (51, 0.043833622708916664), (9, 0.04433881724253297), (6, 0.04669943917542696), (14, 0.048020992893725634), (4, 0.04830810846760869), (2, 0.055020750034600496), (3, 0.0584154543466866), (13, 0.059814860578626394), (11, 0.059899034444242716), (17, 0.06218423508107662), (0, 0.06467558722943068), (1, 0.06740375701338053), (52, 0.06895207986235619), (8, 0.07457178924232721), (10, 0.08119010087102652), (16, 0.08483240380883217), (12, 0.0904950201511383), (5, 0.10637132450938225), (36, 0.3956754393875599), (18, 0.5131525620818138), (53, 0.9999736174941063)]
computing accuracy for after removing block 44 . block score: 0.015711385407485068
removed block 44 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.015960. All blocks and scores: [(45, 0.015960420947521925), (40, 0.01609998452477157), (47, 0.01905744313262403), (41, 0.02308490313589573), (21, 0.024900765623897314), (22, 0.02522905683144927), (39, 0.025287150172516704), (42, 0.026353900087997317), (20, 0.026930685620754957), (38, 0.02859382680617273), (50, 0.02873369329608977), (15, 0.03208377631381154), (19, 0.03249444719403982), (7, 0.03279391024261713), (24, 0.03288106480613351), (23, 0.03508862853050232), (25, 0.0382091854698956), (51, 0.04196186177432537), (9, 0.044338816311210394), (6, 0.046699441503733397), (14, 0.04802099382504821), (4, 0.048308111261576414), (2, 0.055020750500261784), (3, 0.05841545667499304), (13, 0.059814861975610256), (11, 0.05989903584122658), (17, 0.0621842360123992), (52, 0.06340109277516603), (0, 0.06467558722943068), (1, 0.0674037579447031), (8, 0.07457178831100464), (10, 0.08119010180234909), (16, 0.08483240567147732), (12, 0.09049502108246088), (5, 0.1063713263720274), (36, 0.3956754431128502), (18, 0.5131525695323944), (53, 1.1059282571077347)]
computing accuracy for after removing block 45 . block score: 0.015960420947521925
removed block 45 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.016100. All blocks and scores: [(40, 0.016099985223263502), (47, 0.020076334243640304), (41, 0.023084902903065085), (21, 0.024900765856727958), (22, 0.025229056598618627), (39, 0.02528714924119413), (42, 0.026353900087997317), (20, 0.026930685620754957), (38, 0.028593826107680798), (50, 0.02964628767222166), (15, 0.032083775382488966), (19, 0.03249444719403982), (7, 0.03279390884563327), (24, 0.03288106573745608), (23, 0.03508862899616361), (25, 0.03820918407291174), (51, 0.04045954952016473), (9, 0.044338816311210394), (6, 0.04669944103807211), (14, 0.04802099196240306), (4, 0.04830811079591513), (2, 0.055020750034600496), (3, 0.058415455278009176), (13, 0.05981486104428768), (11, 0.059899034909904), (52, 0.06041114730760455), (17, 0.062184237875044346), (0, 0.06467558816075325), (1, 0.06740375701338053), (8, 0.07457178831100464), (10, 0.08119010180234909), (16, 0.08483240474015474), (12, 0.09049502108246088), (5, 0.10637132544070482), (36, 0.395675428211689), (18, 0.5131525844335556), (53, 1.2210967540740967)]
computing accuracy for after removing block 40 . block score: 0.016099985223263502
removed block 40 current accuracy 0.8894 loss from initial  0.062000000000000055
training start
training epoch 0 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.1]
training epoch 1 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 2 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 3 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.1]
training epoch 4 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.1]
training epoch 5 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 6 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.1]
training epoch 7 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.1]
training epoch 8 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.1]
training epoch 9 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.025143. All blocks and scores: [(21, 0.025143437553197145), (22, 0.025204995181411505), (20, 0.027359890285879374), (15, 0.03215899597853422), (7, 0.03231840627267957), (19, 0.03256851574406028), (24, 0.03289470775052905), (23, 0.03485146118327975), (25, 0.038171287160366774), (41, 0.04090644512325525), (50, 0.042754899710416794), (9, 0.043785728979855776), (42, 0.04395253676921129), (6, 0.04668571427464485), (14, 0.047685686498880386), (4, 0.04935633949935436), (51, 0.054225992411375046), (47, 0.05494237178936601), (2, 0.055027696304023266), (3, 0.05856720311567187), (13, 0.059183262288570404), (11, 0.05921104131266475), (39, 0.06230619875714183), (17, 0.06231306213885546), (38, 0.06424110382795334), (0, 0.06444666720926762), (1, 0.0677341278642416), (8, 0.07398908492177725), (10, 0.08067284896969795), (16, 0.08534043747931719), (12, 0.08963577263057232), (52, 0.09513263311237097), (5, 0.10712404642254114), (18, 0.5123645141720772), (36, 0.5529542714357376), (53, 0.8068125993013382)]
computing accuracy for after removing block 21 . block score: 0.025143437553197145
removed block 21 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023487. All blocks and scores: [(22, 0.02348704542964697), (20, 0.02735989075154066), (24, 0.03008684515953064), (23, 0.032081697601825), (15, 0.032158996909856796), (7, 0.03231840766966343), (19, 0.0325685148127377), (25, 0.03531712479889393), (41, 0.03714133985340595), (42, 0.03945643687620759), (50, 0.040104028303176165), (9, 0.04378572991117835), (6, 0.04668571474030614), (14, 0.047685685101896524), (4, 0.04935633856803179), (51, 0.050380551256239414), (47, 0.05186004238203168), (2, 0.05502769583836198), (39, 0.05839862301945686), (38, 0.058399985544383526), (3, 0.05856720032170415), (13, 0.05918326182290912), (11, 0.05921104084700346), (17, 0.06231306539848447), (0, 0.06444667000323534), (1, 0.06773412600159645), (8, 0.07398908585309982), (10, 0.08067284617573023), (52, 0.08076371345669031), (16, 0.08534043747931719), (12, 0.08963577169924974), (5, 0.10712404828518629), (18, 0.5123645216226578), (36, 0.5166114196181297), (53, 0.8343372717499733)]
computing accuracy for after removing block 22 . block score: 0.02348704542964697
removed block 22 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.027360. All blocks and scores: [(20, 0.02735989075154066), (24, 0.027480501914396882), (23, 0.030120365088805556), (15, 0.03215899644419551), (7, 0.03231840627267957), (19, 0.0325685148127377), (25, 0.03315916797146201), (41, 0.035165099427103996), (42, 0.03701278241351247), (50, 0.03809230029582977), (9, 0.043785728979855776), (51, 0.046665006317198277), (6, 0.04668571474030614), (14, 0.0476856860332191), (47, 0.04861163254827261), (4, 0.04935633949935436), (2, 0.05502769444137812), (39, 0.05636392533779144), (38, 0.05717280134558678), (3, 0.05856720078736544), (13, 0.059183260425925255), (11, 0.05921104038134217), (17, 0.06231306493282318), (0, 0.06444667093455791), (1, 0.0677341241389513), (52, 0.07083033118396997), (8, 0.07398908399045467), (10, 0.08067284617573023), (16, 0.08534043747931719), (12, 0.08963577169924974), (5, 0.10712404549121857), (36, 0.5002713538706303), (18, 0.5123645216226578), (53, 0.8402402177453041)]
computing accuracy for after removing block 20 . block score: 0.02735989075154066
removed block 20 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.026820. All blocks and scores: [(24, 0.02682011155411601), (23, 0.028557729441672564), (15, 0.032158995512872934), (7, 0.03231840534135699), (25, 0.03239561477676034), (19, 0.03256851527839899), (41, 0.034599324222654104), (42, 0.03516145283356309), (50, 0.03672416973859072), (9, 0.043785730842500925), (51, 0.044522014912217855), (47, 0.045621403492987156), (6, 0.04668571474030614), (14, 0.047685685101896524), (4, 0.04935633949935436), (39, 0.053906642366200686), (2, 0.05502769676968455), (38, 0.05624715564772487), (3, 0.058567201253026724), (13, 0.05918326089158654), (11, 0.05921104131266475), (17, 0.06231306213885546), (52, 0.06257319962605834), (0, 0.06444666720926762), (1, 0.06773412600159645), (8, 0.07398908399045467), (10, 0.08067284431308508), (16, 0.08534043654799461), (12, 0.08963577263057232), (5, 0.10712404549121857), (36, 0.4970364086329937), (18, 0.5123645141720772), (53, 0.8328147307038307)]
computing accuracy for after removing block 24 . block score: 0.02682011155411601
removed block 24 current accuracy 0.9016 loss from initial  0.049800000000000066
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.028558. All blocks and scores: [(23, 0.028557729674503207), (25, 0.031494039576500654), (15, 0.032158995512872934), (7, 0.03231840580701828), (19, 0.03256851574406028), (41, 0.0334527506493032), (42, 0.034081827849149704), (50, 0.03516933415085077), (51, 0.040556978434324265), (47, 0.04299156786873937), (9, 0.04378572944551706), (6, 0.04668571474030614), (14, 0.04768568789586425), (4, 0.049356340896338224), (39, 0.054034062661230564), (52, 0.054476792458444834), (2, 0.05502769537270069), (38, 0.05606482224538922), (3, 0.05856719985604286), (13, 0.05918326135724783), (11, 0.059211039915680885), (17, 0.06231306539848447), (0, 0.06444667000323534), (1, 0.06773412507027388), (8, 0.07398908492177725), (10, 0.0806728471070528), (16, 0.08534043841063976), (12, 0.08963577263057232), (5, 0.10712404735386372), (36, 0.4921819232404232), (18, 0.5123645067214966), (53, 0.8587252199649811)]
computing accuracy for after removing block 23 . block score: 0.028557729674503207
removed block 23 current accuracy 0.8682 loss from initial  0.08320000000000005
since last training loss: 0.0756 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.031785. All blocks and scores: [(25, 0.03178536519408226), (15, 0.03215899644419551), (7, 0.032318406738340855), (19, 0.0325685148127377), (42, 0.0350077492184937), (41, 0.03558086697012186), (50, 0.035698806401342154), (51, 0.04042296530678868), (47, 0.042382481042295694), (9, 0.04378572944551706), (6, 0.046685715671628714), (14, 0.047685686498880386), (4, 0.04935633996501565), (52, 0.05241942452266812), (2, 0.05502769397571683), (39, 0.055516716092824936), (3, 0.058567201253026724), (13, 0.05918326182290912), (11, 0.05921104224398732), (17, 0.062313064467161894), (38, 0.06270575383678079), (0, 0.06444666907191277), (1, 0.0677341241389513), (8, 0.07398908212780952), (10, 0.0806728508323431), (16, 0.08534043654799461), (12, 0.0896357735618949), (5, 0.10712404642254114), (18, 0.5123645141720772), (36, 0.5215748995542526), (53, 0.8819703906774521)]
computing accuracy for after removing block 25 . block score: 0.03178536519408226
removed block 25 current accuracy 0.8394 loss from initial  0.11199999999999999
since last training loss: 0.10439999999999994 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032159. All blocks and scores: [(15, 0.03215899597853422), (7, 0.03231840627267957), (19, 0.03256851527839899), (50, 0.035487065091729164), (42, 0.03626132709905505), (51, 0.039235797710716724), (41, 0.03994317818433046), (47, 0.04007274471223354), (9, 0.04378572944551706), (6, 0.04668571427464485), (14, 0.04768568556755781), (52, 0.0486158961430192), (4, 0.04935633856803179), (2, 0.05502769770100713), (3, 0.05856720078736544), (13, 0.05918325996026397), (11, 0.05921104131266475), (39, 0.06057667173445225), (17, 0.06231306167319417), (0, 0.06444666720926762), (1, 0.06773412227630615), (38, 0.0723847160115838), (8, 0.0739890830591321), (10, 0.08067284896969795), (16, 0.08534043747931719), (12, 0.0896357698366046), (5, 0.10712404921650887), (18, 0.5123645216226578), (36, 0.5604042485356331), (53, 0.8831728249788284)]
computing accuracy for after removing block 15 . block score: 0.03215899597853422
removed block 15 current accuracy 0.8314 loss from initial  0.12
since last training loss: 0.11239999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032318. All blocks and scores: [(7, 0.03231840580701828), (19, 0.03287399420514703), (50, 0.03610900463536382), (42, 0.03638520371168852), (41, 0.03926952136680484), (51, 0.03955239849165082), (47, 0.0417152582667768), (9, 0.04378572991117835), (6, 0.046685715205967426), (14, 0.0476856860332191), (52, 0.04894476803019643), (4, 0.04935633996501565), (2, 0.05502769537270069), (3, 0.058567201253026724), (13, 0.05918326275423169), (11, 0.059211041778326035), (39, 0.0596935017965734), (0, 0.06444667000323534), (17, 0.06609892100095749), (1, 0.06773412320762873), (8, 0.07398908399045467), (38, 0.07520979177206755), (10, 0.08067284803837538), (12, 0.08963577263057232), (16, 0.09515763446688652), (5, 0.10712404549121857), (18, 0.49988828971982), (36, 0.5609239637851715), (53, 0.8937705382704735)]
computing accuracy for after removing block 7 . block score: 0.03231840580701828
removed block 7 current accuracy 0.8116 loss from initial  0.13980000000000004
since last training loss: 0.13219999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.032730. All blocks and scores: [(19, 0.03273024735972285), (50, 0.034443816635757685), (41, 0.03514989232644439), (42, 0.035729180090129375), (51, 0.03875673143193126), (47, 0.04040528228506446), (9, 0.043744525872170925), (14, 0.044076734222471714), (52, 0.046218272764235735), (6, 0.04668571474030614), (4, 0.04935634043067694), (13, 0.05135793145745993), (2, 0.055027694907039404), (11, 0.05596485594287515), (17, 0.05604291055351496), (39, 0.05703095160424709), (3, 0.0585672021843493), (0, 0.06444666814059019), (1, 0.06773412507027388), (8, 0.07194570451974869), (38, 0.07268141396343708), (10, 0.08304120507091284), (12, 0.08381484635174274), (16, 0.08669482357800007), (5, 0.10712404455989599), (18, 0.4835243597626686), (36, 0.5404010340571404), (53, 0.9232287779450417)]
computing accuracy for after removing block 19 . block score: 0.03273024735972285
removed block 19 current accuracy 0.7646 loss from initial  0.18680000000000008
training start
training epoch 0 val accuracy 0.7796 topk_dict {'top1': 0.7796} is_best True lr [0.1]
training epoch 1 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 3 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 4 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.1]
training epoch 5 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 6 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 7 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 8 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.1]
training epoch 9 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 10 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.935600)
finished training. finished 50 epochs. accuracy 0.9356 topk_dict {'top1': 0.9356}
