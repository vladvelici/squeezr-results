start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589500389993), (30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.01329466060269624), (29, 0.013421116513200104), (35, 0.015957689145579934), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019996491260826588), (46, 0.020590225467458367), (25, 0.022078295005485415), (23, 0.02222871547564864), (41, 0.022336415946483612), (44, 0.023145999060943723), (40, 0.023749591084197164), (45, 0.023975495481863618), (21, 0.02494108909741044), (48, 0.024957707384601235), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.025880582397803664), (49, 0.025916648097336292), (42, 0.026232231641188264), (20, 0.026848891051486135), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129645079374), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.4361986555159092), (18, 0.5117432922124863), (53, 0.8053385391831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013119243667460978), (29, 0.01342111686244607), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019852687139064074), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022977193584665656), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770821910351515), (21, 0.02494108979590237), (22, 0.025151389883831143), (49, 0.025575740495696664), (24, 0.025880582397803664), (42, 0.02589341253042221), (20, 0.026848891284316778), (47, 0.028072760673239827), (38, 0.031091187614947557), (39, 0.031191359972581267), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101367339492), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464461103082), (52, 0.06493351608514786), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4339806139469147), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.012758882134221494), (29, 0.013421116629615426), (35, 0.01591842179186642), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.02360257995314896), (45, 0.02377084968611598), (48, 0.024519873084500432), (50, 0.02463935106061399), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.02539255004376173), (42, 0.025712219765409827), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.028052504640072584), (38, 0.030935874208807945), (39, 0.031173037365078926), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080678507686), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740277051926), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325255781412125), (0, 0.06337464647367597), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4350202977657318), (18, 0.5117433071136475), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400159845128655), (29, 0.013421116629615426), (35, 0.015918650198727846), (26, 0.016072140773758292), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019867350347340107), (46, 0.02027974440716207), (41, 0.021756020607426763), (25, 0.022078295471146703), (23, 0.022228714544326067), (44, 0.023001376539468765), (40, 0.023739926051348448), (45, 0.02379016880877316), (48, 0.024350045947358012), (50, 0.02446310594677925), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025246930541470647), (42, 0.025273551931604743), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02772757480852306), (38, 0.03074627392925322), (39, 0.03128179535269737), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.038952667731791735), (51, 0.040824799332767725), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.059700035490095615), (17, 0.06132525624707341), (0, 0.06337464833632112), (52, 0.06356756016612053), (1, 0.06593216490000486), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4377693012356758), (18, 0.5117433071136475), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.020137187326326966), (41, 0.021584055153653026), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.023840721230953932), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870116962119937), (21, 0.02494108909741044), (42, 0.025045574875548482), (22, 0.025151390815153718), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.027423852356150746), (38, 0.030735648469999433), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632888928056), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003316178918), (17, 0.06132525531575084), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117433071136475), (53, 0.8283700942993164)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421117211692035), (26, 0.016072141006588936), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.02030268427915871), (46, 0.02032419736497104), (41, 0.021962702507153153), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.024168408941477537), (49, 0.024922372540459037), (21, 0.02494108979590237), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.026848890352994204), (47, 0.027568295830860734), (38, 0.03178726462647319), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.061325255781412125), (52, 0.06221094727516174), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.44933702796697617), (18, 0.5117432996630669), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421117211692035
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.1]
training epoch 1 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.1]
training epoch 2 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.1]
training epoch 3 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.1]
training epoch 4 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.1]
training epoch 5 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.1]
training epoch 6 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 7 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.1]
training epoch 8 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.1]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 6
[activation diff]: block to remove picked: 40, with score 0.008480. All blocks and scores: [(40, 0.008480403455905616), (35, 0.01326238492038101), (39, 0.013903683749958873), (38, 0.015813859179615974), (26, 0.01619424344971776), (28, 0.017807082505896688), (27, 0.01909325015731156), (37, 0.021364629035815597), (46, 0.02164329751394689), (43, 0.021823491668328643), (25, 0.022371419239789248), (23, 0.0225196226965636), (44, 0.02492393460124731), (21, 0.02500342228449881), (41, 0.025123465806245804), (22, 0.025355026591569185), (50, 0.025362443178892136), (45, 0.025426546577364206), (48, 0.025606919545680285), (49, 0.02583436109125614), (24, 0.026089119259268045), (20, 0.02718315040692687), (42, 0.028031653258949518), (47, 0.02947621000930667), (15, 0.032216678373515606), (7, 0.032656158320605755), (19, 0.032761344220489264), (51, 0.04237310495227575), (9, 0.043825795873999596), (6, 0.04664397472515702), (14, 0.04815210495144129), (4, 0.04843821516260505), (2, 0.0548869501799345), (3, 0.057957347482442856), (11, 0.05969180027022958), (13, 0.059857516549527645), (17, 0.06233492400497198), (0, 0.06362696085125208), (1, 0.06606725417077541), (52, 0.06801753118634224), (8, 0.07511979714035988), (10, 0.08151043951511383), (16, 0.08557977713644505), (12, 0.09061031229794025), (5, 0.10636383574455976), (36, 0.38060351461172104), (18, 0.514419823884964), (53, 0.7861063107848167)]
computing accuracy for after removing block 40 . block score: 0.008480403455905616
removed block 40 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.013262. All blocks and scores: [(35, 0.01326238492038101), (39, 0.013903684448450804), (38, 0.015813859878107905), (26, 0.01619424275122583), (28, 0.01780708273872733), (27, 0.019093249924480915), (46, 0.021097457967698574), (43, 0.021154511719942093), (37, 0.021364628802984953), (25, 0.02237141947261989), (23, 0.0225196226965636), (41, 0.024729536846280098), (50, 0.024804804008454084), (45, 0.024891913402825594), (21, 0.025003422517329454), (48, 0.02512625348754227), (44, 0.025150735629722476), (22, 0.02535502566024661), (49, 0.025602178880944848), (24, 0.026089119724929333), (42, 0.026880850782617927), (20, 0.02718315040692687), (47, 0.029376124031841755), (15, 0.03221667977049947), (7, 0.03265615925192833), (19, 0.032761344220489264), (51, 0.04242860618978739), (9, 0.043825797736644745), (6, 0.04664397472515702), (14, 0.04815210588276386), (4, 0.04843821469694376), (2, 0.054886949714273214), (3, 0.05795734841376543), (11, 0.059691802598536015), (13, 0.05985751934349537), (17, 0.06233492214232683), (0, 0.06362696178257465), (1, 0.06606725417077541), (52, 0.06793488096445799), (8, 0.07511979714035988), (10, 0.08151043858379126), (16, 0.0855797752737999), (12, 0.09061031322926283), (5, 0.10636383667588234), (36, 0.38060351461172104), (18, 0.5144198164343834), (53, 0.8221021369099617)]
computing accuracy for after removing block 35 . block score: 0.01326238492038101
removed block 35 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 39, with score 0.013354. All blocks and scores: [(39, 0.013353521819226444), (38, 0.01518937957007438), (26, 0.016194242984056473), (28, 0.017807082505896688), (27, 0.019093249924480915), (46, 0.020438125357031822), (43, 0.02065862133167684), (37, 0.021029398310929537), (25, 0.022371419006958604), (23, 0.022519622463732958), (50, 0.02370760263875127), (41, 0.023941615130752325), (48, 0.024194724392145872), (45, 0.024371133651584387), (49, 0.02489680191501975), (21, 0.02500342298299074), (22, 0.02535502682439983), (44, 0.02554718009196222), (24, 0.026089119724929333), (42, 0.026162836933508515), (20, 0.027183151338249445), (47, 0.028022554237395525), (15, 0.03221667883917689), (7, 0.032656158320605755), (19, 0.032761345617473125), (51, 0.04118154011666775), (9, 0.04382579727098346), (6, 0.04664397472515702), (14, 0.048152105417102575), (4, 0.04843821516260505), (2, 0.054886949714273214), (3, 0.057957347482442856), (11, 0.059691802598536015), (13, 0.05985751794651151), (17, 0.06233492121100426), (0, 0.0636269599199295), (52, 0.06496190652251244), (1, 0.06606725417077541), (8, 0.07511979807168245), (10, 0.08151043858379126), (16, 0.0855797752737999), (12, 0.09061031136661768), (5, 0.10636383853852749), (36, 0.3807963766157627), (18, 0.5144198089838028), (53, 0.8333362936973572)]
computing accuracy for after removing block 39 . block score: 0.013353521819226444
removed block 39 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.015189. All blocks and scores: [(38, 0.01518937957007438), (26, 0.016194242984056473), (28, 0.017807082273066044), (27, 0.019093249924480915), (43, 0.01943084830418229), (46, 0.019489390775561333), (37, 0.021029398078098893), (50, 0.021844805916771293), (25, 0.02237141993828118), (48, 0.022513803094625473), (23, 0.022519622929394245), (41, 0.023195681860670447), (45, 0.023263132199645042), (49, 0.023866306990385056), (21, 0.025003422750160098), (22, 0.025355026591569185), (44, 0.025376012548804283), (42, 0.025480478769168258), (24, 0.026089119026437402), (47, 0.026700669433921576), (20, 0.027183150639757514), (15, 0.03221667883917689), (7, 0.032656158320605755), (19, 0.03276134515181184), (51, 0.03981311619281769), (9, 0.04382579727098346), (6, 0.046643974259495735), (14, 0.04815210495144129), (4, 0.04843821469694376), (2, 0.054886949714273214), (3, 0.05795734655112028), (11, 0.059691800735890865), (13, 0.05985751748085022), (52, 0.06102830730378628), (17, 0.06233492260798812), (0, 0.06362696178257465), (1, 0.06606725510209799), (8, 0.07511979807168245), (10, 0.0815104367211461), (16, 0.08557977620512247), (12, 0.0906103141605854), (5, 0.10636383388191462), (36, 0.3807963691651821), (18, 0.5144198089838028), (53, 0.8741541504859924)]
computing accuracy for after removing block 38 . block score: 0.01518937957007438
removed block 38 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.016194. All blocks and scores: [(26, 0.016194243216887116), (28, 0.01780708273872733), (43, 0.01811403688043356), (46, 0.018615439301356673), (27, 0.019093249924480915), (50, 0.020095975371077657), (48, 0.020894023356959224), (37, 0.021029398078098893), (45, 0.02220456604845822), (41, 0.022330637322738767), (25, 0.022371419705450535), (49, 0.022465312387794256), (23, 0.022519622230902314), (42, 0.024793857242912054), (21, 0.025003422750160098), (47, 0.02503535943105817), (44, 0.025153954746201634), (22, 0.025355027057230473), (24, 0.02608911949209869), (20, 0.027183150639757514), (15, 0.032216676976531744), (7, 0.03265615785494447), (19, 0.03276134515181184), (51, 0.039157269056886435), (9, 0.04382579727098346), (6, 0.04664397332817316), (14, 0.04815210402011871), (4, 0.04843821423128247), (2, 0.05488694924861193), (52, 0.057791844476014376), (3, 0.057957347482442856), (11, 0.05969180213287473), (13, 0.05985751794651151), (17, 0.06233492121100426), (0, 0.06362696085125208), (1, 0.06606725323945284), (8, 0.07511979900300503), (10, 0.08151043765246868), (16, 0.08557977806776762), (12, 0.09061031509190798), (5, 0.10636383667588234), (36, 0.3807963728904724), (18, 0.5144198015332222), (53, 0.8975485041737556)]
computing accuracy for after removing block 26 . block score: 0.016194243216887116
removed block 26 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 28, with score 0.017155. All blocks and scores: [(28, 0.017155008390545845), (43, 0.017634109826758504), (46, 0.018135819816961884), (27, 0.018838015850633383), (50, 0.019495635759085417), (48, 0.020262383855879307), (37, 0.02046615886501968), (41, 0.021419177763164043), (45, 0.02184677147306502), (49, 0.022037416696548462), (25, 0.02237141947261989), (23, 0.0225196226965636), (42, 0.02375680534169078), (47, 0.024474036414176226), (44, 0.024909453466534615), (21, 0.02500342298299074), (22, 0.02535502682439983), (24, 0.02608911832794547), (20, 0.027183150639757514), (15, 0.032216678373515606), (7, 0.03265615738928318), (19, 0.032761343754827976), (51, 0.03757311822846532), (9, 0.043825797736644745), (6, 0.04664397332817316), (14, 0.04815210448578), (4, 0.04843821469694376), (2, 0.05488694878295064), (52, 0.05525560304522514), (3, 0.05795734981074929), (11, 0.05969180120155215), (13, 0.05985751561820507), (17, 0.06233492214232683), (0, 0.0636269599199295), (1, 0.06606725044548512), (8, 0.0751197962090373), (10, 0.08151043765246868), (16, 0.08557977713644505), (12, 0.09061031322926283), (5, 0.10636383574455976), (36, 0.37146027386188507), (18, 0.5144198313355446), (53, 0.9261350184679031)]
computing accuracy for after removing block 28 . block score: 0.017155008390545845
removed block 28 current accuracy 0.927 loss from initial  0.024399999999999977
training start
training epoch 0 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 1 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 2 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.1]
training epoch 3 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.1]
training epoch 4 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.1]
training epoch 6 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.1]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 8 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.1]
training epoch 9 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.012865. All blocks and scores: [(46, 0.012864561285823584), (45, 0.016396539518609643), (43, 0.016582602402195334), (44, 0.01769774197600782), (25, 0.021832460071891546), (42, 0.022037820192053914), (23, 0.022523955442011356), (41, 0.024397836765274405), (21, 0.024874594528228045), (22, 0.02504372945986688), (24, 0.025777239119634032), (50, 0.026726498501375318), (20, 0.02700458699837327), (49, 0.02734308410435915), (48, 0.02841838705353439), (15, 0.031970391515642405), (7, 0.03258116077631712), (19, 0.032711738254874945), (47, 0.03314783563837409), (27, 0.04050852311775088), (51, 0.04218227416276932), (9, 0.04392141941934824), (6, 0.04629934020340443), (37, 0.047028787434101105), (14, 0.04777934029698372), (4, 0.04784126440063119), (2, 0.05453807720914483), (3, 0.05722524132579565), (11, 0.05951817100867629), (13, 0.05976750003173947), (17, 0.061821180395781994), (0, 0.06306247552856803), (1, 0.06565304845571518), (52, 0.06727861426770687), (8, 0.074353969655931), (10, 0.08094074297696352), (16, 0.0850415900349617), (12, 0.08991056866943836), (5, 0.10590665321797132), (36, 0.49107252061367035), (18, 0.5115062817931175), (53, 0.810712143778801)]
computing accuracy for after removing block 46 . block score: 0.012864561285823584
removed block 46 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.016397. All blocks and scores: [(45, 0.016396539751440287), (43, 0.016582602402195334), (44, 0.0176977408118546), (25, 0.02183245914056897), (42, 0.022037819726392627), (23, 0.02252395497635007), (41, 0.024397836066782475), (21, 0.024874594528228045), (22, 0.025043729692697525), (24, 0.025777239119634032), (50, 0.02699335478246212), (20, 0.02700458513572812), (49, 0.02727897302247584), (48, 0.02827541553415358), (15, 0.03197039198130369), (7, 0.03258116077631712), (19, 0.03271173778921366), (47, 0.03463967004790902), (27, 0.04050852404907346), (51, 0.04232347663491964), (9, 0.04392141895368695), (6, 0.04629934020340443), (37, 0.047028787434101105), (14, 0.04777933796867728), (4, 0.047841261606663465), (2, 0.05453807674348354), (3, 0.057225240394473076), (11, 0.05951817100867629), (13, 0.0597674991004169), (17, 0.061821180395781994), (0, 0.06306247552856803), (1, 0.0656530512496829), (52, 0.06833820324391127), (8, 0.07435396686196327), (10, 0.0809407439082861), (16, 0.08504159096628428), (12, 0.08991057146340609), (5, 0.1059066541492939), (36, 0.49107251316308975), (18, 0.5115062817931175), (53, 0.866621121764183)]
computing accuracy for after removing block 45 . block score: 0.016396539751440287
removed block 45 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.016583. All blocks and scores: [(43, 0.016582602402195334), (44, 0.017697741743177176), (25, 0.02183245960623026), (42, 0.022037819493561983), (23, 0.02252395497635007), (41, 0.024397836532443762), (21, 0.0248745942953974), (22, 0.025043728994205594), (24, 0.025777240050956607), (20, 0.027004585834220052), (50, 0.027308870805427432), (49, 0.027323096990585327), (48, 0.02858680789358914), (15, 0.03197039198130369), (7, 0.03258115891367197), (19, 0.032711738254874945), (47, 0.0353701813146472), (27, 0.04050852311775088), (51, 0.04160755407065153), (9, 0.043921420350670815), (6, 0.046299342066049576), (37, 0.04702878789976239), (14, 0.047779337503015995), (4, 0.04784126253798604), (2, 0.05453807581216097), (3, 0.057225242257118225), (11, 0.059518168680369854), (13, 0.05976750003173947), (17, 0.06182118225842714), (0, 0.06306247366592288), (1, 0.06565305031836033), (52, 0.0667830016463995), (8, 0.07435396779328585), (10, 0.08094074483960867), (16, 0.08504159282892942), (12, 0.08991056866943836), (5, 0.10590665508061647), (36, 0.49107251688838005), (18, 0.5115062817931175), (53, 0.9507898613810539)]
computing accuracy for after removing block 43 . block score: 0.016582602402195334
removed block 43 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.018901. All blocks and scores: [(44, 0.018900979310274124), (25, 0.021832458674907684), (42, 0.02203781995922327), (23, 0.022523955442011356), (41, 0.024397836066782475), (21, 0.0248745942953974), (22, 0.025043729692697525), (24, 0.025777239352464676), (20, 0.027004585601389408), (49, 0.027398371137678623), (50, 0.027616684325039387), (48, 0.030629232060164213), (15, 0.03197039244696498), (7, 0.03258116031065583), (19, 0.03271173778921366), (47, 0.03678467497229576), (27, 0.04050852358341217), (51, 0.04179427353665233), (9, 0.043921420350670815), (6, 0.04629933927208185), (37, 0.04702878789976239), (14, 0.04777933889999986), (4, 0.04784126207232475), (2, 0.05453807581216097), (3, 0.05722524179145694), (11, 0.05951816961169243), (13, 0.05976750096306205), (17, 0.06182118225842714), (0, 0.0630624764598906), (1, 0.0656530512496829), (52, 0.06784097570925951), (8, 0.07435396686196327), (10, 0.0809407439082861), (16, 0.085041593760252), (12, 0.08991056960076094), (5, 0.1059066578745842), (36, 0.49107251688838005), (18, 0.5115062892436981), (53, 0.9886802136898041)]
computing accuracy for after removing block 44 . block score: 0.018900979310274124
removed block 44 current accuracy 0.9206 loss from initial  0.03080000000000005
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.021832. All blocks and scores: [(25, 0.021832459839060903), (42, 0.022037819493561983), (23, 0.022523955209180713), (41, 0.024397836532443762), (21, 0.024874594528228045), (22, 0.02504372945986688), (24, 0.02577723958529532), (49, 0.026982511626556516), (20, 0.02700458629988134), (50, 0.02789456071332097), (48, 0.030288695823401213), (15, 0.03197039198130369), (7, 0.032581159844994545), (19, 0.03271173872053623), (47, 0.03810527781024575), (27, 0.04050852358341217), (51, 0.041107987985014915), (9, 0.0439214208163321), (6, 0.04629933927208185), (37, 0.04702878650277853), (14, 0.047779339365661144), (4, 0.04784126253798604), (2, 0.05453807534649968), (3, 0.05722524086013436), (11, 0.05951816961169243), (13, 0.05976750003173947), (17, 0.061821180395781994), (0, 0.06306247459724545), (1, 0.06565305404365063), (52, 0.06602109130471945), (8, 0.07435396686196327), (10, 0.08094074577093124), (16, 0.08504159189760685), (12, 0.08991057053208351), (5, 0.10590665601193905), (36, 0.49107250198721886), (18, 0.5115062966942787), (53, 1.060892328619957)]
computing accuracy for after removing block 25 . block score: 0.021832459839060903
removed block 25 current accuracy 0.9178 loss from initial  0.033600000000000074
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 42, with score 0.021840. All blocks and scores: [(42, 0.021840146277099848), (23, 0.02252395497635007), (41, 0.024171498138457537), (21, 0.024874594062566757), (22, 0.02504372945986688), (24, 0.02577723958529532), (49, 0.026072382228448987), (50, 0.026936530601233244), (20, 0.027004585601389408), (48, 0.02978623751550913), (15, 0.031970391515642405), (7, 0.03258116031065583), (19, 0.03271173778921366), (47, 0.03723134100437164), (51, 0.04003989789634943), (27, 0.04047536849975586), (9, 0.04392141941934824), (6, 0.046299340669065714), (37, 0.04768475517630577), (14, 0.04777933889999986), (4, 0.04784126486629248), (2, 0.05453807394951582), (3, 0.05722524179145694), (11, 0.05951816914603114), (13, 0.0597674991004169), (17, 0.06182118272408843), (0, 0.06306247785687447), (52, 0.06487766187638044), (1, 0.06565304938703775), (8, 0.07435396779328585), (10, 0.08094074297696352), (16, 0.08504159096628428), (12, 0.08991056960076094), (5, 0.1059066541492939), (36, 0.4859202243387699), (18, 0.5115062892436981), (53, 1.0783458352088928)]
computing accuracy for after removing block 42 . block score: 0.021840146277099848
removed block 42 current accuracy 0.909 loss from initial  0.04239999999999999
training start
training epoch 0 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 1 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 2 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.1]
training epoch 3 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 4 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 5 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.1]
training epoch 6 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 7 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.1]
training epoch 8 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.1]
training epoch 9 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022703. All blocks and scores: [(23, 0.022702876944094896), (21, 0.025032132398337126), (22, 0.025265069445595145), (24, 0.025862227892503142), (20, 0.027037115301936865), (15, 0.03210028959438205), (7, 0.03251722967252135), (19, 0.032982347533106804), (50, 0.03625226253643632), (48, 0.038630036637187004), (49, 0.04236541036516428), (9, 0.04388678912073374), (6, 0.046552373096346855), (4, 0.047642530873417854), (14, 0.04783785529434681), (51, 0.050519454292953014), (47, 0.05461272317916155), (2, 0.054989433381706476), (3, 0.057296840474009514), (13, 0.05930720455944538), (11, 0.0597918052226305), (17, 0.06180360401049256), (0, 0.06274565402418375), (41, 0.06303762830793858), (27, 0.06644210126250982), (1, 0.06645527575165033), (8, 0.07437135465443134), (10, 0.08099522907286882), (52, 0.08179391082376242), (16, 0.08584279101341963), (37, 0.08635357115417719), (12, 0.09044666681438684), (5, 0.10599275678396225), (18, 0.5123505368828773), (36, 0.6060236170887947), (53, 0.8093419969081879)]
computing accuracy for after removing block 23 . block score: 0.022702876944094896
removed block 23 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.024520. All blocks and scores: [(24, 0.02451978507451713), (21, 0.02503213193267584), (22, 0.025265068979933858), (20, 0.02703711553476751), (15, 0.032100290060043335), (7, 0.032517229206860065), (19, 0.03298234706744552), (50, 0.03487638011574745), (48, 0.038011256605386734), (49, 0.042136942967772484), (9, 0.04388678865507245), (6, 0.04655237216502428), (4, 0.04764252947643399), (14, 0.04783785389736295), (51, 0.04912191815674305), (47, 0.05315775517374277), (2, 0.05498943477869034), (3, 0.057296841870993376), (13, 0.059307204093784094), (11, 0.05979180382564664), (17, 0.061803605407476425), (0, 0.06274565542116761), (41, 0.06301279319450259), (27, 0.06498011015355587), (1, 0.06645527295768261), (8, 0.07437135744839907), (52, 0.0787646546959877), (10, 0.08099522534757853), (16, 0.08584279287606478), (37, 0.08823589608073235), (12, 0.09044666402041912), (5, 0.10599275678396225), (18, 0.512350544333458), (36, 0.6032913774251938), (53, 0.8149611353874207)]
computing accuracy for after removing block 24 . block score: 0.02451978507451713
removed block 24 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.025032. All blocks and scores: [(21, 0.025032132165506482), (22, 0.02526506851427257), (20, 0.02703711553476751), (15, 0.03210028959438205), (7, 0.03251723013818264), (50, 0.032590548042207956), (19, 0.032982347533106804), (48, 0.036287258844822645), (49, 0.03989058826118708), (9, 0.04388678912073374), (51, 0.04510959470644593), (6, 0.04655237169936299), (4, 0.04764253133907914), (14, 0.04783785529434681), (47, 0.05118401674553752), (2, 0.05498943431302905), (3, 0.057296841870993376), (13, 0.05930720362812281), (11, 0.059791806153953075), (41, 0.060112572740763426), (17, 0.06180360401049256), (0, 0.06274565542116761), (27, 0.06374770123511553), (1, 0.06645527482032776), (52, 0.07041755318641663), (8, 0.07437135651707649), (10, 0.08099522721022367), (16, 0.0858427956700325), (37, 0.08612797316163778), (12, 0.0904466649517417), (5, 0.1059927586466074), (18, 0.512350544333458), (36, 0.5812342092394829), (53, 0.8388123288750648)]
computing accuracy for after removing block 21 . block score: 0.025032132165506482
removed block 21 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.025999999999999912 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.023529. All blocks and scores: [(22, 0.023529449943453074), (20, 0.02703711506910622), (50, 0.030276676174253225), (15, 0.03210028959438205), (7, 0.032517229206860065), (19, 0.03298234660178423), (48, 0.03357767965644598), (49, 0.03819619119167328), (51, 0.042115760035812855), (9, 0.04388678818941116), (6, 0.04655237216502428), (4, 0.04764253320172429), (47, 0.04769556364044547), (14, 0.04783785482868552), (41, 0.054910124745219946), (2, 0.0549894324503839), (3, 0.05729684326797724), (13, 0.05930720269680023), (11, 0.05979180568829179), (52, 0.061198707204312086), (27, 0.061625291127711535), (17, 0.06180360401049256), (0, 0.06274565355852246), (1, 0.06645527388900518), (8, 0.07437135744839907), (37, 0.08009679056704044), (10, 0.08099522814154625), (16, 0.08584279101341963), (12, 0.09044666215777397), (5, 0.10599275771528482), (18, 0.5123505294322968), (36, 0.5466521754860878), (53, 0.8605320081114769)]
computing accuracy for after removing block 22 . block score: 0.023529449943453074
removed block 22 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04179999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.027037. All blocks and scores: [(20, 0.02703711553476751), (50, 0.02870210725814104), (48, 0.03141705831512809), (15, 0.03210028912872076), (7, 0.032517231069505215), (19, 0.032982348930090666), (49, 0.03614216763526201), (51, 0.03977280855178833), (9, 0.043886789586395025), (47, 0.044640217907726765), (6, 0.04655237169936299), (4, 0.04764253040775657), (14, 0.047837854363024235), (41, 0.05280900886282325), (52, 0.05411440460011363), (2, 0.05498943571001291), (3, 0.0572968409396708), (13, 0.05930720316246152), (11, 0.059791804291307926), (27, 0.06001754477620125), (17, 0.061803603544831276), (0, 0.06274565355852246), (1, 0.06645527388900518), (8, 0.07437135744839907), (37, 0.08012561965733767), (10, 0.08099522721022367), (16, 0.0858427919447422), (12, 0.09044666308909655), (5, 0.10599275585263968), (18, 0.512350544333458), (36, 0.5372373685240746), (53, 0.8642475008964539)]
computing accuracy for after removing block 20 . block score: 0.02703711553476751
removed block 20 current accuracy 0.8816 loss from initial  0.06979999999999997
since last training loss: 0.0643999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.027640. All blocks and scores: [(50, 0.027639708947390318), (48, 0.029382109409198165), (15, 0.03210028866305947), (7, 0.03251722967252135), (19, 0.03298234706744552), (49, 0.03488783584907651), (51, 0.037543237674981356), (47, 0.040303919930011034), (9, 0.04388678818941116), (6, 0.04655237263068557), (52, 0.04658057680353522), (4, 0.04764253133907914), (14, 0.04783785482868552), (41, 0.05071847699582577), (2, 0.05498943571001291), (3, 0.05729684140533209), (27, 0.05912510212510824), (13, 0.05930720455944538), (11, 0.059791804756969213), (17, 0.061803603544831276), (0, 0.06274565355852246), (1, 0.06645527482032776), (8, 0.07437135744839907), (37, 0.07907495833933353), (10, 0.08099522907286882), (16, 0.08584279287606478), (12, 0.0904466649517417), (5, 0.10599275585263968), (18, 0.512350544333458), (36, 0.5325411334633827), (53, 0.8557343631982803)]
computing accuracy for after removing block 50 . block score: 0.027639708947390318
removed block 50 current accuracy 0.868 loss from initial  0.08340000000000003
since last training loss: 0.07799999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.029382. All blocks and scores: [(48, 0.02938210847787559), (15, 0.03210028912872076), (7, 0.03251723013818264), (19, 0.03298234706744552), (49, 0.03488783584907651), (47, 0.04030391946434975), (51, 0.04070125566795468), (9, 0.04388678725808859), (6, 0.04655237169936299), (4, 0.04764253180474043), (14, 0.04783785482868552), (52, 0.04955113073810935), (41, 0.050718477461487055), (2, 0.054989433847367764), (3, 0.05729684280231595), (27, 0.059125103522092104), (13, 0.05930720595642924), (11, 0.059791806153953075), (17, 0.06180360494181514), (0, 0.06274565355852246), (1, 0.06645527575165033), (8, 0.07437135744839907), (37, 0.07907495740801096), (10, 0.08099522534757853), (16, 0.0858427919447422), (12, 0.09044666308909655), (5, 0.10599275771528482), (18, 0.5123505368828773), (36, 0.5325411260128021), (53, 1.0725184977054596)]
computing accuracy for after removing block 48 . block score: 0.02938210847787559
removed block 48 current accuracy 0.8418 loss from initial  0.10960000000000003
since last training loss: 0.10419999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.032100. All blocks and scores: [(15, 0.03210028959438205), (7, 0.03251723013818264), (19, 0.03298234799876809), (49, 0.03900628304108977), (47, 0.04030392039567232), (51, 0.040629907976835966), (9, 0.043886789586395025), (6, 0.04655237169936299), (4, 0.047642530873417854), (14, 0.047837854363024235), (41, 0.05071847606450319), (52, 0.054266906809061766), (2, 0.054989431984722614), (3, 0.0572968409396708), (27, 0.05912510259076953), (13, 0.059307204093784094), (11, 0.05979180382564664), (17, 0.0618036026135087), (0, 0.06274565355852246), (1, 0.06645527295768261), (8, 0.07437135651707649), (37, 0.07907495647668839), (10, 0.08099522814154625), (16, 0.08584279473870993), (12, 0.09044666681438684), (5, 0.10599275678396225), (18, 0.512350544333458), (36, 0.5325411260128021), (53, 1.1755254715681076)]
computing accuracy for after removing block 15 . block score: 0.03210028959438205
removed block 15 current accuracy 0.8186 loss from initial  0.13280000000000003
since last training loss: 0.12739999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.032517. All blocks and scores: [(7, 0.03251722967252135), (19, 0.03323900606483221), (49, 0.039138633757829666), (51, 0.041232061106711626), (47, 0.0413642143830657), (9, 0.04388678818941116), (6, 0.04655237169936299), (4, 0.04764253133907914), (14, 0.047837854363024235), (41, 0.050183710642158985), (2, 0.05498943291604519), (52, 0.05596534721553326), (27, 0.057027933187782764), (3, 0.057296841870993376), (13, 0.05930720269680023), (11, 0.059791804291307926), (0, 0.0627456558868289), (17, 0.0655954061076045), (1, 0.06645527202636003), (8, 0.07437135744839907), (37, 0.08064252324402332), (10, 0.08099522721022367), (12, 0.09044666681438684), (16, 0.09583932999521494), (5, 0.10599276050925255), (18, 0.4995947517454624), (36, 0.5350526794791222), (53, 1.217296302318573)]
computing accuracy for after removing block 7 . block score: 0.03251722967252135
removed block 7 current accuracy 0.7978 loss from initial  0.15360000000000007
training start
training epoch 0 val accuracy 0.834 topk_dict {'top1': 0.834} is_best True lr [0.1]
training epoch 1 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 2 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.1]
training epoch 3 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 4 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 5 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 6 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 7 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 8 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 9 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
