start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013294661301188171), (29, 0.013421117095276713), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.020590224536135793), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336416644975543), (44, 0.023145999060943723), (40, 0.023749590618535876), (45, 0.023975495481863618), (21, 0.02494109026156366), (48, 0.024957706220448017), (22, 0.025151390116661787), (50, 0.025287174619734287), (24, 0.025880582630634308), (49, 0.025916648795828223), (42, 0.026232231175526977), (20, 0.026848891517147422), (47, 0.0286329488735646), (38, 0.03134434437379241), (39, 0.031441295286640525), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03791803075000644), (51, 0.04178758570924401), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.06132525531575084), (0, 0.06337464833632112), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.10671143420040607), (36, 0.436198640614748), (18, 0.5117432996630669), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187405325472), (31, 0.010232581640593708), (34, 0.013119243900291622), (29, 0.013421116513200104), (26, 0.01607214054092765), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019852687139064074), (46, 0.020300705451518297), (41, 0.0218602754175663), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.02364823711104691), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.02557574096135795), (24, 0.025880583096295595), (42, 0.025893412763252854), (20, 0.026848891284316778), (47, 0.028072759974747896), (38, 0.03109118831343949), (39, 0.031191361136734486), (15, 0.03205838333815336), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740603014827), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525345310569), (0, 0.06337464554235339), (52, 0.06493351515382528), (1, 0.06593215838074684), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4339806102216244), (18, 0.5117432847619057), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.01275888190139085), (29, 0.013421116978861392), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019850464537739754), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.022891478147357702), (40, 0.023602579487487674), (45, 0.023770848754793406), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.024941090028733015), (22, 0.02515139034949243), (49, 0.025392549578100443), (42, 0.025712220929563046), (24, 0.025880582397803664), (20, 0.02684889268130064), (47, 0.02805250510573387), (38, 0.03093587444163859), (39, 0.031173037132248282), (15, 0.03205838380381465), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.04113080911338329), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.054577406495809555), (3, 0.05784992687404156), (13, 0.05914428876712918), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4350203089416027), (18, 0.5117432847619057), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824108667672), (34, 0.012400159845128655), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02300137630663812), (40, 0.023739926517009735), (45, 0.023790168343111873), (48, 0.02435004455037415), (50, 0.024463105713948607), (21, 0.024941088864579797), (22, 0.025151389883831143), (49, 0.02524693007580936), (42, 0.025273551465943456), (24, 0.025880581932142377), (20, 0.026848892448469996), (47, 0.027727575274184346), (38, 0.03074627509340644), (39, 0.031281794887036085), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824797470122576), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003642141819), (17, 0.061325252521783113), (0, 0.06337464647367597), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117432996630669), (53, 0.8228829428553581)]
computing accuracy for after removing block 31 . block score: 0.010244824108667672
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421117095276713), (35, 0.01596891228109598), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02268732455559075), (40, 0.023569097742438316), (45, 0.023840721230953932), (48, 0.024108358891680837), (50, 0.024114208528771996), (49, 0.024870117427781224), (21, 0.024941089563071728), (42, 0.025045575108379126), (22, 0.025151390582323074), (24, 0.025880581932142377), (20, 0.026848891517147422), (47, 0.02742385189048946), (38, 0.030735648469999433), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464554235339), (1, 0.06593215931206942), (8, 0.07466361299157143), (10, 0.08082299772650003), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692685663700104), (18, 0.5117432847619057), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072140773758292), (35, 0.016558772418648005), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962703904137015), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.023045078152790666), (48, 0.024024547543376684), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168408708646894), (49, 0.02492237277328968), (21, 0.02494109026156366), (22, 0.025151390116661787), (42, 0.025816060369834304), (24, 0.025880582630634308), (20, 0.026848891051486135), (47, 0.027568295365199447), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.03225791407749057), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.040690730791538954), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.06221095006912947), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702051639557), (18, 0.5117432773113251), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.1]
training epoch 1 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.1]
training epoch 2 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 3 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.1]
training epoch 4 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.1]
training epoch 6 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.1]
training epoch 7 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.1]
training epoch 8 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.1]
training epoch 9 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.1]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.011311. All blocks and scores: [(35, 0.011310735484585166), (28, 0.013803813722915947), (27, 0.014404805842787027), (38, 0.014696269761770964), (26, 0.01615672162733972), (37, 0.018044986063614488), (43, 0.02106295502744615), (46, 0.021145450649783015), (25, 0.022296754643321037), (23, 0.022512756986543536), (41, 0.023445983417332172), (44, 0.02383582852780819), (45, 0.02451761858537793), (21, 0.02489111479371786), (48, 0.02523319819010794), (22, 0.025236092507839203), (40, 0.025646883761510253), (50, 0.025669677881523967), (24, 0.025992544600740075), (49, 0.026203513611108065), (20, 0.027153700590133667), (42, 0.027469673892483115), (47, 0.02885369141586125), (15, 0.0320911412127316), (19, 0.03256545541808009), (7, 0.03264056658372283), (39, 0.03522973135113716), (51, 0.04053420294076204), (9, 0.04411967797204852), (6, 0.04634959204122424), (4, 0.04648973047733307), (14, 0.04790925653651357), (2, 0.05402394291013479), (3, 0.05759594636037946), (13, 0.05953678069636226), (11, 0.059583190362900496), (17, 0.06158253224566579), (0, 0.06415853649377823), (1, 0.0660499781370163), (52, 0.06715499609708786), (8, 0.0743277259171009), (10, 0.08083636499941349), (16, 0.08421198837459087), (12, 0.09030438028275967), (5, 0.10604929458349943), (36, 0.36317141726613045), (18, 0.5122411847114563), (53, 0.783733606338501)]
computing accuracy for after removing block 35 . block score: 0.011310735484585166
removed block 35 current accuracy 0.9432 loss from initial  0.008199999999999985
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.013804. All blocks and scores: [(28, 0.013803813606500626), (38, 0.01436423638369888), (27, 0.014404805842787027), (26, 0.01615672162733972), (37, 0.017430038889870048), (43, 0.020259795943275094), (46, 0.020278667332604527), (41, 0.022076755994930863), (25, 0.022296754410490394), (23, 0.022512756986543536), (44, 0.023720891680568457), (45, 0.023773193359375), (48, 0.02381798578426242), (50, 0.02439475362189114), (40, 0.024757164530456066), (21, 0.02489111479371786), (49, 0.02512287860736251), (22, 0.02523609297350049), (42, 0.02587299351580441), (24, 0.025992544135078788), (20, 0.027153700357303023), (47, 0.02782383654266596), (15, 0.03209114074707031), (19, 0.03256545448675752), (7, 0.03264056518673897), (39, 0.033526239451020956), (51, 0.039224677719175816), (9, 0.04411967797204852), (6, 0.04634959110990167), (4, 0.04648973233997822), (14, 0.047909257002174854), (2, 0.05402393825352192), (3, 0.05759594822302461), (13, 0.05953677976503968), (11, 0.059583188500255346), (17, 0.06158253038302064), (52, 0.06365927262231708), (0, 0.06415853556245565), (1, 0.06604998093098402), (8, 0.0743277259171009), (10, 0.08083636313676834), (16, 0.08421198837459087), (12, 0.09030438028275967), (5, 0.10604929458349943), (36, 0.35626304522156715), (18, 0.5122412145137787), (53, 0.8142293766140938)]
computing accuracy for after removing block 28 . block score: 0.013803813606500626
removed block 28 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 27, with score 0.014405. All blocks and scores: [(27, 0.014404805842787027), (38, 0.014579982263967395), (26, 0.016156722093001008), (37, 0.017823200207203627), (46, 0.020162716740742326), (43, 0.02060258504934609), (25, 0.02229675487615168), (23, 0.02251275721937418), (41, 0.022527431370690465), (45, 0.023862562142312527), (48, 0.023910911520943046), (44, 0.024234434822574258), (50, 0.024423159658908844), (40, 0.024832544615492225), (21, 0.024891114560887218), (49, 0.02502039005048573), (22, 0.025236093206331134), (24, 0.02599254483357072), (42, 0.026276175398379564), (20, 0.02715370082296431), (47, 0.027326363837346435), (15, 0.0320911412127316), (19, 0.03256545588374138), (7, 0.032640565652400255), (39, 0.03413631394505501), (51, 0.03955053864046931), (9, 0.04411967843770981), (6, 0.04634959110990167), (4, 0.046489732805639505), (14, 0.04790925607085228), (2, 0.05402393965050578), (3, 0.05759594636037946), (13, 0.05953678209334612), (11, 0.059583188965916634), (17, 0.061582529451698065), (0, 0.0641585374251008), (52, 0.0642910972237587), (1, 0.06604997906833887), (8, 0.07432772684842348), (10, 0.08083636499941349), (16, 0.08421198651194572), (12, 0.09030438121408224), (5, 0.106049295514822), (36, 0.3657974824309349), (18, 0.5122412145137787), (53, 0.8137559071183205)]
computing accuracy for after removing block 27 . block score: 0.014404805842787027
removed block 27 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.014754. All blocks and scores: [(38, 0.014753622119314969), (26, 0.016156721394509077), (37, 0.01822343491949141), (46, 0.02004738198593259), (43, 0.020940426271408796), (25, 0.022296755108982325), (23, 0.022512756753712893), (41, 0.022677954751998186), (45, 0.023819871246814728), (48, 0.0239909952506423), (50, 0.024115966632962227), (49, 0.024441611487418413), (44, 0.024467115756124258), (21, 0.02489111525937915), (40, 0.024923610733821988), (22, 0.025236093904823065), (24, 0.02599254436790943), (42, 0.026310050394386053), (47, 0.02638079971075058), (20, 0.027153700590133667), (15, 0.03209114074707031), (19, 0.03256545541808009), (7, 0.03264056611806154), (39, 0.034412311390042305), (51, 0.03882467467337847), (9, 0.04411967843770981), (6, 0.046349591575562954), (4, 0.04648973233997822), (14, 0.04790925793349743), (2, 0.05402394197881222), (3, 0.05759594729170203), (13, 0.05953677976503968), (11, 0.059583190362900496), (17, 0.061582532711327076), (52, 0.06325189489871264), (0, 0.06415853556245565), (1, 0.06604998093098402), (8, 0.0743277259171009), (10, 0.08083636313676834), (16, 0.08421198651194572), (12, 0.09030437842011452), (5, 0.10604929458349943), (36, 0.3735954724252224), (18, 0.5122412070631981), (53, 0.8183890283107758)]
computing accuracy for after removing block 38 . block score: 0.014753622119314969
removed block 38 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.016157. All blocks and scores: [(26, 0.016156721860170364), (37, 0.018223434453830123), (46, 0.019315861398354173), (43, 0.02013062429614365), (41, 0.021420821314677596), (25, 0.022296755341812968), (48, 0.022378924768418074), (23, 0.022512756753712893), (45, 0.022515250369906425), (50, 0.02265049866400659), (49, 0.023441024124622345), (44, 0.023516426095739007), (40, 0.02479491801932454), (47, 0.024848951026797295), (42, 0.024855355266481638), (21, 0.024891114328056574), (22, 0.025236092507839203), (24, 0.025992544600740075), (20, 0.027153699891641736), (15, 0.03209114074707031), (19, 0.03256545355543494), (7, 0.03264056611806154), (39, 0.035171191208064556), (51, 0.0379962925799191), (9, 0.04411967843770981), (6, 0.04634959064424038), (4, 0.04648973187431693), (14, 0.04790925746783614), (2, 0.05402394011616707), (3, 0.05759594589471817), (13, 0.05953678069636226), (11, 0.059583188965916634), (52, 0.06031702784821391), (17, 0.06158253084868193), (0, 0.06415853556245565), (1, 0.06604998093098402), (8, 0.07432772777974606), (10, 0.08083636593073606), (16, 0.08421198837459087), (12, 0.09030437935143709), (5, 0.10604929272085428), (36, 0.3735954761505127), (18, 0.5122412145137787), (53, 0.8386472910642624)]
computing accuracy for after removing block 26 . block score: 0.016156721860170364
removed block 26 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 37, with score 0.017622. All blocks and scores: [(37, 0.017622399143874645), (46, 0.018877977039664984), (43, 0.019654452800750732), (41, 0.020531897665932775), (48, 0.021730957087129354), (50, 0.021932935109362006), (45, 0.022138877538964152), (25, 0.022296755341812968), (23, 0.022512756288051605), (49, 0.023017992498353124), (44, 0.02332595596089959), (42, 0.02347473055124283), (40, 0.02402771101333201), (47, 0.02429597987793386), (21, 0.02489111409522593), (22, 0.025236093439161777), (24, 0.02599254436790943), (20, 0.02715370012447238), (15, 0.03209114074707031), (19, 0.03256545541808009), (7, 0.03264056611806154), (39, 0.034304351545870304), (51, 0.03654240630567074), (9, 0.04411967843770981), (6, 0.04634959204122424), (4, 0.04648973047733307), (14, 0.047909257002174854), (2, 0.05402394104748964), (3, 0.05759594589471817), (52, 0.05787501111626625), (13, 0.05953678023070097), (11, 0.05958318756893277), (17, 0.06158253084868193), (0, 0.0641585336998105), (1, 0.06604997999966145), (8, 0.07432772498577833), (10, 0.08083636406809092), (16, 0.0842119874432683), (12, 0.09030438028275967), (5, 0.10604929458349943), (36, 0.36510972678661346), (18, 0.5122412219643593), (53, 0.8653944209218025)]
computing accuracy for after removing block 37 . block score: 0.017622399143874645
removed block 37 current accuracy 0.9264 loss from initial  0.025000000000000022
training start
training epoch 0 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 1 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 2 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.1]
training epoch 3 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 4 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 5 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.1]
training epoch 6 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 7 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.1]
training epoch 8 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.1]
training epoch 9 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.014450. All blocks and scores: [(41, 0.014449801645241678), (42, 0.016457466408610344), (40, 0.018707974813878536), (23, 0.022532161558046937), (46, 0.02303681569173932), (43, 0.024886684492230415), (21, 0.025262618670240045), (22, 0.025572413811460137), (50, 0.026246295543387532), (49, 0.026586782885715365), (48, 0.02703406964428723), (45, 0.02735807909630239), (20, 0.02740191202610731), (44, 0.027404175838455558), (47, 0.031159564619883895), (39, 0.03219851152971387), (15, 0.03226593416184187), (19, 0.03238478861749172), (7, 0.032610546331852674), (25, 0.03885147860273719), (51, 0.04179698321968317), (9, 0.044014422222971916), (24, 0.04587015276774764), (6, 0.04651923384517431), (4, 0.04766723280772567), (14, 0.048315112479031086), (2, 0.05469226138666272), (3, 0.057936585042625666), (13, 0.05971546703949571), (11, 0.05999889271333814), (17, 0.06287667527794838), (0, 0.06380873452872038), (1, 0.0665253633633256), (52, 0.06713245064020157), (8, 0.075207713060081), (10, 0.08134971931576729), (16, 0.0866399547085166), (12, 0.09077190514653921), (5, 0.10655071586370468), (36, 0.44162049517035484), (18, 0.5171660035848618), (53, 0.8053070604801178)]
computing accuracy for after removing block 41 . block score: 0.014449801645241678
removed block 41 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.016412. All blocks and scores: [(42, 0.016411760821938515), (40, 0.018707975279539824), (23, 0.022532161325216293), (46, 0.02264622924849391), (21, 0.025262619368731976), (22, 0.025572413578629494), (43, 0.025703494204208255), (50, 0.025824198499321938), (48, 0.026308784261345863), (49, 0.02632554084993899), (45, 0.026975499466061592), (20, 0.027401912258937955), (44, 0.028170379577204585), (47, 0.03114114375784993), (39, 0.03219851013273001), (15, 0.03226593462750316), (19, 0.03238478722050786), (7, 0.03261054586619139), (25, 0.03885147860273719), (51, 0.04109238972887397), (9, 0.044014422222971916), (24, 0.04587015137076378), (6, 0.04651923477649689), (4, 0.04766723467037082), (14, 0.0483151120133698), (2, 0.054692262783646584), (3, 0.057936586905270815), (13, 0.059715468902140856), (11, 0.05999889364466071), (17, 0.06287666969001293), (0, 0.06380873546004295), (1, 0.06652536429464817), (52, 0.06729811429977417), (8, 0.07520771026611328), (10, 0.08134971745312214), (16, 0.08663995284587145), (12, 0.09077190700918436), (5, 0.10655071772634983), (36, 0.44162048771977425), (18, 0.517166018486023), (53, 0.8238575309514999)]
computing accuracy for after removing block 42 . block score: 0.016411760821938515
removed block 42 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.018708. All blocks and scores: [(40, 0.01870797504670918), (23, 0.022532162023708224), (46, 0.022630212362855673), (50, 0.024803297594189644), (21, 0.025262620067223907), (49, 0.02539098123088479), (22, 0.025572413112968206), (48, 0.025688823778182268), (43, 0.02656690333969891), (45, 0.02673989161849022), (20, 0.027401913655921817), (44, 0.029138550395146012), (47, 0.030748634599149227), (39, 0.03219851106405258), (15, 0.03226593369618058), (19, 0.03238478768616915), (7, 0.03261054586619139), (25, 0.038851479068398476), (51, 0.04060977324843407), (9, 0.04401442361995578), (24, 0.045870151836425066), (6, 0.04651923244819045), (4, 0.04766723373904824), (14, 0.048315112479031086), (2, 0.054692262317985296), (3, 0.057936585042625666), (13, 0.059715468902140856), (11, 0.05999889271333814), (17, 0.06287667294964194), (0, 0.06380873546004295), (52, 0.06614349223673344), (1, 0.06652536429464817), (8, 0.0752077093347907), (10, 0.08134972117841244), (16, 0.08663995284587145), (12, 0.09077190235257149), (5, 0.10655071679502726), (36, 0.44162049889564514), (18, 0.5171660110354424), (53, 0.8470752760767937)]
computing accuracy for after removing block 40 . block score: 0.01870797504670918
removed block 40 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 46, with score 0.021786. All blocks and scores: [(46, 0.02178613911382854), (23, 0.02253216179087758), (50, 0.02357638766989112), (48, 0.024004728998988867), (49, 0.024857415817677975), (21, 0.02526261960156262), (22, 0.02557241334579885), (43, 0.02616765210404992), (45, 0.026277918368577957), (20, 0.027401912724599242), (47, 0.030335164396092296), (44, 0.03037460381165147), (39, 0.03219851152971387), (15, 0.03226593369618058), (19, 0.03238478675484657), (7, 0.03261054586619139), (25, 0.0388514781370759), (51, 0.03993789851665497), (9, 0.04401442175731063), (24, 0.04587015137076378), (6, 0.04651923291385174), (4, 0.04766723467037082), (14, 0.04831511294469237), (2, 0.05469226045534015), (3, 0.05793658643960953), (13, 0.05971546610817313), (11, 0.059998893178999424), (17, 0.06287667201831937), (0, 0.0638087373226881), (52, 0.06444939225912094), (1, 0.06652536056935787), (8, 0.0752077093347907), (10, 0.08134971652179956), (16, 0.0866399547085166), (12, 0.09077190328389406), (5, 0.10655071306973696), (36, 0.44162049889564514), (18, 0.5171660110354424), (53, 0.895074687898159)]
computing accuracy for after removing block 46 . block score: 0.02178613911382854
removed block 46 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.022532. All blocks and scores: [(23, 0.02253216179087758), (50, 0.024409085046499968), (48, 0.024664118653163314), (21, 0.025262618670240045), (22, 0.025572413578629494), (49, 0.026051208842545748), (43, 0.02616765256971121), (45, 0.026277916971594095), (20, 0.02740191202610731), (44, 0.030374604044482112), (39, 0.03219851152971387), (15, 0.03226593369618058), (19, 0.03238478768616915), (7, 0.03261054726317525), (47, 0.03276137541979551), (25, 0.038851477671414614), (51, 0.04023544630035758), (9, 0.044014420825988054), (24, 0.045870151836425066), (6, 0.04651923477649689), (4, 0.04766723373904824), (14, 0.04831511294469237), (2, 0.05469226324930787), (3, 0.05793658411130309), (13, 0.05971546703949571), (11, 0.05999889364466071), (17, 0.06287667388096452), (0, 0.06380873452872038), (52, 0.06515636015683413), (1, 0.06652536150068045), (8, 0.07520770840346813), (10, 0.08134971838444471), (16, 0.0866399547085166), (12, 0.09077190700918436), (5, 0.10655071586370468), (36, 0.44162049889564514), (18, 0.5171660035848618), (53, 0.995203971862793)]
computing accuracy for after removing block 23 . block score: 0.02253216179087758
removed block 23 current accuracy 0.9216 loss from initial  0.02980000000000005
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.023515. All blocks and scores: [(50, 0.023514691973105073), (48, 0.023879806511104107), (21, 0.025262619135901332), (22, 0.02557241264730692), (49, 0.025624385569244623), (45, 0.025970066664740443), (43, 0.026270268950611353), (20, 0.027401913423091173), (44, 0.02954919566400349), (47, 0.03153733676299453), (39, 0.03193894028663635), (15, 0.03226593369618058), (19, 0.03238478908315301), (7, 0.032610546331852674), (25, 0.03859754092991352), (51, 0.0393640105612576), (24, 0.043760675471276045), (9, 0.044014422222971916), (6, 0.04651923384517431), (4, 0.047667233273386955), (14, 0.048315112479031086), (2, 0.05469226185232401), (3, 0.0579365873709321), (13, 0.05971546703949571), (11, 0.059998891316354275), (52, 0.062246177811175585), (17, 0.06287667294964194), (0, 0.06380873452872038), (1, 0.06652536243200302), (8, 0.07520771026611328), (10, 0.08134972024708986), (16, 0.08663995284587145), (12, 0.09077190328389406), (5, 0.10655071958899498), (36, 0.43690095841884613), (18, 0.5171660259366035), (53, 1.0165062621235847)]
computing accuracy for after removing block 50 . block score: 0.023514691973105073
removed block 50 current accuracy 0.914 loss from initial  0.03739999999999999
training start
training epoch 0 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 1 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 2 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 3 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 5 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.1]
training epoch 8 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 9 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 18
[activation diff]: block to remove picked: 20, with score 0.027050. All blocks and scores: [(20, 0.02704992122016847), (15, 0.03218724112957716), (7, 0.03232809389010072), (19, 0.03256238857284188), (21, 0.034721774980425835), (22, 0.035132503136992455), (49, 0.036973555106669664), (48, 0.039016542956233025), (43, 0.04294534772634506), (45, 0.04389987885951996), (9, 0.043969137128442526), (44, 0.044686323031783104), (6, 0.04635124700143933), (14, 0.04768818477168679), (4, 0.048377348110079765), (47, 0.049639398232102394), (51, 0.04976685531437397), (2, 0.05481629632413387), (25, 0.058135449420660734), (3, 0.05815262766554952), (11, 0.05930148996412754), (13, 0.059426816180348396), (52, 0.06144509604200721), (24, 0.061937985476106405), (17, 0.06201014434918761), (0, 0.0632014274597168), (1, 0.06549391150474548), (8, 0.07376506645232439), (10, 0.08091461285948753), (16, 0.08538242895156145), (39, 0.08567022532224655), (12, 0.08988482505083084), (5, 0.10577056556940079), (18, 0.5119056329131126), (36, 0.6630948111414909), (53, 1.2922046482563019)]
computing accuracy for after removing block 20 . block score: 0.02704992122016847
removed block 20 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 15, with score 0.032187. All blocks and scores: [(15, 0.03218724252656102), (7, 0.03232809575274587), (19, 0.03256238903850317), (22, 0.034284398425370455), (21, 0.03472155099734664), (49, 0.0366408871486783), (48, 0.038864619098603725), (43, 0.0422220709733665), (45, 0.04318041866645217), (9, 0.043969137128442526), (44, 0.04428414162248373), (6, 0.046351246535778046), (47, 0.04728812491521239), (14, 0.04768818523734808), (51, 0.04824616899713874), (4, 0.04837734857574105), (2, 0.05481629632413387), (25, 0.05660545825958252), (3, 0.05815262859687209), (52, 0.05880705965682864), (11, 0.05930149042978883), (13, 0.059426816646009684), (24, 0.059977222699671984), (17, 0.06201014667749405), (0, 0.0632014274597168), (1, 0.06549391336739063), (8, 0.07376506645232439), (10, 0.08091461285948753), (39, 0.08396733831614256), (16, 0.0853824270889163), (12, 0.08988482691347599), (5, 0.10577056556940079), (18, 0.5119056180119514), (36, 0.6542521268129349), (53, 1.2803934514522552)]
computing accuracy for after removing block 15 . block score: 0.03218724252656102
removed block 15 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.032033. All blocks and scores: [(22, 0.032033467665314674), (7, 0.03232809528708458), (21, 0.03235936164855957), (19, 0.03287977585569024), (49, 0.03717278270050883), (48, 0.04043350461870432), (44, 0.043313536792993546), (43, 0.04331557638943195), (9, 0.04396913619711995), (45, 0.0442962315864861), (6, 0.04635124607011676), (14, 0.04768818477168679), (4, 0.0483773467130959), (47, 0.04872995801270008), (51, 0.04889664612710476), (25, 0.05460191331803799), (2, 0.054816295858472586), (24, 0.05689091235399246), (3, 0.058152628131210804), (11, 0.05930149042978883), (13, 0.05942681897431612), (52, 0.0598593195900321), (0, 0.0632014274597168), (1, 0.06549391057342291), (17, 0.06585641298443079), (8, 0.07376506645232439), (10, 0.08091461472213268), (39, 0.0837028007954359), (12, 0.08988482411950827), (16, 0.09535357542335987), (5, 0.10577056650072336), (18, 0.49927451089024544), (36, 0.6470796540379524), (53, 1.2981446385383606)]
computing accuracy for after removing block 22 . block score: 0.032033467665314674
removed block 22 current accuracy 0.922 loss from initial  0.02939999999999998
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 7, with score 0.032328. All blocks and scores: [(7, 0.032328094355762005), (21, 0.032359360717236996), (19, 0.03287977585569024), (49, 0.035512073431164026), (48, 0.038218798115849495), (44, 0.04134893463924527), (43, 0.04157549748197198), (9, 0.04396913526579738), (45, 0.044333670288324356), (47, 0.0457162787206471), (51, 0.0462418282404542), (6, 0.04635124607011676), (14, 0.04768818570300937), (4, 0.0483773467130959), (24, 0.05233974987640977), (25, 0.05268569244071841), (2, 0.05481629492715001), (52, 0.0550464503467083), (3, 0.05815262766554952), (11, 0.059301489032804966), (13, 0.059426816180348396), (0, 0.0632014274597168), (1, 0.06549391243606806), (17, 0.06585641112178564), (8, 0.07376506924629211), (10, 0.08091461192816496), (39, 0.08333418611437082), (12, 0.08988482225686312), (16, 0.09535357542335987), (5, 0.10577056370675564), (18, 0.49927451834082603), (36, 0.6334956586360931), (53, 1.305017203092575)]
computing accuracy for after removing block 7 . block score: 0.032328094355762005
removed block 7 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.031548. All blocks and scores: [(21, 0.03154781740158796), (19, 0.03271587612107396), (49, 0.035092359874397516), (48, 0.03526384476572275), (43, 0.03958246111869812), (44, 0.041313047520816326), (9, 0.043880765326321125), (14, 0.044086620677262545), (45, 0.04497474431991577), (47, 0.04497785121202469), (51, 0.04588951030746102), (6, 0.046351245138794184), (4, 0.04837734764441848), (24, 0.04931244347244501), (25, 0.05082100350409746), (13, 0.0514543242752552), (52, 0.053298329934477806), (2, 0.0548162953928113), (17, 0.05575966741889715), (11, 0.05602071154862642), (3, 0.058152628131210804), (0, 0.06320142652839422), (1, 0.06549391336739063), (8, 0.07169205695390701), (39, 0.08208752144128084), (10, 0.08317536674439907), (12, 0.08398028742522001), (16, 0.0868078013882041), (5, 0.10577056836336851), (18, 0.48282474651932716), (36, 0.6139582544565201), (53, 1.3228123635053635)]
computing accuracy for after removing block 21 . block score: 0.03154781740158796
removed block 21 current accuracy 0.906 loss from initial  0.045399999999999996
since last training loss: 0.03699999999999992 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 19, with score 0.032716. All blocks and scores: [(19, 0.03271587658673525), (48, 0.033123386558145285), (49, 0.033584391232579947), (43, 0.03696557693183422), (44, 0.03934580646455288), (47, 0.04175653075799346), (51, 0.0438667768612504), (9, 0.04388076486065984), (14, 0.044086618814617395), (45, 0.04440952744334936), (24, 0.044978342950344086), (6, 0.04635124560445547), (25, 0.047877517994493246), (52, 0.04805450653657317), (4, 0.04837734857574105), (13, 0.0514543242752552), (2, 0.054816294461488724), (17, 0.05575966648757458), (11, 0.056020712945610285), (3, 0.05815262906253338), (0, 0.06320142932236195), (1, 0.06549391243606806), (8, 0.07169205788522959), (39, 0.08240478672087193), (10, 0.0831753658130765), (12, 0.08398028835654259), (16, 0.08680780231952667), (5, 0.10577056650072336), (18, 0.48282473161816597), (36, 0.5861429423093796), (53, 1.3369888216257095)]
computing accuracy for after removing block 19 . block score: 0.03271587658673525
removed block 19 current accuracy 0.8862 loss from initial  0.06520000000000004
since last training loss: 0.05679999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.032118. All blocks and scores: [(48, 0.03211781894788146), (49, 0.032585172448307276), (43, 0.036379590164870024), (44, 0.037776552606374025), (47, 0.03908552788197994), (51, 0.042519035283476114), (45, 0.04295538226142526), (9, 0.043880763463675976), (14, 0.044086620677262545), (52, 0.04499596310779452), (24, 0.04509313264861703), (25, 0.04542069789022207), (6, 0.04635124607011676), (4, 0.048377346247434616), (13, 0.0514543242752552), (2, 0.05481629492715001), (17, 0.055759665556252), (11, 0.05602071154862642), (3, 0.05815263045951724), (0, 0.0632014274597168), (1, 0.06549391243606806), (8, 0.07169205881655216), (39, 0.08138270303606987), (10, 0.0831753658130765), (12, 0.08398028649389744), (16, 0.0868078013882041), (5, 0.10577056650072336), (18, 0.48282475024461746), (36, 0.5825361087918282), (53, 1.3239649832248688)]
computing accuracy for after removing block 48 . block score: 0.03211781894788146
removed block 48 current accuracy 0.8724 loss from initial  0.07900000000000007
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 43, with score 0.036380. All blocks and scores: [(43, 0.03637958923354745), (49, 0.03725094813853502), (44, 0.0377765535376966), (47, 0.03908552834764123), (45, 0.04295538319274783), (9, 0.043880763463675976), (51, 0.043950452003628016), (14, 0.044086618814617395), (24, 0.04509313218295574), (25, 0.045420697424560785), (6, 0.04635124560445547), (4, 0.04837734950706363), (52, 0.05136730708181858), (13, 0.05145432474091649), (2, 0.05481629678979516), (17, 0.055759665556252), (11, 0.056020709685981274), (3, 0.05815262719988823), (0, 0.06320142652839422), (1, 0.06549391150474548), (8, 0.07169205974787474), (39, 0.08138270489871502), (10, 0.08317536488175392), (12, 0.08398028556257486), (16, 0.0868078013882041), (5, 0.10577056277543306), (18, 0.48282476142048836), (36, 0.5825361236929893), (53, 1.428019031882286)]
computing accuracy for after removing block 43 . block score: 0.03637958923354745
removed block 43 current accuracy 0.8628 loss from initial  0.08860000000000001
since last training loss: 0.08019999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.038092. All blocks and scores: [(49, 0.038092092610895634), (47, 0.041087095625698566), (44, 0.04260256281122565), (51, 0.04320496879518032), (9, 0.043880763463675976), (14, 0.044086620677262545), (24, 0.045093131717294455), (25, 0.04542069789022207), (45, 0.04557349905371666), (6, 0.04635124746710062), (4, 0.04837734764441848), (52, 0.05086743738502264), (13, 0.0514543242752552), (2, 0.054816295858472586), (17, 0.05575966788455844), (11, 0.056020712479949), (3, 0.058152629528194666), (0, 0.0632014274597168), (1, 0.06549391336739063), (8, 0.07169205695390701), (39, 0.08138270303606987), (10, 0.08317536767572165), (12, 0.08398028928786516), (16, 0.08680780231952667), (5, 0.10577056650072336), (18, 0.48282474279403687), (36, 0.5825361385941505), (53, 1.461146429181099)]
computing accuracy for after removing block 49 . block score: 0.038092092610895634
removed block 49 current accuracy 0.8358 loss from initial  0.11560000000000004
training start
training epoch 0 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best False lr [0.1]
training epoch 1 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best True lr [0.1]
training epoch 2 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 3 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 4 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 5 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 6 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 7 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 9 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
