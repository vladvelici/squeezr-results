start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294660835526884), (29, 0.013421116396784782), (35, 0.01595769007690251), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019996492192149162), (46, 0.020590224536135793), (25, 0.022078295471146703), (23, 0.022228715708479285), (41, 0.022336416179314256), (44, 0.023145998595282435), (40, 0.023749591084197164), (45, 0.023975494550541043), (21, 0.02494108979590237), (48, 0.024957706918939948), (22, 0.025151390582323074), (50, 0.025287174154073), (24, 0.025880582397803664), (49, 0.025916648097336292), (42, 0.02623223210684955), (20, 0.026848892215639353), (47, 0.028632948407903314), (38, 0.0313443448394537), (39, 0.03144129551947117), (15, 0.03205838380381465), (7, 0.032445503398776054), (19, 0.03254077956080437), (37, 0.0379180321469903), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.06606104131788015), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119243667460978), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.01985268690623343), (46, 0.02030070498585701), (41, 0.02186027471907437), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02297719265334308), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.02494109026156366), (22, 0.0251513896510005), (49, 0.025575740728527308), (24, 0.025880583096295595), (42, 0.025893412996083498), (20, 0.026848891749978065), (47, 0.028072759741917253), (38, 0.031091187614947557), (39, 0.031191361602395773), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114332690835), (36, 0.4339806064963341), (18, 0.5117433071136475), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.01607214054092765), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.021827629301697016), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.023602579021826386), (45, 0.02377084898762405), (48, 0.024519873084500432), (50, 0.024639351293444633), (21, 0.02494108979590237), (22, 0.025151390582323074), (49, 0.025392549578100443), (42, 0.025712219765409827), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.028052504640072584), (38, 0.0309358739759773), (39, 0.031173035968095064), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464833632112), (52, 0.06441722763702273), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4350203089416027), (18, 0.5117432996630669), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160194374621), (29, 0.013421117211692035), (35, 0.015918649500235915), (26, 0.016072141705080867), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.02175602037459612), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463105481117964), (21, 0.02494108979590237), (22, 0.025151390582323074), (49, 0.02524693077430129), (42, 0.025273551465943456), (24, 0.025880583794787526), (20, 0.026848891749978065), (47, 0.02772757480852306), (38, 0.03074627462774515), (39, 0.031281795585528016), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03895266819745302), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.06132525717839599), (0, 0.06337464833632112), (52, 0.06356756435707211), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829354047775)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116746030748), (35, 0.01596891158260405), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.02268732455559075), (40, 0.023569097742438316), (45, 0.023840720998123288), (48, 0.024108358891680837), (50, 0.02411420992575586), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.025045575108379126), (22, 0.025151390815153718), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027423851657658815), (38, 0.03073564823716879), (39, 0.03141042497009039), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003176480532), (17, 0.06132525438442826), (52, 0.06270107952877879), (0, 0.06337464461103082), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.43692684918642044), (18, 0.5117432773113251), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.02030268427915871), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.02222871477715671), (44, 0.02304507768712938), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.024156817002221942), (45, 0.02416840847581625), (49, 0.024922372540459037), (21, 0.024941089563071728), (22, 0.025151390116661787), (42, 0.025816059904173017), (24, 0.025880581932142377), (20, 0.026848891749978065), (47, 0.02756829489953816), (38, 0.03178726346231997), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621210232377), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.061325253918766975), (52, 0.062210948672145605), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.44933703541755676), (18, 0.5117433071136475), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.1]
training epoch 1 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.1]
training epoch 2 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.1]
training epoch 3 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.1]
training epoch 4 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.1]
training epoch 5 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.1]
training epoch 6 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.1]
training epoch 7 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.1]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.1]
training epoch 9 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.1]
training epoch 10 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.014840. All blocks and scores: [(26, 0.014839697745628655), (28, 0.014911368838511407), (35, 0.015459953108802438), (25, 0.017481870483607054), (27, 0.017540102126076818), (43, 0.019976934883743525), (46, 0.020481259562075138), (24, 0.021223528310656548), (41, 0.02222951129078865), (23, 0.022545057581737638), (44, 0.023125553503632545), (40, 0.023725854931399226), (45, 0.023785562021657825), (48, 0.024794830242171884), (21, 0.025078711798414588), (50, 0.02514548529870808), (22, 0.025349721778184175), (42, 0.025541309732943773), (49, 0.025778949027881026), (20, 0.027163532562553883), (47, 0.02846784726716578), (38, 0.03136244090273976), (39, 0.03143625636585057), (15, 0.032240241300314665), (19, 0.03258239710703492), (7, 0.03268954157829285), (37, 0.03798164101317525), (51, 0.04083612281829119), (9, 0.04413829185068607), (6, 0.046752568800002337), (14, 0.04784265486523509), (4, 0.04791947593912482), (2, 0.05492281587794423), (3, 0.05856972141191363), (13, 0.059298241045325994), (11, 0.05946645047515631), (17, 0.06210217019543052), (0, 0.06419066246598959), (52, 0.06529666809365153), (1, 0.06677951198071241), (8, 0.07425730209797621), (10, 0.08089236728847027), (16, 0.08451640605926514), (12, 0.09039716608822346), (5, 0.10669594630599022), (36, 0.4334256388247013), (18, 0.5126336812973022), (53, 0.8087317124009132)]
computing accuracy for after removing block 26 . block score: 0.014839697745628655
removed block 26 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.014685. All blocks and scores: [(35, 0.014684792840853333), (28, 0.014930106583051383), (25, 0.017481870716437697), (27, 0.017703072633594275), (43, 0.0199574192520231), (46, 0.020427613519132137), (24, 0.02122352854348719), (41, 0.022158623905852437), (23, 0.02254505711607635), (44, 0.02348456857725978), (40, 0.023806463927030563), (45, 0.02383750188164413), (48, 0.024773086654022336), (42, 0.024879194097593427), (50, 0.02496958989650011), (21, 0.025078710401430726), (22, 0.02534972270950675), (49, 0.025955594843253493), (20, 0.027163532096892595), (47, 0.02839355100877583), (38, 0.03171370644122362), (39, 0.031898715533316135), (15, 0.032240241300314665), (19, 0.032582396641373634), (7, 0.032689540181308985), (37, 0.038753749802708626), (51, 0.03994834003970027), (9, 0.04413829185068607), (6, 0.0467525664716959), (14, 0.04784265626221895), (4, 0.0479194768704474), (2, 0.05492281401529908), (3, 0.05856972234323621), (13, 0.05929824197664857), (11, 0.05946645187214017), (17, 0.062102170661091805), (0, 0.06419066246598959), (52, 0.0644464478828013), (1, 0.06677951291203499), (8, 0.07425730116665363), (10, 0.08089236356317997), (16, 0.08451640699058771), (12, 0.09039716608822346), (5, 0.10669594537466764), (36, 0.43690846860408783), (18, 0.512633666396141), (53, 0.8221801221370697)]
computing accuracy for after removing block 35 . block score: 0.014684792840853333
removed block 35 current accuracy 0.9392 loss from initial  0.012199999999999989
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.014930. All blocks and scores: [(28, 0.01493010576814413), (25, 0.017481870483607054), (27, 0.017703072633594275), (43, 0.01871091267094016), (46, 0.019219123758375645), (41, 0.020288960076868534), (24, 0.02122352854348719), (40, 0.022351346211507916), (42, 0.022536412114277482), (23, 0.022545057581737638), (45, 0.022692715749144554), (48, 0.02291558193974197), (44, 0.02298737899400294), (50, 0.02308579650707543), (49, 0.024592492496594787), (21, 0.025078710401430726), (22, 0.025349722243845463), (47, 0.027021046029403806), (20, 0.027163532096892595), (39, 0.029640535358339548), (38, 0.029856921639293432), (15, 0.03224024223163724), (19, 0.032582396641373634), (7, 0.03268954157829285), (37, 0.035789855755865574), (51, 0.03763233404606581), (9, 0.044138291385024786), (6, 0.046752565540373325), (14, 0.04784265719354153), (4, 0.04791947640478611), (2, 0.054922814946621656), (3, 0.05856972141191363), (13, 0.05929824337363243), (52, 0.059308554045856), (11, 0.059466450940817595), (17, 0.062102170661091805), (0, 0.06419066153466702), (1, 0.06677951477468014), (8, 0.07425730302929878), (10, 0.08089236356317997), (16, 0.08451640512794256), (12, 0.09039716701954603), (5, 0.1066959435120225), (36, 0.41650083288550377), (18, 0.512633666396141), (53, 0.8663220703601837)]
computing accuracy for after removing block 28 . block score: 0.01493010576814413
removed block 28 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.017482. All blocks and scores: [(25, 0.017481870716437697), (27, 0.01770307356491685), (43, 0.018291639164090157), (46, 0.018680419540032744), (41, 0.020003559300675988), (24, 0.021223528077825904), (40, 0.02204454643651843), (42, 0.02205145452171564), (48, 0.022251623449847102), (23, 0.02254505641758442), (45, 0.02260248432867229), (50, 0.02266048453748226), (44, 0.02308073826134205), (49, 0.024140866240486503), (21, 0.025078711099922657), (22, 0.025349722243845463), (47, 0.026312900707125664), (20, 0.02716353302821517), (38, 0.029318147338926792), (39, 0.02943281759507954), (15, 0.03224024083465338), (19, 0.03258239757269621), (7, 0.032689542043954134), (37, 0.03514894237741828), (51, 0.03705619368702173), (9, 0.0441382909193635), (6, 0.0467525664716959), (14, 0.04784265719354153), (4, 0.04791947640478611), (2, 0.05492281634360552), (52, 0.05792456353083253), (3, 0.05856972048059106), (13, 0.05929824337363243), (11, 0.059466449078172445), (17, 0.062102170661091805), (0, 0.06419066432863474), (1, 0.06677951384335756), (8, 0.07425730396062136), (10, 0.08089236542582512), (16, 0.08451640699058771), (12, 0.0903971679508686), (5, 0.10669594071805477), (36, 0.41573191434144974), (18, 0.512633666396141), (53, 0.8808054029941559)]
computing accuracy for after removing block 25 . block score: 0.017481870716437697
removed block 25 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 27, with score 0.017911. All blocks and scores: [(27, 0.017911215545609593), (46, 0.018582252552732825), (43, 0.018625353230163455), (41, 0.020542353158816695), (24, 0.021223529241979122), (48, 0.022240041056647897), (50, 0.02239213651046157), (42, 0.022400441812351346), (23, 0.02254505711607635), (40, 0.022608588682487607), (45, 0.022868270985782146), (44, 0.023367008194327354), (49, 0.023803515126928687), (21, 0.025078711099922657), (22, 0.025349722476676106), (47, 0.026074668392539024), (20, 0.027163532562553883), (38, 0.030166370328515768), (39, 0.030398958129808307), (15, 0.03224024223163724), (19, 0.032582396641373634), (7, 0.032689542043954134), (51, 0.03652597963809967), (37, 0.037191074807196856), (9, 0.04413829185068607), (6, 0.04675256833434105), (14, 0.04784265626221895), (4, 0.047919475473463535), (2, 0.054922814946621656), (52, 0.0565261822193861), (3, 0.05856972187757492), (13, 0.05929824197664857), (11, 0.05946645047515631), (17, 0.06210216972976923), (0, 0.06419066525995731), (1, 0.06677951384335756), (8, 0.07425730116665363), (10, 0.0808923663571477), (16, 0.08451640512794256), (12, 0.0903971679508686), (5, 0.10669593885540962), (36, 0.42844608053565025), (18, 0.5126336589455605), (53, 0.8807375505566597)]
computing accuracy for after removing block 27 . block score: 0.017911215545609593
removed block 27 current accuracy 0.925 loss from initial  0.02639999999999998
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.018516. All blocks and scores: [(46, 0.018516360549256206), (43, 0.018808726221323013), (41, 0.02096987422555685), (24, 0.021223528310656548), (48, 0.021898079197853804), (50, 0.022022187942638993), (23, 0.022545057348906994), (42, 0.022840787190943956), (40, 0.022946134908124804), (45, 0.02311095572076738), (49, 0.023512167390435934), (44, 0.023566340561956167), (21, 0.025078710867092013), (22, 0.02534972201101482), (47, 0.025357209611684084), (20, 0.027163532795384526), (38, 0.03046169108711183), (39, 0.030902382684871554), (15, 0.03224024176597595), (19, 0.03258239757269621), (7, 0.032689542043954134), (51, 0.03573193587362766), (37, 0.039164543617516756), (9, 0.044138291385024786), (6, 0.0467525664716959), (14, 0.047842653933912516), (4, 0.04791947593912482), (52, 0.05490665836259723), (2, 0.05492281587794423), (3, 0.05856972141191363), (13, 0.05929824197664857), (11, 0.05946645047515631), (17, 0.06210216926410794), (0, 0.06419066246598959), (1, 0.06677951198071241), (8, 0.07425730302929878), (10, 0.08089236821979284), (16, 0.08451640699058771), (12, 0.09039716888219118), (5, 0.1066959397867322), (36, 0.4392922520637512), (18, 0.512633666396141), (53, 0.8862034156918526)]
computing accuracy for after removing block 46 . block score: 0.018516360549256206
removed block 46 current accuracy 0.921 loss from initial  0.030399999999999983
training start
training epoch 0 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 1 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 2 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.1]
training epoch 3 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 4 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 5 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.1]
training epoch 6 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.1]
training epoch 7 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.1]
training epoch 8 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 9 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.009551. All blocks and scores: [(43, 0.009551316150464118), (41, 0.010868614888750017), (45, 0.011310260044410825), (44, 0.012001347378827631), (42, 0.013162156101316214), (47, 0.013288293848745525), (40, 0.023162494879215956), (50, 0.026806964073330164), (49, 0.027791418135166168), (48, 0.028819615021348), (24, 0.029780886135995388), (39, 0.031014652457088232), (38, 0.031352906255051494), (21, 0.03151178522966802), (15, 0.03206620551645756), (7, 0.0324080646969378), (20, 0.032441966235637665), (22, 0.03263841429725289), (19, 0.03274039505049586), (37, 0.038675210904330015), (23, 0.03891843976452947), (51, 0.041385368444025517), (9, 0.043623548932373524), (6, 0.046276303473860025), (14, 0.04755589971318841), (4, 0.048476174008101225), (2, 0.05508084828034043), (3, 0.058256590738892555), (13, 0.05878027528524399), (11, 0.059509203769266605), (17, 0.06199881061911583), (0, 0.06347448704764247), (52, 0.06581500079482794), (1, 0.06595496088266373), (8, 0.07373637799173594), (10, 0.08077486976981163), (16, 0.08484370540827513), (12, 0.08934913482517004), (5, 0.1053180517628789), (36, 0.2772640697658062), (18, 0.5109026357531548), (53, 0.8062341660261154)]
computing accuracy for after removing block 43 . block score: 0.009551316150464118
removed block 43 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.010869. All blocks and scores: [(41, 0.010868615237995982), (45, 0.011704492499120533), (44, 0.01232318568509072), (42, 0.013162156683392823), (47, 0.013285442953929305), (40, 0.023162495577707887), (50, 0.0267222598195076), (49, 0.027263303752988577), (48, 0.028927727369591594), (24, 0.029780885204672813), (39, 0.031014654552564025), (38, 0.03135290858335793), (21, 0.031511785462498665), (15, 0.032066205982118845), (7, 0.032408065628260374), (20, 0.032441966235637665), (22, 0.032638415694236755), (19, 0.032740394584834576), (37, 0.03867521043866873), (23, 0.03891844069585204), (51, 0.040473044849932194), (9, 0.043623550329357386), (6, 0.04627630254253745), (14, 0.04755589831620455), (4, 0.04847617447376251), (2, 0.05508084921166301), (3, 0.05825658841058612), (13, 0.05878027714788914), (11, 0.05950920330360532), (17, 0.06199881015345454), (0, 0.06347448797896504), (52, 0.06396080367267132), (1, 0.06595495995134115), (8, 0.07373637706041336), (10, 0.08077487163245678), (16, 0.08484370913356543), (12, 0.08934913575649261), (5, 0.10531805269420147), (36, 0.2772640585899353), (18, 0.510902613401413), (53, 0.841544896364212)]
computing accuracy for after removing block 41 . block score: 0.010868615237995982
removed block 41 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.011486. All blocks and scores: [(45, 0.011485859984531999), (44, 0.01239841675851494), (42, 0.012425398570485413), (47, 0.012783115613274276), (40, 0.02316249581053853), (50, 0.025362387066707015), (49, 0.02606158284470439), (48, 0.027004461968317628), (24, 0.0297808856703341), (39, 0.031014654552564025), (38, 0.031352907652035356), (21, 0.03151178592815995), (15, 0.032066204119473696), (7, 0.03240806516259909), (20, 0.032441966235637665), (22, 0.03263841429725289), (19, 0.03274039598181844), (51, 0.03810733463615179), (37, 0.03867521043866873), (23, 0.03891843976452947), (9, 0.04362354939803481), (6, 0.046276303473860025), (14, 0.047555898781865835), (4, 0.04847617447376251), (2, 0.05508085060864687), (3, 0.058256588876247406), (13, 0.05878027668222785), (52, 0.05936592165380716), (11, 0.059509203769266605), (17, 0.06199881061911583), (0, 0.06347448704764247), (1, 0.06595495902001858), (8, 0.07373637612909079), (10, 0.08077486976981163), (16, 0.08484370727092028), (12, 0.08934913855046034), (5, 0.1053180517628789), (36, 0.2772640623152256), (18, 0.5109026357531548), (53, 0.8929997533559799)]
computing accuracy for after removing block 45 . block score: 0.011485859984531999
removed block 45 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.012398. All blocks and scores: [(44, 0.01239841675851494), (42, 0.012425398570485413), (47, 0.013245541951619089), (40, 0.02316249581053853), (50, 0.025869566248729825), (49, 0.026613740250468254), (48, 0.027150385780259967), (24, 0.029780885437503457), (39, 0.031014653854072094), (38, 0.03135290672071278), (21, 0.03151178522966802), (15, 0.03206620505079627), (7, 0.0324080646969378), (20, 0.032441966235637665), (22, 0.03263841429725289), (19, 0.03274039598181844), (51, 0.03745913552120328), (37, 0.03867521043866873), (23, 0.038918440230190754), (9, 0.043623548932373524), (6, 0.0462763044051826), (14, 0.04755589831620455), (4, 0.04847617540508509), (2, 0.055080851539969444), (52, 0.056753852404654026), (3, 0.05825658841058612), (13, 0.058780273888260126), (11, 0.05950920470058918), (17, 0.06199881108477712), (0, 0.06347448704764247), (1, 0.06595496088266373), (8, 0.07373637706041336), (10, 0.08077486976981163), (16, 0.08484370540827513), (12, 0.08934913668781519), (5, 0.10531804896891117), (36, 0.2772640660405159), (18, 0.5109026357531548), (53, 0.9537922516465187)]
computing accuracy for after removing block 44 . block score: 0.01239841675851494
removed block 44 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.012425. All blocks and scores: [(42, 0.012425398570485413), (47, 0.013173215207643807), (40, 0.023162495577707887), (50, 0.02485593850724399), (49, 0.025416354183107615), (48, 0.025648399023339152), (24, 0.02978088497184217), (39, 0.031014654086902738), (38, 0.03135290718637407), (21, 0.031511786160990596), (15, 0.03206620505079627), (7, 0.032408065628260374), (20, 0.032441966235637665), (22, 0.032638413831591606), (19, 0.03274039551615715), (51, 0.03624498704448342), (37, 0.03867521043866873), (23, 0.03891843976452947), (9, 0.043623550329357386), (6, 0.04627630487084389), (14, 0.04755589831620455), (4, 0.04847617307677865), (52, 0.05290482100099325), (2, 0.05508085014298558), (3, 0.05825658841058612), (13, 0.05878027528524399), (11, 0.05950920423492789), (17, 0.061998807825148106), (0, 0.06347448518499732), (1, 0.06595495902001858), (8, 0.07373637706041336), (10, 0.0807748707011342), (16, 0.08484370727092028), (12, 0.08934913855046034), (5, 0.1053180517628789), (36, 0.2772640623152256), (18, 0.5109026357531548), (53, 1.0535972118377686)]
computing accuracy for after removing block 42 . block score: 0.012425398570485413
removed block 42 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 47, with score 0.013177. All blocks and scores: [(47, 0.013177145970985293), (40, 0.023162495344877243), (50, 0.02458588732406497), (49, 0.02497438946738839), (48, 0.025466591119766235), (24, 0.029780885204672813), (39, 0.031014653854072094), (38, 0.031352906255051494), (21, 0.031511784764006734), (15, 0.03206620505079627), (7, 0.032408065628260374), (20, 0.03244196670129895), (22, 0.03263841429725289), (19, 0.03274039505049586), (51, 0.035441912710666656), (37, 0.038675210904330015), (23, 0.03891843929886818), (9, 0.043623548466712236), (6, 0.04627630393952131), (14, 0.047555898781865835), (4, 0.048476175870746374), (52, 0.05122932139784098), (2, 0.05508085060864687), (3, 0.05825658934190869), (13, 0.058780275750905275), (11, 0.05950920423492789), (17, 0.061998809687793255), (0, 0.06347448518499732), (1, 0.06595495902001858), (8, 0.07373637799173594), (10, 0.08077486790716648), (16, 0.08484370820224285), (12, 0.08934913948178291), (5, 0.10531805269420147), (36, 0.2772640623152256), (18, 0.5109026357531548), (53, 1.1069266200065613)]
computing accuracy for after removing block 47 . block score: 0.013177145970985293
removed block 47 current accuracy 0.8996 loss from initial  0.05180000000000007
training start
training epoch 0 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.1]
training epoch 1 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 2 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 3 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 4 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 5 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.1]
training epoch 6 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.1]
training epoch 7 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.1]
training epoch 8 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.1]
training epoch 9 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 18
[activation diff]: block to remove picked: 48, with score 0.027687. All blocks and scores: [(48, 0.02768718544393778), (50, 0.029001396615058184), (24, 0.03010902157984674), (49, 0.0308446588460356), (40, 0.031734643038362265), (21, 0.0318714021705091), (15, 0.03217647969722748), (20, 0.03257716400548816), (7, 0.03262755088508129), (19, 0.0327597688883543), (22, 0.0329987732693553), (23, 0.039694301784038544), (39, 0.03979659220203757), (38, 0.040335556492209435), (9, 0.04390412988141179), (51, 0.04411364812403917), (37, 0.04526497097685933), (6, 0.04693494876846671), (14, 0.04788725497201085), (4, 0.05112616624683142), (2, 0.05541367642581463), (3, 0.05906587699428201), (11, 0.059684062376618385), (13, 0.059811997693032026), (17, 0.06275182869285345), (0, 0.0642179911956191), (1, 0.06695614196360111), (52, 0.07001288514584303), (8, 0.07465000730007887), (10, 0.08048738166689873), (16, 0.08575257286429405), (12, 0.08984107803553343), (5, 0.106925536878407), (36, 0.4532904736697674), (18, 0.5139091685414314), (53, 0.8106264173984528)]
computing accuracy for after removing block 48 . block score: 0.02768718544393778
removed block 48 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.030109. All blocks and scores: [(24, 0.030109022743999958), (40, 0.031734643038362265), (50, 0.03178717312403023), (21, 0.03187140170484781), (15, 0.0321764787659049), (20, 0.032577164471149445), (7, 0.03262754995375872), (19, 0.032759768422693014), (22, 0.032998773735016584), (49, 0.034700201358646154), (23, 0.039694301784038544), (39, 0.03979659220203757), (38, 0.04033555602654815), (51, 0.04242094559594989), (9, 0.043904128950089216), (37, 0.04526497144252062), (6, 0.04693495016545057), (14, 0.04788725497201085), (4, 0.05112616438418627), (2, 0.05541367642581463), (3, 0.05906587792560458), (11, 0.0596840619109571), (13, 0.059811997693032026), (17, 0.06275182776153088), (0, 0.06421798933297396), (1, 0.06695614289492369), (52, 0.07458887621760368), (8, 0.0746500063687563), (10, 0.08048738446086645), (16, 0.08575257193297148), (12, 0.08984107989817858), (5, 0.10692553874105215), (36, 0.4532904773950577), (18, 0.5139091685414314), (53, 0.8801533877849579)]
computing accuracy for after removing block 24 . block score: 0.030109022743999958
removed block 24 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.029850. All blocks and scores: [(50, 0.02985007781535387), (40, 0.031095684273168445), (21, 0.03187140170484781), (15, 0.032176480162888765), (20, 0.032577164471149445), (7, 0.032627550419420004), (19, 0.032759768422693014), (22, 0.032998773735016584), (49, 0.03353814361616969), (39, 0.03952287137508392), (23, 0.039694301784038544), (38, 0.03978599142283201), (51, 0.040711193811148405), (9, 0.04390412708744407), (6, 0.04693495016545057), (37, 0.04705441743135452), (14, 0.04788725730031729), (4, 0.05112616578117013), (2, 0.0554136773571372), (3, 0.059065877459943295), (11, 0.0596840619109571), (13, 0.059811997693032026), (17, 0.06275183008983731), (0, 0.06421799212694168), (1, 0.06695614103227854), (52, 0.0685346107929945), (8, 0.07465000450611115), (10, 0.08048738352954388), (16, 0.08575257286429405), (12, 0.08984107803553343), (5, 0.10692553594708443), (36, 0.45433739200234413), (18, 0.513909175992012), (53, 0.9136114791035652)]
computing accuracy for after removing block 50 . block score: 0.02985007781535387
removed block 50 current accuracy 0.8906 loss from initial  0.060800000000000076
since last training loss: 0.05380000000000007 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 40, with score 0.031096. All blocks and scores: [(40, 0.03109568520449102), (21, 0.03187140077352524), (15, 0.03217647969722748), (20, 0.032577164471149445), (7, 0.03262755088508129), (19, 0.032759769819676876), (22, 0.032998773735016584), (49, 0.033538142684847116), (39, 0.03952287184074521), (23, 0.039694301784038544), (38, 0.03978599235415459), (9, 0.04390412801876664), (51, 0.04460832662880421), (6, 0.046934949234128), (37, 0.04705441603437066), (14, 0.047887254506349564), (4, 0.05112616624683142), (2, 0.05541367642581463), (3, 0.059065877459943295), (11, 0.05968406144529581), (13, 0.059811996296048164), (17, 0.06275182822719216), (0, 0.06421799212694168), (1, 0.06695614382624626), (8, 0.07465000730007887), (10, 0.08048738166689873), (52, 0.0820332644507289), (16, 0.0857525747269392), (12, 0.08984108082950115), (5, 0.1069255406036973), (36, 0.45433739572763443), (18, 0.5139091685414314), (53, 1.084983929991722)]
computing accuracy for after removing block 40 . block score: 0.03109568520449102
removed block 40 current accuracy 0.8718 loss from initial  0.0796
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.031871. All blocks and scores: [(21, 0.03187140170484781), (15, 0.032176478300243616), (49, 0.03245949209667742), (20, 0.03257716493681073), (7, 0.032627550419420004), (19, 0.0327597688883543), (22, 0.0329987732693553), (39, 0.03952287137508392), (23, 0.03969430271536112), (38, 0.03978599142283201), (9, 0.043904128950089216), (51, 0.04518997063860297), (6, 0.046934948302805424), (37, 0.04705441603437066), (14, 0.047887256834656), (4, 0.05112616578117013), (2, 0.05541367596015334), (3, 0.059065877459943295), (11, 0.05968406284227967), (13, 0.05981199583038688), (17, 0.06275183008983731), (0, 0.06421799305826426), (1, 0.06695614103227854), (8, 0.07465000916272402), (10, 0.08048738073557615), (52, 0.08367778919637203), (16, 0.08575257193297148), (12, 0.08984107803553343), (5, 0.10692553780972958), (36, 0.45433738827705383), (18, 0.5139091834425926), (53, 1.1983597576618195)]
computing accuracy for after removing block 21 . block score: 0.03187140170484781
removed block 21 current accuracy 0.8584 loss from initial  0.09299999999999997
since last training loss: 0.08599999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.029913. All blocks and scores: [(22, 0.029912649421021342), (49, 0.031503777019679546), (15, 0.03217647969722748), (20, 0.032577164471149445), (7, 0.032627550419420004), (19, 0.03275976935401559), (23, 0.036205411888659), (38, 0.03760314825922251), (39, 0.03778852242976427), (51, 0.04310721065849066), (9, 0.04390412801876664), (37, 0.0447033797390759), (6, 0.04693495109677315), (14, 0.04788725730031729), (4, 0.05112616391852498), (2, 0.0554136773571372), (3, 0.05906587606295943), (11, 0.05968406144529581), (13, 0.05981199722737074), (17, 0.06275182869285345), (0, 0.06421799212694168), (1, 0.06695614289492369), (52, 0.07245861925184727), (8, 0.07465000730007887), (10, 0.0804873825982213), (16, 0.08575257379561663), (12, 0.08984107803553343), (5, 0.10692553967237473), (36, 0.4248059056699276), (18, 0.513909175992012), (53, 1.271555557847023)]
computing accuracy for after removing block 22 . block score: 0.029912649421021342
removed block 22 current accuracy 0.8392 loss from initial  0.11220000000000008
since last training loss: 0.10520000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 49, with score 0.030636. All blocks and scores: [(49, 0.03063602396287024), (15, 0.03217647969722748), (20, 0.03257716540247202), (7, 0.032627551816403866), (19, 0.0327597688883543), (23, 0.034753517247736454), (39, 0.03667589370161295), (38, 0.03685673465952277), (51, 0.042396757286041975), (9, 0.043904128950089216), (37, 0.045413329266011715), (6, 0.046934949699789286), (14, 0.047887254506349564), (4, 0.05112616438418627), (2, 0.05541367642581463), (3, 0.05906587699428201), (11, 0.05968406330794096), (13, 0.05981199583038688), (17, 0.0627518268302083), (0, 0.06421799398958683), (1, 0.06695614010095596), (52, 0.06704489327967167), (8, 0.07465000823140144), (10, 0.08048738446086645), (16, 0.08575257007032633), (12, 0.089841078966856), (5, 0.10692553874105215), (36, 0.4226463846862316), (18, 0.5139091685414314), (53, 1.3059269040822983)]
computing accuracy for after removing block 49 . block score: 0.03063602396287024
removed block 49 current accuracy 0.7794 loss from initial  0.17200000000000004
since last training loss: 0.16500000000000004 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.032176. All blocks and scores: [(15, 0.032176480162888765), (20, 0.032577164471149445), (7, 0.03262755135074258), (19, 0.032759768422693014), (23, 0.03475351585075259), (39, 0.03667589370161295), (38, 0.0368567337282002), (9, 0.043904127553105354), (51, 0.044786822982132435), (37, 0.04541332880035043), (6, 0.046934949699789286), (14, 0.04788725543767214), (4, 0.051126164849847555), (2, 0.05541367642581463), (3, 0.05906587792560458), (11, 0.05968406284227967), (13, 0.05981199722737074), (17, 0.06275182776153088), (0, 0.06421799212694168), (1, 0.06695614289492369), (52, 0.07288297358900309), (8, 0.07465000823140144), (10, 0.08048738166689873), (16, 0.08575257379561663), (12, 0.089841078966856), (5, 0.10692553967237473), (36, 0.4226463884115219), (18, 0.513909175992012), (53, 1.4945067316293716)]
computing accuracy for after removing block 15 . block score: 0.032176480162888765
removed block 15 current accuracy 0.764 loss from initial  0.1874
since last training loss: 0.1804 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.030870. All blocks and scores: [(20, 0.030870204558596015), (7, 0.03262754995375872), (19, 0.03304426744580269), (23, 0.033498688135296106), (38, 0.03714773012325168), (39, 0.037199410144239664), (9, 0.043904128950089216), (51, 0.04509580275043845), (6, 0.04693495016545057), (37, 0.047034105751663446), (14, 0.047887256834656), (4, 0.05112616438418627), (2, 0.0554136773571372), (3, 0.05906587839126587), (11, 0.059684060513973236), (13, 0.059811996296048164), (0, 0.06421799026429653), (17, 0.06659506633877754), (1, 0.06695614289492369), (8, 0.07465000823140144), (52, 0.0750095583498478), (10, 0.08048738446086645), (12, 0.089841078966856), (16, 0.09569749981164932), (5, 0.106925536878407), (36, 0.4255513995885849), (18, 0.5011613890528679), (53, 1.509594053030014)]
computing accuracy for after removing block 20 . block score: 0.030870204558596015
removed block 20 current accuracy 0.706 loss from initial  0.24540000000000006
training start
training epoch 0 val accuracy 0.84 topk_dict {'top1': 0.84} is_best True lr [0.1]
training epoch 1 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.1]
training epoch 2 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 3 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 4 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 5 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 7 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.1]
training epoch 8 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
