start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232580942101777), (34, 0.013294661417603493), (29, 0.01342111628036946), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019996492192149162), (46, 0.02059022570028901), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.023145999759435654), (40, 0.023749589920043945), (45, 0.02397549571469426), (21, 0.024941089563071728), (48, 0.02495770761743188), (22, 0.02515139034949243), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.02591664856299758), (42, 0.02623223257251084), (20, 0.026848891284316778), (47, 0.02863294817507267), (38, 0.031344343442469835), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.0417875861749053), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216210603714), (52, 0.06606104597449303), (8, 0.0746636176481843), (10, 0.08082299865782261), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.436198640614748), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.01001118728891015), (31, 0.010232581524178386), (34, 0.013119243900291622), (29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.01609392836689949), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019852687139064074), (46, 0.020300705451518297), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.024770822608843446), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.02557574096135795), (24, 0.02588058286346495), (42, 0.025893413461744785), (20, 0.026848892215639353), (47, 0.02807276020757854), (38, 0.03109118831343949), (39, 0.031191361136734486), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992501139641), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4339806027710438), (18, 0.5117432996630669), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581058517098), (34, 0.012758882134221494), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686048798263), (27, 0.019022797932848334), (43, 0.019850464537739754), (46, 0.02041191584430635), (41, 0.021827629767358303), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022891478147357702), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.02451987355016172), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.0253925493452698), (42, 0.025712220696732402), (24, 0.025880583561956882), (20, 0.026848891517147422), (47, 0.028052504640072584), (38, 0.030935873044654727), (39, 0.03117303573526442), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003129914403), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4350203163921833), (18, 0.5117432996630669), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159728713334), (29, 0.013421117211692035), (35, 0.01591864973306656), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019867350114509463), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.02435004524886608), (50, 0.02446310594677925), (21, 0.024941088864579797), (22, 0.025151389883831143), (49, 0.025246930541470647), (42, 0.0252735516987741), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.02772757480852306), (38, 0.030746274162083864), (39, 0.031281795585528016), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.0635675610974431), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4377693049609661), (18, 0.5117432996630669), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116513200104), (35, 0.015968911815434694), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798631340265), (43, 0.01983700809068978), (46, 0.020137187791988254), (41, 0.02158405538648367), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.022687324788421392), (40, 0.02356909797526896), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.024114208994433284), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.025880581932142377), (20, 0.026848891517147422), (47, 0.027423853054642677), (38, 0.030735648004338145), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077723249793), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525531575084), (52, 0.06270107766613364), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.43692684918642044), (18, 0.5117432996630669), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.02030268474482), (46, 0.020324197132140398), (41, 0.021962703205645084), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.023045076988637447), (48, 0.024024546379223466), (50, 0.02409697324037552), (40, 0.0241568167693913), (45, 0.024168409407138824), (49, 0.024922373238950968), (21, 0.024941089330241084), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02756829559803009), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.03225791221484542), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428923279047), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.062210950534790754), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.10671143885701895), (36, 0.44933704286813736), (18, 0.5117432847619057), (53, 0.8277030512690544)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.1]
training epoch 1 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.1]
training epoch 2 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 4 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.1]
training epoch 5 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.1]
training epoch 6 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.1]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 8 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.1]
training epoch 9 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.1]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.014624. All blocks and scores: [(35, 0.01462400029413402), (26, 0.016227375017479062), (37, 0.016623604577034712), (28, 0.01794376620091498), (27, 0.0191125285346061), (43, 0.020671281730756164), (46, 0.020685756811872125), (25, 0.022154559614136815), (23, 0.02252247743308544), (41, 0.022918830160051584), (44, 0.02329519926570356), (45, 0.023875675396993756), (40, 0.024476203368976712), (50, 0.024547253036871552), (48, 0.025007016491144896), (22, 0.025085520697757602), (21, 0.025166848907247186), (49, 0.025461918208748102), (24, 0.026017260504886508), (42, 0.02661630604416132), (20, 0.02728379354812205), (47, 0.028452465077862144), (15, 0.03216261602938175), (7, 0.032437487971037626), (19, 0.03282060334458947), (39, 0.0331559325568378), (38, 0.03387874597683549), (51, 0.040966478642076254), (9, 0.043623038567602634), (6, 0.04646266810595989), (4, 0.04707424994558096), (14, 0.047825220040977), (2, 0.05473156040534377), (3, 0.05735676968470216), (13, 0.059425420593470335), (11, 0.05951206386089325), (17, 0.062009979505091906), (0, 0.06379976775497198), (52, 0.06483161495998502), (1, 0.06671916600316763), (8, 0.07437747064977884), (10, 0.08114950638264418), (16, 0.08643977995961905), (12, 0.09021776355803013), (5, 0.10575397592037916), (36, 0.3465019017457962), (18, 0.5125789046287537), (53, 0.7757214531302452)]
computing accuracy for after removing block 35 . block score: 0.01462400029413402
removed block 35 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.016227. All blocks and scores: [(26, 0.016227375017479062), (37, 0.01656567817553878), (28, 0.017943765968084335), (27, 0.019112528767436743), (46, 0.019966690568253398), (43, 0.0200849745888263), (41, 0.021697995718568563), (25, 0.022154558915644884), (23, 0.02252247743308544), (44, 0.023155792616307735), (45, 0.023222162621095777), (50, 0.0233124743681401), (40, 0.023730522952973843), (48, 0.023909776471555233), (49, 0.024697100510820746), (42, 0.02486197231337428), (22, 0.025085521396249533), (21, 0.0251668484415859), (24, 0.026017260970547795), (47, 0.02722807857207954), (20, 0.02728379308246076), (39, 0.03170357830822468), (15, 0.03216261696070433), (7, 0.03243748936802149), (19, 0.0328206024132669), (38, 0.032948664389550686), (51, 0.039443794172257185), (9, 0.043623036704957485), (6, 0.04646266670897603), (4, 0.04707424994558096), (14, 0.047825220040977), (2, 0.05473156180232763), (3, 0.05735677108168602), (13, 0.05942542012780905), (11, 0.05951206386089325), (52, 0.061581024434417486), (17, 0.062009976245462894), (0, 0.06379976961761713), (1, 0.06671916600316763), (8, 0.07437747064977884), (10, 0.0811495054513216), (16, 0.08643978461623192), (12, 0.0902177644893527), (5, 0.10575397685170174), (36, 0.34027817845344543), (18, 0.5125789195299149), (53, 0.7929413840174675)]
computing accuracy for after removing block 26 . block score: 0.016227375017479062
removed block 26 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 37, with score 0.016244. All blocks and scores: [(37, 0.016244142083451152), (28, 0.017279532505199313), (27, 0.018853757996112108), (43, 0.01949450862593949), (46, 0.01958838850259781), (41, 0.020784023217856884), (25, 0.022154558915644884), (23, 0.02252247743308544), (50, 0.02270418987609446), (45, 0.02289888053201139), (44, 0.022975482512265444), (40, 0.02299980027601123), (48, 0.023243417032063007), (42, 0.023318180115893483), (49, 0.02431577956303954), (22, 0.025085520697757602), (21, 0.025166848674416542), (24, 0.02601726190187037), (47, 0.026731814024969935), (20, 0.02728379424661398), (39, 0.03092392859980464), (38, 0.031795450719073415), (15, 0.03216261696070433), (7, 0.0324374889023602), (19, 0.03282060148194432), (51, 0.03815666912123561), (9, 0.04362303810194135), (6, 0.04646266624331474), (4, 0.04707424994558096), (14, 0.04782521910965443), (2, 0.054731563199311495), (3, 0.05735676968470216), (13, 0.05942542152479291), (11, 0.0595120619982481), (52, 0.05973433656617999), (17, 0.062009977642446756), (0, 0.06379976589232683), (1, 0.0667191669344902), (8, 0.07437747158110142), (10, 0.08114950265735388), (16, 0.08643977995961905), (12, 0.09021776542067528), (5, 0.10575397592037916), (36, 0.3324439935386181), (18, 0.5125789269804955), (53, 0.8175616785883904)]
computing accuracy for after removing block 37 . block score: 0.016244142083451152
removed block 37 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.017280. All blocks and scores: [(28, 0.0172795329708606), (43, 0.017620303900912404), (46, 0.01787603017874062), (41, 0.018526215106248856), (27, 0.018853757996112108), (50, 0.019533358281478286), (48, 0.020350373815745115), (44, 0.020689826924353838), (40, 0.02073573274537921), (45, 0.020876390393823385), (42, 0.021487167570739985), (49, 0.02161928336136043), (25, 0.022154559614136815), (23, 0.02252247743308544), (47, 0.023480358999222517), (22, 0.02508552116341889), (21, 0.025166848674416542), (24, 0.026017261436209083), (20, 0.02728379354812205), (39, 0.029277433408424258), (38, 0.03173949429765344), (15, 0.032162617426365614), (7, 0.032437488436698914), (19, 0.0328206024132669), (51, 0.03465212183073163), (9, 0.04362303763628006), (6, 0.04646266857162118), (4, 0.04707425134256482), (14, 0.047825219575315714), (52, 0.051331921480596066), (2, 0.05473156226798892), (3, 0.05735676968470216), (13, 0.05942542105913162), (11, 0.059512064792215824), (17, 0.062009977642446756), (0, 0.06379976961761713), (1, 0.06671916600316763), (8, 0.07437747158110142), (10, 0.0811495054513216), (16, 0.08643978368490934), (12, 0.09021776542067528), (5, 0.10575397498905659), (36, 0.3324439972639084), (18, 0.5125789046287537), (53, 0.8318217918276787)]
computing accuracy for after removing block 28 . block score: 0.0172795329708606
removed block 28 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 43, with score 0.017124. All blocks and scores: [(43, 0.01712385774590075), (46, 0.017348728608340025), (41, 0.01793491467833519), (27, 0.018853758228942752), (50, 0.019201258663088083), (48, 0.019797195913270116), (40, 0.020363083574920893), (45, 0.0204973709769547), (44, 0.020516083808615804), (42, 0.02069498202763498), (49, 0.021119925193488598), (25, 0.02215455938130617), (23, 0.022522478131577373), (47, 0.022792566334828734), (22, 0.025085521629080176), (21, 0.025166848907247186), (24, 0.026017261436209083), (20, 0.02728379424661398), (39, 0.02883861167356372), (38, 0.030791667522862554), (15, 0.03216261696070433), (7, 0.032437487971037626), (19, 0.032820602878928185), (51, 0.033996636513620615), (9, 0.04362303763628006), (6, 0.04646266717463732), (4, 0.047074249014258385), (14, 0.047825220040977), (52, 0.05002989573404193), (2, 0.05473156040534377), (3, 0.057356772013008595), (13, 0.05942542152479291), (11, 0.05951206339523196), (17, 0.062009978108108044), (0, 0.0637997668236494), (1, 0.06671916507184505), (8, 0.07437747251242399), (10, 0.0811495054513216), (16, 0.08643977902829647), (12, 0.09021776542067528), (5, 0.10575397592037916), (36, 0.32783689722418785), (18, 0.5125789195299149), (53, 0.8431814312934875)]
computing accuracy for after removing block 43 . block score: 0.01712385774590075
removed block 43 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.017926. All blocks and scores: [(46, 0.017925775377079844), (41, 0.017934914212673903), (27, 0.018853757297620177), (50, 0.01930157793685794), (40, 0.02036308334209025), (48, 0.02039120253175497), (42, 0.020694982493296266), (49, 0.020966117968782783), (45, 0.021379755111411214), (44, 0.02161979954689741), (25, 0.02215455938130617), (23, 0.022522476967424154), (47, 0.023504025302827358), (22, 0.02508552116341889), (21, 0.02516684914007783), (24, 0.026017260970547795), (20, 0.027283793780952692), (39, 0.028838611440733075), (38, 0.03079166659153998), (15, 0.03216261649504304), (7, 0.032437487971037626), (19, 0.03282060194760561), (51, 0.03351713204756379), (9, 0.0436230362392962), (6, 0.04646266670897603), (4, 0.04707425041124225), (14, 0.047825220040977), (52, 0.04886938352137804), (2, 0.05473156040534377), (3, 0.05735677247866988), (13, 0.059425420593470335), (11, 0.0595120619982481), (17, 0.06200997857376933), (0, 0.06379976775497198), (1, 0.06671916507184505), (8, 0.07437747064977884), (10, 0.0811495054513216), (16, 0.08643978089094162), (12, 0.09021776635199785), (5, 0.10575397685170174), (36, 0.32783688977360725), (18, 0.5125789120793343), (53, 0.8922352343797684)]
computing accuracy for after removing block 46 . block score: 0.017925775377079844
removed block 46 current accuracy 0.9278 loss from initial  0.023600000000000065
training start
training epoch 0 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 1 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 2 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 3 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.1]
training epoch 4 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 5 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.1]
training epoch 6 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 7 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 8 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.1]
training epoch 9 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 12
[activation diff]: block to remove picked: 49, with score 0.012940. All blocks and scores: [(49, 0.012939517619088292), (48, 0.013569749658927321), (40, 0.015846668742597103), (44, 0.01657528360374272), (45, 0.016716257203370333), (47, 0.019357459619641304), (23, 0.022357818903401494), (25, 0.022421146742999554), (41, 0.022484774235635996), (39, 0.02410248084925115), (21, 0.024999216897413135), (42, 0.025428412249311805), (22, 0.025450593093410134), (24, 0.026396331610158086), (20, 0.027260024799034), (38, 0.027485103346407413), (50, 0.028155855368822813), (15, 0.032180514652282), (19, 0.032398026436567307), (7, 0.032677489798516035), (51, 0.042482681106776), (9, 0.044028164353221655), (27, 0.04413260845467448), (4, 0.04609371488913894), (6, 0.04685082472860813), (14, 0.048168417531996965), (2, 0.05506308609619737), (3, 0.05858042882755399), (13, 0.05961801903322339), (11, 0.060001336969435215), (17, 0.06281814770773053), (0, 0.06373847369104624), (1, 0.06627622805535793), (52, 0.06704201735556126), (8, 0.07462250161916018), (10, 0.08150539826601744), (16, 0.0859775235876441), (12, 0.09082934074103832), (5, 0.10743810050189495), (36, 0.362477071583271), (18, 0.5161631181836128), (53, 0.8089320287108421)]
computing accuracy for after removing block 49 . block score: 0.012939517619088292
removed block 49 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.013570. All blocks and scores: [(48, 0.013569749658927321), (40, 0.01584666920825839), (44, 0.01657528360374272), (45, 0.01671625697053969), (47, 0.019357459153980017), (23, 0.022357819601893425), (25, 0.022421145346015692), (41, 0.02248477376997471), (39, 0.02410247945226729), (21, 0.024999215733259916), (42, 0.02542841248214245), (22, 0.025450591929256916), (24, 0.02639633184298873), (20, 0.027260025264695287), (38, 0.027485103346407413), (50, 0.02945373416878283), (15, 0.03218051511794329), (19, 0.03239802550524473), (7, 0.03267749026417732), (9, 0.04402816528454423), (27, 0.04413260938599706), (51, 0.04493845859542489), (4, 0.04609371488913894), (6, 0.046850825659930706), (14, 0.04816841892898083), (2, 0.05506308702751994), (3, 0.05858043069019914), (13, 0.05961801763623953), (11, 0.060001336969435215), (17, 0.06281814677640796), (0, 0.06373847275972366), (1, 0.06627622991800308), (52, 0.07103281561285257), (8, 0.07462250348180532), (10, 0.08150540012866259), (16, 0.0859775235876441), (12, 0.09082933608442545), (5, 0.10743809677660465), (36, 0.3624770753085613), (18, 0.5161631256341934), (53, 0.8673263043165207)]
computing accuracy for after removing block 48 . block score: 0.013569749658927321
removed block 48 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.015847. All blocks and scores: [(40, 0.015846669673919678), (44, 0.016575284069404006), (45, 0.016716257436200976), (47, 0.019357459619641304), (23, 0.02235781983472407), (25, 0.02242114581167698), (41, 0.022484774002805352), (39, 0.02410248015075922), (21, 0.02499921596609056), (42, 0.025428412249311805), (22, 0.025450592394918203), (24, 0.0263963311444968), (20, 0.027260024566203356), (38, 0.027485102647915483), (50, 0.03118146280758083), (15, 0.03218051418662071), (19, 0.03239802736788988), (7, 0.03267749072983861), (9, 0.04402816388756037), (27, 0.04413260892033577), (51, 0.04474711185321212), (4, 0.04609371442347765), (6, 0.046850825659930706), (14, 0.048168419394642115), (2, 0.05506308749318123), (3, 0.05858042882755399), (13, 0.059618018101900816), (11, 0.06000133603811264), (17, 0.06281814770773053), (0, 0.06373847275972366), (1, 0.06627622898668051), (52, 0.07400415558367968), (8, 0.07462250255048275), (10, 0.08150540105998516), (16, 0.08597751799970865), (12, 0.0908293379470706), (5, 0.10743809957057238), (36, 0.362477071583271), (18, 0.5161631107330322), (53, 0.9363138750195503)]
computing accuracy for after removing block 40 . block score: 0.015846669673919678
removed block 40 current accuracy 0.927 loss from initial  0.024399999999999977
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.016582. All blocks and scores: [(45, 0.016581628704443574), (44, 0.01703442120924592), (47, 0.01965895714238286), (23, 0.022357818903401494), (25, 0.022421146277338266), (41, 0.023587725590914488), (39, 0.024102479685097933), (21, 0.024999216198921204), (22, 0.025450591929256916), (42, 0.025847998913377523), (24, 0.026396331610158086), (20, 0.027260025264695287), (38, 0.027485103346407413), (50, 0.03012851648963988), (15, 0.03218051511794329), (19, 0.03239802597090602), (7, 0.0326774911954999), (51, 0.04386991681531072), (9, 0.04402816481888294), (27, 0.04413260892033577), (4, 0.04609371582046151), (6, 0.04685082472860813), (14, 0.0481684198603034), (2, 0.05506308702751994), (3, 0.05858042882755399), (13, 0.0596180185675621), (11, 0.06000133603811264), (17, 0.06281814677640796), (0, 0.06373847369104624), (1, 0.06627622805535793), (52, 0.07217475585639477), (8, 0.07462250161916018), (10, 0.08150539826601744), (16, 0.08597752172499895), (12, 0.09082933701574802), (5, 0.10743809677660465), (36, 0.36247706785798073), (18, 0.5161631181836128), (53, 1.012325756251812)]
computing accuracy for after removing block 45 . block score: 0.016581628704443574
removed block 45 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.017034. All blocks and scores: [(44, 0.01703442120924592), (47, 0.020300201373174787), (23, 0.02235781983472407), (25, 0.022421146044507623), (41, 0.0235877251252532), (39, 0.02410247945226729), (21, 0.024999215733259916), (22, 0.02545059216208756), (42, 0.025847998447716236), (24, 0.026396330911666155), (20, 0.02726002410054207), (38, 0.027485103346407413), (50, 0.030538976658135653), (15, 0.03218051418662071), (19, 0.03239802550524473), (7, 0.0326774911954999), (51, 0.04283178457990289), (9, 0.04402816481888294), (27, 0.04413260892033577), (4, 0.04609371582046151), (6, 0.04685082519426942), (14, 0.048168417531996965), (2, 0.05506308423355222), (3, 0.058580431155860424), (13, 0.05961801717057824), (11, 0.06000133790075779), (17, 0.06281814817339182), (0, 0.06373846996575594), (1, 0.06627622712403536), (52, 0.06965398043394089), (8, 0.07462250255048275), (10, 0.08150539826601744), (16, 0.08597751893103123), (12, 0.0908293379470706), (5, 0.10743809677660465), (36, 0.3624770827591419), (18, 0.5161631032824516), (53, 1.1270275115966797)]
computing accuracy for after removing block 44 . block score: 0.01703442120924592
removed block 44 current accuracy 0.9104 loss from initial  0.041000000000000036
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 47, with score 0.020513. All blocks and scores: [(47, 0.02051327098160982), (23, 0.02235781936906278), (25, 0.022421145346015692), (41, 0.023587725358083844), (39, 0.02410247945226729), (21, 0.02499921480193734), (22, 0.02545059216208756), (42, 0.025847998447716236), (24, 0.02639633184298873), (20, 0.027260025264695287), (38, 0.027485103346407413), (50, 0.029420030768960714), (15, 0.032180513720959425), (19, 0.032398026436567307), (7, 0.03267749072983861), (51, 0.041719039902091026), (9, 0.04402816528454423), (27, 0.04413260845467448), (4, 0.046093715354800224), (6, 0.046850825659930706), (14, 0.0481684198603034), (2, 0.055063087958842516), (3, 0.05858043022453785), (13, 0.05961801949888468), (11, 0.0600013374350965), (17, 0.06281814770773053), (0, 0.06373847089707851), (52, 0.06549868732690811), (1, 0.06627622712403536), (8, 0.07462250348180532), (10, 0.08150539826601744), (16, 0.08597752079367638), (12, 0.09082933980971575), (5, 0.10743809677660465), (36, 0.3624770753085613), (18, 0.5161631032824516), (53, 1.247316300868988)]
computing accuracy for after removing block 47 . block score: 0.02051327098160982
removed block 47 current accuracy 0.8816 loss from initial  0.06979999999999997
training start
training epoch 0 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.1]
training epoch 1 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.1]
training epoch 2 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.1]
training epoch 3 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.1]
training epoch 4 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.1]
training epoch 5 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.1]
training epoch 6 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.1]
training epoch 7 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.1]
training epoch 8 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.1]
training epoch 9 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 18
[activation diff]: block to remove picked: 25, with score 0.022387. All blocks and scores: [(25, 0.022387047531083226), (23, 0.02252513845451176), (39, 0.02426019194535911), (21, 0.025012310361489654), (22, 0.02543039107695222), (24, 0.026445047929883003), (20, 0.027087490539997816), (38, 0.027448581531643867), (15, 0.032320823054760695), (19, 0.032511341385543346), (7, 0.03292705025523901), (50, 0.03916029306128621), (51, 0.04383014887571335), (9, 0.04401005245745182), (27, 0.044536062981933355), (42, 0.045974486507475376), (6, 0.04711441369727254), (14, 0.04824614757671952), (4, 0.0488966153934598), (41, 0.049465879797935486), (2, 0.05493976315483451), (3, 0.05884770629927516), (13, 0.059682770166546106), (11, 0.05999665940180421), (17, 0.06281342776492238), (0, 0.0648606801405549), (1, 0.0672413082793355), (8, 0.07550792396068573), (10, 0.08195420447736979), (16, 0.0861166575923562), (12, 0.09086475893855095), (52, 0.09504897985607386), (5, 0.10828339774161577), (36, 0.36459511891007423), (18, 0.5180077776312828), (53, 0.7762257009744644)]
computing accuracy for after removing block 25 . block score: 0.022387047531083226
removed block 25 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.022525. All blocks and scores: [(23, 0.02252513775601983), (39, 0.02432563970796764), (21, 0.025012311059981585), (22, 0.02543039107695222), (24, 0.026445047464221716), (38, 0.02689846558496356), (20, 0.027087491238489747), (15, 0.03232082212343812), (19, 0.03251134091988206), (7, 0.0329270507209003), (50, 0.0382220302708447), (51, 0.042204647324979305), (9, 0.04401005385443568), (42, 0.04443025030195713), (27, 0.04500176478177309), (6, 0.04711441369727254), (14, 0.04824614804238081), (41, 0.048807219602167606), (4, 0.04889661492779851), (2, 0.054939764086157084), (3, 0.05884770443663001), (13, 0.05968277156352997), (11, 0.059996659867465496), (17, 0.0628134268335998), (0, 0.06486068200320005), (1, 0.06724130921065807), (8, 0.07550792396068573), (10, 0.08195420727133751), (16, 0.0861166575923562), (52, 0.08813704829663038), (12, 0.0908647608011961), (5, 0.10828339867293835), (36, 0.3584016524255276), (18, 0.5180077850818634), (53, 0.791775070130825)]
computing accuracy for after removing block 23 . block score: 0.02252513775601983
removed block 23 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.024198. All blocks and scores: [(39, 0.024197922088205814), (21, 0.025012309895828366), (24, 0.025076071033254266), (22, 0.025430389912799), (38, 0.026580583536997437), (20, 0.02708749007433653), (15, 0.03232082258909941), (19, 0.032511341385543346), (7, 0.0329270507209003), (50, 0.03787586884573102), (51, 0.041221785824745893), (42, 0.04332482349127531), (9, 0.04401005292311311), (27, 0.04482630267739296), (6, 0.047114414628595114), (41, 0.04796062642708421), (14, 0.048246148973703384), (4, 0.04889661446213722), (2, 0.05493976268917322), (3, 0.058847703505307436), (13, 0.05968277109786868), (11, 0.05999665940180421), (17, 0.06281342869624496), (0, 0.06486068200320005), (1, 0.06724131014198065), (8, 0.07550792582333088), (10, 0.08195420540869236), (52, 0.08275938127189875), (16, 0.08611665479838848), (12, 0.09086475800722837), (5, 0.10828340239822865), (36, 0.35599713400006294), (18, 0.5180077850818634), (53, 0.8018299713730812)]
computing accuracy for after removing block 39 . block score: 0.024197922088205814
removed block 39 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.025012. All blocks and scores: [(21, 0.025012310361489654), (24, 0.025076070800423622), (22, 0.02543039061129093), (38, 0.026580582838505507), (20, 0.027087490307167172), (15, 0.03232082165777683), (19, 0.03251134091988206), (7, 0.03292705025523901), (50, 0.03514416376128793), (51, 0.03755598049610853), (42, 0.042142041958868504), (9, 0.044010053388774395), (27, 0.044826301746070385), (6, 0.0471144150942564), (41, 0.04747565183788538), (14, 0.04824614804238081), (4, 0.04889661492779851), (2, 0.054939765483140945), (3, 0.058847705367952585), (13, 0.05968277109786868), (11, 0.05999666033312678), (52, 0.061032930854707956), (17, 0.0628134272992611), (0, 0.06486068293452263), (1, 0.0672413082793355), (8, 0.0755079248920083), (10, 0.08195420540869236), (16, 0.08611665479838848), (12, 0.09086475893855095), (5, 0.10828339774161577), (36, 0.35599713400006294), (18, 0.5180077701807022), (53, 0.8926515579223633)]
computing accuracy for after removing block 21 . block score: 0.025012310361489654
removed block 21 current accuracy 0.9144 loss from initial  0.03700000000000003
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.023180. All blocks and scores: [(24, 0.023179783951491117), (22, 0.023659993428736925), (38, 0.02476081275381148), (20, 0.02708749077282846), (15, 0.032320823054760695), (19, 0.032511339988559484), (7, 0.032927051186561584), (50, 0.033458882477134466), (51, 0.035626064985990524), (42, 0.03886137064546347), (27, 0.04359255312010646), (9, 0.044010053388774395), (41, 0.04471238236874342), (6, 0.047114414162933826), (14, 0.04824614757671952), (4, 0.0488966153934598), (52, 0.050386738032102585), (2, 0.05493976501747966), (3, 0.05884770629927516), (13, 0.059682772029191256), (11, 0.05999665893614292), (17, 0.0628134272992611), (0, 0.0648606801405549), (1, 0.06724130921065807), (8, 0.0755079248920083), (10, 0.08195420540869236), (16, 0.08611665479838848), (12, 0.0908647608011961), (5, 0.10828340332955122), (36, 0.33486128225922585), (18, 0.5180077776312828), (53, 0.9082250669598579)]
computing accuracy for after removing block 24 . block score: 0.023179783951491117
removed block 24 current accuracy 0.9026 loss from initial  0.048800000000000066
since last training loss: 0.039000000000000035 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.023660. All blocks and scores: [(22, 0.023659994592890143), (38, 0.024592659436166286), (20, 0.027087490307167172), (15, 0.03232082258909941), (19, 0.03251134091988206), (7, 0.03292704978957772), (50, 0.03293859865516424), (51, 0.034451200626790524), (42, 0.037864654790610075), (41, 0.04296674067154527), (27, 0.04378096619620919), (9, 0.04401005385443568), (52, 0.04532509483397007), (6, 0.047114414162933826), (14, 0.048246148973703384), (4, 0.04889661492779851), (2, 0.05493976315483451), (3, 0.0588477049022913), (13, 0.059682773891836405), (11, 0.05999666079878807), (17, 0.0628134268335998), (0, 0.06486068107187748), (1, 0.06724131014198065), (8, 0.0755079248920083), (10, 0.08195420634001493), (16, 0.08611665479838848), (12, 0.09086475614458323), (5, 0.10828339774161577), (36, 0.32916224002838135), (18, 0.5180077850818634), (53, 0.930302269756794)]
computing accuracy for after removing block 22 . block score: 0.023659994592890143
removed block 22 current accuracy 0.8834 loss from initial  0.06800000000000006
since last training loss: 0.05820000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.024304. All blocks and scores: [(38, 0.024304068880155683), (20, 0.02708749007433653), (50, 0.03205342777073383), (15, 0.032320821192115545), (19, 0.032511341385543346), (51, 0.03281796257942915), (7, 0.03292705025523901), (42, 0.03661895822733641), (52, 0.038874033372849226), (41, 0.04190068505704403), (27, 0.04295374033972621), (9, 0.04401005245745182), (6, 0.047114414162933826), (14, 0.04824614757671952), (4, 0.04889661446213722), (2, 0.054939765483140945), (3, 0.0588477049022913), (13, 0.05968277249485254), (11, 0.05999666079878807), (17, 0.06281342590227723), (0, 0.0648606801405549), (1, 0.06724130734801292), (8, 0.0755079248920083), (10, 0.08195420634001493), (16, 0.0861166575923562), (12, 0.0908647608011961), (5, 0.10828339774161577), (36, 0.32469163835048676), (18, 0.5180077999830246), (53, 0.9277564734220505)]
computing accuracy for after removing block 38 . block score: 0.024304068880155683
removed block 38 current accuracy 0.858 loss from initial  0.09340000000000004
since last training loss: 0.08360000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 20, with score 0.027087. All blocks and scores: [(20, 0.02708749007433653), (50, 0.03018843987956643), (51, 0.03037030785344541), (52, 0.03058842965401709), (15, 0.03232082212343812), (19, 0.0325113395228982), (7, 0.03292705211788416), (42, 0.03618156164884567), (41, 0.04176690289750695), (27, 0.042953741271048784), (9, 0.044010053388774395), (6, 0.047114414162933826), (14, 0.0482461485080421), (4, 0.048896615859121084), (2, 0.05493976594880223), (3, 0.0588477049022913), (13, 0.05968277435749769), (11, 0.05999665940180421), (17, 0.06281342636793852), (0, 0.06486068479716778), (1, 0.06724131014198065), (8, 0.0755079248920083), (10, 0.08195420634001493), (16, 0.0861166575923562), (12, 0.09086475893855095), (5, 0.10828339774161577), (36, 0.32469165325164795), (18, 0.5180077776312828), (53, 0.9554894119501114)]
computing accuracy for after removing block 20 . block score: 0.02708749007433653
removed block 20 current accuracy 0.8192 loss from initial  0.13219999999999998
since last training loss: 0.12239999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.027256. All blocks and scores: [(52, 0.027256357949227095), (50, 0.02952944184653461), (51, 0.0297563502099365), (15, 0.03232082398608327), (19, 0.032511341385543346), (7, 0.03292705025523901), (42, 0.03523786552250385), (41, 0.04142360994592309), (27, 0.04189802473410964), (9, 0.04401005432009697), (6, 0.04711441323161125), (14, 0.04824614757671952), (4, 0.04889661492779851), (2, 0.05493976501747966), (3, 0.05884770583361387), (13, 0.05968277342617512), (11, 0.05999666033312678), (17, 0.06281342776492238), (0, 0.0648606801405549), (1, 0.06724130921065807), (8, 0.07550792675465345), (10, 0.08195420540869236), (16, 0.08611665852367878), (12, 0.09086475893855095), (5, 0.1082834005355835), (36, 0.32389383018016815), (18, 0.5180077627301216), (53, 0.9285249635577202)]
computing accuracy for after removing block 52 . block score: 0.027256357949227095
removed block 52 current accuracy 0.7788 loss from initial  0.17259999999999998
training start
training epoch 0 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 1 val accuracy 0.892 topk_dict {'top1': 0.892} is_best True lr [0.1]
training epoch 2 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 4 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 5 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.1]
training epoch 6 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 7 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 8 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 9 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.935600)
finished training. finished 50 epochs. accuracy 0.9356 topk_dict {'top1': 0.9356}
