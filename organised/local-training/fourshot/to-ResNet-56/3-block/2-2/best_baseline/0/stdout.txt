start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013294660719111562), (29, 0.013421116978861392), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019996492192149162), (46, 0.020590225467458367), (25, 0.02207829523831606), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.023145999060943723), (40, 0.023749590618535876), (45, 0.02397549571469426), (21, 0.02494108909741044), (48, 0.024957706220448017), (22, 0.0251513896510005), (50, 0.025287174154073), (24, 0.025880581699311733), (49, 0.025916648795828223), (42, 0.026232231175526977), (20, 0.026848892215639353), (47, 0.0286329488735646), (38, 0.0313443448394537), (39, 0.0314412962179631), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.04178758803755045), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241091430187), (2, 0.054577406495809555), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464461103082), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4361986331641674), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013119243667460978), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016093928134068847), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01985268690623343), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022977193351835012), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.02454021736048162), (50, 0.02477082284167409), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025575740030035377), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.026848892448469996), (47, 0.02807276090607047), (38, 0.03109118901193142), (39, 0.031191360903903842), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.037973211612552404), (51, 0.04127101367339492), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241463959217), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525531575084), (0, 0.06337464554235339), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.43398062512278557), (18, 0.5117432996630669), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581291347742), (34, 0.012758882250636816), (29, 0.013421116746030748), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019850464770570397), (46, 0.02041191654279828), (41, 0.021827629301697016), (25, 0.022078294539824128), (23, 0.022228716406971216), (44, 0.02289147791452706), (40, 0.023602580651640892), (45, 0.02377084968611598), (48, 0.02451987355016172), (50, 0.024639350129291415), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.025712220463901758), (24, 0.02588058332912624), (20, 0.026848891517147422), (47, 0.028052505338564515), (38, 0.030935873510316014), (39, 0.031173037132248282), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038343189749866724), (51, 0.04113080818206072), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464926764369), (52, 0.06441722856834531), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537981152534), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159961543977), (29, 0.013421116629615426), (35, 0.01591864973306656), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.021756020141765475), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.023001376539468765), (40, 0.02373992674984038), (45, 0.023790169041603804), (48, 0.024350045016035438), (50, 0.024463105713948607), (21, 0.024941088864579797), (22, 0.025151390582323074), (49, 0.025246930308640003), (42, 0.02527355100028217), (24, 0.025880583096295595), (20, 0.026848891051486135), (47, 0.027727575972676277), (38, 0.030746273696422577), (39, 0.03128179535269737), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077769815922), (37, 0.03895266726613045), (51, 0.04082479793578386), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.061325255781412125), (0, 0.06337464554235339), (52, 0.06356756202876568), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116396784782), (35, 0.015968912513926625), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01983700878918171), (46, 0.020137187326326966), (41, 0.021584055852144957), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022687324322760105), (40, 0.023569098440930247), (45, 0.023840720765292645), (48, 0.024108359357342124), (50, 0.02411420946009457), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.02742385142482817), (38, 0.030735649866983294), (39, 0.031410425901412964), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03908350970596075), (51, 0.04034594027325511), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.0613252529874444), (52, 0.06270107952877879), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.43692685291171074), (18, 0.5117432847619057), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324198063462973), (41, 0.02196270297281444), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.023045078152790666), (48, 0.02402454731054604), (50, 0.02409697324037552), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922373704612255), (21, 0.024941088631749153), (22, 0.025151390116661787), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.027568295365199447), (38, 0.03178726346231997), (15, 0.0320583856664598), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.05914428550750017), (11, 0.05970003269612789), (17, 0.061325253918766975), (52, 0.062210946809500456), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.44933703169226646), (18, 0.5117433071136475), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.1]
training epoch 1 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.1]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.1]
training epoch 3 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.1]
training epoch 4 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.1]
training epoch 5 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.1]
training epoch 6 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.1]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 8 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.1]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.011081. All blocks and scores: [(35, 0.011081169825047255), (28, 0.01262790581677109), (27, 0.012942938832566142), (26, 0.016280912095680833), (43, 0.02015956537798047), (46, 0.02075355756096542), (25, 0.02208820008672774), (41, 0.0223910768982023), (23, 0.022489071590825915), (44, 0.02310780226252973), (45, 0.023529017809778452), (40, 0.024276472628116608), (48, 0.02430289681069553), (50, 0.025106655433773994), (21, 0.025141982594504952), (22, 0.025248598540201783), (49, 0.02568336552940309), (42, 0.02580560534261167), (24, 0.026306119514629245), (20, 0.027125223074108362), (47, 0.02820092043839395), (15, 0.03216578345745802), (39, 0.03226742101833224), (38, 0.03230668185278773), (19, 0.03263095300644636), (7, 0.032705577090382576), (37, 0.040207633282989264), (51, 0.041309508960694075), (9, 0.04389169067144394), (6, 0.046635011211037636), (4, 0.046716276090592146), (14, 0.04793953895568848), (2, 0.05487721972167492), (3, 0.05750057427212596), (13, 0.059377995785325766), (11, 0.05975096020847559), (17, 0.06235597329214215), (0, 0.06355368532240391), (52, 0.06437620427459478), (1, 0.06678753532469273), (8, 0.07499516755342484), (10, 0.08124581351876259), (16, 0.086321160197258), (12, 0.0899007199332118), (5, 0.10591309145092964), (36, 0.35496797412633896), (18, 0.5140317231416702), (53, 0.7870998904109001)]
computing accuracy for after removing block 35 . block score: 0.011081169825047255
removed block 35 current accuracy 0.9448 loss from initial  0.00660000000000005
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.012628. All blocks and scores: [(28, 0.01262790581677109), (27, 0.012942938599735498), (26, 0.016280911630019546), (43, 0.019198605325073004), (46, 0.019614694407209754), (41, 0.020646205637603998), (25, 0.022088200552389026), (23, 0.02248907182365656), (44, 0.022492125863209367), (48, 0.0226606628857553), (45, 0.022718857508152723), (40, 0.02301972173154354), (50, 0.023721482837572694), (42, 0.024134608218446374), (49, 0.024388670222833753), (21, 0.02514198189601302), (22, 0.025248599471524358), (24, 0.0263061192817986), (20, 0.02712522237561643), (47, 0.027225429425016046), (39, 0.030497211730107665), (38, 0.031182368751615286), (15, 0.03216578392311931), (19, 0.032630953937768936), (7, 0.03270557755604386), (37, 0.03760149562731385), (51, 0.03949212655425072), (9, 0.043891691602766514), (6, 0.046635009814053774), (4, 0.04671627655625343), (14, 0.047939537558704615), (2, 0.05487721785902977), (3, 0.05750057473778725), (13, 0.059377995785325766), (11, 0.059750961139798164), (52, 0.06064244592562318), (17, 0.0623559751547873), (0, 0.06355368532240391), (1, 0.06678753718733788), (8, 0.07499516662210226), (10, 0.08124581445008516), (16, 0.08632116205990314), (12, 0.08990072086453438), (5, 0.10591309051960707), (36, 0.34295735880732536), (18, 0.5140317156910896), (53, 0.8218476176261902)]
computing accuracy for after removing block 28 . block score: 0.01262790581677109
removed block 28 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 27, with score 0.012943. All blocks and scores: [(27, 0.012942939065396786), (26, 0.016280911630019546), (46, 0.01890382426790893), (43, 0.01908607385121286), (41, 0.020326552214100957), (48, 0.021978258155286312), (25, 0.022088201018050313), (45, 0.022458583116531372), (23, 0.02248907182365656), (44, 0.022599331568926573), (40, 0.022726841503754258), (50, 0.02322086226195097), (42, 0.023711706744506955), (49, 0.023733854293823242), (21, 0.02514198236167431), (22, 0.025248598773032427), (47, 0.02617628127336502), (24, 0.026306119514629245), (20, 0.027125223074108362), (39, 0.030814846511930227), (38, 0.031143730506300926), (15, 0.03216578532010317), (19, 0.03263095300644636), (7, 0.03270557755604386), (37, 0.03828844428062439), (51, 0.03874284587800503), (9, 0.04389169067144394), (6, 0.046635009814053774), (4, 0.04671627748757601), (14, 0.047939539421349764), (2, 0.054877220652997494), (3, 0.05750057613477111), (52, 0.05928967287763953), (13, 0.059377997647970915), (11, 0.05975096160545945), (17, 0.06235597329214215), (0, 0.06355368345975876), (1, 0.0667875362560153), (8, 0.07499516475945711), (10, 0.08124581631273031), (16, 0.08632116299122572), (12, 0.08990072179585695), (5, 0.10591309424489737), (36, 0.34771110489964485), (18, 0.5140317156910896), (53, 0.8324234336614609)]
computing accuracy for after removing block 27 . block score: 0.012942939065396786
removed block 27 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 26, with score 0.016281. All blocks and scores: [(26, 0.016280911164358258), (46, 0.01859497604891658), (43, 0.01926357694901526), (41, 0.020440052961930633), (48, 0.021747593069449067), (25, 0.022088200552389026), (45, 0.02240030001848936), (23, 0.022489071590825915), (44, 0.022675806190818548), (40, 0.022700642002746463), (50, 0.022817926481366158), (49, 0.02339725778438151), (42, 0.02379172877408564), (21, 0.02514198236167431), (22, 0.025248598074540496), (47, 0.025514810578897595), (24, 0.0263061192817986), (20, 0.027125223074108362), (39, 0.03136167023330927), (38, 0.03154958598315716), (15, 0.03216578485444188), (19, 0.03263095300644636), (7, 0.03270557755604386), (51, 0.0379164214245975), (37, 0.040112581104040146), (9, 0.04389169020578265), (6, 0.04663501167669892), (4, 0.04671627702191472), (14, 0.04793954035267234), (2, 0.05487721785902977), (3, 0.05750057753175497), (52, 0.05795600451529026), (13, 0.05937799485400319), (11, 0.05975096067413688), (17, 0.06235597236081958), (0, 0.06355368439108133), (1, 0.06678753718733788), (8, 0.07499516848474741), (10, 0.08124581445008516), (16, 0.086321160197258), (12, 0.0899007199332118), (5, 0.10591309238225222), (36, 0.35449766367673874), (18, 0.5140317380428314), (53, 0.8367368280887604)]
computing accuracy for after removing block 26 . block score: 0.016280911164358258
removed block 26 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.018107. All blocks and scores: [(46, 0.018107211217284203), (43, 0.018775336677208543), (41, 0.019503701012581587), (48, 0.02106614038348198), (40, 0.021879376145079732), (45, 0.022010680520907044), (25, 0.022088200552389026), (42, 0.022144865244627), (50, 0.022176701575517654), (44, 0.022393594030290842), (23, 0.022489070892333984), (49, 0.022986333118751645), (47, 0.02488919231109321), (21, 0.025141982128843665), (22, 0.025248597841709852), (24, 0.02630611974745989), (20, 0.027125222608447075), (38, 0.030402017990127206), (39, 0.03051788453012705), (15, 0.03216578485444188), (19, 0.03263095347210765), (7, 0.03270557755604386), (51, 0.03653971944004297), (37, 0.03878397261723876), (9, 0.04389169067144394), (6, 0.046635011211037636), (4, 0.04671627748757601), (14, 0.0479395380243659), (2, 0.05487722158432007), (52, 0.05580103909596801), (3, 0.05750057473778725), (13, 0.05937799671664834), (11, 0.05975096020847559), (17, 0.06235597422346473), (0, 0.06355368159711361), (1, 0.06678753718733788), (8, 0.07499516382813454), (10, 0.08124581258744001), (16, 0.08632116205990314), (12, 0.08990071900188923), (5, 0.10591309797018766), (36, 0.34529537335038185), (18, 0.5140317156910896), (53, 0.8642699792981148)]
computing accuracy for after removing block 46 . block score: 0.018107211217284203
removed block 46 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.018775. All blocks and scores: [(43, 0.018775336910039186), (41, 0.01950370194390416), (48, 0.02118265675380826), (40, 0.021879375213757157), (45, 0.02201068098656833), (25, 0.02208820078521967), (42, 0.022144865477457643), (50, 0.022222211118787527), (44, 0.022393594263121486), (23, 0.022489071125164628), (49, 0.023558700922876596), (21, 0.02514198236167431), (22, 0.02524859900586307), (24, 0.0263061192817986), (47, 0.026429348159581423), (20, 0.02712522353976965), (38, 0.030402017291635275), (39, 0.03051788406446576), (15, 0.032165784388780594), (19, 0.03263095347210765), (7, 0.03270557755604386), (51, 0.03661424061283469), (37, 0.03878397215157747), (9, 0.04389168927446008), (6, 0.04663501074537635), (4, 0.046716276090592146), (14, 0.04793953849002719), (2, 0.05487721925601363), (52, 0.055479328613728285), (3, 0.0575005728751421), (13, 0.05937799531966448), (11, 0.05975096067413688), (17, 0.062355972826480865), (0, 0.06355368345975876), (1, 0.0667875362560153), (8, 0.07499516662210226), (10, 0.08124581258744001), (16, 0.08632116205990314), (12, 0.0899007199332118), (5, 0.10591309610754251), (36, 0.34529536589980125), (18, 0.514031708240509), (53, 0.9596736654639244)]
computing accuracy for after removing block 43 . block score: 0.018775336910039186
removed block 43 current accuracy 0.9228 loss from initial  0.02860000000000007
training start
training epoch 0 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 1 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.1]
training epoch 2 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 3 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 4 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 5 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.1]
training epoch 6 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.1]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 8 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.1]
training epoch 9 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.009824. All blocks and scores: [(48, 0.00982385512907058), (45, 0.011262714746408165), (44, 0.011996836983598769), (41, 0.01240155182313174), (42, 0.014881465351209044), (47, 0.016679142136126757), (37, 0.021176294656470418), (23, 0.02239128085784614), (40, 0.023688555229455233), (21, 0.025100444676354527), (22, 0.025284394854679704), (20, 0.027297349646687508), (50, 0.02800426702015102), (49, 0.029289672849699855), (39, 0.03147262171842158), (15, 0.032308878377079964), (7, 0.0324135972186923), (38, 0.03244580281898379), (19, 0.03270757757127285), (25, 0.036155521869659424), (24, 0.038804051000624895), (51, 0.042800687719136477), (9, 0.04340152628719807), (6, 0.04646491212770343), (4, 0.046552222687751055), (14, 0.048005154356360435), (2, 0.05431077629327774), (3, 0.05801563709974289), (13, 0.059640781953930855), (11, 0.05975928297266364), (17, 0.06261350959539413), (0, 0.06398250441998243), (1, 0.06611277349293232), (52, 0.06855033524334431), (8, 0.07525505777448416), (10, 0.0814663078635931), (16, 0.08561241067945957), (12, 0.09022590797394514), (5, 0.10623507853597403), (36, 0.28697042539715767), (18, 0.5150113329291344), (53, 0.7884641066193581)]
computing accuracy for after removing block 48 . block score: 0.00982385512907058
removed block 48 current accuracy 0.942 loss from initial  0.009400000000000075
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.011263. All blocks and scores: [(45, 0.011262714979238808), (44, 0.011996836867183447), (41, 0.012401551590301096), (42, 0.014881465234793723), (47, 0.016679142834618688), (37, 0.02117629488930106), (23, 0.022391279926523566), (40, 0.023688554763793945), (21, 0.025100445142015815), (22, 0.025284394389018416), (20, 0.02729735034517944), (50, 0.030383042292669415), (49, 0.03139074449427426), (39, 0.03147262125276029), (15, 0.03230887930840254), (7, 0.0324135972186923), (38, 0.03244580328464508), (19, 0.03270757896825671), (25, 0.03615552233532071), (24, 0.038804051000624895), (51, 0.04146196832880378), (9, 0.043401526752859354), (6, 0.04646491166204214), (4, 0.04655222222208977), (14, 0.048005156219005585), (2, 0.05431077815592289), (3, 0.05801563709974289), (13, 0.059640785213559866), (11, 0.05975928483530879), (17, 0.06261350912973285), (0, 0.06398250348865986), (1, 0.0661127744242549), (52, 0.0708578871563077), (8, 0.07525505870580673), (10, 0.0814663115888834), (16, 0.085612409748137), (12, 0.09022590704262257), (5, 0.10623508039861917), (36, 0.28697041794657707), (18, 0.5150113478302956), (53, 0.8197204098105431)]
computing accuracy for after removing block 45 . block score: 0.011262714979238808
removed block 45 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.011997. All blocks and scores: [(44, 0.011996836983598769), (41, 0.012401551473885775), (42, 0.014881465001963079), (47, 0.01686564227566123), (37, 0.021176294423639774), (23, 0.02239128085784614), (40, 0.02368855569511652), (21, 0.025100444676354527), (22, 0.025284394854679704), (20, 0.02729734987951815), (50, 0.030347308376803994), (39, 0.03147262125276029), (49, 0.031923377653583884), (15, 0.032308878377079964), (7, 0.0324135972186923), (38, 0.03244580281898379), (19, 0.03270757757127285), (25, 0.036155522800982), (24, 0.038804051000624895), (51, 0.03945016209036112), (9, 0.04340152628719807), (6, 0.046464911196380854), (4, 0.04655222361907363), (14, 0.048005156219005585), (2, 0.05431077862158418), (3, 0.05801563989371061), (13, 0.05964078288525343), (11, 0.059759285766631365), (17, 0.06261350912973285), (0, 0.06398249976336956), (52, 0.0648226928897202), (1, 0.06611277163028717), (8, 0.07525505870580673), (10, 0.08146630879491568), (16, 0.08561240881681442), (12, 0.09022590424865484), (5, 0.1062350757420063), (36, 0.28697042539715767), (18, 0.515011340379715), (53, 0.891488328576088)]
computing accuracy for after removing block 44 . block score: 0.011996836983598769
removed block 44 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.012402. All blocks and scores: [(41, 0.01240155182313174), (42, 0.014881465234793723), (47, 0.01642806106247008), (37, 0.021176294423639774), (23, 0.02239128085784614), (40, 0.02368855499662459), (21, 0.025100443977862597), (22, 0.025284394854679704), (20, 0.027297348948195577), (50, 0.029227255145087838), (49, 0.030216742074117064), (39, 0.031472620787099004), (15, 0.03230887884274125), (7, 0.0324135972186923), (38, 0.03244580375030637), (19, 0.03270757710561156), (25, 0.03615552233532071), (51, 0.038798227440565825), (24, 0.03880405053496361), (9, 0.04340152582153678), (6, 0.04646491026505828), (4, 0.04655222222208977), (14, 0.048005152959376574), (2, 0.05431077862158418), (3, 0.058015638031065464), (13, 0.059640781953930855), (11, 0.0597592843696475), (52, 0.060440195724368095), (17, 0.06261350773274899), (0, 0.06398249976336956), (1, 0.06611277163028717), (8, 0.07525505591183901), (10, 0.08146630972623825), (16, 0.08561240788549185), (12, 0.09022590611129999), (5, 0.10623507667332888), (36, 0.28697043284773827), (18, 0.515011340379715), (53, 0.9867214411497116)]
computing accuracy for after removing block 41 . block score: 0.01240155182313174
removed block 41 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.013832. All blocks and scores: [(42, 0.013832170981913805), (47, 0.015626376844011247), (37, 0.02117629488930106), (23, 0.022391281090676785), (40, 0.023688555229455233), (21, 0.025100444676354527), (22, 0.025284394389018416), (20, 0.027297349413856864), (50, 0.027634412283077836), (49, 0.029006190598011017), (39, 0.031472620787099004), (15, 0.032308878377079964), (7, 0.03241359768435359), (38, 0.03244580328464508), (19, 0.03270757710561156), (51, 0.03600512258708477), (25, 0.036155523266643286), (24, 0.03880405006930232), (9, 0.04340152582153678), (6, 0.046464911196380854), (4, 0.04655222315341234), (14, 0.04800515482202172), (2, 0.05431077815592289), (52, 0.05459554214030504), (3, 0.05801563709974289), (13, 0.059640781953930855), (11, 0.05975928111001849), (17, 0.06261350912973285), (0, 0.06398250162601471), (1, 0.06611277349293232), (8, 0.07525505870580673), (10, 0.08146631252020597), (16, 0.08561240788549185), (12, 0.09022590611129999), (5, 0.1062350794672966), (36, 0.28697041794657707), (18, 0.5150113254785538), (53, 1.0556201189756393)]
computing accuracy for after removing block 42 . block score: 0.013832170981913805
removed block 42 current accuracy 0.9166 loss from initial  0.03480000000000005
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 47, with score 0.016125. All blocks and scores: [(47, 0.016125048976391554), (37, 0.021176295122131705), (23, 0.02239128085784614), (40, 0.023688554763793945), (21, 0.02510044537484646), (22, 0.02528439462184906), (20, 0.02729734918102622), (50, 0.027456431882455945), (49, 0.029020532965660095), (39, 0.03147262171842158), (15, 0.032308878377079964), (7, 0.032413596753031015), (38, 0.03244580328464508), (19, 0.03270757757127285), (25, 0.03615552233532071), (51, 0.03639225894585252), (24, 0.03880405053496361), (9, 0.04340152768418193), (6, 0.04646490979939699), (4, 0.04655222315341234), (14, 0.04800515528768301), (2, 0.05431077815592289), (52, 0.055364223662763834), (3, 0.05801563756540418), (13, 0.05964078148826957), (11, 0.05975928157567978), (17, 0.06261350680142641), (0, 0.06398250255733728), (1, 0.0661127744242549), (8, 0.07525505684316158), (10, 0.0814663078635931), (16, 0.085612409748137), (12, 0.09022590704262257), (5, 0.1062350794672966), (36, 0.28697042167186737), (18, 0.515011340379715), (53, 1.1184887737035751)]
computing accuracy for after removing block 47 . block score: 0.016125048976391554
removed block 47 current accuracy 0.8918 loss from initial  0.059599999999999986
training start
training epoch 0 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.1]
training epoch 1 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.1]
training epoch 2 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.1]
training epoch 3 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.1]
training epoch 4 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.1]
training epoch 5 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.1]
training epoch 6 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 7 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 8 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.1]
training epoch 9 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.1]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.937600)
finished training. finished 50 epochs. accuracy 0.9376 topk_dict {'top1': 0.9376}
start iteration 18
[activation diff]: block to remove picked: 37, with score 0.020911. All blocks and scores: [(37, 0.020910930121317506), (50, 0.022411522921174765), (23, 0.022491399897262454), (21, 0.025077587692067027), (22, 0.025377174140885472), (20, 0.026976571651175618), (49, 0.03031299659051001), (15, 0.03208780428394675), (38, 0.0322132077999413), (19, 0.03261013049632311), (7, 0.03275257209315896), (40, 0.034315756522119045), (25, 0.036145707592368126), (24, 0.0387168419547379), (51, 0.04334091115742922), (39, 0.043572669848799706), (9, 0.04396028816699982), (6, 0.046841605100780725), (14, 0.04799011815339327), (4, 0.04893254488706589), (2, 0.05510420864447951), (3, 0.05848905397579074), (13, 0.05914199771359563), (11, 0.05961923487484455), (17, 0.061624910682439804), (0, 0.0637572593986988), (1, 0.0665841642767191), (52, 0.0682803625240922), (8, 0.07438501995056868), (10, 0.08142517972737551), (16, 0.08414837904274464), (12, 0.09054214134812355), (5, 0.10617521684616804), (36, 0.28611970692873), (18, 0.5140351876616478), (53, 0.8114021718502045)]
computing accuracy for after removing block 37 . block score: 0.020910930121317506
removed block 37 current accuracy 0.9324 loss from initial  0.019000000000000017
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.020803. All blocks and scores: [(50, 0.02080273488536477), (23, 0.02249139896593988), (21, 0.025077588856220245), (22, 0.025377174140885472), (20, 0.026976571884006262), (49, 0.028481661807745695), (15, 0.032087803818285465), (19, 0.032610130961984396), (7, 0.032752569764852524), (40, 0.03382253972813487), (25, 0.03614570666104555), (38, 0.03654398396611214), (24, 0.0387168419547379), (51, 0.03988514794036746), (39, 0.043727141339331865), (9, 0.04396028770133853), (6, 0.04684160416945815), (14, 0.04799011768773198), (4, 0.0489325444214046), (2, 0.055104210041463375), (3, 0.058489054907113314), (13, 0.05914199771359563), (11, 0.05961923487484455), (17, 0.06162491021677852), (52, 0.061809934210032225), (0, 0.06375725660473108), (1, 0.0665841642767191), (8, 0.07438501808792353), (10, 0.08142518065869808), (16, 0.08414837904274464), (12, 0.09054214041680098), (5, 0.10617521870881319), (36, 0.2861196994781494), (18, 0.5140351727604866), (53, 0.8326953053474426)]
computing accuracy for after removing block 50 . block score: 0.02080273488536477
removed block 50 current accuracy 0.913 loss from initial  0.03839999999999999
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.022491. All blocks and scores: [(23, 0.022491399198770523), (21, 0.02507758792489767), (22, 0.025377173675224185), (20, 0.02697657118551433), (49, 0.028481661342084408), (15, 0.03208780474960804), (19, 0.03261013142764568), (7, 0.03275257162749767), (40, 0.03382254159078002), (25, 0.03614570666104555), (38, 0.036543984431773424), (24, 0.03871684102341533), (39, 0.04372714180499315), (9, 0.04396028630435467), (51, 0.04522343724966049), (6, 0.04684160556644201), (14, 0.047990117222070694), (4, 0.04893254302442074), (2, 0.055104211904108524), (3, 0.05848905583843589), (13, 0.05914199724793434), (11, 0.0596192367374897), (17, 0.06162491114810109), (0, 0.0637572593986988), (1, 0.06658416520804167), (52, 0.0733112683519721), (8, 0.0743850190192461), (10, 0.08142517879605293), (16, 0.08414837624877691), (12, 0.09054214041680098), (5, 0.10617521870881319), (36, 0.2861197106540203), (18, 0.5140351802110672), (53, 0.9602295905351639)]
computing accuracy for after removing block 23 . block score: 0.022491399198770523
removed block 23 current accuracy 0.9094 loss from initial  0.04200000000000004
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.025078. All blocks and scores: [(21, 0.02507758722640574), (22, 0.025377174373716116), (20, 0.026976571418344975), (49, 0.02829582989215851), (15, 0.03208780474960804), (19, 0.03261013235896826), (7, 0.03275257162749767), (40, 0.0331537164747715), (25, 0.03528346633538604), (24, 0.03652060590684414), (38, 0.036640869453549385), (39, 0.04388619540259242), (9, 0.04396028770133853), (51, 0.044140763115137815), (6, 0.04684160277247429), (14, 0.04799011768773198), (4, 0.048932545352727175), (2, 0.05510421143844724), (3, 0.058489053044468164), (13, 0.05914199724793434), (11, 0.059619235806167126), (17, 0.061624910682439804), (0, 0.06375725753605366), (1, 0.06658416520804167), (52, 0.07024044264107943), (8, 0.07438501995056868), (10, 0.08142517972737551), (16, 0.08414837811142206), (12, 0.09054213855415583), (5, 0.10617521870881319), (36, 0.285396333783865), (18, 0.5140351802110672), (53, 0.9684216305613518)]
computing accuracy for after removing block 21 . block score: 0.02507758722640574
removed block 21 current accuracy 0.9004 loss from initial  0.051000000000000045
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.023619. All blocks and scores: [(22, 0.023618535604327917), (49, 0.02662654803134501), (20, 0.026976571884006262), (40, 0.03080325131304562), (15, 0.03208780335262418), (19, 0.03261013003066182), (7, 0.03275257209315896), (25, 0.03352947533130646), (24, 0.03359224833548069), (38, 0.03462280659005046), (39, 0.041398297529667616), (51, 0.041465874295681715), (9, 0.04396028630435467), (6, 0.04684160416945815), (14, 0.04799011815339327), (4, 0.04893254488706589), (2, 0.055104210041463375), (52, 0.05807166546583176), (3, 0.05848905397579074), (13, 0.05914199724793434), (11, 0.0596192330121994), (17, 0.06162490835413337), (0, 0.0637572593986988), (1, 0.0665841642767191), (8, 0.07438501808792353), (10, 0.08142518065869808), (16, 0.08414837811142206), (12, 0.0905421394854784), (5, 0.10617522150278091), (36, 0.2689635902643204), (18, 0.5140351727604866), (53, 1.0135602951049805)]
computing accuracy for after removing block 22 . block score: 0.023618535604327917
removed block 22 current accuracy 0.8856 loss from initial  0.06579999999999997
since last training loss: 0.051999999999999935 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 49, with score 0.025466. All blocks and scores: [(49, 0.025465706596150994), (20, 0.02697657118551433), (40, 0.029531351989135146), (24, 0.031216104282066226), (15, 0.03208780428394675), (25, 0.03230121172964573), (19, 0.032610130961984396), (7, 0.03275257162749767), (38, 0.03468387387692928), (51, 0.038947734516113997), (39, 0.04019268788397312), (9, 0.04396028630435467), (6, 0.04684160556644201), (14, 0.047990117222070694), (4, 0.04893254395574331), (52, 0.05167188309133053), (2, 0.05510421097278595), (3, 0.058489054907113314), (13, 0.05914199724793434), (11, 0.059619235806167126), (17, 0.061624906957149506), (0, 0.06375725567340851), (1, 0.06658416334539652), (8, 0.07438501808792353), (10, 0.08142518065869808), (16, 0.08414837811142206), (12, 0.09054213855415583), (5, 0.10617521684616804), (36, 0.2646969147026539), (18, 0.5140351802110672), (53, 1.0198445916175842)]
computing accuracy for after removing block 49 . block score: 0.025465706596150994
removed block 49 current accuracy 0.8504 loss from initial  0.10099999999999998
since last training loss: 0.08719999999999994 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.026977. All blocks and scores: [(20, 0.026976571418344975), (40, 0.02953135222196579), (24, 0.031216104747727513), (15, 0.03208780428394675), (25, 0.03230121172964573), (19, 0.03261013142764568), (7, 0.03275257162749767), (38, 0.03468387480825186), (51, 0.03953818744048476), (39, 0.04019268788397312), (9, 0.04396028770133853), (6, 0.04684160416945815), (14, 0.047990118619054556), (4, 0.04893254395574331), (2, 0.055104210041463375), (52, 0.055680726654827595), (3, 0.058489056304097176), (13, 0.05914199771359563), (11, 0.059619233943521976), (17, 0.061624906957149506), (0, 0.0637572593986988), (1, 0.06658416800200939), (8, 0.07438501715660095), (10, 0.08142517879605293), (16, 0.08414837904274464), (12, 0.09054214134812355), (5, 0.10617521964013577), (36, 0.2646969184279442), (18, 0.5140351802110672), (53, 1.2314615696668625)]
computing accuracy for after removing block 20 . block score: 0.026976571418344975
removed block 20 current accuracy 0.8266 loss from initial  0.12480000000000002
since last training loss: 0.11099999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 40, with score 0.029455. All blocks and scores: [(40, 0.029455229872837663), (24, 0.030891831498593092), (15, 0.03208780335262418), (25, 0.032126793172210455), (19, 0.032610130961984396), (7, 0.032752573024481535), (38, 0.03432983346283436), (51, 0.03823406994342804), (39, 0.038953219540417194), (9, 0.043960286770015955), (6, 0.04684160556644201), (14, 0.047990118619054556), (4, 0.04893254395574331), (52, 0.0506534269079566), (2, 0.055104210041463375), (3, 0.058489054441452026), (13, 0.05914199911057949), (11, 0.059619235806167126), (17, 0.06162490788847208), (0, 0.06375725660473108), (1, 0.06658416334539652), (8, 0.07438501808792353), (10, 0.08142517972737551), (16, 0.08414837718009949), (12, 0.09054214041680098), (5, 0.10617521405220032), (36, 0.2656197212636471), (18, 0.5140351876616478), (53, 1.2350595593452454)]
computing accuracy for after removing block 40 . block score: 0.029455229872837663
removed block 40 current accuracy 0.7374 loss from initial  0.21399999999999997
since last training loss: 0.20019999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.030892. All blocks and scores: [(24, 0.030891831032931805), (15, 0.032087803818285465), (25, 0.03212679224088788), (19, 0.03261013049632311), (7, 0.032752571161836386), (38, 0.03432983299717307), (51, 0.038482015021145344), (39, 0.03895322047173977), (9, 0.04396028816699982), (6, 0.04684160649776459), (14, 0.04799011675640941), (4, 0.04893254581838846), (2, 0.05510421050712466), (3, 0.05848905397579074), (13, 0.05914199724793434), (11, 0.05961923534050584), (17, 0.06162490975111723), (52, 0.06306349067017436), (0, 0.06375725846737623), (1, 0.06658416520804167), (8, 0.07438501808792353), (10, 0.08142517972737551), (16, 0.08414837718009949), (12, 0.09054214227944613), (5, 0.10617521870881319), (36, 0.2656197138130665), (18, 0.5140351876616478), (53, 1.3582051992416382)]
computing accuracy for after removing block 24 . block score: 0.030891831032931805
removed block 24 current accuracy 0.6778 loss from initial  0.27360000000000007
training start
training epoch 0 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best True lr [0.1]
training epoch 1 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.1]
training epoch 2 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 3 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 4 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 5 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 6 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.1]
training epoch 7 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 8 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.1]
training epoch 9 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 10 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.935000)
finished training. finished 50 epochs. accuracy 0.935 topk_dict {'top1': 0.935}
