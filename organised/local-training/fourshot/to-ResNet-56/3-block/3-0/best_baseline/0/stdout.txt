start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.01023258175700903), (34, 0.013294660835526884), (29, 0.013421116629615426), (35, 0.015957689378410578), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.01999649195931852), (46, 0.02059022500179708), (25, 0.022078295703977346), (23, 0.022228715009987354), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749589920043945), (45, 0.023975494550541043), (21, 0.024941088864579797), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.025880582630634308), (49, 0.02591664926148951), (42, 0.026232231175526977), (20, 0.026848891749978065), (47, 0.028632949339225888), (38, 0.031344345305114985), (39, 0.03144129482097924), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740696147084), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527505863457918), (12, 0.09039537515491247), (5, 0.10671143885701895), (36, 0.4361986331641674), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013119243667460978), (29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016093928134068847), (28, 0.017636860720813274), (27, 0.01902279839850962), (43, 0.019852687371894717), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022977193351835012), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.024770823307335377), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.02557574026286602), (24, 0.025880582630634308), (42, 0.02589341253042221), (20, 0.026848892215639353), (47, 0.028072760673239827), (38, 0.031091188080608845), (39, 0.031191361602395773), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464367970824), (52, 0.06493351748213172), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.013421116513200104), (35, 0.015918421559035778), (26, 0.01607214123941958), (28, 0.01763686165213585), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411916309967637), (41, 0.021827629301697016), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022891478845849633), (40, 0.02360257995314896), (45, 0.023770849220454693), (48, 0.024519872618839145), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.0253925493452698), (42, 0.025712220696732402), (24, 0.02588058216497302), (20, 0.026848892215639353), (47, 0.02805250370875001), (38, 0.030935873510316014), (39, 0.03117303759790957), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.04337632795795798), (6, 0.04682369437068701), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117432922124863), (53, 0.8136166930198669)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350114509463), (46, 0.02027974370867014), (41, 0.02175602037459612), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02300137677229941), (40, 0.023739926051348448), (45, 0.02379016811028123), (48, 0.024350044783204794), (50, 0.024463105481117964), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.025246930541470647), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027727575041353703), (38, 0.030746274162083864), (39, 0.031281794887036085), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03895266819745302), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.015968911815434694), (26, 0.016072141705080867), (28, 0.017636860720813274), (27, 0.01902279839850962), (43, 0.01983700809068978), (46, 0.020137187326326966), (41, 0.021584055852144957), (25, 0.022078294772654772), (23, 0.02222871594130993), (44, 0.022687325486913323), (40, 0.02356909797526896), (45, 0.023840721230953932), (48, 0.02410835982300341), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.024941088864579797), (42, 0.025045573944225907), (22, 0.025151390116661787), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02742385258898139), (38, 0.030735648469999433), (39, 0.03141042543575168), (15, 0.03205838520079851), (7, 0.032445501536130905), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593841060996), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.059700035490095615), (17, 0.06132525345310569), (52, 0.0627010790631175), (0, 0.06337464554235339), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111628036946), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.02030268427915871), (46, 0.02032419736497104), (41, 0.02196270227432251), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02304507722146809), (48, 0.024024547543376684), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168408941477537), (49, 0.024922373006120324), (21, 0.024941089563071728), (22, 0.025151390116661787), (42, 0.025816059671342373), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027568295365199447), (38, 0.03178726392798126), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.040690730325877666), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.061325253918766975), (52, 0.062210946809500456), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.44933703169226646), (18, 0.5117433071136475), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.01342111628036946
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.1]
training epoch 1 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.1]
training epoch 2 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.1]
training epoch 3 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.1]
training epoch 4 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.1]
training epoch 5 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.1]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.1]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.1]
training epoch 8 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.1]
training epoch 9 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.1]
training epoch 10 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.016347. All blocks and scores: [(35, 0.01634661969728768), (26, 0.018297640839591622), (28, 0.019230154575780034), (43, 0.020252485061064363), (46, 0.020529264118522406), (27, 0.02215494425036013), (41, 0.02221971401013434), (25, 0.022388109005987644), (23, 0.02254737983457744), (44, 0.02322007715702057), (40, 0.023747524246573448), (45, 0.024020491167902946), (48, 0.025024939561262727), (50, 0.02503137430176139), (21, 0.02515699784271419), (22, 0.02534719672985375), (49, 0.02574143069796264), (42, 0.025776946218684316), (24, 0.026137113803997636), (20, 0.027423917083069682), (47, 0.028385589830577374), (39, 0.03144113137386739), (38, 0.03156280564144254), (15, 0.032155639957636595), (19, 0.03230645414441824), (7, 0.032762708608061075), (37, 0.03781765140593052), (51, 0.042008135933429), (9, 0.04401505086570978), (6, 0.046954681165516376), (14, 0.04806230030953884), (4, 0.04827008442953229), (2, 0.054711248725652695), (3, 0.058828158769756556), (13, 0.05971162440255284), (11, 0.059957577381283045), (17, 0.06312102871015668), (0, 0.06513005215674639), (52, 0.0670764809474349), (1, 0.06819842103868723), (8, 0.07501748204231262), (10, 0.08178551401942968), (16, 0.08565669879317284), (12, 0.09059265535324812), (5, 0.10763146821409464), (36, 0.4361500255763531), (18, 0.5162581726908684), (53, 0.8032500669360161)]
computing accuracy for after removing block 35 . block score: 0.01634661969728768
removed block 35 current accuracy 0.9472 loss from initial  0.0041999999999999815
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.018298. All blocks and scores: [(26, 0.01829764060676098), (43, 0.01889169472269714), (28, 0.01923015434294939), (46, 0.019438195042312145), (41, 0.020174094941467047), (27, 0.02215494425036013), (40, 0.02230732375755906), (44, 0.022311763605102897), (25, 0.02238810947164893), (23, 0.022547379601746798), (45, 0.022984810173511505), (48, 0.023093466414138675), (42, 0.023322496563196182), (50, 0.023421793011948466), (49, 0.024461997905746102), (21, 0.02515699854120612), (22, 0.02534719556570053), (24, 0.026137113105505705), (47, 0.027308264514431357), (20, 0.027423915918916464), (39, 0.029340460198000073), (38, 0.029886015690863132), (15, 0.03215563949197531), (19, 0.03230645461007953), (7, 0.03276270814239979), (37, 0.03490485157817602), (51, 0.03976681223139167), (9, 0.04401505272835493), (6, 0.046954681631177664), (14, 0.0480623017065227), (4, 0.04827008303254843), (2, 0.05471124779433012), (3, 0.05882815783843398), (13, 0.05971162486821413), (11, 0.059957577381283045), (52, 0.06251124385744333), (17, 0.06312102917581797), (0, 0.06513005122542381), (1, 0.06819842290133238), (8, 0.07501748111099005), (10, 0.08178551215678453), (16, 0.08565669786185026), (12, 0.09059265814721584), (5, 0.10763146821409464), (36, 0.4151058755815029), (18, 0.5162581652402878), (53, 0.8438713476061821)]
computing accuracy for after removing block 26 . block score: 0.01829764060676098
removed block 26 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.018383. All blocks and scores: [(43, 0.018383124144747853), (28, 0.018572875065729022), (46, 0.019065241096541286), (41, 0.019674389623105526), (27, 0.021796843502670527), (40, 0.02195171848870814), (48, 0.02230653678998351), (42, 0.022345150122419), (25, 0.022388109238818288), (23, 0.022547379368916154), (44, 0.02263772999867797), (50, 0.0227655041962862), (45, 0.02280281181447208), (49, 0.02416864549741149), (21, 0.02515699784271419), (22, 0.025347196264192462), (24, 0.026137113105505705), (47, 0.02664935076609254), (20, 0.027423917315900326), (39, 0.029124659253284335), (38, 0.02964141359552741), (15, 0.03215564042329788), (19, 0.0323064555414021), (7, 0.0327627076767385), (37, 0.03509426303207874), (51, 0.038629655726253986), (9, 0.04401505133137107), (6, 0.04695468256250024), (14, 0.04806230077520013), (4, 0.04827008303254843), (2, 0.05471124639734626), (3, 0.05882816202938557), (13, 0.05971162533387542), (11, 0.05995757598429918), (52, 0.06016222620382905), (17, 0.0631210277788341), (0, 0.06513005215674639), (1, 0.06819842662662268), (8, 0.07501748017966747), (10, 0.08178551122546196), (16, 0.08565669879317284), (12, 0.09059265349060297), (5, 0.10763146635144949), (36, 0.41613294929265976), (18, 0.5162581577897072), (53, 0.8698181286454201)]
computing accuracy for after removing block 43 . block score: 0.018383124144747853
removed block 43 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.018573. All blocks and scores: [(28, 0.01857287483289838), (41, 0.019674389623105526), (46, 0.01969541353173554), (27, 0.021796843968331814), (40, 0.021951717557385564), (42, 0.022345150355249643), (25, 0.02238810947164893), (23, 0.022547379601746798), (50, 0.022788672940805554), (48, 0.023039927938953042), (45, 0.023851682897657156), (44, 0.023987423395738006), (49, 0.024006330175325274), (21, 0.025156998774036765), (22, 0.02534719556570053), (24, 0.02613711403682828), (47, 0.027420174796134233), (20, 0.02742391638457775), (39, 0.02912466018460691), (38, 0.029641414526849985), (15, 0.03215563856065273), (19, 0.032306455075740814), (7, 0.032762708608061075), (37, 0.03509426303207874), (51, 0.038169965613633394), (9, 0.044015051797032356), (6, 0.04695468209683895), (14, 0.048062301240861416), (4, 0.04827008489519358), (2, 0.05471124779433012), (3, 0.05882815783843398), (52, 0.05892206262797117), (13, 0.059711625799536705), (11, 0.05995757784694433), (17, 0.06312102684751153), (0, 0.06513005122542381), (1, 0.06819842290133238), (8, 0.07501748111099005), (10, 0.08178551495075226), (16, 0.08565669879317284), (12, 0.09059265349060297), (5, 0.10763147100806236), (36, 0.41613295301795006), (18, 0.5162581726908684), (53, 0.9123895615339279)]
computing accuracy for after removing block 28 . block score: 0.01857287483289838
removed block 28 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019348. All blocks and scores: [(46, 0.019348448608070612), (41, 0.019695808179676533), (27, 0.021796843968331814), (40, 0.022013019770383835), (42, 0.022171061486005783), (50, 0.022355231223627925), (25, 0.022388109704479575), (48, 0.022509038913995028), (23, 0.022547379368916154), (49, 0.023697230964899063), (45, 0.02374203153885901), (44, 0.02436630940064788), (21, 0.025156997377052903), (22, 0.025347195332869887), (24, 0.02613711403682828), (47, 0.026886460604146123), (20, 0.02742391638457775), (39, 0.029383912682533264), (38, 0.029987544286996126), (15, 0.03215563949197531), (19, 0.03230645461007953), (7, 0.0327627076767385), (37, 0.03576886374503374), (51, 0.037892000284045935), (9, 0.04401505086570978), (6, 0.046954681631177664), (14, 0.04806230030953884), (4, 0.048270083498209715), (2, 0.05471124639734626), (52, 0.05693258438259363), (3, 0.05882815783843398), (13, 0.059711627662181854), (11, 0.059957577381283045), (17, 0.06312102871015668), (0, 0.06513005122542381), (1, 0.0681984219700098), (8, 0.07501748390495777), (10, 0.08178551308810711), (16, 0.08565670065581799), (12, 0.09059265349060297), (5, 0.10763147193938494), (36, 0.4246365465223789), (18, 0.5162581652402878), (53, 0.9253650233149529)]
computing accuracy for after removing block 46 . block score: 0.019348448608070612
removed block 46 current accuracy 0.928 loss from initial  0.023399999999999976
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.019696. All blocks and scores: [(41, 0.019695808412507176), (27, 0.021796842338517308), (40, 0.02201302000321448), (42, 0.022171062184497714), (25, 0.022388109704479575), (50, 0.022512310883030295), (23, 0.02254737913608551), (48, 0.022838556673377752), (45, 0.023742031771689653), (44, 0.02436630940064788), (49, 0.024383466923609376), (21, 0.02515699854120612), (22, 0.025347195798531175), (24, 0.02613711333833635), (20, 0.027423917315900326), (47, 0.02849456830881536), (39, 0.02938391244970262), (38, 0.02998754335567355), (15, 0.032155639957636595), (19, 0.03230645461007953), (7, 0.032762708608061075), (37, 0.0357688651420176), (51, 0.037903651129454374), (9, 0.04401505086570978), (6, 0.046954681631177664), (14, 0.048062303103506565), (4, 0.04827008489519358), (2, 0.05471124732866883), (52, 0.05634895013645291), (3, 0.05882815783843398), (13, 0.05971162673085928), (11, 0.059957575518637896), (17, 0.06312102871015668), (0, 0.06513005029410124), (1, 0.0681984219700098), (8, 0.07501748111099005), (10, 0.08178551308810711), (16, 0.08565669786185026), (12, 0.09059265535324812), (5, 0.10763146821409464), (36, 0.4246365427970886), (18, 0.5162581577897072), (53, 1.018741488456726)]
computing accuracy for after removing block 41 . block score: 0.019695808412507176
removed block 41 current accuracy 0.9264 loss from initial  0.025000000000000022
training start
training epoch 0 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 1 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.1]
training epoch 2 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.1]
training epoch 3 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.1]
training epoch 4 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.1]
training epoch 5 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.1]
training epoch 6 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.1]
training epoch 7 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.1]
training epoch 8 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.1]
training epoch 9 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 10 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 15 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 12
[activation diff]: block to remove picked: 44, with score 0.013287. All blocks and scores: [(44, 0.01328692922834307), (45, 0.014140050276182592), (40, 0.01727837766520679), (42, 0.017676025396212935), (38, 0.024109512800350785), (21, 0.025101018836721778), (39, 0.02516626287251711), (22, 0.025318167870864272), (50, 0.026677033165469766), (20, 0.02708590030670166), (49, 0.027454177616164088), (48, 0.02818028093315661), (27, 0.029959814390167594), (23, 0.030196755658835173), (25, 0.03134015295654535), (15, 0.03225236991420388), (7, 0.03263006825000048), (19, 0.032839878462255), (47, 0.03343506157398224), (24, 0.03500632382929325), (37, 0.03766051586717367), (51, 0.041856300085783005), (9, 0.04418394947424531), (6, 0.04675759235396981), (4, 0.047902252059429884), (14, 0.04817851400002837), (2, 0.05524974409490824), (3, 0.05783655680716038), (11, 0.06020597042515874), (13, 0.060211971402168274), (17, 0.06287069618701935), (0, 0.06360320979729295), (52, 0.06657097022980452), (1, 0.0674083037301898), (8, 0.07513712346553802), (10, 0.08121866174042225), (16, 0.08757159113883972), (12, 0.09103199560195208), (5, 0.1071044048294425), (36, 0.4308033213019371), (18, 0.5148058161139488), (53, 0.8143421709537506)]
computing accuracy for after removing block 44 . block score: 0.01328692922834307
removed block 44 current accuracy 0.9428 loss from initial  0.008600000000000052
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.014820. All blocks and scores: [(45, 0.014819966978393495), (40, 0.017278377199545503), (42, 0.017676024697721004), (38, 0.024109512101858854), (21, 0.02510101953521371), (39, 0.02516626287251711), (22, 0.025318167870864272), (20, 0.02708590030670166), (50, 0.027163229417055845), (49, 0.02733147284016013), (48, 0.028077762108296156), (27, 0.02995981485582888), (23, 0.03019675542600453), (25, 0.03134015388786793), (15, 0.03225236851722002), (7, 0.03263006964698434), (19, 0.03283987892791629), (47, 0.034726692363619804), (24, 0.03500632382929325), (37, 0.0376605149358511), (51, 0.042081649880856276), (9, 0.0441839499399066), (6, 0.04675759328529239), (4, 0.04790225299075246), (14, 0.04817851260304451), (2, 0.055249744560569525), (3, 0.05783655866980553), (11, 0.060205972753465176), (13, 0.060211972799152136), (17, 0.06287069618701935), (0, 0.0636032042093575), (52, 0.06738639064133167), (1, 0.06740830466151237), (8, 0.0751371243968606), (10, 0.08121866546571255), (16, 0.08757158927619457), (12, 0.0910319983959198), (5, 0.10710440948605537), (36, 0.4308033175766468), (18, 0.5148057863116264), (53, 0.8723480701446533)]
computing accuracy for after removing block 45 . block score: 0.014819966978393495
removed block 45 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.017278. All blocks and scores: [(40, 0.017278378130868077), (42, 0.017676024930551648), (38, 0.02410951303318143), (21, 0.025101018603891134), (39, 0.025166262639686465), (22, 0.025318167870864272), (20, 0.02708589960820973), (50, 0.02808420150540769), (49, 0.028385210083797574), (48, 0.02876826492138207), (27, 0.02995981532149017), (23, 0.030196755891665816), (25, 0.03134015342220664), (15, 0.03225236898288131), (7, 0.03263006964698434), (19, 0.032839879393577576), (24, 0.035006323363631964), (47, 0.03622976550832391), (37, 0.0376605149358511), (51, 0.04185295384377241), (9, 0.04418395133689046), (6, 0.0467575928196311), (4, 0.04790225392207503), (14, 0.048178511671721935), (2, 0.055249744560569525), (3, 0.05783656006678939), (11, 0.06020597321912646), (13, 0.060211972799152136), (17, 0.06287069479003549), (0, 0.06360320933163166), (52, 0.06701073981821537), (1, 0.0674083037301898), (8, 0.07513712253421545), (10, 0.08121866453438997), (16, 0.08757159020751715), (12, 0.0910319946706295), (5, 0.1071044085547328), (36, 0.4308033213019371), (18, 0.5148057863116264), (53, 0.9283727630972862)]
computing accuracy for after removing block 40 . block score: 0.017278378130868077
removed block 40 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.017934. All blocks and scores: [(42, 0.017934288596734405), (38, 0.02410951186902821), (21, 0.02510101953521371), (39, 0.025166262639686465), (22, 0.02531816763803363), (20, 0.027085900073871017), (50, 0.028348487801849842), (49, 0.029193931724876165), (48, 0.029458690667524934), (27, 0.029959815088659525), (23, 0.03019675496034324), (25, 0.03134015295654535), (15, 0.03225236898288131), (7, 0.03263006918132305), (19, 0.032839878462255), (24, 0.03500632522627711), (37, 0.03766051586717367), (47, 0.03777828486636281), (51, 0.042002178728580475), (9, 0.04418395133689046), (6, 0.04675759095698595), (4, 0.047902252059429884), (14, 0.04817851213738322), (2, 0.055249742697924376), (3, 0.05783655773848295), (11, 0.060205972753465176), (13, 0.06021197326481342), (17, 0.06287069525569677), (0, 0.06360320886597037), (1, 0.06740830466151237), (52, 0.06824949011206627), (8, 0.07513712346553802), (10, 0.08121866546571255), (16, 0.08757159020751715), (12, 0.0910319983959198), (5, 0.10710440762341022), (36, 0.4308033101260662), (18, 0.5148058012127876), (53, 0.9900506511330605)]
computing accuracy for after removing block 42 . block score: 0.017934288596734405
removed block 42 current accuracy 0.9206 loss from initial  0.03080000000000005
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.024110. All blocks and scores: [(38, 0.024109512334689498), (21, 0.025101018603891134), (39, 0.02516626240685582), (22, 0.025318167405202985), (20, 0.02708589960820973), (27, 0.02995981532149017), (23, 0.03019675612449646), (49, 0.030268734553828835), (50, 0.030367274768650532), (25, 0.031340154353529215), (48, 0.031778117176145315), (15, 0.03225236898288131), (7, 0.03263006918132305), (19, 0.03283987985923886), (24, 0.03500632429495454), (37, 0.03766051586717367), (47, 0.041443913243710995), (51, 0.04268110450357199), (9, 0.04418395133689046), (6, 0.04675759142264724), (4, 0.0479022515937686), (14, 0.048178511671721935), (2, 0.055249744560569525), (3, 0.05783655866980553), (11, 0.06020597368478775), (13, 0.06021197373047471), (17, 0.0628706943243742), (0, 0.06360320607200265), (1, 0.06740830559283495), (52, 0.073093525134027), (8, 0.07513712346553802), (10, 0.08121866546571255), (16, 0.08757158927619457), (12, 0.09103199746459723), (5, 0.10710440948605537), (36, 0.430803332477808), (18, 0.514805793762207), (53, 0.9945191368460655)]
computing accuracy for after removing block 38 . block score: 0.024109512334689498
removed block 38 current accuracy 0.9066 loss from initial  0.04480000000000006
since last training loss: 0.040000000000000036 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 21, with score 0.025101. All blocks and scores: [(21, 0.02510101837106049), (22, 0.025318168103694916), (20, 0.02708589960820973), (39, 0.02786622429266572), (27, 0.029959815088659525), (50, 0.03014321788214147), (23, 0.030196755658835173), (49, 0.030600588070228696), (25, 0.03134015388786793), (15, 0.032252369448542595), (48, 0.03255049977451563), (7, 0.032630068715661764), (19, 0.032839878462255), (24, 0.03500632429495454), (37, 0.03766051633283496), (47, 0.041599209886044264), (51, 0.042844890151172876), (9, 0.04418395133689046), (6, 0.04675759328529239), (4, 0.04790225252509117), (14, 0.0481785130687058), (2, 0.05524974595755339), (3, 0.05783655680716038), (11, 0.0602059755474329), (13, 0.06021197186782956), (17, 0.06287069525569677), (0, 0.0636032079346478), (1, 0.06740830466151237), (52, 0.07300230953842402), (8, 0.0751371243968606), (10, 0.08121866639703512), (16, 0.08757159113883972), (12, 0.09103199653327465), (5, 0.10710440762341022), (36, 0.4308033101260662), (18, 0.5148058012127876), (53, 1.0172903314232826)]
computing accuracy for after removing block 21 . block score: 0.02510101837106049
removed block 21 current accuracy 0.9026 loss from initial  0.048800000000000066
training start
training epoch 0 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 1 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 2 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.1]
training epoch 3 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.1]
training epoch 4 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 5 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 6 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 7 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.1]
training epoch 8 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.1]
training epoch 9 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.018678. All blocks and scores: [(19, 0.018677733838558197), (27, 0.02287289872765541), (22, 0.0263548051007092), (50, 0.027924225432798266), (20, 0.028120135655626655), (49, 0.02917628432624042), (25, 0.030513565987348557), (23, 0.030614860355854034), (48, 0.030973943416029215), (15, 0.03209151141345501), (7, 0.03264047019183636), (24, 0.03555000200867653), (47, 0.03753184014931321), (51, 0.043328930623829365), (9, 0.043777305632829666), (6, 0.04644158063456416), (4, 0.046470715664327145), (14, 0.048073581885546446), (2, 0.05426691146567464), (37, 0.054773209150880575), (3, 0.05769220879301429), (13, 0.05937813455238938), (11, 0.0597697589546442), (17, 0.062359525356441736), (0, 0.06312453001737595), (39, 0.0642370069399476), (1, 0.0654325783252716), (52, 0.06692195311188698), (8, 0.0743039594963193), (10, 0.08151134010404348), (16, 0.0855794083327055), (12, 0.09100013971328735), (5, 0.10592337790876627), (18, 0.2848606966435909), (36, 0.40624888241291046), (53, 0.8232680931687355)]
computing accuracy for after removing block 19 . block score: 0.018677733838558197
removed block 19 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 27, with score 0.022479. All blocks and scores: [(27, 0.02247939072549343), (22, 0.026162529597058892), (50, 0.027427329681813717), (49, 0.02854472608305514), (20, 0.02864513313397765), (23, 0.029214065289124846), (48, 0.03073409735225141), (25, 0.030896012671291828), (15, 0.03209151094779372), (7, 0.032640470657497644), (24, 0.03607542300596833), (47, 0.03662239061668515), (51, 0.042950959876179695), (9, 0.04377730702981353), (6, 0.046441580168902874), (4, 0.04647071519866586), (14, 0.04807358281686902), (37, 0.05408080713823438), (2, 0.0542669091373682), (3, 0.057692209258675575), (13, 0.05937813362106681), (11, 0.059769762214273214), (39, 0.061601115856319666), (17, 0.06235952628776431), (0, 0.06312453048303723), (52, 0.06331512425094843), (1, 0.06543257646262646), (8, 0.07430395856499672), (10, 0.08151133731007576), (16, 0.08557940647006035), (12, 0.09100013971328735), (5, 0.10592338256537914), (18, 0.2848607003688812), (36, 0.3964701369404793), (53, 0.8273023366928101)]
computing accuracy for after removing block 27 . block score: 0.02247939072549343
removed block 27 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.026163. All blocks and scores: [(22, 0.026162529829889536), (50, 0.026305766310542822), (49, 0.028000557329505682), (20, 0.028645131969824433), (23, 0.029214065754786134), (48, 0.029805524041876197), (25, 0.03089601220563054), (15, 0.0320915118791163), (7, 0.032640470657497644), (47, 0.03431893419474363), (24, 0.03607542114332318), (51, 0.04024305706843734), (9, 0.04377730516716838), (6, 0.046441581565886736), (4, 0.04647071659564972), (14, 0.04807358328253031), (2, 0.0542669091373682), (37, 0.05575240543112159), (52, 0.055834146682173014), (3, 0.057692209258675575), (13, 0.05937813501805067), (39, 0.05958899948745966), (11, 0.059769760351628065), (17, 0.062359522096812725), (0, 0.06312453094869852), (1, 0.0654325783252716), (8, 0.07430395763367414), (10, 0.08151133917272091), (16, 0.08557940647006035), (12, 0.09100014250725508), (5, 0.105923380702734), (18, 0.2848607040941715), (36, 0.3932397700846195), (53, 0.8468699157238007)]
computing accuracy for after removing block 22 . block score: 0.026162529829889536
removed block 22 current accuracy 0.9166 loss from initial  0.03480000000000005
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.024725. All blocks and scores: [(50, 0.02472523832693696), (23, 0.025064721470698714), (49, 0.02653397247195244), (48, 0.02739683142863214), (20, 0.028645132901147008), (25, 0.02913803909905255), (24, 0.030070593114942312), (47, 0.03166202595457435), (15, 0.032091510482132435), (7, 0.03264047158882022), (51, 0.03701882250607014), (9, 0.043777305632829666), (6, 0.046441580168902874), (4, 0.046470715664327145), (52, 0.04800898488610983), (14, 0.04807358281686902), (2, 0.0542669091373682), (37, 0.05570431845262647), (39, 0.05614175833761692), (3, 0.05769220972433686), (13, 0.05937813455238938), (11, 0.05976976128295064), (17, 0.06235952442511916), (0, 0.06312452955171466), (1, 0.06543257925659418), (8, 0.07430395763367414), (10, 0.08151133637875319), (16, 0.08557940553873777), (12, 0.09100014064460993), (5, 0.1059233769774437), (18, 0.2848606966435909), (36, 0.3781030923128128), (53, 0.8608585372567177)]
computing accuracy for after removing block 50 . block score: 0.02472523832693696
removed block 50 current accuracy 0.9072 loss from initial  0.04420000000000002
since last training loss: 0.03400000000000003 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.025065. All blocks and scores: [(23, 0.025064721470698714), (49, 0.026533971773460507), (48, 0.027396832359954715), (20, 0.028645132202655077), (25, 0.029138038866221905), (24, 0.030070593114942312), (47, 0.031662024557590485), (15, 0.03209151141345501), (7, 0.03264047112315893), (51, 0.040514403488487005), (9, 0.04377730656415224), (6, 0.046441581565886736), (4, 0.04647071612998843), (14, 0.048073583748191595), (2, 0.05426691239699721), (52, 0.055528208147734404), (37, 0.0557043207809329), (39, 0.056141757406294346), (3, 0.05769220972433686), (13, 0.059378134086728096), (11, 0.059769760351628065), (17, 0.06235952256247401), (0, 0.06312452955171466), (1, 0.0654325783252716), (8, 0.07430395856499672), (10, 0.08151133917272091), (16, 0.08557940553873777), (12, 0.09100013971328735), (5, 0.10592337790876627), (18, 0.2848607040941715), (36, 0.3781030885875225), (53, 1.0830947160720825)]
computing accuracy for after removing block 23 . block score: 0.025064721470698714
removed block 23 current accuracy 0.8866 loss from initial  0.06479999999999997
since last training loss: 0.05459999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.026743. All blocks and scores: [(24, 0.026742805261164904), (49, 0.027061005122959614), (48, 0.027627415722236037), (20, 0.02864513243548572), (25, 0.029102507745847106), (47, 0.03129186597652733), (15, 0.032091510482132435), (7, 0.03264047112315893), (51, 0.03972589271143079), (9, 0.04377730609849095), (6, 0.04644158203154802), (4, 0.04647071612998843), (14, 0.04807358328253031), (52, 0.05287508061155677), (2, 0.05426691239699721), (39, 0.05686499644070864), (3, 0.05769221065565944), (13, 0.05937813362106681), (11, 0.05976976174861193), (17, 0.06235952116549015), (37, 0.06296720914542675), (0, 0.06312452955171466), (1, 0.06543257925659418), (8, 0.07430395763367414), (10, 0.08151133824139833), (16, 0.08557940553873777), (12, 0.0910001378506422), (5, 0.10592337511479855), (18, 0.2848607040941715), (36, 0.3960729353129864), (53, 1.0878138989210129)]
computing accuracy for after removing block 24 . block score: 0.026742805261164904
removed block 24 current accuracy 0.8406 loss from initial  0.11080000000000001
since last training loss: 0.10060000000000002 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.026138. All blocks and scores: [(48, 0.026137800188735127), (49, 0.026567818131297827), (25, 0.02837388589978218), (20, 0.02864513243548572), (47, 0.02998634777031839), (15, 0.03209151141345501), (7, 0.03264047112315893), (51, 0.03612921293824911), (9, 0.04377730470150709), (6, 0.046441581565886736), (4, 0.04647071519866586), (52, 0.0467889872379601), (14, 0.04807358421385288), (2, 0.05426691006869078), (39, 0.05610654363408685), (3, 0.057692211121320724), (13, 0.05937813362106681), (11, 0.05976976081728935), (17, 0.062359523959457874), (0, 0.06312453001737595), (37, 0.06477813888341188), (1, 0.0654325783252716), (8, 0.0743039594963193), (10, 0.08151133917272091), (16, 0.08557940740138292), (12, 0.0910001415759325), (5, 0.10592337884008884), (18, 0.28486069291830063), (36, 0.3971792086958885), (53, 1.12240070104599)]
computing accuracy for after removing block 48 . block score: 0.026137800188735127
removed block 48 current accuracy 0.79 loss from initial  0.1614
since last training loss: 0.1512 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 25, with score 0.028374. All blocks and scores: [(25, 0.028373885666951537), (20, 0.028645132202655077), (47, 0.029986347071826458), (49, 0.030685327015817165), (15, 0.032091510482132435), (7, 0.032640470657497644), (51, 0.03750052582472563), (9, 0.043777305632829666), (6, 0.04644158063456416), (4, 0.04647071659564972), (14, 0.04807358235120773), (52, 0.05313324835151434), (2, 0.054266910534352064), (39, 0.05610654456540942), (3, 0.057692209258675575), (13, 0.059378134086728096), (11, 0.05976975988596678), (17, 0.06235952069982886), (0, 0.06312452955171466), (37, 0.06477813888341188), (1, 0.06543257925659418), (8, 0.07430395670235157), (10, 0.08151133637875319), (16, 0.08557940647006035), (12, 0.09100014064460993), (5, 0.10592337790876627), (18, 0.2848606966435909), (36, 0.3971792012453079), (53, 1.280836820602417)]
computing accuracy for after removing block 25 . block score: 0.028373885666951537
removed block 25 current accuracy 0.717 loss from initial  0.23440000000000005
since last training loss: 0.22420000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.028645. All blocks and scores: [(20, 0.028645132668316364), (47, 0.02946873288601637), (49, 0.030850137351080775), (15, 0.03209151141345501), (7, 0.03264047112315893), (51, 0.03808653960004449), (9, 0.04377730656415224), (6, 0.04644158203154802), (4, 0.04647071473300457), (14, 0.04807358421385288), (52, 0.05257424991577864), (2, 0.054266910534352064), (39, 0.057239790447056293), (3, 0.057692209258675575), (13, 0.05937813362106681), (11, 0.05976976174861193), (17, 0.06235952349379659), (0, 0.06312453094869852), (1, 0.06543258018791676), (8, 0.0743039594963193), (37, 0.07749923877418041), (10, 0.08151133824139833), (16, 0.08557940553873777), (12, 0.09100013878196478), (5, 0.10592337884008884), (18, 0.2848607040941715), (36, 0.4318968132138252), (53, 1.2906083911657333)]
computing accuracy for after removing block 20 . block score: 0.028645132668316364
removed block 20 current accuracy 0.6574 loss from initial  0.29400000000000004
training start
training epoch 0 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best True lr [0.1]
training epoch 1 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 2 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.1]
training epoch 3 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 4 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 5 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 6 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 7 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 9 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 10 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
loading model_best from epoch 24 (acc 0.931400)
finished training. finished 50 epochs. accuracy 0.9314 topk_dict {'top1': 0.9314}
