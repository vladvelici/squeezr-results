start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581291347742), (34, 0.013294661068357527), (29, 0.013421116746030748), (35, 0.01595769007690251), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.022078295471146703), (23, 0.022228715242817998), (41, 0.022336415946483612), (44, 0.023145999759435654), (40, 0.02374959085136652), (45, 0.023975495481863618), (21, 0.02494108979590237), (48, 0.024957706686109304), (22, 0.025151389883831143), (50, 0.025287174619734287), (24, 0.025880583096295595), (49, 0.025916648795828223), (42, 0.02623223210684955), (20, 0.026848891051486135), (47, 0.0286329488735646), (38, 0.03134434437379241), (39, 0.031441295286640525), (15, 0.03205838426947594), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.0379180321469903), (51, 0.04178758757188916), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241184562445), (2, 0.05457740277051926), (3, 0.05784992640838027), (13, 0.05914428969845176), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464461103082), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4361986555159092), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.01023258175700903), (34, 0.013119244016706944), (29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.01609392766840756), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019852686673402786), (46, 0.020300705218687654), (41, 0.02186027471907437), (25, 0.022078295703977346), (23, 0.022228715242817998), (44, 0.02297719265334308), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540216894820333), (50, 0.02477082354016602), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.02557574096135795), (24, 0.02588058286346495), (42, 0.025893412996083498), (20, 0.02684889198280871), (47, 0.028072760440409184), (38, 0.03109118714928627), (39, 0.031191361602395773), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06493351608514786), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4339806027710438), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118728891015), (31, 0.010232581640593708), (34, 0.012758882017806172), (29, 0.01342111686244607), (35, 0.015918421559035778), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.01902279839850962), (43, 0.019850464537739754), (46, 0.02041191514581442), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02289147744886577), (40, 0.02360257925465703), (45, 0.02377084968611598), (48, 0.02451987355016172), (50, 0.024639350827783346), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025392549578100443), (42, 0.025712220696732402), (24, 0.025880581699311733), (20, 0.02684889198280871), (47, 0.028052504174411297), (38, 0.03093587327748537), (39, 0.031173037132248282), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577406495809555), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722717136145), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143885701895), (36, 0.4350203163921833), (18, 0.5117433071136475), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.01001118728891015
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.02222871477715671), (44, 0.023001376539468765), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025246930541470647), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027727575274184346), (38, 0.030746274162083864), (39, 0.03128179535269737), (15, 0.03205838520079851), (7, 0.03244550433009863), (19, 0.032540778163820505), (37, 0.03895266866311431), (51, 0.04082479840144515), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992873668671), (13, 0.05914428923279047), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464554235339), (52, 0.06356756156310439), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4377692937850952), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.01342111686244607), (35, 0.015968912513926625), (26, 0.016072141006588936), (28, 0.01763686165213585), (27, 0.019022798165678978), (43, 0.01983700809068978), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.02356909797526896), (45, 0.023840720532462), (48, 0.024108358891680837), (50, 0.024114208994433284), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.025045575108379126), (22, 0.025151390815153718), (24, 0.02588058332912624), (20, 0.026848892215639353), (47, 0.027423852356150746), (38, 0.030735649866983294), (39, 0.03141042497009039), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.039083510637283325), (51, 0.04034593980759382), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.06270107673481107), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361857950687), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016558773117139935), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962702739983797), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02304507768712938), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.024156817002221942), (45, 0.024168408708646894), (49, 0.024922372540459037), (21, 0.024941089330241084), (22, 0.02515139104798436), (42, 0.02581605943851173), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.04008621349930763), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.06221094913780689), (0, 0.06337464554235339), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.44933702051639557), (18, 0.5117432996630669), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.1]
training epoch 1 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.1]
training epoch 2 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.1]
training epoch 3 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.1]
training epoch 4 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.1]
training epoch 5 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.1]
training epoch 6 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.1]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 8 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.1]
training epoch 9 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.012433. All blocks and scores: [(35, 0.012433391297236085), (28, 0.013969177845865488), (26, 0.016233059344813228), (37, 0.016445281449705362), (27, 0.0190150854177773), (43, 0.020172757795080543), (46, 0.02033262117765844), (41, 0.02242027106694877), (25, 0.022464152425527573), (23, 0.02259247051551938), (44, 0.023030146956443787), (45, 0.023719127755612135), (40, 0.024190656142309308), (21, 0.024845900014042854), (48, 0.024955060798674822), (50, 0.025197651935741305), (22, 0.025291159516200423), (49, 0.025729903019964695), (24, 0.02601772267371416), (42, 0.026020093820989132), (20, 0.027133272495120764), (47, 0.028131490806117654), (15, 0.03214072762057185), (19, 0.03258593054488301), (7, 0.03266471019014716), (39, 0.03274900047108531), (38, 0.0333516332320869), (51, 0.04135182872414589), (9, 0.043874106369912624), (6, 0.04641928290948272), (14, 0.04772163229063153), (4, 0.048920939676463604), (2, 0.05512531287968159), (3, 0.058229506481438875), (13, 0.05942328926175833), (11, 0.059773766435682774), (17, 0.06288029113784432), (0, 0.06405741721391678), (52, 0.06666371785104275), (1, 0.06680688261985779), (8, 0.0742563046514988), (10, 0.0813993513584137), (16, 0.08552427124232054), (12, 0.08989218901842833), (5, 0.10610687546432018), (36, 0.3462943099439144), (18, 0.5139003619551659), (53, 0.7816090881824493)]
computing accuracy for after removing block 35 . block score: 0.012433391297236085
removed block 35 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.013969. All blocks and scores: [(28, 0.013969177729450166), (26, 0.01623305887915194), (37, 0.016278610099107027), (27, 0.01901508471928537), (46, 0.019603132968768477), (43, 0.019618184072896838), (41, 0.021284286165609956), (25, 0.022464152658358216), (23, 0.02259247051551938), (44, 0.022930836770683527), (45, 0.023037970066070557), (40, 0.02345582190901041), (48, 0.02385692880488932), (50, 0.023988298373296857), (42, 0.02473048004321754), (49, 0.02474148664623499), (21, 0.02484590047970414), (22, 0.025291159749031067), (24, 0.02601772267371416), (47, 0.02693076618015766), (20, 0.027133272029459476), (39, 0.03155624493956566), (15, 0.032140728551894426), (19, 0.03258592961356044), (7, 0.03266471065580845), (38, 0.0328095518052578), (51, 0.03969474136829376), (9, 0.04387410683557391), (6, 0.046419283375144005), (14, 0.04772163275629282), (4, 0.04892093921080232), (2, 0.055125314742326736), (3, 0.05822950787842274), (13, 0.059423291590064764), (11, 0.0597737655043602), (17, 0.06288029253482819), (52, 0.0632417518645525), (0, 0.06405741907656193), (1, 0.06680688355118036), (8, 0.07425630558282137), (10, 0.0813993513584137), (16, 0.08552427217364311), (12, 0.08989218715578318), (5, 0.10610687918961048), (36, 0.34302667528390884), (18, 0.5139003619551659), (53, 0.8004037737846375)]
computing accuracy for after removing block 28 . block score: 0.013969177729450166
removed block 28 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.016233. All blocks and scores: [(26, 0.016233059344813228), (37, 0.016860442701727152), (27, 0.019015085184946656), (46, 0.019341778242960572), (43, 0.020106549141928554), (41, 0.021441083401441574), (25, 0.022464151959866285), (23, 0.022592470748350024), (45, 0.023197382921352983), (44, 0.023245693184435368), (40, 0.023645159788429737), (48, 0.02376640122383833), (50, 0.023850312689319253), (49, 0.024436950450763106), (21, 0.02484589978121221), (42, 0.02485861163586378), (22, 0.025291159516200423), (24, 0.02601772267371416), (47, 0.026250838534906507), (20, 0.027133271796628833), (15, 0.03214072808623314), (39, 0.03222197154536843), (19, 0.03258593054488301), (7, 0.032664711121469736), (38, 0.033796719275414944), (51, 0.03943280875682831), (9, 0.04387410683557391), (6, 0.04641928104683757), (14, 0.04772163275629282), (4, 0.04892093874514103), (2, 0.05512531427666545), (3, 0.05822950741276145), (13, 0.05942329065874219), (11, 0.05977376317605376), (52, 0.06181579688563943), (17, 0.0628802920691669), (0, 0.06405741721391678), (1, 0.06680688448250294), (8, 0.07425630372017622), (10, 0.0813993513584137), (16, 0.08552427310496569), (12, 0.08989218715578318), (5, 0.10610688105225563), (36, 0.35559310019016266), (18, 0.5139003768563271), (53, 0.8006349205970764)]
computing accuracy for after removing block 26 . block score: 0.016233059344813228
removed block 26 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 37, with score 0.016414. All blocks and scores: [(37, 0.01641445280984044), (27, 0.01875939778983593), (46, 0.018934533931314945), (43, 0.01958980201743543), (41, 0.020647715777158737), (25, 0.022464152658358216), (23, 0.02259247051551938), (45, 0.022836626041680574), (40, 0.022948254365473986), (44, 0.023052186938002706), (48, 0.02308917767368257), (50, 0.023117103148251772), (42, 0.02338917669840157), (49, 0.024020029697567225), (21, 0.02484589978121221), (22, 0.025291160214692354), (47, 0.025572755141183734), (24, 0.026017722208052874), (20, 0.027133271796628833), (39, 0.03149230103008449), (15, 0.03214072808623314), (19, 0.03258593054488301), (38, 0.032610909547656775), (7, 0.03266471065580845), (51, 0.03804147336632013), (9, 0.04387410590425134), (6, 0.046419283375144005), (14, 0.047721631824970245), (4, 0.048920939676463604), (2, 0.05512531194835901), (3, 0.05822950787842274), (13, 0.0594232901930809), (52, 0.0595746198669076), (11, 0.05977376317605376), (17, 0.06288029020652175), (0, 0.06405741814523935), (1, 0.06680688448250294), (8, 0.0742563046514988), (10, 0.08139935228973627), (16, 0.08552426844835281), (12, 0.08989218808710575), (5, 0.10610687918961048), (36, 0.3475309982895851), (18, 0.5139003694057465), (53, 0.823918342590332)]
computing accuracy for after removing block 37 . block score: 0.01641445280984044
removed block 37 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.017339. All blocks and scores: [(46, 0.017338983016088605), (43, 0.017757555469870567), (27, 0.018759398022666574), (41, 0.018775937147438526), (50, 0.020059910602867603), (44, 0.020659951958805323), (48, 0.02067497419193387), (45, 0.020901402924209833), (40, 0.021199708338826895), (49, 0.021380853140726686), (42, 0.021696185925975442), (25, 0.02246415219269693), (23, 0.022592470748350024), (47, 0.022643884643912315), (21, 0.024845899548381567), (22, 0.025291159749031067), (24, 0.026017722440883517), (20, 0.027133272029459476), (39, 0.03008352709002793), (15, 0.032140728551894426), (19, 0.03258593054488301), (7, 0.032664711121469736), (38, 0.03297617193311453), (51, 0.034922088496387005), (9, 0.04387410683557391), (6, 0.04641928244382143), (14, 0.04772163042798638), (4, 0.04892093827947974), (52, 0.05191990779712796), (2, 0.055125311482697725), (3, 0.05822950787842274), (13, 0.05942329065874219), (11, 0.059773762710392475), (17, 0.06288029113784432), (0, 0.0640574200078845), (1, 0.06680688075721264), (8, 0.0742563046514988), (10, 0.08139935042709112), (16, 0.08552426844835281), (12, 0.08989218715578318), (5, 0.10610687639564276), (36, 0.3475310020148754), (18, 0.5139003619551659), (53, 0.8514689579606056)]
computing accuracy for after removing block 46 . block score: 0.017338983016088605
removed block 46 current accuracy 0.9266 loss from initial  0.024800000000000044
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.017758. All blocks and scores: [(43, 0.017757555237039924), (27, 0.018759397557005286), (41, 0.018775937147438526), (50, 0.02025284105911851), (44, 0.020659951958805323), (45, 0.020901402924209833), (48, 0.0210244026966393), (40, 0.02119970857165754), (42, 0.021696184761822224), (49, 0.022073924774304032), (25, 0.02246415102854371), (23, 0.022592470748350024), (47, 0.024169260868802667), (21, 0.024845899548381567), (22, 0.02529115998186171), (24, 0.026017722906544805), (20, 0.027133272029459476), (39, 0.03008352778851986), (15, 0.032140728551894426), (19, 0.032585930079221725), (7, 0.032664711121469736), (38, 0.03297617146745324), (51, 0.03508496517315507), (9, 0.0438741073012352), (6, 0.04641928244382143), (14, 0.04772163042798638), (4, 0.04892094014212489), (52, 0.05210280837491155), (2, 0.05512531381100416), (3, 0.05822950694710016), (13, 0.0594232901930809), (11, 0.05977376364171505), (17, 0.06288029253482819), (0, 0.06405741721391678), (1, 0.06680688261985779), (8, 0.07425630372017622), (10, 0.08139935322105885), (16, 0.08552426751703024), (12, 0.08989218808710575), (5, 0.1061068819835782), (36, 0.3475309982895851), (18, 0.5139003694057465), (53, 0.950023353099823)]
computing accuracy for after removing block 43 . block score: 0.017757555237039924
removed block 43 current accuracy 0.9226 loss from initial  0.028800000000000048
training start
training epoch 0 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 1 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.1]
training epoch 2 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.1]
training epoch 3 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 4 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.1]
training epoch 5 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.1]
training epoch 6 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.1]
training epoch 7 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.1]
training epoch 8 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 9 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.014353. All blocks and scores: [(48, 0.014352856669574976), (49, 0.01529840158764273), (45, 0.01840267493389547), (44, 0.019950473681092262), (42, 0.022317548980936408), (41, 0.022657468682155013), (23, 0.022688976023346186), (40, 0.023268537130206823), (47, 0.02379837678745389), (21, 0.025241973577067256), (22, 0.025419246638193727), (24, 0.02644385094754398), (20, 0.027537132846191525), (50, 0.02777277212589979), (39, 0.02912009321153164), (25, 0.03188613569363952), (15, 0.032222382724285126), (19, 0.03252337221056223), (7, 0.03262910945340991), (38, 0.034032301511615515), (27, 0.03414563601836562), (51, 0.043373835273087025), (9, 0.04404447693377733), (6, 0.04683459084481001), (4, 0.04733724473044276), (14, 0.047963475808501244), (2, 0.05499333702027798), (3, 0.05783968325704336), (11, 0.059445276856422424), (13, 0.05972623312845826), (17, 0.06269463151693344), (0, 0.06351715698838234), (1, 0.0669033182784915), (52, 0.06933631096035242), (8, 0.07463994063436985), (10, 0.08116415981203318), (16, 0.08669858612120152), (12, 0.09062404558062553), (5, 0.10576407983899117), (36, 0.437606580555439), (18, 0.5147520005702972), (53, 0.7879615053534508)]
computing accuracy for after removing block 48 . block score: 0.014352856669574976
removed block 48 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 49, with score 0.016738. All blocks and scores: [(49, 0.016737670404836535), (45, 0.01840267493389547), (44, 0.019950473913922906), (42, 0.022317549446597695), (41, 0.022657468914985657), (23, 0.022688976721838117), (40, 0.023268536431714892), (47, 0.023798377951607108), (21, 0.025241974741220474), (22, 0.02541924687102437), (24, 0.026443851180374622), (20, 0.027537132613360882), (39, 0.029120092513039708), (50, 0.03000238840468228), (25, 0.031886136159300804), (15, 0.03222238318994641), (19, 0.03252337221056223), (7, 0.032629110384732485), (38, 0.03403230058029294), (27, 0.034145636949688196), (51, 0.04389710817486048), (9, 0.04404447739943862), (6, 0.046834591776132584), (4, 0.04733724519610405), (14, 0.047963475342839956), (2, 0.054993337485939264), (3, 0.057839684188365936), (11, 0.059445276856422424), (13, 0.05972623126581311), (17, 0.0626946329139173), (0, 0.06351715512573719), (1, 0.0669033182784915), (52, 0.07347727101296186), (8, 0.0746399387717247), (10, 0.0811641588807106), (16, 0.08669858705252409), (12, 0.09062404371798038), (5, 0.10576407704502344), (36, 0.4376065768301487), (18, 0.5147519931197166), (53, 0.8398909717798233)]
computing accuracy for after removing block 49 . block score: 0.016737670404836535
removed block 49 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.018403. All blocks and scores: [(45, 0.018402675166726112), (44, 0.01995047344826162), (42, 0.022317548980936408), (41, 0.022657469380646944), (23, 0.022688976489007473), (40, 0.023268537130206823), (47, 0.023798377020284534), (21, 0.025241973344236612), (22, 0.025419245939701796), (24, 0.02644385048188269), (20, 0.027537132380530238), (39, 0.029120092745870352), (25, 0.031886136159300804), (15, 0.032222382724285126), (19, 0.03252337174490094), (7, 0.0326291099190712), (50, 0.033059367910027504), (38, 0.03403230011463165), (27, 0.034145636949688196), (9, 0.04404447786509991), (51, 0.046551189851015806), (6, 0.046834591776132584), (4, 0.04733724566176534), (14, 0.047963475808501244), (2, 0.05499333795160055), (3, 0.057839682791382074), (11, 0.05944527592509985), (13, 0.05972623126581311), (17, 0.06269463058561087), (0, 0.06351715605705976), (1, 0.06690332107245922), (8, 0.07463994156569242), (52, 0.07956609595566988), (10, 0.0811641588807106), (16, 0.08669858518987894), (12, 0.09062404464930296), (5, 0.10576407797634602), (36, 0.437606580555439), (18, 0.514751985669136), (53, 0.882476381957531)]
computing accuracy for after removing block 45 . block score: 0.018402675166726112
removed block 45 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.019950. All blocks and scores: [(44, 0.019950473681092262), (42, 0.022317549446597695), (41, 0.022657468682155013), (23, 0.022688975790515542), (40, 0.023268537130206823), (47, 0.024712187936529517), (21, 0.025241974974051118), (22, 0.025419247802346945), (24, 0.026443851180374622), (20, 0.027537131682038307), (39, 0.029120093677192926), (25, 0.03188613569363952), (15, 0.03222238318994641), (19, 0.03252337174490094), (7, 0.03262910898774862), (38, 0.03403230011463165), (27, 0.03414563601836562), (50, 0.034803655464202166), (9, 0.044044478330761194), (51, 0.0446808566339314), (6, 0.04683459037914872), (4, 0.047337244264781475), (14, 0.04796347441151738), (2, 0.054993337485939264), (3, 0.057839684188365936), (11, 0.059445274993777275), (13, 0.059726232662796974), (17, 0.06269463105127215), (0, 0.06351715605705976), (1, 0.06690331641584635), (8, 0.074639942497015), (52, 0.07525966968387365), (10, 0.08116415981203318), (16, 0.08669858518987894), (12, 0.09062404371798038), (5, 0.10576407797634602), (36, 0.4376065768301487), (18, 0.5147519931197166), (53, 0.9666680693626404)]
computing accuracy for after removing block 44 . block score: 0.019950473681092262
removed block 44 current accuracy 0.919 loss from initial  0.032399999999999984
since last training loss: 0.02939999999999998 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.022318. All blocks and scores: [(42, 0.02231754967942834), (41, 0.022657468914985657), (23, 0.022688976023346186), (40, 0.02326853689737618), (47, 0.025114761665463448), (21, 0.025241974275559187), (22, 0.025419247336685658), (24, 0.02644385094754398), (20, 0.027537132846191525), (39, 0.029120092745870352), (25, 0.03188613569363952), (15, 0.03222238318994641), (19, 0.03252337221056223), (7, 0.0326291099190712), (38, 0.03403230104595423), (50, 0.034081263933330774), (27, 0.034145636949688196), (51, 0.04346918174996972), (9, 0.04404447739943862), (6, 0.046834591776132584), (4, 0.047337244264781475), (14, 0.047963475342839956), (2, 0.054993338882923126), (3, 0.057839684188365936), (11, 0.05944527639076114), (13, 0.0597262317314744), (17, 0.06269463011994958), (0, 0.06351715698838234), (1, 0.0669033182784915), (52, 0.06995651498436928), (8, 0.07463993970304728), (10, 0.0811641588807106), (16, 0.08669858612120152), (12, 0.09062404092401266), (5, 0.10576408170163631), (36, 0.4376065693795681), (18, 0.5147519931197166), (53, 1.0873568505048752)]
computing accuracy for after removing block 42 . block score: 0.02231754967942834
removed block 42 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.022657. All blocks and scores: [(41, 0.0226574691478163), (23, 0.022688976023346186), (40, 0.02326853689737618), (21, 0.025241974275559187), (22, 0.025419246638193727), (47, 0.026019779965281487), (24, 0.02644385048188269), (20, 0.027537132613360882), (39, 0.029120092745870352), (25, 0.03188613569363952), (15, 0.032222382724285126), (19, 0.03252337221056223), (7, 0.032629110384732485), (38, 0.03403230011463165), (27, 0.03414563508704305), (50, 0.03432134771719575), (51, 0.04198651807382703), (9, 0.04404447739943862), (6, 0.04683459084481001), (4, 0.04733724566176534), (14, 0.04796347627416253), (2, 0.05499333655461669), (3, 0.057839686051011086), (11, 0.059445276856422424), (13, 0.059726232662796974), (17, 0.06269463058561087), (0, 0.06351715512573719), (1, 0.06690332014113665), (52, 0.06775645446032286), (8, 0.07463993970304728), (10, 0.08116415981203318), (16, 0.08669858798384666), (12, 0.09062404371798038), (5, 0.10576407890766859), (36, 0.4376065880060196), (18, 0.514751985669136), (53, 1.167288139462471)]
computing accuracy for after removing block 41 . block score: 0.0226574691478163
removed block 41 current accuracy 0.8892 loss from initial  0.06220000000000003
training start
training epoch 0 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.1]
training epoch 1 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.1]
training epoch 2 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.1]
training epoch 3 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 4 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.1]
training epoch 5 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.1]
training epoch 6 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.1]
training epoch 7 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.1]
training epoch 8 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.1]
training epoch 9 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022644. All blocks and scores: [(23, 0.022644207812845707), (21, 0.025056306971237063), (22, 0.025406611850485206), (24, 0.025957997888326645), (20, 0.027248611208051443), (39, 0.029135778546333313), (25, 0.031837668269872665), (15, 0.03207922028377652), (19, 0.032544936053454876), (7, 0.03261135192587972), (27, 0.034105672501027584), (38, 0.03434938658028841), (50, 0.038942838087677956), (9, 0.04400788899511099), (51, 0.044368795584887266), (6, 0.04727647081017494), (4, 0.04795807972550392), (14, 0.0480252206325531), (2, 0.05524663859978318), (47, 0.056912900414317846), (3, 0.05802650423720479), (13, 0.05947953322902322), (11, 0.0596757554449141), (17, 0.06174809020012617), (40, 0.06200545048341155), (0, 0.06359732057899237), (1, 0.06777330581098795), (8, 0.07526978477835655), (10, 0.08031349908560514), (16, 0.08555288147181273), (12, 0.0904180072247982), (52, 0.09792848769575357), (5, 0.10687575861811638), (36, 0.4365585297346115), (18, 0.5131668746471405), (53, 0.78201824426651)]
computing accuracy for after removing block 23 . block score: 0.022644207812845707
removed block 23 current accuracy 0.9334 loss from initial  0.018000000000000016
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.024614. All blocks and scores: [(24, 0.02461432688869536), (21, 0.025056307204067707), (22, 0.025406612316146493), (20, 0.027248611208051443), (39, 0.029205453349277377), (25, 0.03063543699681759), (15, 0.032079221680760384), (19, 0.03254493651911616), (7, 0.032611352391541004), (27, 0.03335581440478563), (38, 0.033997329883277416), (50, 0.03817182593047619), (51, 0.0426091318950057), (9, 0.0440078885294497), (6, 0.047276472207158804), (4, 0.047958079259842634), (14, 0.04802522249519825), (2, 0.05524663953110576), (47, 0.05579300411045551), (3, 0.05802650470286608), (13, 0.05947953090071678), (11, 0.05967575358226895), (40, 0.061091558542102575), (17, 0.061748091131448746), (0, 0.0635973229072988), (1, 0.06777330487966537), (8, 0.07526978384703398), (10, 0.08031350001692772), (16, 0.085552878677845), (12, 0.09041800815612078), (52, 0.0921812653541565), (5, 0.10687575675547123), (36, 0.4320274218916893), (18, 0.5131668895483017), (53, 0.7931766733527184)]
computing accuracy for after removing block 24 . block score: 0.02461432688869536
removed block 24 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.025056. All blocks and scores: [(21, 0.025056307204067707), (22, 0.02540661278180778), (20, 0.027248612605035305), (25, 0.028500684071332216), (39, 0.02854571887291968), (15, 0.032079221215099096), (19, 0.032544936053454876), (7, 0.03261135146021843), (27, 0.03297785622999072), (38, 0.03372694691643119), (50, 0.036282061599195004), (51, 0.039391523227095604), (9, 0.04400788899511099), (6, 0.04727647267282009), (4, 0.04795808019116521), (14, 0.04802522109821439), (47, 0.053926635067909956), (2, 0.05524664046242833), (3, 0.058026503305882215), (40, 0.05813424615189433), (13, 0.059479532297700644), (11, 0.059675753116607666), (17, 0.061748089734464884), (0, 0.06359732104465365), (1, 0.06777330581098795), (8, 0.0752697829157114), (52, 0.08017060160636902), (10, 0.08031349908560514), (16, 0.08555288054049015), (12, 0.09041801001876593), (5, 0.10687575954943895), (36, 0.41686733067035675), (18, 0.5131668895483017), (53, 0.8249485939741135)]
computing accuracy for after removing block 21 . block score: 0.025056307204067707
removed block 21 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.023643. All blocks and scores: [(22, 0.023643482010811567), (39, 0.02709183352999389), (20, 0.027248611906543374), (25, 0.027549340622499585), (38, 0.03180674114264548), (15, 0.032079221680760384), (27, 0.032197832595556974), (19, 0.03254493558779359), (7, 0.03261135192587972), (50, 0.03450680896639824), (51, 0.03675285121425986), (9, 0.0440078885294497), (6, 0.04727647267282009), (4, 0.047958080656826496), (14, 0.04802522249519825), (47, 0.05139488214626908), (40, 0.05495331110432744), (2, 0.05524664046242833), (3, 0.05802650284022093), (13, 0.05947953416034579), (11, 0.05967575591057539), (17, 0.06174809159711003), (0, 0.06359732151031494), (52, 0.06653221789747477), (1, 0.06777330301702023), (8, 0.07526978477835655), (10, 0.08031349815428257), (16, 0.08555287681519985), (12, 0.09041801001876593), (5, 0.10687576048076153), (36, 0.39668021351099014), (18, 0.5131668820977211), (53, 0.8451988250017166)]
computing accuracy for after removing block 22 . block score: 0.023643482010811567
removed block 22 current accuracy 0.8954 loss from initial  0.05600000000000005
since last training loss: 0.04259999999999997 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.026160. All blocks and scores: [(39, 0.02616036171093583), (25, 0.0265786643140018), (20, 0.027248611906543374), (38, 0.0314011094160378), (27, 0.031567984726279974), (15, 0.032079221680760384), (19, 0.032544936053454876), (7, 0.03261135099455714), (50, 0.033249715343117714), (51, 0.03460770100355148), (9, 0.04400788759812713), (6, 0.047276472207158804), (4, 0.04795807972550392), (14, 0.048025221563875675), (47, 0.04914888134226203), (40, 0.05338211078196764), (2, 0.05524663953110576), (3, 0.0580265037715435), (52, 0.05822416255250573), (13, 0.05947953276336193), (11, 0.05967575358226895), (17, 0.061748091131448746), (0, 0.06359732057899237), (1, 0.06777330674231052), (8, 0.07526978477835655), (10, 0.08031349815428257), (16, 0.08555287681519985), (12, 0.0904180072247982), (5, 0.10687576048076153), (36, 0.39145510271191597), (18, 0.5131668746471405), (53, 0.8574409037828445)]
computing accuracy for after removing block 39 . block score: 0.02616036171093583
removed block 39 current accuracy 0.8868 loss from initial  0.06459999999999999
since last training loss: 0.05119999999999991 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.026579. All blocks and scores: [(25, 0.026578664546832442), (20, 0.027248611440882087), (50, 0.03042808803729713), (38, 0.031401109881699085), (51, 0.03153003519400954), (27, 0.03156798565760255), (15, 0.032079221215099096), (19, 0.03254493558779359), (7, 0.03261135146021843), (52, 0.042347964365035295), (9, 0.0440078885294497), (6, 0.04727647313848138), (47, 0.047347309067845345), (4, 0.047958079259842634), (14, 0.048025221563875675), (40, 0.052599480375647545), (2, 0.05524663906544447), (3, 0.058026501443237066), (13, 0.059479532297700644), (11, 0.05967575265094638), (17, 0.06174809159711003), (0, 0.06359732197597623), (1, 0.06777330301702023), (8, 0.07526978570967913), (10, 0.08031349908560514), (16, 0.08555287774652243), (12, 0.09041800908744335), (5, 0.10687575675547123), (36, 0.39145510271191597), (18, 0.5131668820977211), (53, 0.9385305196046829)]
computing accuracy for after removing block 25 . block score: 0.026578664546832442
removed block 25 current accuracy 0.8636 loss from initial  0.08779999999999999
since last training loss: 0.07439999999999991 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.027249. All blocks and scores: [(20, 0.027248611440882087), (51, 0.030684937722980976), (50, 0.030912821646779776), (27, 0.03186193574219942), (15, 0.032079221680760384), (19, 0.03254493651911616), (7, 0.03261135146021843), (38, 0.03295783279463649), (52, 0.040016718208789825), (9, 0.044007889460772276), (6, 0.04727647267282009), (47, 0.04781890194863081), (4, 0.04795807972550392), (14, 0.048025221563875675), (40, 0.05430782260373235), (2, 0.05524663953110576), (3, 0.05802650470286608), (13, 0.05947953416034579), (11, 0.059675756841897964), (17, 0.06174809066578746), (0, 0.06359732104465365), (1, 0.0677733039483428), (8, 0.07526978477835655), (10, 0.08031349815428257), (16, 0.085552878677845), (12, 0.0904180109500885), (5, 0.10687575954943895), (36, 0.4068883955478668), (18, 0.5131668746471405), (53, 0.9744596779346466)]
computing accuracy for after removing block 20 . block score: 0.027248611440882087
removed block 20 current accuracy 0.8348 loss from initial  0.11660000000000004
since last training loss: 0.10319999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.029814. All blocks and scores: [(51, 0.02981369267217815), (50, 0.030489778611809015), (27, 0.031580131966620684), (38, 0.0319178223144263), (15, 0.03207922074943781), (19, 0.032544936053454876), (7, 0.03261135146021843), (52, 0.035702075343579054), (9, 0.044007889460772276), (47, 0.045798851642757654), (6, 0.04727647174149752), (4, 0.047958079259842634), (14, 0.04802522202953696), (40, 0.0545334005728364), (2, 0.05524663859978318), (3, 0.0580265037715435), (13, 0.05947953276336193), (11, 0.05967575451359153), (17, 0.06174808833748102), (0, 0.06359732244163752), (1, 0.06777330674231052), (8, 0.07526978384703398), (10, 0.08031349908560514), (16, 0.08555287774652243), (12, 0.09041800908744335), (5, 0.1068757614120841), (36, 0.41051626205444336), (18, 0.5131668895483017), (53, 0.961551122367382)]
computing accuracy for after removing block 51 . block score: 0.02981369267217815
removed block 51 current accuracy 0.7586 loss from initial  0.19279999999999997
since last training loss: 0.1793999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.030490. All blocks and scores: [(50, 0.03048977954313159), (27, 0.03158013103529811), (38, 0.03191782394424081), (15, 0.03207922074943781), (19, 0.0325449351221323), (7, 0.032611352391541004), (52, 0.03518784744665027), (9, 0.044007889460772276), (47, 0.045798851642757654), (6, 0.047276473604142666), (4, 0.04795807832852006), (14, 0.048025221563875675), (40, 0.054533401504158974), (2, 0.055246639996767044), (3, 0.05802650423720479), (13, 0.059479533694684505), (11, 0.05967575404793024), (17, 0.06174809159711003), (0, 0.0635973229072988), (1, 0.06777330674231052), (8, 0.07526978477835655), (10, 0.08031349815428257), (16, 0.08555287774652243), (12, 0.09041801001876593), (5, 0.10687575582414865), (36, 0.41051626205444336), (18, 0.5131668820977211), (53, 1.246433898806572)]
computing accuracy for after removing block 50 . block score: 0.03048977954313159
removed block 50 current accuracy 0.7116 loss from initial  0.2398
training start
training epoch 0 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best True lr [0.1]
training epoch 1 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 2 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.1]
training epoch 3 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 4 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 5 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 6 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.1]
training epoch 7 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.1]
training epoch 8 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 9 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 10 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
