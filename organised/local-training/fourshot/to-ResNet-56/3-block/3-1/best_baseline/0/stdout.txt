start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013294660369865596), (29, 0.01342111686244607), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019996492424979806), (46, 0.020590225234627724), (25, 0.02207829593680799), (23, 0.022228715242817998), (41, 0.02233641571365297), (44, 0.02314599882811308), (40, 0.023749591084197164), (45, 0.02397549571469426), (21, 0.02494108979590237), (48, 0.024957706220448017), (22, 0.025151389883831143), (50, 0.025287174619734287), (24, 0.025880582630634308), (49, 0.02591664856299758), (42, 0.026232231641188264), (20, 0.02684889198280871), (47, 0.0286329488735646), (38, 0.03134434437379241), (39, 0.0314412962179631), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037918031215667725), (51, 0.041787587106227875), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337465019896626), (1, 0.06593216117471457), (52, 0.06606104504317045), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.8053385019302368)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013119243667460978), (29, 0.013421116163954139), (26, 0.016072140773758292), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019852687371894717), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022977192187681794), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025575740495696664), (24, 0.025880581932142377), (42, 0.02589341253042221), (20, 0.026848892448469996), (47, 0.028072759741917253), (38, 0.031091188080608845), (39, 0.03119136206805706), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.0613252529874444), (0, 0.06337464554235339), (52, 0.06493351748213172), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4339805990457535), (18, 0.5117433294653893), (53, 0.8063970282673836)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187987402081), (31, 0.010232581291347742), (34, 0.012758882134221494), (29, 0.013421116629615426), (35, 0.01591842109337449), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.022891478380188346), (40, 0.02360258041881025), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.024941088864579797), (22, 0.025151390116661787), (49, 0.025392550509423018), (42, 0.025712220696732402), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.028052504640072584), (38, 0.030935873510316014), (39, 0.031173036666586995), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03834318928420544), (51, 0.04113080818206072), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4350203201174736), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187987402081
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159728713334), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01986735058017075), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078296169638634), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.02373992674984038), (45, 0.02379016880877316), (48, 0.02435004524886608), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246930541470647), (42, 0.02527355100028217), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.027727575041353703), (38, 0.03074627462774515), (39, 0.031281795585528016), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464833632112), (52, 0.06356756249442697), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537981152534), (5, 0.10671143420040607), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116396784782), (35, 0.015968912048265338), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.02384072169661522), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.02504557464271784), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.027423852123320103), (38, 0.03073564963415265), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325255781412125), (52, 0.06270107859745622), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.43692684173583984), (18, 0.5117432996630669), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.020302684511989355), (46, 0.02032419783063233), (41, 0.02196270297281444), (25, 0.022078295703977346), (23, 0.02222871477715671), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156816070899367), (45, 0.024168408941477537), (49, 0.024922373006120324), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.02581606013700366), (24, 0.02588058332912624), (20, 0.026848892448469996), (47, 0.027568295365199447), (38, 0.03178726485930383), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.040690732188522816), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525485008955), (52, 0.06221094774082303), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117432922124863), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.1]
training epoch 1 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.1]
training epoch 2 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.1]
training epoch 3 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.1]
training epoch 4 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.1]
training epoch 5 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.1]
training epoch 6 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.1]
training epoch 7 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.1]
training epoch 8 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.1]
training epoch 9 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.1]
training epoch 10 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 6
[activation diff]: block to remove picked: 28, with score 0.016864. All blocks and scores: [(28, 0.016864487901329994), (26, 0.01761382562108338), (27, 0.020070906495675445), (43, 0.020126469898968935), (46, 0.020583146950230002), (35, 0.02072408073581755), (41, 0.02231396408751607), (25, 0.02235533413477242), (23, 0.022638906491920352), (44, 0.02327994559891522), (40, 0.023850346449762583), (45, 0.023917871061712503), (50, 0.024817884899675846), (21, 0.02506535337306559), (48, 0.025079265469685197), (22, 0.025398850673809648), (49, 0.025718886870890856), (42, 0.025808806531131268), (24, 0.026082738302648067), (20, 0.027388215297833085), (47, 0.028504965594038367), (38, 0.031397314509376884), (39, 0.03155862889252603), (15, 0.032320489175617695), (7, 0.032538213301450014), (19, 0.03263687202706933), (37, 0.037991021294146776), (51, 0.042060176841914654), (9, 0.04398865904659033), (6, 0.046685881447046995), (4, 0.04766168585047126), (14, 0.04807198839262128), (2, 0.054877919144928455), (3, 0.05768894590437412), (13, 0.0595939508639276), (11, 0.05970785487443209), (17, 0.06209068885073066), (0, 0.06341957207769156), (52, 0.0665002865716815), (1, 0.06663496885448694), (8, 0.07505097053945065), (10, 0.0808261651545763), (16, 0.08556767646223307), (12, 0.09021177422255278), (5, 0.10629176069051027), (36, 0.43437687680125237), (18, 0.5143190771341324), (53, 0.7883859723806381)]
computing accuracy for after removing block 28 . block score: 0.016864487901329994
removed block 28 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.017614. All blocks and scores: [(26, 0.017613824922591448), (35, 0.019685360370203853), (43, 0.019701801240444183), (46, 0.02005668170750141), (27, 0.020070906495675445), (41, 0.022155630867928267), (25, 0.022355334367603064), (23, 0.022638906724750996), (44, 0.023476822767406702), (40, 0.023737756768241525), (45, 0.023751393426209688), (50, 0.024300054647028446), (48, 0.024432351114228368), (21, 0.02506535453721881), (49, 0.025254478445276618), (42, 0.02532750740647316), (22, 0.025398850673809648), (24, 0.02608273900114), (20, 0.02738821809180081), (47, 0.027935351710766554), (38, 0.031243065372109413), (39, 0.03154395869933069), (15, 0.03232048777863383), (7, 0.032538213301450014), (19, 0.032636872958391905), (37, 0.03763563046231866), (51, 0.04163146438077092), (9, 0.0439886599779129), (6, 0.04668588237836957), (4, 0.04766168538480997), (14, 0.04807198932394385), (2, 0.054877917282283306), (3, 0.05768894637003541), (13, 0.05959395319223404), (11, 0.05970785627141595), (17, 0.06209068698808551), (0, 0.06341956974938512), (52, 0.06501120468601584), (1, 0.06663496792316437), (8, 0.0750509724020958), (10, 0.08082616422325373), (16, 0.08556767925620079), (12, 0.09021177608519793), (5, 0.10629176162183285), (36, 0.4351155534386635), (18, 0.5143190771341324), (53, 0.8012591153383255)]
computing accuracy for after removing block 26 . block score: 0.017613824922591448
removed block 26 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 35, with score 0.018367. All blocks and scores: [(35, 0.018367080949246883), (43, 0.019276360981166363), (27, 0.01975109032355249), (46, 0.01980350469239056), (41, 0.021723483223468065), (25, 0.022355333669111133), (23, 0.022638906026259065), (40, 0.023561491165310144), (44, 0.023610556731000543), (45, 0.023790148552507162), (50, 0.023943797685205936), (48, 0.023975257761776447), (42, 0.02428474649786949), (49, 0.02505698404274881), (21, 0.025065353605896235), (22, 0.025398850440979004), (24, 0.026082738069817424), (20, 0.02738821692764759), (47, 0.027586850803345442), (38, 0.03109269868582487), (39, 0.03147555701434612), (15, 0.03232049010694027), (7, 0.03253821237012744), (19, 0.032636872958391905), (37, 0.037664339412003756), (51, 0.040459717623889446), (9, 0.043988659512251616), (6, 0.04668588237836957), (4, 0.04766168678179383), (14, 0.048071988858282566), (2, 0.05487791681662202), (3, 0.057688947301357985), (13, 0.05959394993260503), (11, 0.05970785580575466), (17, 0.06209068838506937), (52, 0.06318204617127776), (0, 0.0634195706807077), (1, 0.06663496792316437), (8, 0.0750509724020958), (10, 0.08082616422325373), (16, 0.08556767925620079), (12, 0.09021177608519793), (5, 0.10629176069051027), (36, 0.4360044561326504), (18, 0.5143190622329712), (53, 0.8227577582001686)]
computing accuracy for after removing block 35 . block score: 0.018367080949246883
removed block 35 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018009. All blocks and scores: [(43, 0.018008567625656724), (46, 0.01870964001864195), (27, 0.019751090556383133), (41, 0.019829377764835954), (50, 0.021971478825435042), (48, 0.021975398994982243), (40, 0.022143716691061854), (42, 0.022155773593112826), (25, 0.02235533343628049), (23, 0.022638906026259065), (45, 0.022782666608691216), (44, 0.023003794252872467), (49, 0.023689930560067296), (21, 0.025065353605896235), (22, 0.025398850673809648), (24, 0.026082738302648067), (47, 0.02646896429359913), (20, 0.027388216694816947), (38, 0.02934899367392063), (39, 0.029391025193035603), (15, 0.03232048870995641), (7, 0.03253821283578873), (19, 0.03263687202706933), (37, 0.03495320538058877), (51, 0.037887427024543285), (9, 0.043988659512251616), (6, 0.04668588005006313), (4, 0.047661686316132545), (14, 0.04807198978960514), (2, 0.05487791821360588), (52, 0.0575468884781003), (3, 0.05768894776701927), (13, 0.05959394993260503), (11, 0.05970785580575466), (17, 0.06209068838506937), (0, 0.06341957114636898), (1, 0.06663496699184179), (8, 0.07505097333341837), (10, 0.08082616236060858), (16, 0.08556767646223307), (12, 0.09021177235990763), (5, 0.10629176069051027), (36, 0.41802164167165756), (18, 0.5143190771341324), (53, 0.8695497438311577)]
computing accuracy for after removing block 43 . block score: 0.018008567625656724
removed block 43 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.013999999999999901 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019335. All blocks and scores: [(46, 0.019335006596520543), (27, 0.01975109032355249), (41, 0.019829377764835954), (50, 0.021990199107676744), (40, 0.02214371645823121), (42, 0.02215577382594347), (25, 0.022355333901941776), (23, 0.02263890695758164), (48, 0.02266435418277979), (49, 0.0235346716362983), (45, 0.023867650888860226), (44, 0.024392297957092524), (21, 0.02506535337306559), (22, 0.02539885090664029), (24, 0.02608273853547871), (47, 0.02721971832215786), (20, 0.027388217393308878), (38, 0.0293489929754287), (39, 0.029391025193035603), (15, 0.032320489175617695), (7, 0.03253821283578873), (19, 0.03263687202706933), (37, 0.03495320584625006), (51, 0.037477603647857904), (9, 0.04398865904659033), (6, 0.04668588191270828), (4, 0.04766168585047126), (14, 0.048071988858282566), (2, 0.054877915885299444), (52, 0.05637463042512536), (3, 0.05768895009532571), (13, 0.059593952260911465), (11, 0.059707856737077236), (17, 0.06209068978205323), (0, 0.06341957161203027), (1, 0.06663496978580952), (8, 0.0750509724020958), (10, 0.08082616329193115), (16, 0.08556768018752337), (12, 0.0902117732912302), (5, 0.10629176069051027), (36, 0.41802164539694786), (18, 0.514319084584713), (53, 0.910103477537632)]
computing accuracy for after removing block 46 . block score: 0.019335006596520543
removed block 46 current accuracy 0.9288 loss from initial  0.022600000000000064
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.019751. All blocks and scores: [(27, 0.01975109102204442), (41, 0.01982937823049724), (40, 0.022143716225400567), (42, 0.022155773593112826), (50, 0.02220182493329048), (25, 0.022355333669111133), (23, 0.022638906026259065), (48, 0.02299930853769183), (45, 0.02386764995753765), (49, 0.02420494705438614), (44, 0.02439229772426188), (21, 0.025065353605896235), (22, 0.025398850440979004), (24, 0.02608273853547871), (20, 0.027388217160478234), (47, 0.02892913739196956), (38, 0.02934899367392063), (39, 0.02939102635718882), (15, 0.03232048824429512), (7, 0.03253821283578873), (19, 0.03263687202706933), (37, 0.03495320538058877), (51, 0.03748119669035077), (9, 0.0439886599779129), (6, 0.04668588284403086), (4, 0.04766168585047126), (14, 0.048071988858282566), (2, 0.05487791821360588), (52, 0.0559959951788187), (3, 0.05768894590437412), (13, 0.05959395179525018), (11, 0.05970785394310951), (17, 0.06209068838506937), (0, 0.06341957161203027), (1, 0.06663496885448694), (8, 0.07505097147077322), (10, 0.08082616794854403), (16, 0.08556767925620079), (12, 0.09021177608519793), (5, 0.10629176255315542), (36, 0.41802164539694786), (18, 0.5143190696835518), (53, 1.0016483440995216)]
computing accuracy for after removing block 27 . block score: 0.01975109102204442
removed block 27 current accuracy 0.9224 loss from initial  0.029000000000000026
training start
training epoch 0 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 1 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 2 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.1]
training epoch 3 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 4 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.1]
training epoch 5 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.1]
training epoch 6 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.1]
training epoch 7 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.1]
training epoch 8 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.1]
training epoch 9 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 12
[activation diff]: block to remove picked: 44, with score 0.010955. All blocks and scores: [(44, 0.010955052333883941), (45, 0.011512858560308814), (40, 0.011951953871175647), (41, 0.012030809768475592), (42, 0.013859655591659248), (47, 0.0156704552937299), (21, 0.024924919242039323), (22, 0.02510192641057074), (50, 0.026384536176919937), (20, 0.027148252818733454), (49, 0.028007503133267164), (48, 0.029004046926274896), (39, 0.030480380868539214), (23, 0.030797111801803112), (38, 0.030879120342433453), (15, 0.03213166585192084), (7, 0.03236444853246212), (19, 0.032388105522841215), (24, 0.03434390528127551), (25, 0.03711076779291034), (37, 0.03758008871227503), (51, 0.04121201019734144), (9, 0.04381598252803087), (6, 0.04633040400221944), (4, 0.04657825501635671), (14, 0.047774079721421), (2, 0.054526067804545164), (3, 0.05730310641229153), (11, 0.05933926906436682), (13, 0.05941535718739033), (17, 0.061867558397352695), (0, 0.06268504029139876), (52, 0.06535317935049534), (1, 0.06550957448780537), (8, 0.07442152593284845), (10, 0.08079848904162645), (16, 0.08569818548858166), (12, 0.09031280875205994), (5, 0.10481792967766523), (36, 0.2751087658107281), (18, 0.5109498053789139), (53, 0.813531830906868)]
computing accuracy for after removing block 44 . block score: 0.010955052333883941
removed block 44 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.011183. All blocks and scores: [(45, 0.01118264498654753), (40, 0.011951953521929681), (41, 0.01203080965206027), (42, 0.013859655591659248), (47, 0.015401713433675468), (21, 0.024924920639023185), (22, 0.02510192641057074), (50, 0.025566671742126346), (49, 0.02675099833868444), (20, 0.027148252818733454), (48, 0.02769438223913312), (39, 0.030480381101369858), (23, 0.03079711296595633), (38, 0.030879120342433453), (15, 0.03213166492059827), (7, 0.03236444806680083), (19, 0.0323881059885025), (24, 0.0343439057469368), (25, 0.037110768258571625), (37, 0.0375800896435976), (51, 0.03975676279515028), (9, 0.043815982062369585), (6, 0.0463304053992033), (4, 0.04657825594767928), (14, 0.04777408065274358), (2, 0.05452606733888388), (3, 0.05730310548096895), (11, 0.05933926999568939), (13, 0.05941535625606775), (52, 0.06164567964151502), (17, 0.06186755886301398), (0, 0.06268503982573748), (1, 0.06550957448780537), (8, 0.07442152686417103), (10, 0.08079849183559418), (16, 0.08569818176329136), (12, 0.09031280875205994), (5, 0.10481792781502008), (36, 0.27510876953601837), (18, 0.5109498277306557), (53, 0.8929258733987808)]
computing accuracy for after removing block 45 . block score: 0.01118264498654753
removed block 45 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.011952. All blocks and scores: [(40, 0.011951953754760325), (41, 0.012030809768475592), (42, 0.013859655242413282), (47, 0.016122856410220265), (21, 0.02492492087185383), (22, 0.025101926643401384), (50, 0.02582738222554326), (49, 0.02680448698811233), (20, 0.027148252353072166), (48, 0.02763768774457276), (39, 0.030480380402877927), (23, 0.030797112500295043), (38, 0.03087912010960281), (15, 0.03213166585192084), (7, 0.032364447601139545), (19, 0.032388107385486364), (24, 0.034343904815614223), (25, 0.03711076872423291), (37, 0.037580089177936316), (51, 0.039302386343479156), (9, 0.043815983925014734), (6, 0.04633040400221944), (4, 0.046578255482017994), (14, 0.047774081118404865), (2, 0.05452606687322259), (3, 0.05730310454964638), (11, 0.05933926999568939), (13, 0.05941535672172904), (52, 0.06005579466000199), (17, 0.06186755932867527), (0, 0.06268504168838263), (1, 0.06550957262516022), (8, 0.07442152593284845), (10, 0.08079848904162645), (16, 0.08569818269461393), (12, 0.09031280782073736), (5, 0.10481792967766523), (36, 0.2751087658107281), (18, 0.5109498202800751), (53, 0.9868242368102074)]
computing accuracy for after removing block 40 . block score: 0.011951953754760325
removed block 40 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.011734. All blocks and scores: [(41, 0.011733551742509007), (42, 0.012743527768179774), (47, 0.01551647367887199), (50, 0.02404416841454804), (21, 0.02492492040619254), (22, 0.02510192710906267), (49, 0.025443068239837885), (48, 0.026046968530863523), (20, 0.027148252353072166), (39, 0.030480380170047283), (23, 0.03079711296595633), (38, 0.030879119876772165), (15, 0.03213166585192084), (7, 0.03236444806680083), (19, 0.03238810691982508), (24, 0.03434390667825937), (25, 0.0371107691898942), (51, 0.03730439208447933), (37, 0.03758009010925889), (9, 0.04381598345935345), (6, 0.04633040400221944), (4, 0.04657825594767928), (14, 0.047774081118404865), (52, 0.054419939406216145), (2, 0.05452606827020645), (3, 0.0573031073436141), (11, 0.05933926999568939), (13, 0.059415357653051615), (17, 0.06186755886301398), (0, 0.06268504215404391), (1, 0.06550957355648279), (8, 0.07442152593284845), (10, 0.08079848997294903), (16, 0.08569818362593651), (12, 0.09031280875205994), (5, 0.10481792781502008), (36, 0.2751087658107281), (18, 0.5109498202800751), (53, 1.0500304847955704)]
computing accuracy for after removing block 41 . block score: 0.011733551742509007
removed block 41 current accuracy 0.9258 loss from initial  0.025600000000000067
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.012448. All blocks and scores: [(42, 0.012448080931790173), (47, 0.015343992155976593), (50, 0.023620513500645757), (49, 0.024737670551985502), (21, 0.024924921337515116), (22, 0.02510192710906267), (48, 0.0254697073251009), (20, 0.02714825188741088), (39, 0.03048037993721664), (23, 0.030797112034633756), (38, 0.030879120575264096), (15, 0.032131665386259556), (7, 0.03236444899812341), (19, 0.0323881059885025), (24, 0.03434390528127551), (51, 0.03571234876289964), (25, 0.037110768258571625), (37, 0.03758009010925889), (9, 0.04381598299369216), (6, 0.04633040400221944), (4, 0.04657825594767928), (14, 0.04777408204972744), (52, 0.05192916467785835), (2, 0.05452606827020645), (3, 0.05730310594663024), (11, 0.059339269530028105), (13, 0.059415353927761316), (17, 0.06186755606904626), (0, 0.06268504029139876), (1, 0.06550957169383764), (8, 0.0744215240702033), (10, 0.08079849183559418), (16, 0.08569818455725908), (12, 0.09031280688941479), (5, 0.10481792967766523), (36, 0.2751087620854378), (18, 0.5109498202800751), (53, 1.1130480915307999)]
computing accuracy for after removing block 42 . block score: 0.012448080931790173
removed block 42 current accuracy 0.9158 loss from initial  0.035600000000000076
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 47, with score 0.015298. All blocks and scores: [(47, 0.015298292506486177), (50, 0.02364707994274795), (49, 0.024547768756747246), (21, 0.02492492040619254), (22, 0.025101926876232028), (48, 0.02539238496683538), (20, 0.02714825258590281), (39, 0.030480380402877927), (23, 0.030797111801803112), (38, 0.030879120342433453), (15, 0.03213166585192084), (7, 0.03236444853246212), (19, 0.0323881059885025), (24, 0.0343439057469368), (51, 0.03464011522009969), (25, 0.037110768258571625), (37, 0.03758009057492018), (9, 0.04381598252803087), (6, 0.046330404467880726), (4, 0.04657825455069542), (14, 0.04777408065274358), (52, 0.051994651556015015), (2, 0.05452606547623873), (3, 0.057303106877952814), (11, 0.05933927185833454), (13, 0.05941535672172904), (17, 0.06186755886301398), (0, 0.06268504029139876), (1, 0.06550957262516022), (8, 0.07442152500152588), (10, 0.08079848811030388), (16, 0.08569818269461393), (12, 0.09031280782073736), (5, 0.10481792967766523), (36, 0.2751087658107281), (18, 0.5109498128294945), (53, 1.1791823357343674)]
computing accuracy for after removing block 47 . block score: 0.015298292506486177
removed block 47 current accuracy 0.8896 loss from initial  0.06180000000000008
training start
training epoch 0 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.1]
training epoch 1 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 2 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.1]
training epoch 3 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.1]
training epoch 4 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.1]
training epoch 5 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 6 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.1]
training epoch 7 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.1]
training epoch 8 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.1]
training epoch 9 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.024704. All blocks and scores: [(21, 0.024704002775251865), (22, 0.025160845834761858), (48, 0.026392726227641106), (20, 0.027156113646924496), (50, 0.02928510634228587), (23, 0.03096539620310068), (15, 0.03194351587444544), (49, 0.03220645128749311), (7, 0.03253140393644571), (19, 0.03269491670653224), (24, 0.034323770087212324), (38, 0.036602357402443886), (25, 0.037356226705014706), (39, 0.037539408542215824), (51, 0.04298291401937604), (37, 0.043584286235272884), (9, 0.04370080539956689), (6, 0.04640836734324694), (14, 0.04752598516643047), (4, 0.047575521282851696), (2, 0.05458663823083043), (3, 0.057472949381917715), (13, 0.05922381207346916), (11, 0.05963209830224514), (17, 0.062069764360785484), (0, 0.0636359378695488), (1, 0.06613624934107065), (52, 0.0677450429648161), (8, 0.07421176228672266), (10, 0.08137443009763956), (16, 0.08467553369700909), (12, 0.09013684745877981), (5, 0.10553273092955351), (36, 0.27779147028923035), (18, 0.5114389061927795), (53, 0.8061602562665939)]
computing accuracy for after removing block 21 . block score: 0.024704002775251865
removed block 21 current accuracy 0.9354 loss from initial  0.016000000000000014
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023439. All blocks and scores: [(22, 0.023439018987119198), (48, 0.02516427799127996), (20, 0.027156115043908358), (50, 0.027404405642300844), (23, 0.02861415990628302), (49, 0.03119917307049036), (24, 0.03121368959546089), (15, 0.03194351587444544), (7, 0.032531404402107), (19, 0.032694915775209665), (38, 0.03385258186608553), (25, 0.035222252830863), (39, 0.035303930286318064), (51, 0.040253296960145235), (37, 0.04120548069477081), (9, 0.043700804468244314), (6, 0.046408367808908224), (14, 0.0475259842351079), (4, 0.04757551942020655), (2, 0.05458663823083043), (3, 0.057472949381917715), (52, 0.05796397244557738), (13, 0.05922381114214659), (11, 0.05963209643959999), (17, 0.062069762498140335), (0, 0.06363593693822622), (1, 0.06613624840974808), (8, 0.07421176414936781), (10, 0.08137443009763956), (16, 0.08467553369700909), (12, 0.09013684839010239), (5, 0.10553273092955351), (36, 0.26143426820635796), (18, 0.5114389136433601), (53, 0.8347198367118835)]
computing accuracy for after removing block 22 . block score: 0.023439018987119198
removed block 22 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 48, with score 0.023951. All blocks and scores: [(48, 0.02395118633285165), (50, 0.026239385828375816), (23, 0.02638536924496293), (20, 0.027156114112585783), (24, 0.028316383250057697), (49, 0.029993260512128472), (15, 0.03194351587444544), (38, 0.032382297329604626), (7, 0.03253140393644571), (19, 0.032694915775209665), (25, 0.0334255937486887), (39, 0.03387291310355067), (51, 0.03803900396451354), (37, 0.04167129332199693), (9, 0.043700805865228176), (6, 0.04640836687758565), (14, 0.047525984700769186), (4, 0.047575518023222685), (52, 0.05238973721861839), (2, 0.05458663869649172), (3, 0.057472947519272566), (13, 0.05922381393611431), (11, 0.059632097370922565), (17, 0.06206976529210806), (0, 0.06363593693822622), (1, 0.0661362474784255), (8, 0.07421176414936781), (10, 0.08137443009763956), (16, 0.08467553369700909), (12, 0.09013684745877981), (5, 0.10553272813558578), (36, 0.2579462267458439), (18, 0.5114388987421989), (53, 0.8475225046277046)]
computing accuracy for after removing block 48 . block score: 0.02395118633285165
removed block 48 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.026799999999999935 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.026385. All blocks and scores: [(23, 0.026385369012132287), (20, 0.027156115276739), (50, 0.027378989616408944), (24, 0.028316383017227054), (49, 0.030525411712005734), (15, 0.03194351587444544), (38, 0.032382297329604626), (7, 0.032531402073800564), (19, 0.03269491717219353), (25, 0.0334255937486887), (39, 0.0338729121722281), (51, 0.034946293104439974), (37, 0.04167129239067435), (9, 0.04370080539956689), (6, 0.04640836641192436), (14, 0.047525983303785324), (4, 0.04757551895454526), (52, 0.05030605336651206), (2, 0.05458663823083043), (3, 0.057472949847579), (13, 0.05922381300479174), (11, 0.059632099699229), (17, 0.06206976342946291), (0, 0.06363593740388751), (1, 0.06613625027239323), (8, 0.07421176228672266), (10, 0.08137443289160728), (16, 0.08467553462833166), (12, 0.09013684745877981), (5, 0.10553273092955351), (36, 0.2579462192952633), (18, 0.5114389061927795), (53, 0.9697269573807716)]
computing accuracy for after removing block 23 . block score: 0.026385369012132287
removed block 23 current accuracy 0.8878 loss from initial  0.06359999999999999
since last training loss: 0.05019999999999991 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.027156. All blocks and scores: [(20, 0.027156115043908358), (24, 0.0273081767372787), (50, 0.027767500141635537), (49, 0.03128008637577295), (15, 0.03194351587444544), (7, 0.032531403470784426), (19, 0.032694915775209665), (38, 0.03332873387262225), (25, 0.033690729178488255), (39, 0.03454077895730734), (51, 0.0349786183796823), (9, 0.043700804468244314), (37, 0.04575118934735656), (6, 0.04640836687758565), (14, 0.04752598516643047), (4, 0.04757552081719041), (52, 0.05054777069017291), (2, 0.054586637765169144), (3, 0.05747294798493385), (13, 0.059223811607807875), (11, 0.059632097370922565), (17, 0.0620697638951242), (0, 0.06363593600690365), (1, 0.06613624934107065), (8, 0.07421176228672266), (10, 0.08137443196028471), (16, 0.08467553462833166), (12, 0.09013684932142496), (5, 0.10553272627294064), (36, 0.27397631481289864), (18, 0.5114388987421989), (53, 0.971046693623066)]
computing accuracy for after removing block 20 . block score: 0.027156115043908358
removed block 20 current accuracy 0.864 loss from initial  0.08740000000000003
since last training loss: 0.07399999999999995 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.026574. All blocks and scores: [(24, 0.02657448942773044), (50, 0.026752365985885262), (49, 0.03020877786912024), (15, 0.03194351587444544), (38, 0.032044360879808664), (7, 0.032531403470784426), (19, 0.03269491624087095), (25, 0.03309708274900913), (39, 0.033265004865825176), (51, 0.034029418136924505), (9, 0.04370080400258303), (6, 0.04640836687758565), (52, 0.046429994981735945), (37, 0.04653369449079037), (14, 0.04752598563209176), (4, 0.04757551942020655), (2, 0.05458663869649172), (3, 0.05747294798493385), (13, 0.05922381253913045), (11, 0.05963209830224514), (17, 0.06206976296380162), (0, 0.06363593693822622), (1, 0.06613624934107065), (8, 0.07421176135540009), (10, 0.08137442916631699), (16, 0.08467553555965424), (12, 0.09013684559613466), (5, 0.10553272627294064), (36, 0.2744499556720257), (18, 0.5114388912916183), (53, 0.975607618689537)]
computing accuracy for after removing block 24 . block score: 0.02657448942773044
removed block 24 current accuracy 0.8186 loss from initial  0.13280000000000003
since last training loss: 0.11939999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.025810. All blocks and scores: [(50, 0.025810223072767258), (49, 0.029798401053994894), (15, 0.031943516340106726), (38, 0.032331112772226334), (7, 0.03253140393644571), (19, 0.03269491670653224), (51, 0.032730720937252045), (39, 0.03297448996454477), (25, 0.03311531385406852), (52, 0.042697819881141186), (9, 0.04370080400258303), (6, 0.046408365946263075), (14, 0.047525984700769186), (4, 0.047575518023222685), (37, 0.04904351895675063), (2, 0.054586637765169144), (3, 0.05747294798493385), (13, 0.059223813470453024), (11, 0.05963209783658385), (17, 0.06206976156681776), (0, 0.0636359378695488), (1, 0.0661362512037158), (8, 0.07421176321804523), (10, 0.08137443102896214), (16, 0.08467553649097681), (12, 0.09013684652745724), (5, 0.10553272906690836), (36, 0.28406694158911705), (18, 0.5114388912916183), (53, 0.9856066033244133)]
computing accuracy for after removing block 50 . block score: 0.025810223072767258
removed block 50 current accuracy 0.7712 loss from initial  0.18020000000000003
since last training loss: 0.16679999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.029798. All blocks and scores: [(49, 0.029798401286825538), (15, 0.031943514477461576), (38, 0.03233111370354891), (7, 0.032531404402107), (19, 0.03269491624087095), (39, 0.032974489498883486), (25, 0.03311531571671367), (51, 0.037268831860274076), (9, 0.04370080400258303), (6, 0.04640836734324694), (14, 0.04752598609775305), (4, 0.04757551942020655), (37, 0.04904352035373449), (52, 0.05343061173334718), (2, 0.054586639162153006), (3, 0.05747294845059514), (13, 0.0592238144017756), (11, 0.05963209830224514), (17, 0.0620697638951242), (0, 0.06363593507558107), (1, 0.06613625027239323), (8, 0.07421176321804523), (10, 0.08137443009763956), (16, 0.08467553649097681), (12, 0.09013684839010239), (5, 0.10553273186087608), (36, 0.28406694531440735), (18, 0.5114389061927795), (53, 1.2661557793617249)]
computing accuracy for after removing block 49 . block score: 0.029798401286825538
removed block 49 current accuracy 0.6836 loss from initial  0.26780000000000004
since last training loss: 0.25439999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 15, with score 0.031944. All blocks and scores: [(15, 0.031943516340106726), (38, 0.03233111370354891), (7, 0.032531403470784426), (19, 0.03269491670653224), (39, 0.03297448996454477), (25, 0.03311531571671367), (51, 0.040790090803056955), (9, 0.0437008049339056), (6, 0.04640836687758565), (14, 0.0475259842351079), (4, 0.047575518023222685), (37, 0.049043519888073206), (2, 0.05458663869649172), (3, 0.057472949847579), (52, 0.05916307354345918), (13, 0.059223813470453024), (11, 0.059632099699229), (17, 0.06206976342946291), (0, 0.06363593693822622), (1, 0.0661362512037158), (8, 0.07421176228672266), (10, 0.08137443009763956), (16, 0.08467553555965424), (12, 0.09013684652745724), (5, 0.10553272813558578), (36, 0.28406694158911705), (18, 0.5114389210939407), (53, 1.5464477837085724)]
computing accuracy for after removing block 15 . block score: 0.031943516340106726
removed block 15 current accuracy 0.6336 loss from initial  0.31779999999999997
training start
training epoch 0 val accuracy 0.846 topk_dict {'top1': 0.846} is_best True lr [0.1]
training epoch 1 val accuracy 0.853 topk_dict {'top1': 0.853} is_best True lr [0.1]
training epoch 2 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 3 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 4 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 5 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 6 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 7 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.1]
training epoch 8 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.1]
training epoch 9 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
