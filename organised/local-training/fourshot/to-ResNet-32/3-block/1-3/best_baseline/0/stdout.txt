start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589500389993), (30, 0.01001118787098676), (31, 0.010232581291347742), (34, 0.013294661184772849), (29, 0.013421116978861392), (35, 0.01595768961124122), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01999649195931852), (46, 0.020590224768966436), (25, 0.02207829523831606), (23, 0.022228715242817998), (41, 0.022336416179314256), (44, 0.023145999060943723), (40, 0.02374959015287459), (45, 0.023975495481863618), (21, 0.02494108909741044), (48, 0.02495770645327866), (22, 0.025151389883831143), (50, 0.025287174619734287), (24, 0.025880583096295595), (49, 0.02591664856299758), (42, 0.02623223210684955), (20, 0.026848891284316778), (47, 0.0286329488735646), (38, 0.0313443448394537), (39, 0.03144129645079374), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.037918031215667725), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216024339199), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.00939958926755935), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013119244133122265), (29, 0.013421116629615426), (26, 0.016072140308097005), (35, 0.016093928134068847), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687371894717), (46, 0.02030070498585701), (41, 0.0218602754175663), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022977192420512438), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.02454021666198969), (50, 0.024770823307335377), (21, 0.024941088864579797), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.025880582397803664), (42, 0.02589341322891414), (20, 0.026848892215639353), (47, 0.028072760440409184), (38, 0.031091189244762063), (39, 0.0311913606710732), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.04127101460471749), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428550750017), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4339806027710438), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.00939958926755935
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.012758882134221494), (29, 0.013421116978861392), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02289147791452706), (40, 0.02360257995314896), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.024639350827783346), (21, 0.02494108979590237), (22, 0.025151390116661787), (49, 0.025392550509423018), (42, 0.025712220463901758), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.028052504872903228), (38, 0.030935873743146658), (39, 0.031173036200925708), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.038343189749866724), (51, 0.04113080818206072), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441723043099046), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159961543977), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.01607214054092765), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.02027974440716207), (41, 0.02175602037459612), (25, 0.022078294539824128), (23, 0.022228715009987354), (44, 0.023001377005130053), (40, 0.023739926982671022), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.025273551931604743), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.02772757480852306), (38, 0.03074627392925322), (39, 0.03128179535269737), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.04082479886710644), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740230485797), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003642141819), (17, 0.06132525485008955), (0, 0.06337464554235339), (52, 0.06356756342574954), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.437769316136837), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116513200104), (35, 0.015968912048265338), (26, 0.016072140773758292), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.01983700809068978), (46, 0.020137187093496323), (41, 0.02158405538648367), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569097509607673), (45, 0.023840721230953932), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.025045574409887195), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027423852356150746), (38, 0.030735649866983294), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525531575084), (52, 0.06270107859745622), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43692687153816223), (18, 0.5117432922124863), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141472250223), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.02030268358066678), (46, 0.02032419736497104), (41, 0.021962702507153153), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02304507768712938), (48, 0.024024546844884753), (50, 0.02409697324037552), (40, 0.024156816070899367), (45, 0.024168408708646894), (49, 0.024922372307628393), (21, 0.024941089330241084), (22, 0.0251513896510005), (42, 0.025816059904173017), (24, 0.02588058216497302), (20, 0.026848892448469996), (47, 0.027568295830860734), (38, 0.031787265092134476), (15, 0.03205838520079851), (39, 0.03225791221484542), (7, 0.032445503398776054), (19, 0.03254077956080437), (51, 0.04008621443063021), (37, 0.040690730791538954), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.062210948672145605), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.44933703169226646), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019856703467667103), (46, 0.019988976418972015), (41, 0.021256206091493368), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022692033322528005), (48, 0.02352137118577957), (50, 0.023533890722319484), (40, 0.023616241058334708), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.02483832696452737), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880582397803664), (47, 0.02681345515884459), (20, 0.026848892215639353), (38, 0.031083731912076473), (39, 0.032056889962404966), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03907974949106574), (37, 0.04015214508399367), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.059700033627450466), (52, 0.060369073413312435), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4432784393429756), (18, 0.5117432996630669), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144364967942), (28, 0.016986022237688303), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022507572546601295), (48, 0.02289936924353242), (50, 0.022937727393582463), (40, 0.023057401878759265), (42, 0.023520408663898706), (45, 0.02363370032981038), (49, 0.02408191910944879), (21, 0.02494108909741044), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.0263227925170213), (20, 0.026848892215639353), (38, 0.03014914900995791), (39, 0.03146669710986316), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.03926890343427658), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992640838027), (52, 0.05846811877563596), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.43490004166960716), (18, 0.5117433071136475), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504144364967942
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381991190835834), (27, 0.018769708229228854), (46, 0.018842301098629832), (41, 0.019016370875760913), (48, 0.02130915760062635), (50, 0.021624521119520068), (44, 0.021748854545876384), (40, 0.021916966885328293), (42, 0.021930374205112457), (25, 0.022078294539824128), (23, 0.02222871547564864), (45, 0.022736448794603348), (49, 0.022970063844695687), (21, 0.024941088631749153), (22, 0.02515139034949243), (47, 0.02535583171993494), (24, 0.02588058216497302), (20, 0.026848892215639353), (38, 0.02869188762269914), (39, 0.02962443232536316), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03601635666564107), (37, 0.03643036726862192), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740556448698), (52, 0.05466858018189669), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.41641608998179436), (18, 0.5117432922124863), (53, 0.8948249369859695)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.1]
training epoch 1 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.1]
training epoch 2 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 3 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.1]
training epoch 4 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.1]
training epoch 5 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.1]
training epoch 6 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.1]
training epoch 7 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.1]
training epoch 8 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.1]
training epoch 9 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.1]
training epoch 10 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.014851. All blocks and scores: [(38, 0.014850934967398643), (37, 0.018828242318704724), (43, 0.020913519896566868), (46, 0.02131595415994525), (23, 0.02263046894222498), (41, 0.023436617571860552), (44, 0.02423512376844883), (45, 0.024734466103836894), (21, 0.02504755021072924), (22, 0.02529192273505032), (48, 0.02551542269065976), (40, 0.025559555739164352), (50, 0.02561217127367854), (27, 0.025745877297595143), (49, 0.025985751068219543), (24, 0.026089296443387866), (42, 0.02711783442646265), (20, 0.02724629151634872), (47, 0.02919512102380395), (25, 0.029934047954156995), (15, 0.03210218343883753), (7, 0.032418690621852875), (19, 0.03274871967732906), (39, 0.03494919463992119), (51, 0.04147937195375562), (9, 0.043370308354496956), (6, 0.04694517236202955), (14, 0.04800089402124286), (4, 0.048635369166731834), (2, 0.054875091183930635), (3, 0.05781092448160052), (13, 0.059169608633965254), (11, 0.059562013018876314), (17, 0.061650821939110756), (0, 0.06351956212893128), (1, 0.06691443733870983), (52, 0.06827807705849409), (8, 0.07452055718749762), (10, 0.08066245540976524), (16, 0.08523337729275227), (12, 0.09002668038010597), (5, 0.10605641175061464), (36, 0.3871430940926075), (18, 0.5114326849579811), (53, 0.7868987023830414)]
computing accuracy for after removing block 38 . block score: 0.014850934967398643
removed block 38 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 37, with score 0.018828. All blocks and scores: [(37, 0.018828242318704724), (43, 0.020112097961828113), (46, 0.020236164797097445), (41, 0.02231943840160966), (23, 0.022630468476563692), (45, 0.023226140532642603), (44, 0.023254779865965247), (50, 0.023647122783586383), (48, 0.023814094718545675), (49, 0.02451595664024353), (40, 0.024994574021548033), (21, 0.025047549745067954), (22, 0.025291923200711608), (42, 0.025523462565615773), (27, 0.025745877297595143), (24, 0.02608929597772658), (47, 0.02694377163425088), (20, 0.027246291283518076), (25, 0.029934049118310213), (15, 0.03210218297317624), (7, 0.03241869015619159), (19, 0.03274872060865164), (39, 0.03590177744626999), (51, 0.0404402450658381), (9, 0.043370306957513094), (6, 0.04694517236202955), (14, 0.048000894486904144), (4, 0.04863536870107055), (2, 0.0548750925809145), (3, 0.0578109254129231), (13, 0.0591696104966104), (11, 0.05956201255321503), (17, 0.06165081961080432), (0, 0.06351956119760871), (52, 0.06475239060819149), (1, 0.06691443920135498), (8, 0.07452055253088474), (10, 0.08066245634108782), (16, 0.08523337822407484), (12, 0.09002667851746082), (5, 0.10605641733855009), (36, 0.3871430940926075), (18, 0.5114326775074005), (53, 0.8074813634157181)]
computing accuracy for after removing block 37 . block score: 0.018828242318704724
removed block 37 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.018680. All blocks and scores: [(43, 0.01867956155911088), (46, 0.01870770030654967), (41, 0.020415841368958354), (50, 0.020870420150458813), (45, 0.021253701532259583), (48, 0.021534974221140146), (44, 0.021601588698104024), (49, 0.02224307181313634), (23, 0.022630468476563692), (40, 0.02375617972575128), (47, 0.024145779898390174), (42, 0.024194526253268123), (21, 0.02504754951223731), (22, 0.025291922967880964), (27, 0.025745877297595143), (24, 0.02608929667621851), (20, 0.02724629151634872), (25, 0.02993404818698764), (15, 0.03210218343883753), (7, 0.03241869015619159), (19, 0.03274872014299035), (39, 0.03658584272488952), (51, 0.037014119792729616), (9, 0.04337030742317438), (6, 0.04694517236202955), (14, 0.04800089541822672), (4, 0.048635369166731834), (2, 0.05487509351223707), (52, 0.05686659039929509), (3, 0.057810924015939236), (13, 0.059169608168303967), (11, 0.059562013018876314), (17, 0.06165082147344947), (0, 0.06351956306025386), (1, 0.06691444106400013), (8, 0.07452055625617504), (10, 0.08066245634108782), (16, 0.08523338101804256), (12, 0.09002668224275112), (5, 0.10605641361325979), (36, 0.3871430940926075), (18, 0.5114326998591423), (53, 0.8324786573648453)]
computing accuracy for after removing block 43 . block score: 0.01867956155911088
removed block 43 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.019534. All blocks and scores: [(46, 0.01953385421074927), (41, 0.020415839971974492), (50, 0.021210823440924287), (49, 0.022288135485723615), (45, 0.02236448833718896), (48, 0.02258627861738205), (23, 0.022630468476563692), (44, 0.023165092803537846), (40, 0.023756179958581924), (42, 0.024194526253268123), (21, 0.025047550443559885), (47, 0.02512413333170116), (22, 0.025291923200711608), (27, 0.025745876831933856), (24, 0.026089296443387866), (20, 0.02724629221484065), (25, 0.029934049351140857), (15, 0.032102182507514954), (7, 0.032418688759207726), (19, 0.03274871967732906), (39, 0.03658584225922823), (51, 0.03671570401638746), (9, 0.04337030602619052), (6, 0.04694517282769084), (14, 0.04800089541822672), (4, 0.04863537009805441), (2, 0.05487509071826935), (52, 0.05638588732108474), (3, 0.0578109254129231), (13, 0.059169608633965254), (11, 0.059562013018876314), (17, 0.061650820542126894), (0, 0.06351956399157643), (1, 0.0669144382700324), (8, 0.07452055718749762), (10, 0.08066245634108782), (16, 0.08523337822407484), (12, 0.09002667851746082), (5, 0.10605641081929207), (36, 0.3871430866420269), (18, 0.5114326998591423), (53, 0.8805081471800804)]
computing accuracy for after removing block 46 . block score: 0.01953385421074927
removed block 46 current accuracy 0.93 loss from initial  0.021399999999999975
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.020416. All blocks and scores: [(41, 0.020415840670466423), (50, 0.021702369675040245), (45, 0.022364488104358315), (23, 0.022630468476563692), (49, 0.022992485901340842), (44, 0.02316509187221527), (48, 0.023211911087855697), (40, 0.023756179492920637), (42, 0.02419452555477619), (21, 0.025047549279406667), (22, 0.02529192273505032), (27, 0.025745877297595143), (24, 0.02608929667621851), (20, 0.027246291982010007), (47, 0.02729594544507563), (25, 0.029934048419818282), (15, 0.03210218343883753), (7, 0.03241868922486901), (19, 0.03274871967732906), (39, 0.03658584365621209), (51, 0.03712326753884554), (9, 0.04337030742317438), (6, 0.04694517282769084), (14, 0.04800089541822672), (4, 0.04863536963239312), (2, 0.05487509164959192), (52, 0.05668776901438832), (3, 0.05781092355027795), (13, 0.05916960909962654), (11, 0.0595620134845376), (17, 0.06165082007646561), (0, 0.06351956306025386), (1, 0.0669144382700324), (8, 0.07452055532485247), (10, 0.08066245540976524), (16, 0.08523338101804256), (12, 0.0900266794487834), (5, 0.10605641268193722), (36, 0.3871430940926075), (18, 0.5114326998591423), (53, 0.9774148389697075)]
computing accuracy for after removing block 41 . block score: 0.020415840670466423
removed block 41 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021402. All blocks and scores: [(50, 0.021401892881840467), (45, 0.0224552636500448), (48, 0.022488479735329747), (49, 0.02256622421555221), (23, 0.02263046824373305), (40, 0.023756179492920637), (42, 0.024338204180821776), (44, 0.02446474297903478), (21, 0.02504755021072924), (22, 0.025291922967880964), (27, 0.025745877996087074), (24, 0.026089296909049153), (20, 0.02724629221484065), (47, 0.02738480200059712), (25, 0.029934048652648926), (15, 0.03210218297317624), (7, 0.03241869015619159), (19, 0.032748721074312925), (51, 0.03548050671815872), (39, 0.03658584225922823), (9, 0.04337030788883567), (6, 0.04694517143070698), (14, 0.04800089495256543), (4, 0.048635369166731834), (52, 0.05419157166033983), (2, 0.05487509211525321), (3, 0.05781092355027795), (13, 0.05916961142793298), (11, 0.0595620134845376), (17, 0.061650820542126894), (0, 0.06351956259459257), (1, 0.0669144382700324), (8, 0.07452055625617504), (10, 0.08066245727241039), (16, 0.08523338008671999), (12, 0.09002668131142855), (5, 0.1060564098879695), (36, 0.3871430903673172), (18, 0.5114326998591423), (53, 1.061223417520523)]
computing accuracy for after removing block 50 . block score: 0.021401892881840467
removed block 50 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.022455. All blocks and scores: [(45, 0.022455262020230293), (48, 0.022488479735329747), (49, 0.022566223982721567), (23, 0.022630468709394336), (40, 0.023756179260089993), (42, 0.024338203947991133), (44, 0.024464743677526712), (21, 0.025047549977898598), (22, 0.025291922967880964), (27, 0.025745877297595143), (24, 0.026089296443387866), (20, 0.027246292680501938), (47, 0.02738480200059712), (25, 0.029934049118310213), (15, 0.032102182041853666), (7, 0.03241869015619159), (19, 0.032748721074312925), (39, 0.036585843190550804), (51, 0.03823916846886277), (9, 0.04337030649185181), (6, 0.04694517236202955), (14, 0.04800089541822672), (4, 0.04863536823540926), (2, 0.05487509071826935), (3, 0.05781092494726181), (13, 0.05916960956528783), (11, 0.05956201534718275), (52, 0.06051806593313813), (17, 0.061650821939110756), (0, 0.06351956306025386), (1, 0.0669144382700324), (8, 0.07452055718749762), (10, 0.08066245820373297), (16, 0.08523337915539742), (12, 0.09002668131142855), (5, 0.10605641361325979), (36, 0.3871430940926075), (18, 0.5114326998591423), (53, 1.2519380152225494)]
computing accuracy for after removing block 45 . block score: 0.022455262020230293
removed block 45 current accuracy 0.9108 loss from initial  0.04059999999999997
since last training loss: 0.03399999999999992 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 48, with score 0.022335. All blocks and scores: [(48, 0.022335002664476633), (49, 0.022598590003326535), (23, 0.02263046824373305), (40, 0.023756179958581924), (42, 0.024338205344974995), (44, 0.02446474344469607), (21, 0.025047549279406667), (22, 0.025291922967880964), (27, 0.025745877297595143), (24, 0.026089295744895935), (20, 0.02724629151634872), (47, 0.028768776450306177), (25, 0.029934048419818282), (15, 0.03210218297317624), (7, 0.03241868922486901), (19, 0.03274871967732906), (39, 0.03658584272488952), (51, 0.037460936699062586), (9, 0.04337030742317438), (6, 0.04694517236202955), (14, 0.048000895883888006), (4, 0.04863536823540926), (2, 0.05487509164959192), (52, 0.0571113433688879), (3, 0.057810924015939236), (13, 0.05916961096227169), (11, 0.05956201208755374), (17, 0.061650821939110756), (0, 0.06351956259459257), (1, 0.06691443733870983), (8, 0.07452055346220732), (10, 0.08066245727241039), (16, 0.08523338008671999), (12, 0.09002668038010597), (5, 0.10605641454458237), (36, 0.3871430866420269), (18, 0.5114326849579811), (53, 1.4123925864696503)]
computing accuracy for after removing block 48 . block score: 0.022335002664476633
removed block 48 current accuracy 0.8984 loss from initial  0.05300000000000005
since last training loss: 0.0464 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.022630. All blocks and scores: [(23, 0.022630468476563692), (40, 0.023756179492920637), (42, 0.024338204879313707), (44, 0.024464743211865425), (21, 0.025047549977898598), (22, 0.02529192273505032), (49, 0.025579742155969143), (27, 0.025745876599103212), (24, 0.02608929667621851), (20, 0.027246291982010007), (47, 0.02876877598464489), (25, 0.029934048419818282), (15, 0.032102182041853666), (7, 0.03241868922486901), (19, 0.03274872014299035), (39, 0.03658584272488952), (51, 0.03761511854827404), (9, 0.04337030742317438), (6, 0.04694517096504569), (14, 0.04800089355558157), (4, 0.04863536963239312), (2, 0.0548750925809145), (3, 0.057810924015939236), (13, 0.05916961096227169), (11, 0.05956201255321503), (17, 0.06165082147344947), (0, 0.06351956306025386), (52, 0.063949772156775), (1, 0.06691443733870983), (8, 0.07452055811882019), (10, 0.08066245820373297), (16, 0.08523337729275227), (12, 0.0900266794487834), (5, 0.10605641268193722), (36, 0.3871431015431881), (18, 0.5114326924085617), (53, 1.5298200398683548)]
computing accuracy for after removing block 23 . block score: 0.022630468476563692
removed block 23 current accuracy 0.89 loss from initial  0.06140000000000001
training start
training epoch 0 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 1 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.1]
training epoch 2 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 3 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 4 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.1]
training epoch 5 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 6 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 7 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 8 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 9 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.025055. All blocks and scores: [(21, 0.02505481243133545), (20, 0.027133348863571882), (15, 0.032130112405866385), (7, 0.03242927882820368), (19, 0.03245512582361698), (22, 0.03593546478077769), (24, 0.03847892116755247), (27, 0.042553418315947056), (9, 0.043646144680678844), (44, 0.04364912677556276), (49, 0.044783863704651594), (25, 0.04593915119767189), (6, 0.04679807089269161), (14, 0.0478355223312974), (4, 0.04950052406638861), (42, 0.05130334943532944), (47, 0.05203852942213416), (40, 0.054567039012908936), (2, 0.055081603582948446), (51, 0.056259425822645426), (3, 0.0580586101859808), (13, 0.05959304515272379), (11, 0.05977841652929783), (17, 0.0622466579079628), (0, 0.06384213641285896), (1, 0.06774733122438192), (39, 0.07112890295684338), (52, 0.0743579613044858), (8, 0.07448644563555717), (10, 0.08082103356719017), (16, 0.08578580897301435), (12, 0.09001057781279087), (5, 0.10663974191993475), (18, 0.5121660828590393), (36, 0.6000766903162003), (53, 1.319495365023613)]
computing accuracy for after removing block 21 . block score: 0.02505481243133545
removed block 21 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 20, with score 0.027133. All blocks and scores: [(20, 0.02713334863074124), (15, 0.03213011100888252), (7, 0.032429279293864965), (19, 0.03245512628927827), (22, 0.032929881010204554), (24, 0.034825481940060854), (27, 0.040145153645426035), (44, 0.04100118204951286), (25, 0.04256112780421972), (49, 0.04323803307488561), (9, 0.043646144680678844), (42, 0.0448530912399292), (6, 0.04679806809872389), (14, 0.047835519071668386), (47, 0.04912695148959756), (4, 0.04950052499771118), (40, 0.05035732360556722), (51, 0.05357280280441046), (2, 0.05508160125464201), (3, 0.058058608788996935), (13, 0.059593044221401215), (11, 0.059778416994959116), (17, 0.06224665604531765), (0, 0.06384213455021381), (52, 0.06738442182540894), (39, 0.06772053707391024), (1, 0.0677473284304142), (8, 0.07448644656687975), (10, 0.08082103170454502), (16, 0.08578581176698208), (12, 0.09001057967543602), (5, 0.10663974191993475), (18, 0.5121660977602005), (36, 0.5622904151678085), (53, 1.3631914407014847)]
computing accuracy for after removing block 20 . block score: 0.02713334863074124
removed block 20 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.032130. All blocks and scores: [(15, 0.0321301119402051), (7, 0.03242928022518754), (19, 0.03245512628927827), (24, 0.03301319247111678), (22, 0.033080758061259985), (27, 0.038222067058086395), (44, 0.04057014128193259), (25, 0.04219786077737808), (42, 0.04222075594589114), (49, 0.042333418503403664), (9, 0.04364614374935627), (47, 0.04657021630555391), (6, 0.04679806903004646), (14, 0.047835519071668386), (4, 0.04950052686035633), (40, 0.05015652719885111), (51, 0.05217868834733963), (2, 0.05508160078898072), (3, 0.058058610651642084), (13, 0.059593044221401215), (11, 0.05977841513231397), (17, 0.062246656976640224), (52, 0.06377337453886867), (0, 0.06384213548153639), (39, 0.06511384528130293), (1, 0.06774733029305935), (8, 0.07448644656687975), (10, 0.0808210326358676), (16, 0.08578580990433693), (12, 0.09001057874411345), (5, 0.10663973912596703), (18, 0.5121660977602005), (36, 0.5518256351351738), (53, 1.3356028348207474)]
computing accuracy for after removing block 15 . block score: 0.0321301119402051
removed block 15 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.031080. All blocks and scores: [(22, 0.03107965411618352), (24, 0.031453872099518776), (7, 0.032429279293864965), (19, 0.032703014090657234), (27, 0.03722849441692233), (44, 0.03925793990492821), (25, 0.040094159077852964), (42, 0.041298039723187685), (49, 0.0424313573166728), (9, 0.04364614421501756), (6, 0.046798068564385176), (14, 0.047835519537329674), (47, 0.047977610025554895), (4, 0.04950052406638861), (40, 0.04954836796969175), (51, 0.05351284192875028), (2, 0.0550816017203033), (3, 0.05805860832333565), (13, 0.05959304701536894), (11, 0.059778413735330105), (0, 0.06384213548153639), (52, 0.06390586774796247), (39, 0.06538494769483805), (17, 0.06608886364847422), (1, 0.06774732936173677), (8, 0.07448644656687975), (10, 0.0808210326358676), (12, 0.09001057967543602), (16, 0.09572891797870398), (5, 0.10663974285125732), (18, 0.4996352978050709), (36, 0.5417604297399521), (53, 1.346260815858841)]
computing accuracy for after removing block 22 . block score: 0.03107965411618352
removed block 22 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.0361999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.028532. All blocks and scores: [(24, 0.02853236859664321), (7, 0.032429279293864965), (19, 0.03270301595330238), (27, 0.03459852049127221), (44, 0.037227469496428967), (25, 0.03835959453135729), (42, 0.040403188206255436), (49, 0.041304525919258595), (9, 0.04364614374935627), (47, 0.04576008627191186), (6, 0.04679806903004646), (14, 0.04783552046865225), (40, 0.04833457712084055), (4, 0.049500524532049894), (51, 0.05064505897462368), (2, 0.05508160265162587), (3, 0.05805860739201307), (13, 0.059593044221401215), (11, 0.05977841652929783), (52, 0.06034622620791197), (0, 0.06384213734418154), (39, 0.06539845373481512), (17, 0.06608886551111937), (1, 0.06774732936173677), (8, 0.07448644749820232), (10, 0.08082103170454502), (12, 0.09001057874411345), (16, 0.09572891891002655), (5, 0.10663974285125732), (18, 0.49963531643152237), (36, 0.5405837893486023), (53, 1.3449552208185196)]
computing accuracy for after removing block 24 . block score: 0.02853236859664321
removed block 24 current accuracy 0.8882 loss from initial  0.06320000000000003
since last training loss: 0.05579999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032429. All blocks and scores: [(7, 0.032429279293864965), (19, 0.03270301455631852), (27, 0.03404379729181528), (44, 0.03633172018453479), (25, 0.036767943762242794), (42, 0.03876390587538481), (49, 0.0401762411929667), (9, 0.04364614514634013), (47, 0.04520701849833131), (6, 0.04679806949570775), (40, 0.04703358095139265), (14, 0.047835520934313536), (51, 0.04891028534621), (4, 0.049500525929033756), (2, 0.05508160125464201), (3, 0.05805860832333565), (52, 0.05814120685681701), (13, 0.059593046084046364), (11, 0.05977841420099139), (0, 0.06384213455021381), (39, 0.06536664627492428), (17, 0.06608886457979679), (1, 0.06774733029305935), (8, 0.07448644656687975), (10, 0.0808210326358676), (12, 0.0900105806067586), (16, 0.09572891891002655), (5, 0.1066397437825799), (18, 0.4996352978050709), (36, 0.5321297571063042), (53, 1.3613197356462479)]
computing accuracy for after removing block 7 . block score: 0.032429279293864965
removed block 7 current accuracy 0.8774 loss from initial  0.07400000000000007
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 27, with score 0.032096. All blocks and scores: [(27, 0.032096163369715214), (19, 0.03247789526358247), (25, 0.035440437495708466), (44, 0.03563745319843292), (42, 0.03712942497804761), (49, 0.039594349917024374), (9, 0.043569120578467846), (40, 0.043762834277004004), (14, 0.04421898443251848), (47, 0.04426426673308015), (6, 0.04679806949570775), (51, 0.047391594387590885), (4, 0.04950052499771118), (13, 0.05163709260523319), (52, 0.054992067627608776), (2, 0.05508160311728716), (17, 0.05594566185027361), (11, 0.056462028529495), (3, 0.058058608788996935), (39, 0.06142351357266307), (0, 0.06384213548153639), (1, 0.06774732936173677), (8, 0.07245547231286764), (10, 0.08310079108923674), (12, 0.08412673231214285), (16, 0.08717940654605627), (5, 0.1066397475078702), (18, 0.4829569235444069), (36, 0.5132660493254662), (53, 1.4095837473869324)]
computing accuracy for after removing block 27 . block score: 0.032096163369715214
removed block 27 current accuracy 0.8594 loss from initial  0.09199999999999997
since last training loss: 0.0845999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 19, with score 0.032478. All blocks and scores: [(19, 0.03247789666056633), (25, 0.035440437495708466), (44, 0.036995119880884886), (49, 0.03897020174190402), (42, 0.04019371047616005), (47, 0.043192912358790636), (9, 0.043569119181483984), (14, 0.044218983966857195), (40, 0.044458162039518356), (6, 0.046798068564385176), (51, 0.04721487173810601), (4, 0.04950052406638861), (13, 0.051637092139571905), (52, 0.05486977705731988), (2, 0.05508160125464201), (17, 0.055945664178580046), (11, 0.05646202666684985), (3, 0.058058606926351786), (0, 0.06384213827550411), (39, 0.06444923020899296), (1, 0.06774732936173677), (8, 0.07245546951889992), (10, 0.08310078922659159), (12, 0.08412673696875572), (16, 0.087179409340024), (5, 0.1066397437825799), (18, 0.4829569384455681), (36, 0.5353798866271973), (53, 1.413607433438301)]
computing accuracy for after removing block 19 . block score: 0.03247789666056633
removed block 19 current accuracy 0.8214 loss from initial  0.13
since last training loss: 0.12259999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 25, with score 0.034322. All blocks and scores: [(25, 0.034321547485888004), (44, 0.035013134591281414), (49, 0.037518370896577835), (42, 0.03903442621231079), (47, 0.04044990846887231), (40, 0.04300025524571538), (9, 0.04356912197545171), (14, 0.044218983966857195), (51, 0.04578155465424061), (6, 0.04679806903004646), (4, 0.04950052499771118), (52, 0.050640849862247705), (13, 0.05163709307089448), (2, 0.05508160125464201), (17, 0.055945662315934896), (11, 0.056462028529495), (3, 0.05805860925465822), (39, 0.06148233776912093), (0, 0.06384213548153639), (1, 0.06774732936173677), (8, 0.07245546951889992), (10, 0.08310079108923674), (12, 0.08412673603743315), (16, 0.08717940840870142), (5, 0.10663974564522505), (18, 0.4829569421708584), (36, 0.5205533877015114), (53, 1.383444756269455)]
computing accuracy for after removing block 25 . block score: 0.034321547485888004
removed block 25 current accuracy 0.77 loss from initial  0.1814
training start
training epoch 0 val accuracy 0.857 topk_dict {'top1': 0.857} is_best True lr [0.1]
training epoch 1 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.1]
training epoch 2 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.1]
training epoch 3 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 4 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.1]
training epoch 5 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 6 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 7 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 8 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 10 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.933800)
finished training. finished 50 epochs. accuracy 0.9338 topk_dict {'top1': 0.9338}
start iteration 27
[activation diff]: block to remove picked: 9, with score 0.035117. All blocks and scores: [(9, 0.03511678706854582), (49, 0.047209825832396746), (40, 0.04881605785340071), (4, 0.049343643710017204), (44, 0.051099775824695826), (14, 0.05250771576538682), (2, 0.05480679124593735), (51, 0.0565603394061327), (47, 0.05736661236733198), (3, 0.058105741161853075), (11, 0.059571105521172285), (13, 0.060884793754667044), (42, 0.061536229215562344), (6, 0.06204563844949007), (17, 0.06242447020485997), (0, 0.0643330430611968), (8, 0.06517981737852097), (10, 0.0653920928016305), (1, 0.06682917568832636), (39, 0.06799770519137383), (52, 0.07432361226528883), (16, 0.08597912825644016), (12, 0.08808617107570171), (5, 0.10570745449513197), (36, 0.5857933536171913), (18, 0.6645760163664818), (53, 1.3433184325695038)]
computing accuracy for after removing block 9 . block score: 0.03511678706854582
removed block 9 current accuracy 0.925 loss from initial  0.02639999999999998
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 49, with score 0.045822. All blocks and scores: [(49, 0.045822456013411283), (40, 0.048014713916927576), (4, 0.049343643710017204), (44, 0.0509680537506938), (14, 0.052708893083035946), (51, 0.05460283067077398), (2, 0.054806789848953485), (3, 0.058105741161853075), (47, 0.0587652251124382), (42, 0.05921242572367191), (17, 0.060019419994205236), (6, 0.06204563984647393), (11, 0.06218408094719052), (13, 0.06427904777228832), (0, 0.06433304399251938), (8, 0.06517982110381126), (1, 0.06682917755097151), (39, 0.06685513444244862), (10, 0.07141199335455894), (52, 0.07296852488070726), (16, 0.08044354151934385), (12, 0.08532784786075354), (5, 0.10570745542645454), (36, 0.577760674059391), (18, 0.6742797046899796), (53, 1.3593332320451736)]
computing accuracy for after removing block 49 . block score: 0.045822456013411283
removed block 49 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 40, with score 0.048015. All blocks and scores: [(40, 0.04801471438258886), (4, 0.04934364464133978), (44, 0.050968050956726074), (14, 0.05270889028906822), (2, 0.054806788451969624), (51, 0.05662102811038494), (3, 0.05810574209317565), (47, 0.05876522371545434), (42, 0.059212425258010626), (17, 0.06001941952854395), (6, 0.062045639380812645), (11, 0.06218407955020666), (13, 0.06427904590964317), (0, 0.06433304212987423), (8, 0.06517981924116611), (1, 0.06682917941361666), (39, 0.06685513257980347), (10, 0.07141199242323637), (52, 0.07934712711721659), (16, 0.080443543381989), (12, 0.08532784786075354), (5, 0.1057074572890997), (36, 0.5777606815099716), (18, 0.6742797344923019), (53, 1.4980885535478592)]
computing accuracy for after removing block 40 . block score: 0.04801471438258886
removed block 40 current accuracy 0.894 loss from initial  0.05740000000000001
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 4, with score 0.049344. All blocks and scores: [(4, 0.04934364231303334), (44, 0.05078157316893339), (14, 0.05270889261737466), (51, 0.05325996968895197), (2, 0.05480678891763091), (47, 0.0568099613301456), (42, 0.05709588946774602), (3, 0.0581057402305305), (17, 0.06001941952854395), (6, 0.06204563705250621), (11, 0.0621840818785131), (13, 0.06427904684096575), (0, 0.0643330430611968), (8, 0.06517981924116611), (1, 0.06682917755097151), (39, 0.06685513630509377), (52, 0.07043937314301729), (10, 0.07141199242323637), (16, 0.08044354151934385), (12, 0.08532784692943096), (5, 0.10570745635777712), (36, 0.577760674059391), (18, 0.6742797046899796), (53, 1.7237053662538528)]
computing accuracy for after removing block 4 . block score: 0.04934364231303334
removed block 4 current accuracy 0.8884 loss from initial  0.06300000000000006
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 44, with score 0.050149. All blocks and scores: [(44, 0.0501485182903707), (14, 0.05054345354437828), (51, 0.05335480021312833), (2, 0.05480679078027606), (17, 0.05665545491501689), (42, 0.056702814530581236), (47, 0.05778382858261466), (3, 0.05810574209317565), (11, 0.058743637055158615), (8, 0.06312190927565098), (0, 0.0643330430611968), (13, 0.06628016009926796), (1, 0.06682917755097151), (6, 0.06705012917518616), (39, 0.06784422043710947), (10, 0.0703154793009162), (16, 0.07255655061453581), (52, 0.07295578625053167), (12, 0.08302377350628376), (5, 0.11008292436599731), (36, 0.5872025340795517), (18, 0.6754370704293251), (53, 1.6774513274431229)]
computing accuracy for after removing block 44 . block score: 0.0501485182903707
removed block 44 current accuracy 0.8522 loss from initial  0.09920000000000007
since last training loss: 0.0816 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 14, with score 0.050543. All blocks and scores: [(14, 0.05054345168173313), (51, 0.05275667319074273), (2, 0.05480678891763091), (17, 0.05665545491501689), (42, 0.05670281499624252), (3, 0.05810574069619179), (11, 0.058743635192513466), (47, 0.06229641102254391), (8, 0.0631219083443284), (0, 0.06433304212987423), (13, 0.06628016196191311), (1, 0.06682917661964893), (6, 0.06705012824386358), (39, 0.06784421857446432), (10, 0.07031547836959362), (16, 0.07255654968321323), (52, 0.07404123526066542), (12, 0.08302377164363861), (5, 0.11008292995393276), (36, 0.5872025117278099), (18, 0.6754370704293251), (53, 1.8805930465459824)]
computing accuracy for after removing block 14 . block score: 0.05054345168173313
removed block 14 current accuracy 0.7914 loss from initial  0.16000000000000003
since last training loss: 0.14239999999999997 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 51, with score 0.050511. All blocks and scores: [(51, 0.05051065282896161), (17, 0.05253493180498481), (2, 0.054806787986308336), (42, 0.055362924467772245), (3, 0.05810573976486921), (11, 0.058743635192513466), (47, 0.058879058342427015), (8, 0.0631219083443284), (0, 0.06433304119855165), (39, 0.06443849951028824), (13, 0.06628016289323568), (1, 0.06682917661964893), (6, 0.06705013010650873), (52, 0.06937531661242247), (10, 0.07031547836959362), (12, 0.08302377164363861), (16, 0.08849722985178232), (5, 0.11008292436599731), (36, 0.5698950439691544), (18, 0.6497291401028633), (53, 2.000149816274643)]
computing accuracy for after removing block 51 . block score: 0.05051065282896161
removed block 51 current accuracy 0.678 loss from initial  0.2734
since last training loss: 0.2557999999999999 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 17, with score 0.052535. All blocks and scores: [(17, 0.05253493133932352), (2, 0.0548067893832922), (42, 0.05536292400211096), (3, 0.05810573976486921), (11, 0.05874363612383604), (47, 0.058879056479781866), (8, 0.06312190880998969), (0, 0.06433304399251938), (39, 0.06443849578499794), (13, 0.06628016289323568), (1, 0.06682917755097151), (6, 0.06705012917518616), (10, 0.07031547836959362), (52, 0.07247414533048868), (12, 0.08302377071231604), (16, 0.08849722892045975), (5, 0.11008292715996504), (36, 0.5698950439691544), (18, 0.6497291177511215), (53, 2.0966504514217377)]
computing accuracy for after removing block 17 . block score: 0.05253493133932352
removed block 17 current accuracy 0.6418 loss from initial  0.3096
since last training loss: 0.2919999999999999 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 42, with score 0.051737. All blocks and scores: [(42, 0.051737332716584206), (2, 0.054806789848953485), (47, 0.057328501250594854), (3, 0.05810574255883694), (11, 0.05874363612383604), (8, 0.06312190601602197), (39, 0.06361533887684345), (0, 0.0643330430611968), (13, 0.06628016289323568), (1, 0.06682917661964893), (6, 0.0670501310378313), (52, 0.06950221583247185), (10, 0.07031547836959362), (12, 0.08302377071231604), (16, 0.08849722892045975), (5, 0.11008292622864246), (36, 0.5349723249673843), (18, 0.6233378872275352), (53, 2.094714939594269)]
computing accuracy for after removing block 42 . block score: 0.051737332716584206
removed block 42 current accuracy 0.564 loss from initial  0.3874000000000001
since last training loss: 0.3698 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 2, with score 0.054807. All blocks and scores: [(2, 0.0548067893832922), (3, 0.05810573976486921), (11, 0.058743635192513466), (47, 0.060537369921803474), (8, 0.06312190741300583), (39, 0.06361533980816603), (0, 0.06433304212987423), (13, 0.06628016289323568), (1, 0.06682917661964893), (6, 0.06705012917518616), (10, 0.07031547650694847), (52, 0.07804078329354525), (12, 0.08302377350628376), (16, 0.0884972270578146), (5, 0.11008293181657791), (36, 0.5349723175168037), (18, 0.623337909579277), (53, 1.9592719376087189)]
computing accuracy for after removing block 2 . block score: 0.0548067893832922
removed block 2 current accuracy 0.4818 loss from initial  0.4696
since last training loss: 0.45199999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 3, with score 0.053085. All blocks and scores: [(3, 0.05308536486700177), (11, 0.054992706049233675), (47, 0.05840207589790225), (39, 0.06034969678148627), (8, 0.0611112411133945), (6, 0.06414920557290316), (0, 0.0643330430611968), (13, 0.06474603340029716), (10, 0.06564334593713284), (1, 0.06682917568832636), (52, 0.06945563573390245), (12, 0.07499422505497932), (16, 0.0760688278824091), (5, 0.10688865557312965), (36, 0.4948226995766163), (18, 0.5756366550922394), (53, 2.0730605721473694)]
computing accuracy for after removing block 3 . block score: 0.05308536486700177
removed block 3 current accuracy 0.3672 loss from initial  0.5842
since last training loss: 0.5666 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.051882. All blocks and scores: [(11, 0.05188173521310091), (47, 0.056102996692061424), (8, 0.05667378567159176), (16, 0.05728138005360961), (39, 0.05745394481346011), (0, 0.06433304492384195), (52, 0.06536880787461996), (13, 0.06649360526353121), (10, 0.06652250234037638), (1, 0.06682917755097151), (6, 0.06714858580380678), (12, 0.07405258435755968), (5, 0.11063107382506132), (36, 0.4840567260980606), (18, 0.5395088568329811), (53, 2.223894417285919)]
computing accuracy for after removing block 11 . block score: 0.05188173521310091
removed block 11 current accuracy 0.3362 loss from initial  0.6152
training start
training epoch 0 val accuracy 0.82 topk_dict {'top1': 0.82} is_best True lr [0.1]
training epoch 1 val accuracy 0.86 topk_dict {'top1': 0.86} is_best True lr [0.1]
training epoch 2 val accuracy 0.8484 topk_dict {'top1': 0.8484} is_best False lr [0.1]
training epoch 3 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.1]
training epoch 4 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 5 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.1]
training epoch 6 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 7 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 8 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 9 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 10 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.928000)
finished training. finished 50 epochs. accuracy 0.928 topk_dict {'top1': 0.928}
