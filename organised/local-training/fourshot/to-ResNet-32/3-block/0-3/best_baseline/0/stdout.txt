start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589500389993), (30, 0.01001118787098676), (31, 0.01023258117493242), (34, 0.013294660719111562), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.019996492192149162), (46, 0.020590225234627724), (25, 0.022078295703977346), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749591084197164), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957707151770592), (22, 0.025151390582323074), (50, 0.025287173921242356), (24, 0.025880582397803664), (49, 0.02591664786450565), (42, 0.026232232339680195), (20, 0.02684889198280871), (47, 0.028632948640733957), (38, 0.03134434437379241), (39, 0.03144129505380988), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.06606104411184788), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.00939958926755935), (30, 0.010011187638156116), (31, 0.010232581058517098), (34, 0.013119243318215013), (29, 0.013421116978861392), (26, 0.016072140773758292), (35, 0.016093928134068847), (28, 0.017636860953643918), (27, 0.019022798631340265), (43, 0.01985268760472536), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.022078295703977346), (23, 0.022228716174140573), (44, 0.02297719265334308), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.024770821910351515), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02557574026286602), (24, 0.025880582397803664), (42, 0.025893412763252854), (20, 0.026848891749978065), (47, 0.028072760440409184), (38, 0.031091188779100776), (39, 0.03119136136956513), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.043376329354941845), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.057849929202347994), (13, 0.05914428550750017), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06493351561948657), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.00939958926755935
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118728891015), (31, 0.010232581524178386), (34, 0.012758881784975529), (29, 0.013421116978861392), (35, 0.01591842109337449), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850464537739754), (46, 0.020411916077136993), (41, 0.021827629068866372), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02289147861301899), (40, 0.023602578090503812), (45, 0.023770849453285336), (48, 0.02451987355016172), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.025712221395224333), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.02805250510573387), (38, 0.030935874208807945), (39, 0.031173035502433777), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632888928056), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527505863457918), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.435020312666893), (18, 0.5117433071136475), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.01001118728891015
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.013421116978861392), (35, 0.01591864973306656), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01986734988167882), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.023001376073807478), (40, 0.023739926517009735), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463106179609895), (21, 0.024941090028733015), (22, 0.025151389883831143), (49, 0.025246930541470647), (42, 0.02527355100028217), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027727574575692415), (38, 0.030746274860575795), (39, 0.03128179581835866), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06356756249442697), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4377693198621273), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116513200104), (35, 0.015968912048265338), (26, 0.016072141006588936), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01983700878918171), (46, 0.020137188024818897), (41, 0.021584056317806244), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.02410835842601955), (50, 0.024114209692925215), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.027423853054642677), (38, 0.03073564893566072), (39, 0.031410424038767815), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.039083510637283325), (51, 0.04034593841060996), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525485008955), (52, 0.06270107859745622), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143233776093), (36, 0.43692685663700104), (18, 0.5117432996630669), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141705080867), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197597801685), (41, 0.021962702739983797), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.023045077454298735), (48, 0.02402454731054604), (50, 0.024096972541883588), (40, 0.02415681630373001), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.02494108909741044), (22, 0.025151389883831143), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.02684889268130064), (47, 0.027568295132368803), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.03225791407749057), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.062210948672145605), (0, 0.06337464554235339), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.44933701679110527), (18, 0.5117432996630669), (53, 0.8277030438184738)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.01637051091529429), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01985670323483646), (46, 0.019988975953310728), (41, 0.021256205393001437), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032856866717), (48, 0.023521371418610215), (50, 0.02353389118798077), (40, 0.023616240359842777), (45, 0.02393329283222556), (49, 0.02444991492666304), (42, 0.0248383276630193), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880582397803664), (47, 0.02681345585733652), (20, 0.026848891284316778), (38, 0.031083731446415186), (39, 0.032056888565421104), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.039079750422388315), (37, 0.0401521441526711), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003502443433), (52, 0.06036907387897372), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4432784356176853), (18, 0.5117432996630669), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.01698602200485766), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700075965374708), (41, 0.02051579928956926), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.022507572313770652), (48, 0.022899368777871132), (50, 0.022937727626413107), (40, 0.02305740211158991), (42, 0.023520407965406775), (45, 0.023633700096979737), (49, 0.024081918643787503), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.02632279135286808), (20, 0.026848892215639353), (38, 0.030149149941280484), (39, 0.03146669710986316), (15, 0.03205838706344366), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.03926890389993787), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849925477057695), (52, 0.05846811691299081), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43490003794431686), (18, 0.5117432996630669), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.018769709393382072), (46, 0.01884230156429112), (41, 0.019016370410099626), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.021748854545876384), (40, 0.02191696665249765), (42, 0.021930374205112457), (25, 0.022078295005485415), (23, 0.02222871547564864), (45, 0.022736449260264635), (49, 0.022970063146203756), (21, 0.024941089563071728), (22, 0.025151390582323074), (47, 0.025355831487104297), (24, 0.025880581932142377), (20, 0.026848891051486135), (38, 0.028691887157037854), (39, 0.029624431394040585), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03601635713130236), (37, 0.03643036773428321), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577406495809555), (52, 0.05466857831925154), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.41641608253121376), (18, 0.5117432698607445), (53, 0.8948249071836472)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.1]
training epoch 1 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.1]
training epoch 2 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.1]
training epoch 3 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.1]
training epoch 4 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.1]
training epoch 5 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.1]
training epoch 6 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.1]
training epoch 7 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.1]
training epoch 8 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.1]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.016248. All blocks and scores: [(38, 0.016248041531071067), (37, 0.020612466847524047), (43, 0.02100509195588529), (46, 0.021108548156917095), (23, 0.022361069219186902), (25, 0.022448454052209854), (41, 0.023330261232331395), (44, 0.02415209449827671), (45, 0.02465829229913652), (21, 0.024881974328309298), (50, 0.025233949534595013), (22, 0.02526614163070917), (48, 0.025382681051269174), (40, 0.02540044323541224), (49, 0.02602068637497723), (24, 0.02612148062326014), (42, 0.02695310115814209), (20, 0.02713186712935567), (47, 0.028892497532069683), (27, 0.029104566434398293), (15, 0.032338885590434074), (19, 0.03253245772793889), (7, 0.032627775333821774), (39, 0.034756521694362164), (51, 0.04177977750077844), (9, 0.04370204685255885), (4, 0.04521293472498655), (6, 0.04658277099952102), (14, 0.04827053705230355), (2, 0.05425508692860603), (3, 0.05760415876284242), (11, 0.05998395383358002), (13, 0.06039723288267851), (17, 0.06300924206152558), (0, 0.0637519396841526), (52, 0.0668481532484293), (1, 0.06724126916378736), (8, 0.07560834009200335), (10, 0.08205921668559313), (16, 0.0873165875673294), (12, 0.0914175109937787), (5, 0.10706511791795492), (36, 0.37852171435952187), (18, 0.5169481784105301), (53, 0.7823510393500328)]
computing accuracy for after removing block 38 . block score: 0.016248041531071067
removed block 38 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 43, with score 0.019542. All blocks and scores: [(43, 0.019541672198101878), (46, 0.020171445328742266), (37, 0.020612467313185334), (41, 0.021687787491828203), (23, 0.022361068753525615), (25, 0.02244845381937921), (45, 0.023231448838487267), (48, 0.023281666450202465), (50, 0.023385199485346675), (44, 0.023718832060694695), (40, 0.02461388660594821), (49, 0.024875489762052894), (21, 0.024881974793970585), (22, 0.025266141165047884), (42, 0.025702328886836767), (24, 0.02612148132175207), (47, 0.026792342541739345), (20, 0.027131866896525025), (27, 0.02910456690005958), (15, 0.03233888605609536), (19, 0.032532458659261465), (7, 0.032627774868160486), (39, 0.03552565583959222), (51, 0.040937707759439945), (9, 0.04370204685255885), (4, 0.04521293239668012), (6, 0.04658277099952102), (14, 0.048270536586642265), (2, 0.05425508692860603), (3, 0.05760415783151984), (11, 0.05998395476490259), (13, 0.060397231951355934), (17, 0.0630092415958643), (0, 0.0637519396841526), (52, 0.06404993124306202), (1, 0.06724127009510994), (8, 0.07560833916068077), (10, 0.08205921296030283), (16, 0.08731658570468426), (12, 0.09141751006245613), (5, 0.10706512071192265), (36, 0.37852171063423157), (18, 0.5169481709599495), (53, 0.8027714192867279)]
computing accuracy for after removing block 43 . block score: 0.019541672198101878
removed block 43 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 37, with score 0.020612. All blocks and scores: [(37, 0.020612465916201472), (46, 0.020968811819329858), (41, 0.021687787724658847), (23, 0.02236106852069497), (25, 0.02244845498353243), (50, 0.023539888905361295), (48, 0.024265433894470334), (45, 0.02440940565429628), (40, 0.02461388660594821), (49, 0.02482536039315164), (21, 0.024881974328309298), (22, 0.025266141863539815), (44, 0.025369177805259824), (42, 0.025702328886836767), (24, 0.026121480856090784), (20, 0.02713186596520245), (47, 0.02770277624949813), (27, 0.029104566667228937), (15, 0.03233888605609536), (19, 0.032532458659261465), (7, 0.032627775333821774), (39, 0.03552565677091479), (51, 0.040478586219251156), (9, 0.043702046386897564), (4, 0.04521293379366398), (6, 0.04658277239650488), (14, 0.04827053751796484), (2, 0.05425508599728346), (3, 0.05760415876284242), (11, 0.059983954299241304), (13, 0.06039723474532366), (17, 0.06300924206152558), (52, 0.0632594246417284), (0, 0.06375193782150745), (1, 0.06724127195775509), (8, 0.07560833916068077), (10, 0.08205921668559313), (16, 0.08731658663600683), (12, 0.0914175109937787), (5, 0.10706511978060007), (36, 0.37852170318365097), (18, 0.5169481560587883), (53, 0.8490462377667427)]
computing accuracy for after removing block 37 . block score: 0.020612465916201472
removed block 37 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.019288. All blocks and scores: [(46, 0.019288152921944857), (41, 0.019881864544004202), (50, 0.020707492250949144), (48, 0.02155607845634222), (49, 0.02215874195098877), (45, 0.022231269627809525), (23, 0.022361068753525615), (25, 0.022448454052209854), (44, 0.022891997126862407), (40, 0.023369976552203298), (42, 0.024588960222899914), (47, 0.024877394549548626), (21, 0.02488197386264801), (22, 0.025266141165047884), (24, 0.02612148132175207), (20, 0.027131866896525025), (27, 0.029104567132890224), (15, 0.03233888605609536), (19, 0.032532458659261465), (7, 0.0326277744024992), (39, 0.03553021885454655), (51, 0.03696241183206439), (9, 0.043702046386897564), (4, 0.04521293332800269), (6, 0.046582771465182304), (14, 0.04827053612098098), (2, 0.054255086462944746), (52, 0.054704285226762295), (3, 0.05760415876284242), (11, 0.05998395383358002), (13, 0.06039723241701722), (17, 0.06300924299284816), (0, 0.0637519396841526), (1, 0.06724127288907766), (8, 0.07560833916068077), (10, 0.0820592176169157), (16, 0.0873165875673294), (12, 0.0914175109937787), (5, 0.10706512071192265), (36, 0.37852169945836067), (18, 0.5169481709599495), (53, 0.8875134363770485)]
computing accuracy for after removing block 46 . block score: 0.019288152921944857
removed block 46 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.019882. All blocks and scores: [(41, 0.019881864311173558), (50, 0.02122544893063605), (48, 0.02221227833069861), (45, 0.022231269860640168), (23, 0.022361069219186902), (25, 0.022448454285040498), (49, 0.02284378418698907), (44, 0.022891996894031763), (40, 0.023369976319372654), (42, 0.024588960222899914), (21, 0.024881974793970585), (22, 0.025266142562031746), (24, 0.026121480856090784), (47, 0.026928289094939828), (20, 0.027131866198033094), (27, 0.02910456690005958), (15, 0.032338886987417936), (19, 0.03253245819360018), (7, 0.0326277744024992), (39, 0.03553021978586912), (51, 0.0372764403000474), (9, 0.0437020449899137), (4, 0.04521293193101883), (6, 0.04658277053385973), (14, 0.04827053612098098), (2, 0.05425508692860603), (52, 0.055069536436349154), (3, 0.05760415783151984), (11, 0.05998395523056388), (13, 0.06039723614230752), (17, 0.06300924252718687), (0, 0.0637519396841526), (1, 0.06724127009510994), (8, 0.07560833916068077), (10, 0.08205921668559313), (16, 0.08731658384203911), (12, 0.09141750726848841), (5, 0.10706511791795492), (36, 0.37852171063423157), (18, 0.5169481784105301), (53, 0.9868793934583664)]
computing accuracy for after removing block 41 . block score: 0.019881864311173558
removed block 41 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021056. All blocks and scores: [(50, 0.021055639488622546), (48, 0.02151444833725691), (45, 0.02223757724277675), (23, 0.022361068753525615), (49, 0.0224009626545012), (25, 0.022448453353717923), (40, 0.02336997678503394), (44, 0.024151941295713186), (42, 0.02462333394214511), (21, 0.024881974095478654), (22, 0.025266142329201102), (24, 0.02612148132175207), (47, 0.027094796998426318), (20, 0.02713186712935567), (27, 0.02910456620156765), (15, 0.032338886987417936), (19, 0.03253245772793889), (7, 0.03262777393683791), (39, 0.035530219320207834), (51, 0.03563315002247691), (9, 0.04370204592123628), (4, 0.045212932862341404), (6, 0.04658277099952102), (14, 0.04827053705230355), (52, 0.05300975311547518), (2, 0.05425508785992861), (3, 0.05760415829718113), (11, 0.05998395336791873), (13, 0.06039723427966237), (17, 0.06300924299284816), (0, 0.0637519396841526), (1, 0.06724126916378736), (8, 0.0756083382293582), (10, 0.0820592176169157), (16, 0.08731658477336168), (12, 0.09141751192510128), (5, 0.10706512164324522), (36, 0.37852171063423157), (18, 0.5169481709599495), (53, 1.0678942799568176)]
computing accuracy for after removing block 50 . block score: 0.021055639488622546
removed block 50 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.021514. All blocks and scores: [(48, 0.02151444833725691), (45, 0.022237577475607395), (23, 0.02236106898635626), (49, 0.0224009626545012), (25, 0.022448453586548567), (40, 0.023369977017864585), (44, 0.024151941994205117), (42, 0.024623333476483822), (21, 0.024881974328309298), (22, 0.025266141397878528), (24, 0.026121481088921428), (47, 0.02709479769691825), (20, 0.027131866430863738), (27, 0.029104566667228937), (15, 0.032338886987417936), (19, 0.032532458659261465), (7, 0.03262777393683791), (39, 0.035530219320207834), (51, 0.038075074553489685), (9, 0.0437020449899137), (4, 0.04521293332800269), (6, 0.04658277053385973), (14, 0.048270536586642265), (2, 0.05425508739426732), (3, 0.05760415829718113), (52, 0.05837230896577239), (11, 0.059983954299241304), (13, 0.060397235210984945), (17, 0.06300924392417073), (0, 0.06375193689018488), (1, 0.06724127195775509), (8, 0.07560834102332592), (10, 0.08205921575427055), (16, 0.08731658570468426), (12, 0.09141750726848841), (5, 0.1070651188492775), (36, 0.37852170690894127), (18, 0.5169481560587883), (53, 1.2681139558553696)]
computing accuracy for after removing block 48 . block score: 0.02151444833725691
removed block 48 current accuracy 0.91 loss from initial  0.04139999999999999
since last training loss: 0.03479999999999994 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.022238. All blocks and scores: [(45, 0.022237577475607395), (23, 0.02236106968484819), (25, 0.022448453586548567), (40, 0.02336997725069523), (44, 0.024151941994205117), (42, 0.02462333394214511), (21, 0.02488197456113994), (22, 0.025266141165047884), (49, 0.02528524911031127), (24, 0.026121481088921428), (47, 0.027094796998426318), (20, 0.02713186666369438), (27, 0.029104566667228937), (15, 0.032338885590434074), (19, 0.03253245819360018), (7, 0.03262777393683791), (39, 0.03553022025153041), (51, 0.03834361908957362), (9, 0.04370204592123628), (4, 0.04521293193101883), (6, 0.046582769602537155), (14, 0.04827053751796484), (2, 0.054255086462944746), (3, 0.05760415876284242), (11, 0.05998395523056388), (13, 0.06039723567664623), (17, 0.06300924206152558), (0, 0.0637519396841526), (52, 0.06522786244750023), (1, 0.06724127009510994), (8, 0.07560834009200335), (10, 0.08205921482294798), (16, 0.08731658570468426), (12, 0.0914175109937787), (5, 0.10706512071192265), (36, 0.37852169945836067), (18, 0.5169481709599495), (53, 1.3908737003803253)]
computing accuracy for after removing block 45 . block score: 0.022237577475607395
removed block 45 current accuracy 0.8916 loss from initial  0.059800000000000075
since last training loss: 0.053200000000000025 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.022361. All blocks and scores: [(23, 0.02236106968484819), (25, 0.022448454285040498), (40, 0.02336997678503394), (44, 0.024151941994205117), (42, 0.024623334873467684), (21, 0.02488197386264801), (22, 0.025266141863539815), (49, 0.025538258953019977), (24, 0.026121481554582715), (20, 0.027131867595016956), (47, 0.02844226872548461), (27, 0.029104567132890224), (15, 0.03233888652175665), (19, 0.03253245772793889), (7, 0.0326277744024992), (39, 0.035530219320207834), (51, 0.03766657505184412), (9, 0.04370204731822014), (4, 0.04521293193101883), (6, 0.04658277053385973), (14, 0.04827053705230355), (2, 0.05425508785992861), (3, 0.057604159228503704), (11, 0.059983954299241304), (13, 0.06039723427966237), (52, 0.06231280555948615), (17, 0.06300924113020301), (0, 0.06375194061547518), (1, 0.06724127009510994), (8, 0.07560833916068077), (10, 0.08205921575427055), (16, 0.08731658291071653), (12, 0.09141751192510128), (5, 0.1070651188492775), (36, 0.37852170318365097), (18, 0.5169481635093689), (53, 1.5550346821546555)]
computing accuracy for after removing block 23 . block score: 0.02236106968484819
removed block 23 current accuracy 0.8876 loss from initial  0.06380000000000008
training start
training epoch 0 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.1]
training epoch 1 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.1]
training epoch 2 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.1]
training epoch 3 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.1]
training epoch 4 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 5 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.1]
training epoch 6 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.1]
training epoch 7 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 8 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.1]
training epoch 9 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.024874. All blocks and scores: [(21, 0.024873928865417838), (22, 0.025254396721720695), (20, 0.026969044469296932), (15, 0.03216414572671056), (19, 0.03260062914341688), (49, 0.03263255627825856), (7, 0.03263542940840125), (44, 0.03322203038260341), (42, 0.03610488027334213), (47, 0.03644377272576094), (51, 0.037839782889932394), (25, 0.040215916465967894), (40, 0.04114924417808652), (24, 0.04144836775958538), (9, 0.044053229968994856), (27, 0.04422046709805727), (6, 0.04706363379955292), (4, 0.047912550158798695), (14, 0.04805536940693855), (52, 0.051117056515067816), (2, 0.05487637501209974), (3, 0.05849386053159833), (13, 0.059524332638829947), (39, 0.059662225656211376), (11, 0.06013094587251544), (17, 0.06242627743631601), (0, 0.06433632131665945), (1, 0.06697749998420477), (8, 0.0743649723008275), (10, 0.0814313692972064), (16, 0.08491709921509027), (12, 0.090765037573874), (5, 0.10654605645686388), (36, 0.3786209300160408), (18, 0.5151597410440445), (53, 1.4761437773704529)]
computing accuracy for after removing block 21 . block score: 0.024873928865417838
removed block 21 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023505. All blocks and scores: [(22, 0.02350481483153999), (20, 0.026969044702127576), (44, 0.030946430517360568), (49, 0.03131821961142123), (15, 0.03216414665803313), (19, 0.03260062914341688), (7, 0.03263542940840125), (42, 0.03291379660367966), (47, 0.03414572402834892), (51, 0.0363754159770906), (40, 0.03754417970776558), (24, 0.03760844701901078), (25, 0.03768060449510813), (27, 0.042106982320547104), (9, 0.04405322903767228), (52, 0.045219902880489826), (6, 0.04706363193690777), (4, 0.04791255062445998), (14, 0.048055370803922415), (2, 0.05487637780606747), (39, 0.056251862552016973), (3, 0.05849386053159833), (13, 0.05952433403581381), (11, 0.0601309472694993), (17, 0.062426276970654726), (0, 0.0643363194540143), (1, 0.06697750091552734), (8, 0.07436496950685978), (10, 0.0814313692972064), (16, 0.08491709642112255), (12, 0.0907650412991643), (5, 0.10654605645686388), (36, 0.3559446223080158), (18, 0.5151597782969475), (53, 1.507117435336113)]
computing accuracy for after removing block 22 . block score: 0.02350481483153999
removed block 22 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.026969. All blocks and scores: [(20, 0.026969044469296932), (44, 0.029202896170318127), (49, 0.030042898142710328), (42, 0.03125704568810761), (15, 0.03216414479538798), (47, 0.032215503975749016), (19, 0.032600628677755594), (7, 0.032635428477078676), (24, 0.03423578990623355), (51, 0.034963253419846296), (25, 0.03518803184852004), (40, 0.036197447683662176), (27, 0.04062352096661925), (52, 0.0409739282913506), (9, 0.04405322950333357), (6, 0.047063634265214205), (4, 0.04791255155578256), (14, 0.04805536940693855), (39, 0.05462686065584421), (2, 0.05487637687474489), (3, 0.05849386192858219), (13, 0.05952433403581381), (11, 0.06013094540685415), (17, 0.062426276970654726), (0, 0.06433632038533688), (1, 0.06697750184684992), (8, 0.07436497043818235), (10, 0.08143136743456125), (16, 0.08491709735244513), (12, 0.09076503943651915), (5, 0.10654605366289616), (36, 0.34656158462166786), (18, 0.5151597633957863), (53, 1.5002464950084686)]
computing accuracy for after removing block 20 . block score: 0.026969044469296932
removed block 20 current accuracy 0.9176 loss from initial  0.03380000000000005
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.028362. All blocks and scores: [(44, 0.028362234588712454), (49, 0.0294644795358181), (42, 0.02953963284380734), (47, 0.03022882854565978), (15, 0.03216414712369442), (19, 0.032600630074739456), (7, 0.03263542940840125), (24, 0.032743350602686405), (51, 0.03383854357525706), (25, 0.03433059994131327), (40, 0.03612422617152333), (52, 0.03796657919883728), (27, 0.03976060962304473), (9, 0.04405323043465614), (6, 0.04706363519653678), (4, 0.04791255062445998), (14, 0.048055368941277266), (39, 0.05292157316580415), (2, 0.05487637687474489), (3, 0.058493861462920904), (13, 0.059524331241846085), (11, 0.060130943078547716), (17, 0.062426278833299875), (0, 0.06433632038533688), (1, 0.06697750184684992), (8, 0.07436497043818235), (10, 0.0814313692972064), (16, 0.0849170982837677), (12, 0.09076504036784172), (5, 0.10654605459421873), (36, 0.3459502346813679), (18, 0.5151597484946251), (53, 1.4666857570409775)]
computing accuracy for after removing block 44 . block score: 0.028362234588712454
removed block 44 current accuracy 0.9082 loss from initial  0.043200000000000016
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 42, with score 0.029540. All blocks and scores: [(42, 0.029539631213992834), (49, 0.031058539636433125), (15, 0.03216414572671056), (19, 0.032600628677755594), (7, 0.03263542940840125), (24, 0.03274335153400898), (47, 0.03328055003657937), (51, 0.03379923291504383), (25, 0.03433060087263584), (40, 0.03612422524020076), (52, 0.03705621184781194), (27, 0.03976060822606087), (9, 0.04405322950333357), (6, 0.047063634265214205), (4, 0.04791255109012127), (14, 0.04805536940693855), (39, 0.05292157316580415), (2, 0.05487637687474489), (3, 0.058493861462920904), (13, 0.05952433496713638), (11, 0.06013094540685415), (17, 0.06242627743631601), (0, 0.06433632224798203), (1, 0.0669774990528822), (8, 0.07436497136950493), (10, 0.08143137022852898), (16, 0.08491709642112255), (12, 0.09076503850519657), (5, 0.10654605459421873), (36, 0.34595024958252907), (18, 0.5151597484946251), (53, 1.7437292784452438)]
computing accuracy for after removing block 42 . block score: 0.029539631213992834
removed block 42 current accuracy 0.8876 loss from initial  0.06380000000000008
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.032164. All blocks and scores: [(15, 0.03216414712369442), (19, 0.03260062914341688), (7, 0.032635428942739964), (24, 0.03274334967136383), (49, 0.03361266432330012), (51, 0.034322033170610666), (25, 0.03433059994131327), (40, 0.03612422524020076), (47, 0.03620236134156585), (52, 0.03929419443011284), (27, 0.03976060915738344), (9, 0.04405322950333357), (6, 0.04706363379955292), (4, 0.04791255155578256), (14, 0.04805537033826113), (39, 0.05292157316580415), (2, 0.054876376409083605), (3, 0.05849385913461447), (13, 0.05952433496713638), (11, 0.060130943544209), (17, 0.062426276970654726), (0, 0.06433632131665945), (1, 0.06697749998420477), (8, 0.07436497043818235), (10, 0.08143137115985155), (16, 0.08491709642112255), (12, 0.09076503943651915), (5, 0.10654605366289616), (36, 0.3459502384066582), (18, 0.5151597782969475), (53, 1.9432644695043564)]
computing accuracy for after removing block 15 . block score: 0.03216414712369442
removed block 15 current accuracy 0.8686 loss from initial  0.08279999999999998
since last training loss: 0.07539999999999991 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.031683. All blocks and scores: [(24, 0.031682769767940044), (7, 0.032635428477078676), (19, 0.03281833278015256), (25, 0.032841392792761326), (49, 0.03411492146551609), (51, 0.034857204649597406), (40, 0.035634311847388744), (47, 0.03693767497316003), (27, 0.03845319431275129), (52, 0.03972456185147166), (9, 0.04405322950333357), (6, 0.04706363473087549), (4, 0.047912550158798695), (14, 0.04805536987259984), (39, 0.05336333531886339), (2, 0.05487637780606747), (3, 0.05849386053159833), (13, 0.059524332638829947), (11, 0.06013094540685415), (0, 0.06433632038533688), (17, 0.06628170888870955), (1, 0.06697749812155962), (8, 0.07436496950685978), (10, 0.0814313692972064), (12, 0.09076503943651915), (16, 0.09471569117158651), (5, 0.10654605459421873), (36, 0.34603151679039), (18, 0.5026109106838703), (53, 1.9503542631864548)]
computing accuracy for after removing block 24 . block score: 0.031682769767940044
removed block 24 current accuracy 0.844 loss from initial  0.10740000000000005
since last training loss: 0.09999999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032635. All blocks and scores: [(7, 0.032635428942739964), (19, 0.03281833045184612), (25, 0.032971073873341084), (49, 0.03376392321661115), (51, 0.03431869903579354), (40, 0.03531190846115351), (47, 0.03680293774232268), (52, 0.038055043667554855), (27, 0.03886715183034539), (9, 0.04405323136597872), (6, 0.04706363379955292), (4, 0.047912552021443844), (14, 0.04805536800995469), (2, 0.054876376409083605), (39, 0.05525156296789646), (3, 0.058493861462920904), (13, 0.05952433543279767), (11, 0.06013094540685415), (0, 0.06433632131665945), (17, 0.06628171168267727), (1, 0.0669774990528822), (8, 0.0743649685755372), (10, 0.08143137022852898), (12, 0.09076504036784172), (16, 0.09471569117158651), (5, 0.10654605273157358), (36, 0.35518156737089157), (18, 0.5026109404861927), (53, 1.9778753519058228)]
computing accuracy for after removing block 7 . block score: 0.032635428942739964
removed block 7 current accuracy 0.8224 loss from initial  0.129
since last training loss: 0.12159999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 25, with score 0.031423. All blocks and scores: [(25, 0.03142344322986901), (19, 0.03256852040067315), (40, 0.033550397492945194), (51, 0.033615633845329285), (49, 0.03365045879036188), (47, 0.0350768300704658), (52, 0.03586610732600093), (27, 0.03739361884072423), (9, 0.04399467632174492), (14, 0.04439974203705788), (6, 0.04706363379955292), (4, 0.04791255155578256), (13, 0.05150980595499277), (39, 0.053823160007596016), (2, 0.05487637873739004), (17, 0.05608518421649933), (11, 0.05677587818354368), (3, 0.05849386053159833), (0, 0.06433632131665945), (1, 0.06697750091552734), (8, 0.0725349085405469), (10, 0.08378004655241966), (12, 0.08471845462918282), (16, 0.08628569263964891), (5, 0.10654605273157358), (36, 0.3387799970805645), (18, 0.48582490533590317), (53, 2.0395817160606384)]
computing accuracy for after removing block 25 . block score: 0.03142344322986901
removed block 25 current accuracy 0.8004 loss from initial  0.15100000000000002
training start
training epoch 0 val accuracy 0.839 topk_dict {'top1': 0.839} is_best True lr [0.1]
training epoch 1 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best True lr [0.1]
training epoch 2 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.1]
training epoch 3 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 6 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 7 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.1]
training epoch 8 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.1]
training epoch 9 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.937200)
finished training. finished 50 epochs. accuracy 0.9372 topk_dict {'top1': 0.9372}
start iteration 27
[activation diff]: block to remove picked: 19, with score 0.032138. All blocks and scores: [(19, 0.03213784284889698), (9, 0.03394994372501969), (51, 0.034095464274287224), (49, 0.03832813911139965), (40, 0.03867328306660056), (17, 0.0451969001442194), (6, 0.04648513672873378), (14, 0.046857384499162436), (4, 0.04704837407916784), (47, 0.050779630430042744), (52, 0.05335001088678837), (2, 0.054583761375397444), (10, 0.05710747418925166), (3, 0.05788909690454602), (11, 0.059621878899633884), (13, 0.06153125083073974), (8, 0.06167993554845452), (16, 0.06295519880950451), (0, 0.0634902841411531), (1, 0.06571311689913273), (39, 0.0661028977483511), (27, 0.07089819945394993), (12, 0.09066486824303865), (5, 0.10617206059396267), (18, 0.2879161611199379), (36, 0.3654332309961319), (53, 1.5004434883594513)]
computing accuracy for after removing block 19 . block score: 0.03213784284889698
removed block 19 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 9, with score 0.033950. All blocks and scores: [(9, 0.03394994419068098), (51, 0.03481210442259908), (49, 0.03851580247282982), (40, 0.038891063537448645), (17, 0.0451969001442194), (6, 0.046485137194395065), (14, 0.04685738403350115), (4, 0.04704837314784527), (47, 0.04906371282413602), (52, 0.05007805582135916), (2, 0.05458376044407487), (10, 0.05710747605189681), (3, 0.05788909737020731), (11, 0.05962187796831131), (13, 0.06153124896809459), (8, 0.06167993461713195), (16, 0.0629551992751658), (0, 0.06349028507247567), (1, 0.06571311317384243), (39, 0.06705012265592813), (27, 0.06927504483610392), (12, 0.09066486917436123), (5, 0.1061720559373498), (18, 0.2879161648452282), (36, 0.36806561052799225), (53, 1.4245353192090988)]
computing accuracy for after removing block 9 . block score: 0.03394994419068098
removed block 9 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.033771. All blocks and scores: [(51, 0.03377124201506376), (49, 0.03694489551708102), (40, 0.037542194593697786), (17, 0.04336094809696078), (14, 0.04529438400641084), (6, 0.04648513440042734), (4, 0.04704837268218398), (47, 0.0477964011952281), (52, 0.04842375125735998), (2, 0.054583760909736156), (16, 0.05731934914365411), (3, 0.05788909504190087), (11, 0.060308308340609074), (13, 0.06089108623564243), (8, 0.06167993601411581), (0, 0.0634902841411531), (10, 0.06450334656983614), (1, 0.06571311596781015), (39, 0.065733402967453), (27, 0.07021527085453272), (12, 0.087324901483953), (5, 0.10617206059396267), (18, 0.28556814789772034), (36, 0.35851938650012016), (53, 1.4164404273033142)]
computing accuracy for after removing block 51 . block score: 0.03377124201506376
removed block 51 current accuracy 0.8788 loss from initial  0.0726
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.036945. All blocks and scores: [(49, 0.036944895051419735), (40, 0.03754219552502036), (17, 0.04336094716563821), (14, 0.04529438400641084), (6, 0.046485137194395065), (4, 0.047048371750861406), (47, 0.04779639979824424), (52, 0.053550389129668474), (2, 0.054583760909736156), (16, 0.05731935007497668), (3, 0.05788909597322345), (11, 0.060308309737592936), (13, 0.06089108483865857), (8, 0.06167993461713195), (0, 0.06349028320983052), (10, 0.06450334470719099), (1, 0.065713114105165), (39, 0.06573340389877558), (27, 0.07021526992321014), (12, 0.08732489962130785), (5, 0.10617206059396267), (18, 0.28556814417243004), (36, 0.35851939395070076), (53, 1.5041924118995667)]
computing accuracy for after removing block 49 . block score: 0.036944895051419735
removed block 49 current accuracy 0.8188 loss from initial  0.13260000000000005
since last training loss: 0.11840000000000006 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.037542. All blocks and scores: [(40, 0.03754219552502036), (17, 0.04336094856262207), (14, 0.04529438400641084), (6, 0.04648513626307249), (4, 0.04704837407916784), (47, 0.04779640166088939), (2, 0.054583759512752295), (16, 0.05731935007497668), (3, 0.057889096438884735), (52, 0.059766557067632675), (11, 0.060308309737592936), (13, 0.06089108297601342), (8, 0.061679935082793236), (0, 0.0634902841411531), (10, 0.06450334750115871), (1, 0.065713114105165), (39, 0.065733402967453), (27, 0.07021527085453272), (12, 0.08732490055263042), (5, 0.1061720596626401), (18, 0.28556814044713974), (36, 0.35851939022541046), (53, 1.5034186244010925)]
computing accuracy for after removing block 40 . block score: 0.03754219552502036
removed block 40 current accuracy 0.7444 loss from initial  0.20700000000000007
since last training loss: 0.19280000000000008 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 17, with score 0.043361. All blocks and scores: [(17, 0.04336094995960593), (14, 0.04529438354074955), (6, 0.04648513486608863), (4, 0.04704837314784527), (47, 0.05107775283977389), (2, 0.054583760909736156), (16, 0.05731934821233153), (3, 0.05788909690454602), (11, 0.06030830880627036), (13, 0.06089108530431986), (8, 0.06167993415147066), (0, 0.0634902841411531), (52, 0.06402282556518912), (10, 0.06450334470719099), (1, 0.06571311596781015), (39, 0.06573340483009815), (27, 0.07021527271717787), (12, 0.087324901483953), (5, 0.1061720596626401), (18, 0.28556815534830093), (36, 0.35851938650012016), (53, 1.4689120799303055)]
computing accuracy for after removing block 17 . block score: 0.04336094995960593
removed block 17 current accuracy 0.7176 loss from initial  0.2338
since last training loss: 0.21960000000000002 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 14, with score 0.045294. All blocks and scores: [(14, 0.04529438493773341), (6, 0.04648513626307249), (4, 0.047048373613506556), (47, 0.05031888606026769), (2, 0.05458376184105873), (16, 0.057319349609315395), (3, 0.05788909550756216), (11, 0.06030831020325422), (13, 0.06089108483865857), (8, 0.06167993461713195), (52, 0.06197115872055292), (39, 0.06283033359795809), (0, 0.06349028320983052), (10, 0.06450334377586842), (1, 0.065713114105165), (27, 0.0662182504311204), (12, 0.08732490334659815), (5, 0.10617205873131752), (18, 0.2703882046043873), (36, 0.34256042912602425), (53, 1.5068246722221375)]
computing accuracy for after removing block 14 . block score: 0.04529438493773341
removed block 14 current accuracy 0.6368 loss from initial  0.3146
since last training loss: 0.3004 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 6, with score 0.046485. All blocks and scores: [(6, 0.04648513626307249), (4, 0.04704837314784527), (47, 0.0502646341919899), (2, 0.054583761375397444), (3, 0.057889094576239586), (52, 0.059616978745907545), (11, 0.06030831066891551), (13, 0.060891083907336), (8, 0.06167993415147066), (39, 0.06186060421168804), (27, 0.06291978107765317), (0, 0.06349028227850795), (10, 0.06450334656983614), (1, 0.06571311689913273), (16, 0.07638501655310392), (12, 0.087324901483953), (5, 0.10617205873131752), (18, 0.2630605436861515), (36, 0.33731578290462494), (53, 1.5071558058261871)]
computing accuracy for after removing block 6 . block score: 0.04648513626307249
removed block 6 current accuracy 0.5454 loss from initial  0.406
since last training loss: 0.39180000000000004 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 4, with score 0.047048. All blocks and scores: [(4, 0.047048372216522694), (47, 0.04839356802403927), (11, 0.05418093502521515), (2, 0.05458376184105873), (52, 0.05498182913288474), (13, 0.057287093717604876), (27, 0.05787351680919528), (3, 0.05788909690454602), (8, 0.0585550032556057), (39, 0.05894138105213642), (16, 0.05969893839210272), (0, 0.06349028367549181), (1, 0.065713114105165), (10, 0.06794979888945818), (12, 0.07909791637212038), (5, 0.10617206059396267), (18, 0.24793230183422565), (36, 0.3291783481836319), (53, 1.551099419593811)]
computing accuracy for after removing block 4 . block score: 0.047048372216522694
removed block 4 current accuracy 0.479 loss from initial  0.47240000000000004
since last training loss: 0.45820000000000005 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 47, with score 0.047498. All blocks and scores: [(47, 0.047497608698904514), (11, 0.05036281934008002), (16, 0.051976839546114206), (2, 0.054583761375397444), (52, 0.05750894546508789), (13, 0.057708618231117725), (3, 0.057889096438884735), (27, 0.05842791823670268), (39, 0.05894870776683092), (8, 0.05978527944535017), (0, 0.06349028646945953), (1, 0.06571311317384243), (10, 0.06786416284739971), (12, 0.07789801992475986), (5, 0.11054466478526592), (18, 0.25557107850909233), (36, 0.33494266867637634), (53, 1.5081920474767685)]
computing accuracy for after removing block 47 . block score: 0.047497608698904514
removed block 47 current accuracy 0.402 loss from initial  0.5494
since last training loss: 0.5352 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.050363. All blocks and scores: [(11, 0.05036281840875745), (16, 0.05197683861479163), (2, 0.054583759512752295), (13, 0.05770861869677901), (3, 0.057889096438884735), (27, 0.05842791777104139), (39, 0.05894870590418577), (8, 0.05978528084233403), (0, 0.06349028600379825), (52, 0.06437157467007637), (1, 0.06571311503648758), (10, 0.06786416005343199), (12, 0.07789801992475986), (5, 0.11054466478526592), (18, 0.25557107105851173), (36, 0.33494265750050545), (53, 1.3953819572925568)]
computing accuracy for after removing block 11 . block score: 0.05036281840875745
removed block 11 current accuracy 0.3638 loss from initial  0.5876
since last training loss: 0.5734 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 16, with score 0.035516. All blocks and scores: [(16, 0.03551557147875428), (13, 0.05426597082987428), (2, 0.054583759512752295), (27, 0.054829273372888565), (3, 0.0578890941105783), (39, 0.059399555902928114), (8, 0.059785280376672745), (52, 0.06127170752733946), (0, 0.06349028600379825), (1, 0.06571311503648758), (12, 0.06669818237423897), (10, 0.06786416005343199), (5, 0.11054466664791107), (18, 0.2540457956492901), (36, 0.33378496766090393), (53, 1.3982845395803452)]
computing accuracy for after removing block 16 . block score: 0.03551557147875428
removed block 16 current accuracy 0.2974 loss from initial  0.654
training start
training epoch 0 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best True lr [0.1]
training epoch 1 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.1]
training epoch 2 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best True lr [0.1]
training epoch 3 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 4 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 6 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 7 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 8 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 9 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 10 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
loading model_best from epoch 24 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
