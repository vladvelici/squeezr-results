start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294661184772849), (29, 0.013421116629615426), (35, 0.01595769007690251), (26, 0.016072141006588936), (28, 0.01763686048798263), (27, 0.019022798165678978), (43, 0.019996491260826588), (46, 0.020590225467458367), (25, 0.022078295471146703), (23, 0.02222871547564864), (41, 0.0223364164121449), (44, 0.02314599882811308), (40, 0.023749591317027807), (45, 0.02397549618035555), (21, 0.024941089330241084), (48, 0.024957706686109304), (22, 0.025151389883831143), (50, 0.02528717485256493), (24, 0.025880582397803664), (49, 0.02591664856299758), (42, 0.026232231874018908), (20, 0.026848892215639353), (47, 0.02863294817507267), (38, 0.03134434390813112), (39, 0.031441295286640525), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740603014827), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525531575084), (0, 0.06337464833632112), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.436198640614748), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187405325472), (31, 0.010232581640593708), (34, 0.013119243900291622), (29, 0.013421116513200104), (26, 0.016072140308097005), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985268690623343), (46, 0.020300704753026366), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02297719311900437), (40, 0.02357383049093187), (45, 0.023648238042369485), (48, 0.02454021736048162), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.02684889198280871), (47, 0.028072760440409184), (38, 0.0310911878477782), (39, 0.03119136206805706), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.03254077769815922), (37, 0.03797321254387498), (51, 0.04127101460471749), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740696147084), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4339806139469147), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.019850464770570397), (46, 0.020411915611475706), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.02360258041881025), (45, 0.023770849220454693), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.028052504640072584), (38, 0.030935873743146658), (39, 0.031173036666586995), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740277051926), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432847619057), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824108667672), (34, 0.012400160194374621), (29, 0.01342111686244607), (35, 0.015918649500235915), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078294539824128), (23, 0.022228715708479285), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350046180188656), (50, 0.02446310524828732), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025246931007131934), (42, 0.025273551233112812), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.02772757480852306), (38, 0.03074627509340644), (39, 0.03128179581835866), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03895266866311431), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740603014827), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464554235339), (52, 0.06356756202876568), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4377693235874176), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824108667672
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.01342111686244607), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.020137187791988254), (41, 0.0215840560849756), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022687325021252036), (40, 0.023569097742438316), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870116962119937), (21, 0.02494108909741044), (42, 0.025045575574040413), (22, 0.025151390582323074), (24, 0.02588058332912624), (20, 0.026848891517147422), (47, 0.027423852821812034), (38, 0.03073564963415265), (39, 0.03141042497009039), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908351017162204), (51, 0.04034593887627125), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577406495809555), (3, 0.05784992594271898), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525485008955), (52, 0.06270107813179493), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114332690835), (36, 0.43692685663700104), (18, 0.5117432996630669), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023045078618451953), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.02416840917430818), (49, 0.02492237277328968), (21, 0.024941089330241084), (22, 0.0251513896510005), (42, 0.025816059904173017), (24, 0.02588058216497302), (20, 0.026848891284316778), (47, 0.027568294433876872), (38, 0.03178726485930383), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.040690732188522816), (9, 0.043376327492296696), (6, 0.04682369437068701), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525345310569), (52, 0.06221094774082303), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.44933702424168587), (18, 0.5117432847619057), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370510449633002), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985670323483646), (46, 0.019988976418972015), (41, 0.021256205393001437), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022692032624036074), (48, 0.023521371884271502), (50, 0.023533890722319484), (40, 0.023616240825504065), (45, 0.02393329213373363), (49, 0.024449915857985616), (42, 0.024838327895849943), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.02588058332912624), (47, 0.026813456090167165), (20, 0.02684889198280871), (38, 0.03108373167924583), (39, 0.03205688903108239), (15, 0.03205838426947594), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.03907974902540445), (37, 0.04015214368700981), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003455877304), (52, 0.06036907387897372), (17, 0.06132525624707341), (0, 0.06337464926764369), (1, 0.06593216303735971), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4432784356176853), (18, 0.5117433071136475), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143084399402), (28, 0.016986022237688303), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022507572080940008), (48, 0.022899369010701776), (50, 0.022937728092074394), (40, 0.023057402577251196), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.02408191910944879), (21, 0.02494108979590237), (22, 0.0251513896510005), (24, 0.025880582630634308), (47, 0.026322792284190655), (20, 0.02684889198280871), (38, 0.030149148777127266), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03785192780196667), (37, 0.03926890203729272), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992780536413), (52, 0.05846812017261982), (13, 0.0591442845761776), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43490004539489746), (18, 0.5117432773113251), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504143084399402
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.018381991423666477), (27, 0.01876970869489014), (46, 0.018842301797121763), (41, 0.019016370410099626), (48, 0.021309157833456993), (50, 0.02162452065385878), (44, 0.021748854545876384), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078295703977346), (23, 0.02222871547564864), (45, 0.02273644902743399), (49, 0.022970063146203756), (21, 0.02494108909741044), (22, 0.025151390815153718), (47, 0.025355831487104297), (24, 0.025880582630634308), (20, 0.026848891517147422), (38, 0.028691886691376567), (39, 0.029624432092532516), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.036016357596963644), (37, 0.03643036866560578), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.04852241417393088), (2, 0.05457740416750312), (52, 0.05466857831925154), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.41641607880592346), (18, 0.5117432922124863), (53, 0.8948248848319054)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.1]
training epoch 1 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.1]
training epoch 2 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.1]
training epoch 3 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.1]
training epoch 4 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.1]
training epoch 5 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.1]
training epoch 6 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.1]
training epoch 7 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.1]
training epoch 8 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.1]
training epoch 9 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.1]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 9
[activation diff]: block to remove picked: 37, with score 0.018743. All blocks and scores: [(37, 0.018743010936304927), (46, 0.021067043067887425), (43, 0.021115511190146208), (23, 0.022594344336539507), (41, 0.023042589193210006), (44, 0.023454829584807158), (45, 0.02421532990410924), (40, 0.024957677582278848), (21, 0.025020425207912922), (50, 0.025028284871950746), (22, 0.0251351164188236), (25, 0.0253602247685194), (49, 0.02551537100225687), (48, 0.025638498598709702), (42, 0.026634278474375606), (20, 0.027011254569515586), (27, 0.027776358416303992), (47, 0.028932892251759768), (24, 0.029328093631193042), (15, 0.03225173894315958), (19, 0.032623075414448977), (7, 0.032748065423220396), (39, 0.03372810548171401), (38, 0.03463891847059131), (51, 0.04111113864928484), (9, 0.04404798150062561), (6, 0.04636642895638943), (4, 0.04727772017940879), (14, 0.0481053595431149), (2, 0.054881406016647816), (3, 0.058284417260438204), (13, 0.05972322728484869), (11, 0.05980203114449978), (17, 0.06282828003168106), (0, 0.06420911755412817), (52, 0.0651374077424407), (1, 0.06683375872671604), (8, 0.07491299323737621), (10, 0.08147519081830978), (16, 0.08602443803101778), (12, 0.09033429808914661), (5, 0.10692824143916368), (36, 0.3806210421025753), (18, 0.5142503455281258), (53, 0.7959721833467484)]
computing accuracy for after removing block 37 . block score: 0.018743010936304927
removed block 37 current accuracy 0.942 loss from initial  0.009400000000000075
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019229. All blocks and scores: [(46, 0.019229347351938486), (43, 0.019465625286102295), (44, 0.020691796205937862), (41, 0.020763972541317344), (50, 0.021754137007519603), (45, 0.021918941754847765), (23, 0.022594345035031438), (49, 0.022790767019614577), (48, 0.022824208484962583), (40, 0.023121825652197003), (21, 0.025020424975082278), (22, 0.0251351164188236), (42, 0.02527827536687255), (25, 0.02536022407002747), (47, 0.025743216974660754), (20, 0.02701125480234623), (27, 0.02777635818347335), (24, 0.029328093165531754), (15, 0.03225173847749829), (39, 0.032537083607167006), (19, 0.032623075880110264), (7, 0.03274806449189782), (38, 0.03563679987564683), (51, 0.03789160726591945), (9, 0.04404798289760947), (6, 0.04636643175035715), (4, 0.04727771878242493), (14, 0.04810535907745361), (2, 0.05488140555098653), (52, 0.05745402816683054), (3, 0.05828441586345434), (13, 0.05972322868183255), (11, 0.059802031610161066), (17, 0.06282828096300364), (0, 0.06420911755412817), (1, 0.06683375779539347), (8, 0.07491299230605364), (10, 0.08147518988698721), (16, 0.08602443430572748), (12, 0.09033429529517889), (5, 0.10692824330180883), (36, 0.3806210346519947), (18, 0.5142503380775452), (53, 0.8294747546315193)]
computing accuracy for after removing block 46 . block score: 0.019229347351938486
removed block 46 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.008200000000000096 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019466. All blocks and scores: [(43, 0.019465624587610364), (44, 0.02069179597310722), (41, 0.020763971842825413), (45, 0.021918942453339696), (50, 0.022016375325620174), (23, 0.02259434456937015), (40, 0.023121825186535716), (48, 0.023158586351200938), (49, 0.02344090398401022), (21, 0.025020425906404853), (22, 0.0251351164188236), (42, 0.02527827536687255), (25, 0.0253602247685194), (20, 0.027011254336684942), (47, 0.027683437569066882), (27, 0.02777635818347335), (24, 0.029328093864023685), (15, 0.03225173894315958), (39, 0.032537083607167006), (19, 0.032623075880110264), (7, 0.03274806449189782), (38, 0.03563679987564683), (51, 0.03805153304710984), (9, 0.04404798336327076), (6, 0.046366431284695864), (4, 0.047277717385441065), (14, 0.0481053595431149), (2, 0.054881407879292965), (52, 0.057709220331162214), (3, 0.05828441772609949), (13, 0.05972322588786483), (11, 0.0598020339384675), (17, 0.06282828096300364), (0, 0.06420911476016045), (1, 0.06683375686407089), (8, 0.07491299230605364), (10, 0.08147518988698721), (16, 0.08602443523705006), (12, 0.09033429622650146), (5, 0.10692824237048626), (36, 0.3806210346519947), (18, 0.5142503306269646), (53, 0.9200932905077934)]
computing accuracy for after removing block 43 . block score: 0.019465624587610364
removed block 43 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.020764. All blocks and scores: [(41, 0.020763971842825413), (44, 0.022129241609945893), (50, 0.022365295561030507), (23, 0.022594345035031438), (45, 0.023067824076861143), (40, 0.023121824953705072), (49, 0.02333619398996234), (48, 0.024449388263747096), (21, 0.02502042567357421), (22, 0.02513511572033167), (42, 0.02527827536687255), (25, 0.025360223837196827), (20, 0.027011253871023655), (27, 0.02777635888196528), (47, 0.02875024056993425), (24, 0.02932809293270111), (15, 0.03225173940882087), (39, 0.03253708314150572), (19, 0.03262307681143284), (7, 0.03274806495755911), (38, 0.03563679940998554), (51, 0.03784095076844096), (9, 0.0440479819662869), (6, 0.04636643035337329), (4, 0.04727771878242493), (14, 0.048105358611792326), (2, 0.05488140555098653), (52, 0.057225927244871855), (3, 0.058284418657422066), (13, 0.059723228216171265), (11, 0.05980203254148364), (17, 0.06282828003168106), (0, 0.06420911848545074), (1, 0.06683375686407089), (8, 0.07491299137473106), (10, 0.08147519361227751), (16, 0.08602443430572748), (12, 0.09033429902046919), (5, 0.10692824423313141), (36, 0.3806210346519947), (18, 0.514250323176384), (53, 0.9703027680516243)]
computing accuracy for after removing block 41 . block score: 0.020763971842825413
removed block 41 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 50, with score 0.021958. All blocks and scores: [(50, 0.021958149736747146), (23, 0.02259434456937015), (49, 0.02282748860307038), (45, 0.02310170349664986), (40, 0.02312182611785829), (44, 0.023257605265825987), (48, 0.023606377886608243), (21, 0.025020425440743566), (22, 0.025135115487501025), (42, 0.02523713489063084), (25, 0.025360223837196827), (20, 0.02701125480234623), (27, 0.027776358649134636), (47, 0.02902153762988746), (24, 0.029328093631193042), (15, 0.03225173847749829), (39, 0.03253708407282829), (19, 0.032623075414448977), (7, 0.032748065423220396), (38, 0.03563679987564683), (51, 0.036086011212319136), (9, 0.04404798336327076), (6, 0.046366430819034576), (4, 0.04727771785110235), (14, 0.048105360474437475), (52, 0.054696071427315474), (2, 0.054881406016647816), (3, 0.05828441772609949), (13, 0.05972322728484869), (11, 0.059802033472806215), (17, 0.0628282823599875), (0, 0.06420911755412817), (1, 0.06683375965803862), (8, 0.07491299137473106), (10, 0.08147518895566463), (16, 0.08602443616837263), (12, 0.09033429808914661), (5, 0.10692824143916368), (36, 0.3806210421025753), (18, 0.5142503306269646), (53, 1.0539811700582504)]
computing accuracy for after removing block 50 . block score: 0.021958149736747146
removed block 50 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 23, with score 0.022594. All blocks and scores: [(23, 0.02259434456937015), (49, 0.022827488835901022), (45, 0.023101703263819218), (40, 0.023121825186535716), (44, 0.023257605265825987), (48, 0.02360637835226953), (21, 0.025020425440743566), (22, 0.025135115953162313), (42, 0.02523713535629213), (25, 0.025360223837196827), (20, 0.02701125480234623), (27, 0.02777635888196528), (47, 0.029021537164226174), (24, 0.02932809293270111), (15, 0.03225173894315958), (39, 0.032537083607167006), (19, 0.032623075880110264), (7, 0.032748065423220396), (38, 0.03563679940998554), (51, 0.038716763723641634), (9, 0.044047984294593334), (6, 0.04636643035337329), (4, 0.047277719248086214), (14, 0.04810535814613104), (2, 0.05488140741363168), (3, 0.05828441819176078), (13, 0.05972322728484869), (11, 0.059802031610161066), (52, 0.06158568803220987), (17, 0.06282828003168106), (0, 0.06420911755412817), (1, 0.06683375872671604), (8, 0.07491299230605364), (10, 0.08147518988698721), (16, 0.08602443616837263), (12, 0.09033429995179176), (5, 0.10692824237048626), (36, 0.3806210346519947), (18, 0.5142503455281258), (53, 1.2459494918584824)]
computing accuracy for after removing block 23 . block score: 0.02259434456937015
removed block 23 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.022673. All blocks and scores: [(40, 0.022673076018691063), (49, 0.022757352562621236), (44, 0.022898185765370727), (45, 0.02318445546552539), (48, 0.02318646595813334), (42, 0.024272161535918713), (25, 0.024884637212380767), (21, 0.025020425440743566), (22, 0.0251351164188236), (20, 0.0270112541038543), (27, 0.027160013560205698), (24, 0.027833950938656926), (47, 0.028421184280887246), (15, 0.032251739874482155), (39, 0.03246855642646551), (19, 0.03262307634577155), (7, 0.03274806495755911), (38, 0.03539061499759555), (51, 0.03842059290036559), (9, 0.04404798150062561), (6, 0.046366430819034576), (4, 0.04727771785110235), (14, 0.04810536000877619), (2, 0.05488140741363168), (3, 0.05828441819176078), (13, 0.05972322868183255), (11, 0.059802033472806215), (52, 0.06023575132712722), (17, 0.06282828049734235), (0, 0.06420911848545074), (1, 0.06683375779539347), (8, 0.07491299137473106), (10, 0.08147518802434206), (16, 0.08602443616837263), (12, 0.09033429808914661), (5, 0.10692824423313141), (36, 0.3813485838472843), (18, 0.5142503306269646), (53, 1.25217404961586)]
computing accuracy for after removing block 40 . block score: 0.022673076018691063
removed block 40 current accuracy 0.9128 loss from initial  0.03860000000000008
since last training loss: 0.0344000000000001 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.021975. All blocks and scores: [(49, 0.021975287701934576), (48, 0.02233359939418733), (45, 0.02260400541126728), (42, 0.02351669780910015), (44, 0.023821433540433645), (25, 0.024884637212380767), (21, 0.025020425440743566), (22, 0.0251351164188236), (20, 0.0270112541038543), (27, 0.02716001425869763), (24, 0.02783395047299564), (47, 0.028445175383239985), (15, 0.03225173940882087), (39, 0.03246855642646551), (19, 0.032623075880110264), (7, 0.03274806449189782), (38, 0.035390615463256836), (51, 0.037323156371712685), (9, 0.0440479819662869), (6, 0.04636643035337329), (4, 0.04727771878242493), (14, 0.0481053595431149), (2, 0.05488140694797039), (52, 0.05744094820693135), (3, 0.058284416794776917), (13, 0.05972322728484869), (11, 0.059802033472806215), (17, 0.06282828003168106), (0, 0.06420911569148302), (1, 0.06683375686407089), (8, 0.07491299416869879), (10, 0.08147518988698721), (16, 0.08602443337440491), (12, 0.09033429808914661), (5, 0.10692824516445398), (36, 0.3813485875725746), (18, 0.514250323176384), (53, 1.3757678717374802)]
computing accuracy for after removing block 49 . block score: 0.021975287701934576
removed block 49 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.022334. All blocks and scores: [(48, 0.02233359939418733), (45, 0.022604005876928568), (42, 0.02351669827476144), (44, 0.023821433074772358), (25, 0.024884636513888836), (21, 0.025020424742251635), (22, 0.025135116185992956), (20, 0.027011254336684942), (27, 0.027160014025866985), (24, 0.027833950705826283), (47, 0.028445175383239985), (15, 0.03225173847749829), (39, 0.0324685568921268), (19, 0.032623075414448977), (7, 0.03274806495755911), (38, 0.03539061453193426), (51, 0.038836343213915825), (9, 0.04404798103496432), (6, 0.046366430819034576), (4, 0.04727772017940879), (14, 0.0481053595431149), (2, 0.05488140694797039), (3, 0.058284416794776917), (52, 0.059047823771834373), (13, 0.059723228216171265), (11, 0.05980203254148364), (17, 0.06282827956601977), (0, 0.0642091166228056), (1, 0.06683375872671604), (8, 0.07491299137473106), (10, 0.08147519081830978), (16, 0.08602443337440491), (12, 0.09033429529517889), (5, 0.10692823957651854), (36, 0.3813485950231552), (18, 0.5142503082752228), (53, 1.56871198117733)]
computing accuracy for after removing block 48 . block score: 0.02233359939418733
removed block 48 current accuracy 0.8792 loss from initial  0.07220000000000004
training start
training epoch 0 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 1 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.1]
training epoch 2 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 3 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 4 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.1]
training epoch 5 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.1]
training epoch 6 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.1]
training epoch 7 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 9 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[activation diff]: block to remove picked: 20, with score 0.027308. All blocks and scores: [(20, 0.027307533659040928), (19, 0.03236354747787118), (15, 0.032482814975082874), (7, 0.0326777920126915), (22, 0.03518010815605521), (21, 0.03702271310612559), (25, 0.03945086570456624), (24, 0.04177133506163955), (27, 0.04233554424718022), (9, 0.04375634994357824), (44, 0.04408926609903574), (45, 0.046350918244570494), (6, 0.046835615299642086), (42, 0.04798202170059085), (14, 0.048054258804768324), (4, 0.048128155060112476), (47, 0.05138578126206994), (2, 0.05506255757063627), (51, 0.0575607162900269), (3, 0.05890803411602974), (13, 0.05983605980873108), (11, 0.059906546492129564), (38, 0.06246183207258582), (17, 0.06320610456168652), (0, 0.06469246465712786), (1, 0.06669039279222488), (39, 0.06767081376165152), (8, 0.07494839280843735), (10, 0.08175710681825876), (16, 0.0860175359994173), (12, 0.09054068382829428), (52, 0.09505630284547806), (5, 0.10752344410866499), (18, 0.5157518982887268), (36, 0.5827115103602409), (53, 0.7898592874407768)]
computing accuracy for after removing block 20 . block score: 0.027307533659040928
removed block 20 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 19, with score 0.032364. All blocks and scores: [(19, 0.032363546546548605), (15, 0.032482813112437725), (7, 0.03267779387533665), (22, 0.035038657020777464), (21, 0.03652805835008621), (25, 0.03808726742863655), (24, 0.040141348261386156), (27, 0.04061796981841326), (44, 0.043207735288888216), (9, 0.04375634994357824), (42, 0.04556711856275797), (45, 0.04571311408653855), (6, 0.04683561576530337), (14, 0.04805425927042961), (4, 0.04812815599143505), (47, 0.0495473425835371), (2, 0.05506255850195885), (51, 0.056444205809384584), (3, 0.058908035047352314), (13, 0.059836062137037516), (11, 0.05990654602646828), (38, 0.06142697436735034), (17, 0.06320610688999295), (0, 0.06469246093183756), (39, 0.06634156033396721), (1, 0.06669039279222488), (8, 0.07494839373975992), (10, 0.08175710216164589), (16, 0.0860175397247076), (52, 0.08818350918591022), (12, 0.0905406828969717), (5, 0.10752343945205212), (18, 0.5157518833875656), (36, 0.572825126349926), (53, 0.7895088046789169)]
computing accuracy for after removing block 19 . block score: 0.032363546546548605
removed block 19 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.032483. All blocks and scores: [(15, 0.032482814975082874), (7, 0.03267779340967536), (25, 0.03493911726400256), (22, 0.03513775719329715), (21, 0.0372044425457716), (24, 0.037502819672226906), (27, 0.04005907289683819), (44, 0.04171218350529671), (9, 0.04375635087490082), (42, 0.04422009875997901), (45, 0.04524535173550248), (6, 0.04683561576530337), (47, 0.04728123312816024), (14, 0.04805425927042961), (4, 0.048128155525773764), (2, 0.05506255803629756), (51, 0.05611242679879069), (3, 0.05890803225338459), (13, 0.05983606120571494), (11, 0.05990654602646828), (38, 0.06036775466054678), (17, 0.06320610363036394), (0, 0.06469246093183756), (39, 0.06630904600024223), (1, 0.06669039186090231), (8, 0.07494839932769537), (52, 0.08053078223019838), (10, 0.08175710588693619), (16, 0.08601753693073988), (12, 0.09054068382829428), (5, 0.10752344038337469), (18, 0.5157518982887268), (36, 0.56705392152071), (53, 0.7859506607055664)]
computing accuracy for after removing block 15 . block score: 0.032482814975082874
removed block 15 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 7, with score 0.032678. All blocks and scores: [(7, 0.03267779294401407), (25, 0.0338332480750978), (22, 0.03411021828651428), (21, 0.03533302387222648), (24, 0.03603530628606677), (27, 0.039089486468583345), (44, 0.041068443562835455), (42, 0.04296164819970727), (9, 0.04375634994357824), (45, 0.04527373379096389), (6, 0.04683561576530337), (14, 0.04805425927042961), (4, 0.0481281541287899), (47, 0.04834560677409172), (2, 0.05506255803629756), (51, 0.05672974232584238), (3, 0.05890803411602974), (13, 0.059836060740053654), (11, 0.05990654602646828), (38, 0.060509356670081615), (0, 0.06469246093183756), (39, 0.06661293841898441), (1, 0.06669039279222488), (17, 0.06719908118247986), (8, 0.0749483946710825), (52, 0.07988668605685234), (10, 0.08175710402429104), (12, 0.09054068382829428), (16, 0.09608271345496178), (5, 0.10752344317734241), (18, 0.5029055774211884), (36, 0.5588257759809494), (53, 0.7941621243953705)]
computing accuracy for after removing block 7 . block score: 0.03267779294401407
removed block 7 current accuracy 0.9166 loss from initial  0.03480000000000005
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.032222. All blocks and scores: [(22, 0.03222242183983326), (25, 0.03259058250114322), (24, 0.032627299427986145), (21, 0.03448472311720252), (27, 0.03760948032140732), (42, 0.04022150952368975), (44, 0.04077383177354932), (9, 0.04370394302532077), (45, 0.04394263448193669), (14, 0.04440477769821882), (47, 0.0465129679068923), (6, 0.046835615299642086), (4, 0.04812815645709634), (13, 0.05174980405718088), (51, 0.05438902089372277), (2, 0.05506255803629756), (11, 0.05658146785572171), (17, 0.056807862129062414), (38, 0.05699470639228821), (3, 0.0589080355130136), (0, 0.06469246093183756), (39, 0.06486040260642767), (1, 0.06669039279222488), (8, 0.07301896344870329), (52, 0.0759657695889473), (10, 0.08413839433342218), (12, 0.08459700644016266), (16, 0.08752560894936323), (5, 0.10752343945205212), (18, 0.48592301830649376), (36, 0.5391777083277702), (53, 0.8190410137176514)]
computing accuracy for after removing block 22 . block score: 0.03222242183983326
removed block 22 current accuracy 0.9054 loss from initial  0.04600000000000004
since last training loss: 0.03859999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.029095. All blocks and scores: [(24, 0.029095079051330686), (25, 0.02981196530163288), (21, 0.03448472311720252), (27, 0.03490792075172067), (42, 0.03775538271293044), (44, 0.0385546344332397), (45, 0.04296758444979787), (47, 0.043196768034249544), (9, 0.04370394488796592), (14, 0.04440477769821882), (6, 0.046835613902658224), (4, 0.048128155060112476), (51, 0.05106559535488486), (13, 0.05174980452284217), (2, 0.055062558967620134), (38, 0.055967339780181646), (11, 0.05658146645873785), (17, 0.05680786073207855), (3, 0.05890803411602974), (39, 0.06404199078679085), (0, 0.06469246093183756), (52, 0.06547521892935038), (1, 0.06669039279222488), (8, 0.07301896251738071), (10, 0.08413839433342218), (12, 0.08459700364619493), (16, 0.08752561174333096), (5, 0.10752343758940697), (18, 0.48592299595475197), (36, 0.5260370150208473), (53, 0.8526359722018242)]
computing accuracy for after removing block 24 . block score: 0.029095079051330686
removed block 24 current accuracy 0.8928 loss from initial  0.058599999999999985
since last training loss: 0.05119999999999991 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 25, with score 0.028370. All blocks and scores: [(25, 0.028370448388159275), (21, 0.03448472265154123), (27, 0.03455893974751234), (42, 0.036162462551146746), (44, 0.03811110882088542), (47, 0.04141126340255141), (45, 0.04268555250018835), (9, 0.04370394442230463), (14, 0.04440477816388011), (6, 0.0468356148339808), (4, 0.048128155060112476), (51, 0.04843710223212838), (13, 0.05174980079755187), (2, 0.05506255943328142), (38, 0.056555498857051134), (11, 0.05658146785572171), (17, 0.056807862129062414), (52, 0.056943430099636316), (3, 0.05890803411602974), (39, 0.06399483792483807), (0, 0.06469246093183756), (1, 0.06669038999825716), (8, 0.07301896251738071), (10, 0.08413839526474476), (12, 0.08459700457751751), (16, 0.08752561081200838), (5, 0.10752344224601984), (18, 0.48592301830649376), (36, 0.527807928621769), (53, 0.8786657229065895)]
computing accuracy for after removing block 25 . block score: 0.028370448388159275
removed block 25 current accuracy 0.875 loss from initial  0.07640000000000002
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 21, with score 0.034485. All blocks and scores: [(21, 0.03448472311720252), (42, 0.03701798850670457), (27, 0.03712960798293352), (44, 0.03869603108614683), (47, 0.04101527249440551), (45, 0.04219725960865617), (9, 0.04370394395664334), (14, 0.04440477956086397), (6, 0.046835615299642086), (4, 0.0481281541287899), (51, 0.048312436789274216), (13, 0.05174980312585831), (52, 0.0534056406468153), (2, 0.05506255989894271), (11, 0.05658146785572171), (17, 0.05680786399170756), (3, 0.05890803365036845), (38, 0.05990141909569502), (0, 0.06469246093183756), (39, 0.06574227940291166), (1, 0.06669039186090231), (8, 0.07301896158605814), (10, 0.08413839340209961), (12, 0.08459700364619493), (16, 0.0875256098806858), (5, 0.10752344503998756), (18, 0.48592301458120346), (36, 0.5512127876281738), (53, 0.8983930125832558)]
computing accuracy for after removing block 21 . block score: 0.03448472311720252
removed block 21 current accuracy 0.8386 loss from initial  0.11280000000000001
since last training loss: 0.10539999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 27, with score 0.036634. All blocks and scores: [(27, 0.03663397300988436), (42, 0.03694603452458978), (44, 0.039035034365952015), (47, 0.03980639390647411), (45, 0.04281729133799672), (9, 0.04370394302532077), (14, 0.04440477816388011), (6, 0.04683561576530337), (4, 0.04812815459445119), (51, 0.048158576246351004), (52, 0.04925262974575162), (13, 0.051749804988503456), (2, 0.05506255943328142), (11, 0.056581469252705574), (17, 0.05680786445736885), (3, 0.05890803365036845), (38, 0.06269834889099002), (0, 0.06469246093183756), (1, 0.06669038999825716), (39, 0.06793579179793596), (8, 0.07301896344870329), (10, 0.08413839340209961), (12, 0.08459700271487236), (16, 0.0875256098806858), (5, 0.10752344131469727), (18, 0.48592301830649376), (36, 0.5606425330042839), (53, 0.918050192296505)]
computing accuracy for after removing block 27 . block score: 0.03663397300988436
removed block 27 current accuracy 0.803 loss from initial  0.14839999999999998
training start
training epoch 0 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best True lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 2 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 3 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 4 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.1]
training epoch 5 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.1]
training epoch 6 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 7 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 8 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.1]
training epoch 9 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.1]
training epoch 10 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.934400)
finished training. finished 50 epochs. accuracy 0.9344 topk_dict {'top1': 0.9344}
start iteration 27
[activation diff]: block to remove picked: 9, with score 0.031344. All blocks and scores: [(9, 0.03134359675459564), (44, 0.04767725383862853), (4, 0.04892138484865427), (6, 0.04924151999875903), (45, 0.04933696845546365), (14, 0.05074600223451853), (47, 0.05277983006089926), (42, 0.053922138176858425), (2, 0.05492576025426388), (13, 0.055039959494024515), (3, 0.05797902029007673), (51, 0.05900120409205556), (11, 0.059557899832725525), (0, 0.06355465948581696), (1, 0.06644531432539225), (38, 0.06759883835911751), (8, 0.06819605175405741), (17, 0.0706355283036828), (39, 0.07699081115424633), (10, 0.08079894911497831), (12, 0.08876709267497063), (5, 0.09061042312532663), (16, 0.094309002161026), (52, 0.09970389865338802), (36, 0.5178054496645927), (18, 0.5760513842105865), (53, 0.7869854271411896)]
computing accuracy for after removing block 9 . block score: 0.03134359675459564
removed block 9 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 44, with score 0.048466. All blocks and scores: [(44, 0.048465773928910494), (4, 0.04892138624563813), (6, 0.04924152139574289), (45, 0.04988934798166156), (14, 0.050058663822710514), (42, 0.052515311632305384), (47, 0.05354452831670642), (2, 0.05492576025426388), (13, 0.05617404356598854), (51, 0.05758611159399152), (3, 0.05797901842743158), (11, 0.06252314941957593), (0, 0.06355465948581696), (1, 0.06644531339406967), (8, 0.06819605175405741), (38, 0.06903946958482265), (17, 0.07278098911046982), (39, 0.07811722159385681), (16, 0.08338930364698172), (5, 0.09061042219400406), (10, 0.09284830931574106), (12, 0.09371779579669237), (52, 0.0996229313313961), (36, 0.5212267637252808), (18, 0.5819451436400414), (53, 0.7883765250444412)]
computing accuracy for after removing block 44 . block score: 0.048465773928910494
removed block 44 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 4, with score 0.048921. All blocks and scores: [(4, 0.04892138531431556), (6, 0.04924151860177517), (14, 0.05005866335704923), (45, 0.05180752230808139), (42, 0.05251531070098281), (2, 0.05492576025426388), (51, 0.055419265292584896), (13, 0.05617404216900468), (47, 0.05724917305633426), (3, 0.057979017961770296), (11, 0.06252315174788237), (0, 0.06355465948581696), (1, 0.06644531339406967), (8, 0.06819604989141226), (38, 0.0690394714474678), (17, 0.07278098911046982), (39, 0.07811722252517939), (16, 0.08338930271565914), (52, 0.08981513883918524), (5, 0.09061042033135891), (10, 0.09284830652177334), (12, 0.09371780045330524), (36, 0.5212267562747002), (18, 0.5819451212882996), (53, 0.9244985058903694)]
computing accuracy for after removing block 4 . block score: 0.04892138531431556
removed block 4 current accuracy 0.8998 loss from initial  0.05159999999999998
since last training loss: 0.034599999999999964 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.049829. All blocks and scores: [(14, 0.04982917755842209), (45, 0.0527399810962379), (42, 0.05347483605146408), (51, 0.054407413583248854), (6, 0.05476268846541643), (2, 0.05492575978860259), (13, 0.05512910941615701), (47, 0.05701036565005779), (3, 0.05797901842743158), (11, 0.05919461837038398), (0, 0.06355465948581696), (1, 0.06644531432539225), (8, 0.06824299413710833), (17, 0.06964479852467775), (38, 0.07053777575492859), (16, 0.07211928628385067), (39, 0.07814611028879881), (52, 0.08922889176756144), (12, 0.08956027496606112), (10, 0.09334771893918514), (5, 0.09709871839731932), (36, 0.5297576412558556), (18, 0.5884823724627495), (53, 0.9115227088332176)]
computing accuracy for after removing block 14 . block score: 0.04982917755842209
removed block 14 current accuracy 0.8578 loss from initial  0.09360000000000002
since last training loss: 0.0766 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 42, with score 0.049573. All blocks and scores: [(42, 0.04957340843975544), (45, 0.05201601516455412), (51, 0.05393370660021901), (6, 0.05476268986240029), (2, 0.05492575839161873), (13, 0.05512910755351186), (47, 0.05617729853838682), (3, 0.05797901889309287), (11, 0.059194616973400116), (0, 0.06355466041713953), (17, 0.06404565088450909), (38, 0.06558661349117756), (1, 0.06644531339406967), (8, 0.06824299693107605), (39, 0.07732887007296085), (52, 0.08247592486441135), (12, 0.08956027403473854), (10, 0.09334771987050772), (16, 0.09368959069252014), (5, 0.09709871839731932), (36, 0.5101342052221298), (18, 0.5581085458397865), (53, 0.9408595412969589)]
computing accuracy for after removing block 42 . block score: 0.04957340843975544
removed block 42 current accuracy 0.8224 loss from initial  0.129
since last training loss: 0.11199999999999999 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.053960. All blocks and scores: [(51, 0.05395969748497009), (6, 0.05476268846541643), (2, 0.05492576165124774), (13, 0.05512910941615701), (45, 0.05579541577026248), (3, 0.05797901889309287), (11, 0.059194616973400116), (47, 0.060366364661604166), (0, 0.0635546576231718), (17, 0.06404565088450909), (38, 0.06558661162853241), (1, 0.06644531060010195), (8, 0.06824299599975348), (39, 0.07732887100428343), (52, 0.08210265450179577), (12, 0.08956027217209339), (10, 0.09334771987050772), (16, 0.09368959069252014), (5, 0.09709871653467417), (36, 0.5101341903209686), (18, 0.5581085383892059), (53, 1.0694014728069305)]
computing accuracy for after removing block 51 . block score: 0.05395969748497009
removed block 51 current accuracy 0.7322 loss from initial  0.21920000000000006
since last training loss: 0.20220000000000005 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 6, with score 0.054763. All blocks and scores: [(6, 0.05476268893107772), (2, 0.054925757460296154), (13, 0.055129109881818295), (45, 0.05579541344195604), (3, 0.05797901842743158), (11, 0.0591946174390614), (47, 0.060366364661604166), (0, 0.06355465948581696), (17, 0.06404564995318651), (38, 0.06558661069720984), (1, 0.06644531060010195), (8, 0.0682429950684309), (39, 0.07732887007296085), (52, 0.07770601939409971), (12, 0.08956027124077082), (10, 0.09334771987050772), (16, 0.09368958976119757), (5, 0.09709871653467417), (36, 0.5101341903209686), (18, 0.5581085383892059), (53, 1.3578049093484879)]
computing accuracy for after removing block 6 . block score: 0.05476268893107772
removed block 6 current accuracy 0.5836 loss from initial  0.3678
since last training loss: 0.3508 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 13, with score 0.054309. All blocks and scores: [(13, 0.054308888502418995), (2, 0.05492576025426388), (11, 0.05508672399446368), (45, 0.05584709299728274), (47, 0.05696596531197429), (3, 0.05797901935875416), (38, 0.062061768025159836), (0, 0.0635546576231718), (17, 0.06463773548603058), (1, 0.06644531153142452), (52, 0.06901208963245153), (8, 0.06979597453027964), (39, 0.07454457506537437), (12, 0.08506508450955153), (16, 0.08887353353202343), (5, 0.09709871746599674), (10, 0.12422071304172277), (36, 0.5129561126232147), (18, 0.5678155869245529), (53, 1.4404123276472092)]
computing accuracy for after removing block 13 . block score: 0.054308888502418995
removed block 13 current accuracy 0.394 loss from initial  0.5574
since last training loss: 0.5404 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 47, with score 0.053020. All blocks and scores: [(47, 0.053019643761217594), (2, 0.05492575792595744), (11, 0.05508672259747982), (45, 0.055424561724066734), (3, 0.057979019824415445), (38, 0.058345185592770576), (52, 0.06021967809647322), (0, 0.06355466041713953), (1, 0.06644531153142452), (8, 0.06979597359895706), (17, 0.07448162883520126), (39, 0.07778319343924522), (12, 0.08506508450955153), (5, 0.09709871653467417), (16, 0.09808931965380907), (10, 0.12422071490436792), (36, 0.5163463950157166), (18, 0.582619234919548), (53, 1.546646311879158)]
computing accuracy for after removing block 47 . block score: 0.053019643761217594
removed block 47 current accuracy 0.3032 loss from initial  0.6482
since last training loss: 0.6312 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 2, with score 0.054926. All blocks and scores: [(2, 0.054925758857280016), (11, 0.05508672585710883), (45, 0.055424561724066734), (3, 0.05797901935875416), (38, 0.05834518698975444), (0, 0.0635546576231718), (1, 0.06644531339406967), (8, 0.06979597359895706), (17, 0.07448162883520126), (52, 0.07673710491508245), (39, 0.0777831943705678), (12, 0.08506508730351925), (5, 0.09709871560335159), (16, 0.09808931685984135), (10, 0.12422071397304535), (36, 0.5163463950157166), (18, 0.582619234919548), (53, 1.5496177226305008)]
computing accuracy for after removing block 2 . block score: 0.054925758857280016
removed block 2 current accuracy 0.2394 loss from initial  0.712
since last training loss: 0.6950000000000001 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.051346. All blocks and scores: [(11, 0.0513456123881042), (3, 0.05297530768439174), (45, 0.05449359491467476), (38, 0.05610078573226929), (17, 0.0632082661613822), (0, 0.06355465855449438), (1, 0.06644531153142452), (8, 0.06705981772392988), (39, 0.07267177570611238), (52, 0.07275013532489538), (12, 0.07815404608845711), (16, 0.0854041101410985), (5, 0.08847442362457514), (10, 0.1230707922950387), (36, 0.4795428663492203), (18, 0.5384089276194572), (53, 1.6368359327316284)]
computing accuracy for after removing block 11 . block score: 0.0513456123881042
removed block 11 current accuracy 0.1894 loss from initial  0.762
since last training loss: 0.745 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 3, with score 0.052975. All blocks and scores: [(3, 0.05297530721873045), (17, 0.0566077996045351), (45, 0.05666648456826806), (16, 0.057245394214987755), (38, 0.05818600673228502), (0, 0.06355466041713953), (1, 0.0664453124627471), (12, 0.06684183608740568), (8, 0.06705981679260731), (52, 0.06766147259622812), (39, 0.06904485635459423), (5, 0.08847442455589771), (10, 0.12307079322636127), (36, 0.46172696352005005), (18, 0.5304488241672516), (53, 1.7926864922046661)]
computing accuracy for after removing block 3 . block score: 0.05297530721873045
removed block 3 current accuracy 0.14 loss from initial  0.8114
training start
training epoch 0 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.1]
training epoch 1 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.1]
training epoch 2 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 3 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 5 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 6 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 7 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 8 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.1]
training epoch 9 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 10 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.935000)
finished training. finished 50 epochs. accuracy 0.935 topk_dict {'top1': 0.935}
