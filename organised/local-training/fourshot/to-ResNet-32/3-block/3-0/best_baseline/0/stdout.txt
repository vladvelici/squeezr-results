start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013294660951942205), (29, 0.013421116746030748), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019996491260826588), (46, 0.02059022500179708), (25, 0.022078295005485415), (23, 0.022228715242817998), (41, 0.022336416179314256), (44, 0.023145999293774366), (40, 0.02374959015287459), (45, 0.023975495481863618), (21, 0.02494108909741044), (48, 0.024957706686109304), (22, 0.025151390116661787), (50, 0.02528717485256493), (24, 0.02588058286346495), (49, 0.02591664926148951), (42, 0.02623223210684955), (20, 0.026848892914131284), (47, 0.0286329488735646), (38, 0.0313443448394537), (39, 0.031441295286640525), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077723249793), (37, 0.03791803168132901), (51, 0.04178758757188916), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117433145642281), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581291347742), (34, 0.0131192437838763), (29, 0.013421117211692035), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.021860275650396943), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02297719265334308), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540216429159045), (50, 0.02477082284167409), (21, 0.024941089330241084), (22, 0.025151389883831143), (49, 0.025575740495696664), (24, 0.02588058216497302), (42, 0.025893412763252854), (20, 0.026848892215639353), (47, 0.028072759741917253), (38, 0.031091187614947557), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.043376326095312834), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.0613252529874444), (0, 0.06337464461103082), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.43398062139749527), (18, 0.5117432996630669), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116746030748), (35, 0.01591842109337449), (26, 0.016072141472250223), (28, 0.01763686048798263), (27, 0.01902279839850962), (43, 0.01985046500340104), (46, 0.020411916309967637), (41, 0.02182762953452766), (25, 0.022078295005485415), (23, 0.02222871477715671), (44, 0.02289147791452706), (40, 0.023602579021826386), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.024941089563071728), (22, 0.0251513896510005), (49, 0.0253925493452698), (42, 0.025712220929563046), (24, 0.02588058332912624), (20, 0.026848891749978065), (47, 0.028052504872903228), (38, 0.030935872811824083), (39, 0.03117303689941764), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.061325252521783113), (0, 0.06337464647367597), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432922124863), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421117211692035), (35, 0.015918649500235915), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019867350114509463), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350044783204794), (50, 0.024463105015456676), (21, 0.024941090028733015), (22, 0.025151390582323074), (49, 0.02524693077430129), (42, 0.025273551931604743), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027727575274184346), (38, 0.03074627392925322), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117433071136475), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.020137188024818897), (41, 0.0215840560849756), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.02356909867376089), (45, 0.023840721929445863), (48, 0.02410835982300341), (50, 0.024114210857078433), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.02742385258898139), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908350924029946), (51, 0.04034594027325511), (9, 0.043376329354941845), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740277051926), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525438442826), (52, 0.06270107720047235), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692685291171074), (18, 0.5117432996630669), (53, 0.8283700942993164)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141006588936), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.020324198296293616), (41, 0.021962702739983797), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02304507722146809), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.024941089563071728), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.02684889268130064), (47, 0.02756829489953816), (38, 0.03178726485930383), (15, 0.0320583856664598), (39, 0.03225791221484542), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.0613252529874444), (52, 0.06221094913780689), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.44933702051639557), (18, 0.5117432847619057), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.01637051091529429), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.019988976418972015), (41, 0.02125620562583208), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.022692033322528005), (48, 0.023521371884271502), (50, 0.023533890722319484), (40, 0.023616240359842777), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.02681345585733652), (20, 0.02684889198280871), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077909514308), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.05970003502443433), (52, 0.060369073413312435), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4432784356176853), (18, 0.5117432922124863), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.016986022237688303), (27, 0.018769708462059498), (43, 0.019405571278184652), (46, 0.01970007666386664), (41, 0.02051579882390797), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022507571848109365), (48, 0.022899368312209845), (50, 0.02293772785924375), (40, 0.023057401878759265), (42, 0.023520408663898706), (45, 0.023633700096979737), (49, 0.02408191910944879), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.02588058332912624), (47, 0.026322791818529367), (20, 0.026848892215639353), (38, 0.030149149242788553), (39, 0.03146669641137123), (15, 0.03205838380381465), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.037851928267627954), (37, 0.03926890343427658), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992780536413), (52, 0.05846811970695853), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43490004912018776), (18, 0.5117432996630669), (53, 0.8595061227679253)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986022237688303), (43, 0.018381991190835834), (27, 0.018769708462059498), (46, 0.018842302029952407), (41, 0.01901637064293027), (48, 0.021309157367795706), (50, 0.021624520886689425), (44, 0.02174885431304574), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078296169638634), (23, 0.022228715708479285), (45, 0.02273644902743399), (49, 0.022970062913373113), (21, 0.024941089563071728), (22, 0.02515139034949243), (47, 0.025355831254273653), (24, 0.025880581932142377), (20, 0.026848891749978065), (38, 0.028691887389868498), (39, 0.029624431859701872), (15, 0.03205838659778237), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.036016357596963644), (37, 0.036430368199944496), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (52, 0.054668578784912825), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537329226732), (5, 0.1067114369943738), (36, 0.41641608253121376), (18, 0.5117432996630669), (53, 0.8948249518871307)]
computing accuracy for after removing block 28 . block score: 0.016986022237688303
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.1]
training epoch 1 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.1]
training epoch 2 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.1]
training epoch 3 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.1]
training epoch 4 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.1]
training epoch 5 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.1]
training epoch 6 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.1]
training epoch 7 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.1]
training epoch 8 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.1]
training epoch 9 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.1]
training epoch 10 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.019715. All blocks and scores: [(43, 0.01971470331773162), (46, 0.02035889821127057), (41, 0.02185358921997249), (44, 0.023064480163156986), (40, 0.023221508134156466), (45, 0.023718562675639987), (48, 0.024676561821252108), (50, 0.02473311242647469), (21, 0.024819239042699337), (22, 0.024919180665165186), (49, 0.025154679315164685), (42, 0.025188133819028735), (20, 0.027039862936362624), (27, 0.027715931180864573), (47, 0.028380521340295672), (25, 0.029409070499241352), (23, 0.029715129174292088), (38, 0.03099037823267281), (39, 0.031014059437438846), (24, 0.031359124928712845), (15, 0.032030435279011726), (19, 0.032537620048969984), (7, 0.03262687660753727), (37, 0.03773216297850013), (51, 0.04162175161764026), (9, 0.04421629849821329), (6, 0.046342866495251656), (4, 0.04656831221655011), (14, 0.04770289175212383), (2, 0.05469926027581096), (3, 0.057737046387046576), (13, 0.059137852396816015), (11, 0.05940007232129574), (17, 0.06217828672379255), (0, 0.06406538188457489), (52, 0.06510608224198222), (1, 0.06674753688275814), (8, 0.07450554426759481), (10, 0.08078245911747217), (16, 0.08535271417349577), (12, 0.08918045833706856), (5, 0.1069024158641696), (36, 0.42928794771432877), (18, 0.5104473754763603), (53, 0.8012882173061371)]
computing accuracy for after removing block 43 . block score: 0.01971470331773162
removed block 43 current accuracy 0.944 loss from initial  0.007400000000000073
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.021201. All blocks and scores: [(46, 0.021200622664764524), (41, 0.021853588754311204), (40, 0.02322150836698711), (44, 0.02458550757728517), (21, 0.02481923927552998), (50, 0.024890620727092028), (22, 0.024919181130826473), (45, 0.024983394658192992), (49, 0.02509811893105507), (42, 0.02518813358619809), (48, 0.02582127321511507), (20, 0.027039861772209406), (27, 0.027715931180864573), (25, 0.029409070732071996), (47, 0.029454672010615468), (23, 0.029715127544477582), (38, 0.030990377767011523), (39, 0.031014059903100133), (24, 0.031359124230220914), (15, 0.032030435744673014), (19, 0.032537620048969984), (7, 0.03262687707319856), (37, 0.03773216251283884), (51, 0.04121669754385948), (9, 0.044216298032552004), (6, 0.046342866495251656), (4, 0.04656831035390496), (14, 0.04770289361476898), (2, 0.05469926120713353), (3, 0.057737046387046576), (13, 0.05913785193115473), (11, 0.05940007325261831), (17, 0.06217828765511513), (0, 0.06406538467854261), (52, 0.06472489424049854), (1, 0.06674753502011299), (8, 0.07450554706156254), (10, 0.08078245725482702), (16, 0.08535271510481834), (12, 0.08918046206235886), (5, 0.10690241679549217), (36, 0.42928793653845787), (18, 0.5104473754763603), (53, 0.8407818973064423)]
computing accuracy for after removing block 46 . block score: 0.021200622664764524
removed block 46 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.021854. All blocks and scores: [(41, 0.02185358921997249), (40, 0.023221507668495178), (44, 0.024585507810115814), (21, 0.024819239042699337), (22, 0.024919181363657117), (45, 0.024983394658192992), (50, 0.02509814826771617), (42, 0.025188132654875517), (49, 0.025732316775247455), (48, 0.02620172011666), (20, 0.02703986270353198), (27, 0.027715931413695216), (25, 0.029409069567918777), (23, 0.029715127544477582), (38, 0.030990378465503454), (39, 0.03101405967026949), (24, 0.03135912376455963), (47, 0.031557907117530704), (15, 0.03203043481335044), (19, 0.032537620048969984), (7, 0.03262687660753727), (37, 0.037732161581516266), (51, 0.041187895461916924), (9, 0.044216298032552004), (6, 0.04634286602959037), (4, 0.04656830942258239), (14, 0.04770289035513997), (2, 0.05469925981014967), (3, 0.05773704778403044), (13, 0.05913785193115473), (11, 0.05940007418394089), (17, 0.062178284395486116), (0, 0.06406538374722004), (52, 0.06454880489036441), (1, 0.06674753688275814), (8, 0.07450554706156254), (10, 0.08078245725482702), (16, 0.08535271510481834), (12, 0.08918045926839113), (5, 0.10690241400152445), (36, 0.4292879290878773), (18, 0.5104473754763603), (53, 0.9238725155591965)]
computing accuracy for after removing block 41 . block score: 0.02185358921997249
removed block 41 current accuracy 0.9354 loss from initial  0.016000000000000014
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 40, with score 0.023222. All blocks and scores: [(40, 0.023221508599817753), (50, 0.02474124706350267), (21, 0.024819239741191268), (22, 0.024919181130826473), (49, 0.025347873335704207), (45, 0.025350775569677353), (48, 0.025368160335347056), (42, 0.02555574430152774), (44, 0.025838940404355526), (20, 0.027039863169193268), (27, 0.027715931180864573), (25, 0.029409070732071996), (23, 0.029715128475800157), (38, 0.030990377767011523), (39, 0.031014059903100133), (24, 0.03135912539437413), (47, 0.031876168213784695), (15, 0.03203043481335044), (19, 0.03253761865198612), (7, 0.03262687614187598), (37, 0.03773216251283884), (51, 0.039568067993968725), (9, 0.04421629896387458), (6, 0.046342866495251656), (4, 0.046568311750888824), (14, 0.047702893149107695), (2, 0.05469925981014967), (3, 0.05773704592138529), (13, 0.05913785193115473), (11, 0.05940007418394089), (52, 0.06215495429933071), (17, 0.06217828532680869), (0, 0.06406538467854261), (1, 0.06674753874540329), (8, 0.07450554706156254), (10, 0.08078246004879475), (16, 0.08535271417349577), (12, 0.08918046113103628), (5, 0.10690241772681475), (36, 0.42928793281316757), (18, 0.5104473903775215), (53, 0.9972626566886902)]
computing accuracy for after removing block 40 . block score: 0.023221508599817753
removed block 40 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 50, with score 0.023717. All blocks and scores: [(50, 0.0237169002648443), (48, 0.024395477259531617), (42, 0.024499145802110434), (49, 0.024677225155755877), (21, 0.024819239741191268), (45, 0.024849170120432973), (22, 0.024919181829318404), (44, 0.026947352336719632), (20, 0.027039863169193268), (27, 0.027715931413695216), (25, 0.029409071197733283), (23, 0.02971512731164694), (38, 0.030990377767011523), (39, 0.031014059903100133), (24, 0.031359124230220914), (47, 0.03188395593315363), (15, 0.032030435279011726), (19, 0.03253761865198612), (7, 0.03262687660753727), (37, 0.03773216204717755), (51, 0.03884871769696474), (9, 0.04421629756689072), (6, 0.04634286602959037), (4, 0.04656831221655011), (14, 0.04770289361476898), (2, 0.05469925794750452), (3, 0.05773704685270786), (13, 0.0591378528624773), (11, 0.059400072786957026), (52, 0.06007756292819977), (17, 0.062178284861147404), (0, 0.06406538374722004), (1, 0.06674753688275814), (8, 0.07450554426759481), (10, 0.08078245911747217), (16, 0.08535271510481834), (12, 0.08918045926839113), (5, 0.1069024195894599), (36, 0.42928795143961906), (18, 0.5104473903775215), (53, 1.0939266681671143)]
computing accuracy for after removing block 50 . block score: 0.0237169002648443
removed block 50 current accuracy 0.923 loss from initial  0.02839999999999998
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 48, with score 0.024395. All blocks and scores: [(48, 0.024395477259531617), (42, 0.024499147199094296), (49, 0.02467722538858652), (21, 0.024819239508360624), (45, 0.02484917058609426), (22, 0.024919180432334542), (44, 0.0269473516382277), (20, 0.027039862470701337), (27, 0.027715931180864573), (25, 0.02940907026641071), (23, 0.029715127544477582), (38, 0.030990378465503454), (39, 0.031014059437438846), (24, 0.03135912446305156), (47, 0.03188395733013749), (15, 0.03203043481335044), (19, 0.03253762098029256), (7, 0.03262687660753727), (37, 0.03773216204717755), (51, 0.041177763137966394), (9, 0.04421629663556814), (6, 0.04634286556392908), (4, 0.04656831128522754), (14, 0.04770289221778512), (2, 0.05469926027581096), (3, 0.057737048249691725), (13, 0.059137852396816015), (11, 0.059400071389973164), (17, 0.06217828346416354), (0, 0.06406538281589746), (1, 0.06674753967672586), (52, 0.06709681358188391), (8, 0.07450554426759481), (10, 0.0807824581861496), (16, 0.08535271510481834), (12, 0.08918046019971371), (5, 0.1069024195894599), (36, 0.42928794026374817), (18, 0.5104473754763603), (53, 1.2828717082738876)]
computing accuracy for after removing block 48 . block score: 0.024395477259531617
removed block 48 current accuracy 0.9114 loss from initial  0.040000000000000036
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.024499. All blocks and scores: [(42, 0.024499145802110434), (21, 0.024819239508360624), (45, 0.024849171051755548), (22, 0.02491918089799583), (44, 0.026947351871058345), (20, 0.02703986200504005), (27, 0.027715931413695216), (49, 0.027919125044718385), (25, 0.02940907096490264), (23, 0.029715128242969513), (38, 0.030990377068519592), (39, 0.031014059903100133), (24, 0.03135912516154349), (47, 0.03188395593315363), (15, 0.03203043434768915), (19, 0.03253761911764741), (7, 0.03262687707319856), (37, 0.03773216297850013), (51, 0.041466363705694675), (9, 0.04421629849821329), (6, 0.04634286696091294), (4, 0.04656831128522754), (14, 0.04770289268344641), (2, 0.05469926027581096), (3, 0.05773704685270786), (13, 0.05913785193115473), (11, 0.05940007325261831), (17, 0.06217828672379255), (0, 0.06406538467854261), (1, 0.06674753595143557), (8, 0.07450554613023996), (52, 0.07601085770875216), (10, 0.08078245911747217), (16, 0.08535271603614092), (12, 0.08918045833706856), (5, 0.10690241679549217), (36, 0.42928794398903847), (18, 0.5104473754763603), (53, 1.3964715749025345)]
computing accuracy for after removing block 42 . block score: 0.024499145802110434
removed block 42 current accuracy 0.9074 loss from initial  0.04400000000000004
since last training loss: 0.03980000000000006 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.024819. All blocks and scores: [(21, 0.024819239042699337), (22, 0.02491918089799583), (45, 0.025808801874518394), (20, 0.027039862470701337), (27, 0.02771593094803393), (44, 0.028270078590139747), (49, 0.028358538169413805), (25, 0.029409070499241352), (23, 0.029715127078816295), (38, 0.030990378465503454), (39, 0.03101405967026949), (24, 0.03135912446305156), (15, 0.03203043481335044), (19, 0.03253761911764741), (7, 0.03262687521055341), (47, 0.03265232313424349), (37, 0.03773216204717755), (51, 0.0409846561960876), (9, 0.04421629849821329), (6, 0.04634286789223552), (4, 0.046568311750888824), (14, 0.047702891286462545), (2, 0.05469925934448838), (3, 0.05773704685270786), (13, 0.05913785332813859), (11, 0.059400072786957026), (17, 0.06217828532680869), (0, 0.06406538467854261), (1, 0.06674753781408072), (8, 0.07450554240494967), (52, 0.07604406401515007), (10, 0.0807824581861496), (16, 0.08535271417349577), (12, 0.08918045833706856), (5, 0.1069024158641696), (36, 0.42928794026374817), (18, 0.5104473829269409), (53, 1.4492790699005127)]
computing accuracy for after removing block 21 . block score: 0.024819239042699337
removed block 21 current accuracy 0.9016 loss from initial  0.049800000000000066
since last training loss: 0.045600000000000085 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.023218. All blocks and scores: [(22, 0.023218376096338034), (45, 0.024885511491447687), (44, 0.02628146018832922), (27, 0.026482511311769485), (20, 0.027039862237870693), (49, 0.027112943353131413), (23, 0.027793490327894688), (24, 0.02820776030421257), (25, 0.028210877208039165), (38, 0.029476615600287914), (39, 0.029911647317931056), (47, 0.03114619478583336), (15, 0.0320304362103343), (19, 0.03253761865198612), (7, 0.03262687660753727), (37, 0.03621285920962691), (51, 0.03899016231298447), (9, 0.04421629756689072), (6, 0.04634286556392908), (4, 0.04656831035390496), (14, 0.04770289082080126), (2, 0.05469925981014967), (3, 0.05773704778403044), (13, 0.05913785379379988), (11, 0.0594000737182796), (17, 0.06217828532680869), (0, 0.06406538281589746), (1, 0.06674753874540329), (52, 0.06832395773380995), (8, 0.07450554613023996), (10, 0.0807824581861496), (16, 0.0853527169674635), (12, 0.08918045740574598), (5, 0.1069024158641696), (36, 0.40635673701763153), (18, 0.5104473680257797), (53, 1.475104495882988)]
computing accuracy for after removing block 22 . block score: 0.023218376096338034
removed block 22 current accuracy 0.8882 loss from initial  0.06320000000000003
training start
training epoch 0 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 1 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.1]
training epoch 2 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 3 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 4 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 5 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.1]
training epoch 6 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.1]
training epoch 7 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.1]
training epoch 8 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 9 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.022035. All blocks and scores: [(49, 0.022035041358321905), (45, 0.02735393587499857), (27, 0.027361231623217463), (25, 0.03013864648528397), (23, 0.031121544307097793), (47, 0.031192137161269784), (19, 0.032257164362818), (15, 0.03239619079977274), (7, 0.03276418661698699), (24, 0.03280356386676431), (44, 0.032967147417366505), (20, 0.03809866635128856), (38, 0.040216921363025904), (39, 0.04133136384189129), (9, 0.043614184483885765), (51, 0.04409006563946605), (4, 0.046186058316379786), (6, 0.04678775742650032), (14, 0.04787643952295184), (37, 0.04984165774658322), (2, 0.05465289019048214), (3, 0.05790186207741499), (13, 0.05916122393682599), (11, 0.05979799944907427), (17, 0.06245254958048463), (0, 0.06407747603952885), (1, 0.06726986356079578), (52, 0.068504155613482), (8, 0.07477839849889278), (10, 0.08163511846214533), (16, 0.08585725072771311), (12, 0.09098370280116796), (5, 0.10742342099547386), (18, 0.3248751647770405), (36, 0.4372967816889286), (53, 0.8239196464419365)]
computing accuracy for after removing block 49 . block score: 0.022035041358321905
removed block 49 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.027354. All blocks and scores: [(45, 0.027353935642167926), (27, 0.027361232321709394), (25, 0.030138647183775902), (23, 0.031121545005589724), (47, 0.03119213692843914), (19, 0.03225716482847929), (15, 0.03239619079977274), (7, 0.03276418708264828), (24, 0.03280356386676431), (44, 0.03296714695170522), (20, 0.03809866541996598), (38, 0.04021691996604204), (39, 0.041331364307552576), (9, 0.04361418355256319), (51, 0.046118454076349735), (4, 0.04618605924770236), (6, 0.04678775789216161), (14, 0.0478764409199357), (37, 0.04984165774658322), (2, 0.054652889259159565), (3, 0.05790186207741499), (13, 0.05916122207418084), (11, 0.059797999914735556), (17, 0.06245254771783948), (0, 0.0640774741768837), (1, 0.06726986262947321), (8, 0.07477839943021536), (52, 0.08086321596056223), (10, 0.08163512125611305), (16, 0.08585725259035826), (12, 0.09098370186984539), (5, 0.10742342658340931), (18, 0.3248751610517502), (36, 0.4372967705130577), (53, 0.9079135879874229)]
computing accuracy for after removing block 45 . block score: 0.027353935642167926
removed block 45 current accuracy 0.922 loss from initial  0.02939999999999998
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 27, with score 0.027361. All blocks and scores: [(27, 0.027361232321709394), (25, 0.030138647416606545), (23, 0.031121545238420367), (19, 0.032257163897156715), (15, 0.032396191731095314), (7, 0.032764187548309565), (24, 0.032803564332425594), (44, 0.03296714695170522), (47, 0.03472874779254198), (20, 0.038098666816949844), (38, 0.040216921363025904), (39, 0.04133136384189129), (9, 0.04361418215557933), (51, 0.044463520403951406), (4, 0.04618605924770236), (6, 0.04678775742650032), (14, 0.047876440454274416), (37, 0.04984165821224451), (2, 0.05465288972482085), (3, 0.05790186068043113), (13, 0.0591612234711647), (11, 0.059797999914735556), (17, 0.06245254725217819), (0, 0.06407747510820627), (1, 0.06726986262947321), (8, 0.07477839943021536), (52, 0.08105793967843056), (10, 0.0816351193934679), (16, 0.08585725259035826), (12, 0.09098370093852282), (5, 0.10742342378944159), (18, 0.3248751685023308), (36, 0.4372967779636383), (53, 1.0445890426635742)]
computing accuracy for after removing block 27 . block score: 0.027361232321709394
removed block 27 current accuracy 0.9158 loss from initial  0.035600000000000076
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.030139. All blocks and scores: [(25, 0.030138646252453327), (23, 0.03112154547125101), (19, 0.03225716482847929), (15, 0.03239619126543403), (44, 0.032584324944764376), (7, 0.03276418801397085), (24, 0.03280356340110302), (47, 0.03311436017975211), (20, 0.038098664954304695), (38, 0.03905565803870559), (39, 0.040829659439623356), (51, 0.04259810829535127), (9, 0.04361418355256319), (4, 0.04618605878204107), (6, 0.04678775742650032), (14, 0.04787644138559699), (37, 0.05069319624453783), (2, 0.05465288879349828), (3, 0.05790186068043113), (13, 0.05916122253984213), (11, 0.05979799944907427), (17, 0.06245254818350077), (0, 0.06407747324556112), (1, 0.06726986262947321), (52, 0.07439698465168476), (8, 0.07477839943021536), (10, 0.08163512125611305), (16, 0.08585725259035826), (12, 0.09098370093852282), (5, 0.10742342565208673), (18, 0.3248751722276211), (36, 0.43475568294525146), (53, 1.0804965049028397)]
computing accuracy for after removing block 25 . block score: 0.030138646252453327
removed block 25 current accuracy 0.8898 loss from initial  0.06159999999999999
since last training loss: 0.05479999999999996 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.031122. All blocks and scores: [(23, 0.031121545238420367), (47, 0.03211269387975335), (19, 0.03225716482847929), (15, 0.032396191731095314), (7, 0.032764187548309565), (24, 0.03280356293544173), (44, 0.03330006496980786), (20, 0.03809866635128856), (38, 0.038946802262216806), (51, 0.04109878931194544), (39, 0.042608929332345724), (9, 0.043614182621240616), (4, 0.046186058316379786), (6, 0.046787756495177746), (14, 0.0478764409199357), (37, 0.053041400387883186), (2, 0.054652889259159565), (3, 0.05790186207741499), (13, 0.05916122440248728), (11, 0.05979800038039684), (17, 0.06245254958048463), (0, 0.06407747697085142), (1, 0.06726986356079578), (52, 0.07058083545416594), (8, 0.07477840036153793), (10, 0.08163512125611305), (16, 0.08585725259035826), (12, 0.09098370373249054), (5, 0.10742342192679644), (18, 0.3248751647770405), (36, 0.4456217736005783), (53, 1.1030955761671066)]
computing accuracy for after removing block 23 . block score: 0.031121545238420367
removed block 23 current accuracy 0.8488 loss from initial  0.10260000000000002
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.029455. All blocks and scores: [(24, 0.029455282725393772), (19, 0.03225716529414058), (15, 0.03239619126543403), (47, 0.03239667369052768), (7, 0.03276418661698699), (44, 0.034841279964894056), (20, 0.03809866635128856), (38, 0.04062147019430995), (51, 0.042026082053780556), (9, 0.04361418401822448), (4, 0.04618605878204107), (39, 0.04624030878767371), (6, 0.04678775789216161), (14, 0.0478764409199357), (2, 0.05465288879349828), (3, 0.05790186207741499), (13, 0.05916122393682599), (11, 0.05979800084605813), (17, 0.06245254958048463), (0, 0.06407747697085142), (37, 0.06503519974648952), (1, 0.06726986356079578), (52, 0.06995125021785498), (8, 0.07477839849889278), (10, 0.0816351231187582), (16, 0.08585725352168083), (12, 0.09098370186984539), (5, 0.10742342472076416), (18, 0.3248751722276211), (36, 0.4956774078309536), (53, 1.0977713912725449)]
computing accuracy for after removing block 24 . block score: 0.029455282725393772
removed block 24 current accuracy 0.7764 loss from initial  0.17500000000000004
since last training loss: 0.16820000000000002 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.031194. All blocks and scores: [(47, 0.03119350248016417), (19, 0.03225716482847929), (15, 0.03239619079977274), (7, 0.03276418801397085), (44, 0.033968762028962374), (20, 0.03809866588562727), (38, 0.040687103755772114), (51, 0.04078460857272148), (9, 0.0436141830869019), (39, 0.04600782925263047), (4, 0.046186060179024935), (6, 0.04678775742650032), (14, 0.04787644138559699), (2, 0.054652889259159565), (3, 0.0579018616117537), (13, 0.05916122253984213), (11, 0.05979800038039684), (17, 0.06245254818350077), (52, 0.06253152852877975), (0, 0.064077477902174), (37, 0.06678466498851776), (1, 0.06726986076682806), (8, 0.07477839849889278), (10, 0.0816351231187582), (16, 0.08585725072771311), (12, 0.09098370280116796), (5, 0.10742342378944159), (18, 0.3248751685023308), (36, 0.5083277970552444), (53, 1.1525119692087173)]
computing accuracy for after removing block 47 . block score: 0.03119350248016417
removed block 47 current accuracy 0.6852 loss from initial  0.2662
since last training loss: 0.25939999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 19, with score 0.032257. All blocks and scores: [(19, 0.032257164362818), (15, 0.032396191731095314), (7, 0.032764187548309565), (44, 0.033968762028962374), (20, 0.038098664954304695), (38, 0.04068710282444954), (51, 0.0420036930590868), (9, 0.04361418401822448), (39, 0.04600782971829176), (4, 0.04618605924770236), (6, 0.04678775696083903), (14, 0.04787643952295184), (2, 0.054652889259159565), (3, 0.05790186021476984), (13, 0.05916122253984213), (11, 0.059797998517751694), (17, 0.06245254725217819), (0, 0.06407747510820627), (37, 0.06678466685116291), (1, 0.06726986262947321), (52, 0.07234359439462423), (8, 0.07477840036153793), (10, 0.08163512218743563), (16, 0.08585725259035826), (12, 0.09098370280116796), (5, 0.10742342285811901), (18, 0.3248751610517502), (36, 0.508327804505825), (53, 1.2578256279230118)]
computing accuracy for after removing block 19 . block score: 0.032257164362818
removed block 19 current accuracy 0.6612 loss from initial  0.2902
since last training loss: 0.2834 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.032123. All blocks and scores: [(44, 0.03212269814684987), (15, 0.03239619126543403), (7, 0.03276418661698699), (20, 0.037063040770590305), (38, 0.039060702081769705), (51, 0.04123692959547043), (9, 0.0436141830869019), (4, 0.04618605971336365), (39, 0.04663596395403147), (6, 0.046787756495177746), (14, 0.04787643998861313), (2, 0.054652889259159565), (3, 0.057901863008737564), (13, 0.05916122207418084), (11, 0.05979799944907427), (17, 0.06245254771783948), (37, 0.06360095739364624), (0, 0.06407747510820627), (52, 0.0659742346033454), (1, 0.06726986262947321), (8, 0.07477839756757021), (10, 0.08163511846214533), (16, 0.08585724886506796), (12, 0.09098370373249054), (5, 0.10742342099547386), (18, 0.3248751647770405), (36, 0.48796841874718666), (53, 1.2992473989725113)]
computing accuracy for after removing block 44 . block score: 0.03212269814684987
removed block 44 current accuracy 0.5956 loss from initial  0.3558
training start
training epoch 0 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 1 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.1]
training epoch 2 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 3 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 4 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 5 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.1]
training epoch 6 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 7 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 8 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 9 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 10 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.031971. All blocks and scores: [(15, 0.03197126369923353), (7, 0.032454980071634054), (9, 0.043853068724274635), (51, 0.045970498118549585), (6, 0.04661934170871973), (14, 0.047778424341231585), (4, 0.04962913319468498), (2, 0.05490010138601065), (3, 0.057963219471275806), (13, 0.059228767175227404), (11, 0.05970542738214135), (0, 0.0627979077398777), (1, 0.0668414793908596), (52, 0.06994071882218122), (8, 0.07400922011584044), (17, 0.07472999300807714), (39, 0.07486170902848244), (38, 0.0750775970518589), (10, 0.08083468861877918), (12, 0.09015920478850603), (16, 0.09229916706681252), (37, 0.10107220709323883), (5, 0.10556362196803093), (20, 0.16802196204662323), (36, 0.43340256065130234), (18, 0.5946149006485939), (53, 0.8217925578355789)]
computing accuracy for after removing block 15 . block score: 0.03197126369923353
removed block 15 current accuracy 0.9292 loss from initial  0.022199999999999998
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 7, with score 0.032455. All blocks and scores: [(7, 0.032454980071634054), (9, 0.04385306825861335), (51, 0.045824585016816854), (6, 0.04661934310570359), (14, 0.04777842480689287), (4, 0.04962913366034627), (2, 0.05490010092034936), (3, 0.05796322086825967), (13, 0.05922876624390483), (11, 0.05970542738214135), (0, 0.06279790494590998), (1, 0.06684148032218218), (52, 0.0696017611771822), (17, 0.07381049171090126), (8, 0.07400921918451786), (38, 0.07419744692742825), (39, 0.07485036551952362), (10, 0.08083469048142433), (12, 0.09015920758247375), (16, 0.09589495696127415), (37, 0.10396689642220736), (5, 0.10556361824274063), (20, 0.15479743480682373), (36, 0.4283177927136421), (18, 0.5809702575206757), (53, 0.8249123468995094)]
computing accuracy for after removing block 7 . block score: 0.032454980071634054
removed block 7 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043736. All blocks and scores: [(9, 0.04373597167432308), (14, 0.044169443659484386), (51, 0.044439406134188175), (6, 0.04661934124305844), (4, 0.04962913133203983), (13, 0.05140243377536535), (2, 0.054900103248655796), (11, 0.056431992910802364), (3, 0.05796322086825967), (0, 0.06279790587723255), (17, 0.06522301118820906), (52, 0.06640054006129503), (1, 0.06684148032218218), (8, 0.07190746534615755), (39, 0.07367741409689188), (38, 0.07467870600521564), (10, 0.08322246000170708), (12, 0.08424010872840881), (16, 0.0849222308024764), (37, 0.09506195038557053), (5, 0.10556362103670835), (20, 0.14869685284793377), (36, 0.413395207375288), (18, 0.5529383718967438), (53, 0.8414328619837761)]
computing accuracy for after removing block 9 . block score: 0.04373597167432308
removed block 9 current accuracy 0.9088 loss from initial  0.04259999999999997
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.040107. All blocks and scores: [(14, 0.04010666813701391), (51, 0.041741670574992895), (6, 0.046619342640042305), (13, 0.048719524405896664), (4, 0.04962913179770112), (11, 0.0521652908064425), (2, 0.05490010045468807), (17, 0.057848733849823475), (3, 0.05796322226524353), (52, 0.06076786946505308), (0, 0.06279790634289384), (1, 0.06684148125350475), (16, 0.07057873345911503), (39, 0.0718940980732441), (8, 0.07190746534615755), (12, 0.07244120165705681), (38, 0.07338311150670052), (37, 0.08059810847043991), (10, 0.0816462729126215), (5, 0.10556362010538578), (20, 0.1426478773355484), (36, 0.3790545277297497), (18, 0.5329007655382156), (53, 0.8636933043599129)]
computing accuracy for after removing block 14 . block score: 0.04010666813701391
removed block 14 current accuracy 0.8914 loss from initial  0.06000000000000005
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.041048. All blocks and scores: [(51, 0.04104799451306462), (6, 0.046619342640042305), (13, 0.04871952487155795), (4, 0.04962913319468498), (11, 0.0521652908064425), (2, 0.05490010092034936), (17, 0.05597278010100126), (3, 0.05796321900561452), (52, 0.058051133528351784), (0, 0.0627979077398777), (1, 0.06684147845953703), (39, 0.07140761986374855), (8, 0.07190746441483498), (38, 0.07227835897356272), (12, 0.07244120165705681), (10, 0.0816462766379118), (37, 0.08195553813129663), (16, 0.08792806230485439), (5, 0.10556362010538578), (20, 0.1325452346354723), (36, 0.3764348365366459), (18, 0.530148096382618), (53, 0.8623457252979279)]
computing accuracy for after removing block 51 . block score: 0.04104799451306462
removed block 51 current accuracy 0.788 loss from initial  0.1634
since last training loss: 0.14559999999999995 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 6, with score 0.046619. All blocks and scores: [(6, 0.04661934170871973), (13, 0.04871952626854181), (4, 0.049629132729023695), (11, 0.052165291737765074), (2, 0.05490010231733322), (52, 0.05582511378452182), (17, 0.0559727787040174), (3, 0.057963219936937094), (0, 0.0627979077398777), (1, 0.06684148032218218), (39, 0.07140761893242598), (8, 0.07190746441483498), (38, 0.07227835804224014), (12, 0.07244120072573423), (10, 0.0816462766379118), (37, 0.08195553626865149), (16, 0.0879280585795641), (5, 0.10556361824274063), (20, 0.13254523277282715), (36, 0.3764348439872265), (18, 0.530148096382618), (53, 1.1063091605901718)]
computing accuracy for after removing block 6 . block score: 0.04661934170871973
removed block 6 current accuracy 0.6816 loss from initial  0.26980000000000004
since last training loss: 0.252 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 13, with score 0.045889. All blocks and scores: [(13, 0.04588858596980572), (11, 0.04772029863670468), (4, 0.04962913226336241), (52, 0.05127068003639579), (17, 0.05244757002219558), (2, 0.05490010092034936), (3, 0.05796322040259838), (0, 0.0627979077398777), (1, 0.06684148125350475), (12, 0.06752460263669491), (39, 0.06988410465419292), (16, 0.07025587651878595), (8, 0.07096877414733171), (38, 0.07099429424852133), (37, 0.08089551609009504), (10, 0.08541021402925253), (5, 0.10556361824274063), (20, 0.12245615664869547), (36, 0.3726366423070431), (18, 0.5173610001802444), (53, 1.1164203882217407)]
computing accuracy for after removing block 13 . block score: 0.04588858596980572
removed block 13 current accuracy 0.5746 loss from initial  0.3768
since last training loss: 0.359 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 52, with score 0.046735. All blocks and scores: [(52, 0.046735013369470835), (11, 0.04772029863670468), (4, 0.04962913319468498), (2, 0.054900101851671934), (17, 0.056123966351151466), (3, 0.057963219936937094), (0, 0.06279790587723255), (1, 0.0668414793908596), (12, 0.06752460077404976), (39, 0.06776329223066568), (38, 0.06868078093975782), (8, 0.07096877321600914), (16, 0.07885046862065792), (37, 0.08097733184695244), (10, 0.08541021402925253), (5, 0.10556362103670835), (20, 0.11678065173327923), (36, 0.3627059906721115), (18, 0.5326172485947609), (53, 1.1592969000339508)]
computing accuracy for after removing block 52 . block score: 0.046735013369470835
removed block 52 current accuracy 0.4782 loss from initial  0.4732
since last training loss: 0.45539999999999997 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 11, with score 0.047720. All blocks and scores: [(11, 0.04772029723972082), (4, 0.04962913226336241), (2, 0.05490010138601065), (17, 0.05612396588549018), (3, 0.057963219471275806), (0, 0.06279790680855513), (1, 0.0668414793908596), (12, 0.06752460077404976), (39, 0.06776329129934311), (38, 0.06868078000843525), (8, 0.07096877321600914), (16, 0.07885046862065792), (37, 0.08097733184695244), (10, 0.08541021309792995), (5, 0.10556362010538578), (20, 0.11678065452724695), (36, 0.3627059906721115), (18, 0.5326172634959221), (53, 0.9454168975353241)]
computing accuracy for after removing block 11 . block score: 0.04772029723972082
removed block 11 current accuracy 0.4414 loss from initial  0.51
since last training loss: 0.49219999999999997 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 4, with score 0.049629. All blocks and scores: [(4, 0.04962913226336241), (17, 0.050429655238986015), (2, 0.054900103248655796), (16, 0.05674727074801922), (12, 0.057370062451809645), (3, 0.05796321853995323), (0, 0.06279790494590998), (1, 0.06684148032218218), (38, 0.06813312508165836), (39, 0.06951630301773548), (8, 0.07096877321600914), (37, 0.07717423420399427), (10, 0.08541021309792995), (5, 0.10556361731141806), (20, 0.11332266218960285), (36, 0.35676997527480125), (18, 0.5648732855916023), (53, 0.9905488789081573)]
computing accuracy for after removing block 4 . block score: 0.04962913226336241
removed block 4 current accuracy 0.3934 loss from initial  0.558
since last training loss: 0.5402 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 17, with score 0.050393. All blocks and scores: [(17, 0.05039320467039943), (16, 0.05061612091958523), (2, 0.05490010138601065), (3, 0.057963219471275806), (12, 0.05838127713650465), (0, 0.06279790587723255), (1, 0.06684148032218218), (38, 0.06785552855581045), (39, 0.06824605632573366), (8, 0.07731096353381872), (37, 0.08085962850600481), (10, 0.08711754344403744), (5, 0.11010775528848171), (20, 0.1130585502833128), (36, 0.359555259346962), (18, 0.5906205773353577), (53, 0.9933128654956818)]
computing accuracy for after removing block 17 . block score: 0.05039320467039943
removed block 17 current accuracy 0.3772 loss from initial  0.5742
since last training loss: 0.5564 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 16, with score 0.050616. All blocks and scores: [(16, 0.0506161218509078), (2, 0.05490010045468807), (3, 0.057963219936937094), (12, 0.0583812789991498), (0, 0.06279790727421641), (39, 0.06522189453244209), (38, 0.06589566543698311), (1, 0.06684147845953703), (8, 0.07731096632778645), (37, 0.08205008506774902), (10, 0.08711754344403744), (5, 0.11010775808244944), (20, 0.11032711435109377), (36, 0.34662283957004547), (18, 0.5753127261996269), (53, 0.9662283062934875)]
computing accuracy for after removing block 16 . block score: 0.0506161218509078
removed block 16 current accuracy 0.3142 loss from initial  0.6372
training start
training epoch 0 val accuracy 0.859 topk_dict {'top1': 0.859} is_best True lr [0.1]
training epoch 1 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.1]
training epoch 2 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 3 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 4 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.1]
training epoch 5 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 6 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 7 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 8 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 9 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 10 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.931600)
finished training. finished 50 epochs. accuracy 0.9316 topk_dict {'top1': 0.9316}
