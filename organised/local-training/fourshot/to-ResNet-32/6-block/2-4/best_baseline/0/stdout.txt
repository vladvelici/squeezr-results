start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589383974671), (30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.013294660835526884), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.022078295471146703), (23, 0.02222871594130993), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749591084197164), (45, 0.023975494550541043), (21, 0.024941089330241084), (48, 0.024957707151770592), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.025916648795828223), (42, 0.02623223257251084), (20, 0.026848892448469996), (47, 0.028632948640733957), (38, 0.03134434320963919), (39, 0.03144129551947117), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077723249793), (37, 0.03791803168132901), (51, 0.041787585243582726), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.054577403236180544), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986480653286), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019852687371894717), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.02222871477715671), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540216429159045), (50, 0.02477082284167409), (21, 0.024941090028733015), (22, 0.02515139034949243), (49, 0.025575740030035377), (24, 0.025880582630634308), (42, 0.025893412297591567), (20, 0.026848891284316778), (47, 0.028072759741917253), (38, 0.031091187614947557), (39, 0.03119136136956513), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03797321068122983), (51, 0.041271014139056206), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464833632112), (52, 0.0649335184134543), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117433071136475), (53, 0.8063970282673836)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.01023258175700903), (34, 0.012758882250636816), (29, 0.013421116746030748), (35, 0.01591842109337449), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022797234356403), (43, 0.01985046500340104), (46, 0.02041191654279828), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.023602578788995743), (45, 0.023770849220454693), (48, 0.024519872618839145), (50, 0.024639350827783346), (21, 0.02494109026156366), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.02571221999824047), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.028052504872903228), (38, 0.0309358739759773), (39, 0.03117303573526442), (15, 0.032058386132121086), (7, 0.03244550386443734), (19, 0.03254077956080437), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441722810268402), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350203089416027), (18, 0.5117432922124863), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159612298012), (29, 0.013421116746030748), (35, 0.015918648801743984), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867350114509463), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.02300137630663812), (40, 0.023739926982671022), (45, 0.02379016764461994), (48, 0.024350045016035438), (50, 0.02446310524828732), (21, 0.02494108909741044), (22, 0.0251513896510005), (49, 0.02524693077430129), (42, 0.02527355100028217), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.027727574110031128), (38, 0.03074627509340644), (39, 0.03128179511986673), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.040824799332767725), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144285041838884), (11, 0.059700032230466604), (17, 0.061325252521783113), (0, 0.06337464740499854), (52, 0.06356756389141083), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4377693049609661), (18, 0.5117432996630669), (53, 0.8228829354047775)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116513200104), (35, 0.015968912513926625), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01983700878918171), (46, 0.020137187326326966), (41, 0.0215840560849756), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.022687324788421392), (40, 0.023569098208099604), (45, 0.023840721463784575), (48, 0.024108358891680837), (50, 0.02411420992575586), (49, 0.024870117427781224), (21, 0.024941088631749153), (42, 0.02504557464271784), (22, 0.025151389883831143), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02742385258898139), (38, 0.030735648702830076), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.03244550386443734), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.04034593887627125), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.06270107859745622), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299120724201), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143420040607), (36, 0.43692686408758163), (18, 0.5117432922124863), (53, 0.8283700942993164)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421117211692035), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302684046328068), (46, 0.020324197597801685), (41, 0.02196270227432251), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02304507768712938), (48, 0.024024547077715397), (50, 0.02409697277471423), (40, 0.024156817002221942), (45, 0.024168409407138824), (49, 0.024922372307628393), (21, 0.024941089330241084), (22, 0.025151390582323074), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02756829489953816), (38, 0.0317872641608119), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.040690730791538954), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772257208824), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525345310569), (52, 0.06221094960346818), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.44933702424168587), (18, 0.5117432922124863), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421117211692035
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370510682463646), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019856704166159034), (46, 0.01998897618614137), (41, 0.021256206091493368), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022692033322528005), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616240359842777), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.024941088864579797), (22, 0.025151390815153718), (24, 0.025880582397803664), (47, 0.026813455624505877), (20, 0.026848891749978065), (38, 0.031083731446415186), (39, 0.03205688949674368), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.03907974902540445), (37, 0.0401521441526711), (9, 0.043376325629651546), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.0597000359557569), (52, 0.0603690748102963), (17, 0.061325255781412125), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432996630669), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.016986022237688303), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700076896697283), (41, 0.02051579882390797), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02250757161527872), (48, 0.022899368777871132), (50, 0.022937727393582463), (40, 0.023057401180267334), (42, 0.023520408663898706), (45, 0.02363369963131845), (49, 0.024081918876618147), (21, 0.02494108979590237), (22, 0.025151390582323074), (24, 0.025880583096295595), (47, 0.026322792284190655), (20, 0.02684889198280871), (38, 0.03014914900995791), (39, 0.031466696644201875), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.03785192919895053), (37, 0.039268902502954006), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789771977812052), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992780536413), (52, 0.058468119241297245), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43490003049373627), (18, 0.5117432996630669), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986022237688303), (43, 0.01838199095800519), (27, 0.018769708462059498), (46, 0.018842301797121763), (41, 0.019016370410099626), (48, 0.02130915760062635), (50, 0.021624520886689425), (44, 0.021748854545876384), (40, 0.021916967583820224), (42, 0.0219303744379431), (25, 0.022078295005485415), (23, 0.02222871594130993), (45, 0.022736449260264635), (49, 0.0229700633790344), (21, 0.024941089563071728), (22, 0.025151389883831143), (47, 0.025355831487104297), (24, 0.025880582397803664), (20, 0.026848891749978065), (38, 0.02869188762269914), (39, 0.029624431394040585), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.036016357596963644), (37, 0.03643036866560578), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740416750312), (52, 0.05466857831925154), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.0613252529874444), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.41641608625650406), (18, 0.5117432996630669), (53, 0.8948248848319054)]
computing accuracy for after removing block 28 . block score: 0.016986022237688303
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.1]
training epoch 1 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 2 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 3 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.1]
training epoch 4 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.1]
training epoch 5 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.1]
training epoch 6 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.1]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.1]
training epoch 8 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.1]
training epoch 9 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.1]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 11 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 9
[activation diff]: block to remove picked: 39, with score 0.013930. All blocks and scores: [(39, 0.01393044856376946), (38, 0.016393372090533376), (46, 0.02186346100643277), (43, 0.021925293607637286), (37, 0.022380251670256257), (23, 0.022391883190721273), (25, 0.02430643211118877), (41, 0.024470353964716196), (21, 0.025015684077516198), (45, 0.02509143715724349), (44, 0.025315376929938793), (22, 0.025352695723995566), (27, 0.02584315137937665), (48, 0.02588394470512867), (50, 0.025916401762515306), (49, 0.02628599898889661), (40, 0.02712475322186947), (20, 0.027175214141607285), (42, 0.02805941621772945), (47, 0.029474194161593914), (24, 0.03184296004474163), (15, 0.03206431306898594), (19, 0.032593329437077045), (7, 0.032621316611766815), (51, 0.041588013991713524), (9, 0.0440373164601624), (6, 0.04704805975779891), (4, 0.047886624932289124), (14, 0.047949112951755524), (2, 0.05491739930585027), (3, 0.05827117990702391), (13, 0.05958371423184872), (11, 0.05992968287318945), (17, 0.06213824637234211), (0, 0.06407807860523462), (52, 0.06639349274337292), (1, 0.06646822951734066), (8, 0.07527044415473938), (10, 0.08144836407154799), (16, 0.0849558049812913), (12, 0.09109003748744726), (5, 0.10684997495263815), (36, 0.44265390560030937), (18, 0.5154022350907326), (53, 0.8042503520846367)]
computing accuracy for after removing block 39 . block score: 0.01393044856376946
removed block 39 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 38, with score 0.016393. All blocks and scores: [(38, 0.016393372090533376), (43, 0.02059649070724845), (46, 0.0214506508782506), (37, 0.02238025260157883), (23, 0.022391883190721273), (41, 0.023888714844360948), (25, 0.02430643211118877), (45, 0.02435076399706304), (50, 0.02459844248369336), (48, 0.02463710238225758), (21, 0.025015683844685555), (44, 0.025212303502485156), (22, 0.025352695025503635), (49, 0.025664119282737374), (27, 0.025843150913715363), (40, 0.02670267689973116), (42, 0.02685748040676117), (20, 0.027175213675945997), (47, 0.02911383891478181), (24, 0.03184296051040292), (15, 0.032064314000308514), (19, 0.03259332850575447), (7, 0.03262131800875068), (51, 0.04128888715058565), (9, 0.04403731506317854), (6, 0.047048060689121485), (4, 0.04788662539795041), (14, 0.047949114348739386), (2, 0.05491740070283413), (3, 0.05827117944136262), (13, 0.05958371143788099), (11, 0.05992968333885074), (17, 0.06213824450969696), (0, 0.0640780795365572), (52, 0.06449784338474274), (1, 0.06646822765469551), (8, 0.07527044415473938), (10, 0.08144836034625769), (16, 0.08495580218732357), (12, 0.09109003935009241), (5, 0.10684997402131557), (36, 0.4426538869738579), (18, 0.515402227640152), (53, 0.8512289971113205)]
computing accuracy for after removing block 38 . block score: 0.016393372090533376
removed block 38 current accuracy 0.9348 loss from initial  0.01660000000000006
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019694. All blocks and scores: [(43, 0.019693864742293954), (46, 0.020518841920420527), (37, 0.0223802519030869), (23, 0.022391883889213204), (50, 0.02303090807981789), (48, 0.02305453340522945), (45, 0.02307537035085261), (41, 0.023466475773602724), (25, 0.024306431878358126), (49, 0.024422271642833948), (44, 0.024900840828195214), (21, 0.02501568221487105), (22, 0.025352695723995566), (27, 0.02584315137937665), (42, 0.025905561866238713), (40, 0.0268153368961066), (20, 0.02717521321028471), (47, 0.02733224956318736), (24, 0.03184295957908034), (15, 0.03206431306898594), (19, 0.03259333036839962), (7, 0.032621316611766815), (51, 0.04030490014702082), (9, 0.044037315994501114), (6, 0.04704806208610535), (4, 0.04788662353530526), (14, 0.0479491138830781), (2, 0.05491740256547928), (3, 0.05827118223533034), (13, 0.059583712834864855), (11, 0.05992968240752816), (52, 0.061239649541676044), (17, 0.062138247303664684), (0, 0.0640780795365572), (1, 0.06646823137998581), (8, 0.07527044415473938), (10, 0.08144836127758026), (16, 0.08495580311864614), (12, 0.09109003748744726), (5, 0.10684997402131557), (36, 0.4426538981497288), (18, 0.5154022350907326), (53, 0.8821156248450279)]
computing accuracy for after removing block 43 . block score: 0.019693864742293954
removed block 43 current accuracy 0.9336 loss from initial  0.017800000000000038
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.021329. All blocks and scores: [(46, 0.021328738192096353), (37, 0.022380252135917544), (23, 0.022391883889213204), (50, 0.02315096533857286), (41, 0.023466475773602724), (48, 0.02388049359433353), (25, 0.024306432576850057), (49, 0.024308841209858656), (45, 0.024313249858096242), (21, 0.025015684310346842), (22, 0.025352695025503635), (27, 0.02584315137937665), (42, 0.02590556163340807), (44, 0.02644211705774069), (40, 0.026815337827429175), (20, 0.027175214374437928), (47, 0.028161128284409642), (24, 0.03184296004474163), (15, 0.03206431260332465), (19, 0.032593329437077045), (7, 0.032621316611766815), (51, 0.03977957973256707), (9, 0.0440373164601624), (6, 0.04704805929213762), (4, 0.0478866258636117), (14, 0.04794911341741681), (2, 0.05491739884018898), (3, 0.05827117990702391), (13, 0.05958371050655842), (52, 0.05977876065298915), (11, 0.05992968147620559), (17, 0.06213824450969696), (0, 0.06407808046787977), (1, 0.06646822858601809), (8, 0.07527044415473938), (10, 0.08144836407154799), (16, 0.08495580218732357), (12, 0.09109003935009241), (5, 0.106849973089993), (36, 0.4426538981497288), (18, 0.5154022499918938), (53, 0.9292655810713768)]
computing accuracy for after removing block 46 . block score: 0.021328738192096353
removed block 46 current accuracy 0.9266 loss from initial  0.024800000000000044
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 37, with score 0.022380. All blocks and scores: [(37, 0.0223802519030869), (23, 0.022391883423551917), (41, 0.02346647623926401), (50, 0.023776468355208635), (25, 0.024306432344019413), (45, 0.0243132496252656), (48, 0.02454885235056281), (21, 0.02501568361185491), (49, 0.025200176052749157), (22, 0.025352695723995566), (27, 0.02584315137937665), (42, 0.025905561400577426), (44, 0.026442118221893907), (40, 0.026815336663275957), (20, 0.027175212744623423), (47, 0.03035562322475016), (24, 0.03184295957908034), (15, 0.032064314000308514), (19, 0.03259332897141576), (7, 0.032621316611766815), (51, 0.039974015671759844), (9, 0.0440373164601624), (6, 0.047048060689121485), (4, 0.047886624932289124), (14, 0.0479491138830781), (2, 0.05491740070283413), (3, 0.05827118083834648), (52, 0.05936056422069669), (13, 0.05958371423184872), (11, 0.0599296810105443), (17, 0.06213824450969696), (0, 0.0640780795365572), (1, 0.06646823044866323), (8, 0.07527044601738453), (10, 0.08144836500287056), (16, 0.08495580218732357), (12, 0.09109003562480211), (5, 0.10684997588396072), (36, 0.4426538906991482), (18, 0.515402227640152), (53, 1.0266141220927238)]
computing accuracy for after removing block 37 . block score: 0.0223802519030869
removed block 37 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021362. All blocks and scores: [(50, 0.02136227209120989), (45, 0.022097476525232196), (41, 0.02233790187165141), (23, 0.02239188365638256), (48, 0.02273039799183607), (49, 0.022765618283301592), (25, 0.02430643211118877), (44, 0.024453197605907917), (21, 0.02501568291336298), (42, 0.02529576770029962), (22, 0.02535269525833428), (27, 0.02584315137937665), (40, 0.02705785376019776), (20, 0.027175212977454066), (47, 0.027692888863384724), (24, 0.03184296051040292), (15, 0.03206431306898594), (19, 0.03259332850575447), (7, 0.0326213170774281), (51, 0.03684295853599906), (9, 0.044037317391484976), (6, 0.04704805975779891), (4, 0.04788662353530526), (14, 0.04794911481440067), (52, 0.052804379258304834), (2, 0.05491740023717284), (3, 0.05827117990702391), (13, 0.059583712834864855), (11, 0.05992968240752816), (17, 0.062138245441019535), (0, 0.06407807860523462), (1, 0.06646822858601809), (8, 0.07527044508606195), (10, 0.08144836314022541), (16, 0.08495580218732357), (12, 0.09109003748744726), (5, 0.106849973089993), (36, 0.4426538906991482), (18, 0.515402227640152), (53, 1.0598441660404205)]
computing accuracy for after removing block 50 . block score: 0.02136227209120989
removed block 50 current accuracy 0.9062 loss from initial  0.04520000000000002
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.022097. All blocks and scores: [(45, 0.022097476525232196), (41, 0.022337901405990124), (23, 0.02239188365638256), (48, 0.022730398224666715), (49, 0.02276561874896288), (25, 0.02430643211118877), (44, 0.024453197605907917), (21, 0.025015684077516198), (42, 0.02529576839879155), (22, 0.02535269595682621), (27, 0.025843151845037937), (40, 0.02705785376019776), (20, 0.027175213675945997), (47, 0.027692888863384724), (24, 0.03184296051040292), (15, 0.03206431306898594), (19, 0.03259332850575447), (7, 0.032621316611766815), (51, 0.039360156282782555), (9, 0.0440373164601624), (6, 0.04704806208610535), (4, 0.04788662353530526), (14, 0.047949112951755524), (2, 0.054917399771511555), (3, 0.05827117897570133), (52, 0.05842189351096749), (13, 0.05958371376618743), (11, 0.05992968287318945), (17, 0.06213824590668082), (0, 0.0640780795365572), (1, 0.06646822858601809), (8, 0.07527044415473938), (10, 0.08144836220890284), (16, 0.08495580311864614), (12, 0.09109003469347954), (5, 0.10684997588396072), (36, 0.4426538906991482), (18, 0.5154022425413132), (53, 1.2592478692531586)]
computing accuracy for after removing block 45 . block score: 0.022097476525232196
removed block 45 current accuracy 0.8962 loss from initial  0.05520000000000003
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 41, with score 0.022338. All blocks and scores: [(41, 0.022337901638820767), (23, 0.02239188295789063), (48, 0.022624253295361996), (49, 0.022956902161240578), (25, 0.024306431878358126), (44, 0.024453197373077273), (21, 0.025015683379024267), (42, 0.025295768631622195), (22, 0.02535269595682621), (27, 0.025843151146546006), (40, 0.02705785445868969), (20, 0.027175213443115354), (47, 0.0289941041264683), (24, 0.03184295957908034), (15, 0.03206431306898594), (19, 0.03259332897141576), (7, 0.032621316611766815), (51, 0.03856229968369007), (9, 0.04403731785714626), (6, 0.04704806115478277), (4, 0.04788662539795041), (14, 0.0479491138830781), (2, 0.05491740070283413), (52, 0.05571676604449749), (3, 0.05827117990702391), (13, 0.059583712834864855), (11, 0.05992968147620559), (17, 0.062138245441019535), (0, 0.0640780795365572), (1, 0.06646822951734066), (8, 0.07527044415473938), (10, 0.08144836220890284), (16, 0.08495580218732357), (12, 0.09109003841876984), (5, 0.10684997402131557), (36, 0.4426538981497288), (18, 0.515402227640152), (53, 1.408177062869072)]
computing accuracy for after removing block 41 . block score: 0.022337901638820767
removed block 41 current accuracy 0.89 loss from initial  0.06140000000000001
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 48, with score 0.022326. All blocks and scores: [(48, 0.022325649159029126), (23, 0.02239188365638256), (49, 0.022853755159303546), (25, 0.024306431645527482), (21, 0.025015682447701693), (22, 0.025352695723995566), (27, 0.025843151845037937), (44, 0.02595860604196787), (42, 0.02600095490925014), (40, 0.02705785376019776), (20, 0.02717521321028471), (47, 0.02945581078529358), (24, 0.031842959113419056), (15, 0.03206431260332465), (19, 0.03259332897141576), (7, 0.0326213170774281), (51, 0.03674865560606122), (9, 0.0440373164601624), (6, 0.047048060689121485), (4, 0.0478866258636117), (14, 0.047949116211384535), (52, 0.05410317564383149), (2, 0.05491740070283413), (3, 0.058271181769669056), (13, 0.05958371190354228), (11, 0.05992968147620559), (17, 0.06213824637234211), (0, 0.0640780795365572), (1, 0.06646822765469551), (8, 0.0752704432234168), (10, 0.08144836407154799), (16, 0.08495580311864614), (12, 0.09109003655612469), (5, 0.10684997495263815), (36, 0.4426538944244385), (18, 0.5154022425413132), (53, 1.5025620460510254)]
computing accuracy for after removing block 48 . block score: 0.022325649159029126
removed block 48 current accuracy 0.8666 loss from initial  0.08479999999999999
training start
training epoch 0 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.1]
training epoch 1 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.1]
training epoch 2 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.1]
training epoch 3 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.1]
training epoch 4 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 5 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 6 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.1]
training epoch 7 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.1]
training epoch 8 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 9 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022125. All blocks and scores: [(23, 0.02212465601041913), (25, 0.024175551487132907), (21, 0.024825498461723328), (22, 0.025199332972988486), (20, 0.027101776795461774), (24, 0.031792302150279284), (15, 0.03208834724500775), (19, 0.032403229270130396), (7, 0.03265328239649534), (9, 0.044004385359585285), (6, 0.046195550356060266), (49, 0.046946513932198286), (14, 0.047644443809986115), (4, 0.04811297124251723), (27, 0.04904860723763704), (44, 0.050401747692376375), (47, 0.05315984971821308), (2, 0.0545736663043499), (42, 0.054842240642756224), (51, 0.05672282911837101), (3, 0.05774946603924036), (13, 0.05925805866718292), (11, 0.05929396068677306), (17, 0.06230334797874093), (0, 0.06410168763250113), (40, 0.06490655243396759), (52, 0.0651638563722372), (1, 0.06628290563821793), (8, 0.07408019062131643), (10, 0.081156425178051), (16, 0.08485659770667553), (12, 0.08997086901217699), (5, 0.1058306535705924), (18, 0.5132041424512863), (36, 0.6312403455376625), (53, 1.4025596678256989)]
computing accuracy for after removing block 23 . block score: 0.02212465601041913
removed block 23 current accuracy 0.935 loss from initial  0.01639999999999997
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 25, with score 0.023410. All blocks and scores: [(25, 0.0234102220274508), (21, 0.024825498461723328), (22, 0.02519933390431106), (20, 0.027101775631308556), (24, 0.029499792493879795), (15, 0.03208834724500775), (19, 0.032403229270130396), (7, 0.03265328239649534), (9, 0.044004383496940136), (6, 0.04619554942473769), (49, 0.046399681363254786), (27, 0.04736719047650695), (14, 0.04764444474130869), (4, 0.04811297124251723), (44, 0.04954533092677593), (47, 0.05202566925436258), (42, 0.053584194742143154), (2, 0.05457366490736604), (51, 0.05568608362227678), (3, 0.05774946650490165), (13, 0.0592580595985055), (11, 0.05929396394640207), (17, 0.06230334844440222), (40, 0.06325434055179358), (52, 0.06355627719312906), (0, 0.06410168576985598), (1, 0.06628290843218565), (8, 0.07408019062131643), (10, 0.08115642424672842), (16, 0.08485660050064325), (12, 0.08997086808085442), (5, 0.10583065543323755), (18, 0.5132041424512863), (36, 0.6211672574281693), (53, 1.4134461432695389)]
computing accuracy for after removing block 25 . block score: 0.0234102220274508
removed block 25 current accuracy 0.928 loss from initial  0.023399999999999976
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.024825. All blocks and scores: [(21, 0.02482549869455397), (22, 0.025199333438649774), (20, 0.027101776329800487), (24, 0.029499791795387864), (15, 0.03208834771066904), (19, 0.03240322833880782), (7, 0.03265328239649534), (9, 0.04400438303127885), (49, 0.04601199505850673), (6, 0.046195550821721554), (27, 0.046840711031109095), (14, 0.047644443809986115), (4, 0.04811297031119466), (44, 0.0499571468681097), (47, 0.050252323504537344), (51, 0.05412399908527732), (2, 0.05457366770133376), (42, 0.057303777895867825), (3, 0.057749466970562935), (13, 0.05925805913284421), (11, 0.059293962083756924), (52, 0.061827776953577995), (17, 0.06230334751307964), (0, 0.06410168763250113), (1, 0.06628290377557278), (40, 0.06750559899955988), (8, 0.07408019062131643), (10, 0.08115642424672842), (16, 0.0848566023632884), (12, 0.08997086528688669), (5, 0.10583065450191498), (18, 0.5132041350007057), (36, 0.6384561955928802), (53, 1.4221608191728592)]
computing accuracy for after removing block 21 . block score: 0.02482549869455397
removed block 21 current accuracy 0.9256 loss from initial  0.025800000000000045
since last training loss: 0.014600000000000057 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.023466. All blocks and scores: [(22, 0.02346574212424457), (24, 0.026506057707592845), (20, 0.02710177656263113), (15, 0.03208834631368518), (19, 0.032403229270130396), (7, 0.03265328286215663), (9, 0.044004383496940136), (49, 0.04422105522826314), (27, 0.0445953574962914), (6, 0.046195550821721554), (47, 0.046991487964987755), (44, 0.047415814362466335), (14, 0.04764444334432483), (4, 0.048112970776855946), (51, 0.05129483342170715), (42, 0.05146300280466676), (2, 0.0545736663043499), (52, 0.055622383020818233), (3, 0.05774946557357907), (13, 0.05925805540755391), (11, 0.05929396254941821), (40, 0.061165483202785254), (17, 0.06230334797874093), (0, 0.0641016885638237), (1, 0.0662829065695405), (8, 0.07408019248396158), (10, 0.08115642610937357), (16, 0.0848565986379981), (12, 0.08997086808085442), (5, 0.1058306535705924), (18, 0.5132041350007057), (36, 0.5969803482294083), (53, 1.4320005178451538)]
computing accuracy for after removing block 22 . block score: 0.02346574212424457
removed block 22 current accuracy 0.9138 loss from initial  0.03760000000000008
since last training loss: 0.02640000000000009 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024289. All blocks and scores: [(24, 0.024289089255034924), (20, 0.027101776096969843), (15, 0.032088346779346466), (19, 0.032403227873146534), (7, 0.03265328239649534), (49, 0.04239563504233956), (27, 0.0430232984945178), (9, 0.04400438442826271), (47, 0.04459634888917208), (44, 0.044994767755270004), (6, 0.046195550356060266), (14, 0.0476444442756474), (4, 0.04811297124251723), (51, 0.04896348109468818), (42, 0.04939676960930228), (52, 0.05082324147224426), (2, 0.05457366677001119), (3, 0.057749466970562935), (40, 0.05916909873485565), (13, 0.05925805773586035), (11, 0.059293962083756924), (17, 0.06230334844440222), (0, 0.06410168670117855), (1, 0.06628290750086308), (8, 0.07408019155263901), (10, 0.08115642424672842), (16, 0.08485659770667553), (12, 0.08997086621820927), (5, 0.10583065636456013), (18, 0.5132041200995445), (36, 0.5844931229948997), (53, 1.4115788638591766)]
computing accuracy for after removing block 24 . block score: 0.024289089255034924
removed block 24 current accuracy 0.8808 loss from initial  0.0706
since last training loss: 0.05940000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.027102. All blocks and scores: [(20, 0.027101776329800487), (15, 0.03208834724500775), (19, 0.032403227873146534), (7, 0.032653281930834055), (27, 0.0430369284003973), (47, 0.04326265677809715), (49, 0.04333311691880226), (9, 0.044004385359585285), (44, 0.045191282872110605), (6, 0.04619554942473769), (14, 0.047644443809986115), (4, 0.04811297124251723), (51, 0.04826524434611201), (52, 0.04839403182268143), (42, 0.05083699803799391), (2, 0.05457366816699505), (3, 0.057749466970562935), (13, 0.05925805540755391), (11, 0.059293962083756924), (40, 0.061029181350022554), (17, 0.062303348910063505), (0, 0.06410168576985598), (1, 0.0662829065695405), (8, 0.07408019248396158), (10, 0.08115642424672842), (16, 0.0848565986379981), (12, 0.08997086714953184), (5, 0.1058306535705924), (18, 0.5132041499018669), (36, 0.6055863946676254), (53, 1.4532827585935593)]
computing accuracy for after removing block 20 . block score: 0.027101776329800487
removed block 20 current accuracy 0.8498 loss from initial  0.10160000000000002
since last training loss: 0.09040000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032088. All blocks and scores: [(15, 0.03208834817633033), (19, 0.03240322880446911), (7, 0.03265328239649534), (47, 0.041173746809363365), (49, 0.04278835654258728), (27, 0.0428959634155035), (9, 0.044004383496940136), (44, 0.04502627765759826), (52, 0.04565920541062951), (6, 0.04619555175304413), (51, 0.04691107617691159), (14, 0.047644443809986115), (4, 0.04811297031119466), (42, 0.048715535551309586), (2, 0.054573665373027325), (3, 0.05774946650490165), (13, 0.05925805866718292), (11, 0.059293961618095636), (40, 0.06092256400734186), (17, 0.06230334844440222), (0, 0.0641016848385334), (1, 0.0662829065695405), (8, 0.07408019155263901), (10, 0.08115642238408327), (16, 0.0848565986379981), (12, 0.08997086621820927), (5, 0.10583065543323755), (18, 0.5132041424512863), (36, 0.6042474433779716), (53, 1.426127314567566)]
computing accuracy for after removing block 15 . block score: 0.03208834817633033
removed block 15 current accuracy 0.8406 loss from initial  0.11080000000000001
since last training loss: 0.09960000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032653. All blocks and scores: [(7, 0.032653281930834055), (19, 0.03267495473846793), (27, 0.041923279874026775), (47, 0.042706859298050404), (49, 0.04306710883975029), (9, 0.04400438303127885), (44, 0.044616885017603636), (6, 0.04619555128738284), (52, 0.046540580689907074), (51, 0.047255809884518385), (14, 0.047644445206969976), (42, 0.04775736853480339), (4, 0.048112969379872084), (2, 0.054573667235672474), (3, 0.05774946603924036), (13, 0.05925805680453777), (11, 0.05929396115243435), (40, 0.060575599782168865), (0, 0.06410168576985598), (17, 0.06615025270730257), (1, 0.0662829065695405), (8, 0.07408019155263901), (10, 0.08115641865879297), (12, 0.08997086621820927), (16, 0.09460647031664848), (5, 0.1058306535705924), (18, 0.5007870756089687), (36, 0.5991581305861473), (53, 1.450966164469719)]
computing accuracy for after removing block 7 . block score: 0.032653281930834055
removed block 7 current accuracy 0.7996 loss from initial  0.15180000000000005
since last training loss: 0.14060000000000006 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.032485. All blocks and scores: [(19, 0.03248526714742184), (27, 0.040251997765153646), (47, 0.041201799642294645), (49, 0.04341344488784671), (44, 0.04374227160587907), (9, 0.04391858307644725), (52, 0.044003700371831656), (14, 0.04401616705581546), (42, 0.04524201666936278), (6, 0.04619554989039898), (51, 0.04623473761603236), (4, 0.04811297170817852), (13, 0.05137042282149196), (2, 0.0545736663043499), (11, 0.055983944330364466), (17, 0.05599441519007087), (40, 0.05653120670467615), (3, 0.05774946743622422), (0, 0.0641016848385334), (1, 0.06628290563821793), (8, 0.07201969530433416), (10, 0.08353639952838421), (12, 0.08406581915915012), (16, 0.08612119033932686), (5, 0.10583065450191498), (18, 0.48451017588377), (36, 0.5725044533610344), (53, 1.4743456095457077)]
computing accuracy for after removing block 19 . block score: 0.03248526714742184
removed block 19 current accuracy 0.7526 loss from initial  0.19879999999999998
training start
training epoch 0 val accuracy 0.847 topk_dict {'top1': 0.847} is_best True lr [0.1]
training epoch 1 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.1]
training epoch 2 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.1]
training epoch 3 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 4 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.1]
training epoch 5 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 6 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 9 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.1]
training epoch 10 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.935400)
finished training. finished 50 epochs. accuracy 0.9354 topk_dict {'top1': 0.9354}
start iteration 27
[activation diff]: block to remove picked: 9, with score 0.038612. All blocks and scores: [(9, 0.038611994590610266), (4, 0.04680329654365778), (42, 0.0492009068839252), (49, 0.05108713125810027), (2, 0.05468167690560222), (40, 0.05612920457497239), (51, 0.05770152807235718), (3, 0.0579632930457592), (6, 0.0595448287203908), (14, 0.06025673495605588), (47, 0.06087492173537612), (44, 0.062007348984479904), (11, 0.06250387663021684), (52, 0.06414871197193861), (0, 0.06418908759951591), (1, 0.06716307904571295), (13, 0.07704160362482071), (17, 0.07706899382174015), (12, 0.09143100958317518), (8, 0.09310666378587484), (10, 0.0952716451138258), (16, 0.10319392010569572), (5, 0.12672410625964403), (27, 0.13298607431352139), (36, 0.5601731464266777), (18, 0.7389233782887459), (53, 1.438380554318428)]
computing accuracy for after removing block 9 . block score: 0.038611994590610266
removed block 9 current accuracy 0.931 loss from initial  0.020399999999999974
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 4, with score 0.046803. All blocks and scores: [(4, 0.04680329654365778), (42, 0.04841972095891833), (49, 0.04982559569180012), (2, 0.054681675508618355), (14, 0.05483097396790981), (51, 0.05643507046625018), (11, 0.05694289691746235), (40, 0.05714283511042595), (3, 0.057963293977081776), (6, 0.05954483151435852), (44, 0.0624220035970211), (47, 0.06283170077949762), (52, 0.06284852838143706), (0, 0.06418908853083849), (1, 0.06716307904571295), (13, 0.07133943680673838), (17, 0.07192330807447433), (12, 0.08012415375560522), (10, 0.09240152034908533), (8, 0.09310666285455227), (16, 0.09375620353966951), (5, 0.1267241071909666), (27, 0.13306286744773388), (36, 0.557739369571209), (18, 0.7290189191699028), (53, 1.4153350740671158)]
computing accuracy for after removing block 4 . block score: 0.04680329654365778
removed block 4 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 42, with score 0.049412. All blocks and scores: [(42, 0.0494120717048645), (49, 0.04971317946910858), (14, 0.05269100610166788), (11, 0.0529582635499537), (2, 0.054681675508618355), (51, 0.05675524286925793), (3, 0.057963293977081776), (40, 0.05891418969258666), (47, 0.06321902107447386), (44, 0.0632517235353589), (52, 0.06354491412639618), (0, 0.06418908666819334), (6, 0.06475881952792406), (1, 0.06716307997703552), (17, 0.06870625540614128), (13, 0.07100473996251822), (12, 0.07654524222016335), (16, 0.0804953845217824), (10, 0.08849715162068605), (8, 0.09603921789675951), (27, 0.13199377618730068), (5, 0.1320158950984478), (36, 0.5682626664638519), (18, 0.7446791380643845), (53, 1.385392740368843)]
computing accuracy for after removing block 42 . block score: 0.0494120717048645
removed block 42 current accuracy 0.9102 loss from initial  0.041200000000000014
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.047715. All blocks and scores: [(49, 0.047715477645397186), (14, 0.05269100936129689), (11, 0.052958260755985975), (51, 0.05342037370428443), (2, 0.054681677371263504), (3, 0.05796329490840435), (40, 0.058914190623909235), (52, 0.05939764669165015), (47, 0.0622646426782012), (0, 0.06418908666819334), (6, 0.06475881952792406), (1, 0.06716308183968067), (17, 0.06870625261217356), (44, 0.0693625109270215), (13, 0.07100473903119564), (12, 0.07654524315148592), (16, 0.0804953845217824), (10, 0.08849715813994408), (8, 0.09603921696543694), (27, 0.13199377618730068), (5, 0.13201590068638325), (36, 0.5682626664638519), (18, 0.7446791604161263), (53, 1.384318932890892)]
computing accuracy for after removing block 49 . block score: 0.047715477645397186
removed block 49 current accuracy 0.893 loss from initial  0.05840000000000001
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 14, with score 0.052691. All blocks and scores: [(14, 0.05269100656732917), (11, 0.05295826308429241), (2, 0.05468167597427964), (51, 0.056693372782319784), (3, 0.057963293977081776), (40, 0.05891418922692537), (47, 0.06226464407518506), (0, 0.06418908759951591), (6, 0.06475881859660149), (1, 0.06716307811439037), (52, 0.06842533871531487), (17, 0.06870625354349613), (44, 0.06936250999569893), (13, 0.07100474089384079), (12, 0.07654524315148592), (16, 0.08049538731575012), (10, 0.08849715162068605), (8, 0.09603921789675951), (27, 0.13199377432465553), (5, 0.1320158988237381), (36, 0.5682626664638519), (18, 0.7446791604161263), (53, 1.5640356838703156)]
computing accuracy for after removing block 14 . block score: 0.05269100656732917
removed block 14 current accuracy 0.8754 loss from initial  0.07600000000000007
since last training loss: 0.06000000000000005 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 11, with score 0.052958. All blocks and scores: [(11, 0.0529582635499537), (51, 0.054369368590414524), (2, 0.05468167783692479), (40, 0.0576321710832417), (3, 0.05796329351142049), (47, 0.061064678244292736), (0, 0.06418908853083849), (6, 0.06475882045924664), (52, 0.06621465366333723), (1, 0.06716307997703552), (44, 0.06745151057839394), (17, 0.06875321734696627), (13, 0.07100473809987307), (12, 0.0765452440828085), (10, 0.08849715255200863), (8, 0.09603921789675951), (16, 0.10930912848562002), (27, 0.11980333738029003), (5, 0.13201590068638325), (36, 0.555524542927742), (18, 0.7354651167988777), (53, 1.5921823382377625)]
computing accuracy for after removing block 11 . block score: 0.0529582635499537
removed block 11 current accuracy 0.8604 loss from initial  0.09099999999999997
since last training loss: 0.07499999999999996 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 51, with score 0.054652. All blocks and scores: [(51, 0.054651851300150156), (2, 0.05468167969956994), (3, 0.05796329444274306), (40, 0.059674065094441175), (0, 0.06418908759951591), (6, 0.06475881859660149), (17, 0.06662887800484896), (1, 0.06716307904571295), (44, 0.06717758905142546), (47, 0.06865751184523106), (52, 0.06916537787765265), (13, 0.07193042896687984), (16, 0.08391461335122585), (12, 0.08582250401377678), (10, 0.08849715534597635), (8, 0.09603921696543694), (27, 0.122513672336936), (5, 0.13201590068638325), (36, 0.5596104934811592), (18, 0.7691152542829514), (53, 1.5898341983556747)]
computing accuracy for after removing block 51 . block score: 0.054651851300150156
removed block 51 current accuracy 0.79 loss from initial  0.1614
since last training loss: 0.14539999999999997 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 2, with score 0.054682. All blocks and scores: [(2, 0.05468167643994093), (3, 0.05796329490840435), (40, 0.059674065094441175), (0, 0.06418908666819334), (6, 0.06475881766527891), (17, 0.06662887707352638), (1, 0.06716307997703552), (44, 0.06717758998274803), (47, 0.06865751277655363), (13, 0.07193042989820242), (52, 0.07364465668797493), (16, 0.08391461241990328), (12, 0.08582250401377678), (10, 0.08849715627729893), (8, 0.09603921882808208), (27, 0.12251367326825857), (5, 0.13201590068638325), (36, 0.5596104934811592), (18, 0.7691152691841125), (53, 1.8045093715190887)]
computing accuracy for after removing block 2 . block score: 0.05468167643994093
removed block 2 current accuracy 0.719 loss from initial  0.23240000000000005
since last training loss: 0.21640000000000004 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 3, with score 0.052964. All blocks and scores: [(3, 0.05296386359259486), (17, 0.05514240823686123), (40, 0.055255734361708164), (6, 0.06083013117313385), (44, 0.06158288288861513), (0, 0.06418908573687077), (47, 0.0668124407529831), (1, 0.06716307997703552), (13, 0.0672102514654398), (52, 0.0677329208701849), (12, 0.07398109696805477), (16, 0.07589148357510567), (10, 0.08101167716085911), (8, 0.09299937449395657), (27, 0.1094280881807208), (5, 0.12284964043647051), (36, 0.5189109593629837), (18, 0.7175474390387535), (53, 1.8208186775445938)]
computing accuracy for after removing block 3 . block score: 0.05296386359259486
removed block 3 current accuracy 0.559 loss from initial  0.39239999999999997
since last training loss: 0.37639999999999996 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 17, with score 0.049320. All blocks and scores: [(17, 0.049319741781800985), (40, 0.051820284221321344), (16, 0.05700571043416858), (44, 0.057484524324536324), (6, 0.06155497767031193), (52, 0.06402265280485153), (0, 0.06418908853083849), (47, 0.06490739155560732), (13, 0.06630643364042044), (1, 0.06716307997703552), (12, 0.06801944132894278), (10, 0.07936763111501932), (8, 0.08982445765286684), (27, 0.09860261343419552), (5, 0.12619736976921558), (36, 0.4957256056368351), (18, 0.698672741651535), (53, 1.8970808684825897)]
computing accuracy for after removing block 17 . block score: 0.049319741781800985
removed block 17 current accuracy 0.5198 loss from initial  0.4316
since last training loss: 0.41559999999999997 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 40, with score 0.049712. All blocks and scores: [(40, 0.04971224861219525), (44, 0.05480697192251682), (16, 0.05700570764020085), (6, 0.06155497906729579), (47, 0.06173056364059448), (52, 0.062505385838449), (0, 0.06418908853083849), (13, 0.06630643270909786), (1, 0.0671630771830678), (12, 0.06801943946629763), (10, 0.0793676320463419), (8, 0.08982445765286684), (27, 0.0908685103058815), (5, 0.12619736790657043), (36, 0.4700343944132328), (18, 0.6532854810357094), (53, 1.9375095665454865)]
computing accuracy for after removing block 40 . block score: 0.04971224861219525
removed block 40 current accuracy 0.473 loss from initial  0.47840000000000005
since last training loss: 0.46240000000000003 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 52, with score 0.055256. All blocks and scores: [(52, 0.05525637650862336), (16, 0.05700570764020085), (47, 0.05794078577309847), (6, 0.061554976273328066), (0, 0.06418908480554819), (44, 0.0647686654701829), (13, 0.06630643457174301), (1, 0.06716307997703552), (12, 0.06801944132894278), (10, 0.07936763018369675), (8, 0.08982445765286684), (27, 0.09086851216852665), (5, 0.1261973651126027), (36, 0.4700343944132328), (18, 0.6532854810357094), (53, 1.9713790565729141)]
computing accuracy for after removing block 52 . block score: 0.05525637650862336
removed block 52 current accuracy 0.372 loss from initial  0.5794
training start
training epoch 0 val accuracy 0.859 topk_dict {'top1': 0.859} is_best True lr [0.1]
training epoch 1 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.1]
training epoch 2 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 3 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 4 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 5 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 6 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 7 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 8 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 9 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 10 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.928600)
finished training. finished 50 epochs. accuracy 0.9286 topk_dict {'top1': 0.9286}
