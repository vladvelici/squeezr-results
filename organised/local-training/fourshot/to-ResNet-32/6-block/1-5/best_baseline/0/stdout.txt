start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589733220637), (30, 0.010011187172494829), (31, 0.010232581524178386), (34, 0.013294660951942205), (29, 0.013421116629615426), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.01999649149365723), (46, 0.02059022500179708), (25, 0.022078295471146703), (23, 0.022228715242817998), (41, 0.022336415946483612), (44, 0.023145999293774366), (40, 0.023749590385705233), (45, 0.02397549501620233), (21, 0.024941089330241084), (48, 0.024957707384601235), (22, 0.02515139034949243), (50, 0.025287173921242356), (24, 0.02588058286346495), (49, 0.025916648795828223), (42, 0.02623223210684955), (20, 0.026848892448469996), (47, 0.0286329488735646), (38, 0.03134434437379241), (39, 0.031441294588148594), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03791803028434515), (51, 0.041787587106227875), (9, 0.043376326095312834), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241463959217), (2, 0.054577403236180544), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104411184788), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671143978834152), (36, 0.4361986517906189), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013119244016706944), (29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.01985268690623343), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.02297719265334308), (40, 0.0235738311894238), (45, 0.023648238042369485), (48, 0.024540216894820333), (50, 0.024770822376012802), (21, 0.024941090028733015), (22, 0.0251513896510005), (49, 0.025575740728527308), (24, 0.025880583096295595), (42, 0.02589341253042221), (20, 0.026848891749978065), (47, 0.028072760673239827), (38, 0.031091187614947557), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789771931245923), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337465019896626), (52, 0.06493351748213172), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4339806027710438), (18, 0.5117433145642281), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.012758882134221494), (29, 0.013421117095276713), (35, 0.015918421559035778), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.019850465236231685), (46, 0.020411915611475706), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022891477681696415), (40, 0.023602579720318317), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.024639349663630128), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.025392549578100443), (42, 0.025712220231071115), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.028052505338564515), (38, 0.0309358739759773), (39, 0.031173037365078926), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.057849930599331856), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441722949966788), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.4350203163921833), (18, 0.5117432773113251), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160194374621), (29, 0.013421116978861392), (35, 0.015918649034574628), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.023001376539468765), (40, 0.023739926517009735), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463105015456676), (21, 0.024941089563071728), (22, 0.025151390815153718), (49, 0.025246930541470647), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.02772757480852306), (38, 0.03074627392925322), (39, 0.031281795585528016), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03895266819745302), (51, 0.04082479886710644), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241417393088), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756389141083), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829801082611)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.01342111686244607), (35, 0.01596891228109598), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837009022012353), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.023569097509607673), (45, 0.023840721929445863), (48, 0.02410835842601955), (50, 0.024114209692925215), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.025151390815153718), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027423851657658815), (38, 0.03073564823716879), (39, 0.0314104245044291), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525345310569), (52, 0.06270107813179493), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.43692686781287193), (18, 0.5117432922124863), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.01763686165213585), (27, 0.01902279839850962), (43, 0.02030268427915871), (46, 0.02032419736497104), (41, 0.021962703205645084), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096972309052944), (40, 0.0241568167693913), (45, 0.024168409639969468), (49, 0.024922373238950968), (21, 0.024941088864579797), (22, 0.025151389883831143), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.027568295132368803), (38, 0.031787263229489326), (15, 0.03205838426947594), (39, 0.032257913146167994), (7, 0.03244550386443734), (19, 0.03254077769815922), (51, 0.04008621349930763), (37, 0.040690730325877666), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.057849925477057695), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525531575084), (52, 0.06221095006912947), (0, 0.06337464554235339), (1, 0.06593216303735971), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370510682463646), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019856703700497746), (46, 0.01998897548764944), (41, 0.02125620562583208), (25, 0.022078295471146703), (23, 0.02222871594130993), (44, 0.02269203308969736), (48, 0.023521371884271502), (50, 0.02353389048948884), (40, 0.023616241058334708), (45, 0.02393329283222556), (49, 0.024449915159493685), (42, 0.024838327895849943), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.02681345515884459), (20, 0.026848891051486135), (38, 0.031083732144907117), (39, 0.032056889962404966), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974902540445), (37, 0.0401521441526711), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003409311175), (52, 0.060369073413312435), (17, 0.0613252567127347), (0, 0.06337464461103082), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4432784393429756), (18, 0.5117432996630669), (53, 0.8375032395124435)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.01698602200485766), (27, 0.01876970869489014), (43, 0.019405571976676583), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295703977346), (23, 0.022228716406971216), (44, 0.022507572313770652), (48, 0.022899368777871132), (50, 0.022937728092074394), (40, 0.023057402344420552), (42, 0.023520408663898706), (45, 0.023633699398487806), (49, 0.024081918643787503), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880582630634308), (47, 0.026322792284190655), (20, 0.026848891517147422), (38, 0.030149149242788553), (39, 0.031466696644201875), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.039268902968615294), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740416750312), (3, 0.05784992687404156), (52, 0.058468119241297245), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43490004166960716), (18, 0.5117432922124863), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.018769708229228854), (46, 0.018842301331460476), (41, 0.019016370410099626), (48, 0.021309157134965062), (50, 0.021624521352350712), (44, 0.021748854080215096), (40, 0.02191696735098958), (42, 0.021930373972281814), (25, 0.022078294772654772), (23, 0.022228715242817998), (45, 0.022736449958756566), (49, 0.022970063844695687), (21, 0.024941089330241084), (22, 0.02515139034949243), (47, 0.025355831487104297), (24, 0.025880582630634308), (20, 0.02684889198280871), (38, 0.02869188808836043), (39, 0.029624431394040585), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077909514308), (51, 0.03601635713130236), (37, 0.03643036773428321), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.048522413708269596), (2, 0.05457740603014827), (52, 0.05466857925057411), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.41641608253121376), (18, 0.5117433071136475), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.1]
training epoch 1 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.1]
training epoch 2 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.1]
training epoch 3 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.1]
training epoch 4 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 5 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.1]
training epoch 6 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.1]
training epoch 7 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.1]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.1]
training epoch 9 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 9
[activation diff]: block to remove picked: 40, with score 0.010720. All blocks and scores: [(40, 0.010720452875830233), (39, 0.014704323490150273), (38, 0.017421793658286333), (46, 0.021334809018298984), (43, 0.02184246527031064), (37, 0.02245793235488236), (23, 0.022519299061968923), (21, 0.02493274281732738), (45, 0.02502380288206041), (44, 0.025066792033612728), (41, 0.025183763587847352), (22, 0.025249447906389832), (50, 0.02529665920883417), (48, 0.025612573139369488), (24, 0.025949075119569898), (49, 0.026183331152424216), (20, 0.027056807652115822), (27, 0.0273253892082721), (42, 0.029078188352286816), (47, 0.02933725342154503), (25, 0.030607479391619563), (15, 0.032124300953000784), (19, 0.03231854969635606), (7, 0.03262563142925501), (51, 0.04164405260235071), (9, 0.04423065762966871), (6, 0.04652943601831794), (4, 0.04715155018493533), (14, 0.04795572627335787), (2, 0.05449524614959955), (3, 0.057644777465611696), (13, 0.059292906895279884), (11, 0.05987939611077309), (17, 0.062020104844123125), (0, 0.0642291009426117), (52, 0.06602694187313318), (1, 0.06709371600300074), (8, 0.07444286067038774), (10, 0.08142157550901175), (16, 0.08555465377867222), (12, 0.09059454407542944), (5, 0.10610754415392876), (36, 0.3952076956629753), (18, 0.5140345171093941), (53, 0.8024893403053284)]
computing accuracy for after removing block 40 . block score: 0.010720452875830233
removed block 40 current accuracy 0.9404 loss from initial  0.01100000000000001
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 39, with score 0.014704. All blocks and scores: [(39, 0.014704323839396238), (38, 0.01742179412394762), (43, 0.021382275270298123), (46, 0.021416857140138745), (37, 0.022457932587713003), (23, 0.02251929882913828), (45, 0.024591199355199933), (50, 0.024628110695630312), (41, 0.02482842723838985), (21, 0.024932743282988667), (48, 0.0251262285746634), (22, 0.02524944837205112), (44, 0.025914429919794202), (49, 0.025925559224560857), (24, 0.02594907581806183), (20, 0.027056807652115822), (27, 0.02732538990676403), (42, 0.02792403707280755), (47, 0.02982464712113142), (25, 0.03060748055577278), (15, 0.03212430188432336), (19, 0.03231854969635606), (7, 0.032625630497932434), (51, 0.04209403833374381), (9, 0.04423065856099129), (6, 0.04652943555265665), (4, 0.04715155158191919), (14, 0.04795572580769658), (2, 0.05449524614959955), (3, 0.05764477886259556), (13, 0.05929290736094117), (11, 0.05987939611077309), (17, 0.06202010391280055), (0, 0.06422910001128912), (52, 0.06672229152172804), (1, 0.06709371693432331), (8, 0.07444285973906517), (10, 0.08142157550901175), (16, 0.08555465470999479), (12, 0.09059454407542944), (5, 0.10610754229128361), (36, 0.3952076993882656), (18, 0.5140345096588135), (53, 0.8432747423648834)]
computing accuracy for after removing block 39 . block score: 0.014704323839396238
removed block 39 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 38, with score 0.017422. All blocks and scores: [(38, 0.017421793658286333), (43, 0.020392795326188207), (46, 0.020932822255417705), (37, 0.02245793235488236), (23, 0.022519299294799566), (50, 0.02267635823227465), (48, 0.0232783246319741), (45, 0.023807589430361986), (41, 0.024207874201238155), (49, 0.02487695566378534), (21, 0.02493274211883545), (22, 0.025249448604881763), (44, 0.025915440870448947), (24, 0.02594907581806183), (20, 0.027056808350607753), (27, 0.027325388742610812), (42, 0.027467558393254876), (47, 0.029118838952854276), (25, 0.030607478693127632), (15, 0.03212430141866207), (19, 0.032318548299372196), (7, 0.032625631894916296), (51, 0.04096051584929228), (9, 0.04423065809533), (6, 0.04652943555265665), (4, 0.04715154925361276), (14, 0.04795572627335787), (2, 0.054495245683938265), (3, 0.05764477839693427), (13, 0.059292908757925034), (11, 0.059879396576434374), (17, 0.06202010391280055), (52, 0.06353890430182219), (0, 0.06422910187393427), (1, 0.06709371693432331), (8, 0.0744428588077426), (10, 0.0814215736463666), (16, 0.08555465470999479), (12, 0.09059454593807459), (5, 0.10610753856599331), (36, 0.3952077031135559), (18, 0.5140345096588135), (53, 0.8903609216213226)]
computing accuracy for after removing block 38 . block score: 0.017421793658286333
removed block 38 current accuracy 0.929 loss from initial  0.022399999999999975
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.019598. All blocks and scores: [(43, 0.01959781674668193), (46, 0.020203580847010016), (50, 0.021429134532809258), (48, 0.021688053151592612), (37, 0.02245793165639043), (23, 0.022519299760460854), (45, 0.022589462576434016), (41, 0.02374264458194375), (49, 0.024204557528719306), (21, 0.024932742584496737), (22, 0.025249448139220476), (44, 0.025828059064224362), (24, 0.025949074421077967), (42, 0.026053829351440072), (20, 0.027056808350607753), (27, 0.0273253892082721), (47, 0.02761956211179495), (25, 0.030607478227466345), (15, 0.032124300953000784), (19, 0.03231854969635606), (7, 0.03262563096359372), (51, 0.04044504510238767), (9, 0.04423065762966871), (6, 0.046529436483979225), (4, 0.04715155018493533), (14, 0.047955726739019156), (2, 0.05449524661526084), (3, 0.057644777931272984), (13, 0.05929290736094117), (11, 0.05987939750775695), (52, 0.06117322063073516), (17, 0.06202010530978441), (0, 0.06422910001128912), (1, 0.06709371693432331), (8, 0.07444285973906517), (10, 0.08142157644033432), (16, 0.08555465284734964), (12, 0.09059454500675201), (5, 0.10610754229128361), (36, 0.3952076993882656), (18, 0.5140345245599747), (53, 0.9172243550419807)]
computing accuracy for after removing block 43 . block score: 0.01959781674668193
removed block 43 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.017799999999999927 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 46, with score 0.021020. All blocks and scores: [(46, 0.021019609412178397), (50, 0.021530305966734886), (37, 0.02245793235488236), (23, 0.02251929882913828), (48, 0.022572673624381423), (41, 0.02374264318495989), (45, 0.023808934725821018), (49, 0.024217354133725166), (21, 0.024932741886004806), (22, 0.02524944767355919), (24, 0.025949074886739254), (42, 0.026053829351440072), (20, 0.027056807884946465), (27, 0.02732538990676403), (44, 0.027702017221599817), (47, 0.02869666856713593), (25, 0.030607480322942138), (15, 0.032124300953000784), (19, 0.032318548765033484), (7, 0.03262563096359372), (51, 0.04006268084049225), (9, 0.044230659026652575), (6, 0.04652943555265665), (4, 0.04715154925361276), (14, 0.04795572627335787), (2, 0.05449524661526084), (3, 0.05764477839693427), (13, 0.05929290782660246), (52, 0.05977596063166857), (11, 0.059879396576434374), (17, 0.06202010344713926), (0, 0.06422910187393427), (1, 0.06709371879696846), (8, 0.07444285973906517), (10, 0.08142157644033432), (16, 0.08555465377867222), (12, 0.09059454780071974), (5, 0.10610754135996103), (36, 0.3952076956629753), (18, 0.5140345394611359), (53, 0.9716079160571098)]
computing accuracy for after removing block 46 . block score: 0.021019609412178397
removed block 46 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.022207. All blocks and scores: [(50, 0.022207207046449184), (37, 0.022457932122051716), (23, 0.022519299760460854), (48, 0.023389509646221995), (41, 0.023742643650621176), (45, 0.023808934492990375), (21, 0.02493274211883545), (49, 0.025231008417904377), (22, 0.02524944767355919), (24, 0.025949075585231185), (42, 0.026053829351440072), (20, 0.02705680811777711), (27, 0.0273253892082721), (44, 0.02770201675593853), (25, 0.03060748055577278), (47, 0.031230134656652808), (15, 0.0321243004873395), (19, 0.032318548765033484), (7, 0.03262563096359372), (51, 0.040167201310396194), (9, 0.04423065949231386), (6, 0.04652943555265665), (4, 0.047151549719274044), (14, 0.047955726739019156), (2, 0.05449524847790599), (3, 0.05764477560296655), (13, 0.059292906895279884), (52, 0.05946972919628024), (11, 0.059879397973418236), (17, 0.06202010391280055), (0, 0.0642291009426117), (1, 0.06709371600300074), (8, 0.07444285973906517), (10, 0.08142157550901175), (16, 0.08555465377867222), (12, 0.09059454593807459), (5, 0.10610754042863846), (36, 0.3952076956629753), (18, 0.5140345245599747), (53, 1.0796518921852112)]
computing accuracy for after removing block 50 . block score: 0.022207207046449184
removed block 50 current accuracy 0.9096 loss from initial  0.04180000000000006
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 37, with score 0.022458. All blocks and scores: [(37, 0.02245793305337429), (23, 0.022519299760460854), (48, 0.023389508947730064), (41, 0.023742644116282463), (45, 0.02380893426015973), (21, 0.0249327439814806), (49, 0.025231008417904377), (22, 0.025249448139220476), (24, 0.025949075119569898), (42, 0.026053830049932003), (20, 0.027056807419285178), (27, 0.027325389673933387), (44, 0.027702017221599817), (25, 0.030607479391619563), (47, 0.031230134423822165), (15, 0.0321243004873395), (19, 0.03231854783371091), (7, 0.03262563142925501), (51, 0.042998640332370996), (9, 0.04423065856099129), (6, 0.04652943555265665), (4, 0.04715155065059662), (14, 0.04795572580769658), (2, 0.05449524661526084), (3, 0.05764477699995041), (13, 0.059292908292263746), (11, 0.0598793956451118), (17, 0.06202010437846184), (0, 0.06422910187393427), (52, 0.06708476319909096), (1, 0.06709371600300074), (8, 0.0744428625330329), (10, 0.08142157271504402), (16, 0.08555465377867222), (12, 0.09059454407542944), (5, 0.10610754042863846), (36, 0.3952077031135559), (18, 0.5140345245599747), (53, 1.2795604020357132)]
computing accuracy for after removing block 37 . block score: 0.02245793305337429
removed block 37 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.04799999999999993 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 48, with score 0.021348. All blocks and scores: [(48, 0.02134821400977671), (45, 0.021492463536560535), (23, 0.02251929882913828), (41, 0.022546535125002265), (49, 0.022882127668708563), (42, 0.024888597195968032), (21, 0.024932743282988667), (22, 0.025249448837712407), (44, 0.025290721794590354), (24, 0.025949074886739254), (20, 0.027056807419285178), (27, 0.027325389673933387), (47, 0.027779607567936182), (25, 0.03060747985728085), (15, 0.0321243004873395), (19, 0.032318548299372196), (7, 0.03262563236057758), (51, 0.03936665039509535), (9, 0.04423065995797515), (6, 0.04652943508699536), (4, 0.04715154925361276), (14, 0.04795572720468044), (2, 0.05449524708092213), (3, 0.057644777465611696), (52, 0.058327038772404194), (13, 0.0592929064296186), (11, 0.0598793956451118), (17, 0.062020101584494114), (0, 0.0642291009426117), (1, 0.06709371693432331), (8, 0.0744428625330329), (10, 0.08142157644033432), (16, 0.08555465284734964), (12, 0.09059454407542944), (5, 0.10610753949731588), (36, 0.3952077031135559), (18, 0.5140345245599747), (53, 1.3412106186151505)]
computing accuracy for after removing block 48 . block score: 0.02134821400977671
removed block 48 current accuracy 0.8842 loss from initial  0.06720000000000004
since last training loss: 0.059799999999999964 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.021492. All blocks and scores: [(45, 0.021492463536560535), (23, 0.022519299294799566), (41, 0.022546534426510334), (42, 0.0248885964974761), (21, 0.02493274281732738), (22, 0.02524944767355919), (44, 0.025290722958743572), (49, 0.02560508158057928), (24, 0.02594907581806183), (20, 0.027056808350607753), (27, 0.027325388975441456), (47, 0.027779605938121676), (25, 0.030607480322942138), (15, 0.0321243004873395), (19, 0.03231854969635606), (7, 0.03262563236057758), (51, 0.039075775537639856), (9, 0.04423065762966871), (6, 0.04652943601831794), (4, 0.047151549719274044), (14, 0.04795572720468044), (2, 0.05449524661526084), (3, 0.057644777465611696), (13, 0.05929290736094117), (11, 0.05987939424812794), (17, 0.062020102981477976), (52, 0.06387910898774862), (0, 0.0642291009426117), (1, 0.06709371693432331), (8, 0.0744428588077426), (10, 0.0814215773716569), (16, 0.08555465470999479), (12, 0.09059454221278429), (5, 0.10610753856599331), (36, 0.3952076956629753), (18, 0.5140345171093941), (53, 1.477593407034874)]
computing accuracy for after removing block 45 . block score: 0.021492463536560535
removed block 45 current accuracy 0.8646 loss from initial  0.08679999999999999
training start
training epoch 0 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.1]
training epoch 1 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 2 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.1]
training epoch 3 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.1]
training epoch 4 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.1]
training epoch 5 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 6 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.1]
training epoch 7 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 8 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.940400)
finished training. finished 50 epochs. accuracy 0.9404 topk_dict {'top1': 0.9404}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022688. All blocks and scores: [(23, 0.022687844932079315), (21, 0.024951349711045623), (22, 0.02529095741920173), (24, 0.026060099713504314), (20, 0.027045401046052575), (27, 0.027484374353662133), (25, 0.03059307299554348), (15, 0.03230779571458697), (7, 0.03279753541573882), (19, 0.03279938828200102), (9, 0.044121528044342995), (49, 0.045049389358609915), (6, 0.04649959225207567), (4, 0.047632047440856695), (14, 0.04815898276865482), (44, 0.052047035191208124), (42, 0.052977933548390865), (47, 0.053448572754859924), (2, 0.05480455793440342), (51, 0.05546341184526682), (3, 0.05823458032682538), (41, 0.058574794325977564), (13, 0.059941298328340054), (11, 0.06009581731632352), (17, 0.06326845427975059), (0, 0.06411601789295673), (1, 0.06640252657234669), (52, 0.0677631450816989), (8, 0.07525550574064255), (10, 0.08185349870473146), (16, 0.08603543881326914), (12, 0.09096293617039919), (5, 0.10714661329984665), (18, 0.5151353031396866), (36, 0.6067191958427429), (53, 1.4000655263662338)]
computing accuracy for after removing block 23 . block score: 0.022687844932079315
removed block 23 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.024695. All blocks and scores: [(24, 0.024695296538993716), (21, 0.024951350409537554), (22, 0.0252909567207098), (20, 0.02704540081322193), (27, 0.027245287084951997), (25, 0.029487636173143983), (15, 0.032307795248925686), (7, 0.03279753541573882), (19, 0.03279938828200102), (9, 0.04412152757868171), (49, 0.04428966389968991), (6, 0.04649959038943052), (4, 0.04763204650953412), (14, 0.048158980906009674), (44, 0.051412489265203476), (47, 0.05234929081052542), (42, 0.05258527351543307), (51, 0.05464071175083518), (2, 0.05480455560609698), (41, 0.05801771255210042), (3, 0.05823458032682538), (13, 0.05994129506871104), (11, 0.06009581824764609), (17, 0.06326845614239573), (0, 0.06411601789295673), (52, 0.06535187736153603), (1, 0.06640252564102411), (8, 0.07525550667196512), (10, 0.08185349591076374), (16, 0.08603544160723686), (12, 0.09096293710172176), (5, 0.10714661423116922), (18, 0.515135295689106), (36, 0.6001252979040146), (53, 1.4140506237745285)]
computing accuracy for after removing block 24 . block score: 0.024695296538993716
removed block 24 current accuracy 0.93 loss from initial  0.021399999999999975
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.024951. All blocks and scores: [(21, 0.024951350409537554), (22, 0.025290956487879157), (27, 0.026691547594964504), (20, 0.02704540081322193), (25, 0.027954693417996168), (15, 0.0323077947832644), (7, 0.03279753681272268), (19, 0.032799388747662306), (49, 0.042136000003665686), (9, 0.04412152851000428), (6, 0.0464995913207531), (4, 0.047632047440856695), (14, 0.04815898276865482), (44, 0.04878798918798566), (42, 0.050293516367673874), (47, 0.05040776822715998), (51, 0.05195315880700946), (41, 0.05427621165290475), (2, 0.054804557003080845), (3, 0.058234581258147955), (52, 0.059770575258880854), (13, 0.059941296465694904), (11, 0.060095817781984806), (17, 0.06326845614239573), (0, 0.06411601696163416), (1, 0.06640252843499184), (8, 0.07525550946593285), (10, 0.08185350056737661), (16, 0.08603544067591429), (12, 0.09096293710172176), (5, 0.10714661702513695), (18, 0.5151353254914284), (36, 0.5777789056301117), (53, 1.4582389742136002)]
computing accuracy for after removing block 21 . block score: 0.024951350409537554
removed block 21 current accuracy 0.925 loss from initial  0.02639999999999998
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.023543. All blocks and scores: [(22, 0.023543454241007566), (27, 0.025773635366931558), (25, 0.026986361481249332), (20, 0.027045402210205793), (15, 0.0323077947832644), (7, 0.032797536347061396), (19, 0.03279938828200102), (49, 0.040137221571058035), (9, 0.044121528044342995), (42, 0.045526864007115364), (44, 0.045891174115240574), (6, 0.04649958945810795), (4, 0.047632047440856695), (47, 0.047781442292034626), (14, 0.048158982302993536), (51, 0.04964173538610339), (41, 0.0501743839122355), (52, 0.054080025758594275), (2, 0.05480455793440342), (3, 0.05823457986116409), (13, 0.059941297862678766), (11, 0.060095819644629955), (17, 0.06326845614239573), (0, 0.06411601789295673), (1, 0.06640252564102411), (8, 0.07525550574064255), (10, 0.08185349591076374), (16, 0.08603544067591429), (12, 0.09096293617039919), (5, 0.1071466114372015), (18, 0.5151353105902672), (36, 0.5474509745836258), (53, 1.4765938818454742)]
computing accuracy for after removing block 22 . block score: 0.023543454241007566
removed block 22 current accuracy 0.9096 loss from initial  0.04180000000000006
since last training loss: 0.03080000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 27, with score 0.025243. All blocks and scores: [(27, 0.025242753559723496), (25, 0.025970882270485163), (20, 0.027045402210205793), (15, 0.03230779571458697), (7, 0.03279753588140011), (19, 0.032799388747662306), (49, 0.03820451209321618), (44, 0.04367899475619197), (42, 0.04380795266479254), (9, 0.04412152711302042), (47, 0.04522619163617492), (6, 0.04649959085509181), (51, 0.04725259589031339), (4, 0.04763204697519541), (14, 0.048158982302993536), (41, 0.048979253973811865), (52, 0.04906668607145548), (2, 0.05480455793440342), (3, 0.05823458172380924), (13, 0.059941297862678766), (11, 0.06009581685066223), (17, 0.06326845521107316), (0, 0.06411601789295673), (1, 0.06640252564102411), (8, 0.0752555076032877), (10, 0.08185349870473146), (16, 0.08603544160723686), (12, 0.09096293430775404), (5, 0.10714661423116922), (18, 0.5151353105902672), (36, 0.5361347496509552), (53, 1.4721006453037262)]
computing accuracy for after removing block 27 . block score: 0.025242753559723496
removed block 27 current accuracy 0.893 loss from initial  0.05840000000000001
since last training loss: 0.0474 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.025971. All blocks and scores: [(25, 0.02597088273614645), (20, 0.027045401511713862), (15, 0.032307795248925686), (7, 0.03279753681272268), (19, 0.03279938828200102), (49, 0.037048444617539644), (47, 0.04267297079786658), (44, 0.04298116406425834), (42, 0.04411838762462139), (9, 0.04412152757868171), (52, 0.04567666258662939), (6, 0.04649959271773696), (51, 0.04705252917483449), (4, 0.047632047440856695), (14, 0.04815898183733225), (41, 0.04916164884343743), (2, 0.054804560262709856), (3, 0.05823458079248667), (13, 0.05994129879400134), (11, 0.06009581871330738), (17, 0.06326845474541187), (0, 0.06411601509898901), (1, 0.06640252564102411), (8, 0.0752555076032877), (10, 0.08185350056737661), (16, 0.08603544067591429), (12, 0.09096293337643147), (5, 0.10714661609381437), (18, 0.5151353105902672), (36, 0.5412762612104416), (53, 1.4969091266393661)]
computing accuracy for after removing block 25 . block score: 0.02597088273614645
removed block 25 current accuracy 0.852 loss from initial  0.09940000000000004
since last training loss: 0.08840000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.027045. All blocks and scores: [(20, 0.02704540081322193), (15, 0.03230779664590955), (7, 0.032797536347061396), (19, 0.032799388747662306), (49, 0.037746081594377756), (47, 0.04198013711720705), (44, 0.04370610881596804), (9, 0.044121528044342995), (52, 0.04619059665128589), (6, 0.046499589923769236), (4, 0.04763204697519541), (42, 0.04791404725983739), (14, 0.048158982302993536), (51, 0.04861694388091564), (2, 0.05480455793440342), (41, 0.05553637491539121), (3, 0.05823457986116409), (13, 0.059941299725323915), (11, 0.06009581685066223), (17, 0.06326845474541187), (0, 0.06411601696163416), (1, 0.06640252564102411), (8, 0.0752555076032877), (10, 0.08185349870473146), (16, 0.08603543974459171), (12, 0.09096293337643147), (5, 0.10714661236852407), (18, 0.515135295689106), (36, 0.581321157515049), (53, 1.5337578654289246)]
computing accuracy for after removing block 20 . block score: 0.02704540081322193
removed block 20 current accuracy 0.8308 loss from initial  0.12060000000000004
since last training loss: 0.10960000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.032308. All blocks and scores: [(15, 0.0323077947832644), (7, 0.03279753588140011), (19, 0.032799387350678444), (49, 0.036393824964761734), (47, 0.0398447597399354), (52, 0.04249220062047243), (44, 0.042819018475711346), (9, 0.04412152711302042), (42, 0.045866766944527626), (6, 0.04649959085509181), (4, 0.04763204697519541), (14, 0.048158982302993536), (51, 0.0481992824934423), (41, 0.054452091455459595), (2, 0.05480455793440342), (3, 0.05823457892984152), (13, 0.059941298328340054), (11, 0.060095817781984806), (17, 0.06326845567673445), (0, 0.06411601696163416), (1, 0.06640252657234669), (8, 0.07525550853461027), (10, 0.08185350056737661), (16, 0.08603544160723686), (12, 0.09096293617039919), (5, 0.1071466151624918), (18, 0.5151353031396866), (36, 0.5748301595449448), (53, 1.5040237754583359)]
computing accuracy for after removing block 15 . block score: 0.0323077947832644
removed block 15 current accuracy 0.8248 loss from initial  0.12660000000000005
since last training loss: 0.11560000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 7, with score 0.032798. All blocks and scores: [(7, 0.03279753541573882), (19, 0.0330179282464087), (49, 0.036295331083238125), (47, 0.04100805567577481), (44, 0.042270132806152105), (52, 0.04314721142873168), (9, 0.04412152664735913), (42, 0.04628900624811649), (6, 0.04649959085509181), (4, 0.04763204697519541), (14, 0.04815898276865482), (51, 0.04894085647538304), (41, 0.05408676480874419), (2, 0.05480455793440342), (3, 0.05823458032682538), (13, 0.05994129925966263), (11, 0.060095819644629955), (0, 0.06411601882427931), (1, 0.06640252843499184), (17, 0.06724785175174475), (8, 0.07525550667196512), (10, 0.08185350056737661), (12, 0.09096293710172176), (16, 0.09605157654732466), (5, 0.10714661609381437), (18, 0.5024327673017979), (36, 0.575291745364666), (53, 1.5464778989553452)]
computing accuracy for after removing block 7 . block score: 0.03279753541573882
removed block 7 current accuracy 0.8024 loss from initial  0.14900000000000002
training start
training epoch 0 val accuracy 0.8122 topk_dict {'top1': 0.8122} is_best True lr [0.1]
training epoch 1 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.1]
training epoch 2 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 3 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 4 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 5 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 7 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 8 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 9 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 10 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.934800)
finished training. finished 50 epochs. accuracy 0.9348 topk_dict {'top1': 0.9348}
start iteration 27
[activation diff]: block to remove picked: 44, with score 0.047122. All blocks and scores: [(44, 0.04712243052199483), (4, 0.04753789212554693), (47, 0.04855306167155504), (49, 0.05270695220679045), (6, 0.052893901243805885), (2, 0.05484541552141309), (42, 0.0578508242033422), (3, 0.05823033628985286), (51, 0.059661269187927246), (9, 0.060782771557569504), (13, 0.06211646972224116), (41, 0.06314539723098278), (14, 0.06402993202209473), (0, 0.06413896381855011), (17, 0.065943225286901), (1, 0.06695680320262909), (52, 0.07054253853857517), (11, 0.07070096395909786), (8, 0.08218673709779978), (10, 0.08580758608877659), (5, 0.10707168653607368), (16, 0.11112773697823286), (19, 0.11174606624990702), (12, 0.14156743325293064), (36, 0.6600713953375816), (18, 0.7418529987335205), (53, 1.410376325249672)]
computing accuracy for after removing block 44 . block score: 0.04712243052199483
removed block 44 current accuracy 0.9234 loss from initial  0.028000000000000025
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 4, with score 0.047538. All blocks and scores: [(4, 0.04753789212554693), (47, 0.05251001100987196), (6, 0.0528939007781446), (49, 0.053705738857388496), (2, 0.05484541645273566), (42, 0.05785082373768091), (3, 0.05823033628985286), (51, 0.05890884576365352), (9, 0.060782771557569504), (13, 0.06211647065356374), (41, 0.06314539862796664), (14, 0.06402993202209473), (0, 0.06413896381855011), (17, 0.06594322249293327), (52, 0.0664956346154213), (1, 0.06695680413395166), (11, 0.07070096675306559), (8, 0.08218673802912235), (10, 0.08580758608877659), (5, 0.10707168653607368), (16, 0.11112774163484573), (19, 0.11174606811255217), (12, 0.1415674351155758), (36, 0.6600713953375816), (18, 0.7418529614806175), (53, 1.598025918006897)]
computing accuracy for after removing block 4 . block score: 0.04753789212554693
removed block 4 current accuracy 0.9172 loss from initial  0.03420000000000001
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 47, with score 0.052808. All blocks and scores: [(47, 0.05280831875279546), (49, 0.05435037240386009), (2, 0.054845417849719524), (6, 0.05793068092316389), (51, 0.058176830410957336), (3, 0.05823033396154642), (42, 0.05976304970681667), (13, 0.06145015824586153), (14, 0.06262327078729868), (9, 0.06368542090058327), (17, 0.06387291941791773), (0, 0.06413896381855011), (41, 0.06461954303085804), (1, 0.06695680413395166), (52, 0.06700371392071247), (11, 0.06870133429765701), (8, 0.07917146198451519), (10, 0.08294263761490583), (16, 0.09904746245592833), (5, 0.11142723634839058), (19, 0.1145327715203166), (12, 0.13622717931866646), (36, 0.6761189624667168), (18, 0.7535134255886078), (53, 1.5637772381305695)]
computing accuracy for after removing block 47 . block score: 0.05280831875279546
removed block 47 current accuracy 0.897 loss from initial  0.054400000000000004
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 2, with score 0.054845. All blocks and scores: [(2, 0.05484541691839695), (6, 0.05793068278580904), (51, 0.05793989868834615), (3, 0.058230336755514145), (49, 0.059729390777647495), (42, 0.0597630487754941), (52, 0.06139064207673073), (13, 0.061450157314538956), (14, 0.06262327264994383), (9, 0.06368541810661554), (17, 0.06387291569262743), (0, 0.06413896474987268), (41, 0.06461954489350319), (1, 0.06695680413395166), (11, 0.06870133150368929), (8, 0.07917145639657974), (10, 0.08294263668358326), (16, 0.09904746152460575), (5, 0.11142723634839058), (19, 0.11453277245163918), (12, 0.1362271811813116), (36, 0.6761189475655556), (18, 0.7535134553909302), (53, 1.6443327367305756)]
computing accuracy for after removing block 2 . block score: 0.05484541691839695
removed block 2 current accuracy 0.8774 loss from initial  0.07400000000000007
since last training loss: 0.05740000000000001 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 6, with score 0.052385. All blocks and scores: [(6, 0.05238481843844056), (3, 0.0531795471906662), (51, 0.054504421539604664), (49, 0.05615201871842146), (42, 0.05672215297818184), (52, 0.05711099039763212), (41, 0.057762965094298124), (17, 0.057999083772301674), (14, 0.05834911670535803), (13, 0.059719703160226345), (9, 0.06344984285533428), (0, 0.06413896474987268), (11, 0.0647201044484973), (1, 0.06695680506527424), (8, 0.07402789685875177), (10, 0.07937073428183794), (16, 0.0875052073970437), (19, 0.10068207047879696), (5, 0.10802276339381933), (12, 0.12952652014791965), (36, 0.6307338327169418), (18, 0.6894985139369965), (53, 1.71222385764122)]
computing accuracy for after removing block 6 . block score: 0.05238481843844056
removed block 6 current accuracy 0.8508 loss from initial  0.10060000000000002
since last training loss: 0.08399999999999996 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 41, with score 0.050524. All blocks and scores: [(41, 0.050523541402071714), (14, 0.0505465529859066), (51, 0.051431534346193075), (49, 0.05175056355074048), (52, 0.052419690415263176), (42, 0.05313159245997667), (3, 0.05317954579368234), (13, 0.05545890936627984), (17, 0.056866972241550684), (9, 0.059566217474639416), (11, 0.06059700716286898), (0, 0.06413896568119526), (1, 0.06695680692791939), (8, 0.07168546225875616), (16, 0.08005021698772907), (19, 0.08908749558031559), (10, 0.0909222336485982), (5, 0.10802276059985161), (12, 0.12313634809106588), (36, 0.5960123240947723), (18, 0.6517026275396347), (53, 1.803170070052147)]
computing accuracy for after removing block 41 . block score: 0.050523541402071714
removed block 41 current accuracy 0.8122 loss from initial  0.1392
since last training loss: 0.12259999999999993 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 52, with score 0.049146. All blocks and scores: [(52, 0.049146056175231934), (51, 0.04941896256059408), (14, 0.050546552054584026), (49, 0.051460649352520704), (3, 0.053179547656327486), (13, 0.05545890890061855), (17, 0.05686697131022811), (9, 0.05956621700897813), (11, 0.06059700669720769), (42, 0.06100595789030194), (0, 0.06413896474987268), (1, 0.06695680599659681), (8, 0.07168546039611101), (16, 0.0800502160564065), (19, 0.08908749558031559), (10, 0.09092223551124334), (5, 0.10802276153117418), (12, 0.12313634995371103), (36, 0.5960123240947723), (18, 0.6517026275396347), (53, 1.9155459254980087)]
computing accuracy for after removing block 52 . block score: 0.049146056175231934
removed block 52 current accuracy 0.7392 loss from initial  0.21220000000000006
since last training loss: 0.1956 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 51, with score 0.049419. All blocks and scores: [(51, 0.04941896162927151), (14, 0.05054655158892274), (49, 0.051460650749504566), (3, 0.05317954812198877), (13, 0.055458910297602415), (17, 0.05686696944758296), (9, 0.05956621654331684), (11, 0.060597009025514126), (42, 0.061005959287285805), (0, 0.06413896381855011), (1, 0.06695680413395166), (8, 0.07168545946478844), (16, 0.0800502160564065), (19, 0.08908749837428331), (10, 0.0909222299233079), (5, 0.10802276339381933), (12, 0.12313634809106588), (36, 0.5960123464465141), (18, 0.6517026275396347), (53, 1.8622736632823944)]
computing accuracy for after removing block 51 . block score: 0.04941896162927151
removed block 51 current accuracy 0.6 loss from initial  0.35140000000000005
since last training loss: 0.3348 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 14, with score 0.050547. All blocks and scores: [(14, 0.050546552520245314), (49, 0.05146065168082714), (3, 0.05317954579368234), (13, 0.05545890983194113), (17, 0.05686696991324425), (9, 0.059566215611994267), (11, 0.060597009025514126), (42, 0.061005957424640656), (0, 0.06413896381855011), (1, 0.06695680413395166), (8, 0.07168546132743359), (16, 0.0800502160564065), (19, 0.08908749371767044), (10, 0.09092223178595304), (5, 0.1080227643251419), (12, 0.12313635088503361), (36, 0.5960123315453529), (18, 0.6517026275396347), (53, 2.0695429742336273)]
computing accuracy for after removing block 14 . block score: 0.050546552520245314
removed block 14 current accuracy 0.4324 loss from initial  0.519
since last training loss: 0.5024 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 49, with score 0.049108. All blocks and scores: [(49, 0.04910783423110843), (3, 0.05317954579368234), (13, 0.05545890890061855), (17, 0.05587249016389251), (9, 0.05956621468067169), (11, 0.06059700669720769), (42, 0.06369529850780964), (0, 0.06413896474987268), (1, 0.06695680506527424), (8, 0.07168546132743359), (19, 0.08328683115541935), (10, 0.09092223178595304), (16, 0.09553236048668623), (5, 0.10802276618778706), (12, 0.12313634809106588), (36, 0.6026218011975288), (18, 0.6570744812488556), (53, 2.2980065643787384)]
computing accuracy for after removing block 49 . block score: 0.04910783423110843
removed block 49 current accuracy 0.352 loss from initial  0.5994
since last training loss: 0.5828 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 3, with score 0.053180. All blocks and scores: [(3, 0.05317955045029521), (13, 0.0554589107632637), (17, 0.05587249202653766), (9, 0.05956621514633298), (11, 0.06059700483456254), (42, 0.06369529850780964), (0, 0.06413896474987268), (1, 0.06695680506527424), (8, 0.07168546039611101), (19, 0.0832868292927742), (10, 0.0909222299233079), (16, 0.09553235862404108), (5, 0.1080227643251419), (12, 0.12313634343445301), (36, 0.6026217937469482), (18, 0.6570744588971138), (53, 2.357412427663803)]
computing accuracy for after removing block 3 . block score: 0.05317955045029521
removed block 3 current accuracy 0.2722 loss from initial  0.6792
since last training loss: 0.6626 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.053422. All blocks and scores: [(17, 0.053422142285853624), (13, 0.05450510326772928), (11, 0.056982362642884254), (9, 0.06287345755845308), (42, 0.06365450844168663), (0, 0.06413896288722754), (1, 0.06695680692791939), (8, 0.06862391717731953), (16, 0.06991869118064642), (19, 0.07373673841357231), (10, 0.08981788251549006), (5, 0.11163723189383745), (12, 0.1167612336575985), (36, 0.595287062227726), (18, 0.626522570848465), (53, 2.3087225556373596)]
computing accuracy for after removing block 17 . block score: 0.053422142285853624
removed block 17 current accuracy 0.2564 loss from initial  0.6950000000000001
training start
training epoch 0 val accuracy 0.81 topk_dict {'top1': 0.81} is_best True lr [0.1]
training epoch 1 val accuracy 0.858 topk_dict {'top1': 0.858} is_best True lr [0.1]
training epoch 2 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 3 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.1]
training epoch 4 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best False lr [0.1]
training epoch 5 val accuracy 0.8308 topk_dict {'top1': 0.8308} is_best False lr [0.1]
training epoch 6 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 7 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 8 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best True lr [0.1]
training epoch 9 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.1]
training epoch 10 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.930400)
finished training. finished 50 epochs. accuracy 0.9304 topk_dict {'top1': 0.9304}
