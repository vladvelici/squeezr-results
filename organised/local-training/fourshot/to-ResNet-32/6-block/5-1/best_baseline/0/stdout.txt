start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589616805315), (30, 0.01001118728891015), (31, 0.010232581640593708), (34, 0.013294660719111562), (29, 0.013421116629615426), (35, 0.01595769007690251), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019996492424979806), (46, 0.020590224768966436), (25, 0.022078294539824128), (23, 0.022228715242817998), (41, 0.022336415480822325), (44, 0.023145999060943723), (40, 0.023749591084197164), (45, 0.023975494783371687), (21, 0.024941089563071728), (48, 0.024957706918939948), (22, 0.025151390815153718), (50, 0.025287174386903644), (24, 0.025880583096295595), (49, 0.02591664926148951), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129482097924), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03791803075000644), (51, 0.04178758803755045), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428550750017), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464461103082), (1, 0.06593216117471457), (52, 0.06606104411184788), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581291347742), (34, 0.013119244133122265), (29, 0.013421116746030748), (26, 0.01607214054092765), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.019852687837556005), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.02222871477715671), (44, 0.022977193351835012), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025575740495696664), (24, 0.02588058216497302), (42, 0.02589341253042221), (20, 0.026848892215639353), (47, 0.028072760673239827), (38, 0.0310911878477782), (39, 0.031191361835226417), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4339806064963341), (18, 0.5117432847619057), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.013421117095276713), (35, 0.01591842109337449), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019850464770570397), (46, 0.02041191584430635), (41, 0.021827629301697016), (25, 0.022078294306993484), (23, 0.022228715708479285), (44, 0.022891478380188346), (40, 0.02360257925465703), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.024941089563071728), (22, 0.025151389883831143), (49, 0.025392550276592374), (42, 0.025712220929563046), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.028052504872903228), (38, 0.030935873743146658), (39, 0.03117303689941764), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525438442826), (0, 0.06337464461103082), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4350203163921833), (18, 0.5117432996630669), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421116513200104), (35, 0.015918649034574628), (26, 0.016072141006588936), (28, 0.01763686048798263), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.02222871594130993), (44, 0.023001376073807478), (40, 0.023739926517009735), (45, 0.02379016811028123), (48, 0.024350044783204794), (50, 0.02446310594677925), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025246929842978716), (42, 0.025273551233112812), (24, 0.02588058216497302), (20, 0.02684889198280871), (47, 0.02772757434286177), (38, 0.030746274162083864), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.04082479793578386), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06356756063178182), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693086862564), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116978861392), (35, 0.015968912048265338), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.020137187093496323), (41, 0.02158405538648367), (25, 0.022078295471146703), (23, 0.02222871477715671), (44, 0.02268732525408268), (40, 0.023569098440930247), (45, 0.02384072169661522), (48, 0.024108359590172768), (50, 0.024114209227263927), (49, 0.024870117427781224), (21, 0.024941088864579797), (42, 0.02504557464271784), (22, 0.0251513896510005), (24, 0.02588058216497302), (20, 0.026848892215639353), (47, 0.02742385142482817), (38, 0.03073564823716879), (39, 0.0314104245044291), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.06270107766613364), (0, 0.06337464274838567), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43692684173583984), (18, 0.5117432922124863), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.01763686165213585), (27, 0.019022798165678978), (43, 0.02030268427915871), (46, 0.020324197132140398), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.023045078618451953), (48, 0.024024547543376684), (50, 0.024096973473206162), (40, 0.024156817235052586), (45, 0.024168409407138824), (49, 0.024922373006120324), (21, 0.02494108909741044), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.025880583096295595), (20, 0.026848892215639353), (47, 0.027568295830860734), (38, 0.03178726392798126), (15, 0.0320583856664598), (39, 0.03225791361182928), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.04008621396496892), (37, 0.04069073125720024), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428923279047), (11, 0.05970003502443433), (17, 0.06132525531575084), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.44933702424168587), (18, 0.5117433071136475), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.01637051161378622), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.019988975720480084), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022692032624036074), (48, 0.023521372117102146), (50, 0.02353389048948884), (40, 0.02361623989418149), (45, 0.023933291900902987), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.024941088631749153), (22, 0.025151389883831143), (24, 0.02588058332912624), (47, 0.026813455624505877), (20, 0.026848891051486135), (38, 0.031083731446415186), (39, 0.032056888565421104), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03907974809408188), (37, 0.04015214554965496), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.05970003269612789), (52, 0.060369073413312435), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750651538372), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022507571382448077), (48, 0.022899368777871132), (50, 0.022937727626413107), (40, 0.023057401413097978), (42, 0.023520408431068063), (45, 0.023633699165657163), (49, 0.02408191910944879), (21, 0.024941089330241084), (22, 0.025151389883831143), (24, 0.025880582397803664), (47, 0.02632279205136001), (20, 0.026848892215639353), (38, 0.030149149475619197), (39, 0.03146669687703252), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03785192780196667), (37, 0.039268902968615294), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241463959217), (2, 0.05457740416750312), (3, 0.057849929202347994), (52, 0.05846811830997467), (13, 0.059144286904484034), (11, 0.05970003176480532), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.43490003049373627), (18, 0.5117433145642281), (53, 0.8595060780644417)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381991423666477), (27, 0.01876970916055143), (46, 0.01884230156429112), (41, 0.019016370410099626), (48, 0.021309157134965062), (50, 0.021624521585181355), (44, 0.021748854545876384), (40, 0.02191696665249765), (42, 0.021930373972281814), (25, 0.022078295471146703), (23, 0.02222871547564864), (45, 0.02273644949309528), (49, 0.022970063611865044), (21, 0.024941089330241084), (22, 0.025151390582323074), (47, 0.02535583171993494), (24, 0.025880582397803664), (20, 0.02684889198280871), (38, 0.028691887855529785), (39, 0.02962443232536316), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.036016357596963644), (37, 0.03643036773428321), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740416750312), (52, 0.05466857925057411), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.41641608625650406), (18, 0.5117432996630669), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 1 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.1]
training epoch 2 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 3 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.1]
training epoch 4 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.1]
training epoch 5 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.1]
training epoch 6 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.1]
training epoch 7 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 8 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.1]
training epoch 9 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.020664. All blocks and scores: [(43, 0.02066404139623046), (46, 0.02081154426559806), (27, 0.021123518468812108), (21, 0.022234609816223383), (41, 0.02228059433400631), (22, 0.023264026502147317), (44, 0.02328100148588419), (23, 0.02340044640004635), (45, 0.023789709201082587), (40, 0.023950723931193352), (48, 0.024720138870179653), (50, 0.025386941619217396), (49, 0.02590240095742047), (25, 0.02602629200555384), (42, 0.02640124480240047), (24, 0.026714913547039032), (20, 0.027219252893701196), (47, 0.028746565338224173), (39, 0.03217527503147721), (15, 0.03226990904659033), (19, 0.032691088039427996), (38, 0.032691631466150284), (7, 0.0327772400341928), (51, 0.040087724570184946), (37, 0.040444647427648306), (9, 0.04390624072402716), (6, 0.04698401689529419), (14, 0.047931088134646416), (4, 0.048815269488841295), (2, 0.05492351250723004), (3, 0.059150501154363155), (13, 0.05951024917885661), (11, 0.0598015608265996), (17, 0.06306976405903697), (52, 0.06417634570971131), (0, 0.06489173881709576), (1, 0.06719432678073645), (8, 0.07453479617834091), (10, 0.08155585173517466), (16, 0.0846178662031889), (12, 0.0902889957651496), (5, 0.10706499963998795), (36, 0.38174357265233994), (18, 0.5157246217131615), (53, 0.8032270520925522)]
computing accuracy for after removing block 43 . block score: 0.02066404139623046
removed block 43 current accuracy 0.94 loss from initial  0.011400000000000077
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 27, with score 0.021124. All blocks and scores: [(27, 0.021123517770320177), (46, 0.021730065578594804), (21, 0.022234609350562096), (41, 0.022280593868345022), (22, 0.02326402673497796), (23, 0.023400446865707636), (40, 0.023950723698362708), (44, 0.024932326981797814), (45, 0.025043035158887506), (50, 0.02555640903301537), (49, 0.025815711356699467), (48, 0.025883389404043555), (25, 0.02602629200555384), (42, 0.02640124480240047), (24, 0.02671491331420839), (20, 0.0272192545235157), (47, 0.029891121899709105), (39, 0.0321752754971385), (15, 0.03226990858092904), (19, 0.03269108757376671), (38, 0.032691631000488997), (7, 0.03277724049985409), (51, 0.039762338157743216), (37, 0.04044464696198702), (9, 0.04390624072402716), (6, 0.04698401689529419), (14, 0.04793108766898513), (4, 0.04881526855751872), (2, 0.054923513904213905), (3, 0.05915049975737929), (13, 0.05951024917885661), (11, 0.059801561292260885), (17, 0.06306976545602083), (52, 0.06365882977843285), (0, 0.06489173695445061), (1, 0.06719432771205902), (8, 0.07453480083495378), (10, 0.08155585080385208), (16, 0.0846178662031889), (12, 0.09028899669647217), (5, 0.10706499963998795), (36, 0.38174357637763023), (18, 0.5157246068120003), (53, 0.845803290605545)]
computing accuracy for after removing block 27 . block score: 0.021123517770320177
removed block 27 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.006799999999999917 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.021126. All blocks and scores: [(46, 0.021126241190358996), (41, 0.021842046175152063), (21, 0.02223460958339274), (22, 0.02326402673497796), (40, 0.023335369303822517), (23, 0.023400445701554418), (45, 0.024532331619411707), (44, 0.02471470576710999), (50, 0.024953441927209496), (49, 0.025054215220734477), (48, 0.02525924565270543), (42, 0.02581675653345883), (25, 0.026026292936876416), (24, 0.026714913779869676), (20, 0.027219254057854414), (47, 0.029084838228300214), (39, 0.03186888410709798), (15, 0.032269909512251616), (38, 0.032471103593707085), (19, 0.03269108897075057), (7, 0.03277724049985409), (51, 0.03896781010553241), (37, 0.0413802838884294), (9, 0.04390624025836587), (6, 0.046984015963971615), (14, 0.04793108720332384), (4, 0.04881526855751872), (2, 0.05492351250723004), (3, 0.059150501154363155), (13, 0.05951024917885661), (11, 0.059801561292260885), (52, 0.06267838040366769), (17, 0.06306976452469826), (0, 0.06489173788577318), (1, 0.0671943249180913), (8, 0.07453479617834091), (10, 0.0815558498725295), (16, 0.08461786527186632), (12, 0.0902889957651496), (5, 0.1070649940520525), (36, 0.3851030468940735), (18, 0.5157246068120003), (53, 0.8666747063398361)]
computing accuracy for after removing block 46 . block score: 0.021126241190358996
removed block 46 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.021842. All blocks and scores: [(41, 0.021842046407982707), (21, 0.02223460958339274), (22, 0.023264026502147317), (40, 0.023335369070991874), (23, 0.023400446865707636), (45, 0.024532330688089132), (44, 0.024714704835787416), (50, 0.02508281567133963), (48, 0.025546006858348846), (49, 0.025698241544887424), (42, 0.025816756999120116), (25, 0.02602629200555384), (24, 0.026714913081377745), (20, 0.02721925382502377), (47, 0.03103584609925747), (39, 0.03186888410709798), (15, 0.03226990904659033), (38, 0.032471103593707085), (19, 0.03269108943641186), (7, 0.03277723956853151), (51, 0.03916589915752411), (37, 0.04138028295710683), (9, 0.04390624072402716), (6, 0.046984015963971615), (14, 0.047931088134646416), (4, 0.04881526809185743), (2, 0.05492351111024618), (3, 0.059150501154363155), (13, 0.05951025104150176), (11, 0.0598015608265996), (52, 0.062486521899700165), (17, 0.06306976545602083), (0, 0.06489173602312803), (1, 0.06719432678073645), (8, 0.07453479710966349), (10, 0.08155584894120693), (16, 0.0846178662031889), (12, 0.09028899669647217), (5, 0.10706499684602022), (36, 0.3851030468940735), (18, 0.5157246068120003), (53, 0.957291841506958)]
computing accuracy for after removing block 41 . block score: 0.021842046407982707
removed block 41 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 21, with score 0.022235. All blocks and scores: [(21, 0.02223461028188467), (22, 0.023264026502147317), (40, 0.023335368605330586), (23, 0.023400446167215705), (45, 0.024747240589931607), (50, 0.024758801329880953), (48, 0.024784149136394262), (49, 0.025372111005708575), (44, 0.025847246404737234), (25, 0.02602629200555384), (42, 0.026122967014089227), (24, 0.026714913779869676), (20, 0.02721925382502377), (47, 0.03133650543168187), (39, 0.03186888410709798), (15, 0.03226990904659033), (38, 0.032471103593707085), (19, 0.032691089902073145), (7, 0.03277723956853151), (51, 0.03775596898049116), (37, 0.0413802838884294), (9, 0.043906241189688444), (6, 0.0469840164296329), (14, 0.04793108766898513), (4, 0.048815267626196146), (2, 0.05492351297289133), (3, 0.05915050068870187), (13, 0.05951024917885661), (11, 0.05980156268924475), (52, 0.06018266314640641), (17, 0.06306976592168212), (0, 0.06489173788577318), (1, 0.0671943249180913), (8, 0.07453479710966349), (10, 0.08155584800988436), (16, 0.08461786340922117), (12, 0.09028899483382702), (5, 0.10706499684602022), (36, 0.3851030617952347), (18, 0.5157245993614197), (53, 1.0362099558115005)]
computing accuracy for after removing block 21 . block score: 0.02223461028188467
removed block 21 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.021102. All blocks and scores: [(22, 0.02110237954184413), (23, 0.021323262015357614), (40, 0.022326290840283036), (24, 0.023272052872925997), (50, 0.023853017017245293), (48, 0.023916892940178514), (42, 0.024076415691524744), (25, 0.02417556825093925), (44, 0.02443441585637629), (45, 0.024515761760994792), (49, 0.024814347736537457), (20, 0.02721925382502377), (47, 0.03041948936879635), (39, 0.03152628103271127), (38, 0.031652880599722266), (15, 0.03226990904659033), (19, 0.03269108897075057), (7, 0.032777240965515375), (51, 0.03646377148106694), (37, 0.04082665592432022), (9, 0.04390624212101102), (6, 0.0469840164296329), (14, 0.0479310886003077), (4, 0.048815267626196146), (2, 0.05492351250723004), (52, 0.05674000969156623), (3, 0.05915050208568573), (13, 0.05951024917885661), (11, 0.05980156175792217), (17, 0.06306976592168212), (0, 0.06489173695445061), (1, 0.06719432584941387), (8, 0.07453479617834091), (10, 0.0815558498725295), (16, 0.08461786527186632), (12, 0.09028899669647217), (5, 0.10706499963998795), (36, 0.36932223290205), (18, 0.5157245993614197), (53, 1.0561773926019669)]
computing accuracy for after removing block 22 . block score: 0.02110237954184413
removed block 22 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.020228. All blocks and scores: [(23, 0.02022750163450837), (24, 0.021845317212864757), (40, 0.021912181051447988), (42, 0.023191992426291108), (50, 0.02330388524569571), (25, 0.023430102271959186), (48, 0.02353344764560461), (44, 0.02385877794586122), (45, 0.024378936272114515), (49, 0.024385585449635983), (20, 0.02721925382502377), (47, 0.029589274199679494), (39, 0.03170492756180465), (38, 0.03176323766820133), (15, 0.032269909512251616), (19, 0.03269108850508928), (7, 0.03277724049985409), (51, 0.03558384906500578), (37, 0.04219789523631334), (9, 0.04390624025836587), (6, 0.04698401549831033), (14, 0.047931086737662554), (4, 0.048815269488841295), (52, 0.0548504707403481), (2, 0.054923512041568756), (3, 0.05915050068870187), (13, 0.05951024824753404), (11, 0.0598015608265996), (17, 0.06306976545602083), (0, 0.06489173695445061), (1, 0.06719432678073645), (8, 0.07453479617834091), (10, 0.0815558498725295), (16, 0.08461786434054375), (12, 0.09028899669647217), (5, 0.1070649940520525), (36, 0.37015051022171974), (18, 0.5157246142625809), (53, 1.070149913430214)]
computing accuracy for after removing block 23 . block score: 0.02022750163450837
removed block 23 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.03599999999999992 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 24, with score 0.020824. All blocks and scores: [(24, 0.020823867060244083), (40, 0.021527171600610018), (42, 0.02293780748732388), (50, 0.023085090331733227), (48, 0.023355521028861403), (25, 0.023602059576660395), (44, 0.02387936576269567), (49, 0.024413923965767026), (45, 0.024534494383260608), (20, 0.027219254290685058), (47, 0.029094965429976583), (39, 0.031978925224393606), (38, 0.0320152691565454), (15, 0.03226990858092904), (19, 0.03269108850508928), (7, 0.0327772400341928), (51, 0.03538794117048383), (9, 0.04390624072402716), (37, 0.044639128260314465), (6, 0.0469840164296329), (14, 0.0479310886003077), (4, 0.04881526716053486), (52, 0.054390802048146725), (2, 0.05492351111024618), (3, 0.05915050068870187), (13, 0.05951024778187275), (11, 0.05980156222358346), (17, 0.06306976731866598), (0, 0.06489173788577318), (1, 0.0671943249180913), (8, 0.07453479897230864), (10, 0.08155584707856178), (16, 0.08461786340922117), (12, 0.09028899483382702), (5, 0.10706499591469765), (36, 0.3813147284090519), (18, 0.5157246142625809), (53, 1.096097618341446)]
computing accuracy for after removing block 24 . block score: 0.020823867060244083
removed block 24 current accuracy 0.8944 loss from initial  0.05700000000000005
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.020721. All blocks and scores: [(40, 0.020721071399748325), (50, 0.0216854193713516), (42, 0.021900137420743704), (48, 0.022239523008465767), (49, 0.02310789842158556), (44, 0.02327162609435618), (25, 0.02345452015288174), (45, 0.023561146343126893), (20, 0.0272192545235157), (47, 0.027398200472816825), (39, 0.03120444668456912), (38, 0.0313949859701097), (15, 0.03226990904659033), (19, 0.03269108943641186), (7, 0.0327772400341928), (51, 0.033859238028526306), (9, 0.043906241189688444), (37, 0.044604229275137186), (6, 0.046984017826616764), (14, 0.0479310886003077), (4, 0.04881526716053486), (52, 0.05066245887428522), (2, 0.05492351157590747), (3, 0.059150501154363155), (13, 0.059510250110179186), (11, 0.05980156268924475), (17, 0.06306976731866598), (0, 0.06489173788577318), (1, 0.06719432584941387), (8, 0.07453479524701834), (10, 0.0815558498725295), (16, 0.08461786713451147), (12, 0.09028899483382702), (5, 0.10706499870866537), (36, 0.37657351791858673), (18, 0.5157246142625809), (53, 1.1157140284776688)]
computing accuracy for after removing block 40 . block score: 0.020721071399748325
removed block 40 current accuracy 0.886 loss from initial  0.06540000000000001
training start
training epoch 0 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 1 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.1]
training epoch 3 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best True lr [0.1]
training epoch 4 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.1]
training epoch 5 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 6 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 7 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 8 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.1]
training epoch 9 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.939400)
finished training. finished 50 epochs. accuracy 0.9394 topk_dict {'top1': 0.9394}
start iteration 18
[activation diff]: block to remove picked: 47, with score 0.022913. All blocks and scores: [(47, 0.022912679240107536), (45, 0.023671859176829457), (44, 0.025098441634327173), (50, 0.028815411729738116), (49, 0.0295890502166003), (48, 0.03081851708702743), (42, 0.032308063469827175), (15, 0.03231056407094002), (7, 0.032801106572151184), (51, 0.043548814952373505), (9, 0.04395893355831504), (39, 0.044587592128664255), (38, 0.044963160529732704), (6, 0.046218135859817266), (4, 0.04627330880612135), (14, 0.048037955071777105), (2, 0.05475839227437973), (37, 0.05711771082133055), (3, 0.057577645406126976), (11, 0.0597766968421638), (13, 0.0599880893714726), (0, 0.06340089160948992), (19, 0.06357259023934603), (1, 0.06726936064660549), (52, 0.06770141422748566), (17, 0.07068715803325176), (20, 0.07387815974652767), (8, 0.07457847986370325), (10, 0.08145146071910858), (25, 0.08858427032828331), (12, 0.09083103388547897), (16, 0.092830715700984), (5, 0.1061495915055275), (36, 0.5903700739145279), (18, 0.6971046552062035), (53, 0.8206263184547424)]
computing accuracy for after removing block 47 . block score: 0.022912679240107536
removed block 47 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.023672. All blocks and scores: [(45, 0.0236718594096601), (44, 0.025098441867157817), (49, 0.030094766058027744), (50, 0.030112933833152056), (48, 0.03077566996216774), (42, 0.0323080625385046), (15, 0.03231056407094002), (7, 0.03280110703781247), (9, 0.04395893309265375), (51, 0.04449773672968149), (39, 0.04458759259432554), (38, 0.044963160529732704), (6, 0.04621813399717212), (4, 0.046273309737443924), (14, 0.04803795600309968), (2, 0.05475839460268617), (37, 0.0571177126839757), (3, 0.057577645406126976), (11, 0.059776697773486376), (13, 0.05998808844015002), (0, 0.06340089254081249), (19, 0.06357259023934603), (1, 0.06726935971528292), (52, 0.06897734571248293), (17, 0.07068715896457434), (20, 0.07387815974652767), (8, 0.07457848079502583), (10, 0.08145145792514086), (25, 0.08858427125960588), (12, 0.0908310366794467), (16, 0.09283071663230658), (5, 0.10614959429949522), (36, 0.5903700664639473), (18, 0.6971046477556229), (53, 0.8801519274711609)]
computing accuracy for after removing block 45 . block score: 0.0236718594096601
removed block 45 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.025098. All blocks and scores: [(44, 0.02509844209998846), (49, 0.030802560737356544), (50, 0.031185403000563383), (48, 0.0318988545332104), (42, 0.03230806393548846), (15, 0.03231056407094002), (7, 0.0328011061064899), (51, 0.04362803418189287), (9, 0.04395893309265375), (39, 0.04458759305998683), (38, 0.044963160529732704), (6, 0.04621813353151083), (4, 0.046273307874798775), (14, 0.04803795414045453), (2, 0.05475839413702488), (37, 0.057117709424346685), (3, 0.05757764587178826), (11, 0.05977669730782509), (13, 0.05998809216544032), (0, 0.06340089160948992), (19, 0.06357258930802345), (1, 0.06726935971528292), (52, 0.06805906631052494), (17, 0.07068715989589691), (20, 0.0738781588152051), (8, 0.07457847986370325), (10, 0.08145146258175373), (25, 0.08858427125960588), (12, 0.09083103388547897), (16, 0.09283071849495173), (5, 0.1061495952308178), (36, 0.5903700664639473), (18, 0.6971046403050423), (53, 0.958303339779377)]
computing accuracy for after removing block 44 . block score: 0.02509844209998846
removed block 44 current accuracy 0.9068 loss from initial  0.04459999999999997
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.030423. All blocks and scores: [(49, 0.030423364834859967), (50, 0.03139795083552599), (48, 0.03182956762611866), (42, 0.032308061607182026), (15, 0.03231056407094002), (7, 0.032801106572151184), (51, 0.04268135828897357), (9, 0.043958932626992464), (39, 0.04458759119734168), (38, 0.044963160529732704), (6, 0.04621813306584954), (4, 0.04627330834046006), (14, 0.048037956934422255), (2, 0.05475839367136359), (37, 0.05711771221831441), (3, 0.05757764587178826), (11, 0.05977669497951865), (13, 0.05998808844015002), (0, 0.06340089254081249), (19, 0.06357258558273315), (52, 0.06692808959633112), (1, 0.06726935878396034), (17, 0.07068715989589691), (20, 0.07387815974652767), (8, 0.07457847986370325), (10, 0.08145145885646343), (25, 0.08858426660299301), (12, 0.09083103481680155), (16, 0.09283071849495173), (5, 0.1061495952308178), (36, 0.5903700590133667), (18, 0.6971046477556229), (53, 1.081151083111763)]
computing accuracy for after removing block 49 . block score: 0.030423364834859967
removed block 49 current accuracy 0.8864 loss from initial  0.06500000000000006
since last training loss: 0.05300000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.031830. All blocks and scores: [(48, 0.03182956809177995), (42, 0.03230806393548846), (15, 0.03231056593358517), (7, 0.03280110517516732), (50, 0.033220607321709394), (9, 0.04395893169566989), (51, 0.04449286637827754), (39, 0.04458759352564812), (38, 0.04496316006407142), (6, 0.04621813166886568), (4, 0.04627330927178264), (14, 0.04803795460611582), (2, 0.05475839367136359), (37, 0.05711771221831441), (3, 0.057577647268772125), (11, 0.0597766968421638), (13, 0.05998808750882745), (0, 0.06340089160948992), (19, 0.06357258465141058), (1, 0.06726935971528292), (52, 0.0675203874707222), (17, 0.07068715989589691), (20, 0.07387816067785025), (8, 0.07457848079502583), (10, 0.081451459787786), (25, 0.08858427125960588), (12, 0.09083103574812412), (16, 0.092830715700984), (5, 0.1061495952308178), (36, 0.5903700664639473), (18, 0.6971046552062035), (53, 1.246860757470131)]
computing accuracy for after removing block 48 . block score: 0.03182956809177995
removed block 48 current accuracy 0.8644 loss from initial  0.08700000000000008
since last training loss: 0.07500000000000007 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 42, with score 0.032308. All blocks and scores: [(42, 0.032308063469827175), (15, 0.03231056407094002), (7, 0.032801106572151184), (50, 0.039953520987182856), (9, 0.043958932626992464), (51, 0.044036540668457747), (39, 0.04458759305998683), (38, 0.04496316146105528), (6, 0.04621813353151083), (4, 0.04627330927178264), (14, 0.048037955071777105), (2, 0.05475839227437973), (37, 0.05711771221831441), (3, 0.05757764587178826), (11, 0.059776694513857365), (13, 0.05998808844015002), (0, 0.06340089067816734), (19, 0.06357258930802345), (1, 0.06726935878396034), (17, 0.07068715989589691), (52, 0.07332917395979166), (20, 0.07387816067785025), (8, 0.0745784817263484), (10, 0.081451459787786), (25, 0.08858427032828331), (12, 0.09083103388547897), (16, 0.0928307194262743), (5, 0.10614959243685007), (36, 0.5903700813651085), (18, 0.6971046552062035), (53, 1.3277686834335327)]
computing accuracy for after removing block 42 . block score: 0.032308063469827175
removed block 42 current accuracy 0.8392 loss from initial  0.11220000000000008
since last training loss: 0.10020000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032311. All blocks and scores: [(15, 0.03231056500226259), (7, 0.03280110564082861), (51, 0.04304975923150778), (9, 0.04395893169566989), (39, 0.04458759259432554), (50, 0.04463005205616355), (38, 0.04496316099539399), (6, 0.04621813353151083), (4, 0.04627331020310521), (14, 0.048037956934422255), (2, 0.05475839274004102), (37, 0.057117713149636984), (3, 0.0575776444748044), (11, 0.05977669823914766), (13, 0.05998808890581131), (0, 0.06340088974684477), (19, 0.06357259023934603), (1, 0.06726936157792807), (17, 0.07068715989589691), (20, 0.07387816347181797), (8, 0.07457847986370325), (52, 0.07897353172302246), (10, 0.081451459787786), (25, 0.08858426846563816), (12, 0.09083103388547897), (16, 0.092830715700984), (5, 0.10614959243685007), (36, 0.5903700664639473), (18, 0.6971046775579453), (53, 1.3524134010076523)]
computing accuracy for after removing block 15 . block score: 0.03231056500226259
removed block 15 current accuracy 0.8242 loss from initial  0.12719999999999998
since last training loss: 0.11519999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032801. All blocks and scores: [(7, 0.03280110517516732), (51, 0.041977521032094955), (9, 0.04395893216133118), (39, 0.044213269371539354), (38, 0.04437016509473324), (50, 0.04581688577309251), (6, 0.04621813399717212), (4, 0.04627330927178264), (14, 0.048037955071777105), (2, 0.05475839227437973), (3, 0.057577645406126976), (37, 0.057657347060739994), (11, 0.05977669730782509), (13, 0.05998808704316616), (19, 0.06334616988897324), (0, 0.06340089254081249), (1, 0.06726936064660549), (20, 0.06890007015317678), (8, 0.0745784817263484), (17, 0.07501563895493746), (52, 0.07691327389329672), (10, 0.08145146071910858), (25, 0.08491063490509987), (12, 0.09083103109151125), (16, 0.09556048549711704), (5, 0.1061495952308178), (36, 0.5802121609449387), (18, 0.6752715036273003), (53, 1.3833675682544708)]
computing accuracy for after removing block 7 . block score: 0.03280110517516732
removed block 7 current accuracy 0.7928 loss from initial  0.15860000000000007
since last training loss: 0.14660000000000006 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.040044. All blocks and scores: [(51, 0.04004399757832289), (38, 0.04360618442296982), (39, 0.04375665448606014), (9, 0.04382432624697685), (14, 0.044390559662133455), (6, 0.046218134462833405), (4, 0.04627330880612135), (50, 0.048210571985691786), (13, 0.051931270863860846), (37, 0.0541172344237566), (2, 0.05475839180871844), (11, 0.05646029394119978), (3, 0.05757764773443341), (19, 0.06106372131034732), (0, 0.06340089067816734), (17, 0.06521467864513397), (20, 0.06666641402989626), (1, 0.06726936250925064), (52, 0.07124932110309601), (8, 0.07261371053755283), (25, 0.07970245089381933), (10, 0.08387652970850468), (12, 0.08483340963721275), (16, 0.08926092833280563), (5, 0.1061495952308178), (36, 0.5583784580230713), (18, 0.6496016979217529), (53, 1.405577838420868)]
computing accuracy for after removing block 51 . block score: 0.04004399757832289
removed block 51 current accuracy 0.676 loss from initial  0.2754
training start
training epoch 0 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.1]
training epoch 1 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 2 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 3 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.1]
training epoch 4 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.1]
training epoch 5 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 6 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 8 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 9 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 10 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.935600)
finished training. finished 50 epochs. accuracy 0.9356 topk_dict {'top1': 0.9356}
start iteration 27
[activation diff]: block to remove picked: 4, with score 0.048374. All blocks and scores: [(4, 0.04837361071258783), (2, 0.05162747064605355), (6, 0.05876161064952612), (3, 0.06105105299502611), (11, 0.062456391751766205), (9, 0.06277352292090654), (0, 0.06369548663496971), (19, 0.06456517614424229), (1, 0.06745889317244291), (17, 0.07385728508234024), (14, 0.07422334048897028), (50, 0.07451717741787434), (20, 0.07523327879607677), (13, 0.07753435522317886), (38, 0.08141893707215786), (25, 0.08532202243804932), (37, 0.08797789085656404), (39, 0.08868316374719143), (8, 0.09180240798741579), (52, 0.092486503534019), (16, 0.09710484929382801), (12, 0.1008898401632905), (10, 0.10696323122829199), (5, 0.11178019735962152), (36, 0.5848629772663116), (18, 0.6884400174021721), (53, 0.8155245929956436)]
computing accuracy for after removing block 4 . block score: 0.04837361071258783
removed block 4 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 2, with score 0.051627. All blocks and scores: [(2, 0.05162746971473098), (11, 0.05979189509525895), (3, 0.06105105113238096), (0, 0.06369548849761486), (6, 0.06380328349769115), (9, 0.06614806968718767), (1, 0.06745889503508806), (19, 0.06798859778791666), (14, 0.07142613548785448), (17, 0.07188966497778893), (50, 0.0738986898213625), (20, 0.0746140368282795), (13, 0.07576538436114788), (38, 0.08169863279908895), (25, 0.08410337381064892), (39, 0.08799176663160324), (37, 0.0901227779686451), (16, 0.0915236584842205), (52, 0.09191570430994034), (8, 0.09212045092135668), (12, 0.09579201135784388), (10, 0.10452690254896879), (5, 0.12152445875108242), (36, 0.5918489620089531), (18, 0.695797473192215), (53, 0.811558835208416)]
computing accuracy for after removing block 2 . block score: 0.05162746971473098
removed block 2 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 3, with score 0.053042. All blocks and scores: [(3, 0.0530424565076828), (11, 0.05831254692748189), (6, 0.05833439389243722), (17, 0.0611406029202044), (9, 0.06273160176351666), (0, 0.06369549036026001), (19, 0.06583332177251577), (1, 0.06745889410376549), (14, 0.06792793609201908), (50, 0.07001177780330181), (13, 0.07050742395222187), (20, 0.0708947042003274), (25, 0.07683350332081318), (38, 0.07740782387554646), (37, 0.08355917036533356), (39, 0.08449474722146988), (8, 0.08531434368342161), (52, 0.08616736810654402), (16, 0.08653381559997797), (12, 0.0940463999286294), (10, 0.10569813195616007), (5, 0.11949885915964842), (36, 0.553254209458828), (18, 0.6425177603960037), (53, 0.8126378580927849)]
computing accuracy for after removing block 3 . block score: 0.0530424565076828
removed block 3 current accuracy 0.9072 loss from initial  0.04420000000000002
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 11, with score 0.054570. All blocks and scores: [(11, 0.054569951724261045), (17, 0.059019829612225294), (6, 0.06006807088851929), (14, 0.06336711812764406), (0, 0.06369548849761486), (20, 0.06552560161799192), (19, 0.0656117768958211), (50, 0.06655218172818422), (1, 0.06745889410376549), (13, 0.06904885452240705), (25, 0.06965146493166685), (9, 0.0706382766366005), (16, 0.07234301697462797), (38, 0.07369678374379873), (52, 0.07957795727998018), (37, 0.07983627170324326), (39, 0.0800258656963706), (8, 0.08185948431491852), (12, 0.09066199325025082), (10, 0.10637572035193443), (5, 0.13640561141073704), (36, 0.5229506716132164), (18, 0.6045274063944817), (53, 0.8019895255565643)]
computing accuracy for after removing block 11 . block score: 0.054569951724261045
removed block 11 current accuracy 0.8922 loss from initial  0.05920000000000003
since last training loss: 0.043399999999999994 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 16, with score 0.053008. All blocks and scores: [(16, 0.05300774797797203), (17, 0.05578242754563689), (14, 0.056045631878077984), (6, 0.060068070422858), (0, 0.06369548756629229), (20, 0.06379510834813118), (13, 0.06416559964418411), (19, 0.06441779155284166), (50, 0.06524806655943394), (25, 0.06616266630589962), (1, 0.06745889410376549), (9, 0.07063827756792307), (38, 0.07397060468792915), (12, 0.07468728348612785), (52, 0.07867288216948509), (37, 0.07891433965414762), (39, 0.08028580248355865), (8, 0.08185948245227337), (10, 0.10637571942061186), (5, 0.1364056132733822), (36, 0.5202185586094856), (18, 0.5949403047561646), (53, 0.8090819269418716)]
computing accuracy for after removing block 16 . block score: 0.05300774797797203
removed block 16 current accuracy 0.8522 loss from initial  0.09920000000000007
since last training loss: 0.08340000000000003 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 14, with score 0.056046. All blocks and scores: [(14, 0.05604563234373927), (17, 0.05976308835670352), (6, 0.0600680741481483), (0, 0.06369548756629229), (25, 0.06398131232708693), (13, 0.06416559778153896), (50, 0.0660046674311161), (20, 0.06685333512723446), (1, 0.06745889224112034), (9, 0.07063827477395535), (38, 0.07135466020554304), (52, 0.07452487573027611), (12, 0.0746872816234827), (19, 0.07565387897193432), (37, 0.07829948700964451), (39, 0.07866549491882324), (8, 0.08185948431491852), (10, 0.10637572035193443), (5, 0.1364056095480919), (36, 0.4842076934874058), (18, 0.5787858366966248), (53, 0.7801178321242332)]
computing accuracy for after removing block 14 . block score: 0.05604563234373927
removed block 14 current accuracy 0.7784 loss from initial  0.17300000000000004
since last training loss: 0.1572 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 6, with score 0.060068. All blocks and scores: [(6, 0.060068073216825724), (25, 0.06248723668977618), (0, 0.06369548849761486), (13, 0.06416559964418411), (20, 0.06424839235842228), (1, 0.06745889317244291), (17, 0.06757637578994036), (50, 0.06871210038661957), (52, 0.06982580851763487), (38, 0.06992808450013399), (9, 0.0706382766366005), (12, 0.07468728348612785), (19, 0.07695598062127829), (39, 0.07855131663382053), (8, 0.08185948338359594), (37, 0.08391328528523445), (10, 0.10637571755796671), (5, 0.1364056132733822), (36, 0.4989030286669731), (18, 0.6142288893461227), (53, 0.757305420935154)]
computing accuracy for after removing block 6 . block score: 0.060068073216825724
removed block 6 current accuracy 0.6712 loss from initial  0.2802
since last training loss: 0.26439999999999997 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 25, with score 0.060292. All blocks and scores: [(25, 0.06029160926118493), (52, 0.06171713909134269), (13, 0.06309005990624428), (20, 0.06313967704772949), (0, 0.06369548756629229), (38, 0.0665711360052228), (17, 0.06672216206789017), (1, 0.06745889317244291), (50, 0.06816885806620121), (12, 0.0734027000144124), (9, 0.0738454107195139), (39, 0.07434924598783255), (37, 0.08379095140844584), (19, 0.08431283198297024), (8, 0.08463752921670675), (10, 0.11620762012898922), (5, 0.13640561141073704), (36, 0.48681382089853287), (18, 0.630860447883606), (53, 0.7414042204618454)]
computing accuracy for after removing block 25 . block score: 0.06029160926118493
removed block 25 current accuracy 0.609 loss from initial  0.34240000000000004
since last training loss: 0.3266 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 52, with score 0.060206. All blocks and scores: [(52, 0.06020582374185324), (13, 0.063090062700212), (20, 0.06313967797905207), (0, 0.06369548756629229), (17, 0.06672216672450304), (1, 0.06745889596641064), (50, 0.06882440950721502), (38, 0.07206965424120426), (12, 0.0734027000144124), (39, 0.07358875311911106), (9, 0.07384541165083647), (19, 0.08431283198297024), (8, 0.08463753573596478), (37, 0.09491614997386932), (10, 0.1162076173350215), (5, 0.13640561699867249), (36, 0.5578541532158852), (18, 0.6308604404330254), (53, 0.7489693388342857)]
computing accuracy for after removing block 52 . block score: 0.06020582374185324
removed block 52 current accuracy 0.4916 loss from initial  0.45980000000000004
since last training loss: 0.444 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 13, with score 0.063090. All blocks and scores: [(13, 0.06309006316587329), (20, 0.06313968077301979), (0, 0.06369548942893744), (17, 0.06672216579318047), (1, 0.06745889503508806), (50, 0.06882440857589245), (38, 0.07206965610384941), (12, 0.0734027000144124), (39, 0.07358875218778849), (9, 0.0738454107195139), (19, 0.08431283105164766), (8, 0.08463753294199705), (37, 0.09491614997386932), (10, 0.11620761640369892), (5, 0.1364056132733822), (36, 0.5578541532158852), (18, 0.6308604404330254), (53, 1.0863566100597382)]
computing accuracy for after removing block 13 . block score: 0.06309006316587329
removed block 13 current accuracy 0.3414 loss from initial  0.6100000000000001
since last training loss: 0.5942000000000001 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 20, with score 0.063226. All blocks and scores: [(20, 0.06322590727359056), (0, 0.06369548849761486), (39, 0.06699097994714975), (1, 0.06745889503508806), (50, 0.07223658263683319), (38, 0.07249215804040432), (12, 0.0734027000144124), (9, 0.07384541165083647), (8, 0.08463753387331963), (17, 0.09519599284976721), (19, 0.09708540141582489), (37, 0.1034732423722744), (10, 0.11620761919766665), (5, 0.13640561699867249), (36, 0.5988000556826591), (18, 0.7161936089396477), (53, 1.0410598367452621)]
computing accuracy for after removing block 20 . block score: 0.06322590727359056
removed block 20 current accuracy 0.2764 loss from initial  0.675
since last training loss: 0.6592 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 0, with score 0.063695. All blocks and scores: [(0, 0.06369548756629229), (50, 0.0648637181147933), (39, 0.06719211675226688), (1, 0.06745889410376549), (12, 0.07340269908308983), (9, 0.07384541258215904), (38, 0.07459614519029856), (8, 0.0846375310793519), (17, 0.09519599284976721), (19, 0.09708540141582489), (10, 0.11620761267840862), (37, 0.1216904204338789), (5, 0.13640561513602734), (36, 0.6477496027946472), (18, 0.7161936089396477), (53, 1.0497449338436127)]
computing accuracy for after removing block 0 . block score: 0.06369548756629229
removed block 0 current accuracy 0.2284 loss from initial  0.7230000000000001
training start
training epoch 0 val accuracy 0.853 topk_dict {'top1': 0.853} is_best True lr [0.1]
training epoch 1 val accuracy 0.8118 topk_dict {'top1': 0.8118} is_best False lr [0.1]
training epoch 2 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.1]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 4 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 5 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 6 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best True lr [0.1]
training epoch 7 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 8 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 9 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 10 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.936400)
finished training. finished 50 epochs. accuracy 0.9364 topk_dict {'top1': 0.9364}
